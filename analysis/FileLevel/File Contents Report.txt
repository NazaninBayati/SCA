['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8maxpool\\16x9p8q-neon.c', [], ['    pytorch_u8maxpool_ukernel_16x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8maxpool\\16x9p8q-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8maxpool\\16x9p8q-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8maxpool\\16x9p8q-sse2.c', [], ['    pytorch_u8maxpool_ukernel_16x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\2x4c8-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\2x4c8-sse2.c', [], ['    pytorch_sse_reduce4_i32(__m128i x,__m128i y,__m128i z,__m128i w)', '    pytorch_q8gemm_ukernel_2x4c8__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x-sumrows-neon.c', [], ['    pytorch_q8sumrows_ukernel_4x__neon(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *a_sum)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x-sumrows-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x4c2-dq-sse2.c', [], ['    pytorch_q8gemm_dq_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x4c2-dq-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8conv\\4x4c2-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8conv\\4x4c2-sse2.c', [], ['    pytorch_q8conv_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x4c2-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x4c2-sse2.c', [], ['    pytorch_q8gemm_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x8-dq-neon.c', [], ['    pytorch_q8gemm_dq_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x8-dq-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8conv\\4x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8conv\\4x8-neon.c', [], ['    pytorch_q8conv_ukernel_4x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x8-neon.c', [], ['    pytorch_q8gemm_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\4x8c2-xzp-neon.c', [], ['    pytorch_q8gemm_xzp_ukernel_4x8c2__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params [1] requantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\4x8c2-xzp-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\sgemm\\5x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sgemm\\5x8-neon.c', [], ['    pytorch_sgemm_ukernel_5x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\6x4-neon.c', [], ['    pytorch_q8gemm_ukernel_6x4__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\6x4-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sgemm\\6x8-neon.c', [], ['    pytorch_sgemm_ukernel_6x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\sgemm\\6x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sconv\\6x8-psimd.c', [], ['    pytorch_sconv_ukernel_6x8__psimd(size_t mr,size_t nr,size_t kc,size_t ks,const float **a,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\sgemm\\6x8-psimd.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sgemm\\6x8-psimd.c', [], ['    pytorch_sgemm_ukernel_6x8__psimd(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gemm\\8x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8conv\\8x8-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gemm\\8x8-neon.c', [], ['    pytorch_q8gemm_ukernel_8x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8conv\\8x8-neon.c', [], ['    pytorch_q8conv_ukernel_8x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\hgemm\\8x8-neonfp16arith.c', [], ['    pytorch_hgemm_ukernel_8x8__neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\_functions.cpp', [], ['    backward(AutogradContext *ctx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,const Variable & input,const CrossMapLRN2dOptions & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\_functions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\abi-check.cpp', [], ['    main']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\abs_op.cc', ['    GetAbsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAbs', '    CAFFE_ANONYMOUS_VARIABLE_CPUAbsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Abs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AbsGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\abs_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\accumulate_grad.cpp', [], ['    AccumulateGrad(Variable variable_)', '    apply(variable_list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\accumulate_grad.h', [], ['    accumulateGrad(const Variable & variable,at::Tensor & variable_grad,const at::Tensor & new_grad,size_t num_expected_refs,const T & update_grad)', '    callHooks(const Variable & variable,at::Tensor new_grad)', '    _indices', '    _values', '    clone', '    defined', '    detach', '    is_contiguous', '    is_sparse', '    options', '    sizes', '    use_count', '    AccumulateGrad(Variable variable_)', '    apply(variable_list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\accumulate_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAccumulate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Accumulate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\accumulate_op.h', ['    final'], ['    AccumulateOp(Args,...)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\AccumulateType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\accuracy_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAccuracy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Accuracy', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\accuracy_op.h', ['    final'], ['    AccuracyOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\acos_op.cc', ['    GetAcosGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAcos', '    CAFFE_ANONYMOUS_VARIABLE_CPUAcosGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Acos', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AcosGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\acos_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Activation.cpp', [], ['    threshold_out(optional opt_result,const Tensor & self,Scalar threshold,Scalar value,const Tensor & other)', '    softshrink_check(Scalar lambd)', '    _rrelu_with_noise_train(Tensor & output,const Tensor & input,const Tensor & noise,Scalar lower_,Scalar upper_,Generator generator)', '    celu(const Tensor & self,Scalar alpha)', '    celu_(Tensor & self,Scalar alpha)', '    elu(const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    elu_(Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    elu_backward(const Tensor & grad_output,Scalar alpha,Scalar scale,Scalar input_scale,const Tensor & output)', '    elu_backward_out(Tensor & grad_input,const Tensor & grad_output,Scalar alpha,Scalar scale,Scalar input_scale,const Tensor & output)', '    elu_out(Tensor & result,const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    hardsigmoid(const Tensor & self)', '    hardsigmoid_(Tensor & self)', '    hardsigmoid_backward(const Tensor & grad_output,const Tensor & self)', '    hardsigmoid_out(Tensor & result,const Tensor & self)', '    hardswish(const Tensor & self)', '    hardswish_(Tensor & self)', '    hardswish_backward(const Tensor & grad_output,const Tensor & self)', '    hardswish_out(Tensor & result,const Tensor & self)', '    hardtanh(const Tensor & self,Scalar min,Scalar max)', '    hardtanh_(Tensor & self,Scalar min,Scalar max)', '    hardtanh_backward(const Tensor & grad_output,const Tensor & self,Scalar min,Scalar max)', '    hardtanh_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,Scalar min,Scalar max)', '    hardtanh_out(Tensor & result,const Tensor & self,Scalar min,Scalar max)', '    prelu_cpu(const Tensor & self,const Tensor & weight_)', '    prelu_cpu_backward_kernel_share_weights(const Tensor & input,const Tensor & weight,const Tensor & grad_out,Tensor & input_grad,Tensor & weight_grad)', '    prelu_cpu_kernel_multi_weights(Tensor & result,const Tensor & input,const Tensor & weight,int64_t input_dim0_size,int64_t channel_size,int64_t input_stride0,int64_t input_stride1)', '    prelu_cpu_kernel_share_weights(Tensor & result,const Tensor & input,const Tensor & weight)', '    relu(const Tensor & self)', '    relu_(Tensor & self)', '    rrelu(const Tensor & self,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_(Tensor & self,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_backward(const Tensor & grad_output,const Tensor & self_or_result,const Tensor & noise,Scalar lower,Scalar upper,bool training,bool is_result)', '    rrelu_with_noise_cpu(const Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_cpu_(Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_out_cpu(Tensor & output,const Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    selu(const Tensor & self)', '    selu_(Tensor & self)', '    softplus(const Tensor & self,Scalar beta,Scalar threshold)', '    softplus_backward(const Tensor & grad_output,const Tensor & self,Scalar beta,Scalar threshold,const Tensor & output)', '    softplus_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,Scalar beta,Scalar threshold,const Tensor & output)', '    softplus_out(Tensor & result,const Tensor & self,Scalar beta,Scalar threshold)', '    threshold(const Tensor & self,Scalar threshold,Scalar value)', '    threshold_(Tensor & self,Scalar threshold,Scalar value)', '    threshold_backward(const Tensor & grad,const Tensor & self,Scalar threshold)', '    threshold_out(Tensor & result,const Tensor & self,Scalar threshold,Scalar value)', '    prelu_backward_cpu(const Tensor & grad_out_,const Tensor & self,const Tensor & weight_)', '    prelu_cpu_backward_kernel_multi_weights(const Tensor & input,const Tensor & weight,const Tensor & grad_out,Tensor & input_grad,Tensor & weight_grad_collector,int64_t input_dim0_size,int64_t channel_size,int64_t input_stride0,int64_t input_stride1)', '    gelu_backward_cpu(const Tensor & grad,const Tensor & self)', '    gelu_cpu(const Tensor & self)', '    hardshrink(const Tensor & self,Scalar lambd)', '    hardshrink_backward(const Tensor & grad,const Tensor & self,Scalar lambd)', '    leaky_relu(const Tensor & self,Scalar negval)', '    leaky_relu_(Tensor & self,Scalar neg_val)', '    leaky_relu_backward(const Tensor & grad_output,const Tensor & self_or_result,Scalar negval,bool is_result)', '    leaky_relu_out(Tensor & result,const Tensor & self,Scalar negval)', '    log_sigmoid_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & buffer)', '    log_sigmoid_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & buffer)', '    log_sigmoid_forward_cpu(const Tensor & input)', '    log_sigmoid_forward_out_cpu(Tensor & result,Tensor & buffer,const Tensor & input)', '    softshrink(const Tensor & self,Scalar lambd)', '    softshrink_backward(const Tensor & grad,const Tensor & self,Scalar lambd)', '    softshrink_backward_out(Tensor & grad_input,const Tensor & grad,const Tensor & self,Scalar lambd)', '    softshrink_out(Tensor & result,const Tensor & self,Scalar lambd)', '    sum']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\activation.cpp', [], ['    CELUImpl(const CELUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    ELUImpl(const ELUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    GLUImpl(const GLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    HardshrinkImpl(const HardshrinkOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    HardtanhImpl(const HardtanhOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    LeakyReLUImpl(const LeakyReLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    LogSoftmaxImpl(const LogSoftmaxOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    _reset_parameters', '    forward(const Tensor & query,const Tensor & key,const Tensor & value,const Tensor & key_padding_mask,bool need_weights,const Tensor & attn_mask)', '    MultiheadAttentionImpl(const MultiheadAttentionOptions & options_)', '    reset', '    forward(const Tensor & input)', '    PReLUImpl(const PReLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    ReLU6Impl(const ReLU6Options & options_)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    ReLUImpl(const ReLUOptions & options_)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    RReLUImpl(const RReLUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    SELUImpl(const SELUOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftmaxImpl(const SoftmaxOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftminImpl(const SoftminOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftplusImpl(const SoftplusOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftshrinkImpl(const SoftshrinkOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    ThresholdImpl(const ThresholdOptions & options_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\activation.cpp', [], ['    GLUOptions(int64_t dim)', '    HardshrinkOptions(double lambda)', '    LogSoftmaxFuncOptions(int64_t dim)', '    LogSoftmaxOptions(int64_t dim)', '    MultiheadAttentionForwardFuncOptions(int64_t embed_dim_to_check,int64_t num_heads,Tensor in_proj_weight,Tensor in_proj_bias,Tensor bias_k,Tensor bias_v,bool add_zero_attn,double dropout_p,Tensor out_proj_weight,Tensor out_proj_bias)', '    MultiheadAttentionOptions(int64_t embed_dim,int64_t num_heads)', '    ReLU6Options(bool inplace)', '    ReLUOptions(bool inplace)', '    SELUOptions(bool inplace)', '    SoftmaxFuncOptions(int64_t dim)', '    SoftmaxOptions(int64_t dim)', '    SoftminFuncOptions(int64_t dim)', '    SoftminOptions(int64_t dim)', '    SoftshrinkOptions(double lambda)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\Activation.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\activation.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\activation.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Activation.h', [], ['    elu_backward_stub', '    elu_backward_stub', '    operator=', '    elu_stub', '    elu_stub', '    operator=', '    GeluBackwardKernel', '    GeluBackwardKernel', '    operator=', '    GeluKernel', '    GeluKernel', '    operator=', '    glu_backward_stub', '    glu_backward_stub', '    operator=', '    glu_stub', '    glu_stub', '    operator=', '    hardshrink_stub', '    hardshrink_stub', '    operator=', '    hardsigmoid_backward_stub', '    hardsigmoid_backward_stub', '    operator=', '    hardsigmoid_stub', '    hardsigmoid_stub', '    operator=', '    hardswish_backward_stub', '    hardswish_backward_stub', '    operator=', '    hardswish_stub', '    hardswish_stub', '    operator=', '    hardtanh_backward_stub', '    hardtanh_backward_stub', '    operator=', '    leaky_relu_backward_stub', '    leaky_relu_backward_stub', '    operator=', '    leaky_relu_stub', '    leaky_relu_stub', '    operator=', '    log_sigmoid_backward_cpu_stub', '    log_sigmoid_backward_cpu_stub', '    operator=', '    log_sigmoid_cpu_stub', '    log_sigmoid_cpu_stub', '    operator=', '    operator=', '    shrink_backward_stub', '    shrink_backward_stub', '    operator=', '    softplus_backward_stub', '    softplus_backward_stub', '    operator=', '    softplus_stub', '    softplus_stub', '    operator=', '    softshrink_stub', '    softshrink_stub', '    operator=', '    threshold_stub', '    threshold_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\activation.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\activation_distribution_observer.cc', [], ['    HasDNNLowPEngine_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorBase & op)', '    FindMinMax(const T *data,float *min,float *max,int len)', '    FindMinMax(const float *data,float *min,float *max,int len)', '    GetFloatTensorData(TensorCPU *tensor)', '    DumpAndReset_(const string & out_file_name,bool print_total_min_max)', '    HistogramNetObserver(NetBase *subject,const string & out_file_name,int nbins,int dump_freq,bool mul_nets,string op_filter,string delimiter)', '    Stop', '    ~HistogramNetObserver', '    HistogramObserver(OperatorBase *op,shared_ptr info)', '    Stop', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    OutputColumnMaxHistogramNetObserver(NetBase *subject,const std::string & out_file_name,const std::vector & observe_column_max_for_blobs,int nbins,int dump_freq,bool mul_nets,string delimiter)', '    Stop', '    ~OutputColumnMaxHistogramNetObserver', '    OutputColumnMaxHistogramObserver(OperatorBase *op,const std::string & col_max_blob_name,int nbins,std::shared_ptr info)', '    Stop', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    OutputMinMaxNetObserver(NetBase *subject,const string & out_file_name,int dump_freq,string delimiter)', '    Stop', '    ~OutputMinMaxNetObserver', '    OutputMinMaxObserver(OperatorBase *op)', '    Stop', '    ~OutputMinMaxObserver', '    RegisterQuantizationParamsNetObserver(NetBase *subject,const string & min_max_file_name,bool is_weight,const string & qparams_output_file_name)', '    RegisterQuantizationParamsWithHistogramNetObserver(NetBase *subject,const string & histogram_file_name,bool is_weight,const string & qparams_output_file_name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\activation_distribution_observer.h', ['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final'], ['    localtime_r(time_t *_clock,struct tm *_result)', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    DumpHistogramFile', '    GetInfo', '    HistogramNetObserver(NetBase *subject,const std::string & out_file_name,int nbins,int dump_freq,bool mul_nets,string op_filter,string delimiter)', '    HistogramObserver(OperatorBase *op,std::shared_ptr info)', '    OutputColumnMaxHistogramNetObserver(NetBase *subject,const std::string & out_file_name,const std::vector & observe_column_max_for_blobs,int nbins,int dump_freq,bool mul_nets,string delimiter)', '    OutputColumnMaxHistogramObserver(OperatorBase *op,const std::string & col_max_blob_name,int nbins,std::shared_ptr info)', '    OutputMinMaxNetObserver(NetBase *subject,const std::string & out_file_name,int dump_freq,string delimiter)', '    OutputMinMaxObserver(OperatorBase *op)', '    RegisterQuantizationParamsNetObserver(NetBase *subject,const std::string & min_max_file_name,bool is_weight,const std::string & qparams_output_file_name)', '    RegisterQuantizationParamsWithHistogramNetObserver(NetBase *subject,const std::string & histogram_file_name,bool is_weight,const std::string & qparams_output_file_name)', '    Stop', '    TensorInfo(const std::string & name)', '    Update(float cur_min,float cur_max)', '    ~HistogramNetObserver', '    ~OutputColumnMaxHistogramNetObserver', '    ~OutputMinMaxNetObserver', '    ~OutputMinMaxObserver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\activation_ops_cudnn.h', ['    CuDNNActivationOpBase', '    final', '    final'], ['    CuDNNActivationOpBase(Args,...)', '    SetTensorDescriptor(const cudnnDataType_t data_type,const int data_size)', '    ~CuDNNActivationOpBase', '    CuDNNActivationGradientOp(Args,...)', '    CuDNNActivationOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\hip\\activation_ops_miopen.h', ['    final', '    final', '    MIOPENActivationOpBase'], ['    DoRunWithType', '    DoRunWithType', '    MIOPENActivationGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    MIOPENActivationOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    MIOPENActivationOpBase(const OperatorDef & operator_def,Workspace *ws)', '    ~MIOPENActivationOpBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adadelta_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAdadelta', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdadelta', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adadelta', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdadelta']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adadelta_op.h', ['    final', '    final'], ['    AdadeltaUpdate(int N,const float *w,const float *g,const float *h,const float *d,const float epsilon,const float decay,const float *lr,float *nw,float *nh,float *nd,Context *)', '    AdadeltaOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SparseAdadeltaOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\adagrad.cc', [], ['    adagrad_fp16_update_prefetch(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_fp16_update_prefetch__base(int N,const at::Half *w,const at::Half *,const float *g,const at::Half *h,const at::Half *,at::Half *nw,at::Half *,at::Half *nh,at::Half *,float epsilon,float lr)', '    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update__base(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,const float lr)', '    adagrad_update_prefetch(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)', '    adagrad_update_prefetch__base(int N,const float *w,const float *,const float *g,const float *h,const float *,float *nw,float *,float *nh,float *,float epsilon,float lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\adagrad.cpp', [], ['    make_sparse', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    operator==(const AdagradOptions & lhs,const AdagradOptions & rhs)', '    operator==(const AdagradParamState & lhs,const AdagradParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    AdagradOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\adagrad.h', [], ['    adagrad_update_base_inlined(int N,const T *w,const float *g,const T *h,T *nw,T *nh,float decay,float epsilon,float lr)', '    adagrad_fp16_update_prefetch(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update_prefetch(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)', '    adagrad_update_prefetch_inlined(int N,const float *w,const float *,const float *g,const float *h,const float *,float *nw,float *,float *nh,float *,float epsilon,float lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\adagrad.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\adagrad_avx.cc', [], ['    adagrad_fp16_update_prefetch__avx_f16c(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_update__avx_f16c(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update_prefetch__avx_f16c(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adagrad_fused.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    operator()(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adagrad_fused.h', ['    final', '    final', '    final'], ['    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdagradFusedWithSparseLengthsSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    SparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp(const OperatorDef & operator_def,Workspace *ws)', '    SparseAdagradFusedWithSparseLengthsWeightedSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    Resize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adagrad_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAdagrad', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagrad', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagrad', '    CostInferenceForSparseAdagrad(const OperatorDef &,const vector & inputs)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adagrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagrad']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adagrad_op.h', ['    final', '    final', '    final'], ['    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,const float *lr,Context *)', '    adagrad_update_output_effective_lr(int N,const float *paramIn,const float *gradIn,const float *momentIn,float *paramOut,float *momentOut,float *effectiveLROut,float epsilon,float decay,const float *lr,Context *)', '    adagrad_update_output_effective_lr_and_update(int N,const float *paramIn,const float *gradIn,const float *momentIn,float *paramOut,float *momentOut,float *effectiveLROut,float *updateOut,float epsilon,float decay,const float *lr,Context *)', '    q_none(float *,size_t)', '    q_none_stoc(float *,size_t,CPUContext::rand_gen_type &)', '    AdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RowWiseSparseAdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\adam.cpp', [], ['    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    operator==(const AdamOptions & lhs,const AdamOptions & rhs)', '    operator==(const AdamParamState & lhs,const AdamParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    AdamOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\adam.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\adam_op.cc', ['    final'], ['    adam_ideep_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    adam_ideep_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    adam_ideep_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    beta1_', '    beta2_', '    epsilon_', '    IDEEPAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adam_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAdam', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdam', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdam']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\adam_op.h', ['    final', '    final', '    final'], ['    adam_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    adam_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    adam_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    radam_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    radam_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    radam_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    AdamOp(const OperatorDef & operator_def,Workspace *ws)', '    beta1_', '    beta2_', '    DoRunWithType', '    DoRunWithType', '    epsilon_', '    GetSingleArgument', '    RowWiseSparseAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\adaptive.cpp', [], ['    _get_full_log_prob(const Tensor & input,const Tensor & head_output)', '    AdaptiveLogSoftmaxWithLossImpl(AdaptiveLogSoftmaxWithLossOptions options_)', '    forward(const Tensor & input,const Tensor & target)', '    log_prob(const Tensor & input)', '    predict(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    ASMoutput(Tensor output_,double loss_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\adaptive.cpp', [], ['    AdaptiveLogSoftmaxWithLossOptions(int64_t in_features,int64_t n_classes,std::vector cutoffs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\adaptive.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\adaptive.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AdaptiveAveragePooling.cpp', [], ['    adaptive_avg_pool2d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_avg_pool2d(at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_backward_cpu(const Tensor & gradOutput,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool2d_cpu(at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_cpu_template(at::Tensor & output,at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AdaptiveAveragePooling3d.cpp', [], ['    adaptive_avg_pool3d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_avg_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_cpu(Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    adaptive_avg_pool3d_out_cpu_template(Tensor & output,Tensor const & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AdaptiveMaxPooling2d.cpp', [], ['    adaptive_max_pool2d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool2d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *indices,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool2d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool2d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_cpu(const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool2d_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool2d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AdaptiveMaxPooling3d.cpp', [], ['    adaptive_max_pool3d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool3d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool3d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool3d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_cpu(const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool3d_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool3d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\add-operator-tester.h', ['    AddOperatorTester'], ['    aScale(float aScale)', '    aScale', '    aScale_', '    aStride(size_t aStride)', '    aStride', '    aStride_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    bScale(float bScale)', '    bScale', '    bScale_', '    bStride(size_t bStride)', '    bStride', '    bStride_', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    channels(size_t channels)', '    channels', '    channels_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8', '    yScale(float yScale)', '    yScale', '    yScale_', '    yStride(size_t yStride)', '    yStride', '    yStride_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_', '    min_element']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\add.c', [], ['    pytorch_qnnp_create_add_nc_q8(size_t channels,uint8_t a_zero_point,float a_scale,uint8_t b_zero_point,float b_scale,uint8_t sum_zero_point,float sum_scale,uint8_t sum_min,uint8_t sum_max,uint32_t flags,pytorch_qnnp_operator_t *add_out)', '    pytorch_qnnp_setup_add_nc_q8(pytorch_qnnp_operator_t add_op,size_t batch_size,const uint8_t *a,size_t a_stride,const uint8_t *b,size_t b_stride,uint8_t *sum,size_t sum_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\add.cc', [], ['    add_nc_q8(benchmark::State & state)', '    add_nc_q8_inplace(benchmark::State & state)', '    CharacteristicArguments(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\add.cc', [], ['    TEST(ADD_OP,zero_batch)', '    TEST(ADD_OP,unit_batch)', '    TEST(ADD_OP,unit_batch_with_qmin)', '    TEST(ADD_OP,unit_batch_with_qmax)', '    TEST(ADD_OP,unit_batch_with_a_scale)', '    TEST(ADD_OP,unit_batch_with_b_scale)', '    TEST(ADD_OP,unit_batch_with_y_scale)', '    TEST(ADD_OP,unit_batch_with_a_zero_point)', '    TEST(ADD_OP,unit_batch_with_b_zero_point)', '    TEST(ADD_OP,unit_batch_with_y_zero_point)', '    TEST(ADD_OP,small_batch)', '    TEST(ADD_OP,small_batch_with_a_stride)', '    TEST(ADD_OP,small_batch_with_b_stride)', '    TEST(ADD_OP,small_batch_with_y_stride)', '    TEST(ADD_OP,small_batch_with_qmin)', '    TEST(ADD_OP,small_batch_with_qmax)', '    TEST(ADD_OP,small_batch_with_a_scale)', '    TEST(ADD_OP,small_batch_with_b_scale)', '    TEST(ADD_OP,small_batch_with_y_scale)', '    TEST(ADD_OP,small_batch_with_a_zero_point)', '    TEST(ADD_OP,small_batch_with_b_zero_point)', '    TEST(ADD_OP,small_batch_with_y_zero_point)', '    TEST(ADD_OP,strided_batch)', '    TEST(ADD_OP,strided_batch_with_qmin)', '    TEST(ADD_OP,strided_batch_with_qmax)', '    TEST(ADD_OP,strided_batch_with_a_scale)', '    TEST(ADD_OP,strided_batch_with_b_scale)', '    TEST(ADD_OP,strided_batch_with_y_scale)', '    TEST(ADD_OP,strided_batch_with_a_zero_point)', '    TEST(ADD_OP,strided_batch_with_b_zero_point)', '    TEST(ADD_OP,strided_batch_with_y_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\add_cpu.cc', [], ['    add_op_cpu_impl(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & C_,bool legacy_broadcast,int64_t axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\affine_channel_op.cc', ['    GetAffineChannelGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAffineChannel', '    CAFFE_ANONYMOUS_VARIABLE_CPUAffineChannelGradient', '    AffineChannelScaleBiasBackwardNCHW(const int N,const int C,const int HxW,const T *dY,const T *X,T *dscale,T *dbias)', '    AffineChannelScaleBiasBackwardNHWC(const int N,const int C,const int HxW,const T *dY,const T *X,T *dscale,T *dbias)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AffineChannel', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AffineChannelGradient', '    RunOnDeviceWithOrderNCHW', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\affine_channel_op.h', ['    final', '    final'], ['    AffineChannelGradientOp(Args,...)', '    AffineChannelOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\AffineGridGenerator.cpp', [], ['    cudnn_affine_grid_generator_backward(const Tensor & grad_grid_t,int64_t N,int64_t C,int64_t H,int64_t W)', '    cudnn_affine_grid_generator_forward(const Tensor & theta_t,int64_t N,int64_t C,int64_t H,int64_t W)', '    setSamplerDescriptor(SpatialTransformerDescriptor & desc,cudnnDataType_t dataType,int N,int C,int H,int W)', '    grad_grid', '    theta']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AffineGridGenerator.cpp', [], ['    affine_grid_generator(const Tensor & theta,IntArrayRef size,bool align_corners)', '    affine_grid_generator_4D(const Tensor & theta,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_4D_backward(const Tensor & grad_grid,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_5D(const Tensor & theta,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_5D_backward(const Tensor & grad_grid,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_backward(const Tensor & grad,IntArrayRef size,bool align_corners)', '    linspace_from_neg_one(const Tensor & grid,int64_t num_steps,bool align_corners)', '    make_base_grid_4D(const Tensor & theta,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    make_base_grid_5D(const Tensor & theta,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Graph\\Algorithms.h', [], ['    createSubgraph(GraphType *g)', '    induceEdges(SubgraphType *sg)', '    dominatorTree(G *g,G::NodeRef source)', '    immediateDominatorMap(G *g,G::NodeRef source)', '    reachable(G::NodeRef root,G::NodeRef ignored,std::unordered_set *seen)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\AlgorithmsTest.cc', [], ['    TEST(DominatorTree,Test1)', '    TEST(DominatorTree,Test2)', '    TEST(Subgraph,InduceEdges)', '    TEST(Subgraph,InduceEdgesCycle)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\alias_analysis.cpp', ['    WorkingSet'], ['    ss', '    getMutableTypePtr(const TypePtr & type)', '    mutableType(const Value *v)', '    findSameBlock(Node *target,Node *n)', '    addContainedTypesToFreshElement(Element *container_elem,const TypePtr & mut_type)', '    addToContainedElements(const Value *elem,const Value *container)', '    AliasDb(std::shared_ptr graph,bool isFrozen)', '    analyze(const std::shared_ptr & graph)', '    analyze(Block *block)', '    analyze(Node *node)', '    analyzeBroadcastingChunk(Node *node)', '    analyzeChunk(Node *node)', '    analyzeConservative(Node *node)', '    analyzeContainerConstruct(Node *node)', '    analyzeCreator(Node *node)', '    analyzeExtractor(Node *node)', '    analyzeFork(Node *node)', '    analyzeGradOf(Node *node)', '    analyzeIf(Node *node)', '    analyzeImpl(Node *node)', '    analyzeLoop(Node *node)', '    analyzeRpcAsync(Node *node)', '    analyzeSetAttr(Node *node)', '    analyzeSubgraph(Node *node)', '    analyzeWait(Node *node)', '    couldMoveAfterTopologically(Node *n,Node *movePoint)', '    couldMoveBeforeTopologically(Node *n,Node *movePoint)', '    dump', '    escapesScope(const at::ArrayRef & vs)', '    getElementName(const Element *e)', '    getElements(at::ArrayRef vs)', '    getOrCreateElement(const Value *value)', '    getReads(Node *n)', '    getReadsImpl(Node *n,MemoryLocations & ret)', '    getWildcard(const TypePtr & type)', '    getWrites(Node *n)', '    getWritesImpl(Node *n,MemoryLocations & ret)', '    giveFreshAlias(const Value *value)', '    hasInputWriters(const Node *n)', '    hasOutputWriters(const Node *n)', '    hasWriters(const Node *n)', '    hasWriters(const Value *v)', '    hasWriters(const at::ArrayRef & values)', '    isContainerType(const TypePtr & type)', '    isMutable(Node *n)', '    makePointerTo(const Value *from,const Value *to)', '    mapAliases(at::ArrayRef from,at::ArrayRef to)', '    mayAlias(const Value *a,const Value *b)', '    mayAlias(const ValueSet & a,const ValueSet & b)', '    mayAliasWildcard(const Value *v)', '    mayAliasWildcard(const at::ArrayRef vs)', '    mayContainAlias(Value *a,Value *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    move(Node *toMove,Node *movePoint,MoveSide moveSide)', '    moveAfterTopologicallyValid(Node *n,Node *movePoint)', '    moveBeforeTopologicallyValid(Node *n,Node *movePoint)', '    mutableType(const TypePtr & type)', '    nonAliasingValue(const Value *elem)', '    rebuildWriteCache', '    registerWrite(const Value *v,Node *n)', '    registerWrite(const Element *e,Node *n)', '    safeToChangeAliasingRelationship(const at::ArrayRef & a,const at::ArrayRef & b)', '    setWildcard(const Value *v)', '    toString', '    tryGetOrCreateWildcard(const TypePtr & type)', '    tryMove(Node *toMove,Node *movePoint,MoveSide moveSide,bool dryRun)', '    tryRegisteredAnalysis(Node *node)', '    add(Node *n)', '    consumesFrom(Node *n)', '    dependentNodes', '    dependsOn(Node *n)', '    eraseMover', '    getUsersSameBlock(Node *n)', '    hasDataDependency(Node *n)', '    hasMutabilityDependency(Node *n)', '    producesFor(Node *n)', '    WorkingSet(Node *mover,const AliasDb & aliasDb)', '    writesToAlias(Node *n,const ValueSet & vs)', '    writesToWildcard(Node *n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\alias_analysis.h', ['    AliasDb', '    MoveSide'], ['    getMutableTypeKind(const TypePtr & type)', '    isContainerType(const TypePtr & type)', '    mutableType(const Value *v)', '    mutableType(const TypePtr & type)', '    addContainedTypesToFreshElement(Element *container_elem,const TypePtr & mut_type)', '    addToContainedElements(const Value *elem,const Value *container)', '    AliasDb(std::shared_ptr graph,bool isFrozen)', '    analyze(const std::shared_ptr & graph)', '    analyze(Node *node)', '    analyze(Block *block)', '    analyzeBroadcastingChunk(Node *node)', '    analyzeChunk(Node *node)', '    analyzeConservative(Node *node)', '    analyzeContainerConstruct(Node *node)', '    analyzeCreator(Node *node)', '    analyzeExtractor(Node *node)', '    analyzeFork(Node *node)', '    analyzeGradOf(Node *node)', '    analyzeIf(Node *node)', '    analyzeImpl(Node *node)', '    analyzeLoop(Node *node)', '    analyzeRpcAsync(Node *node)', '    analyzeSetAttr(Node *node)', '    analyzeSubgraph(Node *node)', '    analyzeWait(Node *node)', '    couldMoveAfterTopologically(Node *n,Node *movePoint)', '    couldMoveBeforeTopologically(Node *n,Node *movePoint)', '    dump', '    escapesScope(const at::ArrayRef & vs)', '    getElementName(const Element *e)', '    getElements(at::ArrayRef vs)', '    getOrCreateElement(const Value *value)', '    getReads(Node *n)', '    getReadsImpl(Node *n,MemoryLocations & ret)', '    getWildcard(const TypePtr & type)', '    getWrites(Node *n)', '    getWritesImpl(Node *n,MemoryLocations & ret)', '    giveFreshAlias(const Value *value)', '    hasInputWriters(const Node *n)', '    hasOutputWriters(const Node *n)', '    hasWriters(const Node *n)', '    hasWriters(const Value *v)', '    hasWriters(const at::ArrayRef & values)', '    isBeforeOrAfter(const Node *n,MoveSide moveSide)', '    isMutable(Node *n)', '    makeAllAlias(const std::vector & values)', '    makePointerTo(const Value *from,const Value *to)', '    mapAliases(at::ArrayRef from,at::ArrayRef to)', '    mayAlias(const Value *a,const Value *b)', '    mayAlias(const ValueSet & a,const ValueSet & b)', '    mayAliasWildcard(const Value *v)', '    mayAliasWildcard(const at::ArrayRef vs)', '    mayContainAlias(Value *a,Value *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    move(Node *toMove,Node *movePoint,MoveSide moveSide)', '    moveAfterTopologicallyValid(Node *n,Node *movePoint)', '    moveBeforeTopologicallyValid(Node *n,Node *movePoint)', '    nonAliasingValue(const Value *elem)', '    rebuildWriteCache', '    registerWrite(const Value *v,Node *n)', '    registerWrite(const Element *e,Node *n)', '    safeToChangeAliasingRelationship(const at::ArrayRef & a,const at::ArrayRef & b)', '    setWildcard(const Value *v)', '    toString', '    tryGetOrCreateWildcard(const TypePtr & type)', '    tryMove(Node *toMove,Node *movePoint,MoveSide moveSide,bool dryRun)', '    tryRegisteredAnalysis(Node *node)', '    writesToAlias(Node *n,const ValueSet & vs)', '    writesToWildcard(Node *n)', '    ~AliasDb']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\alias_info.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\alias_with_name.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAliasWithName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AliasWithName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\alias_with_name.h', ['    final'], ['    schema_AliasWithName', '    AliasWithNameOp(Args,...)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\AlignedAllocator.h', ['    AlignedAllocator', '    AlignedAllocator'], ['    address(reference x)', '    address(const_reference x)', '    AlignedAllocator', '    AlignedAllocator(const AlignedAllocator & other)', '    allocate(size_type n,AlignedAllocator::const_pointer hint)', '    construct(U *p,Args,...)', '    deallocate(pointer p,size_type n)', '    destroy(U *p)', '    max_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\AlignOf.h', ['    AlignerImpl'], ['    AlignerImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\all.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\allgather_ops.cc', [], ['    initializeAlgorithm']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\allgather_ops.h', ['    final'], ['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    AllgatherOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeAlgorithm', '    RunOnDevice', '    update(GlooParameters & params)', '    ~AllgatherOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\alloc_info.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\allocator.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Allocator.cpp', [], ['    deleteInefficientStdFunctionContext(void *ptr)', '    GetAllocator(const at::DeviceType & t)', '    SetAllocator(at::DeviceType t,at::Allocator *alloc)', '    makeDataPtr(void *ptr,const std::function & deleter,Device device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Allocator.h', ['    DataPtr'], ['    cast_context(DeleterFnPtr expected_deleter)', '    compare_exchange_deleter(DeleterFnPtr expected_deleter,DeleterFnPtr new_deleter)', '    device', '    get_deleter', '    operator bool', '    unsafe_set_device(Device device)', '    GetAllocator(const DeviceType & t)', '    operator!=(const DataPtr & dp,std::nullptr_t)', '    operator!=(std::nullptr_t,const DataPtr & dp)', '    operator==(const DataPtr & dp,std::nullptr_t)', '    operator==(std::nullptr_t,const DataPtr & dp)', '    SetAllocator(DeviceType t,Allocator *alloc)', '    makeDataPtr(void *ptr,const std::function & deleter,Device device)', '    allocate(size_t n)', '    raw_allocate(size_t n)', '    raw_deallocate(void *ptr)', '    raw_deleter', '    ~Allocator', '    AllocatorRegisterer(Allocator *alloc)', '    clear', '    DataPtr', '    DataPtr(void *data,Device device)', '    DataPtr(void *data,void *ctx,DeleterFnPtr ctx_deleter,Device device)', '    get', '    get_context', '    operator->', '    release_context', '    InefficientStdFunctionContext(std::unique_ptr,std::function)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\allocator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\utils\\Allocator.h', ['    final'], ['    memory', '    memory', '    deleter(void *pointer)', '    allocate(size_t nbytes)', '    GuardingAllocator', '    raw_deleter', '    ~GuardingAllocator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\example\\allreduce.cpp', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\allreduce_ops.cc', [], ['    getAllrduceBcubeBase(int nodes)', '    base', '    baseCheck', '    getExponent', '    initializeBcube', '    initializeRingChunked', '    initializeRingFull']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\allreduce_ops.h', ['    final'], ['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    AllreduceOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeBcube', '    initializeHalvingDoubling', '    initializeRingChunked', '    initializeRingFull', '    RunOnDevice', '    update(GlooParameters & params)', '    ~AllreduceOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\allreduce_ops_gpu.cc', [], ['    getAllrduceBcubeBase(int nodes)', '    base', '    baseCheck', '    initializeAlgorithm(bool gpu_direct_,std::shared_ptr context,std::vector ptrs,size_t size)', '    getExponent', '    initializeHalvingDoubling', '    initializeRingChunked', '    initializeRingFull']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\analysis.h', ['    HasRand'], ['    has_rand', '    HasRand(Stmt *stmt)', '    visit(const Intrinsics *v)', '    op_type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\code_analyzer\\analyzer.cpp', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\annotations.cc', [], ['    classof(const Annotation *A)', '    getComponentLevels', '    getDevice', '    getDeviceOption', '    getDeviceType', '    getKeyNode', '    getLengthNode', '    getMutableDeviceOption', '    getMutableOperatorDef', '    getOperatorDef', '    getParallelization', '    getParallelizationScheme', '    hasDeviceOption', '    hasOperatorDef', '    setComponentLevels(std::vector components)', '    setDevice(std::string device)', '    setDeviceOption(const caffe2::DeviceOption & devOpt)', '    setDeviceType(int device)', '    setKeyNode(NNGraph::NodeRef n)', '    setLengthNode(NNGraph::NodeRef n)', '    setOperatorDef(const caffe2::OperatorDef & opDef)', '    setParallelization(Caffe2Annotation::ParallelizationScheme s,int num)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\annotations.h', ['    Caffe2Annotation', '    ParallelizationScheme'], ['    classof(const Annotation *A)', '    Caffe2Annotation', '    Caffe2Annotation(std::string device)', '    getComponentLevels', '    getDevice', '    getDeviceOption', '    getDeviceType', '    getKeyNode', '    getLengthNode', '    getMutableDeviceOption', '    getMutableOperatorDef', '    getOperatorDef', '    getParallelization', '    getParallelizationScheme', '    hasDeviceOption', '    hasOperatorDef', '    setComponentLevels(std::vector components)', '    setDevice(std::string device)', '    setDeviceOption(const caffe2::DeviceOption & devOpt)', '    setDeviceType(int device)', '    setKeyNode(nom::repr::NNGraph::NodeRef)', '    setLengthNode(nom::repr::NNGraph::NodeRef)', '    setOperatorDef(const caffe2::OperatorDef & opDef)', '    setParallelization(Caffe2Annotation::ParallelizationScheme s,int num)', '    ~Caffe2Annotation']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\anomaly_mode.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\anomaly_mode.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\any.cpp', [], ['    TEST_F(AnyModuleTest,SimpleReturnType)', '    TEST_F(AnyModuleTest,SimpleReturnTypeAndSingleArgument)', '    TEST_F(AnyModuleTest,StringLiteralReturnTypeAndArgument)', '    TEST_F(AnyModuleTest,StringReturnTypeWithConstArgument)', '    TEST_F(AnyModuleTest,TensorReturnTypeAndStringArgumentsWithFunkyQualifications)', '    TEST_F(AnyModuleTest,WrongArgumentType)', '    TEST_F(AnyModuleTest,WrongNumberOfArguments)', '    TEST_F(AnyModuleTest,PassingArgumentsToModuleWithDefaultArgumentsInForwardMethod)', '    TEST_F(AnyModuleTest,GetWithCorrectTypeSucceeds)', '    TEST_F(AnyModuleTest,GetWithIncorrectTypeThrows)', '    TEST_F(AnyModuleTest,PtrWithBaseClassSucceeds)', '    TEST_F(AnyModuleTest,PtrWithGoodDowncastSuccceeds)', '    TEST_F(AnyModuleTest,PtrWithBadDowncastThrows)', '    TEST_F(AnyModuleTest,DefaultStateIsEmpty)', '    TEST_F(AnyModuleTest,AllMethodsThrowForEmptyAnyModule)', '    TEST_F(AnyModuleTest,CanMoveAssignDifferentModules)', '    TEST_F(AnyModuleTest,ConstructsFromModuleHolder)', '    TEST_F(AnyModuleTest,ConvertsVariableToTensorCorrectly)', '    TEST_F(AnyValueTest,CorrectlyAccessesIntWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesStringLiteralWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesStringWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesPointersWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesReferencesWhenCorrectType)', '    TEST_F(AnyValueTest,TryGetReturnsNullptrForTheWrongType)', '    TEST_F(AnyValueTest,GetThrowsForTheWrongType)', '    TEST_F(AnyValueTest,MoveConstructionIsAllowed)', '    TEST_F(AnyValueTest,MoveAssignmentIsAllowed)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForInt)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForStringLiteral)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForString)', '    make_value(T)', '    forward(int x)', '    forward(int x)', '    forward(torch::Tensor input)', '    forward(int x)', '    forward(float x)', '    forward(const char *x)', '    forward(int x,const double f)', '    forward(std::string a,const std::string & b,std::string)', '    forward', '    forward(float x)', '    forward(float x)', '    M(int value_)', '    M(int value_)', '    _forward_has_default_args', '    _forward_num_required_args', '    _forward_populate_default_args(std::vector)', '    forward(int a,int b,double c)', '    forward(int a,int b,double c)', '    forward(int a,int b)', '    forward(float x)', '    MImpl(int value_)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(float x)', '    operator()', '    TestAnyValue(T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\any.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\any_module_holder.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\any_value.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\apmeter_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAPMeter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_APMeter', '    BufferPredictions(const float *XData,const int *labelData,int N,int D)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\apmeter_op.h', ['    final'], ['    APMeterOp(Args,...)', '    BufferPredictions(const float *Xdata,const int *labelData,int N,int D)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\ios\\TestApp\\TestApp\\AppDelegate.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\apply_utils_test.cpp', [], ['    fill_tensor(int64_t scalar,Tensor & t_)', '    test(DeprecatedTypeProperties & type,IntArrayRef shape,int64_t a,int64_t b)', '    TEST(ApplyUtilsTest,Contiguous2D)', '    TEST(ApplyUtilsTest,Small2D)', '    TEST(ApplyUtilsTest,_2D)', '    TEST(ApplyUtilsTest,_3D)', '    TEST(ApplyUtilsTest,Medium3D)', '    TEST(ApplyUtilsTest,_10D)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\serialize\\archive.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\arg.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\arg_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUArgMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUArgMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ArgMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ArgMin', '    ComputeArgImpl(const int prev_size,const int next_size,const int n,const Compare & comp,const T *X,int64_t *Y,Context *context)', '    InferTensor(const OperatorDef & def,const std::vector & in)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,CPUContext *context)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\arg_ops.h', ['    final'], ['    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,Context *context)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,Context *context)', '    ArgOp(Args,...)', '    DoRunWithType', '    reducer_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\arg_spec.h', [], ['    descs', '    device', '    hashCode', '    operator!=(const ArgSpec & spec)', '    operator==(const ArgSpec & other)', '    ArgSpec(at::TensorList inputs,const int _device)', '    device_', '    hash_code_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\argument_spec.cpp', [], ['    scanWrittenSlots(Block *block,ArgumentSpecCreator::WrittenSlots & written_slots)', '    ArgumentSpecCreator(Graph & graph)', '    create(bool with_grad,const Stack & input)', '    dump', '    scan(const TypePtr & typ,size_t depth,const WrittenSlots & written_slots)', '    specializeTypes(Graph & graph,const ArgumentSpec & spec)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\argument_spec.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Array.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Array.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Array.h', [], ['    Array', '    Array(const Array &)', '    operator=(const Array &)', '    operator[](int i)', '    operator[](int i)', '    T']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\Array_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\ArrayRef.h', ['    final'], ['    operator!=(c10::ArrayRef a1,const std::vector & a2)', '    operator!=(const std::vector & a1,c10::ArrayRef a2)', '    operator!=(c10::ArrayRef a1,c10::ArrayRef a2)', '    operator<<(std::ostream & out,ArrayRef list)', '    operator==(c10::ArrayRef a1,const std::vector & a2)', '    operator==(const std::vector & a1,c10::ArrayRef a2)', '    operator==(c10::ArrayRef a1,c10::ArrayRef a2)', '    ArrayRef', '    ArrayRef(const std::initializer_list & Vec)', '    ArrayRef(const (*) () T)', '    ArrayRef(const std::array & Arr)', '    ArrayRef(const std::vector & Vec)', '    ArrayRef(const SmallVectorTemplateCommon & Vec)', '    ArrayRef(const T *begin,const T *end)', '    ArrayRef(const T *data,size_t length)', '    ArrayRef(const T & OneElt)', '    ArrayRef', '    at(size_t Index)', '    back', '    begin', '    cbegin', '    cend', '    data', '    empty', '    end', '    equals(ArrayRef RHS)', '    front', '    operator[](size_t Index)', '    rbegin', '    rend', '    size', '    slice(size_t N)', '    slice(size_t N,size_t M)', '    vec', '    begin', '    end']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ArrayRef.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\asan.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\asin_op.cc', ['    GetAsinGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAsin', '    CAFFE_ANONYMOUS_VARIABLE_CPUAsinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Asin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AsinGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\asin_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\assembly.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\assert_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAssert', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Assert']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\assert_op.h', ['    final'], ['    AssertOp(Args,...)', '    cmp_tensor_', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\nql\\ast.h', [], ['    allocString', '    allocVector', '    parseFile(const char *,ASTGraph *)', '    parseString(const char *,ASTGraph *)', '    dump(int level)', '    isCall', '    starInputs', '    ~ASTExpr', '    dump', '    ~ASTGraph', '    dump(int level)', '    ~ASTStmt']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\at_launch_benchmark.cc', ['    C10FlagParser_benchmark_iter', '    C10FlagParser_inter_op_threads', '    C10FlagParser_iter', '    C10FlagParser_warmup_iter'], ['    counter', '    launch_tasks', '    launch_tasks_and_wait(int tasks_num)', '    main(int argc,char **argv)', '    C10FlagParser_benchmark_iter(const std::string & content)', '    C10FlagParser_inter_op_threads(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_warmup_iter(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\atan_op.cc', ['    GetAtanGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAtan', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Atan', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtanGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\atan_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ATen.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\aten_interned_strings.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\jit\\templates\\aten_interned_strings.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\aten\\aten_op.cc', [], ['    Set(const std::int64_t,const at::Half h,at::Half *v,CPUContext *c)', '    Set(const std::int64_t,const at::BFloat16 b,at::BFloat16 *v,CPUContext *c)', '    backend']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\aten\\aten_op.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\aten\\aten_op_gpu.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\aten\\aten_op_template.h', ['    ATenOp'], ['    assignListStartingAt(size_t offset,const std::vector & tensors)', '    assignTo(Tensor *dst,const at::Tensor & src_)', '    assignTo(Tensor *dst,at::ScalarType scalar_type,at::Scalar scalar)', '    assignToValue(Tensor *dst,T v)', '    ATenOp(const OperatorDef & operator_def,Workspace *ws)', '    extract(const at::Scalar & s)', '    extract(const at::Scalar & s)', '    findImplementation(const OperatorDef & operator_def)', '    optionsFor(const Tensor & ten)', '    peek(size_t i,size_t N)', '    peekSlice(size_t i,size_t len,size_t N)', '    readAttribute(const std::string & name)', '    readBoolMask(const std::string & name)', '    readIntArrayRef(const std::string & name)', '    readScalarAttribute(const std::string & name)', '    RunOnDevice', '    tensorWrapping(const Tensor & ten_)', '    typeMetaFor(const at::Tensor & t)', '    typeMetaFor(at::ScalarType st)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\jit\\templates\\aten_schema_declarations.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\ATenCUDAGeneral.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ATenGeneral.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ATenGeneral.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\nvrtc_stub\\ATenNVRTC.cpp', [], ['    load_nvrtc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\nvrtc_stub\\ATenNVRTC.h', [], ['    load_nvrtc', '    decltype(& nvrtcVersion)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\atest.cpp', [], ['    f2', '    f2', '    f2', '    TEST(atest,atest)', '    trace']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\atomic_ops.cc', ['    final', '    final', '    final', '    final', '    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicFetchAdd', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicFetchAdd64', '    CAFFE_ANONYMOUS_VARIABLE_CPUCheckAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUConditionalSetAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateMutex', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicFetchAdd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicFetchAdd64', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConditionalSetAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateMutex', '    AtomicFetchAddOp(Args,...)', '    CreateMutexOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\AtomicAddFloat.h', [], ['    cpu_atomic_add_float(float *dst,float fvalue)', '    atomic_compare_exchange_strong']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\attributes.cpp', [], ['    clone', '    clone']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\attributes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\auto_gil.h', [], ['    with_no_gil(F f)', '    AutoGIL', '    ~AutoGIL', '    AutoNoGIL', '    ~AutoNoGIL']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\autocast_mode.cpp', ['    CastPolicy'], ['    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    cached_cast(at::ScalarType to_type,const Tensor & arg)', '    clear_cache', '    decrement_nesting', '    increment_nesting', '    is_eligible(const Tensor & arg)', '    is_enabled', '    prioritize(at::ScalarType current,const Tensor & nextArg)', '    prioritize(at::ScalarType current,const TensorList & list)', '    prioritize(at::ScalarType current,T nextArg)', '    promote_type(at::ScalarType current)', '    promote_type(at::ScalarType current,Arg0 arg0,Args,...)', '    set_enabled(bool new_enabled)', '    binary_cross_entropy_banned(const Tensor &,const Tensor &,const Tensor &,int64_t)', '    cached_cast(at::ScalarType to_type,const TensorList & arg)', '    cached_cast(at::ScalarType to_type,T arg)', '    firstarg_is_eligible(const Tensor & arg,Args,...)', '    set_opt_dtype(at::ScalarType to_type,const c10::optional & dtype)', '    set_opt_dtype(at::ScalarType to_type,T arg)', '    type_from_firstarg(at::ScalarType to_type,const Tensor & arg,Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\autocast_mode.h', [], ['    clear_cache', '    decrement_nesting', '    increment_nesting', '    is_enabled', '    set_enabled(bool new_enabled)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\autocast_VS2017_helper.h', [], ['    _cat(TensorList A,int64_t B)', '    _convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H,int64_t I,bool J,bool K,bool L)', '    _convolution_nogroup(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H)', '    acos(const Tensor & A)', '    addbmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addcdiv(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D)', '    addcmul(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D)', '    addmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addmv(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addr(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    asin(const Tensor & A)', '    atan2(const Tensor & A,const Tensor & B)', '    baddbmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    bilinear(const Tensor & A,const Tensor & B,const Tensor & C,const Tensor & D)', '    binary_cross_entropy_with_logits(const Tensor & A,const Tensor & B,const Tensor & C,const Tensor & D,int64_t E)', '    bmm(const Tensor & A,const Tensor & B)', '    cat(TensorList A,int64_t B)', '    cat(TensorList A,Dimname B)', '    cdist(const Tensor & A,const Tensor & B,double C,c10::optional D)', '    chain_matmul(TensorList A)', '    conv1d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv2d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv3d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv_tbc(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D)', '    conv_transpose1d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    conv_transpose2d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    conv_transpose3d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H,int64_t I)', '    cosh(const Tensor & A)', '    cosine_embedding_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,int64_t E)', '    cosine_similarity(const Tensor & A,const Tensor & B,int64_t C,double D)', '    cross(const Tensor & A,const Tensor & B,c10::optional C)', '    cudnn_convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,bool H,bool I)', '    cudnn_convolution(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D,IntArrayRef E,int64_t F,bool G,bool H)', '    cudnn_convolution_transpose(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,IntArrayRef G,int64_t H,bool I,bool J)', '    cudnn_convolution_transpose(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,bool H,bool I)', '    cumprod(const Tensor & A,int64_t B,c10::optional C)', '    cumprod(const Tensor & A,Dimname B,c10::optional C)', '    cumsum(const Tensor & A,int64_t B,c10::optional C)', '    cumsum(const Tensor & A,Dimname B,c10::optional C)', '    dist(const Tensor & A,const Tensor & B,Scalar C)', '    dot(const Tensor & A,const Tensor & B)', '    equal(const Tensor & A,const Tensor & B)', '    erfinv(const Tensor & A)', '    exp(const Tensor & A)', '    expm1(const Tensor & A)', '    frobenius_norm(const Tensor & A)', '    frobenius_norm(const Tensor & A,IntArrayRef B,bool C)', '    gelu(const Tensor & A)', '    group_norm(const Tensor & A,int64_t B,const Tensor & C,const Tensor & D,double E,bool F)', '    hinge_embedding_loss(const Tensor & A,const Tensor & B,double C,int64_t D)', '    kl_div(const Tensor & A,const Tensor & B,int64_t C)', '    l1_loss(const Tensor & A,const Tensor & B,int64_t C)', '    layer_norm(const Tensor & A,IntArrayRef B,const Tensor & C,const Tensor & D,double E,bool F)', '    linear(const Tensor & A,const Tensor & B,const Tensor & C)', '    log(const Tensor & A)', '    log10(const Tensor & A)', '    log1p(const Tensor & A)', '    log2(const Tensor & A)', '    log_softmax(const Tensor & A,int64_t B,c10::optional C)', '    log_softmax(const Tensor & A,Dimname B,c10::optional C)', '    margin_ranking_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,int64_t E)', '    matmul(const Tensor & A,const Tensor & B)', '    mm(const Tensor & A,const Tensor & B)', '    mse_loss(const Tensor & A,const Tensor & B,int64_t C)', '    multi_margin_loss(const Tensor & A,const Tensor & B,Scalar C,Scalar D,const Tensor & E,int64_t F)', '    multilabel_margin_loss(const Tensor & A,const Tensor & B,int64_t C)', '    mv(const Tensor & A,const Tensor & B)', '    native_layer_norm(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E,double F)', '    nll_loss(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E)', '    nll_loss2d(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E)', '    norm(const Tensor & A,c10::optional B,ScalarType C)', '    norm(const Tensor & A,c10::optional B,IntArrayRef C,bool D,ScalarType E)', '    norm(const Tensor & A,c10::optional B,DimnameList C,bool D,ScalarType E)', '    nuclear_norm(const Tensor & A,bool B)', '    nuclear_norm(const Tensor & A,IntArrayRef B,bool C)', '    pdist(const Tensor & A,double B)', '    poisson_nll_loss(const Tensor & A,const Tensor & B,bool C,bool D,double E,int64_t F)', '    pow(const Tensor & A,Scalar B)', '    pow(const Tensor & A,const Tensor & B)', '    pow(Scalar A,const Tensor & B)', '    prelu(const Tensor & A,const Tensor & B)', '    prod(const Tensor & A,c10::optional B)', '    prod(const Tensor & A,int64_t B,bool C,c10::optional D)', '    prod(const Tensor & A,Dimname B,bool C,c10::optional D)', '    reciprocal(const Tensor & A)', '    renorm(const Tensor & A,Scalar B,int64_t C,Scalar D)', '    rsqrt(const Tensor & A)', '    sinh(const Tensor & A)', '    smooth_l1_loss(const Tensor & A,const Tensor & B,int64_t C)', '    soft_margin_loss(const Tensor & A,const Tensor & B,int64_t C)', '    softmax(const Tensor & A,int64_t B,c10::optional C)', '    softmax(const Tensor & A,Dimname B,c10::optional C)', '    softplus(const Tensor & A,Scalar B,Scalar C)', '    stack(TensorList A,int64_t B)', '    sum(const Tensor & A,c10::optional B)', '    sum(const Tensor & A,IntArrayRef B,bool C,c10::optional D)', '    sum(const Tensor & A,DimnameList B,bool C,c10::optional D)', '    tan(const Tensor & A)', '    tensordot(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D)', '    triplet_margin_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,double E,double F,bool G,int64_t H)', '    _cat', '    _convolution', '    _convolution_nogroup', '    acos', '    addbmm', '    addcdiv', '    addcmul', '    addmm', '    addmv', '    addr', '    asin', '    atan2', '    baddbmm', '    bilinear', '    binary_cross_entropy_with_logits', '    bmm', '    cat', '    cdist', '    chain_matmul', '    conv1d', '    conv2d', '    conv3d', '    conv_tbc', '    conv_transpose1d', '    conv_transpose2d', '    conv_transpose3d', '    convolution', '    cosh', '    cosine_embedding_loss', '    cosine_similarity', '    cross', '    cudnn_convolution', '    cudnn_convolution_transpose', '    cumprod', '    cumsum', '    dist', '    dot', '    equal', '    erfinv', '    exp', '    expm1', '    frobenius_norm', '    gelu', '    group_norm', '    hinge_embedding_loss', '    kl_div', '    l1_loss', '    layer_norm', '    linear', '    log', '    log10', '    log1p', '    log2', '    log_softmax', '    margin_ranking_loss', '    matmul', '    mm', '    mse_loss', '    multi_margin_loss', '    multilabel_margin_loss', '    mv', '    native_layer_norm', '    nll_loss', '    nll_loss2d', '    norm', '    nuclear_norm', '    pdist', '    poisson_nll_loss', '    pow', '    prelu', '    prod', '    reciprocal', '    renorm', '    rsqrt', '    sinh', '    smooth_l1_loss', '    soft_margin_loss', '    softmax', '    softplus', '    stack', '    sum', '    tan', '    tensordot', '    triplet_margin_loss']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\autodiff.cpp', ['    GradientHelper'], ['    addReverseInline(Gradient & grad_desc)', '    createAutogradAdd(Value *a,Value *b)', '    deduplicateSizeCaptures(Gradient & grad_desc,ReverseDetails & rev_info)', '    eliminateDeadCode(ReverseDetails & rev_info)', '    err', '    foldSizeIfNotEqual(Block *reverse_block)', '    foldSizeIfNotEqual(Node *node)', '    getReverseCaptures(Gradient & grad_desc)', '    inBlock(Node *node,Block *container)', '    lambdaLiftReverse(Gradient & grad_desc,ReverseDetails & rev_info)', '    liftConstants(Block *block,Block *move_to_this_block)', '    liftConstants(Node *node,Block *move_to_this_block)', '    linearGradientForNode(Node *node,ArrayRef grad_values)', '    Optimize(Gradient & grad_desc,ReverseDetails & rev_info)', '    differentiate(std::shared_ptr & graph)', '    get_grad', '    graph', '    insert_guard', '    ival', '    packReturnValuesIntoTuple(const std::shared_ptr & graph)', '    isDifferentiable(Node *n)', '    isDifferentiable(Graph & g)', '    needTrimGrad(Node *n)', '    wrapDim(int64_t & dim,const std::vector & sizes)', '    buildSymbolicGradient(const ArrayRef & grad_values)', '    gradient(ArrayRef grad_values)', '    GradientHelper(Node *n)', '    ReverseDetails(value_map,Block *reverse_block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\autodiff.h', [], ['    differentiate(std::shared_ptr & graph)', '    isDifferentiable(Node *n)', '    isDifferentiable(Graph & g)', '    isZero(Value *v)', '    operator bool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\autograd.cpp', [], ['    graph_desc(std::shared_ptr node)', '    simple_fn(const Variable & x,const Variable & y)', '    TEST(AutogradAPITests,BackwardSimpleTest)', '    TEST(AutogradAPITests,BackwardTest)', '    TEST(AutogradAPITests,GradSimpleTest)', '    TEST(AutogradAPITests,GradTest)', '    TEST(AutogradAPITests,GradNonLeafTest)', '    TEST(AutogradAPITests,GradUnreachableTest)', '    TEST(AutogradAPITests,RetainGrad)', '    TEST(CustomAutogradTest,CustomFunction)', '    TEST(CustomAutogradTest,FunctionReturnsInput)', '    TEST(CustomAutogradTest,NoGradCustomFunction)', '    TEST(CustomAutogradTest,MarkDirty)', '    TEST(CustomAutogradTest,MarkNonDifferentiable)', '    TEST(CustomAutogradTest,MarkNonDifferentiableMixed)', '    TEST(CustomAutogradTest,MarkNonDifferentiableNone)', '    TEST(CustomAutogradTest,ReturnLeafInplace)', '    TEST(CustomAutogradTest,ReturnDuplicateInplace)', '    TEST(CustomAutogradTest,ReturnDuplicate)', '    TEST(CustomAutogradTest,SaveEmptyForBackward)', '    TEST(CustomAutogradTest,InvalidGradients)', '    TEST(CustomAutogradTest,NoGradInput)', '    TEST(CustomAutogradTest,TooManyGrads)', '    TEST(CustomAutogradTest,DepNoGrad)', '    TEST(CustomAutogradTest,Reentrant)', '    TEST(CustomAutogradTest,DeepReentrant)', '    TEST(CustomAutogradTest,ReentrantPriority)', '    TEST(CustomAutogradTest,Hooks)', '    TEST(CustomAutogradTest,HookNone)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctsx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable input)', '    backward(AutogradContext *,variable_list grad_output)', '    forward(AutogradContext *,Variable input,Variable ignore)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable a,Variable b)', '    backward(AutogradContext *,variable_list grad)', '    backward(AutogradContext *,variable_list grad_output)', '    backward(AutogradContext *,variable_list grad_outputs)', '    backward(AutogradContext *ctsx,variable_list grad_outputs)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_outputs)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable var1,int mul,Variable var2)', '    forward(AutogradContext *,Variable x)', '    forward(AutogradContext *ctx,Variable x)', '    forward(AutogradContext *,Variable x)', '    forward(AutogradContext *,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable v)', '    forward(AutogradContext *ctx,Variable v)', '    forward(AutogradContext *ctx,Variable var1)', '    backward(AutogradContext *ctx,variable_list dy)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad)', '    forward(AutogradContext *ctx,Variable x,Variable y)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable x)', '    forward(AutogradContext *ctx,Variable input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\autograd.cpp', [], ['    _make_grads(const variable_list & outputs,const variable_list & grad_outputs)', '    backward(const variable_list & tensors,const variable_list & grad_tensors,c10::optional retain_graph,bool create_graph)', '    grad(const variable_list & outputs,const variable_list & inputs,const variable_list & grad_outputs,c10::optional retain_graph,bool create_graph,bool allow_unused)', '    run_backward(const variable_list & outputs,const variable_list & grad_outputs,bool keep_graph,bool create_graph,const variable_list & inputs,bool allow_unused)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\autograd.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\autograd.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\autograd.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\autograd_metadata.cpp', [], ['    AutogradMetadata(int64_t autogradContextId_,int64_t autogradMessageId_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\autograd_metadata.h', [], ['    AutogradMetadata(int64_t autogradContextId_,int64_t autogradMessageId_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\average-pooling-operator-tester.h', ['    AveragePoolingOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputHeight(size_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputSize(size_t inputHeight,size_t inputWidth)', '    inputWidth(size_t inputWidth)', '    inputWidth', '    inputWidth_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    nextBatchSize(size_t nextBatchSize)', '    nextBatchSize', '    nextBatchSize_', '    nextInputHeight(uint32_t nextInputHeight)', '    nextInputHeight', '    nextInputHeight_', '    nextInputSize(uint32_t nextInputHeight,uint32_t nextInputWidth)', '    nextInputWidth(uint32_t nextInputWidth)', '    nextInputWidth', '    nextInputWidth_', '    nextOutputHeight', '    nextOutputWidth', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputWidth', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    poolingHeight(uint32_t poolingHeight)', '    poolingHeight', '    poolingHeight_', '    poolingSize(uint32_t poolingSize)', '    poolingSize(uint32_t poolingHeight,uint32_t poolingWidth)', '    poolingWidth(uint32_t poolingWidth)', '    poolingWidth', '    poolingWidth_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testQ8', '    testSetupQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\average-pooling.c', [], ['    compute_output_dimension(size_t padded_input_dimension,size_t pooling_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_average_pooling2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *average_pooling_out)', '    pytorch_qnnp_setup_average_pooling2d_nhwc_q8(pytorch_qnnp_operator_t average_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\average-pooling.cc', [], ['    TEST(AVERAGE_POOLING_OP,zero_batch)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_qmax)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_qmax)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_qmax)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,setup_increasing_batch)', '    TEST(AVERAGE_POOLING_OP,setup_decreasing_batch)', '    TEST(AVERAGE_POOLING_OP,setup_changing_height)', '    TEST(AVERAGE_POOLING_OP,setup_changing_width)', '    TEST(AVERAGE_POOLING_OP,setup_swap_height_and_width)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\average-pooling.cc', [], ['    average_pooling_q8(benchmark::State & state,const char *net)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\averaged_loss_cpu.cc', ['    final'], ['    operator()(const at::Tensor & X_,const at::Tensor & sum_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AveragePool2d.cpp', [], ['    avg_pool2d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\AveragePool3d.cpp', [], ['    avg_pool3d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int padT,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int padT,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\avgpool-microkernel-tester.h', ['    AvgPoolMicrokernelTester'], ['    iterations(size_t iterations)', '    iterations', '    iterations_', '    kc(size_t kc)', '    kc', '    kc_', '    kh(size_t kh)', '    kh', '    kh_', '    kr(size_t kr)', '    kr', '    kr_', '    ks', '    kw(size_t kw)', '    kw', '    kw_', '    mr(size_t mr)', '    mr', '    mr_', '    n(size_t n)', '    n', '    n_', '    packedKs', '    packedN', '    qr(size_t qr)', '    qr', '    qr_', '    s(size_t s)', '    s', '    s_', '    test(pytorch_q8avgpool_up_ukernel_function q8avgpool)', '    test(pytorch_q8avgpool_mp_ukernel_function q8avgpool)', '    xScale(float xScale)', '    xScale', '    xScale_', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    xZeroPoint(uint8_t xZeroPoint)', '    xZeroPoint', '    xZeroPoint_', '    yMax(uint8_t yMax)', '    yMax', '    yMax_', '    yMin(uint8_t yMin)', '    yMin', '    yMin_', '    yScale(float yScale)', '    yScale', '    yScale_', '    yStride(size_t yStride)', '    yStride', '    yStride_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\vector\\AVX.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\vector\\AVX.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\avx_mathfun.h', [], ['    _mm256_add_epi32(v8si x,v8si y)', '    _mm256_and_si128(v8si x,v8si y)', '    _mm256_andnot_si128(v8si x,v8si y)', '    _mm256_cmpeq_epi32(v8si x,v8si y)', '    _mm256_slli_epi32(v8si x,int a)', '    _mm256_srli_epi32(v8si x,int a)', '    _mm256_sub_epi32(v8si x,v8si y)', '    cos256_ps(v8sf x)', '    exp256_ps(v8sf x)', '    log256_ps(v8sf x)', '    sin256_ps(v8sf x)', '    sincos256_ps(v8sf x,v8sf *s,v8sf *c)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\backend.cc', [], ['    kBrokenOperators', '    kRenamedAttrs', '    kRenamedOperators', '    kRNNOperators', '    AlmostEqual(double a,double b)', '    BuildOperator(caffe2::OperatorDef *c2_op,const std::string & op_type,const std::vector & inputs,const std::vector & outputs,const std::vector & args)', '    BuildOperator(caffe2::OperatorDef *c2_op,const std::string & op_type,const std::vector & inputs,const std::vector & outputs)', '    CopyOnnxAttrValueToCaffe2Arg(caffe2::Argument *arg,const AttributeProto & attr)', '    GetDeviceOption(const Device & onnx_device)', '    IsOperator(const std::string & op_type)', '    LookUpWithDefault(const std::unordered_map & map,const T & key,const U & default_value)', '    OptimizeOnnx(const ModelProto & input,bool init)', '    TryConvertingTensorRawValues(const TensorProto & onnx_tensor,::google::protobuf::RepeatedField *field)', '    UpdateNames(std::shared_ptr dummy,const caffe2::OperatorDef & op)', '    check_fc', '    converter', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    graph_value_infos', '    passes', '    value_infos', '    get_broken_operators', '    get_renamed_attrs', '    get_renamed_operators', '    get_rnn_operators', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    OnnxAttributes(const NodeProto & node)', '    OnnxAttrToCaffe2Arg(std::function mapper)', '    AllNamesInGraph(const GraphProto & graph)', '    BuildTensorFillingOp(caffe2::OperatorDef *c2_op,const TensorProto & onnx_tensor,const std::string & output_name,const std::string & shape_name)', '    CheckOpSchemaArguments(const caffe2::OpSchema & schema,const caffe2::OperatorDef & op)', '    CommonOnnxNodeToCaffe2Ops(OnnxNode *onnx_node,const ConversionContext & ctx)', '    ConvertNode(const std::string & node_str,const ConversionContext & ctx)', '    CreateArgMaxMin(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateBatchNormalization(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateCast(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConcat(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstant(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstantOfShape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConvPoolOpBase(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDropout(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDynamicSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGather(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGemm(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLogSoftmax(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLRN(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMatMul(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMultinomialOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateNonZeroOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePad(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateRandomNormal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReciprocal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReshape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSplit(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateUpsample(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateWhereOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    get_special_operators', '    OnnxNodeToCaffe2Ops(const ModelProto & init_model,const ModelProto & pred_model,const ConversionContext & ctx,OnnxNode *onnx_node)', '    OnnxToCaffe2(caffe2::NetDef *init_net,caffe2::NetDef *pred_net,const ModelProto & onnx_model,const std::string & device,int opset_version,bool include_initializers,const std::vector & extras)', '    Prepare(const std::string & onnx_model_str,const std::string & device,const std::vector & extras)', '    PreprocessSliceIndexTensor(OnnxNode *onnx_node,Caffe2Ops & ret,std::string indices_tensor,std::string axes_tensor,std::string rank_tensor,std::string zero_tensor,std::string one_tensor,int default_value)', '    SupportOp(const std::string type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Backend.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Backend.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\backend.h', ['    Caffe2Backend', '    ConversionContext', '    OnnxAttributes'], ['    AllNamesInGraph(const GraphProto & graph)', '    BuildTensorFillingOp(caffe2::OperatorDef *c2_op,const TensorProto & onnx_tensor,const std::string & output_name,const std::string & shape_name)', '    Caffe2Backend(DummyName *dummy)', '    CheckOpSchemaArguments(const caffe2::OpSchema & schema,const caffe2::OperatorDef & op)', '    CommonOnnxNodeToCaffe2Ops(OnnxNode *onnx_node,const ConversionContext & ctx)', '    ConvertNode(const std::string & node_str,const ConversionContext & ctx)', '    CreateArgMaxMin(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateBatchNormalization(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateCast(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConcat(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstant(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstantOfShape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConvPoolOpBase(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDropout(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDynamicSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGather(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGemm(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLogSoftmax(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLRN(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMatMul(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMultinomialOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateNonZeroOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePad(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePadPool(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateRandomNormal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReciprocal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReshape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSplit(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateUpsample(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateWhereOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    get_broken_operators', '    get_renamed_attrs', '    get_renamed_operators', '    get_rnn_operators', '    get_special_operators', '    OnnxNodeToCaffe2Ops(const ModelProto & init_model,const ModelProto & pred_model,const ConversionContext & ctx,OnnxNode *onnx_node)', '    OnnxToCaffe2(caffe2::NetDef *init_net,caffe2::NetDef *pred_net,const ModelProto & onnx_model,const std::string & device,int opset_version,bool include_initializers,const std::vector & extras)', '    Prepare(const std::string & onnx_model_str,const std::string & device,const std::vector & extras)', '    PreprocessSliceIndexTensor(OnnxNode *onnx_node,Caffe2Ops & ret,std::string indices_tensor,std::string axes_tensor,std::string rank_tensor,std::string zero_tensor,std::string one_tensor,int default_value)', '    SupportOp(const std::string tyep)', '    ConversionContext(const ValueInfoMap & value_infos,int opset_version)', '    opset_version', '    value_infos', '    AddRewrittenAttribute(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key,const T & default_value)', '    get(const std::string & key)', '    HasAttribute(const std::string & key)', '    OnnxAttributes(const NodeProto & node)', '    OnnxAttrToCaffe2Arg(std::function mapper)', '    remove(const std::string & key)', '    OnnxNode(const NodeProto & node_in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\backend_cutting.cc', [], ['    ConvertToC2Net(const TransformSubgraph & sub,const std::unordered_map & infos)', '    DetectBoundaryReferences(TransformSubgraph *subgraph,const std::unordered_map & infos,const std::unordered_set & original_external_output)', '    DumpGraph(NNGraph *g,const std::string & fname)', '    Explore(const std::vector & current_frontier,VisitorContext *context)', '    GetInfo(std::unordered_map & infos,NodeRef node)', '    GetInfo(const std::unordered_map & infos,NodeRef node)', '    OptimizeForBackend(caffe2::NetDef & net,std::function supports,std::function transform_func,bool debug)', '    PruneUnrefereredNodes(NNModule *nn)', '    ReplaceSubgraph(const TransformSubgraph & subgraph,caffe2::NetDef & net_opt,NNGraph *g)', '    ShowNode(NodeRef node)', '    GroupAnnotation(int i,int g)', '    needs_transform', '    group_id', '    needed', '    operator=(TransformSubgraph)', '    Print', '    TransformSubgraph(std::vector,std::vector,int id,bool need)', '    TransformSubgraph(TransformSubgraph)', '    find_supported', '    group', '    VisitorContext(std::function func)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\backend_cutting.h', [], ['    DumpGraph(NNGraph *g,const std::string & fname)', '    OptimizeForBackend(caffe2::NetDef & net,std::function supports,std::function transform_func,bool debug)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\backend_cutting_test.cc', [], ['    AddConv(caffe2::NetDef *net,int tick)', '    Supports(const caffe2::OperatorDef & op)', '    TEST(BackendCuttingTest,unit)', '    TEST(BackendCuttingTest,line)', '    TEST(BackendCuttingTest,convergedPaths)', '    TEST(BackendCuttingTest,skipPath)', '    Transform(const caffe2::NetDef & net)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\backend_fallback_test.cpp', [], ['    callBoxedWorkaround(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    generic_mode_fallback(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    generic_wrapper_fallback(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    TEST(BackendFallbackTest,TestBackendFallbackWithMode)', '    TEST(BackendFallbackTest,TestBackendFallbackWithWrapper)', '    TEST(BackendFallbackTest,TestFallthroughBackendFallback)', '    GenericWrapperTensorImpl(at::Tensor rep)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\backend_rep.cc', [], ['    CheckInit', '    Run(const caffe2::Predictor::TensorList & inputs,caffe2::Predictor::TensorList *outputs)', '    RunMap(const caffe2::Predictor::TensorMap & inputs,caffe2::Predictor::TensorList *outputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\backend_rep.h', ['    Caffe2BackendRep'], ['    CheckInit', '    init_net', '    init_net', '    pred_net', '    pred_net', '    predictor_', '    Run(const caffe2::Predictor::TensorList & inputs,caffe2::Predictor::TensorList *outputs)', '    RunMap(const caffe2::Predictor::TensorMap & inputs,caffe2::Predictor::TensorList *outputs)', '    uninitialized_inputs', '    uninitialized_inputs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\backend_transformer_base.cc', [], ['    seq_id', '    wrapShapeInfoIntoQTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    wrapShapeInfoIntoTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    annotateOpIndex(NetDef *net)', '    getModelId(const NetDef & net)', '    addShapeToNet(NetDef & shape_net,const ShapeInfoMap & shape_hints)', '    dumpNet(const NetDef & pred_net,const ShapeInfoMap & shape_hints,const std::string & fname)', '    inferShapes(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & shape_hints_mapped,const BoundShapeSpec & spec)', '    ssaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & input_shape_hints)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\backend_transformer_base.h', ['    BackendTransformerBase'], ['    wrapShapeInfoIntoQTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    wrapShapeInfoIntoTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    annotateOpIndex(NetDef *net)', '    getModelId(const NetDef & net)', '    addShapeToNet(NetDef & shape_net,const ShapeInfoMap & shape_hints)', '    BackendTransformerBase', '    dumpNet(const NetDef & pred_net,const ShapeInfoMap & shape_hints,const std::string & fname)', '    inferShapes(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & shape_hints_mapped,const BoundShapeSpec & spec)', '    input_mapping', '    reverse_input_mapping', '    ssaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & input_shape_hints)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    ~BackendTransformerBase', '    BackendTransformOptions', '    debug', '    min_ops']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\BackendSelectRegister.cpp', [], ['    registry', '    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Backtrace.cpp', [], ['    get_backtrace(size_t frames_to_skip,size_t maximum_number_of_frames,bool skip_python_frames)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Backtrace.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Backtrace.h', [], ['    get_backtrace(size_t frames_to_skip,size_t maximum_number_of_frames,bool skip_python_frames)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Backtrace.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\bailout_graph.cpp', [], ['    locateBailOutNodeInUnoptimizedGraph(Block *b,int64_t index)', '    removeBailouts(Block *b)', '    shouldBeCapturedInByBailOut(Node *n)', '    BuildBailOutGraphFrom(int64_t bailout_index,const std::shared_ptr & orig,const std::shared_ptr & target)', '    InsertBailOuts(std::shared_ptr graph)', '    addNewInputForValue(Value *old_value)', '    BailOutGraphBuilderForNode(std::shared_ptr graph,std::shared_ptr target)', '    buildBailOutBlockFrom(Node *n)', '    buildBailOutGraphFrom(Node *n)', '    buildBailOutIf(const at::ArrayRef block_outputs,Node *outer_node)', '    buildBailOutLoop(Node *outer_node)', '    cloneNode(Node *node)', '    getInputForValue(Value *v)', '    getOrAddInputForValue(Value *v)', '    mapValueAndCopyMetadata(Value *old_value,Value *new_value)', '    mapValues(const at::ArrayRef block_outputs,const at::ArrayRef carried_deps)', '    addUnoptimizedFuncToBailouts', '    BailOutInserter(std::shared_ptr graph)', '    insertBailOuts(Block *b)', '    removeGuards(Block *b)', '    replaceGuardsWithBailouts', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\bailout_graph.h', [], ['    BuildBailOutGraphFrom(int64_t bailout_index,const std::shared_ptr & orig,const std::shared_ptr & target)', '    InsertBailOuts(std::shared_ptr graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\barrier_ops.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\barrier_ops.h', ['    final'], ['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    signalFailure(ws_,ioe)', '    BarrierOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~BarrierOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\dataloader\\base.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\base.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\base.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms\\base.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\basic.cpp', [], ['    SendContext', '    test(DeprecatedTypeProperties & type)', '    TEST(BasicTest,BasicTestCPU)', '    TEST(BasicTest,BasicTestCUDA)', '    TEST(BasicTest,FactoryMethodsTest)', '    TestAbsValue(DeprecatedTypeProperties & type)', '    TestAdd(DeprecatedTypeProperties & type)', '    TestAddingAValueWithScalar(DeprecatedTypeProperties & type)', '    TestCopy(DeprecatedTypeProperties & type)', '    TestCopyBroadcasting(DeprecatedTypeProperties & type)', '    TestDispatch', '    TestIndexingByScalar', '    TestIndexingByZerodimTensor', '    TestIndexingMixedDevice(DeprecatedTypeProperties & type)', '    TestIntArrayRefExpansion(DeprecatedTypeProperties & type)', '    TestIsContiguous(DeprecatedTypeProperties & type)', '    TestLoadOfAddsWithCopy(DeprecatedTypeProperties & type)', '    TestLoadsOfAdds(DeprecatedTypeProperties & type)', '    TestMm(DeprecatedTypeProperties & type)', '    TestNegativeDim(DeprecatedTypeProperties & type)', '    TestOnesAndDot(DeprecatedTypeProperties & type)', '    TestPermute(DeprecatedTypeProperties & type)', '    TestRandperm(DeprecatedTypeProperties & type)', '    TestResize(DeprecatedTypeProperties & type)', '    TestSelect(DeprecatedTypeProperties & type)', '    TestSort(DeprecatedTypeProperties & type)', '    TestSqueeze(DeprecatedTypeProperties & type)', '    TestTensorFromTH', '    TestToCFloat', '    TestToString', '    TestView(DeprecatedTypeProperties & type)', '    TestZeroDim(DeprecatedTypeProperties & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\basic_ops.cpp', [], ['    apply(variable_list)', '    apply(variable_list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\basic_ops.h', [], ['    apply(variable_list)', '    DelayedError(std::string msg,int num_inputs)', '    apply(variable_list)', '    Error(std::string msg,edge_list)', '    Error(std::string msg)', '    apply(variable_list)', '    GraphRoot(edge_list functions,variable_list inputs)', '    undefined_input', '    NotImplemented(const std::string & forward_fn,edge_list)', '    NotImplemented(const std::string & forward_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_box_cox_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBoxCox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBoxCox', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_box_cox_op.h', ['    final'], ['    BatchBoxCoxOp(Args,...)', '    BoxCoxNaive(int64_t N,int64_t D,const T *data_ptr,const T *lambda1_ptr,const T *lambda2_ptr,T k_eps,T *output_ptr)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_bucketize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBucketize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBucketize', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_bucketize_op.h', ['    final'], ['    BatchBucketizeOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\batch_gather_cpu.cc', [], ['    batch_gather_op_cpu(const at::Tensor & data,const at::Tensor & indices,const at::Tensor & output)', '    batch_gather_op_cpu_impl(const at::Tensor & data_,const at::Tensor & indices_,const at::Tensor & output_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_gather_ops.cc', ['    GetBatchGatherGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchGather', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchGatherGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchGatherGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_gather_ops.h', ['    final', '    final'], ['    BatchGatherGradientOp(Args,...)', '    BatchGatherOp(Args,...)', '    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    RunOnDevice', '    ~BatchGatherGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\batch_matmul_cpu.cc', ['    final'], ['    operator()(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & Y_,int64_t trans_a,int64_t trans_b,int64_t broadcast)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\batch_matmul_dnnlowp_op.cc', [], ['    noBroadcastErrorMsg', '    doNothingObj', '    doNothingObj', '    doNothingObj', '    BatchMatMulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\batch_matmul_dnnlowp_op.h', ['    final'], ['    BatchMatMulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    broadcast_', '    first_invocation_', '    is_B_constant_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_matmul_op.cc', ['    GetBatchMatMulGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMatMul', '    TensorInferenceForBatchMatMul(const OperatorDef & def,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMatMul', '    CostInferenceForBatchMatMul(const OperatorDef & def,const vector & in)', '    output_dims', '    trans_a_arg', '    trans_b_arg', '    trans_both_arg', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_matmul_op.h', ['    final'], ['    BatchMatMulOp(Args,...)', '    DoRunWithType', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_matmul_op_gpu_test.cc', ['    BatchMatMulOpGPUTest'], ['    TEST_F(BatchMatMulOpGPUTest,BatchMatMulOpGPUNormalTest)', '    TEST_F(BatchMatMulOpGPUTest,BatchMatMulOpGPUBroadcastTest)', '    AddConstInput(const std::vector & dims,const float value,const string & name)', '    SetUp', '    VerifyOutput(const std::vector & dims,const float value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_matmul_op_test.cc', ['    BatchMatMulOpTest'], ['    TEST_F(BatchMatMulOpTest,BatchMatMulOpNormalTest)', '    TEST_F(BatchMatMulOpTest,BatchMatMulOpBroadcastTest)', '    AddConstInput(const std::vector & dims,const float value,const string & name)', '    SetUp', '    VerifyOutput(const std::vector & dims,const float value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\batch_mm.cpp', ['    Side'], ['    batch_side', '    BatchMM(std::shared_ptr & graph)', '    BatchMMSide(Block *block,AliasDb & alias_db)', '    hasMutableOperators(Block *block)', '    insert_guard', '    insert_guard', '    insert_guard', '    queue', '    aliasAnalysisIsSpecialCase', '    BatchMMTreeReduce(Block *block)', '    have_same_shape(at::TensorList inputs)', '    postprocess', '    shape_is_fast_for_reduce(const at::Tensor & lhs,const at::Tensor & rhs)', '    shape_is_fast_for_side(const at::Tensor & other_side_input)', '    should_be_transposed(at::TensorList inputs)', '    transpose_inputs(at::TensorList inputs)', '    add(Node *add,TreeToken & l,TreeToken & r)', '    mm(Node *mm)', '    transpose(Node *t,TreeToken & inp_token)', '    operator bool', '    removeTransposesAndGatherMatmuls']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\batch_mm.h', [], ['    BatchMM(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_moments_op.cc', ['    GetBatchMomentsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMoments', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMomentsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMoments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMomentsGradient', '    ComputeBatchMomentsGradientNCHW(const int N,const int C,const int HxW,const float *dmu,const float *dvar,const float *X,float *dX)', '    ComputeBatchMomentsGradientNHWC(const int N,const int C,const int HxW,const float *dmu,const float *dvar,const float *X,float *dX)', '    ComputeBatchMomentsNCHW(const int N,const int C,const int HxW,const float *X,float *mu,float *var)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_moments_op.h', ['    final', '    final'], ['    BatchMomentsGradientOp(Args,...)', '    BatchMomentsOp(Args,...)', '    ComputeBatchMomentsGradientNCHW(const int N,const int C,const int HxW,const T *dmu,const T *dvar,const T *X,T *dX)', '    ComputeBatchMomentsGradientNHWC(const int N,const int C,const int HxW,const T *dmu,const T *dvar,const T *X,T *dX)', '    ComputeBatchMomentsNCHW(const int N,const int C,const int HxW,const T *X,T *mu,T *var)', '    ComputeBatchMomentsNHWC(const int N,const int C,const int HxW,const T *X,T *mu,T *var)', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\batch_norm.h', [], ['    batch_norm_cpu_inference_contiguous_stub', '    batch_norm_cpu_inference_contiguous_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\batch_norm_kernel.cpp', [], ['    batch_norm_cpu_inference_collect_linear_and_constant_terms(TensorAccessor alpha,TensorAccessor beta,int64_t n_channel,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_contiguous_impl(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_contiguous_kernel(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\batch_permutation_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8BatchPermutation', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\batch_permutation_dnnlowp_op.h', ['    final'], ['    BatchPermutationDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_permutation_op.cc', ['    GetBatchPermutationGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchPermutation', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchPermutationGradient', '    schema_OperatorName', '    batch_permutation_loop(const int N,const int K,const float *src,const int *indices,float *dst)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchPermutation', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchPermutationGradient', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_permutation_op.h', ['    final', '    final'], ['    schema_BatchPermutation', '    BatchPermutationGradientOp(const OperatorDef & def,Workspace *ws)', '    BatchPermutationOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_permutation_op_gpu_test.cc', [], ['    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInputCPU(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInputGPU(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    CheckCPUGPUEqual(vector shape,vector indices)', '    CreateAndRun(TensorCPU *outResult,int N,vector & shape,vector & features,vector indices)', '    CreateAndRunGradient(TensorCPU *outResult,int N,vector & shape,vector & features,vector indices)', '    GetDeviceType', '    TEST(BatchPermutationTest,CHECKCPUGPUEqualGenericDimension)', '    y_cpu', '    y_cpu_grad', '    y_gpu', '    y_gpu_grad']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_sparse_to_dense_op.cc', ['    GetBatchDenseToSparseGradient', '    GetBatchSparseToDenseGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchDenseToSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchSparseToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchDenseToSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchSparseToDense', '    vector', '    vector', '    FillInSparseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const float *dense_data,float *output_data,CPUContext *)', '    FillInDenseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const float *values_data,float *output_data,CPUContext *)', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\batch_sparse_to_dense_op.h', ['    BatchDenseToSparseOp', '    BatchSparseToDenseOp'], ['    BatchDenseToSparseOp(Args,...)', '    FillInSparseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const T *dense_data,T *output_data,Context *context)', '    len_prefix_sum_', '    len_prefix_tmp_', '    RunOnDevice', '    BatchSparseToDenseOp(Args,...)', '    FillInDenseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const T *values_data,T *output_data,Context *context)', '    len_prefix_sum_', '    len_prefix_tmp_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp', [], ['    apply_cholesky(Tensor & self,bool upper,std::vector & infos)', '    apply_cholesky_solve(Tensor & b,Tensor & A,bool upper,std::vector & infos)', '    apply_geqrf(Tensor & self,Tensor & tau,int64_t m,int64_t n,std::vector & infos)', '    apply_inverse(Tensor & self,std::vector & infos)', '    apply_lu(Tensor & self,Tensor & pivots,Tensor & infos)', '    apply_lu_solve(Tensor & b,const Tensor & lu,const Tensor & pivots,std::vector & infos)', '    apply_orgqr(Tensor & self,const Tensor & tau,int64_t m,int64_t n_columns,int64_t k,std::vector & infos)', '    apply_solve(Tensor & b,Tensor & A,std::vector & infos)', '    apply_svd(Tensor & self,Tensor & U,Tensor & S,Tensor & VT,char jobz,std::vector & infos)', '    apply_symeig(Tensor & self,Tensor & eigvals,bool eigenvectors,bool upper,std::vector & infos)', '    apply_triangular_solve(Tensor & b,Tensor & A,bool upper,bool transpose,bool unitriangular)', '    _cholesky_helper_cpu(const Tensor & self,bool upper)', '    _cholesky_solve_helper_cpu(const Tensor & self,const Tensor & A,bool upper)', '    _inverse_helper_cpu(const Tensor & self)', '    _lu_solve_helper_cpu(const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    _lu_with_info_cpu(const Tensor & self,bool pivot,bool check_errors)', '    _qr_helper_cpu(const Tensor & self,bool some)', '    _solve_helper_cpu(const Tensor & self,const Tensor & A)', '    _svd_helper_cpu(const Tensor & self,bool some,bool compute_uv)', '    _symeig_helper_cpu(const Tensor & self,bool eigenvectors,bool upper)', '    _triangular_solve_helper_cpu(const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)', '    cholesky(const Tensor & self,bool upper)', '    cholesky_out(Tensor & result,const Tensor & self,bool upper)', '    cholesky_solve(const Tensor & self,const Tensor & A,bool upper)', '    cholesky_solve_out(Tensor & result,const Tensor & self,const Tensor & A,bool upper)', '    inverse(const Tensor & self)', '    inverse_out(Tensor & result,const Tensor & self)', '    lu_solve(const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    lu_solve_out(Tensor & result,const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    qr(const Tensor & self,bool some)', '    qr_out(Tensor & Q,Tensor & R,const Tensor & self,bool some)', '    solve(const Tensor & self,const Tensor & A)', '    solve_out(Tensor & solution,Tensor & lu,const Tensor & self,const Tensor & A)', '    svd(const Tensor & self,bool some,bool compute_uv)', '    svd_out(Tensor & U,Tensor & S,Tensor & VT,const Tensor & self,bool some,bool compute_uv)', '    symeig(const Tensor & self,bool eigenvectors,bool upper)', '    symeig_out(Tensor & vals,Tensor & vecs,const Tensor & self,bool eigenvectors,bool upper)', '    triangular_solve(const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)', '    triangular_solve_out(Tensor & result,Tensor & clone_A,const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\BatchNorm.cpp', [], ['    cudnn_batch_norm_backward(const Tensor & input_t,const Tensor & grad_output_t,const Tensor & weight_t,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean_t,const Tensor & save_var_t,double epsilon,const Tensor & reserveSpace)', '    cudnn_batch_norm(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,const Tensor & running_mean_t,const Tensor & running_var_t,bool training,double exponential_average_factor,double epsilon)', '    expandScale(const Tensor & t,int64_t dim)', '    idesc', '    idesc', '    input', '    input', '    odesc', '    output', '    size', '    t', '    t', '    wdesc', '    wdesc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\batchnorm.cpp', [], ['    BatchNormOptions(int64_t num_features)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\batchnorm.cpp', [], ['    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    pretty_print(std::ostream & stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\batchnorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\batchnorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\batchnorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\miopen\\BatchNorm_miopen.cpp', [], ['    miopen_batch_norm_backward(const Tensor & input_t,const Tensor & grad_output_t,const Tensor & weight_t,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean_t,const Tensor & save_var_t,double epsilon)', '    expandScale(const Tensor & t,int64_t dim)', '    miopen_batch_norm(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,const Tensor & running_mean_t,const Tensor & running_var_t,bool training,double exponential_average_factor,double epsilon)', '    idesc', '    idesc', '    input', '    input', '    output', '    size', '    t', '    t', '    wdesc', '    wdesc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bbox_transform_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBBoxTransform', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BBoxTransform', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bbox_transform_op.h', ['    final'], ['    schema_BBoxTransform', '    angle_bound_hi_', '    angle_bound_lo_', '    angle_bound_on_', '    apply_scale_', '    BBoxTransformOp(Args,...)', '    clip_angle_thresh_', '    legacy_plus_one_', '    rotated_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\bench_utils.cc', [], ['    wipe_cache']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\bench_utils.h', [], ['    wipe_cache']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\benchmark.cc', ['    C10FlagParser_data_net', '    C10FlagParser_init_net', '    C10FlagParser_input_dims', '    C10FlagParser_input_types', '    C10FlagParser_iter', '    C10FlagParser_num_loading_threads', '    C10FlagParser_run_net', '    C10FlagParser_runs', '    C10FlagParser_threads', '    C10FlagParser_warmup'], ['    C10FlagParser_data_net(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_types(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_num_loading_threads(const std::string & content)', '    C10FlagParser_run_net(const std::string & content)', '    C10FlagParser_runs(const std::string & content)', '    C10FlagParser_threads(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)', '    benchmark(const BenchmarkParam & param)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\benchmark.h', ['    BenchmarkRunner'], ['    benchmark(const BenchmarkParam & param)', '    post_benchmark_cleanup', '    pre_benchmark_setup', '    ~BenchmarkRunner']]
['RELATIVE:\\pytorch-master\\pytorch-master\\ios\\TestApp\\TestApp\\Benchmark.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\benchmark_args.h', ['    C10FlagParser_backend', '    C10FlagParser_init_net', '    C10FlagParser_input', '    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_measure_memory', '    C10FlagParser_net', '    C10FlagParser_output', '    C10FlagParser_output_folder', '    C10FlagParser_run_individual', '    C10FlagParser_sleep_before_run', '    C10FlagParser_sleep_between_iteration', '    C10FlagParser_sleep_between_net_and_operator', '    C10FlagParser_text_output', '    C10FlagParser_warmup', '    C10FlagParser_wipe_cache'], ['    C10FlagParser_backend(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_measure_memory(const std::string & content)', '    C10FlagParser_net(const std::string & content)', '    C10FlagParser_output(const std::string & content)', '    C10FlagParser_output_folder(const std::string & content)', '    C10FlagParser_run_individual(const std::string & content)', '    C10FlagParser_sleep_before_run(const std::string & content)', '    C10FlagParser_sleep_between_iteration(const std::string & content)', '    C10FlagParser_sleep_between_net_and_operator(const std::string & content)', '    C10FlagParser_text_output(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)', '    C10FlagParser_wipe_cache(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\benchmark_helper.cc', [], ['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input,const string & FLAGS_input_dims,const string & FLAGS_input_file,const string & FLAGS_input_type,int FLAGS_iter,bool FLAGS_measure_memory,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    getVirtualMemoryIfOptionEnabled(bool FLAGS_measure_memory)', '    loadInput(shared_ptr workspace,const bool run_on_gpu,map & tensor_protos_map,const string & input,const string & input_file,const string & input_dims,const string & input_type)', '    logBenchmarkResult(const std::string & type,const std::string & metric,const std::string & unit,const int value)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetBase *net,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setDeviceType(caffe2::NetDef *net_def,caffe2::DeviceType & run_dev)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\benchmark_helper.h', [], ['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input,const string & FLAGS_input_dims,const string & FLAGS_input_file,const string & FLAGS_input_type,int FLAGS_iter,bool FLAGS_measure_memory,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    getVirtualMemoryIfOptionEnabled(bool FLAGS_measure_memory)', '    loadInput(shared_ptr workspace,const bool run_on_gpu,map & tensor_protos_map,const string & input,const string & input_file,const string & input_dims,const string & input_type)', '    logBenchmarkResult(const std::string & type,const std::string & metric,const std::string & unit,const int value)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetBase *net,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)', '    writeTextOutput(TensorType *tensor,const string & output_prefix,const string & name,int index,int num_blobs)', '    replace', '    shared_ptr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\BFloat16-inl.h', [], ['    denorm_min', '    epsilon', '    infinity', '    lowest', '    max', '    min', '    quiet_NaN', '    round_error', '    signaling_NaN', '    operator&(BFloat16 & a,const BFloat16 & b)', '    operator*(const BFloat16 & a,const BFloat16 & b)', '    operator*(BFloat16 a,float b)', '    operator*(float a,BFloat16 b)', '    operator*(BFloat16 a,double b)', '    operator*(double a,BFloat16 b)', '    operator*(BFloat16 a,int b)', '    operator*(int a,BFloat16 b)', '    operator*(BFloat16 a,int64_t b)', '    operator*(int64_t a,BFloat16 b)', '    operator*=(BFloat16 & a,const BFloat16 & b)', '    operator*=(float & a,const BFloat16 & b)', '    operator+(const BFloat16 & a,const BFloat16 & b)', '    operator+(BFloat16 a,float b)', '    operator+(float a,BFloat16 b)', '    operator+(BFloat16 a,double b)', '    operator+(double a,BFloat16 b)', '    operator+(BFloat16 a,int b)', '    operator+(int a,BFloat16 b)', '    operator+(BFloat16 a,int64_t b)', '    operator+(int64_t a,BFloat16 b)', '    operator+=(BFloat16 & a,const BFloat16 & b)', '    operator+=(float & a,const BFloat16 & b)', '    operator-(const BFloat16 & a,const BFloat16 & b)', '    operator-(const BFloat16 & a)', '    operator-(BFloat16 a,float b)', '    operator-(float a,BFloat16 b)', '    operator-(BFloat16 a,double b)', '    operator-(double a,BFloat16 b)', '    operator-(BFloat16 a,int b)', '    operator-(int a,BFloat16 b)', '    operator-(BFloat16 a,int64_t b)', '    operator-(int64_t a,BFloat16 b)', '    operator-=(BFloat16 & a,const BFloat16 & b)', '    operator-=(float & a,const BFloat16 & b)', '    operator/(const BFloat16 & a,const BFloat16 & b)', '    operator/(BFloat16 a,float b)', '    operator/(float a,BFloat16 b)', '    operator/(BFloat16 a,double b)', '    operator/(double a,BFloat16 b)', '    operator/(BFloat16 a,int b)', '    operator/(int a,BFloat16 b)', '    operator/(BFloat16 a,int64_t b)', '    operator/(int64_t a,BFloat16 b)', '    operator/=(BFloat16 & a,const BFloat16 & b)', '    operator/=(float & a,const BFloat16 & b)', '    operator^(BFloat16 & a,const BFloat16 & b)', '    operator|(BFloat16 & a,const BFloat16 & b)', '    exp(c10::BFloat16 a)', '    log(c10::BFloat16 a)', '    BFloat16(float value)', '    from_bits', '    operator float', '    f32_from_bits', '    round_to_nearest_even', '    exp', '    log']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\BFloat16.h', [], ['    from_bits', '    BFloat16', '    BFloat16(unsigned short bits,from_bits_t)', '    BFloat16(float value)', '    bits_from_f32(float src)', '    f32_from_bits(uint16_t src)', '    round_to_nearest_even(float src)', '    operator float', '    isnan']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\bfloat16_test.cpp', ['    BFloat16Test'], ['    BinaryToFloat(uint32_t bytes)', '    float_from_bytes(uint32_t sign,uint32_t exponent,uint32_t fraction)', '    TEST(BFloat16Conversion,FloatToBFloat16AndBack)', '    TEST(BFloat16Conversion,FloatToBFloat16RNEAndBack)', '    TEST(BFloat16Conversion,NaN)', '    TEST(BFloat16Conversion,Inf)', '    TEST(BFloat16Conversion,SmallestDenormal)', '    TEST(BFloat16Math,Addition)', '    TEST(BFloat16Math,Substraction)', '    TEST_P(BFloat16Test,BFloat16RNETest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Graph\\BinaryMatchImpl.h', [], ['    assert']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\BinaryMatchImplTest.cc', [], ['    exp', '    exp1', '    exp2', '    TEST(BinaryMatch,NoMatch)', '    TEST(BinaryMatch,AllMatch)', '    TEST(BinaryMatch,EmptyGraph)', '    TEST(BinaryMatch,Basic)', '    TEST(BinaryMatch,RemovedMiddleNode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\BinaryOps.cpp', [], ['    mkldnn_add(const Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_add_(Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_add_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_mul(const Tensor & self,const Tensor & other)', '    mkldnn_mul_(Tensor & self,const Tensor & other)', '    mkldnn_mul_out(Tensor & result,const Tensor & self,const Tensor & other)', '    scales', '    scales']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\BinaryOps.cpp', [], ['    check_convert(Scalar scalar,ScalarType scalarType)', '    wrapped_scalar_tensor(Scalar scalar)', '    wrapped_scalar_tensor_and_check_convert(Scalar scalar,Tensor tensor)', '    torch_warn_once_63', '    torch_warn_once_78', '    __and__(const Tensor & self,const Tensor & other)', '    __and__(const Tensor & self,Scalar other)', '    __iand__(Tensor & self,const Tensor & other)', '    __iand__(Tensor & self,Scalar other)', '    __ilshift__(Tensor & self,const Tensor & other)', '    __ilshift__(Tensor & self,Scalar other)', '    __ior__(Tensor & self,const Tensor & other)', '    __ior__(Tensor & self,Scalar other)', '    __irshift__(Tensor & self,const Tensor & other)', '    __irshift__(Tensor & self,Scalar other)', '    __ixor__(Tensor & self,const Tensor & other)', '    __ixor__(Tensor & self,Scalar other)', '    __lshift__(const Tensor & self,const Tensor & other)', '    __lshift__(const Tensor & self,Scalar other)', '    __or__(const Tensor & self,const Tensor & other)', '    __or__(const Tensor & self,Scalar other)', '    __rshift__(const Tensor & self,const Tensor & other)', '    __rshift__(const Tensor & self,Scalar other)', '    __xor__(const Tensor & self,const Tensor & other)', '    __xor__(const Tensor & self,Scalar other)', '    add(const Tensor & self,const Tensor & other,Scalar alpha)', '    add(const Tensor & self,Scalar other,Scalar alpha)', '    add_(Tensor & self,const Tensor & other,Scalar alpha)', '    add_(Tensor & self,Scalar other,Scalar alpha)', '    add_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    atan2(const Tensor & self,const Tensor & other)', '    atan2_(Tensor & self,const Tensor & other)', '    atan2_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_and(const Tensor & self,const Tensor & other)', '    bitwise_and(const Tensor & self,Scalar other)', '    bitwise_and_(Tensor & self,const Tensor & other)', '    bitwise_and_(Tensor & self,Scalar other)', '    bitwise_and_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_and_out(Tensor & result,const Tensor & self,Scalar other)', '    bitwise_or(const Tensor & self,const Tensor & other)', '    bitwise_or(const Tensor & self,Scalar other)', '    bitwise_or_(Tensor & self,const Tensor & other)', '    bitwise_or_(Tensor & self,Scalar other)', '    bitwise_or_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_or_out(Tensor & result,const Tensor & self,Scalar other)', '    bitwise_xor(const Tensor & self,const Tensor & other)', '    bitwise_xor(const Tensor & self,Scalar other)', '    bitwise_xor_(Tensor & self,const Tensor & other)', '    bitwise_xor_(Tensor & self,Scalar other)', '    bitwise_xor_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_xor_out(Tensor & result,const Tensor & self,Scalar other)', '    comparison_op(const Tensor & self,const Tensor & other,OutImpl & out_impl)', '    comparison_op(const Tensor & self,Scalar other,OutImpl & out_impl)', '    comparison_op_(Tensor & self,const Tensor & other,OutImpl & out_impl)', '    comparison_op_(Tensor & self,Scalar other,OutImpl & out_impl)', '    comparison_op_out(Tensor & result,const Tensor & self,const Tensor & other,Stub & stub)', '    comparison_op_out(Tensor & result,const Tensor & self,Scalar other,OutImpl & out_impl)', '    div(const Tensor & self,const Tensor & other)', '    div(const Tensor & self,Scalar other)', '    div_(Tensor & self,const Tensor & other)', '    div_(Tensor & self,Scalar other)', '    div_out(Tensor & result,const Tensor & self,const Tensor & other)', '    eq(const Tensor & self,const Tensor & other)', '    eq(const Tensor & self,Scalar other)', '    eq_(Tensor & self,const Tensor & other)', '    eq_(Tensor & self,Scalar other)', '    eq_out(Tensor & result,const Tensor & self,const Tensor & other)', '    eq_out(Tensor & result,const Tensor & self,Scalar other)', '    floor_divide(const Tensor & self,const Tensor & other)', '    floor_divide(const Tensor & self,Scalar other)', '    floor_divide_(Tensor & self,const Tensor & other)', '    floor_divide_(Tensor & self,Scalar other)', '    floor_divide_out(Tensor & result,const Tensor & self,const Tensor & other)', '    fmod(const Tensor & self,const Tensor & other)', '    fmod(const Tensor & self,Scalar other)', '    fmod_(Tensor & self,const Tensor & other)', '    fmod_(Tensor & self,Scalar other)', '    fmod_out(Tensor & result,const Tensor & self,const Tensor & other)', '    fmod_out(Tensor & result,const Tensor & self,Scalar other)', '    ge(const Tensor & self,const Tensor & other)', '    ge(const Tensor & self,Scalar other)', '    ge_(Tensor & self,const Tensor & other)', '    ge_(Tensor & self,Scalar other)', '    ge_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ge_out(Tensor & result,const Tensor & self,Scalar other)', '    gt(const Tensor & self,const Tensor & other)', '    gt(const Tensor & self,Scalar other)', '    gt_(Tensor & self,const Tensor & other)', '    gt_(Tensor & self,Scalar other)', '    gt_out(Tensor & result,const Tensor & self,const Tensor & other)', '    gt_out(Tensor & result,const Tensor & self,Scalar other)', '    le(const Tensor & self,const Tensor & other)', '    le(const Tensor & self,Scalar other)', '    le_(Tensor & self,const Tensor & other)', '    le_(Tensor & self,Scalar other)', '    le_out(Tensor & result,const Tensor & self,const Tensor & other)', '    le_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_and(const Tensor & self,const Tensor & other)', '    logical_and(const Tensor & self,Scalar other)', '    logical_and_(Tensor & self,const Tensor & other)', '    logical_and_(Tensor & self,Scalar other)', '    logical_and_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_and_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_or(const Tensor & self,const Tensor & other)', '    logical_or(const Tensor & self,Scalar other)', '    logical_or_(Tensor & self,const Tensor & other)', '    logical_or_(Tensor & self,Scalar other)', '    logical_or_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_or_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_xor(const Tensor & self,const Tensor & other)', '    logical_xor(const Tensor & self,Scalar other)', '    logical_xor_(Tensor & self,const Tensor & other)', '    logical_xor_(Tensor & self,Scalar other)', '    logical_xor_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_xor_out(Tensor & result,const Tensor & self,Scalar other)', '    lt(const Tensor & self,const Tensor & other)', '    lt(const Tensor & self,Scalar other)', '    lt_(Tensor & self,const Tensor & other)', '    lt_(Tensor & self,Scalar other)', '    lt_out(Tensor & result,const Tensor & self,const Tensor & other)', '    lt_out(Tensor & result,const Tensor & self,Scalar other)', '    max(const Tensor & self,const Tensor & other)', '    max_(Tensor & self,const Tensor & other)', '    max_out(Tensor & result,const Tensor & self,const Tensor & other)', '    min(const Tensor & self,const Tensor & other)', '    min_(Tensor & self,const Tensor & other)', '    min_out(Tensor & result,const Tensor & self,const Tensor & other)', '    mul(const Tensor & self,const Tensor & other)', '    mul(const Tensor & self,Scalar other)', '    mul_(Tensor & self,const Tensor & other)', '    mul_(Tensor & self,Scalar other)', '    mul_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ne(const Tensor & self,const Tensor & other)', '    ne(const Tensor & self,Scalar other)', '    ne_(Tensor & self,const Tensor & other)', '    ne_(Tensor & self,Scalar other)', '    ne_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ne_out(Tensor & result,const Tensor & self,Scalar other)', '    remainder(const Tensor & self,const Tensor & other)', '    remainder(const Tensor & self,Scalar other)', '    remainder_(Tensor & self,const Tensor & other)', '    remainder_(Tensor & self,Scalar other)', '    remainder_out(Tensor & result,const Tensor & self,const Tensor & other)', '    remainder_out(Tensor & result,const Tensor & self,Scalar other)', '    rsub(const Tensor & self,const Tensor & other,Scalar alpha)', '    rsub(const Tensor & self,Scalar other,Scalar alpha)', '    sigmoid_backward(const Tensor & grad_output,const Tensor & output)', '    sigmoid_backward_out(Tensor & result,const Tensor & grad_output,const Tensor & output)', '    sub(const Tensor & self,const Tensor & other,Scalar alpha)', '    sub(const Tensor & self,Scalar other,Scalar alpha)', '    sub_(Tensor & self,const Tensor & other,Scalar alpha)', '    sub_(Tensor & self,Scalar other,Scalar alpha)', '    sub_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    tanh_backward(const Tensor & grad_output,const Tensor & output)', '    tanh_backward_out(Tensor & result,const Tensor & grad_output,const Tensor & output)', '    true_divide(const Tensor & self,const Tensor & divisor)', '    true_divide(const Tensor & self,Scalar divisor)', '    true_divide_(Tensor & self,const Tensor & divisor)', '    true_divide_(Tensor & self,Scalar divisor)', '    true_divide_out(Tensor & result,const Tensor & self,const Tensor & divisor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\BinaryOps.h', [], ['    alpha_check(const ScalarType dtype,Scalar alpha)', '    sub_check(const Tensor & self,const Tensor & other)', '    add_stub', '    add_stub', '    operator=', '    atan2_stub', '    atan2_stub', '    operator=', '    bitwise_and_stub', '    bitwise_and_stub', '    operator=', '    bitwise_or_stub', '    bitwise_or_stub', '    operator=', '    bitwise_xor_stub', '    bitwise_xor_stub', '    operator=', '    div_stub', '    div_stub', '    operator=', '    eq_stub', '    eq_stub', '    operator=', '    fmod_scalar_stub', '    fmod_scalar_stub', '    operator=', '    fmod_stub', '    fmod_stub', '    operator=', '    ge_stub', '    ge_stub', '    operator=', '    gt_stub', '    gt_stub', '    operator=', '    le_stub', '    le_stub', '    operator=', '    logical_and_stub', '    logical_and_stub', '    operator=', '    logical_or_stub', '    logical_or_stub', '    operator=', '    logical_xor_stub', '    logical_xor_stub', '    operator=', '    lshift_stub', '    lshift_stub', '    operator=', '    lt_stub', '    lt_stub', '    operator=', '    max_elementwise_stub', '    max_elementwise_stub', '    operator=', '    min_elementwise_stub', '    min_elementwise_stub', '    operator=', '    mse_stub', '    mse_stub', '    operator=', '    mul_stub', '    mul_stub', '    operator=', '    ne_stub', '    ne_stub', '    operator=', '    operator=', '    remainder_stub', '    remainder_stub', '    operator=', '    rshift_stub', '    rshift_stub', '    operator=', '    sigmoid_backward_stub', '    sigmoid_backward_stub', '    operator=', '    smooth_l1_stub', '    smooth_l1_stub', '    operator=', '    sub_stub', '    sub_stub', '    operator=', '    tanh_backward_stub', '    tanh_backward_stub', '    scalar_type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\BinaryOpsKernel.cpp', [], ['    lshift_wrapper(scalar_t a,scalar_t b)', '    lshift_wrapper(int8_t a,int8_t b)', '    lshift_wrapper(int16_t a,int16_t b)', '    lshift_wrapper(int32_t a,int32_t b)', '    lshift_wrapper(int64_t a,int64_t b)', '    rshift_wrapper(scalar_t a,scalar_t b)', '    rshift_wrapper(int8_t a,int8_t b)', '    rshift_wrapper(int16_t a,int16_t b)', '    rshift_wrapper(int32_t a,int32_t b)', '    rshift_wrapper(int64_t a,int64_t b)', '    torch_warn_once_536', '    add_kernel(TensorIterator & iter,Scalar alpha_scalar)', '    atan2_kernel(TensorIterator & iter)', '    bitwise_and_kernel(TensorIterator & iter)', '    bitwise_or_kernel(TensorIterator & iter)', '    bitwise_xor_kernel(TensorIterator & iter)', '    div_kernel(TensorIterator & iter)', '    eq_kernel(TensorIterator & iter)', '    fmod_kernel(TensorIterator & iter)', '    fmod_scalar_kernel(TensorIterator & iter,Scalar divisor)', '    ge_kernel(TensorIterator & iter)', '    gt_kernel(TensorIterator & iter)', '    le_kernel(TensorIterator & iter)', '    logical_and_kernel(TensorIterator & iter)', '    logical_or_kernel(TensorIterator & iter)', '    logical_xor_kernel(TensorIterator & iter)', '    lshift_kernel(TensorIterator & iter)', '    lt_kernel(TensorIterator & iter)', '    max_elementwise_kernel(TensorIterator & iter)', '    min_elementwise_kernel(TensorIterator & iter)', '    mse_kernel(TensorIterator & iter)', '    mul_kernel(TensorIterator & iter)', '    ne_kernel(TensorIterator & iter)', '    remainder_kernel(TensorIterator & iter)', '    rshift_kernel(TensorIterator & iter)', '    sigmoid_backward_kernel(TensorIterator & iter)', '    smooth_l1_kernel(TensorIterator & iter)', '    sub_kernel(TensorIterator & iter,Scalar alpha_scalar)', '    tanh_backward_kernel(TensorIterator & iter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bisect_percentile_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBisectPercentile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BisectPercentile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bisect_percentile_op.h', ['    final'], ['    binary_search(const std::vector::iterator & data,int lo,int hi,float val)', '    BisectPercentileOp(Args,...)', '    compute_percentile(const std::vector::iterator & pct_raw_it,const std::vector::iterator & pct_mapping_it,const std::vector::iterator & pct_lower_it,const std::vector::iterator & pct_upper_it,const int size,const float val)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\BlasWrappersCPU.cpp', [], ['    mm_cpu(const Tensor & self,const Tensor & mat2)', '    mm_cpu_out(Tensor & result,const Tensor & self,const Tensor & mat2)', '    mv_cpu(const Tensor & self,const Tensor & vec)', '    mv_cpu_out(Tensor & result,const Tensor & self,const Tensor & vec)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\blob.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob.h', [], ['    BlobGetMutableTensor(Blob *blob,at::IntArrayRef dims,at::TensorOptions options)', '    BlobGetMutableTensor(Blob *blob,DeviceType device_type)', '    BlobGetTensor(const Blob & blob,DeviceType device_type)', '    BlobGetTensorOrUndefined(const Blob & blob)', '    BlobIsInt8TensorCPUType(const Blob & blob)', '    BlobIsTensorType(const Blob & blob,DeviceType device_type)', '    BlobSetTensor(Blob *blob,Tensor)', '    GetSizedTensorWithOptions(Tensor,at::IntArrayRef dims,at::TensorOptions options)', '    XBlobGetMutableTensor(Blob *blob,at::IntArrayRef dims,at::TensorOptions options)', '    defined', '    GetDevice', '    GetDeviceType', '    has_index', '    raw_mutable_data', '    Resize', '    UnsafeSharedInstance', '    TypeName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\blob.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_gpu_test.cc', ['    TensorGPUDeathTest', '    TensorGPUTest'], ['    TEST(TensorGPUTest,TensorSerialization_bool)', '    TEST(TensorGPUTest,TensorSerialization_double)', '    TEST(TensorGPUTest,TensorSerialization_float)', '    TEST(TensorGPUTest,TensorSerialization_int)', '    TEST(TensorGPUTest,TensorSerialization_int8_t)', '    TEST(TensorGPUTest,TensorSerialization_int16_t)', '    TEST(TensorGPUTest,TensorSerialization_uint8_t)', '    TEST(TensorGPUTest,TensorSerialization_uint16_t)', '    TEST(TensorGPUTest,TensorSerialization_int64_t)', '    TEST(TensorConstruction,ReinitializeTensorTest)', '    TEST(TensorTest,TensorSerializationMultiDevices)', '    TYPED_TEST(TensorGPUTest,TensorInitializedEmpty)', '    TYPED_TEST(TensorGPUTest,TensorInitializedNonEmpty)', '    TYPED_TEST(TensorGPUTest,TensorAlias)', '    TYPED_TEST(TensorGPUTest,TensorAliasCanUseDifferentShapes)', '    TYPED_TEST(TensorGPUTest,NoLongerAliasAfterNumelChanges)', '    TYPED_TEST(TensorGPUDeathTest,CannotAccessDataWhenEmpty)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_serialization.cc', ['    C10FlagParser_caffe2_max_tensor_serializer_threads', '    C10FlagParser_caffe2_serialize_fp16_as_bytes', '    C10FlagParser_caffe2_serialize_using_bytes_as_holder', '    C10FlagParser_caffe2_tensor_chunk_size', '    StringDeserializer', '    StringSerializer'], ['    ContextFromProto(const TensorProto & tensor_proto)', '    DimsFromTensorProto(const TensorProto & proto)', '    EnableByteEncoding(const TensorProto::DataType & dataType,const size_t & typeSize)', '    GetDataType(const TensorProto & tensor_proto)', '    NumelFromTensorProto(const TensorProto & tensor_proto)', '    SerializeUsingBytesOrInt32(const Tensor & input,const TensorProto::DataType & dataType,size_t chunkBegin,int32_t chunkSize,BaseContext *context,TensorProto & proto)', '    TensorOptionsFromProto(const TensorProto & tensor_proto)', '    DeserializeBlob(const string & content,Blob *result)', '    DeserializeBlob(const BlobProto & blob_proto,Blob *result)', '    DeserializeFromBytesOrInt32(const TensorProto & tensor_proto,size_t chunkBegin,int32_t chunkSize,BaseContext *context,Tensor *tensor)', '    EmptyTensorFromProto(const TensorProto & tensor_proto)', '    RegistryName', '    RegistryName', '    SerializeAsString_EnforceCheck(const google::protobuf::MessageLite & msg,const char *error_location)', '    SerializeBlob(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const void *pointer,TypeMeta typeMeta,const string & name)', '    SerializeBlob(const Blob & blob,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const Blob & blob,const string & name)', '    processChunk', '    task', '    C10FlagParser_caffe2_max_tensor_serializer_threads(const std::string & content)', '    C10FlagParser_caffe2_serialize_fp16_as_bytes(const std::string & content)', '    C10FlagParser_caffe2_serialize_using_bytes_as_holder(const std::string & content)', '    C10FlagParser_caffe2_tensor_chunk_size(const std::string & content)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    StringSerializer', '    ~StringSerializer', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const TensorProto & tensor_proto)', '    DeserializeToTensor(const TensorProto & tensor_proto,Tensor *tensor)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Serialize(const Tensor & input,const string & name,TensorProto *proto_ptr,size_t chunkBegin,int32_t chunkSize)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    StoreDeviceDetail(const Tensor & input,TensorProto *proto)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_serialization.h', ['    TensorDeserializer', '    TensorSerializer'], ['    DeserializeBlob(const string & content,Blob *result)', '    DeserializeBlob(const BlobProto & blob_proto,Blob *result)', '    CopyFromProtoAsIs(const size_t size,const google::protobuf::RepeatedField & field,DstType *dst,BaseContext *context)', '    CopyFromProtoWithCast(const size_t size,const google::protobuf::RepeatedField & field,DstType *dst,BaseContext *context)', '    CopyToProtoAsIs(const size_t size,const SrcType *src,google::protobuf::RepeatedField *field,BaseContext *context)', '    CopyToProtoWithCast(const size_t size,const SrcType *src,google::protobuf::RepeatedField *field,BaseContext *context)', '    EmptyTensorFromProto(const TensorProto & tensor_proto)', '    SerializeAsString_EnforceCheck(const google::protobuf::MessageLite & msg,const char *error_location)', '    SerializeBlob(const Blob & blob,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const Blob & blob,const string & name)', '    SerializeBlobProtoAsString_EnforceCheck(const BlobProto & blob)', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const TensorProto & tensor_proto)', '    DeserializeToTensor(const TensorProto & tensor_proto,Tensor *tensor)', '    Serialize(const Tensor & input,const string & name,TensorProto *proto_ptr,size_t chunkBegin,int32_t chunkSize)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor,int chunk_size)', '    StoreDeviceDetail(const Tensor & input,TensorProto *proto)', '    TensorSerializer', '    ~TensorSerializer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_serialization_gpu.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_serializer_base.h', ['    BlobDeserializerBase', '    BlobSerializerBase'], ['    CreateDeserializer(const string & type)', '    CreateSerializer(TypeIdentifier id)', '    RegistryName', '    Deserialize(const BlobProto & proto,Blob *blob)', '    ~BlobDeserializerBase', '    Serialize(const void *pointer,TypeMeta typeMeta,const std::string & name,SerializationAcceptor acceptor)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const std::string & name,SerializationAcceptor acceptor,int)', '    ~BlobSerializerBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_stats.cc', [], ['    sizeBytes(const Blob & blob)', '    doRegister(TypeIdentifier id,std::unique_ptr)', '    get(TypeIdentifier id)', '    instance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_stats.h', [], ['    sizeBytes(const Blob & blob)', '    sizeBytes(const Blob & blob)', '    ~BlobStatGetter', '    doRegister(TypeIdentifier id,std::unique_ptr)', '    get(TypeIdentifier id)', '    instance', '    instance', '    Registrar', '    Id']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\blob_test.cc', ['    C10FlagParser_caffe2_test_big_tensor_size', '    BlobTestBar', '    BlobTestFoo', '    BlobTestFooDeserializer', '    BlobTestFooSerializer', '    BlobTestNonDefaultConstructible', '    DummyTypeDeserializer', '    DummyTypeSerializer', '    TensorCPUDeathTest', '    TensorCPUTest', '    TypedTensorTest', '    VectorCursor', '    VectorDB'], ['    CreateProtoWithInt32Data(const caffe2::TensorProto::DataType & dataType,size_t numEl,bool useCached)', '    blob3', '    TEST(BlobTest,Blob)', '    TEST(BlobTest,BlobUninitialized)', '    TEST(BlobTest,BlobWrongType)', '    TEST(BlobTest,BlobReset)', '    TEST(BlobTest,BlobMove)', '    TEST(BlobTest,BlobNonConstructible)', '    TEST(BlobTest,BlobShareExternalPointer)', '    TEST(BlobTest,BlobShareExternalObject)', '    TEST(BlobTest,StringSerialization)', '    TEST(TensorNonTypedTest,TensorChangeType)', '    TEST(TensorNonTypedTest,NonDefaultConstructible)', '    TEST(TensorTest,TensorNonFundamentalType)', '    TEST(TensorTest,TensorNonFundamentalTypeClone)', '    TEST(TensorTest,Tensor64BitDimension)', '    TEST(TensorTest,UndefinedTensor)', '    TEST(TensorDeathTest,CannotCastDownLargeDims)', '    TEST(TensorTest,TensorSerialization_bool)', '    TEST(EmptyTensorTest,TensorSerialization_bool)', '    TEST(TensorTest,TensorSerialization_double)', '    TEST(EmptyTensorTest,TensorSerialization_double)', '    TEST(TensorTest,TensorSerialization_float)', '    TEST(EmptyTensorTest,TensorSerialization_float)', '    TEST(TensorTest,TensorSerialization_int)', '    TEST(EmptyTensorTest,TensorSerialization_int)', '    TEST(TensorTest,TensorSerialization_int8_t)', '    TEST(EmptyTensorTest,TensorSerialization_int8_t)', '    TEST(TensorTest,TensorSerialization_int16_t)', '    TEST(EmptyTensorTest,TensorSerialization_int16_t)', '    TEST(TensorTest,TensorSerialization_uint8_t)', '    TEST(EmptyTensorTest,TensorSerialization_uint8_t)', '    TEST(TensorTest,TensorSerialization_uint16_t)', '    TEST(EmptyTensorTest,TensorSerialization_uint16_t)', '    TEST(TensorTest,TensorSerialization_int64_t)', '    TEST(EmptyTensorTest,TensorSerialization_int64_t)', '    TEST(TensorTest,TensorSerialization_CustomType)', '    TEST(TensorTest,Half)', '    TEST(TensorTest,TensorFactory)', '    TEST(QTensorTest,QTensorSerialization)', '    TEST(ContentChunks,Serialization)', '    TEST(CustomChunkSize,BigTensorSerialization)', '    TEST(QTensor,QTensorSizingTest)', '    TEST(BlobTest,CastingMessage)', '    TEST(TensorConstruction,UninitializedCopyTest)', '    TEST(TensorConstruction,CopyConstructorTest)', '    TEST(TensorConstruction,MoveAssignmentOpTest)', '    TEST(TensorSerialization,MistakenlySerializingDtypeUninitializedTensor)', '    TEST(TensorSerialization,TestCorrectness)', '    TestDataType(const caffe2::TensorProto::DataType & dataType,std::string dataTypeName)', '    TYPED_TEST(TensorCPUTest,TensorInitializedEmpty)', '    TYPED_TEST(TensorCPUTest,TensorInitializedNonEmpty)', '    TYPED_TEST(TensorCPUTest,TensorInitializedZeroDim)', '    TYPED_TEST(TensorCPUTest,TensorResizeZeroDim)', '    TYPED_TEST(TensorCPUTest,TensorInitializedScalar)', '    TYPED_TEST(TensorCPUTest,TensorAlias)', '    TYPED_TEST(TensorCPUTest,TensorShareDataRawPointer)', '    TYPED_TEST(TensorCPUTest,TensorShareDataRawPointerWithMeta)', '    TYPED_TEST(TensorCPUTest,TensorAliasCanUseDifferentShapes)', '    TYPED_TEST(TensorCPUTest,NoLongerAliassAfterNumelChanges)', '    TYPED_TEST(TensorCPUTest,NoLongerAliasAfterFreeMemory)', '    TYPED_TEST(TensorCPUTest,KeepOnShrink)', '    TYPED_TEST(TensorCPUTest,MaxKeepOnShrink)', '    TYPED_TEST(TensorCPUDeathTest,CannotAccessRawDataWhenEmpty)', '    TYPED_TEST(TensorCPUDeathTest,CannotAccessDataWhenEmpty)', '    TYPED_TEST(TypedTensorTest,BigTensorSerialization)', '    dims', '    dims', '    registerData(const string & name,StringMap)', '    C10FlagParser_caffe2_test_big_tensor_size(const std::string & content)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    BlobTestFooSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~BlobTestFooSerializer', '    BlobTestNonDefaultConstructible(int x)', '    deserialize(const BlobProto &)', '    DummyType(int n_chunks_init)', '    serialize(const std::string & name,const int32_t chunk_id)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    DummyTypeSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~DummyTypeSerializer', '    key', '    Next', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    VectorCursor(StringMap *data)', '    ~VectorCursor', '    Close', '    getData', '    NewCursor', '    NewTransaction', '    VectorDB(const string & source,db::Mode mode)', '    ~VectorDB', '    vector', '    vector', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '  Static Member Variables', '    data_', '    dataRegistryMutex_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\blobs_queue.cc', [], ['    canRead', '    blockingWrite(const std::vector & inputs)', '    canWrite', '    close', '    doWrite(const std::vector & inputs)', '    tryWrite(const std::vector & inputs)', '    BlobsQueue(Workspace *ws,const std::string & queueName,size_t capacity,size_t numBlobs,bool enforceUniqueName,const std::vector & fieldNames)', '    blockingRead(const std::vector & inputs,float timeout_secs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\blobs_queue.h', ['    BlobsQueue'], ['    BlobsQueue(Workspace *ws,const std::string & queueName,size_t capacity,size_t numBlobs,bool enforceUniqueName,const std::vector & fieldNames)', '    blockingRead(const std::vector & inputs,float timeout_secs)', '    blockingWrite(const std::vector & inputs)', '    canWrite', '    close', '    closing_', '    doWrite(const std::vector & inputs)', '    getNumBlobs', '    queue_balance', '    queue_dequeued_bytes', '    queue_dequeued_records', '    QueueStats(std::string name)', '    read_time_ns', '    write_time_ns', '    reader_', '    tryWrite(const std::vector & inputs)', '    writer_', '    ~BlobsQueue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\blobs_queue_db.cc', ['    CreateBlobsQueueDBOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateBlobsQueueDB', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateBlobsQueueDB', '    CreateBlobsQueueDBOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\blobs_queue_db.h', ['    BlobsQueueDB', '    BlobsQueueDBCursor'], ['    blob_vector', '    GetStringFromBlob(Blob *blob)', '    BlobsQueueDB(const string & source,Mode mode,std::shared_ptr queue,int key_blob_index,int value_blob_index,float timeout_secs)', '    Close', '    NewCursor', '    NewTransaction', '    ~BlobsQueueDB', '    BlobsQueueDBCursor(std::shared_ptr queue,int key_blob_index,int value_blob_index,float timeout_secs)', '    key', '    Next', '    Seek(const string &)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~BlobsQueueDBCursor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\boolean_mask_ops.cc', ['    final', '    GetBooleanMaskGradient', '    GetSequenceMaskGradient', '    LowerDiagFunctor', '    LowerFunctor', '    SequenceFunctor', '    UpperDiagFunctor', '    UpperFunctor', '    WindowFunctor'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanMask', '    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanMaskLengths', '    CAFFE_ANONYMOUS_VARIABLE_CPUSequenceMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMaskGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMaskLengths', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SequenceMask', '    MaskWithFunctor(int N,int M,int B,const float *in,Functor fn,float fill_val,float *out)', '    RepeatedMaskWithFunctor(int N,int M,int D,const float *in,Functor fn,float fill_val,float *out)', '    vector', '    RunOnDevice', '    DoRunWithType', '    BooleanMaskLengthsOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    GetGradientDefs', '    CopyArguments', '    GetGradientDefs', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    SequenceFunctor(const int *sl,const size_t len)', '    DoRunWithType', '    RunOnDevice', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    WindowFunctor(const int *c,int r)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\boolean_mask_ops.h', ['    final', '    final', '    final'], ['    BooleanMaskOp(Args,...)', '    BooleanMaskOpGradient(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SequenceMaskOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\boolean_unmask_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanUnmask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanUnmask', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\boolean_unmask_ops.h', ['    final'], ['    BooleanUnmaskOp(Args,...)', '    RunOnDevice', '    ~BooleanUnmaskOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\boolean_unmask_ops_test.cc', [], ['    AddScalarInput(const DataT & value,const string & name,Workspace *ws,bool isEmpty)', '    TEST(BooleanUnmaskTest,Test)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\bound_shape_inference_test.cc', [], ['    makeTensorInfo(const std::vector & t,const std::vector & dims,TensorProto::DataType dtype,bool quantized)', '    new_shape', '    new_shape2', '    TEST(BoundShapeInference,SparseLengthsSum)', '    TEST(BoundShapeInference,SparseLengthsSumFused8BitRowwise)', '    TEST(BoundShapeInference,SparseLengthsSumFused4BitRowwise)', '    TEST(BoundShapeInference,LengthsRangeFill)', '    TEST(BoundShapeInference,Reshape)', '    TEST(BoundShapeInference,ConcatMissingInput)', '    TEST(BoundShapeInference,DISABLED_Int8QuantizeInferInputBackwards)', '    TEST(BoundShapeInference,ConcatInferInputBackwards)', '    TEST(BoundShapeInference,Bucketize)', '    TEST(BoundShapeInference,Split)', '    TEST(BoundShapeInference,FC)', '    TEST(BoundShapeInference,FC3D)', '    TEST(BoundShapeInference,Quantization)', '    TEST(BoundShapeInference,Combo0)', '    verifyShapeInfo(const ShapeInfoMap & info,const std::string & name,const std::vector & t,const std::vector & dims,TensorProto::DataType dtype,bool quantized)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\bound_shape_inferencer.cc', [], ['    unsupported', '    ConvertToVec(const ::google::protobuf::RepeatedField & in)', '    InferOutput(const OperatorDef & op,const std::vector & input_shapes)', '    setDimTypeWithFirst(TensorBoundShape::DimType firstDimType,uint32_t n)', '    SizeFromDim(const TensorShape & shape,int axis)', '    SizeToDim(const TensorShape & shape,int axis)', '    getBoundShapeInferencer(const BoundShapeSpec & spec)', '    input_shapes', '    RegistryName', '    InferCommonOp(const OperatorDef & op)', '    InferConcat(const OperatorDef & op)', '    InferConcatInputs(const OperatorDef & op)', '    InferFC(const OperatorDef & op)', '    InferInt8QuantizeInput(const OperatorDef & op)', '    InferQuantizationTransformation(const OperatorDef & op)', '    InferReshape(const OperatorDef & op)', '    InferShape(const OperatorDef & op)', '    CheckAndSetTensorBoundShape(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized,bool allow_existing_shape)', '    EnsureShapeNames(std::unordered_map *info)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    InferGivenTensorFill(const OperatorDef & op)', '    InferLengthsRangeFill(const OperatorDef & op)', '    InferOps(const OperatorDef & op,caffe2::Workspace *)', '    InferSparseLengthsSum(const OperatorDef & op)', '    Initialize(const ShapeInfoMap & info,bool extract_feature_len)', '    SetTensorBoundShapeIfNotExist(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\bound_shape_inferencer.h', ['    BoundShapeInferencer', '    BoundShapeInferencerBase'], ['    getBoundShapeInferencer(const BoundShapeSpec & spec)', '    RegistryName', '    BoundShapeInferencer(const BoundShapeSpec & spec)', '    CheckAndSetTensorBoundShape(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized,bool allow_existing_shape)', '    current_dim_type_', '    current_max_batch_size_', '    EnsureShapeNames(ShapeInfoMap *info)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    InferCommonOp(const OperatorDef & op)', '    InferConcat(const OperatorDef & op)', '    InferConcatInputs(const OperatorDef & op)', '    InferFC(const OperatorDef & op)', '    InferGivenTensorFill(const OperatorDef & op)', '    InferInt8QuantizeInput(const OperatorDef & op)', '    InferLengthsRangeFill(const OperatorDef & op)', '    InferOps(const OperatorDef & op,caffe2::Workspace *)', '    InferQuantizationTransformation(const OperatorDef & op)', '    InferReshape(const OperatorDef & op)', '    InferShape(const OperatorDef & op)', '    InferSparseLengthsSum(const OperatorDef & op)', '    Initialize(const ShapeInfoMap & info,bool extract_feature_len)', '    SetTensorBoundShapeIfNotExist(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized)', '    ~BoundShapeInferencer', '    BoundShapeInferencerBase(const BoundShapeSpec & spec)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    PrintShapeInfo', '    shape_info', '    ~BoundShapeInferencerBase', '    BoundShapeSpec(int64_t b,int64_t q)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\box_with_nms_limit_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBoxWithNMSLimit', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BoxWithNMSLimit', '    get_all_scores_sorted', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\box_with_nms_limit_op.h', ['    final'], ['    schema_BoxWithNMSLimit', '    BoxWithNMSLimitOp(Args,...)', '    cls_agnostic_bbox_reg_', '    get_box_cls_index(int bg_fg_cls_id)', '    get_score_cls_index(int bg_fg_cls_id)', '    input_boxes_include_bg_cls_', '    input_scores_fg_cls_starting_id_', '    legacy_plus_one_', '    output_classes_include_bg_cls_', '    rotated_', '    RunOnDevice', '    ~BoxWithNMSLimitOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\boxing.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\broadcast.cc', [], ['    AffineChannel(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y,CPUContext *)', '    AffineChannel(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\broadcast.h', [], ['    AffineChannel(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\broadcast_ops.cc', [], ['    initializeAlgorithm']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\broadcast_ops.h', ['    final'], ['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    BroadcastOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeAlgorithm', '    RunOnDevice', '    update(GlooParameters & params)', '    ~BroadcastOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\broadcast_ops_gpu.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\broadcast_test.cpp', [], ['    TEST(BroadcastTest,Broadcast)', '    TestEmptyTensor(DeprecatedTypeProperties & T)', '    TestExplicitDimBasic(DeprecatedTypeProperties & T)', '    TestExplicitDimWithMismatchedSizes(DeprecatedTypeProperties & T)', '    TestExplicitDimWithScalar(DeprecatedTypeProperties & T)', '    TestIn2Basic(DeprecatedTypeProperties & T)', '    TestIn2ExpandError(DeprecatedTypeProperties & T)', '    TestIn2WithScalar(DeprecatedTypeProperties & T)', '    TestIn3Basic(DeprecatedTypeProperties & T)', '    TestIn3ExpandError(DeprecatedTypeProperties & T)', '    TestIn3WithScalar(DeprecatedTypeProperties & T)', '    TestOut2Basic(DeprecatedTypeProperties & T)', '    TestOut2MismatchedSizes(DeprecatedTypeProperties & T)', '    TestOut2OldFallback(DeprecatedTypeProperties & T)', '    TestOut2WithScalar(DeprecatedTypeProperties & T)', '    TestOut3Basic(DeprecatedTypeProperties & T)', '    TestOut3MismatchedSizes(DeprecatedTypeProperties & T)', '    TestOut3OldFallback(DeprecatedTypeProperties & T)', '    TestOut3WithScalar(DeprecatedTypeProperties & T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bucketize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBucketize', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Bucketize', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\bucketize_op.h', ['    final'], ['    schema_BucketizeOp', '    boundaries_device_', '    BucketizeOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    is_sorted']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\buffer.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\buffer.h', ['    Buffer'], ['    begin', '    end', '    Buffer(const VarHandle & data,const Dtype & dtype,const std::vector & dims)', '    Buffer(const std::string & name,const Dtype & dtype,const std::vector & dims)', '    call(const std::vector & args)', '    data', '    dim(int index)', '    dtype', '    Index(const ExprHandle & x)', '    Index(const ExprHandle & x,const ExprHandle & y)', '    Index(const ExprHandle & x,const ExprHandle & y,const ExprHandle & z)', '    Index(const ExprHandle & x,const ExprHandle & y,const ExprHandle & z,const ExprHandle & w)', '    Index(const std::vector & indices)', '    LoadValue(const ExprHandle & index)', '    ndim', '    operator()(Args,...)', '    make']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\builtin_function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\builtin_functions.cpp', [], ['    rhs', '    scalar', '    scalar', '    getAllBuiltinFunctionsFor(Symbol name)', '    getAllBuiltinFunctionsFor(Symbol name)', '    loadBuiltinFunctions', '    loadSource(const std::string & source,const std::string & the_namespace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\builtin_functions.h', [], ['    getAllBuiltinFunctionsFor(Symbol name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\byte_order.cpp', [], ['    decodeUInt16BE(const uint8_t *data)', '    decodeUInt16LE(const uint8_t *data)', '    decodeUInt32BE(const uint8_t *data)', '    decodeUInt32LE(const uint8_t *data)', '    decodeUInt64BE(const uint8_t *data)', '    decodeUInt64LE(const uint8_t *data)', '    swapBytes16(void *ptr)', '    swapBytes32(void *ptr)', '    swapBytes64(void *ptr)', '    THP_decodeBFloat16Buffer(at::BFloat16 *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeBoolBuffer(bool *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeDoubleBuffer(double *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeFloatBuffer(float *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeHalfBuffer(at::Half *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt16Buffer(int16_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt32Buffer(int32_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt64Buffer(int64_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_encodeDoubleBuffer(uint8_t *dst,const double *src,THPByteOrder order,size_t len)', '    THP_encodeFloatBuffer(uint8_t *dst,const float *src,THPByteOrder order,size_t len)', '    THP_encodeInt16Buffer(uint8_t *dst,const int16_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt32Buffer(uint8_t *dst,const int32_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt64Buffer(uint8_t *dst,const int64_t *src,THPByteOrder order,size_t len)', '    THP_nativeByteOrder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\byte_order.h', [], ['    THP_decodeBFloat16Buffer(at::BFloat16 *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeBoolBuffer(bool *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeDoubleBuffer(double *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeFloatBuffer(float *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeHalfBuffer(at::Half *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt16Buffer(int16_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt32Buffer(int32_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt64Buffer(int64_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_encodeDoubleBuffer(uint8_t *dst,const double *src,THPByteOrder order,size_t len)', '    THP_encodeFloatBuffer(uint8_t *dst,const float *src,THPByteOrder order,size_t len)', '    THP_encodeInt16Buffer(uint8_t *dst,const int16_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt32Buffer(uint8_t *dst,const int32_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt64Buffer(uint8_t *dst,const int64_t *src,THPByteOrder order,size_t len)', '    THP_nativeByteOrder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\byte_weight_dequant_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUByteWeightDequant', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ByteWeightDequant']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\byte_weight_dequant_op.h', ['    ByteWeightDequantOp'], ['    ByteWeightDequantOp(const OperatorDef & operator_def,Workspace *ws)', '    GetRepeatedArgument', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\C++17.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\C++17.h', ['    final'], ['    call(T value)', '    apply_impl(F,Tuple,std::index_sequence)', '    max(const T & a,const T & b)', '    min(const T & a,const T & b)', '    to_string(T value)', '    invoke(Functor,Args,...)', '    invoke(Functor,Args,...)', '    make_index_sequence', '    make_index_sequence', '    to_string(c10::guts::detail::DummyClassForToString)', '    call(T)', '    forward', '    mem_fn', '    call']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\C++17_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\c10_utils.h', [], ['    callOp(const c10::OperatorHandle & op,Args,...)', '    callOp(const char *func_name,const char *overload_name,Args,...)', '    makeStack(Inputs,...)', '    has_value', '    value', '    singleton']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\c10d.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\caffe2_benchmark.cc', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\caffe2_dnnlowp_utils.cc', [], ['    GetQuantizationFactoryOf_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorBase & op)', '    OutputArgumentIdxString_(int idx)', '    OutputScaleArgumentName(int idx)', '    OutputZeroPointArgumentName(int idx)', '    SetStaticQuantizationParams_(OperatorDef *op_def,int output_index,const TensorQuantizationParams & qparams)', '    AddScaleZeroOffsetArgumentsWithHistogram(NetDef net_def,const string & histogram_file_name)', '    AdjustOutputTensorQuantizationParamsWithFollowedBy(OperatorBase *op,const string & followed_by)', '    GetInputTensorQuantizationParamsOf(OperatorBase *op,int idx,const QuantizationFactory *qfactory,bool is_weight)', '    GetQuantizationFactoryOf(const OperatorBase *op)', '    GetStaticQuantizationParamsOf(const caffe2::OperatorBase *op,int idx)', '    HasStaticQuantization(const caffe2::OperatorBase *op,int output_index)', '    MeasureQuantizationError(const float *actual,const float *ref,size_t len,QuantizationErrorStats *stat)', '    ParseDNNLowPOperatorArguments(OperatorBase *op,bool *dequantize_output,bool *measure_quantization_error,string *followed_by)', '    PropagateOutputTensorQuantizationParams(OperatorBase *op,int idx,const TensorQuantizationParams & qparams)', '    QuantizeInputIfNeeded(OperatorBase *op,int input_index,const TensorQuantizationParams & qparams,vector & temp)', '    ReportQuantizationError(const OperatorBase *op,const QuantizationErrorStats & stat)', '    RowWiseQuantizeInputIfNeeded(OperatorBase *op,int input_index,const std::vector & qparams,vector & temp)', '    SetStaticQuantizationParams(OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\caffe2_dnnlowp_utils.h', [], ['    AddScaleZeroOffsetArgumentsWithHistogram(caffe2::NetDef net_def,const std::string & histogram_file_name)', '    AdjustOutputTensorQuantizationParamsWithFollowedBy(caffe2::OperatorBase *op,const std::string & followed_by)', '    GetInputTensorQuantizationParamsOf(caffe2::OperatorBase *op,int input_index,const QuantizationFactory *qfactory,bool is_weight)', '    GetQuantizationFactoryOf(const caffe2::OperatorBase *op)', '    GetStaticQuantizationParamsOf(const caffe2::OperatorBase *op,int idx)', '    HasStaticQuantization(const caffe2::OperatorBase *op,int output_index)', '    MeasureQuantizationError(const float *actual,const float *ref,size_t len,QuantizationErrorStats *stat)', '    ParseDNNLowPOperatorArguments(caffe2::OperatorBase *op,bool *dequantize_output,bool *measure_quantization_error,std::string *followed_by)', '    PropagateOutputTensorQuantizationParams(caffe2::OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)', '    QuantizeInputIfNeeded(caffe2::OperatorBase *op,int input_index,const TensorQuantizationParams & qparams,std::vector & temp)', '    ReportQuantizationError(const caffe2::OperatorBase *op,const QuantizationErrorStats & stat)', '    RowWiseQuantizeInputIfNeeded(caffe2::OperatorBase *op,int input_index,const std::vector & qparams,std::vector & temp)', '    SetStaticQuantizationParams(caffe2::OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)', '    max_abs_err', '    max_err_actual', '    max_err_ref', '    measure_cnt', '    sum_err_sq', '    sum_sq']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\test\\caffe2_gtest_main.cc', ['    C10FlagParser_caffe_test_root'], ['    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\proto\\caffe2_pb.h', [], ['    DeviceToOption(const at::Device & device)', '    ExtractDeviceOption(DeviceOption *device_option,const at::Device & device)', '    OptionToDevice(const caffe2::DeviceOption option)', '    ProtoToType(const caffe2::DeviceTypeProto p)', '    ProtoToType(int p)', '    TypeToProto(const DeviceType & t)', '    Device']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\canonicalize.cpp', [], ['    CanonicalizeIfOutputs(Node *n)', '    CanonicalizeLoopOutputs(Node *n)', '    CanonicalizeOutputs(Block *block)', '    CanonicalizeOutputs(std::shared_ptr & graph)', '    sort_indexes(at::ArrayRef values)', '    blockIndex(const Block *b)', '    Canonicalize(const std::shared_ptr & graph,bool keep_unique_names)', '    isBefore(Node *n1,Node *n2)', '    isBefore(const Use & a,const Use & b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\canonicalize.h', [], ['    Canonicalize(const std::shared_ptr & graph,bool keep_unique_names)', '    CanonicalizeOutputs(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\canonicalize_modified_loop.cpp', [], ['    canonicalizeModifiedLoops(Block *block)', '    CanonicalizeModifiedLoops(std::shared_ptr & graph)', '    canonicalizeModifiedLoop(Node *n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\canonicalize_modified_loop.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\canonicalize_ops.cpp', [], ['    CanonicalizeOps(Block *block)', '    CanonicalizeOps(const std::shared_ptr & graph)', '    insert_guard', '    ChunkOutput(Value *v,size_t o)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\canonicalize_ops.h', [], ['    CanonicalizeOps(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cast.h', [], ['    GetCastDataType(const ArgumentHelper & helper,std::string arg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\cast_all_constant_to_floating.cpp', [], ['    CastAllConstantToFloating(Block *block)', '    CastAllConstantToFloating(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\cast_all_constant_to_floating.h', [], ['    CastAllConstantToFloating(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\cast_cpu.cc', [], ['    cast_op_cpu(const at::Tensor & input,const at::Tensor & output,int64_t to)', '    cast_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_,int64_t to_)', '    do_cast_(const Tensor & input,const Tensor & output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cast_op.cc', ['    GetCastGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cast', '    vector', '    call(SrcType data)', '    call(SrcType data)', '    DoRunWithDstType', '    DoRunWithType', '    SetBody(TensorProto_DataType to)', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cast_op.h', ['    CastOp'], ['    CastOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithDstType', '    DoRunWithType', '    RunOnDevice', '    SetBody(TensorProto_DataType to)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cast_test.cc', [], ['    TEST(CastTest,GetCastDataType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Support\\Casting.h', [], ['    doit(const std::unique_ptr & Val)', '    assert(isa)', '    cast(const Y & Val)', '    cast(Y & Val)', '    cast(Y *Val)', '    cast_or_null(const Y & Val)', '    cast_or_null(Y & Val)', '    cast_or_null(Y *Val)', '    dyn_cast(const Y & Val)', '    dyn_cast(Y & Val)', '    dyn_cast(Y *Val)', '    dyn_cast_or_null(const Y & Val)', '    dyn_cast_or_null(Y & Val)', '    dyn_cast_or_null(Y *Val)', '    isa(const Y & Val)', '    doit(From & Val)', '    doit(const FromTy & Val)', '    doit(const From &)', '    doit(const From & Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From & Val)', '    doit(const From & Val)', '    doit(const From & Val)', '    doit(const FromTy & Val)', '    getSimplifiedValue(From & Val)', '    getSimplifiedValue(const From & Val)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\testing\\catch_utils.hpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\CatKernel.cpp', [], ['    cat_serial_kernel(Tensor & result,TensorList tensors,int64_t dim)', '    cat_serial_kernel_impl(Tensor & result,TensorList tensors,int64_t dim)', '    InputMeta(const Tensor & t,int64_t dim,int64_t inner)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\CatKernel.h', [], ['    cat_serial_stub', '    cat_serial_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cblas.h', [], ['    catlas_caxpby(const int N,const void *alpha,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    catlas_cset(const int N,const void *alpha,void *X,const int incX)', '    catlas_daxpby(const int N,const double alpha,const double *X,const int incX,const double beta,double *Y,const int incY)', '    catlas_dset(const int N,const double alpha,double *X,const int incX)', '    catlas_saxpby(const int N,const float alpha,const float *X,const int incX,const float beta,float *Y,const int incY)', '    catlas_sset(const int N,const float alpha,float *X,const int incX)', '    catlas_zaxpby(const int N,const void *alpha,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    catlas_zset(const int N,const void *alpha,void *X,const int incX)', '    cblas_caxpy(const int N,const void *alpha,const void *X,const int incX,void *Y,const int incY)', '    cblas_ccopy(const int N,const void *X,const int incX,void *Y,const int incY)', '    cblas_cdotc_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotc)', '    cblas_cdotu_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotu)', '    cblas_cgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_cgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cgerc(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_cgeru(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_chbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_chemm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_chemv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cher(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const void *X,const int incX,void *A,const int lda)', '    cblas_cher2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_cher2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const float beta,void *C,const int ldc)', '    cblas_cherk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const void *A,const int lda,const float beta,void *C,const int ldc)', '    cblas_chpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *Ap,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_chpr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const void *X,const int incX,void *A)', '    cblas_chpr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *Ap)', '    cblas_crotg(void *a,void *b,void *c,void *s)', '    cblas_cscal(const int N,const void *alpha,void *X,const int incX)', '    cblas_csrot(const int N,void *X,const int incX,void *Y,const int incY,const float c,const float s)', '    cblas_csscal(const int N,const float alpha,void *X,const int incX)', '    cblas_cswap(const int N,void *X,const int incX,void *Y,const int incY)', '    cblas_csymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_csyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_csyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *beta,void *C,const int ldc)', '    cblas_ctbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ctbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ctpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ctpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ctrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ctrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_ctrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ctrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_dasum(const int N,const double *X,const int incX)', '    cblas_daxpy(const int N,const double alpha,const double *X,const int incX,double *Y,const int incY)', '    cblas_dcopy(const int N,const double *X,const int incX,double *Y,const int incY)', '    cblas_ddot(const int N,const double *X,const int incX,const double *Y,const int incY)', '    cblas_dgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dger(const enum CBLAS_ORDER Order,const int M,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A,const int lda)', '    cblas_dnrm2(const int N,const double *X,const int incX)', '    cblas_drot(const int N,double *X,const int incX,double *Y,const int incY,const double c,const double s)', '    cblas_drotg(double *a,double *b,double *c,double *s)', '    cblas_drotm(const int N,double *X,const int incX,double *Y,const int incY,const double *P)', '    cblas_drotmg(double *d1,double *d2,double *b1,const double b2,double *P)', '    cblas_dsbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dscal(const int N,const double alpha,double *X,const int incX)', '    cblas_dsdot(const int N,const float *X,const int incX,const float *Y,const int incY)', '    cblas_dspmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *Ap,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dspr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,double *Ap)', '    cblas_dspr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A)', '    cblas_dswap(const int N,double *X,const int incX,double *Y,const int incY)', '    cblas_dsymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dsymv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dsyr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,double *A,const int lda)', '    cblas_dsyr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A,const int lda)', '    cblas_dsyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dsyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const double *A,const int lda,const double beta,double *C,const int ldc)', '    cblas_dtbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const double *A,const int lda,double *X,const int incX)', '    cblas_dtbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const double *A,const int lda,double *X,const int incX)', '    cblas_dtpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *Ap,double *X,const int incX)', '    cblas_dtpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *Ap,double *X,const int incX)', '    cblas_dtrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const double alpha,const double *A,const int lda,double *B,const int ldb)', '    cblas_dtrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *A,const int lda,double *X,const int incX)', '    cblas_dtrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const double alpha,const double *A,const int lda,double *B,const int ldb)', '    cblas_dtrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *A,const int lda,double *X,const int incX)', '    cblas_dzasum(const int N,const void *X,const int incX)', '    cblas_dznrm2(const int N,const void *X,const int incX)', '    cblas_errprn(int ierr,int info,char *form,...)', '    cblas_icamax(const int N,const void *X,const int incX)', '    cblas_idamax(const int N,const double *X,const int incX)', '    cblas_isamax(const int N,const float *X,const int incX)', '    cblas_izamax(const int N,const void *X,const int incX)', '    cblas_sasum(const int N,const float *X,const int incX)', '    cblas_saxpy(const int N,const float alpha,const float *X,const int incX,float *Y,const int incY)', '    cblas_scasum(const int N,const void *X,const int incX)', '    cblas_scnrm2(const int N,const void *X,const int incX)', '    cblas_scopy(const int N,const float *X,const int incX,float *Y,const int incY)', '    cblas_sdot(const int N,const float *X,const int incX,const float *Y,const int incY)', '    cblas_sdsdot(const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY)', '    cblas_sgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_sgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sger(const enum CBLAS_ORDER Order,const int M,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A,const int lda)', '    cblas_snrm2(const int N,const float *X,const int incX)', '    cblas_srot(const int N,float *X,const int incX,float *Y,const int incY,const float c,const float s)', '    cblas_srotg(float *a,float *b,float *c,float *s)', '    cblas_srotm(const int N,float *X,const int incX,float *Y,const int incY,const float *P)', '    cblas_srotmg(float *d1,float *d2,float *b1,const float b2,float *P)', '    cblas_ssbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sscal(const int N,const float alpha,float *X,const int incX)', '    cblas_sspmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *Ap,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sspr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,float *Ap)', '    cblas_sspr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A)', '    cblas_sswap(const int N,float *X,const int incX,float *Y,const int incY)', '    cblas_ssymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_ssymv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_ssyr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,float *A,const int lda)', '    cblas_ssyr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A,const int lda)', '    cblas_ssyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_ssyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const float *A,const int lda,const float beta,float *C,const int ldc)', '    cblas_stbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const float *A,const int lda,float *X,const int incX)', '    cblas_stbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const float *A,const int lda,float *X,const int incX)', '    cblas_stpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *Ap,float *X,const int incX)', '    cblas_stpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *Ap,float *X,const int incX)', '    cblas_strmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const float alpha,const float *A,const int lda,float *B,const int ldb)', '    cblas_strmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *A,const int lda,float *X,const int incX)', '    cblas_strsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const float alpha,const float *A,const int lda,float *B,const int ldb)', '    cblas_strsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *A,const int lda,float *X,const int incX)', '    cblas_xerbla(int p,const char *rout,const char *form,...)', '    cblas_zaxpy(const int N,const void *alpha,const void *X,const int incX,void *Y,const int incY)', '    cblas_zcopy(const int N,const void *X,const int incX,void *Y,const int incY)', '    cblas_zdotc_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotc)', '    cblas_zdotu_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotu)', '    cblas_zdrot(const int N,void *X,const int incX,void *Y,const int incY,const double c,const double s)', '    cblas_zdscal(const int N,const double alpha,void *X,const int incX)', '    cblas_zgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zgerc(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zgeru(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zhbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zhemm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zhemv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zher(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const void *X,const int incX,void *A,const int lda)', '    cblas_zher2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zher2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const double beta,void *C,const int ldc)', '    cblas_zherk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const void *A,const int lda,const double beta,void *C,const int ldc)', '    cblas_zhpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *Ap,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zhpr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const void *X,const int incX,void *A)', '    cblas_zhpr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *Ap)', '    cblas_zrotg(void *a,void *b,void *c,void *s)', '    cblas_zscal(const int N,const void *alpha,void *X,const int incX)', '    cblas_zswap(const int N,void *X,const int incX,void *Y,const int incY)', '    cblas_zsymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zsyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zsyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *beta,void *C,const int ldc)', '    cblas_ztbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ztbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ztpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ztpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ztrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ztrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_ztrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ztrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cbrt_op.cc', ['    GetCbrtGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCbrt', '    CAFFE_ANONYMOUS_VARIABLE_CPUCbrtGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cbrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CbrtGradient', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *Y,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cbrt_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & Y_dims,const T *dY,const T *Y,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\cc_amrc.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConcatAddMulReplaceNaNClip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatAddMulReplaceNaNClip']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\cc_amrc.h', ['    final'], ['    ConcatAddMulReplaceNaNClipOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cc_bmm_bg_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConcatBatchMatMulBatchGatherOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatBatchMatMulBatchGatherOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cc_bmm_bg_op.h', ['    final'], ['    ConcatBatchMatMulBatchGatherOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    Gemm']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ceil_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCeil', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Ceil']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ceil_op.h', ['    final'], ['    CeilOp(Args,...)', '    RunOnDevice', '    ~CeilOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\channel-shuffle-operator-tester.h', ['    ChannelShuffleOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels', '    groupChannels(size_t groupChannels)', '    groupChannels', '    groupChannels_', '    groups(size_t groups)', '    groups', '    groups_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    testX8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\channel-shuffle.c', [], ['    pytorch_qnnp_create_channel_shuffle_nc_x8(size_t groups,size_t group_channels,uint32_t flags,pytorch_qnnp_operator_t *channel_shuffle_out)', '    pytorch_qnnp_setup_channel_shuffle_nc_x8(pytorch_qnnp_operator_t channel_shuffle_op,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\channel-shuffle.cc', [], ['    TEST(CHANNEL_SHUFFLE_OP,zero_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_input_and_output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\channel-shuffle.cc', [], ['    channel_shuffle_x8(benchmark::State & state,const char *net)', '    ShuffleNetV1G2Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x0_5Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x1_0Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x1_5Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x2_0Arguments(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_backprop_stats_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUChannelBackpropStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelBackpropStats', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_backprop_stats_op.h', ['    ChannelBackpropStatsOp'], ['    ChannelBackpropStatsOp(Args,...)', '    RunOnDevice', '    ~ChannelBackpropStatsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\channel_shuffle_dnnlowp_op.cc', [], ['    ChannelShuffleDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\channel_shuffle_dnnlowp_op.h', ['    final'], ['    ChannelShuffleDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\channel_shuffle_op.cc', ['    final', '    final'], ['    ChannelShuffleGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    ChannelShuffleOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_shuffle_op.cc', ['    GetChannelShuffleGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUChannelShuffle', '    RunChannelShuffleNCHW(const int N,const int G,const int K,const int HxW,const T *X,T *Y,CPUContext *context)', '    RunChannelShuffleNHWC(const int N,const int G,const int K,const int HxW,const T *X,T *Y,CPUContext *context)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelShuffleGradient', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_shuffle_op.h', ['    final', '    final'], ['    ChannelShuffleGradientOp(Args,...)', '    ChannelShuffleOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_stats_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUChannelStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelStats', '    ComputeChannelStatsNCHW(const int N,const int C,const int HxW,const float *X,float *sum,float *sumsq)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\channel_stats_op.h', ['    final'], ['    ChannelStatsOp(Args,...)', '    ComputeChannelStatsNCHW(int N,int C,int HxW,const T *X,T *sum,T *sumsq)', '    ComputeChannelStatsNHWC(int N,int C,int HxW,const T *X,T *sum,T *sumsq)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\check_alias_annotation.cpp', [], ['    checkAliasAnnotation(const std::shared_ptr & graph,std::vector pythonInputs,const std::string & unqualifiedOpName)', '    checkAliases(const std::vector & inputs,const std::vector & outputs)', '    checkInputPreconditions(const Stack & inputs)', '    checkWrites(const std::vector & inputs,const std::vector & deepCopiedInputs)', '    deepCopy(const IValue & self)', '    deepCopy(const Stack & stack)', '    deepEquals(const IValue & lhs,const IValue & rhs)', '    findNodeForOp(const Graph & g,const std::string & unqualifiedOpName)', '    toIValueProp(const Value *v)', '    AliasAndIValue(c10::optional aliasInfo,IValue iValue)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\check_alias_annotation.h', [], ['    checkAliasAnnotation(const std::shared_ptr & graph,std::vector pythonInputs,const std::string & unqualifiedOpName)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\chunk.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl.h', [], ['    clBuildProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCompileProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_headers,const cl_program *input_headers,const char **header_include_names,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCreateBuffer(cl_context context,cl_mem_flags flags,size_t size,void *host_ptr,cl_int *errcode_ret)', '    clCreateCommandQueue(cl_context context,cl_device_id device,cl_command_queue_properties properties,cl_int *errcode_ret)', '    clCreateContext(const cl_context_properties *properties,cl_uint num_devices,const cl_device_id *devices,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateContextFromType(const cl_context_properties *properties,cl_device_type device_type,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateImage(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,const cl_image_desc *image_desc,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage2D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_row_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage3D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_depth,size_t image_row_pitch,size_t image_slice_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateKernel(cl_program program,const char *kernel_name,cl_int *errcode_ret)', '    clCreateKernelsInProgram(cl_program program,cl_uint num_kernels,cl_kernel *kernels,cl_uint *num_kernels_ret)', '    clCreateProgramWithBinary(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const size_t *lengths,const unsigned char **binaries,cl_int *binary_status,cl_int *errcode_ret)', '    clCreateProgramWithBuiltInKernels(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *kernel_names,cl_int *errcode_ret)', '    clCreateProgramWithSource(cl_context context,cl_uint count,const char **strings,const size_t *lengths,cl_int *errcode_ret)', '    clCreateSampler(cl_context context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *errcode_ret)', '    clCreateSubBuffer(cl_mem buffer,cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *errcode_ret)', '    clCreateSubDevices(cl_device_id in_device,const cl_device_partition_property *properties,cl_uint num_devices,cl_device_id *out_devices,cl_uint *num_devices_ret)', '    clCreateUserEvent(cl_context context,cl_int *errcode_ret)', '    clEnqueueBarrier(cl_command_queue command_queue)', '    clEnqueueBarrierWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBuffer(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,size_t src_offset,size_t dst_offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferRect(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,const size_t *src_origin,const size_t *dst_origin,const size_t *region,size_t src_row_pitch,size_t src_slice_pitch,size_t dst_row_pitch,size_t dst_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferToImage(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_image,size_t src_offset,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImage(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_image,const size_t *src_origin,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImageToBuffer(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_buffer,const size_t *src_origin,const size_t *region,size_t dst_offset,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillBuffer(cl_command_queue command_queue,cl_mem buffer,const void *pattern,size_t pattern_size,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillImage(cl_command_queue command_queue,cl_mem image,const void *fill_color,const size_t *origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMapBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_map,cl_map_flags map_flags,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMapImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_map,cl_map_flags map_flags,const size_t *origin,const size_t *region,size_t *image_row_pitch,size_t *image_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMarker(cl_command_queue command_queue,cl_event *event)', '    clEnqueueMarkerWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMigrateMemObjects(cl_command_queue command_queue,cl_uint num_mem_objects,const cl_mem *mem_objects,cl_mem_migration_flags flags,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNativeKernel(cl_command_queue command_queue,void (*) (void *) user_func,void *args,size_t cb_args,cl_uint num_mem_objects,const cl_mem *mem_list,const void **args_mem_loc,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNDRangeKernel(cl_command_queue command_queue,cl_kernel kernel,cl_uint work_dim,const size_t *global_work_offset,const size_t *global_work_size,const size_t *local_work_size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,size_t offset,size_t size,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_read,const size_t *origin,const size_t *region,size_t row_pitch,size_t slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueTask(cl_command_queue command_queue,cl_kernel kernel,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueUnmapMemObject(cl_command_queue command_queue,cl_mem memobj,void *mapped_ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWaitForEvents(cl_command_queue command_queue,cl_uint num_events,const cl_event *event_list)', '    clEnqueueWriteBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,size_t offset,size_t size,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_write,const size_t *origin,const size_t *region,size_t input_row_pitch,size_t input_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clFinish(cl_command_queue command_queue)', '    clFlush(cl_command_queue command_queue)', '    clGetCommandQueueInfo(cl_command_queue command_queue,cl_command_queue_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetContextInfo(cl_context context,cl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetDeviceIDs(cl_platform_id platform,cl_device_type device_type,cl_uint num_entries,cl_device_id *devices,cl_uint *num_devices)', '    clGetDeviceInfo(cl_device_id device,cl_device_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventInfo(cl_event event,cl_event_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventProfilingInfo(cl_event event,cl_profiling_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetExtensionFunctionAddress(const char *func_name)', '    clGetExtensionFunctionAddressForPlatform(cl_platform_id platform,const char *func_name)', '    clGetImageInfo(cl_mem image,cl_image_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelArgInfo(cl_kernel kernel,cl_uint arg_indx,cl_kernel_arg_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelInfo(cl_kernel kernel,cl_kernel_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelWorkGroupInfo(cl_kernel kernel,cl_device_id device,cl_kernel_work_group_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetMemObjectInfo(cl_mem memobj,cl_mem_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetPlatformIDs(cl_uint num_entries,cl_platform_id *platforms,cl_uint *num_platforms)', '    clGetPlatformInfo(cl_platform_id platform,cl_platform_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramBuildInfo(cl_program program,cl_device_id device,cl_program_build_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramInfo(cl_program program,cl_program_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSamplerInfo(cl_sampler sampler,cl_sampler_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSupportedImageFormats(cl_context context,cl_mem_flags flags,cl_mem_object_type image_type,cl_uint num_entries,cl_image_format *image_formats,cl_uint *num_image_formats)', '    clLinkProgram(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_programs,const cl_program *input_programs,void (*) (cl_program, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clReleaseCommandQueue(cl_command_queue command_queue)', '    clReleaseContext(cl_context context)', '    clReleaseDevice(cl_device_id device)', '    clReleaseEvent(cl_event event)', '    clReleaseKernel(cl_kernel kernel)', '    clReleaseMemObject(cl_mem memobj)', '    clReleaseProgram(cl_program program)', '    clReleaseSampler(cl_sampler sampler)', '    clRetainCommandQueue(cl_command_queue command_queue)', '    clRetainContext(cl_context context)', '    clRetainDevice(cl_device_id device)', '    clRetainEvent(cl_event event)', '    clRetainKernel(cl_kernel kernel)', '    clRetainMemObject(cl_mem memobj)', '    clRetainProgram(cl_program program)', '    clRetainSampler(cl_sampler sampler)', '    clSetEventCallback(cl_event event,cl_int command_exec_callback_type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    clSetKernelArg(cl_kernel kernel,cl_uint arg_index,size_t arg_size,const void *arg_value)', '    clSetMemObjectDestructorCallback(cl_mem memobj,void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    clSetUserEventStatus(cl_event event,cl_int execution_status)', '    clUnloadCompiler', '    clUnloadPlatformCompiler(cl_platform_id platform)', '    clWaitForEvents(cl_uint num_events,const cl_event *event_list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\opencl\\OpenCL\\cl.hpp', ['    Buffer', '    BufferGL', '    BufferRenderGL', '    CommandQueue', '    Context', '    KernelFunctorGlobal', '    NullType', '    Wrapper', '    Wrapper', '    Device', '    Event', '    Image', '    Image1D', '    Image1DArray', '    Image1DBuffer', '    Image2D', '    Image2DArray', '    Image3D', '    ImageGL', '    Kernel', '    Memory', '    NDRange', '    Platform', '    Program', '    Sampler', '    size_t', '    UserEvent'], ['    errHandler(cl_int err,const char *errStr)', '    getDevicePlatformVersion(cl_device_id device)', '    getPlatformVersion(cl_platform_id platform)', '    getVersion(const char *versionInfo)', '    WaitForEvents(const std::vector & events)', '    __local(::size_t size)', '    copy(const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    copy(const CommandQueue & queue,const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    compare_exchange(volatile int *dest,int exchange,int comparand)', '    fence', '    getInfo(Func f,const Arg0 & arg0,cl_uint name,T *param)', '    getInfo(Func f,const Arg0 & arg0,const Arg1 & arg1,cl_uint name,T *param)', '    getInfo(Func f,cl_uint name,T *param)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,long)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,int,T::cl_type)', '    getInfoHelper(Func f,cl_uint name,T *param,int,T::cl_type)', '    getInfoHelper(Func f,cl_uint name,STRING_CLASS *param,long)', '    getInfoHelper(Func f,cl_uint name,size_t *param,long)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,int)', '    getInfoHelper(Functor f,cl_uint name,T *param,long)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    linkProgram(Program input1,Program input2,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    linkProgram(std::vector inputPrograms,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    Local(::size_t size)', '    getDefault(cl_int *err)', '    getDefault(cl_int *err)', '    ptr(const T & value)', '    ptr(const LocalSpaceArg &)', '    size(const LocalSpaceArg & value)', '    size(const T &)', '    release(cl_context context)', '    release(cl_mem memory)', '    release(cl_command_queue queue)', '    release(cl_sampler sampler)', '    release(cl_kernel kernel)', '    release(cl_program program)', '    release(cl_platform_id)', '    release(cl_event event)', '    release(cl_device_id device)', '    retain(cl_context context)', '    retain(cl_mem memory)', '    retain(cl_command_queue queue)', '    retain(cl_kernel kernel)', '    retain(cl_program program)', '    retain(cl_platform_id)', '    retain(cl_event event)', '    retain(cl_device_id device)', '    retain(cl_sampler sampler)', '    set(Kernel kernel,T0 arg)', '    set(Kernel,NullType)', '    isReferenceCountable(cl_device_id device)', '    getDefault(cl_int *err)', '    waitForEvents(const std::vector & events)', '    get(std::vector *platforms)', '    get(Platform *platform)', '    get(cl_int *errResult)', '    getDefault(cl_int *errResult)', '    Buffer(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const Context & context,cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const Buffer & buf)', '    Buffer', '    Buffer(IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const cl_mem & buffer)', '    Buffer(cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const Context & context,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    createSubBuffer(cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Buffer & buf)', '    BufferGL(const Context & context,cl_mem_flags flags,cl_GLuint bufobj,cl_int *err)', '    BufferGL(const cl_mem & buffer)', '    BufferGL', '    BufferGL(const BufferGL & buf)', '    getObjectInfo(cl_gl_object_type *type,cl_GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferGL & buf)', '    BufferRenderGL(const Context & context,cl_mem_flags flags,cl_GLuint bufobj,cl_int *err)', '    BufferRenderGL(const BufferRenderGL & buf)', '    BufferRenderGL', '    BufferRenderGL(const cl_mem & buffer)', '    getObjectInfo(cl_gl_object_type *type,cl_GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferRenderGL & rhs)', '    CommandQueue(cl_command_queue_properties properties,cl_int *err)', '    CommandQueue', '    CommandQueue(const CommandQueue & queue)', '    CommandQueue(const Context & context,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(const cl_command_queue & commandQueue)', '    CommandQueue(const Context & context,const Device & device,cl_command_queue_properties properties,cl_int *err)', '    enqueueAcquireGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueBarrierWithWaitList(const std::vector *events,Event *event)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueFillBuffer(const Buffer & buffer,PatternType pattern,::size_t offset,::size_t size,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_float4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_int4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_uint4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueMapImage(const Image & buffer,cl_bool blocking,cl_map_flags flags,const size_t & origin,const size_t & region,::size_t *row_pitch,::size_t *slice_pitch,const std::vector *events,Event *event,cl_int *err)', '    enqueueMarkerWithWaitList(const std::vector *events,Event *event)', '    enqueueMigrateMemObjects(const std::vector & memObjects,cl_mem_migration_flags flags,const std::vector *events,Event *event)', '    enqueueNativeKernel(void (*) (void *) userFptr,std::pair args,const std::vector *mem_objects,const std::vector *mem_locs,const std::vector *events,Event *event)', '    enqueueNDRangeKernel(const Kernel & kernel,const NDRange & offset,const NDRange & global,const NDRange & local,const std::vector *events,Event *event)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReleaseGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueTask(const Kernel & kernel,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    getInfo(cl_command_queue_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const CommandQueue & queue)', '    operator=(const cl_command_queue & rhs)', '    Context(const std::vector & devices,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Device & device,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Context & ctx)', '    Context', '    Context(const cl_context & context)', '    Context(cl_device_type type,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_context_info name,T *param)', '    getSupportedImageFormats(cl_mem_flags flags,cl_mem_object_type type,std::vector *formats)', '    operator=(const Context & ctx)', '    operator=(const cl_context & rhs)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30,T31 arg31)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    KernelFunctorGlobal(Kernel kernel)', '    KernelFunctorGlobal(const Program & program,const STRING_CLASS name,cl_int *err)', '    operator()(const EnqueueArgs & args,T0 t0,T1 t1,T2 t2,T3 t3,T4 t4,T5 t5,T6 t6,T7 t7,T8 t8,T9 t9,T10 t10,T11 t11,T12 t12,T13 t13,T14 t14,T15 t15,T16 t16,T17 t17,T18 t18,T19 t19,T20 t20,T21 t21,T22 t22,T23 t23,T24 t24,T25 t25,T26 t26,T27 t27,T28 t28,T29 t29,T30 t30,T31 t31)', '    operator()', '    operator()', '    operator()', '    operator()', '    operator=(const cl_type & rhs)', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    operator=(const Wrapper & rhs)', '    release', '    release', '    retain', '    retain', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    ~Wrapper', '    ~Wrapper', '    createSubDevices(const cl_device_partition_property *properties,std::vector *devices)', '    Device', '    Device(const cl_device_id & device)', '    Device(const Device & dev)', '    getInfo(cl_device_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const cl_device_id & rhs)', '    operator=(const Device & dev)', '    EnqueueArgs(const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(NDRange global)', '    EnqueueArgs(NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange global)', '    EnqueueArgs(Event e,NDRange global,NDRange local)', '    EnqueueArgs(NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(const std::vector & events,NDRange global)', '    EnqueueArgs(const std::vector & events,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange global)', '    EnqueueArgs(CommandQueue & queue,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global,NDRange local)', '    Event', '    Event(const cl_event & event)', '    getInfo(cl_int *err)', '    getInfo(cl_event_info name,T *param)', '    getProfilingInfo(cl_profiling_info name,T *param)', '    getProfilingInfo(cl_int *err)', '    operator=(const cl_event & rhs)', '    setCallback(cl_int type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    wait', '    Image1D(const cl_mem & image1D)', '    Image1D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,void *host_ptr,cl_int *err)', '    Image1D', '    Image1D(const Image1D & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1D & img)', '    Image1DArray(const cl_mem & imageArray)', '    Image1DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t rowPitch,void *host_ptr,cl_int *err)', '    Image1DArray', '    Image1DArray(const Image1DArray & img)', '    operator=(const Image1DArray & img)', '    operator=(const cl_mem & rhs)', '    Image1DBuffer(const cl_mem & image1D)', '    Image1DBuffer(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,const Buffer & buffer,cl_int *err)', '    Image1DBuffer', '    Image1DBuffer(const Image1DBuffer & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1DBuffer & img)', '    Image2D(const cl_mem & image2D)', '    Image2D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t row_pitch,void *host_ptr,cl_int *err)', '    Image2D', '    Image2D(const Image2D & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2D & img)', '    Image2DArray(const cl_mem & imageArray)', '    Image2DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t height,::size_t rowPitch,::size_t slicePitch,void *host_ptr,cl_int *err)', '    Image2DArray', '    Image2DArray(const Image2DArray & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2DArray & img)', '    Image3D(const cl_mem & image3D)', '    Image3D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t depth,::size_t row_pitch,::size_t slice_pitch,void *host_ptr,cl_int *err)', '    Image3D', '    Image3D(const Image3D & img)', '    operator=(const Image3D & img)', '    operator=(const cl_mem & rhs)', '    getImageInfo(cl_image_info name,T *param)', '    getImageInfo(cl_int *err)', '    Image(const cl_mem & image)', '    Image', '    Image(const Image & img)', '    operator=(const Image & img)', '    operator=(const cl_mem & rhs)', '    ImageFormat', '    ImageFormat(cl_channel_order order,cl_channel_type type)', '    operator=(const ImageFormat & rhs)', '    ImageGL(const Context & context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texobj,cl_int *err)', '    ImageGL(const cl_mem & image)', '    ImageGL', '    ImageGL(const ImageGL & img)', '    operator=(const cl_mem & rhs)', '    operator=(const ImageGL & img)', '    getArgInfo(cl_uint argIndex,cl_kernel_arg_info name,T *param)', '    getArgInfo(cl_uint argIndex,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_kernel_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_kernel_work_group_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_int *err)', '    Kernel(const Program & program,const char *name,cl_int *err)', '    Kernel(const Kernel & kernel)', '    Kernel(const cl_kernel & kernel)', '    Kernel', '    operator=(const Kernel & kernel)', '    operator=(const cl_kernel & rhs)', '    setArg(cl_uint index,const T & value)', '    setArg(cl_uint index,::size_t size,const void *argPtr)', '    make_kernel(const Program & program,const STRING_CLASS name,cl_int *err)', '    make_kernel(const Kernel kernel)', '    getInfo(cl_mem_info name,T *param)', '    getInfo(cl_int *err)', '    Memory(const cl_mem & memory)', '    Memory', '    Memory(const Memory & mem)', '    operator=(const cl_mem & rhs)', '    operator=(const Memory & mem)', '    setDestructorCallback(void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    dimensions', '    NDRange', '    NDRange(::size_t size0)', '    NDRange(::size_t size0,::size_t size1)', '    NDRange(::size_t size0,::size_t size1,::size_t size2)', '    operator const size_t *', '    getDevices(cl_device_type type,std::vector *devices)', '    getInfo(cl_int *err)', '    getInfo(cl_platform_info name,STRING_CLASS *param)', '    operator=(const cl_platform_id & rhs)', '    Platform', '    Platform(const cl_platform_id & platform)', '    unloadCompiler', '    build(const std::vector & devices,const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    build(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    compile(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    createKernels(std::vector *kernels)', '    getBuildInfo(const Device & device,cl_program_build_info name,T *param)', '    getBuildInfo(const Device & device,cl_int *err)', '    getInfo(cl_program_info name,T *param)', '    getInfo(cl_int *err)', '    getInfo(cl_int *err)', '    operator=(const Program & program)', '    operator=(const cl_program & rhs)', '    Program(const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Program & program)', '    Program(const cl_program & program)', '    Program(const Context & context,const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const STRING_CLASS & kernelNames,cl_int *err)', '    Program(const Context & context,const Sources & sources,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const Binaries & binaries,std::vector *binaryStatus,cl_int *err)', '    Program', '    getInfo(cl_sampler_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const Sampler & sam)', '    operator=(const cl_sampler & rhs)', '    Sampler(const cl_sampler & sampler)', '    Sampler(const Context & context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *err)', '    Sampler', '    Sampler(const Sampler & sam)', '    operator const size_t *', '    operator size_t *', '    operator[](int index)', '    operator[](int index)', '    size_t', '    setStatus(cl_int status)', '    UserEvent', '    UserEvent(const Context & context,cl_int *err)', '  Static Member Variables', '    default_', '    default_error_', '    default_initialized_', '    default_', '    default_error_', '    default_initialized_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl.hpp', ['    Buffer', '    BufferGL', '    BufferRenderGL', '    CommandQueue', '    Context', '    KernelFunctorGlobal', '    NullType', '    Wrapper', '    Wrapper', '    Device', '    Event', '    Image', '    Image1D', '    Image1DArray', '    Image1DBuffer', '    Image2D', '    Image2DArray', '    Image3D', '    ImageGL', '    Kernel', '    Memory', '    NDRange', '    Platform', '    Program', '    Sampler', '    size_t', '    UserEvent'], ['    errHandler(cl_int err,const char *errStr)', '    getDevicePlatformVersion(cl_device_id device)', '    getPlatformVersion(cl_platform_id platform)', '    getVersion(const char *versionInfo)', '    WaitForEvents(const std::vector & events)', '    __local(::size_t size)', '    copy(const CommandQueue & queue,const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    copy(const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    compare_exchange(volatile int *dest,int exchange,int comparand)', '    fence', '    getInfo(Func,const Arg0 & arg0,cl_uint name,T *param)', '    getInfo(Func,const Arg0 & arg0,const Arg1 & arg1,cl_uint name,T *param)', '    getInfo(Func,cl_uint name,T *param)', '    getInfoHelper(Func,cl_uint name,std::vector *param,long)', '    getInfoHelper(Func,cl_uint name,std::vector *param,int,T::cl_type)', '    getInfoHelper(Func,cl_uint name,T *param,int,T::cl_type)', '    getInfoHelper(Func,cl_uint name,STRING_CLASS *param,long)', '    getInfoHelper(Func,cl_uint name,size_t *param,long)', '    getInfoHelper(Func,cl_uint name,std::vector *param,int)', '    getInfoHelper(Functor,cl_uint name,T *param,long)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    linkProgram(Program input1,Program input2,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    linkProgram(std::vector inputPrograms,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    Local(::size_t size)', '    getDefault(cl_int *err)', '    getDefault(cl_int *err)', '    ptr(T & value)', '    ptr(LocalSpaceArg &)', '    size(const LocalSpaceArg & value)', '    size(const T &)', '    release(cl_context context)', '    release(cl_mem memory)', '    release(cl_command_queue queue)', '    release(cl_sampler sampler)', '    release(cl_kernel kernel)', '    release(cl_program program)', '    release(cl_platform_id)', '    release(cl_event event)', '    release(cl_device_id device)', '    retain(cl_context context)', '    retain(cl_mem memory)', '    retain(cl_command_queue queue)', '    retain(cl_kernel kernel)', '    retain(cl_program program)', '    retain(cl_platform_id)', '    retain(cl_event event)', '    retain(cl_device_id device)', '    retain(cl_sampler sampler)', '    Kernel', '    Kernel', '    isReferenceCountable(cl_device_id device)', '    getDefault(cl_int *err)', '    waitForEvents(const std::vector & events)', '    get(Platform *platform)', '    get(cl_int *errResult)', '    get(std::vector *platforms)', '    getDefault(cl_int *errResult)', '    Buffer(const Buffer & buffer)', '    Buffer', '    Buffer(IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const cl_mem & buffer)', '    Buffer(const Context & context,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const Context & context,cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    createSubBuffer(cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Buffer & rhs)', '    BufferGL', '    BufferGL(const BufferGL & buffer)', '    BufferGL(const cl_mem & buffer)', '    BufferGL(const Context & context,cl_mem_flags flags,GLuint bufobj,cl_int *err)', '    getObjectInfo(cl_gl_object_type *type,GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferGL & rhs)', '    BufferRenderGL', '    BufferRenderGL(const cl_mem & buffer)', '    BufferRenderGL(const Context & context,cl_mem_flags flags,GLuint bufobj,cl_int *err)', '    BufferRenderGL(const BufferGL & buffer)', '    getObjectInfo(cl_gl_object_type *type,GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferRenderGL & rhs)', '    CommandQueue', '    CommandQueue(const CommandQueue & commandQueue)', '    CommandQueue(const Context & context,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(const cl_command_queue & commandQueue)', '    CommandQueue(const Context & context,const Device & device,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(cl_command_queue_properties properties,cl_int *err)', '    enqueueAcquireGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueBarrierWithWaitList(const std::vector *events,Event *event)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueFillBuffer(const Buffer & buffer,PatternType pattern,::size_t offset,::size_t size,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_float4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_int4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_uint4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueMapImage(const Image & buffer,cl_bool blocking,cl_map_flags flags,const size_t & origin,const size_t & region,::size_t *row_pitch,::size_t *slice_pitch,const std::vector *events,Event *event,cl_int *err)', '    enqueueMarkerWithWaitList(const std::vector *events,Event *event)', '    enqueueMigrateMemObjects(const std::vector & memObjects,cl_mem_migration_flags flags,const std::vector *events,Event *event)', '    enqueueNativeKernel(void (*) (void *) userFptr,std::pair args,const std::vector *mem_objects,const std::vector *mem_locs,const std::vector *events,Event *event)', '    enqueueNDRangeKernel(const Kernel & kernel,const NDRange & offset,const NDRange & global,const NDRange & local,const std::vector *events,Event *event)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReleaseGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueTask(const Kernel & kernel,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    getInfo(cl_command_queue_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const CommandQueue & rhs)', '    operator=(const cl_command_queue & rhs)', '    Context(const Device & device,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Context & context)', '    Context', '    Context(const cl_context & context)', '    Context(cl_device_type type,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const std::vector & devices,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_context_info name,T *param)', '    getSupportedImageFormats(cl_mem_flags flags,cl_mem_object_type type,std::vector *formats)', '    operator=(const Context & rhs)', '    operator=(const cl_context & rhs)', '    ~Context', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30,T31 arg31)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    KernelFunctorGlobal(Kernel kernel)', '    KernelFunctorGlobal(const Program & program,const STRING_CLASS name,cl_int *err)', '    operator()(const EnqueueArgs & args,T0 t0,T1 t1,T2 t2,T3 t3,T4 t4,T5 t5,T6 t6,T7 t7,T8 t8,T9 t9,T10 t10,T11 t11,T12 t12,T13 t13,T14 t14,T15 t15,T16 t16,T17 t17,T18 t18,T19 t19,T20 t20,T21 t21,T22 t22,T23 t23,T24 t24,T25 t25,T26 t26,T27 t27,T28 t28,T29 t29,T30 t30,T31 t31)', '    set', '    operator()', '    operator()', '    operator()', '    operator()', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    release', '    release', '    retain', '    retain', '    Wrapper(const Wrapper & rhs)', '    Wrapper(const cl_type & obj)', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    Wrapper', '    ~Wrapper', '    ~Wrapper', '    createSubDevices(const cl_device_partition_property *properties,std::vector *devices)', '    Device(const cl_device_id & device)', '    Device(const Device & device)', '    Device', '    getInfo(cl_device_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const cl_device_id & rhs)', '    operator=(const Device & rhs)', '    EnqueueArgs(const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(NDRange global)', '    EnqueueArgs(NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange global)', '    EnqueueArgs(Event e,NDRange global,NDRange local)', '    EnqueueArgs(NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(const std::vector & events,NDRange global)', '    EnqueueArgs(const std::vector & events,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange global)', '    EnqueueArgs(CommandQueue & queue,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global,NDRange local)', '    Event', '    Event(const cl_event & event)', '    Event(const Event & event)', '    getInfo(cl_int *err)', '    getInfo(cl_event_info name,T *param)', '    getProfilingInfo(cl_profiling_info name,T *param)', '    getProfilingInfo(cl_int *err)', '    operator=(const cl_event & rhs)', '    operator=(const Event & rhs)', '    setCallback(cl_int type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    wait', '    ~Event', '    Image1D(const cl_mem & image1D)', '    Image1D', '    Image1D(const Image1D & image1D)', '    Image1D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1D & rhs)', '    Image1DArray(const cl_mem & imageArray)', '    Image1DArray', '    Image1DArray(const Image1DArray & imageArray)', '    Image1DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t rowPitch,void *host_ptr,cl_int *err)', '    operator=(const Image1DArray & rhs)', '    operator=(const cl_mem & rhs)', '    Image1DBuffer(const cl_mem & image1D)', '    Image1DBuffer', '    Image1DBuffer(const Image1DBuffer & image1D)', '    Image1DBuffer(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,const Buffer & buffer,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1DBuffer & rhs)', '    Image2D(const cl_mem & image2D)', '    Image2D', '    Image2D(const Image2D & image2D)', '    Image2D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t row_pitch,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2D & rhs)', '    Image2DArray(const cl_mem & imageArray)', '    Image2DArray', '    Image2DArray(const Image2DArray & imageArray)', '    Image2DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t height,::size_t rowPitch,::size_t slicePitch,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2DArray & rhs)', '    Image3D(const cl_mem & image3D)', '    Image3D', '    Image3D(const Image3D & image3D)', '    Image3D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t depth,::size_t row_pitch,::size_t slice_pitch,void *host_ptr,cl_int *err)', '    operator=(const Image3D & rhs)', '    operator=(const cl_mem & rhs)', '    getImageInfo(cl_image_info name,T *param)', '    getImageInfo(cl_int *err)', '    Image', '    Image(const cl_mem & image)', '    Image(const Image & image)', '    operator=(const Image & rhs)', '    operator=(const cl_mem & rhs)', '    ImageFormat', '    ImageFormat(cl_channel_order order,cl_channel_type type)', '    operator=(const ImageFormat & rhs)', '    ImageGL', '    ImageGL(const ImageGL & image)', '    ImageGL(const cl_mem & image)', '    ImageGL(const Context & context,cl_mem_flags flags,GLenum target,GLint miplevel,GLuint texobj,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const ImageGL & rhs)', '    getArgInfo(cl_uint argIndex,cl_kernel_arg_info name,T *param)', '    getArgInfo(cl_uint argIndex,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_kernel_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_kernel_work_group_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_int *err)', '    Kernel(const Kernel & kernel)', '    Kernel', '    Kernel(const cl_kernel & kernel)', '    Kernel(const Program & program,const char *name,cl_int *err)', '    operator=(const Kernel & rhs)', '    operator=(const cl_kernel & rhs)', '    setArg(cl_uint index,T value)', '    setArg(cl_uint index,::size_t size,void *argPtr)', '    ~Kernel', '    make_kernel(const Program & program,const STRING_CLASS name,cl_int *err)', '    make_kernel(const Kernel kernel)', '    getInfo(cl_mem_info name,T *param)', '    getInfo(cl_int *err)', '    Memory', '    Memory(const cl_mem & memory)', '    Memory(const Memory & memory)', '    operator=(const cl_mem & rhs)', '    operator=(const Memory & rhs)', '    setDestructorCallback(void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    ~Memory', '    dimensions', '    NDRange', '    NDRange(::size_t size0)', '    NDRange(::size_t size0,::size_t size1)', '    NDRange(::size_t size0,::size_t size1,::size_t size2)', '    operator const size_t *', '    getDevices(cl_device_type type,std::vector *devices)', '    getInfo(cl_int *err)', '    getInfo(cl_platform_info name,STRING_CLASS *param)', '    operator=(const cl_platform_id & rhs)', '    operator=(const Platform & rhs)', '    Platform(const cl_platform_id & platform)', '    Platform(const Platform & platform)', '    Platform', '    unloadCompiler', '    build(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    build(const std::vector & devices,const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    compile(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    createKernels(std::vector *kernels)', '    getBuildInfo(const Device & device,cl_int *err)', '    getBuildInfo(const Device & device,cl_program_build_info name,T *param)', '    getInfo(cl_program_info name,T *param)', '    getInfo(cl_int *err)', '    getInfo(cl_int *err)', '    operator=(const Program & rhs)', '    operator=(const cl_program & rhs)', '    Program(const Program & program)', '    Program(const cl_program & program)', '    Program(const Context & context,const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const STRING_CLASS & kernelNames,cl_int *err)', '    Program(const Context & context,const Sources & sources,cl_int *err)', '    Program', '    Program(const Context & context,const std::vector & devices,const Binaries & binaries,std::vector *binaryStatus,cl_int *err)', '    Program(const STRING_CLASS & source,bool build,cl_int *err)', '    getInfo(cl_sampler_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const Sampler & rhs)', '    operator=(const cl_sampler & rhs)', '    Sampler(const cl_sampler & sampler)', '    Sampler', '    Sampler(const Context & context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *err)', '    Sampler(const Sampler & sampler)', '    ~Sampler', '    operator const size_t *', '    operator size_t *', '    operator[](int index)', '    operator[](int index)', '    size_t', '    operator=(const UserEvent & rhs)', '    setStatus(cl_int status)', '    UserEvent', '    UserEvent(const Context & context,cl_int *err)', '    UserEvent(const UserEvent & event)', '    checked_array_iterator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl_ext.h', [], ['    clCreateSubDevicesEXT(cl_device_id,const cl_device_partition_property_ext *,cl_uint,cl_device_id *,cl_uint *)', '    clIcdGetPlatformIDsKHR(cl_uint,cl_platform_id *,cl_uint *)', '    clLogMessagesToStderrAPPLE(const char *,const void *,size_t,void *)', '    clLogMessagesToStdoutAPPLE(const char *,const void *,size_t,void *)', '    clLogMessagesToSystemLogAPPLE(const char *,const void *,size_t,void *)', '    clReleaseDeviceEXT(cl_device_id)', '    clRetainDeviceEXT(cl_device_id)', '    clSetMemObjectDestructorAPPLE(cl_mem,void (*) (cl_mem, void *),void *)', '    clTerminateContextKHR(cl_context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl_gl.h', [], ['    clCreateFromGLBuffer(cl_context context,cl_mem_flags flags,cl_GLuint bufobj,int *errcode_ret)', '    clCreateFromGLRenderbuffer(cl_context context,cl_mem_flags flags,cl_GLuint renderbuffer,cl_int *errcode_ret)', '    clCreateFromGLTexture(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture2D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture3D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clEnqueueAcquireGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReleaseGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clGetGLContextInfoKHR(const cl_context_properties *properties,cl_gl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetGLObjectInfo(cl_mem memobj,cl_gl_object_type *gl_object_type,cl_GLuint *gl_object_name)', '    clGetGLTextureInfo(cl_mem memobj,cl_gl_texture_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl_gl_ext.h', [], ['    clCreateEventFromGLsyncKHR(cl_context,cl_GLsync,cl_int *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\cl_platform.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\clamp-microkernel-tester.h', ['    ClampMicrokernelTester'], ['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_u8clamp_ukernel_function u8clamp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\clamp-operator-tester.h', ['    ClampOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testU8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\clamp.c', [], ['    pytorch_qnnp_create_clamp_nc_u8(size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *clamp_out)', '    pytorch_qnnp_setup_clamp_nc_u8(pytorch_qnnp_operator_t clamp,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\clamp.cc', [], ['    TEST(CLAMP_OP,zero_batch)', '    TEST(CLAMP_OP,unit_batch)', '    TEST(CLAMP_OP,unit_batch_with_qmin)', '    TEST(CLAMP_OP,unit_batch_with_qmax)', '    TEST(CLAMP_OP,small_batch)', '    TEST(CLAMP_OP,small_batch_with_input_stride)', '    TEST(CLAMP_OP,small_batch_with_output_stride)', '    TEST(CLAMP_OP,small_batch_with_input_and_output_stride)', '    TEST(CLAMP_OP,qmin_and_qmax_equal_uint8_max)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\cleanup_autograd_context_req.cpp', [], ['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextReq(int64_t context_id)', '    getContextId', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\cleanup_autograd_context_req.h', ['    CleanupAutogradContextReq'], ['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextReq(int64_t context_id)', '    getContextId', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\cleanup_autograd_context_resp.cpp', [], ['    fromMessage(const rpc::Message & message)', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\cleanup_autograd_context_resp.h', ['    CleanupAutogradContextResp'], ['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextResp', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\clear_undefinedness.cpp', [], ['    clearUndefinedness(Value *o)', '    clearUndefinedness(Block *block)', '    ClearUndefinedness(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\clear_undefinedness.h', [], ['    ClearUndefinedness(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\utils\\clip_grad.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\clip_op.cc', ['    GetClipGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUClip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Clip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ClipGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\clip_op.h', ['    final', '    final'], ['    ClipGradientOp(Args,...)', '    ClipOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\clip_tensor_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUClipTensorByScaling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ClipTensorByScaling']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\clip_tensor_op.h', ['    final'], ['    ClipTensorByScalingOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\deps\\clog\\src\\clog.c', [], ['    clog_vlog_debug(const char *module,const char *format,va_list args)', '    clog_vlog_error(const char *module,const char *format,va_list args)', '    clog_vlog_fatal(const char *module,const char *format,va_list args)', '    clog_vlog_info(const char *module,const char *format,va_list args)', '    clog_vlog_warning(const char *module,const char *format,va_list args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\deps\\clog\\test\\clog.cc', [], ['    named_log_debug(const char *format,...)', '    named_log_error(const char *format,...)', '    named_log_fatal(const char *format,...)', '    named_log_info(const char *format,...)', '    named_log_warning(const char *format,...)', '    nameless_log_debug(const char *format,...)', '    nameless_log_error(const char *format,...)', '    nameless_log_fatal(const char *format,...)', '    nameless_log_info(const char *format,...)', '    nameless_log_warning(const char *format,...)', '    suppressed_log_debug(const char *format,...)', '    suppressed_log_error(const char *format,...)', '    suppressed_log_fatal(const char *format,...)', '    suppressed_log_info(const char *format,...)', '    suppressed_log_warning(const char *format,...)', '    TEST(CLOG,debug)', '    TEST(CLOG,info)', '    TEST(CLOG,warning)', '    TEST(CLOG,error)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\deps\\clog\\include\\clog.h', [], ['    clog_vlog_debug(const char *module,const char *format,va_list args)', '    clog_vlog_error(const char *module,const char *format,va_list args)', '    clog_vlog_fatal(const char *module,const char *format,va_list args)', '    clog_vlog_info(const char *module,const char *format,va_list args)', '    clog_vlog_warning(const char *module,const char *format,va_list args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\cloneable.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\src\\main\\cpp\\cmake_macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\code_template.h', [], ['    format(const std::string & fmt,TemplateEnv & env)', '    keyIsString(const std::string & k)', '    s(const std::string & k)', '    v(const std::string & k)', '    charAt(size_t p)', '    CodeTemplate(std::string t)', '    emitCommaSeparatedList(std::ostream & out,const string_list & strings,bool comma_before,bool comma_after)', '    emitIndent(std::ostream & out,size_t indent)', '    emitLinesIndented(std::stringstream & out,size_t indent,const string_list & strings)', '    emitStringWithIndents(std::ostream & out,size_t indent,const std::string & str)', '    format(const TemplateEnv & env)', '    parseIdent(size_t pos,std::ostream & k)', '    parseKey(size_t pos,std::ostream & k,bool & comma_before,bool & comma_after)', '    TemplateEnv', '    TemplateEnv(TemplateEnv & parent)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\codegen.cpp', [], ['    calcScalarTypeName(const at::ScalarType type)', '    emitIndexingFor(std::ostream & out,const std::string & tensor,const int ndim,const bool last_is_cont)', '    encodeRHS(const Node *n)', '    encodeSpecialRHS(const Node *n,TemplateEnv & env)', '    scalarTypeName(const at::ScalarType type)', '    scalarValue(const int64_t v)', '    scalarValue(const bool v)', '    scalarValue(const double v)', '    typeCastedValueName(const std::shared_ptr & t,const at::ScalarType outtype,const std::string & vn)', '    valueName(const Value *n)', '    variableType(const std::shared_ptr & t)', '    generateKernel(const std::string & name,const Graph & graph,const std::vector,const c10::optional & inputs,const std::vector,const TensorDesc,const bool use_cuda)', '    RHSTemplate(const char *for_float)', '    RHSTemplate(const char *for_float,const char *for_double)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\codegen.cpp', [], ['    CreateCodeGen(const std::string & name,Stmt *stmt,const std::vector & params,at::Device device)', '    AddStmtFactoryMethod(const std::string & name,const StmtFactoryMethod & stmt_factory_method)', '    FindStmtFactoryMethod(const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\codegen.h', ['    RegisterCodeGen', '    RegisterCodeGenList', '    CodeGen', '    BufferArg', '    CallArg'], ['    CreateCodeGen(const std::string & name,Stmt *stmt,const std::vector & params,at::Device device)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    BytePtr', '    CharPtr', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    DoublePtr', '    FloatPtr', '    IntPtr', '    LongPtr', '    ShortPtr', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    GetInstance', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    RegisterCodeGen(const std::string & name)', '    AddStmtFactoryMethod(const std::string & name,const StmtFactoryMethod & stmt_factory_method)', '    FindStmtFactoryMethod(const std::string & name)', '    operator=', '    RegisterCodeGenList', '    RegisterCodeGenList', '    data', '    buffer_args', '    buffer_args', '    BufferArg(const Buffer & buffer)', '    BufferArg(Tensor *tensor)', '    BufferArg(const Function & func)', '    BufferArg(const VarHandle & var)', '    dtype', '    isVar', '    isVar_', '    var', '    call(const std::vector & args)', '    ByteData', '    CallArg(const PaddedBuffer & buffer)', '    CallArg(const std::vector & buffer)', '    CallArg(void *ptr)', '    CallArg(uint8_t v)', '    CallArg(int8_t v)', '    CallArg(int16_t v)', '    CallArg(int v)', '    CallArg(int64_t v)', '    CallArg(float v)', '    CallArg(double v)', '    CallArg((*) () decltype)', '    CallArg((*) () decltype)', '    CharData', '    data', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    DoubleData', '    FloatData', '    IntData', '    LongData', '    ShortData', '    CodeGen(Stmt *stmt,Ts,...)', '    CodeGen(Stmt *stmt,const std::vector & buffer_args,at::Device device)', '    device', '    stmt', '    ~CodeGen']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\codegen.h', [], ['    generateKernel(const std::string & name,const Graph & graph,const std::vector,const c10::optional & inputs,const std::vector,const TensorDesc,const bool use_cuda)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Col2Im.cpp', [], ['    col2im_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_cpu(const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_cpu(const Tensor & input,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms\\collate.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\collect_and_distribute_fpn_rpn_proposals_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCollectAndDistributeFpnRpnProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUCollectRpnProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUDistributeFpnProposals', '    schema_OperatorName', '    schema_OperatorName', '    schema_OperatorName', '    ArgSort(EArrXi & arr)', '    BoxesArea(const ERArrXXf & boxes,const bool legacy_plus_one)', '    MapRoIsToFpnLevels(Eigen::Ref rois,const float k_min,const float k_max,const float s0,const float lvl0,const bool legacy_plus_one)', '    RowsWhereRoILevelEquals(Eigen::Ref rois,const ERArrXXf & lvls,const int lvl,ERArrXXf *out_filtered,EArrXi *out_indices)', '    SortAndLimitRoIsByScores(Eigen::Ref scores,int n,ERArrXXf & rois)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectAndDistributeFpnRpnProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectRpnProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DistributeFpnProposals', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\collect_and_distribute_fpn_rpn_proposals_op.h', ['    final', '    final', '    final'], ['    schema_CollectAndDistributeFpnRpnProposals', '    schema_CollectRpnProposals', '    schema_DistributeFpnProposals', '    BoxesArea(const ERArrXXf & boxes,const bool legacy_plus_one)', '    MapRoIsToFpnLevels(Eigen::Ref rois,const float k_min,const float k_max,const float s0,const float lvl0,const bool legacy_plus_one)', '    RowsWhereRoILevelEquals(Eigen::Ref rois,const ERArrXXf & lvls,const int lvl,ERArrXXf *out_filtered,EArrXi *out_indices)', '    SortAndLimitRoIsByScores(Eigen::Ref scores,int n,ERArrXXf & rois)', '    CollectAndDistributeFpnRpnProposalsOp(Args,...)', '    CollectRpnProposalsOp(Args,...)', '    DistributeFpnProposalsOp(Args,...)', '    legacy_plus_one_', '    legacy_plus_one_', '    roi_canonical_level_', '    roi_canonical_level_', '    roi_canonical_scale_', '    roi_canonical_scale_', '    roi_max_level_', '    roi_max_level_', '    roi_min_level_', '    roi_min_level_', '    rpn_max_level_', '    rpn_max_level_', '    rpn_min_level_', '    rpn_min_level_', '    rpn_post_nms_topN_', '    rpn_post_nms_topN_', '    RunOnDevice', '    ~CollectAndDistributeFpnRpnProposalsOp', '    ~CollectRpnProposalsOp', '    ~DistributeFpnProposalsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\comm.cpp', [], ['    apply(variable_list)', '    Gather(const at::Device & destination_device,int64_t dim)', '    ~Gather', '    apply(variable_list)', '    Scatter(std::vector devices,const c10::optional,int64_t dim,const c10::optional,bool unsqueeze_scalars)', '    ~Scatter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\comm.cpp', [], ['    broadcast(const Tensor & tensor,IntArrayRef devices)', '    broadcast_coalesced(TensorList tensors,IntArrayRef devices,size_t buffer_size)', '    gather(at::TensorList tensors,int64_t dim,c10::optional destination_index)', '    scatter(const at::Tensor & tensor,at::IntArrayRef devices,const c10::optional,int64_t dim,const c10::optional)', '    show(const at::DeprecatedTypeProperties & t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\comm.cpp', ['    BroadcastWork'], ['    broadcast_coalesced(std::shared_ptr process_group,at::TensorList tensors,size_t buffer_size)', '    BroadcastWork(const std::shared_ptr & process_group,std::vector bucket_tensors)', '    finish']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\comm.h', [], ['    apply(variable_list)', '    Gather(const at::Device & destination_device,int64_t dim)', '    ~Gather', '    apply(variable_list)', '    Scatter(std::vector devices,const c10::optional,int64_t dim,const c10::optional,bool unsqueeze_scalars)', '    ~Scatter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\comm.h', [], ['    broadcast_coalesced(std::shared_ptr process_group,at::TensorList tensors,size_t buffer_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\comm.h', [], ['    broadcast(const at::Tensor & tensor,at::IntArrayRef devices)', '    broadcast_coalesced(at::TensorList tensors,at::IntArrayRef devices,size_t buffer_size)', '    gather(at::TensorList tensors,int64_t dim,c10::optional destination_index)', '    scatter(const at::Tensor & tensor,at::IntArrayRef devices,const c10::optional,int64_t dim,const c10::optional)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\common.cc', [], ['    createDevice(const createDeviceAttr attr)', '    signalFailure(Blob *status_blob,std::exception &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common.cc', [], ['    g_caffe2_has_cuda_linked', '    g_caffe2_has_hip_linked', '    GetBuildOptions', '    HasCudaRuntime', '    HasHipRuntime', '    SetCudaRuntimeFlag', '    SetHipRuntimeFlag']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\common.cc', ['    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp', '    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp_denorms'], ['    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp(const std::string & content)', '    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp_denorms(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\common.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common.h', ['    SkipIndices', '    SkipIndices'], ['    dynamic_cast_if_rtti(Src ptr)', '    GetBuildOptions', '    HasCudaRuntime', '    HasHipRuntime', '    SetCudaRuntimeFlag', '    SetHipRuntimeFlag', '    Contains(const int)', '    Contains(const int i)', '    ContainsInternal(const int i)', '    ContainsInternal(const int i)', '    unique_ptr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\common.h', [], ['    createDevice(const createDeviceAttr attr)', '    signalFailure(Blob *status_blob,std::exception &)', '    getInputs', '    getOutput', '    getOutputs', '    IsType', '    operator==(GlooParameters const & other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Support\\Common.h', ['    Notifier', '    StorageType', '    StorageType'], ['    deleteCallback(std::list & callbackList,Callback *toDelete)', '    deleteDestructorCallback(Callback *c)', '    deleteNotificationCallback(Callback *c)', '    Notifier', '    notify', '    registerDestructorCallback(Callback fn)', '    registerNotificationCallback(Callback fn)', '    ~Notifier', '    data', '    mutableData', '    resetData(T)', '    StorageType(T)', '    StorageType', '    StorageType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\common.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\common.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Common.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THCUNN\\common.h', [], ['    GET_BLOCKS(const int N)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\common_avx.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\common_avx2.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\common_avx512.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_cudnn.cc', [], ['    PrintCuDNNInfo(int *,char ***)', '    cudnn_states']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_cudnn.h', ['    cudnnFilterDescWrapper', '    cudnnTensorDescWrapper', '    cudnnTypeWrapper', '    cudnnTypeWrapper', '    cudnnTypeWrapper'], ['    CheckCuDNNVersions', '    cudnnCompiledVersion', '    cudnnRuntimeVersion', '    GetCudnnTensorFormat(const StorageOrder & order)', '    cudnnGetErrorString(cudnnStatus_t status)', '    static_assert(CUDNN_VERSION,)', '    kOne', '    kOne', '    kOne', '    kZero', '    kZero', '    kZero', '    cudnnFilterDescWrapper', '    cudnnFilterDescWrapper', '    Descriptor(const StorageOrder & order,const cudnnDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    operator=', '    ~cudnnFilterDescWrapper', '    cudnnTensorDescWrapper', '    cudnnTensorDescWrapper', '    Descriptor(const cudnnTensorFormat_t format,const cudnnDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    operator=', '    ~cudnnTensorDescWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_gpu.cc', ['    CudaRuntimeFlagFlipper'], ['    CaffeCudaGetDevice', '    CaffeCudaSetDevice(const int id)', '    cublasGetErrorString(cublasStatus_t error)', '    curandGetErrorString(curandStatus_t error)', '    DeviceQuery(const int device)', '    GetCudaPeerAccessPattern(vector *pattern)', '    GetDefaultGPUID', '    GetDeviceProperty(const int deviceid)', '    GetGPUIDForPointer(const void *ptr)', '    NumCudaDevices', '    SetDefaultGPUID(const int deviceid)', '    TensorCoreAvailable', '    CudaDevicePropWrapper', '    CudaRuntimeFlagFlipper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_gpu.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\hip\\common_miopen.h', ['    miopenTensorDescWrapper', '    miopenTypeWrapper', '    miopenTypeWrapper'], ['    CheckMIOPENVersions', '    miopenGetErrorString(miopenStatus_t status)', '    miopenCompiledVersion', '    miopenRuntimeVersion', '    kOne', '    kOne', '    kZero', '    kZero', '    Descriptor(const miopenDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    miopenTensorDescWrapper', '    miopenTensorDescWrapper', '    operator=', '    ~miopenTensorDescWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_omp.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\cuda_rtc\\common_rtc.h', ['    CudaRTCFunction'], ['    GetUniqueName', '    Compile(Args,...)', '    CudaRTCFunction', '    Launch(unsigned int gx,unsigned int gy,unsigned int gz,unsigned int bx,unsigned int by,unsigned int bz,unsigned int shared_mem,cudaStream_t stream,Args,...)', '    LaunchEx(unsigned int gx,unsigned int gy,unsigned int gz,unsigned int bx,unsigned int by,unsigned int bz,unsigned int shared_mem,cudaStream_t stream,void **extra)', '    ~CudaRTCFunction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\common_subexpression_elimination.cc', [], ['    are_nodes_common(const Graph & g,int model_idx,int candidate_idx)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\common_subexpression_elimination.cpp', [], ['    EliminateCommonSubexpression(const std::shared_ptr & graph)', '    EliminateCommonSubexpression(Block *block,const AliasDb & aliasDb,std::function parent_lookup_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\common_subexpression_elimination.h', [], ['    EliminateCommonSubexpression(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\common_subexpression_elimination.h', ['    CommonSubexpressionEliminationTransform'], ['    CommonSubexpressionEliminationTransform', '    IsWhitelisted(string op_type)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\common_subexpression_elimination_test.cc', [], ['    TEST(CommonSubexpressionEliminationTest,TestSimple)', '    TEST(CommonSubexpressionEliminationTest,TestFromExternal)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\common_test.cc', [], ['    TEST(CommonTest,TestStoi)', '    TEST(CommonTest,TestStod)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\common_world_ops.cc', [], ['    initializeForContext']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\common_world_ops.h', ['    final', '    final', '    final'], ['    initializeForContext', '    CloneCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    DestroyCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    handleException(std::exception & ex)', '    RunOnDevice', '    RunOnDevice', '    ~CloneCommonWorld', '    CreateCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    handleException(std::exception & ex)', '    initialize', '    initializeForContext', '    rendezvousWithMPI', '    rendezvousWithStore(const std::unique_ptr & handler)', '    RunOnDevice', '    ~CreateCommonWorld', '    what', '    milliseconds']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\common_world_ops_gpu.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\communicator_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CPUAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUBarrier', '    CAFFE_ANONYMOUS_VARIABLE_CPUBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CPUCloneCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUDestroyCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceScatter', '    CAFFE_ANONYMOUS_VARIABLE_CPUSendTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Allgather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Allreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Barrier', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Broadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloneCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DestroyCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReceiveTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceScatter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SendTensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\communicator_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CUDAAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDABroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDACloneCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDAReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CUDAReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDASendTensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\compilation_unit.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\compiler.cpp', [], ['    fusion_backends_lock_', '    debug_fusion', '    getFusionBackends', '    getInputDependencies(const Value *output)', '    next_kernel_id', '    setInputBroadcastGroups(KernelSpec & spec)', '    setInputChunkDescriptors(KernelSpec & spec)', '    upfrontCompilation(KernelSpec & spec)', '    usedInFusedChunk(const Value *input)', '    fusionBackendLock', '    queue', '    compileKernel(const KernelSpec & spec,const ArgSpec & arg_spec,const std::vector & map_size,const at::Device device)', '    debugFuser', '    getConstructor(at::Device::Type backend_type)', '    hasFusionBackend(at::Device::Type backend_type)', '    nCompiledKernels', '    registerFusion(const Node *fusion_group)', '    registerFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\compiler.h', [], ['    compileKernel(const KernelSpec & spec,const ArgSpec & arg_spec,const std::vector & map_size,const at::Device device)', '    debugFuser', '    hasFusionBackend(at::Device::Type backend_type)', '    nCompiledKernels', '    registerFusion(const Node *fusion_group)', '    registerFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)', '    RegisterFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Representations\\Compiler.h', ['    Branch', '    Data', '    Instruction', '    Opcode', '    Phi', '    Return', '    Terminator', '    Value', '    ValueKind'], ['    classof(const Value *V)', '    classof(const Value *V)', '    classof(const Value *V)', '    isTerminator(const Opcode & op)', '    Branch', '    Data', '    getVersion', '    setVersion(size_t version)', '    ~Data', '    getOpcode', '    Instruction', '    Instruction(Opcode op)', '    ~Instruction', '    Phi', '    Return', '    Terminator(Instruction::Opcode op)', '    getKind', '    Value(ValueKind K)', '    Value', '    ~Value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Complex.h', ['    numeric_limits'], ['    operator*(const std::complex & a,const iT & b)', '    operator*(const iT & a,const std::complex & b)', '    operator+(const std::complex & a,const iT & b)', '    operator+(const iT & a,const std::complex & b)', '    operator-(const std::complex & a,const iT & b)', '    operator-(const iT & a,const std::complex & b)', '    operator/(const std::complex & a,const iT & b)', '    operator/(const iT & a,const std::complex & b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\complex_test.cpp', [], ['    TestBinaryOpsForAllIntTypes(T real,T img,int8_t i)', '    TestBinaryOpsForIntType(T real,T img,int_t num)', '    TEST(ComplexTest,Integer)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ComplexHelper.h', [], ['    computeStrideForComplex(IntArrayRef oldstride)', '    view_complex_as_float(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\concat_cpu.cc', [], ['    concat_op_cpu_impl(c10::List inputs,const at::Tensor & output_,const at::Tensor & split_,int64_t axis,int64_t add_axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\concat_dnnlowp_op.cc', [], ['    ConcatDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\concat_dnnlowp_op.h', ['    final'], ['    ConcatDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\concat_elim.cc', ['    ConcatAddMulNaNClipElim', '    ConcatElim', '    GatherFuse8BitRowwiseQuantFloatMulLengthsSumElim'], ['    concatAddMulNaNClipElim(NNModule *nn)', '    concatElim(NNModule *nn)', '    gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim(NNModule *nn)', '    run', '    run', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\concat_elim.h', [], ['    concatAddMulNaNClipElim(NNModule *nn)', '    concatElim(NNModule *nn)', '    gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim(NNModule *nn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\concat_elim_test.cc', [], ['    lut_dims', '    TEST(gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim,Basic)', '    TEST(gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim,NoFuse)', '    TEST(ConcatElim,BasicNet)', '    TEST(ConcatElim,ProdNet)', '    TEST(ConcatAddMulNaNClipElim,BasicNet)', '    TEST(ConcatAddMulNaNClipElim,ProdNet)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\concat_split_op.cc', ['    GetConcatGradient', '    GetSplitGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConcat', '    CAFFE_ANONYMOUS_VARIABLE_CPUDepthConcat', '    CAFFE_ANONYMOUS_VARIABLE_CPUDepthSplit', '    CAFFE_ANONYMOUS_VARIABLE_CPUSplit', '    CAFFE_ANONYMOUS_VARIABLE_CPUSplitByLengths', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Concat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DepthConcat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DepthSplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Split', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SplitByLengths', '    CostInferenceForConcat(const OperatorDef & def,const vector & in)', '    ret_invalid_shape', '    TensorInferenceForConcat(const OperatorDef & def,const vector & in)', '    TensorInferenceForSplit(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\concat_split_op.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\concat_split_op.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\concat_split_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAConcat', '    CAFFE_ANONYMOUS_VARIABLE_CUDADepthConcat', '    CAFFE_ANONYMOUS_VARIABLE_CUDADepthSplit', '    CAFFE_ANONYMOUS_VARIABLE_CUDASplit', '    CAFFE_ANONYMOUS_VARIABLE_CUDASplitByLengths']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\concrete_module_type.cpp', [], ['    operator==(const ConcreteModuleTypeBuilder::ModuleInfo & lhs,const ConcreteModuleTypeBuilder::ModuleInfo & rhs)', '    fromJitType(TypePtr type)', '    dump', '    findBuiltinFunction(const std::string & name)', '    findFailedAttribute(const std::string & name)', '    findFunctionAttribute(const std::string & name)', '    findSubmoduleConcreteType(const std::string & name)', '    getConstantsPy', '    getIterableModuleKind', '    addAttribute(std::string name,TypePtr type,bool isParameter)', '    addBuiltinFunction(std::string name,std::string symbol_name)', '    addConstant(std::string name,py::object value)', '    addFailedAttribute(std::string name,std::string failureReason)', '    addFunctionAttribute(std::string name,const TypePtr & type,py::object pyFunction)', '    addModule(std::string name,std::shared_ptr meta)', '    addOverload(std::string methodName,std::vector overloadedMethodNames)', '    setIterableModuleKind(IterableModuleKind kind)', '    setPoisoned', '    ConcreteModuleType(ConcreteModuleTypeBuilder data)', '    getJitType', '    getPyClass', '    createTypeFromThis', '    equals(const ConcreteModuleTypeBuilder & other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\concrete_module_type.h', ['    ConcreteModuleType', '    ConcreteModuleTypeBuilder', '    IterableModuleKind'], ['    operator==(const Constant & lhs,const Constant & rhs)', '    operator==(const FunctionAttribute & lhs,const FunctionAttribute & rhs)', '    operator==(const Attribute & lhs,const Attribute & rhs)', '    fromJitType(TypePtr type)', '    ConcreteModuleType(ConcreteModuleTypeBuilder data)', '    ConcreteModuleType', '    dump', '    equals(const ConcreteModuleType & other)', '    equals(const ConcreteModuleTypeBuilder & other)', '    findBuiltinFunction(const std::string & name)', '    findFailedAttribute(const std::string & name)', '    findFunctionAttribute(const std::string & name)', '    findSubmoduleConcreteType(const std::string & name)', '    getConstantsPy', '    getIterableModuleKind', '    getJitType', '    getPyClass', '    addAttribute(std::string name,TypePtr type,bool isParameter)', '    addBuiltinFunction(std::string name,std::string symbol_name)', '    addConstant(std::string name,py::object value)', '    addFailedAttribute(std::string name,std::string failureReason)', '    addFunctionAttribute(std::string name,const TypePtr & type,py::object pyFunction)', '    addModule(std::string name,std::shared_ptr meta)', '    addOverload(std::string methodName,std::vector overloadedMethodNames)', '    Attribute(TypePtr type,bool isParam)', '    build', '    ConcreteModuleTypeBuilder(py::object pyClass)', '    ConcreteModuleTypeBuilder', '    Constant(py::object v)', '    createTypeFromThis', '    equals(const ConcreteModuleTypeBuilder & other)', '    ModuleInfo(std::string name,std::shared_ptr meta)', '    setIterableModuleKind(IterableModuleKind kind)', '    setPoisoned']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conditional_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConditional', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conditional', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conditional_op.h', ['    final'], ['    ConditionalOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp', [], ['    areNodeInputsConstant(Node *node,const ValueToParamPairMap & valsToParamsMap)', '    buildParamsMapFromValueToParamsMap(const ValueToParamPairMap & valsToParamsMap,ParamMap & paramsDict)', '    ConstantFoldONNX(Block *b,ParamMap & paramsDict,int opset_version)', '    eraseUnusedBlockInputs(Block *b)', '    getOnnxConstParentsToRemove(Node *node)', '    getValues(Node *node,const ValueToParamPairMap & valsToParamsMap)', '    handleNegativeStartEndIndex(int64_t & start,int64_t & end,int64_t & axis,c10::IntArrayRef tensorSizes)', '    isConstant(Value *val,const ValueToParamPairMap & valsToParamsMap)', '    runTorchBackendForOnnx(const Node *node,std::vector & inputTensorValues,int opset_version)', '    runTorchSlice_opset10(const Node *node,std::vector & inputTensorValues)', '    runTorchSlice_opset9(const Node *node,std::vector & inputTensorValues)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.h', [], ['    ConstantFoldONNX(Block *b,std::map & paramDict,int opset_version)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\constant_pooling.cpp', [], ['    ConstantPooling(const std::shared_ptr & graph)', '    ConstantPooling(Block *block,std::unordered_set & constants,const AliasDb & aliasDb)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\constant_pooling.h', [], ['    ConstantPooling(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\constant_propagation.cpp', [], ['    ConstantPropagation(std::shared_ptr & graph)', '    ConstantPropagationImmutableTypes(std::shared_ptr & graph)', '    NoAliasDb(std::shared_ptr graph)', '    WithAliasDb(std::shared_ptr graph)', '    ConstantPropagation(at::ArrayRef blocks)', '    ConstantPropagation(Node *n)', '    ConstantPropagation(Block *block)', '    ConstantPropagator(std::shared_ptr graph,bool aliasing_types)', '    inlineIf(Node *n)', '    inlineIfBody(Block *body)', '    loopWillNotRun(Node *node)', '    noMutableValues(at::ArrayRef values)', '    propagateNode(Node *n)', '    removeExtraIfOutputs(Node *n)', '    removeExtraLoopOutputs(Node *node)', '    removeLoopNode(Node *n)', '    replaceAndRemoveIfOutput(Node *n,size_t i,Value *replacement)', '    run', '    runnableInputs(Node *n)', '    supportedNode(Node *n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\constant_propagation.h', [], ['    ConstantPropagation(std::shared_ptr & graph)', '    ConstantPropagationImmutableTypes(std::shared_ptr & graph)', '    runNodeIfInputsAreConstant(const Node *node)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ConstantPadNd.cpp', [], ['    constant_pad_nd(const Tensor & self,IntArrayRef pad,Scalar value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\constants.cpp', [], ['    aliasAnalysisInternalSpecialCase', '    insertableIValue(const IValue & ivalue)', '    insertableTensor(const at::Tensor & ten)', '    insertConstant(Graph & g,const IValue & val,c10::optional loc,c10::optional scope)', '    toIValue(const Value *v)', '    tryInsertConstant(Graph & g,const IValue & val,c10::optional loc,c10::optional scope)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\constants.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\torch_ops\\constants.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\ConstexprCrc.h', [], ['    crc64(c10::string_view str)', '    crc64(const char *str,size_t size)', '    crc64impl(uint64_t accumulator,const char *data,size_t size)', '    checksum', '    crc64_t(uint64_t checksum)', '    underlyingId', '    operator()(c10::util::crc64_t x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\ConstexprCrc_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\context\\container.cpp', [], ['    currentContextId', '    forceCurrentContextId(int64_t contextId)', '    getInstance', '    getInstanceInternal', '    init(int64_t worker_id)', '    setCurrentContextId(int64_t contextId)', '    clearCurrentContext', '    currentContext', '    DistAutogradContainer', '    eraseContextIdAndReset(int64_t context_id)', '    getMaxId', '    getOrCreateContext(int64_t context_id)', '    getWorkerId', '    hasValidContext', '    isValidContext(int64_t context_id)', '    newAutogradMessageId', '    newContext', '    numAutogradContexts', '    releaseContext(int64_t context_id)', '    releaseContextIfPresent(int64_t context_id)', '    retrieveContext(int64_t context_id)', '    sendReleaseContextRpc(int64_t context_id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\context\\container.h', ['    DistAutogradContainer'], ['    currentContextId', '    forceCurrentContextId(int64_t contextId)', '    getInstance', '    getInstanceInternal', '    init(int64_t worker_id)', '    setCurrentContextId(int64_t contextId)', '    clearCurrentContext', '    currentContext', '    DistAutogradContainer', '    DistAutogradContainer', '    DistAutogradContainer', '    eraseContextIdAndReset(int64_t context_id)', '    getMaxId', '    getOrCreateContext(int64_t context_id)', '    getWorkerId', '    hasValidContext', '    isValidContext(int64_t context_id)', '    newAutogradMessageId', '    newContext', '    numAutogradContexts', '    operator=', '    operator=', '    releaseContext(int64_t context_id)', '    releaseContextIfPresent(int64_t context_id)', '    retrieveContext(int64_t context_id)', '    sendReleaseContextRpc(int64_t context_id)', '    ~DistAutogradContainer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\context.cc', [], ['    noexcept', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context.cc', [], ['    CopyBytesImpl(size_t nbytes,const void *src,void *dst)', '    CopyBytesWrapper(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device)', '    RandomNumberSeed', '    CopyBytesSameDevice(size_t nbytes,const void *src,void *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\opencl\\context.cc', [], ['    EventCreateOPENCL(const DeviceOption &,Event *)', '    EventFinishOPENCL(const Event *)', '    EventRecordOPENCL(Event *,const void *,const char *)', '    EventResetOPENCL(Event *)', '    EventWaitOPENCL(const Event *,void *)', '    noexcept', '    getInstance', '    OpenCLContextSingleton', '    BuildArgumentList(std::vector,std::string)', '    BuildKernel(const char *src,std::string additional_options,const char *fn_name)', '    Delete(void *ptr)', '    GetSingleton', '    New(size_t nbytes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Context.cpp', [], ['    supported_qengines', '    getCPUAllocator', '    globalContext', '    benchmarkCuDNN', '    Context', '    deterministicCuDNN', '    hasLAPACK', '    hasMKL', '    hasMKLDNN', '    hasOpenMP', '    isXNNPACKAvailable', '    qEngine', '    setBenchmarkCuDNN(bool b)', '    setDeterministicCuDNN(bool b)', '    setFlushDenormal(bool on)', '    setQEngine(at::QEngine e)', '    setUserEnabledCuDNN(bool e)', '    setUserEnabledMkldnn(bool e)', '    supportedQEngines', '    userEnabledCuDNN', '    userEnabledMkldnn', '    initCPU', '    initCUDA', '    initHIP', '    LegacyDeviceTypeInit(LegacyDeviceTypeInitArgs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\context\\context.cpp', [], ['    accumulateGrad(const torch::autograd::Variable & variable,const torch::Tensor & grad,size_t num_expected_refs)', '    addOutstandingRpc(const std::shared_ptr & futureMessage)', '    clearAndWaitForOutstandingRpcsAsync', '    clearOutstandingRpcs', '    getGradients', '    resetGraphTask', '    retrieveGraphTask', '    retrieveSendFunction(int64_t autograd_message_id)', '    setGraphTask(std::shared_ptr graphTask)', '    alreadySentError', '    State(int32_t count)', '    addKnownWorkerId(const rpc::worker_id_t workerId)', '    addRecvFunction(std::shared_ptr & func,int64_t autograd_message_id)', '    addSendFunction(const std::shared_ptr & func,int64_t autograd_message_id)', '    contextId', '    DistAutogradContext(int64_t contextId)', '    getKnownWorkerIds']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context.h', ['    final'], ['    GetDeviceType', '    HasAsyncPartDefault', '    IsStreamFree(const DeviceOption &,int)', '    SupportsAsyncScheduling', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyItems(const TypeMeta & meta,size_t n,const void *src,void *dst)', '    device', '    device_type', '    random_seed_', '    random_seed_set_', '    RandomNumberSeed', '    size_t', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    CPUContext', '    CPUContext(const DeviceOption & option)', '    CPUContext(const at::Device & device)', '    FinishDeviceComputation', '    RandGenerator', '    Record(Event *ev,const char *err_msg)', '    SwitchToDevice(int)', '    WaitEvent(const Event & ev)', '    ~CPUContext', '    CopyBytes(size_t nbytes,const void *src,void *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Context.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\context.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\context\\context.h', ['    DistAutogradContext'], ['    accumulateGrad(const torch::autograd::Variable & variable,const torch::Tensor & grad,size_t num_expected_refs)', '    addKnownWorkerId(const rpc::worker_id_t workerId)', '    addOutstandingRpc(const std::shared_ptr & futureMessage)', '    addRecvFunction(std::shared_ptr & func,int64_t autograd_message_id)', '    addSendFunction(const std::shared_ptr & func,int64_t autograd_message_id)', '    clearAndWaitForOutstandingRpcsAsync', '    clearOutstandingRpcs', '    contextId', '    DistAutogradContext(int64_t contextId)', '    DistAutogradContext', '    DistAutogradContext', '    getGradients', '    getKnownWorkerIds', '    operator=', '    operator=', '    resetGraphTask', '    retrieveGraphTask', '    retrieveSendFunction(int64_t autograd_message_id)', '    setGraphTask(std::shared_ptr graphTask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\opencl\\context.h', ['    final'], ['    BuildArgumentList(std::vector,std::string)', '    GetSingleton', '    IsStreamFree(const DeviceOption &,int)', '    BuildKernel(const char *src,std::string additional_options,const char *fn_name)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    CopyBytes(n *meta,src,dst)', '    FinishDeviceComputation', '    HasAsyncPartDefault', '    Record(Event *ev,const char *&)', '    SupportsAsyncScheduling', '    SwitchToDevice(int a,...)', '    SwitchToDevice', '    WaitEvent(const Event & ev)', '    getInstance', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(n *,,)', '    OpenCLContext', '    OpenCLContext(const DeviceOption & option)', '    ~OpenCLContext', '    OpenCLContextSingleton', '    OpenCLContextSingleton', '    OpenCLContextSingleton']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context_base.cc', [], ['    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context_base.h', ['    BaseContext'], ['    CreateContext(const at::Device & device)', '    RegistryName', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesSameDevice(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyFromCPU(size_t n,const T *src,T *dst)', '    CopyItemsFromCPU(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopyItemsSameDevice(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopyItemsToCPU(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopySameDevice(size_t n,const T *src,T *dst)', '    CopyToCPU(size_t n,const T *src,T *dst)', '    device', '    device_type', '    EnforceMetaCopyOK', '    FinishDeviceComputation', '    Record(caffe2::Event *ev,const char *err_msg)', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    WaitEvent(const caffe2::Event & ev)', '    ~BaseContext', '    ContextRegistry']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context_gpu.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context_gpu_test.cc', [], ['    getStreamForHandle(cublasHandle_t handle)', '    TEST(CUDATest,HasCudaRuntime)', '    TEST(CUDAContextTest,TestAllocDealloc)', '    TEST(CUDAContextTest,TestSetGetDeviceWithoutCaffeMode)', '    TEST(CUDAContextTest,MemoryPoolAllocateDealloc)', '    TEST(CUDAContextTest,TestSameThreadSameObject)', '    TEST(CUDAContextTest,TestSameThreadTempObject)', '    TEST(CUDAContextTest,TestSameThreadDifferntObjectIfDifferentDevices)', '    TEST(CUDAContextTest,TestDifferntThreadDifferentobject)', '    TEST_GetStreamAddress(cudaStream_t *ptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\opencl\\context_test.cc', [], ['    TEST(ContextTest,BasicInit)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\context_test.cc', [], ['    TEST(CPUContextTest,TestAllocAlignment)', '    TEST(CPUContextTest,TestAllocDealloc)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Representations\\ControlFlow.h', ['    ControlFlowGraph', '    BasicBlock'], ['    deleteNode(ControlFlowGraph *cfg,G::NodeRef node)', '    ControlFlowGraph', '    ControlFlowGraph', '    ControlFlowGraph', '    createAnonymousFunction', '    createNamedFunction(std::string name)', '    createNode', '    operator=', '    ~ControlFlowGraph', '    BasicBlock', '    BasicBlock', '    BasicBlock', '    deleteInstruction(NodeRef instr)', '    getInstructions', '    getMutableInstructions', '    hasInstruction(NodeRef instr)', '    insertInstructionBefore(NodeRef newInstr,NodeRef instr)', '    moveInstructionBefore(NodeRef instr1,NodeRef instr2)', '    operator=', '    pushInstructionNode(NodeRef node)', '    trackNode(NodeRef node)', '    untrackNode(NodeRef node)', '    ~BasicBlock', '    static_assert(,)', '    remove']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\conv-prepack.cc', [], ['    PrePackConvWeights(const conv_param_t & conv_p,const uint8_t *kernel,const int32_t *bias)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\conv-run.cc', [], ['    compute_dwconv_multiipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_dwconv_unipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_output_dimension(size_t padded_input_dim,size_t kernel_dimension,size_t dilation_dimension,size_t subsampling_dimension)', '    compute_q8conv(const struct q8conv_context [1] context,size_t group_index,size_t image_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t image_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm_xzp(const struct q8gemm_xzp_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_sum_rows(const struct q8sum_rows_context [1] context,size_t group_index,size_t batch_index,size_t block_start,size_t group_range,size_t batch_range,size_t block_size)', '    convolution', '    qnnpackConv(const conv_param_t & conv_p,void *packed_weights,const size_t batch_size,const size_t input_height,const size_t input_width,const float input_scale,const uint8_t input_zero_point,const uint8_t *input,const float output_scale,const uint8_t output_zero_point,uint8_t *output,pthreadpool_t threadpool)', '    operator()(pytorch_qnnp_operator_t op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\conv.cpp', [], ['    _get_pad_mode_from_conv_padding_mode(torch::nn::detail::conv_padding_mode_t conv_padding_mode)', '    Conv1dImpl(Conv1dOptions options_)', '    forward(const Tensor & input)', '    _conv_forward(const Tensor & input,const Tensor & weight)', '    Conv2dImpl(Conv2dOptions options_)', '    forward(const Tensor & input)', '    Conv3dImpl(Conv3dOptions options_)', '    forward(const Tensor & input)', '    ConvTranspose1dImpl(ConvTranspose1dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    ConvTranspose2dImpl(ConvTranspose2dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    ConvTranspose3dImpl(ConvTranspose3dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    _output_padding(const Tensor & input,const c10::optional & output_size,const ExpandingArray & stride,const ExpandingArray & padding,const ExpandingArray & kernel_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\Conv.cpp', ['    AlgoIterator'], ['    check_args(CheckedFrom,IntArrayRef args,size_t expected_size,const char *arg_name)', '    convolution_shape_check(CheckedFrom c,const TensorGeometryArg & input,const TensorGeometryArg & weight,const TensorGeometryArg & output,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    split_batch_dim_to_32bit_out(const at::Tensor & output,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,int64_t max_worksize,func_t func_32bit)', '    args', '    args', '    args', '    cudnn_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    cudnn_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_forward(CheckedFrom c,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    allocate_workspace(size_t size,const Tensor & other)', '    cudnn_convolution(const Tensor & input_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_deprecated(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    cudnn_convolution_transpose_backward_input(const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_deprecated(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    getMaxWorkspaceSize(const ConvolutionArgs & args,const algo_t *algo,int n_algo)', '    getValidAlgorithms(perf_t *perfResults,const ConvolutionArgs & args,int n_algo)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdDataAlgo_t algo,size_t *sz)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdFilterAlgo_t algo,size_t *sz)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionFwdAlgo_t algo,size_t *sz)', '    narrowGroup(const Tensor & t,int dim,int group_idx,int64_t groups)', '    raw_cudnn_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_forward_out_32bit(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    setConvolutionParams(ConvolutionParams *params,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool deterministic)', '    raw_cudnn_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_backward_input_out_32bit(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose(const Tensor & input_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    grad_input', '    grad_output', '    grad_output', '    grad_output_contig', '    grad_weight', '    input', '    input', '    input', '    output', '    raw_cudnn_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_backward_weight_out_32bit(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    onlyDefaultAlgorithm(const ConvolutionArgs & args)', '    cache', '    cache', '    cache', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdDataAlgo_t algo,size_t *workspaceSize)', '    getWorkspaceSize(const ConvolutionArgs & args,algo_t algo,size_t *workspaceSize)', '    getWorkspaceSize(const ConvolutionArgs & args,algo_t algo,size_t *workspaceSize)', '    AlgoIterator(const ConvolutionArgs & args,bool benchmark)', '    try_all(std::function f)', '    find(const ConvolutionParams & params,T *results)', '    insert(const ConvolutionParams & params,const T & results)', '    ConvolutionArgs(const Tensor & input,const Tensor & output,const Tensor & weight)', '    Workspace(size_t size)', '    ~Workspace']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\conv.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Conv.cpp', [], ['    _mkldnn_conv2d(const ideep::tensor & x,const ideep::tensor & w,const c10::optional & b,at::IntArrayRef padding,at::IntArrayRef stride,at::IntArrayRef dilation,int64_t groups)', '    get_mkldnn_tensor(const at::Tensor & tensor)', '    mkldnn_bias', '    mkldnn_convolution(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    mkldnn_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,std::array output_mask)', '    mkldnn_convolution_backward_input(IntArrayRef input_size,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool bias_defined)', '    mkldnn_convolution_backward_weights(IntArrayRef weight_size,const at::Tensor & grad_output,const at::Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool bias_defined)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\conv.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\conv.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\conv.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_dnnlowp_acc16_op.cc', ['    C10FlagParser_caffe2_dnnlowp_acc16_density_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_k_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_m_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_n_threshold'], ['    conv_nhwc_acc16_ref_(int num_groups,int N,int output_image_size,int M,int kernel_dim,const uint8_t *col_buffer,const int8_t *W,int32_t *Y)', '    C10FlagParser_caffe2_dnnlowp_acc16_density_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_k_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_m_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_n_threshold(const std::string & content)', '    ConvDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    ConvOutlier_(const uint8_t *col_buffer,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,const uint8_t *col_buffer_data,vector *Y_int32,uint8_t *Y_uint8_data)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_dnnlowp_acc16_op.h', ['    final'], ['    Acc16', '    ConvDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    ConvOutlier_(const std::uint8_t *col_buffer,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,const std::uint8_t *col_buffer_data,vector *Y_int32,uint8_t *Y_uint8_data)', '    fallback_to_32_bit_accumulation_', '    first_invocation_', '    GetQuantizationParameters_', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_dnnlowp_op.cc', ['    C10FlagParser_caffe2_dnnlowp_dump_tensors', '    C10FlagParser_caffe2_dnnlowp_shared_int32_buffer'], ['    conv_nhwc_ref_(int group_id,int num_groups,int i_begin,int i_end,int M,int kernel_dim,const T *col_buffer,const T_signed *W,int32_t *Y)', '    C10FlagParser_caffe2_dnnlowp_dump_tensors(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_shared_int32_buffer(const std::string & content)', '    ConvDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    FilterQuantizationParams(int group_id)', '    GetConvParam_', '    RequantizationParams(int group_id)', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    ~ConvDNNLowPOp', '    ConvNHWCCore_(const T *col_buffer_data,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,vector *Y_int32,uint8_t *Y_uint8_data)', '    GetConv3DParam_', '    GetQuantizationParameters_', '    Im2ColNHWC_(Tensor *col_buffer)', '    IsConvGEMM_', '    KernelDim_', '    NoIm2ColNHWC_', '    PartitionGroupedNHWCConv_(int *group_begin,int *group_end,int *i_begin,int *i_end,int num_groups,int m,int nthreads,int thread_id)', '    PreComputeRowColumnOffsets_', '    QuantizeBias_', '    QuantizeWeight_', '    RunOnDeviceEpilogueNCHW_(const T *col_buffer_data,int32_t *Y_int32,T *Y_data,size_t i_offset,int group_id)', '    RunOnDeviceEpilogueNHWC_(const T *col_buffer_data,int32_t *Y_int32)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    TakeGConvFastPath_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_dnnlowp_op.h', ['    ConvDNNLowPOp'], ['    PartitionGroupedNHWCConv_(int *group_begin,int *group_end,int *i_begin,int *i_end,int num_groups,int m,int nthreads,int thread_id)', '    Acc16', '    b_quantized_data_', '    col_buffer_', '    col_buffer_shape_device_', '    ConvDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ConvNHWCCore_(const T *col_buffer_data,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,vector *Y_int32,uint8_t *Y_uint8_data)', '    FilterQuantizationParams(int group_id)', '    GetConv3DParam_', '    GetConvParam_', '    GetQuantizationParameters_', '    Im2ColNHWC_(Tensor *col_buffer)', '    img_shape_device_', '    in_qparams_scale_old_', '    in_qparams_zero_point_old_', '    IsConvGEMM_', '    KernelDim_', '    NoIm2ColNHWC_', '    PreComputeRowColumnOffsets_', '    QuantizeBias_', '    QuantizeWeight_', '    RequantizationParams(int group_id)', '    RunOnDeviceEpilogueNCHW_(const T *col_buffer_data,std::int32_t *Y_int32,T *Y_data,std::size_t i_offset,int group_id)', '    RunOnDeviceEpilogueNHWC_(const T *col_buffer_data,std::int32_t *Y_int32)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    ~ConvDNNLowPOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_gradient_op.cc', ['    GetConvGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConv1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConvGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvGradient', '    CostInferenceForConvGradient(const OperatorDef & def,const vector & inputs)', '    TensorInferenceForConvGradient(const OperatorDef & def,const std::vector & in)', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\miopen\\Conv_miopen.cpp', [], ['    check_args(CheckedFrom,IntArrayRef args,size_t expected_size,const char *arg_name)', '    convolution_shape_check(CheckedFrom c,const TensorGeometryArg & input,const TensorGeometryArg & weight,const TensorGeometryArg & output,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    args', '    args', '    args', '    args', '    args', '    args', '    miopen_convolution(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_convolution_transpose_backward_input(const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    bdesc', '    chooseAlgorithm(const ConvolutionArgs & args,bool benchmark,algo_t *algo)', '    findAlgorithm(const ConvolutionArgs & args,bool benchmark,algo_t *algo)', '    getBestAlgorithm(perf_t *perfResults,bool deterministic,int n_algo)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvBwdWeightsAlgorithm_t)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvBwdDataAlgorithm_t)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvFwdAlgorithm_t)', '    miopen_convolution_add_bias_(CheckedFrom c,const TensorArg & output,const TensorArg & bias)', '    narrowGroup(const Tensor & t,int dim,int group_idx,int64_t groups)', '    setConvolutionParams(ConvolutionParams *params,miopenHandle_t handle,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool deterministic)', '    raw_miopen_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    bdesc', '    grad_bias', '    grad_input', '    grad_input', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_weight', '    grad_weight', '    input', '    input', '    input', '    miopen_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_convolution_backward_bias(const Tensor & grad_output_t)', '    miopen_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const TensorArg & grad_output,const TensorArg & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_forward(CheckedFrom c,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_depthwise_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const TensorArg & grad_output,const TensorArg & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    odesc', '    output', '    output', '    raw_miopen_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cache', '    cache', '    cache', '    findAlgorithm(const ConvolutionArgs & args)', '    findAlgorithm(const ConvolutionArgs & args)', '    findAlgorithm(const ConvolutionArgs & args)', '    wsscache', '    wsscache', '    wsscache', '    find(const ConvolutionParams & params,T *results)', '    insert(const ConvolutionParams & params,const T & results)', '    ConvolutionArgs(const Tensor & input,const Tensor & output,const Tensor & weight)', '    operator()(const ConvolutionParams & a,const ConvolutionParams & b)', '    operator()(const ConvolutionParams & params)', '    Workspace(size_t size)', '    ~Workspace']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\conv_op.cc', ['    final', '    final', '    IDEEPConvOp'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvFusion', '    ConvFusionDocGenerator(const char *dim)', '    IDEEPConvFusionOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvFusionOp', '    ~IDEEPConvGradientOp', '    IDEEPConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\nnpack\\conv_op.cc', ['    C10FlagParser_caffe2_profile_nnpack', '    final'], ['    initNNPACK', '    C10FlagParser_caffe2_profile_nnpack(const std::string & content)', '    NNPACKConvOp(const OperatorDef & operator_def,Workspace *ws)', '    getActivationType', '    getConvolutionAlgorithm', '    getConvolutionTransformStrategy', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConv', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv3D', '    ConvDocGenerator(const char *dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op.h', ['    final', '    final'], ['    bias_multiplier_', '    col_buffer_', '    col_buffer_shape_device_', '    col_buffer_shape_device_', '    ConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    img_shape_device_', '    img_shape_device_', '    Run1x1ConvOnDeviceWithOrderNCHW(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    Run1x1ConvOnDeviceWithOrderNHWC(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~ConvGradientOp', '    ~ConvOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_cache_cudnn.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_cache_cudnn.h', ['    AlgorithmsCache'], ['    getAlgorithm(at::IntArrayRef tensorDimensions1,at::IntArrayRef tensorDimensions2,int algorithmFlags,std::function generatingFunc)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_cache_cudnn_test.cc', [], ['    TEST(AlgorithmsCacheTest,CachesCorrectly)', '    TEST(AlgorithmsCacheTest,KeysDifferIfOneVectorIsEmpty)', '    TEST(AlgorithmsCacheTest,KeysDifferIfFlagsAreDifferent)', '    res2', '    res3', '    result']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_cudnn.cc', ['    CudnnConvOpBase', '    final', '    final'], ['    CudnnConvOpBase(const OperatorDef & operator_def,Workspace *ws)', '    DetermineComputeTypeFromInput(const T & X)', '    DuplicateConvDesc(cudnnConvolutionDescriptor_t input,size_t kernelDims,size_t dilationDims,cudnnConvolutionDescriptor_t copy)', '    SetConvDescComputeType(cudnnConvolutionDescriptor_t conv_desc,cudnnDataType_t math)', '    SetConvDescFromArguments', '    SetTensorNdDescriptorWithGroup(int size,cudnnTensorDescriptor_t tensorDesc,int N,int C,int H,int W,int D)', '    ~CudnnConvOpBase', '    CudnnConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    CudnnConvOp(const OperatorDef & operator_def,Workspace *ws)', '    ~CudnnConvGradientOp', '    ~CudnnConvOp', '    DoRunWithType', '    RunOnDevice', '    DoRunWithType', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_eigen.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAConv', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv1D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv2D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv3D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConvGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_impl.h', [], ['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    runWithSharedBuffer(ws_,f)', '    copy(Y_dims,Y_dims,buffer_shape)', '    GetDims', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    Run1x1ConvOnDeviceWithOrderNCHW(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    Run1x1ConvOnDeviceWithOrderNHWC(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    RunOnDeviceWithOrderNCHW', '    SetOutputSize', '    SetOutputSize(X,Y,M)', '    Col2Im', '    Col2ImNd', '    Gemm', '    GemmBatched', '    GemmEx', '    GemmStridedBatched', '    Gemv', '    Im2Col', '    Im2ColNd', '    Set', '    cend', '    data', '    dim', '    dim32', '    mutable_data', '    numel', '    sizes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_shared.cc', ['    C10FlagParser_caffe2_force_shared_col_buffer'], ['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)', '    C10FlagParser_caffe2_force_shared_col_buffer(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_shared.h', [], ['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_op_shared_gpu.cc', [], ['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\conv_pool_base_op.h', ['    IDEEPConvPoolOpBase'], ['    CalcOutputDims(const ideep::tensor & input,int output_channel)', '    IDEEPConvPoolOpBase(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    Output(int index)', '    pad_br', '    pad_tl', '    RunOnDevice', '    ~IDEEPConvPoolOpBase', '    get_dims', '    get_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_pool_dnnlowp_op_base.h', ['    ConvPoolDNNLowPOpBase'], ['    arguments_parsed_', '    ConvPoolDNNLowPOpBase(const OperatorDef & operator_def,Workspace *ws)', '    CreateSharedInt32Buffer_', '    debug_def', '    engine', '    Fp32Op_', '    GetOutputQuantizationParams_', '    GetQuantizedOutputData_', '    InputTensorCPU_(int idx)', '    measure_quantization_error_', '    MeasureQuantizationError_', '    output', '    OutputTensorCPU_(int idx)', '    OutputTensorCPU_(int idx,at::IntArrayRef dims,at::TensorOptions options)', '    ParseDNNLowPOperatorArguments_', '    RunOnDeviceEpilogue_', '    RunWithSharedBuffer_(Tensor *col_buffer,vector *Y_int32,std::function)', '    static_assert(std::is_integral,)', '    type', '    ~ConvPoolDNNLowPOpBase', '    Output', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_pool_op_base.h', ['    ConvPoolOpBase'], ['    check_and_set_default_value', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int dilation,LegacyPadding legacy_pad,int *pad_head,int *pad_tail,int *out_size)', '    ComputeSizeAndPad64(const int in_size,const int stride,const int kernel,const int dilation,LegacyPadding legacy_pad,int *pad_head,int *pad_tail,int64_t *out_size)', '    CostInferenceForConv(const OperatorDef & def,const vector & inputs)', '    InferOutputSize(const at::IntArrayRef & input_dims,const int output_channel,const StorageOrder order,const bool global_pooling,const LegacyPadding legacy_pad,const std::vector & dilation,const std::vector & stride,std::vector *kernel,std::vector *pads,std::vector *output_dims)', '    InferOutputSize64(const at::IntArrayRef & input_dims,const int output_channel,const StorageOrder order,const bool global_pooling,const LegacyPadding legacy_pad,const std::vector & dilation,const std::vector & stride,std::vector *kernel,std::vector *pads,std::vector *output_dims)', '    TensorInferenceForConv(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForLC(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForPool(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForSchema(const OperatorDef & def,const vector & in,int output_channel)', '    AllocateAndCopy(const vector & vec,Tensor & tensor)', '    ComputePads(const vector & dims)', '    ConvPoolOpBase(const OperatorDef & operator_def,Workspace *ws)', '    dilation_h', '    dilation_w', '    GetDims(const Tensor & input)', '    GetDimsSize(const Tensor & input)', '    GetOutputSize(const Tensor & input,int output_channel)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasPad', '    HasStride', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    SetBiasMultiplier(const int size,Tensor *bias_multiplier_)', '    SetDeviceTensor(const std::vector & data,Tensor *tensor)', '    SetOutputSize(const Tensor & input,Tensor *output,int output_channel)', '    stride_h', '    stride_w', '    ~ConvPoolOpBase', '    begin', '    dim', '    end', '    size_from_dim', '    copy_n']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_relu_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConvRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvRelu', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\conv_relu_op.h', ['    final'], ['    ConvReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~ConvReluOp', '    CreateBlob', '    GetBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\conv_to_nnpack_transform.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\conv_to_nnpack_transform.h', ['    ConvToNNPackTransform'], ['    MatchOperator(const OperatorDef & op)', '    ReplaceOperator(OperatorDef *op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\conv_to_nnpack_transform_test.cc', [], ['    TEST(ConvToNNPackTest,TestSimple)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_gradient_op.cc', ['    GetConvTransposeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConvTransposeGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvTransposeGradient', '    vector', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\conv_transpose_op.cc', ['    final', '    final'], ['    IDEEPConvTransposeGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPConvTransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvTransposeGradientOp', '    ~IDEEPConvTransposeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConvTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvTranspose']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op.h', ['    final', '    final'], ['    ConvTransposeGradientOp(Args,...)', '    ConvTransposeOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_cudnn.cc', ['    CudnnConvTransposeOpBase', '    final', '    final'], ['    CudnnConvTransposeOpBase(Args,...)', '    SetTensor4DDescriptorWithGroup(const cudnnDataType_t data_type,const int N,const int C,const int H,const int W,cudnnTensorDescriptor_t *desc)', '    ~CudnnConvTransposeOpBase', '    CudnnConvTransposeGradientOp(Args,...)', '    CudnnConvTransposeOp(Args,...)', '    ~CudnnConvTransposeGradientOp', '    ~CudnnConvTransposeOp', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAConvTranspose', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConvTransposeGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_impl.h', [], ['    dtype', '    MessageLogger(,,)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    func(& col_buffer_)', '    runWithSharedBuffer(ws_,func)', '    device', '    kernel_w', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    kernel_w', '    RunOnDeviceWithOrderNCHW', '    GetOutputSize', '    Add', '    Col2Im', '    Gemm', '    Gemm(CblasNoTrans,CblasTrans,M,kernel_dim,X_HxW,,X_data,col_buffer_data,,dfilter_data,& context_)', '    Gemm(CblasNoTrans,CblasNoTrans,M,X_HxW,kernel_dim,,filter_data,col_buffer_data,,dX_data,& context_)', '    Gemm(CblasTrans,CblasNoTrans,M,kernel_dim,X_HxW,,X_data,col_buffer_data,,dfilter_data,& context_)', '    Gemm(CblasNoTrans,CblasTrans,X_HxW,M,kernel_dim,,col_buffer_data,filter_data,,dX_data,& context_)', '    GemmEx', '    GemmEx(CblasTrans,CblasNoTrans,M,kernel_dim,X_HxW,,X_data,M,col_buffer_data,G *kernel_dim,,dfilter_data,kernel_dim,& context_)', '    GemmEx(CblasNoTrans,CblasTrans,X_HxW,M,kernel_dim,,col_buffer_data,G *kernel_dim,filter_data,kernel_dim,,dX_data,M,& context_)', '    GemmStridedBatched', '    GemmStridedBatched(CblasNoTrans,CblasTrans,G,M,kernel_dim,X_HxW,,X_data,M,col_buffer_data,col_buffer_,,dfilter_data,M,& context_)', '    GemmStridedBatched(CblasNoTrans,CblasNoTrans,G,M,X_HxW,kernel_dim,,filter_data,M,col_buffer_data,col_buffer_,,dX_data,M,& context_)', '    Im2Col(C,dY,dY,kernel_h,kernel_w,,,pad_t,pad_l,pad_b,pad_r,stride_h,stride_w,dY_data,col_buffer_data,& context_)', '    Im2Col(C,dY,dY,kernel_h,kernel_w,,,pad_t,pad_l,pad_b,pad_r,stride_h,stride_w,dY_data,col_buffer_data,& context_,G)', '    ReduceSum(,Y_dims,b_dims,T,dY_data,dbias_data,& context_)', '    Set']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_mobile.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_mobile.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_mobile_impl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_op_mobile_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int adjH,int adjW,float maxRelErr,float absErrForRelErrFailure)', '    relativeError(float a,float b)', '    randInt(int a,int b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\conv_transpose_unpool_base_op.h', ['    IDEEPConvTransposeUnpoolBase'], ['    Input(int index)', '    Output(int index)', '    get_dim', '    get_dims', '    get_size', '    adj_h', '    adj_w', '    CalcOutputDims(const ideep::tensor & input,int output_channel)', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int adj,int *pad_head,int *pad_tail,int *out_size)', '    IDEEPConvTransposeUnpoolBase(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    kernel_h', '    kernel_w', '    Output(int index)', '    pad_b', '    pad_br', '    pad_l', '    pad_r', '    pad_t', '    pad_tl', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    stride_h', '    stride_w', '    ~IDEEPConvTransposeUnpoolBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\conv_transpose_unpool_op_base.h', ['    ConvTransposeUnpoolBase'], ['    adj_h', '    adj_w', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int adj,int *pad_head,int *pad_tail,int *out_size)', '    ConvTransposeUnpoolBase(const OperatorDef & operator_def,Workspace *ws)', '    GetOutputSize(const Tensor & input,int output_channel)', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    stride_h', '    stride_w', '    ~ConvTransposeUnpoolBase', '    dim32']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\include\\conv_utils.h', [], ['    conv_param_t(const std::array kernel,const std::array subsampling,const std::array dil,const std::array pd,const uint32_t grp,const size_t in_ch,const size_t out_ch,const uint8_t kernel_zp,const float kernel_s,const uint8_t out_min,const uint8_t out_max)', '    isnormal']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\conversions.h', [], ['    Get(IN x)', '    To(const IN in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\convert_and_benchmark.cc', ['    C10FlagParser_batch_size', '    C10FlagParser_color', '    C10FlagParser_crop', '    C10FlagParser_input_image_files', '    C10FlagParser_input_text_files', '    C10FlagParser_preprocess', '    C10FlagParser_report_time', '    C10FlagParser_scale', '    C10FlagParser_warp'], ['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input_dims,int FLAGS_iter,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    convertImages(std::string & image_file)', '    convertOneImage(std::string & filename,int *height_ptr,int *width_ptr)', '    convertToVector(cv::Mat & img)', '    convertValues(std::string & file_name)', '    cropToRec(cv::Mat & img,int *height_ptr,int *width_ptr)', '    getBatchSize(int num_items)', '    reportTime(std::string type,double ts,std::string metric,std::string unit)', '    resizeImage(cv::Mat & img)', '    splitSizes(const std::string & arg,int *ptr0,int *ptr1)', '    splitString(std::string & line)', '    writeValues(std::vector,std::vector)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    main(int argc,char **argv)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetDef & net_def,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_crop(const std::string & content)', '    C10FlagParser_input_image_files(const std::string & content)', '    C10FlagParser_input_text_files(const std::string & content)', '    C10FlagParser_preprocess(const std::string & content)', '    C10FlagParser_report_time(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_warp(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\convert_caffe_image_db.cc', ['    C10FlagParser_batch_size', '    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_output_db', '    C10FlagParser_output_db_type'], ['    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_output_db(const std::string & content)', '    C10FlagParser_output_db_type(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\convert_db.cc', ['    C10FlagParser_batch_size', '    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_output_db', '    C10FlagParser_output_db_type'], ['    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_output_db(const std::string & content)', '    C10FlagParser_output_db_type(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\convert_encoded_to_raw_leveldb.cc', ['    C10FlagParser_color', '    C10FlagParser_input_db_name', '    C10FlagParser_output_db_name', '    C10FlagParser_scale', '    C10FlagParser_warp'], ['    ConvertToRawDataset(const string & input_db_name,const string & output_db_name)', '    main(int argc,char **argv)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_input_db_name(const std::string & content)', '    C10FlagParser_output_db_name(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_warp(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\convert_image_to_tensor.cc', ['    C10FlagParser_batch_size', '    C10FlagParser_color', '    C10FlagParser_crop', '    C10FlagParser_input_image_file', '    C10FlagParser_input_images', '    C10FlagParser_input_text_file', '    C10FlagParser_output_tensor', '    C10FlagParser_output_text_tensor', '    C10FlagParser_preprocess', '    C10FlagParser_report_time', '    C10FlagParser_scale', '    C10FlagParser_text_output', '    C10FlagParser_warp'], ['    convertImages', '    convertOneImage(std::string & filename,int *height_ptr,int *width_ptr)', '    convertToVector(cv::Mat & img)', '    convertValues', '    cropToRec(cv::Mat & img,int *height_ptr,int *width_ptr)', '    getBatchSize(int num_items)', '    reportTime(std::string type,double ts,std::string metric,std::string unit)', '    resizeImage(cv::Mat & img)', '    splitSizes(const std::string & arg,int *ptr0,int *ptr1)', '    splitString(std::string & line)', '    writeValues(std::vector,std::vector,std::string output_file)', '    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_crop(const std::string & content)', '    C10FlagParser_input_image_file(const std::string & content)', '    C10FlagParser_input_images(const std::string & content)', '    C10FlagParser_input_text_file(const std::string & content)', '    C10FlagParser_output_tensor(const std::string & content)', '    C10FlagParser_output_text_tensor(const std::string & content)', '    C10FlagParser_preprocess(const std::string & content)', '    C10FlagParser_report_time(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_text_output(const std::string & content)', '    C10FlagParser_warp(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\utils\\convert_parameters.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\convert_to_ssa.cpp', [], ['    ConvertToSSA(std::shared_ptr & graph)', '    addBlockInput(Block *b,const TypePtr & type,const std::string & name)', '    addBlockOutput(Block *exit_block,const TypePtr & type,const std::string & name)', '    addNodeInput(Node *n,const TypePtr & type,const std::string & name)', '    addNodeOutput(Node *n,const TypePtr & type,const std::string & name)', '    addControlFlowLoadStores(Block *block)', '    addIfLoadStores(Node *n)', '    addLoopLoadStores(Node *n)', '    popFrame', '    pushFrame(Block *b)', '    run(std::shared_ptr & graph)', '    eraseBlockLoadStores(Block *block)', '    popFrame', '    pushFrame(Block *b)', '    run(std::shared_ptr & graph)', '    addLoopCarriedOutputs(Node *n)', '    assignExitContinuations(Block *block)', '    run(std::shared_ptr & graph)', '    run(Block *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\convert_to_ssa.h', [], ['    ConvertToSSA(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\converter.cc', ['    AveragePoolConverter', '    BatchNormalizationConverter', '    ClipConverter', '    ConcatConverter', '    ConvConverter', '    ConvTransposeConverter', '    FCConverter', '    FlattenConverter', '    MaxPoolConverter', '    ReluConverter', '    SumConverter'], ['    convertToCaffe2Proto(repr::NNModule & m)', '    convertToCaffe2Proto(repr::NNModule & m,const caffe2::NetDef & oldNet)', '    convertToNeuralNetOperator(const caffe2::OperatorDef & op)', '    convertToNNModule(const caffe2::NetDef & net,bool strict,std::vector *opNodeVec)', '    convertToOperatorDef(const repr::NNGraph::NodeRef & instrNode)', '    getKernelShape(std::map argMap)', '    getLayout(std::map argMap)', '    getOrAddCaffe2Annotation(nom::repr::NNGraph::NodeRef & instrNode)', '    injectDataEdgeIndicators(caffe2::NetDef *net)', '    mergeExternalTensors(const std::unordered_set & currExternal,const std::vector & oldExternal)', '    pushOpToFront(caffe2::OperatorDef & op,caffe2::NetDef *net)', '    RegistryName', '    removeDataEdgeIndicators(caffe2::NetDef *net)', '    getDilations(std::map argMap)', '    getGroup(std::map & argMap)', '    getPads(std::map argMap)', '    getStrides(std::map argMap)', '    getArgumentsFromOperator(caffe2::OperatorDef op)', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~AveragePoolConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchNormalizationConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ClipConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConcatConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConvConverter', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    getDeviceOption(const nom::repr::NeuralNetOperator *nnOp)', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConvTransposeConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~FCConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~FlattenConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~MaxPoolConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ReluConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~SumConverter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\converter.cc', ['    AddConverter', '    BatchGatherConverter', '    BatchMatMulConverter', '    CastConverter', '    ClipRangesConverter', '    ClipRangesGatherSigridHashConverter', '    ConcatAddMulReplaceNaNClipConverter', '    MulConverter', '    ReplaceNaNConverter', '    SigridHashConverter', '    SliceConverter'], ['    convertToNeuralNetOperator(const OperatorDef & op)', '    ~AddConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchGatherConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchMatMulConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~CastConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ClipRangesConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ClipRangesGatherSigridHashConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ConcatAddMulReplaceNaNClipConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~MulConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ReplaceNaNConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~SigridHashConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~SliceConverter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\converter.h', ['    Converter'], ['    convertToCaffe2Proto(repr::NNModule & m)', '    convertToCaffe2Proto(repr::NNModule & m,const caffe2::NetDef & oldNet)', '    convertToNeuralNetOperator(const caffe2::OperatorDef & op)', '    convertToNNModule(const caffe2::NetDef & net,bool strict,std::vector *opNodeVec)', '    convertToOperatorDef(const nom::repr::NNGraph::NodeRef & instrNode)', '    RegistryName', '    getArgumentsFromOperator(caffe2::OperatorDef op)', '    Converter', '    convertToNeuralNetOperator(const OperatorDef &)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    getDeviceOption(const nom::repr::NeuralNetOperator *nnOp)', '    ~Converter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\converter_nomigraph_test.cc', [], ['    fakeNet', '    TEST(Converter,Basic)', '    TEST(Converter,UnknownType)', '    TEST(Converter,SpecializeConverter)', '    TEST(Converter,ExternalInputs)', '    TEST(Converter,ExternalOutputs)', '    TEST(Converter,InjectDataEdgeIndicators)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\converter_test.cc', [], ['    TEST(Converter,ClipRangesGatherSigridHashConverter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\convolution-operator-tester.h', ['    ConvolutionOperatorTester', '    Mode'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    dilatedKernelHeight', '    dilatedKernelWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    groupInputChannels(size_t groupInputChannels)', '    groupInputChannels', '    groupInputChannels_', '    groupOutputChannels(size_t groupOutputChannels)', '    groupOutputChannels', '    groupOutputChannels_', '    groups(uint32_t groups)', '    groups', '    groups_', '    inputHeight(uint32_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(uint32_t inputHeight,uint32_t inputWidth)', '    inputWidth(uint32_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize(uint32_t kernelSize)', '    kernelSize(uint32_t kernelHeight,uint32_t kernelWidth)', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    subsampling(uint32_t subsampling)', '    subsampling(uint32_t subsamplingHeight,uint32_t subsamplingWidth)', '    subsamplingHeight(uint32_t subsamplingHeight)', '    subsamplingHeight', '    subsamplingHeight_', '    subsamplingWidth(uint32_t subsamplingWidth)', '    subsamplingWidth', '    subsamplingWidth_', '    testQ8(const Mode mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\convolution.c', [], ['    compute_output_dimension(size_t padded_input_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t subsampling_dimension)', '    pytorch_qnnp_create_convolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t kernel_height,uint32_t kernel_width,uint32_t subsampling_height,uint32_t subsampling_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *convolution_out)', '    pytorch_qnnp_setup_convolution2d_nhwc_q8(pytorch_qnnp_operator_t convolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\convolution.cc', [], ['    TEST(CONVOLUTION_OP,zero_batch)', '    TEST(CONVOLUTION_OP,grouped_1x1)', '    TEST(CONVOLUTION_OP,xzp_1x1)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_qmin)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_qmax)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_input_stride)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_output_stride)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_batch)', '    TEST(CONVOLUTION_OP,grouped_xzp_1x1)', '    TEST(CONVOLUTION_OP,grouped_xzp_1x1_runtime_quant)', '    TEST(CONVOLUTION_OP,grouped_1x3)', '    TEST(CONVOLUTION_OP,grouped_1x3_runtime_quant)', '    TEST(CONVOLUTION_OP,grouped_3x1)', '    TEST(CONVOLUTION_OP,grouped_3x3)', '    TEST(CONVOLUTION_OP,depthwise_3x3)', '    TEST(CONVOLUTION_OP,depthwise_3x3_runtime_quant)', '    TEST(CONVOLUTION_OP,depthwise_3x3s2)', '    TEST(CONVOLUTION_OP,depthwise_3x3s1x2)', '    TEST(CONVOLUTION_OP,depthwise_3x3s2x1)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2)', '    TEST(CONVOLUTION_OP,depthwise_3x3d1x2)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2x1)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2x1_runtime_quant)', '    TEST(CONVOLUTION_OP,depthwise_5x5)', '    TEST(CONVOLUTION_OP,depthwise_5x5s2)', '    TEST(CONVOLUTION_OP,depthwise_5x5s1x2)', '    TEST(CONVOLUTION_OP,depthwise_5x5s2x1)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2)', '    TEST(CONVOLUTION_OP,depthwise_5x5d1x2)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2x1)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2x1_runtime_quant)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\convolution.cc', [], ['    convolution_q8(benchmark::State & state,const char *net)', '    DWConv3x3(benchmark::internal::Benchmark *b)', '    DWConv3x3d2(benchmark::internal::Benchmark *b)', '    DWConv5x5(benchmark::internal::Benchmark *b)', '    MobileNetV1(benchmark::internal::Benchmark *b)', '    MobileNetV2(benchmark::internal::Benchmark *b)', '    ResNet18(benchmark::internal::Benchmark *b)', '    ResNet50(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X05(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X10(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X15(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X20(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Convolution.cpp', [], ['    check_shape_forward(const at::Tensor & input,const c10::IntArrayRef & weight_sizes,const at::Tensor & bias,const ConvParams & params)', '    subtensor(at::Tensor & tensor,int dim,int groups,int g)', '    subvariable(const Tensor & var,int dim,int groups,int g)', '    view3d(const at::Tensor & tensor)', '    view4d(const at::Tensor & tensor)', '    _convolution(const Tensor & input_r,const Tensor & weight_r,const Tensor & bias_r,IntArrayRef stride_,IntArrayRef padding_,IntArrayRef dilation_,bool transposed_,IntArrayRef output_padding_,int64_t groups_,bool benchmark,bool deterministic,bool cudnn_enabled)', '    _convolution_double_backward(const Tensor & ggI,const Tensor & ggW_r,const Tensor & ggb,const Tensor & gO_r,const Tensor & weight_r,const Tensor & input,IntArrayRef stride_,IntArrayRef padding_,IntArrayRef dilation_,bool transposed_,IntArrayRef output_padding_,int64_t groups_,bool benchmark,bool deterministic,bool cudnn_enabled,std::array output_mask)', '    _convolution_nogroup(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding)', '    check_cudnn_depthwise_workload(const at::Tensor & input,int stride)', '    conv1d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv2d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv3d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv_transpose1d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    conv_transpose2d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    conv_transpose3d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    convolution(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    convolution_backward_overrideable(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups,std::array output_mask)', '    convolution_overrideable(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    operator<<(std::ostream & out,const ConvParams & params)', '    is_depthwise(const at::Tensor & input,const at::Tensor & weight)', '    is_dilated', '    is_output_padding_big', '    is_output_padding_neg', '    is_padded', '    is_padding_neg', '    is_stride_nonpos', '    is_strided', '    needs_64bit_indexing_no_split(const at::Tensor & input,const at::Tensor & weight)', '    use_cpu_depthwise3x3_winograd(const at::Tensor & input,const at::Tensor & weight)', '    use_cudnn(const at::Tensor & input,const at::Tensor & weight)', '    use_cudnn_depthwise(const at::Tensor & input,const at::Tensor & weight)', '    use_miopen(const at::Tensor & input,bool bias_defined)', '    use_mkldnn(const at::Tensor & input)', '    use_nnpack(const at::Tensor & input)', '    view1d_as_2d']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Convolution.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Convolution.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ConvolutionMM2d.cpp', [], ['    slow_conv2d_backward_parameters_out_cpu_template(Tensor & grad_weight,Tensor & grad_bias,const Tensor & input_,const Tensor & grad_output_,const Tensor & finput,Tensor fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width,bool weight_optional)', '    slow_conv2d_update_output_frame(Tensor & input,Tensor & output,const Tensor & weight,const Tensor & bias,Tensor & finput,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t n_output_plane,int64_t output_height,int64_t output_width)', '    view_weight_2d(const Tensor & weight_)', '    slow_conv2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input,std::array output_mask)', '    slow_conv2d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input)', '    slow_conv2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input_,const Tensor & weight_,const Tensor & finput,Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_backward_parameters_frame(Tensor & grad_weight,Tensor & grad_bias,Tensor & grad_output,const Tensor & finput)', '    slow_conv2d_backward_update_grad_input_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & weight,Tensor & fgrad_input,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width)', '    slow_conv2d_forward_cpu(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_forward_out_cpu(Tensor & output,Tensor & finput,Tensor & fgrad_input,const Tensor & self,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ConvolutionMM3d.cpp', [], ['    slow_conv3d_backward_parameters_out_cpu_template(Tensor & grad_weight,Tensor & grad_bias,const Tensor & input,const Tensor & grad_output,const Tensor & finput,Tensor fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width,bool weight_optional)', '    slow_conv3d_update_output_frame(Tensor & input,Tensor & output,const Tensor & weight,const Tensor & bias,Tensor & finput,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width,int64_t n_input_plane,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t n_output_plane,int64_t output_depth,int64_t output_height,int64_t output_width)', '    view_weight_2d(const Tensor & weight_)', '    slow_conv3d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input,std::array output_mask)', '    slow_conv3d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input)', '    slow_conv3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & weight,const Tensor & finput,Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_backward_parameters_frame(Tensor & grad_weight,Tensor & grad_bias,Tensor & grad_output,const Tensor & finput)', '    slow_conv3d_backward_update_grad_input_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & weight,Tensor & fgrad_input,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width)', '    slow_conv3d_forward_cpu(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_forward_out_cpu(Tensor & output,Tensor & finput,Tensor & fgrad_input,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ConvolutionTBC.cpp', [], ['    conv_tbc(const Tensor & self,const Tensor & weight,const Tensor & bias,int64_t pad)', '    conv_tbc_backward(const Tensor & dOutput,const Tensor & input,const Tensor & weight,const Tensor & bias,int64_t pad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ConvUtils.h', [], ['    conv_input_size(IntArrayRef output_size,IntArrayRef weight_size,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    conv_output_size(IntArrayRef input_size,IntArrayRef weight_size,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation)', '    conv_weight_size(IntArrayRef input_size,IntArrayRef output_size,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    cudnn_conv_use_channels_last(const at::Tensor & input,const at::Tensor & weight)', '    reshape_bias(int64_t dim,const Tensor & bias)', '    getCUDAHooks', '    reshape', '    scalar_type', '    suggest_memory_format']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Copy.cpp', [], ['    copy_impl(Tensor & self,const Tensor & src,bool non_blocking)', '    copy_(Tensor & self,const Tensor & src,bool non_blocking)', '    copy_same_type_transpose_(Tensor & self,const Tensor & src)', '    copy_transpose_valid(const Tensor & self,const Tensor & src)', '    is_supported_device(Device device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\Copy.cpp', [], ['    quantized_copy_from_float_(Tensor & self,const Tensor & src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Copy.h', [], ['    copy_stub', '    copy_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\Copy.h', [], ['    quantized_copy_from_float_(Tensor & self,const Tensor & src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\copy_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCopy', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyFromCPUInput', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyOnDeviceLike', '    schema_CopyCPUToGPU', '    schema_CopyGPUToCPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Copy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyCPUToGPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyFromCPUInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyGPUToCPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyOnDeviceLike', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\copy_op.h', ['    CopyOnDeviceLikeOp', '    CopyOp'], ['    schema_CopyCPUToGPU', '    schema_CopyGPUToCPU', '    CopyOnDeviceLikeOp(Args,...)', '    CopyOp(Args,...)', '    Input', '    Output', '    RunOnDevice', '    ~CopyOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\copy_rows_to_tensor_op.cc', ['    GetCopyRowsToTensorGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyRowsToTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyRowsToTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyRowsToTensorGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\copy_rows_to_tensor_op.h', ['    CopyRowsToTensorGradientOp', '    CopyRowsToTensorOp'], ['    CopyRowsToTensorGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice', '    CopyRowsToTensorOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\copy_utils.h', [], ['    THPCopy(const THPCopyList & v,PyObject *dst,PyObject *src,bool non_blocking,bool broadcast)', '    THPInsertStorageCopyFunction(PyTypeObject *srcType,THPCopyList & copyList,void (*) (LIBRARY_STATE_TYPE StorageDst *, StorageSrc *) copyFunc,bool non_blocking)', '    THPStorageCopyMethod(const THPCopyList & v,PyObject *self,PyObject *args,PyObject *kwargs)', '    tryTHPCopy(const THPCopyList & v,PyObject *dst,PyObject *src,bool non_blocking,bool broadcast)', '    push_back']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\CopyBytes.cpp', [], ['    CopyBytes(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device,bool async)', '    _CopyBytesFunctionRegisterer(DeviceType fromType,DeviceType toType,CopyBytesFunction func_sync,CopyBytesFunction func_async)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\CopyBytes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\CopyKernel.cpp', [], ['    copy_kernel(TensorIterator & iter,bool non_blocking)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\core.cpp', [], ['    deleteTHManagedMapAllocator(void *ptr)', '    get_alloc_info(const char *filename)', '    get_manager_socket(const std::string & manager_handle)', '    libshm_init(const char *manager_exec_path)', '    manager', '    start_manager', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    close', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    THManagedMapAllocatorInit(const char *manager_handle,const char *filename)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm_windows\\core.cpp', [], ['    deleteTHManagedMapAllocator(void *ptr)', '    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\core_overhead_benchmark.cc', [], ['    BM_APILogging(benchmark::State & state)', '    BM_NoAPILogging(benchmark::State & state)', '    call(int id)', '    call_no_logging(int id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\core_overhead_benchmark_gpu.cc', ['    DummyEmptyOp'], ['    BM_CUDAContextCreation(benchmark::State & state)', '    BM_CUDAContextStreamAccess(benchmark::State & state)', '    BM_cudaEventRecord(benchmark::State & state)', '    BM_cudaGetDevice(benchmark::State & state)', '    BM_CudaPointerAffinity(benchmark::State & state)', '    BM_cudaSetAndGetDevice(benchmark::State & state)', '    BM_cudaSetDevice(benchmark::State & state)', '    BM_cudaSetSameDevice(benchmark::State & state)', '    BM_cudaStreamCreateSyncDelete(benchmark::State & state)', '    BM_cudaStreamSynchronize(benchmark::State & state)', '    BM_cudaStreamWaitEventThenStreamSynchronize(benchmark::State & state)', '    BM_OperatorCreationCPU(benchmark::State & state)', '    BM_OperatorCreationCUDA(benchmark::State & state)', '    BM_RawAllocDeallocCPU(benchmark::State & state)', '    BM_TensorAllocDeallocCPU(benchmark::State & state)', '    BM_TensorAllocDeallocCUDA(benchmark::State & state)', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyEmpty', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyEmpty', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyEmpty', '    DummyEmptyOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cos_op.cc', ['    GetCosGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCos', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cos', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cos_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cosh_op.cc', ['    GetCoshGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCosh', '    CAFFE_ANONYMOUS_VARIABLE_CPUCoshGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cosh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CoshGradient', '    Forward(const std::vector &,const std::vector & X_dims,const T *dY,const T *X,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cosh_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cosine_embedding_criterion_op.cc', ['    GetCosineEmbeddingCriterionGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCosineEmbeddingCriterion', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosineEmbeddingCriterionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineEmbeddingCriterion', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineEmbeddingCriterionGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cosine_embedding_criterion_op.h', ['    final', '    final'], ['    CosineEmbeddingCriterionGradientOp(Args,...)', '    CosineEmbeddingCriterionOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\counter_ops.cc', ['    CounterDeserializer', '    CounterSerializer'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCheckCounterDone', '    CAFFE_ANONYMOUS_VARIABLE_CPUCountDown', '    CAFFE_ANONYMOUS_VARIABLE_CPUCountUp', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateCounter', '    CAFFE_ANONYMOUS_VARIABLE_CPUResetCounter', '    CAFFE_ANONYMOUS_VARIABLE_CPURetrieveCount', '    kCountExample', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckCounterDone', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CountDown', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CountUp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResetCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RetrieveCount', '    noexcept', '    Deserialize(const BlobProto & proto,Blob *blob)', '    CounterSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~CounterSerializer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\counter_ops.h', ['    Counter', '    final', '    final', '    final', '    final', '    final', '    final'], ['    checkIfDone', '    countDown', '    Counter(T count)', '    countUp', '    reset(T init_count)', '    retrieve', '    CheckCounterDoneOp(Args,...)', '    CountDownOp(Args,...)', '    CountUpOp(Args,...)', '    CreateCounterOp(Args,...)', '    GetSingleArgument', '    ResetCounterOp(Args,...)', '    RetrieveCountOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\counter_ops_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACheckCounterDone', '    CAFFE_ANONYMOUS_VARIABLE_CUDACountDown', '    CAFFE_ANONYMOUS_VARIABLE_CUDACountUp', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateCounter', '    CAFFE_ANONYMOUS_VARIABLE_CUDAResetCounter', '    CAFFE_ANONYMOUS_VARIABLE_CUDARetrieveCount']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpp_custom_type_hack.h', [], ['    cast(const Tensor & packed)', '    create(std::unique_ptr ptr,TensorOptions options)', '    isa(const Tensor & packed)', '    data_ptr', '    get', '    scalar_type', '    storage']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\cpp_frontend_extension.cpp', [], ['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    add_new_buffer(const std::string & name,torch::Tensor tensor)', '    add_new_parameter(const std::string & name,torch::Tensor tensor)', '    add_new_submodule(const std::string & name)', '    fc', '    forward(torch::Tensor x)', '    get_bias', '    Net(int64_t in,int64_t out)', '    reset', '    set_bias(torch::Tensor bias)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\cpp_hook.cpp', [], ['    check_single_result(Variable,Variable result,std::string hook_name)', '    CppFunctionPreHook(const std::shared_ptr & hooks,int value_idx)', '    operator()(const variable_list & values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\cpp_hook.h', [], ['    CppFunctionPreHook(const std::shared_ptr & hooks,int value_idx)', '    operator()(const variable_list & values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cpu_generator_test.cpp', [], ['    TEST(CPUGenerator,TestGeneratorDynamicCast)', '    TEST(CPUGenerator,TestDefaultGenerator)', '    TEST(CPUGenerator,TestCloning)', '    TEST(CPUGenerator,TestMultithreadingGetEngineOperator)', '    TEST(CPUGenerator,TestGetSetCurrentSeed)', '    TEST(CPUGenerator,TestMultithreadingGetSetCurrentSeed)', '    TEST(CPUGenerator,TestRNGForking)', '    TEST(CPUGenerator,TestPhiloxEngineReproducibility)', '    TEST(CPUGenerator,TestPhiloxEngineOffset1)', '    TEST(CPUGenerator,TestPhiloxEngineOffset2)', '    TEST(CPUGenerator,TestPhiloxEngineOffset3)', '    TEST(CPUGenerator,TestPhiloxEngineIndex)', '    TEST(CPUGenerator,TestMT19937EngineReproducibility)', '    thread_func_get_engine_op(CPUGenerator *generator)', '    thread_func_get_set_current_seed(Generator generator)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cpu_neon.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cpu_rng_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\CPUAllocator.cpp', ['    C10FlagParser_caffe2_cpu_allocator_do_junk_fill', '    C10FlagParser_caffe2_cpu_allocator_do_zero_fill', '    C10FlagParser_caffe2_report_cpu_memory_usage', '    MemoryAllocationReporter'], ['    alloc_cpu(size_t nbytes)', '    free_cpu(void *data)', '    GetCPUAllocator', '    GetDefaultCPUAllocator', '    memset_junk(void *data,size_t num)', '    NoDelete(void *)', '    SetCPUAllocator(at::Allocator *alloc)', '    getMemoryAllocationReporter', '    ReportAndDelete(void *ptr)', '    C10FlagParser_caffe2_cpu_allocator_do_junk_fill(const std::string & content)', '    C10FlagParser_caffe2_cpu_allocator_do_zero_fill(const std::string & content)', '    C10FlagParser_caffe2_report_cpu_memory_usage(const std::string & content)', '    allocate(size_t nbytes)', '    DefaultCPUAllocator', '    raw_deleter', '    ~DefaultCPUAllocator', '    Delete(void *ptr)', '    MemoryAllocationReporter', '    New(void *ptr,size_t nbytes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\CPUAllocator.h', [], ['    alloc_cpu(size_t nbytes)', '    free_cpu(void *data)', '    GetCPUAllocator', '    GetDefaultCPUAllocator', '    memset_junk(void *data,size_t num)', '    NoDelete(void *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\CPUApplyUtils.h', [], ['    _all_equal_numel(at::ArrayRef tensors)', '    _all_equal_numel_error(at::ArrayRef tensors)', '    _apply_preamble(ArrayRef tensors)', '    _max_dim_tensors(ArrayRef tensors)', '    apply_op', '    apply_op(int64_t numel,int64_t offset,const Op & op,Args,...)', '    collapse_dims(T *sizes,T *strides,int64_t dims,const int excludeDim)', '    CPU_tensor_apply1(Tensor tensor1,const Op op)', '    CPU_tensor_apply2(Tensor tensor1,Tensor tensor2,const Op op)', '    CPU_tensor_apply3(Tensor tensor1,Tensor tensor2,Tensor tensor3,const Op op)', '    CPU_tensor_apply4(Tensor tensor1,Tensor tensor2,Tensor tensor3,Tensor tensor4,const Op op)', '    forward(int64_t offset)', '    forward(int64_t offset,Arg & iter,Args &,...)', '    iterate(int64_t size)', '    iterate(int64_t size,Arg & iter,Args &,...)', '    iterate_continue', '    iterate_continue(Arg & iter,Args &,...)', '    iterate_overflow', '    iterate_overflow(Arg & iter,Args &,...)', '    max_dim', '    max_dim(Arg & iter,Args &,...)', '    max_iterate_size', '    max_iterate_size(Arg & iter,Args &,...)', '    sort_strides(Tensor & tensor_)', '    operator=', '    strided_tensor_iter', '    strided_tensor_iter', '    strided_tensor_iter(Tensor & tensor)', '    operator=', '    strided_tensor_iter_fixed', '    strided_tensor_iter_fixed', '    strided_tensor_iter_fixed(Tensor & tensor,bool sort_strides)', '    data', '    data_ptr', '    dim', '    ndimension', '    numel', '    permute', '    sizes', '    strides', '    vec', '    memset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\CPUFixedAllocator.h', [], ['    cpu_fixed_free(void *state,void *allocation)', '    cpu_fixed_malloc(void *,ptrdiff_t)', '    cpu_fixed_realloc(void *,void *,ptrdiff_t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\CPUGenerator.cpp', [], ['    createCPUGenerator(uint64_t seed_val)', '    getDefaultCPUGenerator', '    make64BitsFrom32Bits(uint32_t hi,uint32_t lo)', '    engine_', '    next_double_normal_sample_', '    next_float_normal_sample_', '    clone', '    clone_impl', '    CPUGenerator(uint64_t seed_in)', '    current_seed', '    device_type', '    engine', '    next_double_normal_sample', '    next_float_normal_sample', '    random', '    random64', '    seed', '    set_current_seed(uint64_t seed)', '    set_engine(at::mt19937 engine)', '    set_next_double_normal_sample(c10::optional randn)', '    set_next_float_normal_sample(c10::optional randn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\CPUGenerator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\CPUGuardImpl.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\CPUGuardImpl.h', [], ['    block(void *event,const Stream & stream)', '    CPUGuardImpl', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device)', '    exchangeStream(Stream s)', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device)', '    type', '    uncheckedSetDevice(Device d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cpuid.cc', [], ['    GetCpuId', '    CpuId', '  Static Member Variables', '    f1c_', '    f1d_', '    f7b_', '    f7c_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cpuid.h', ['    CpuId'], ['    GetCpuId', '    acpi', '    adx', '    aes', '    apic', '    avx', '    avx2', '    avx512bw', '    avx512cd', '    avx512dq', '    avx512er', '    avx512f', '    avx512ifma', '    avx512pf', '    avx512vbmi', '    avx512vl', '    bmi1', '    bmi2', '    clflushopt', '    clfsh', '    clwb', '    cmov', '    cnxtid', '    CpuId', '    cx16', '    cx8', '    dca', '    de', '    ds', '    dscpl', '    dtes64', '    eist', '    erms', '    f16c', '    fma', '    fpu', '    fxsr', '    hle', '    htt', '    invpcid', '    mca', '    mce', '    mmx', '    monitor', '    movbe', '    mpx', '    msr', '    mtrr', '    osxsave', '    pae', '    pat', '    pbe', '    pcid', '    pclmuldq', '    pcommit', '    pdcm', '    pge', '    popcnt', '    prefetchwt1', '    pse', '    pse36', '    psn', '    rdrand', '    rdseed', '    rtm', '    sep', '    sha', '    smap', '    smep', '    smx', '    ss', '    sse', '    sse2', '    sse3', '    sse41', '    sse42', '    ssse3', '    tm', '    tm2', '    tsc', '    tscdeadline', '    vme', '    vmx', '    x2apic', '    xsave', '    xtpr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\cpuid_test.cc', [], ['    TEST(CpuIdTest,ShouldAlwaysHaveMMX)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\crash_op.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\create_autodiff_subgraphs.cpp', ['    SubgraphSlicer'], ['    CreateAutodiffSubgraphs(const std::shared_ptr & graph,size_t threshold)', '    inlineIfTooSmall(Node *n)', '    run(std::vector & diffGraphs)', '    scanNode(Node *consumer,AliasDb & aliasDb)', '    shouldConsiderForMerge(Node *node)', '    sortReverseTopological(ArrayRef inputs)', '    SubgraphSlicer(Block *block,std::shared_ptr graph,size_t minSubgraphSize)', '    tryMerge(Node *consumer,Node *producer,AliasDb & aliasDb)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\create_autodiff_subgraphs.h', [], ['    CreateAutodiffSubgraphs(const std::shared_ptr & graph,size_t threshold)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\create_db_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateDB', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateDB']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\create_db_op.h', ['    final'], ['    CreateDBOp(const OperatorDef & operator_def,Workspace *ws)', '    CreateDBOp', '    operator=', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\create_db_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACreateDB']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\create_functional_graphs.cpp', [], ['    CreateFunctionalGraphs(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(const std::shared_ptr & graph)', '    RemoveMutation(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(Block *block)', '    AnalyzeFunctionalSubset(Node *n)', '    AnalyzeFunctionalSubset(at::ArrayRef blocks)', '    AnalyzeFunctionalSubset(Block *block)', '    CreateFunctionalGraphsImpl(Block *block)', '    FunctionalGraphSlicer(std::shared_ptr graph)', '    inlineIfTooSmall(Node *n)', '    isEmptyFunctionalGraph(Node *n)', '    nonConstNodes(Block *block,size_t *num)', '    run', '    inplaceOpVariant(Node *n)', '    listAppendFollowingListConstruct(Node *n)', '    MutationRemover(const std::shared_ptr & graph)', '    newMemoryLocation(Value *v)', '    RemoveAtenMutation(Block *block)', '    RemoveListMutation(Block *block)', '    run', '    tryMakeCreationAndMutationAtomic(Value *mutated_value,Node *mutating_op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\create_functional_graphs.h', [], ['    CreateFunctionalGraphs(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(const std::shared_ptr & graph)', '    RemoveMutation(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\create_scope_op.cc', ['    C10FlagParser_caffe2_workspace_stack_debug'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateScope', '    CAFFE_ANONYMOUS_VARIABLE_CPUHasScope', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateScope', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HasScope', '    C10FlagParser_caffe2_workspace_stack_debug(const std::string & content)', '    RunOnDevice', '    RunOnDevice', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\create_scope_op.h', ['    WorkspaceStack', '    final', '    final'], ['    checkBindingsMatch(const std::unordered_map & bindings,const std::unordered_map & test_bindings)', '    checkStack', '    clear', '    empty', '    popGradientWorkspace(Workspace *parent_ws,const std::unordered_map & grad_blob_bindings)', '    pushForwardWorkspace(Workspace *parent_ws)', '    pushForwardWorkspace(Workspace *parent_ws,const std::unordered_map & blob_bindings)', '    reuseLastForwardWorkspace(Workspace *parent_ws)', '    reuseLastForwardWorkspace(Workspace *parent_ws,const std::unordered_map & blob_bindings)', '    WorkspaceStack', '    CreateScopeOp(Args,...)', '    HasScopeOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\crf_viterbi_op.cc', ['    SwapBestPathOp', '    ViterbiPathOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSwapBestPath', '    CAFFE_ANONYMOUS_VARIABLE_CPUViterbiPath', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SwapBestPath', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ViterbiPath', '    ColwiseMaxAndArg(const float *mat,int32_t N,int32_t D,float *colMax,int32_t *argMax)', '    RowwiseMaxAndArg(const float *mat,int32_t N,int32_t D,float *rowMax,int32_t *argMax)', '    RunOnDevice', '    SwapBestPathOp(Args,...)', '    AddColToMat(const TensorCPU & mat,const TensorCPU & col,TensorCPU *result)', '    GatherRow(const TensorCPU & data,int32_t rowIndex,int32_t block_size,int32_t block_bytesize,TensorCPU *outRow)', '    RunOnDevice', '    ViterbiPathOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Cross.cpp', [], ['    cross(const Tensor & input,const Tensor & other,const c10::optional dimension)', '    cross_out(Tensor & out,const Tensor & input,const Tensor & other,const c10::optional dimension)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Cross.h', [], ['    cross_stub', '    cross_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cross_entropy_op.cc', ['    GetLabelCrossEntropyGradient', '    GetCrossEntropyGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULabelCrossEntropy', '    CAFFE_ANONYMOUS_VARIABLE_CPULabelCrossEntropyGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUCrossEntropy', '    CAFFE_ANONYMOUS_VARIABLE_CPUCrossEntropyGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMakeTwoClass', '    CAFFE_ANONYMOUS_VARIABLE_CPUMakeTwoClassGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyWithLogits', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyWithLogitsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSigmoidCrossEntropyWithLogits', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSigmoidCrossEntropyWithLogitsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LabelCrossEntropy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LabelCrossEntropyGradient', '    sigmoid_partition(float lgt)', '    sigmoid_xent_backward(float lgt,float tgt)', '    sigmoid_xent_backward_with_log_d_trick(float lgt,float tgt)', '    sigmoid_xent_forward(float lgt,float tgt)', '    sigmoid_xent_forward_with_log_d_trick(float lgt,float tgt)', '    unjoined_sigmoid_xent_backward(float lgt,float tgt)', '    unjoined_sigmoid_xent_forward(float lgt,float tgt)', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CrossEntropy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CrossEntropyGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MakeTwoClass', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MakeTwoClassGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyWithLogits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyWithLogitsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSigmoidCrossEntropyWithLogits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSigmoidCrossEntropyWithLogitsGradient', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cross_entropy_op.h', ['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final'], ['    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    CrossEntropyGradientOp(Args,...)', '    CrossEntropyOp(Args,...)', '    LabelCrossEntropyGradientOp(Args,...)', '    LabelCrossEntropyOp(Args,...)', '    MakeTwoClassGradientOp(Args,...)', '    MakeTwoClassOp(Args,...)', '    RunOnDevice', '    SigmoidCrossEntropyWithLogitsGradientOp(Args,...)', '    SigmoidCrossEntropyWithLogitsOp(Args,...)', '    WeightedSigmoidCrossEntropyWithLogitsGradientOp(Args,...)', '    WeightedSigmoidCrossEntropyWithLogitsOp(Args,...)', '    ~CrossEntropyGradientOp', '    ~CrossEntropyOp', '    ~LabelCrossEntropyGradientOp', '    ~LabelCrossEntropyOp', '    ~MakeTwoClassGradientOp', '    ~MakeTwoClassOp', '    ~WeightedSigmoidCrossEntropyWithLogitsGradientOp', '    ~WeightedSigmoidCrossEntropyWithLogitsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\CrossKernel.cpp', [], ['    apply_cross(Tensor & result,const Tensor & a,const Tensor & b,const int64_t dim)', '    cross_kernel_impl(Tensor & result,const Tensor & a,const Tensor & b,const int64_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ctc_beam_search_decoder_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCTCBeamSearchDecoder', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTCBeamSearchDecoder', '    getTensorDataPtr(const Tensor & tensor,int t,int n)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ctc_beam_search_decoder_op.h', ['    CTCBeamSearchDecoderOp'], ['    CTCBeamSearchDecoderOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ctc_greedy_decoder_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCTCGreedyDecoder', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTCGreedyDecoder', '    getTensorDataPtr(const Tensor & tensor,int t,int n)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ctc_greedy_decoder_op.h', ['    CTCGreedyDecoderOp'], ['    CTCGreedyDecoderOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\warpctc\\ctc_op.cpp', ['    GetCTCGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCTC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTC', '    workspaceInfo(const CPUContext &)', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\warpctc\\ctc_op.h', ['    final'], ['    workspaceInfo(const Context & context)', '    CTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\warpctc\\ctc_op_gpu.cpp', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACTC', '    workspaceInfo(const CUDAContext & context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cube_op.cc', ['    GetCubeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCube', '    CAFFE_ANONYMOUS_VARIABLE_CPUCubeGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cube', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CubeGradient', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *X,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\cube_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp', [], ['    createCublasHandle(cublasHandle_t *handle)', '    destroyCublasHandle(cublasHandle_t handle)', '    getCurrentCUDABlasHandle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\cuda.cpp', [], ['    cudnn_is_available', '    device_count', '    is_available']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\cuda.h', [], ['    cudnn_is_available', '    device_count', '    is_available']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cuda_apply_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\cuda_codegen.cpp', ['    PrioritizeLoad', '    ScopedVarName'], ['    as_int(const Expr *expr)', '    getMajorMinor(const cudaDeviceProp *const prop,int & major,int & minor)', '    is_zero(const Expr *expr)', '    nvrtc', '    cudaDtypeCppString(const Dtype & dtype)', '    CudaSetContext(CUcontext pctx)', '    AddMemLoadsFromList(Stmt *stmt)', '    mutate(const Load *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const IfThenElse *v)', '    PopList', '    Process(Stmt *stmt)', '    PushList', '    call(const std::vector & args)', '    CompileToNVRTC(const std::string & code,const std::string & func_name)', '    GetUniqueFuncName(const std::string & func_prefix)', '    Initialize', '    visit(const For *v)', '    visit(const Intrinsics *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const LetStmt *v)', '    visit(const IfThenElse *v)', '    ScopedVarName(VarNameMap *mapping,const Var *var,const std::string & name)', '    ScopedVarName(UniqueNameManager *manager,const Var *var,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\cuda_codegen.h', ['    CudaCodeGen', '    CudaPrinter'], ['    call(const std::vector & args)', '    CompileToNVRTC(const std::string & code,const std::string & func_name)', '    CudaCodeGen(Stmt *stmt,Ts,...)', '    CudaCodeGen(Stmt *stmt,const std::vector & buffer_args,at::Device device)', '    GetUniqueFuncName(const std::string & func_prefix)', '    Initialize', '    name_manager', '    operator()(const Ts &,...)', '    os', '    ~CudaCodeGen', '    CudaPrinter(std::ostream *os,bool has_random)', '    gpu_block_extents', '    gpu_thread_extents', '    rand_func', '    visit(const For *v)', '    visit(const Intrinsics *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const LetStmt *v)', '    visit(const IfThenElse *v)', '    visit(const Cast *v)', '    name_manager', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cuda_cudnn_test.cpp', [], ['    TEST(CUDNNTest,CUDNNTestCUDA)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\cuda_enabled.h', [], ['    cuda_enabled']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\cuda_extension.cpp', [], ['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    sigmoid_add(torch::Tensor x,torch::Tensor y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\cuda_graph_fuser.cpp', [], ['    simple_mappable', '    CudaFuseGraph(std::shared_ptr & graph)', '    insert_guard', '    insert_guard', '    insert_guard', '    PeepholeOptimizeShapeExpressions(Block *block)', '    registerCudaFuseGraph', '    broadcastSizes(at::ArrayRef sizes)', '    isSimpleMap(Node *node)', '    allUsersAreThisConsumerOrCalcSizes(Node *consumer,Value *producer)', '    broadcast_tensors(value_list inputs)', '    buildShapeExpressions(Node *fusion_group)', '    calculatesSize(Node *node)', '    canFuseChunk(Node *consumer,Value *producer)', '    canFuseWithConcat(Value *producer,Node *before_check)', '    createFusedConcat(Node *node)', '    createSingletonCudaFusionGroup(Node *n)', '    findFusedChunk(Node *group,Value *input)', '    fuseChunk(Node *consumer,Value *producer)', '    fuseChunkByReusingExistingFusedChunk(Node *group,Node *chunk,Node *existingFusedChunk)', '    fuseConcats', '    getSubgraph(Node *n)', '    GraphFuser(Block *block,std::shared_ptr graph)', '    GraphFuser(Block *block,std::shared_ptr graph,FusionCallback callback,Symbol kind)', '    insertExplicitBroadcast(Node *node)', '    isFusable(Node *node)', '    isFusableCatNode(Node *node)', '    isFusableDefault(Node *node)', '    isFusableDevice(Value *v)', '    isFusableMap(Node *node)', '    mergeCudaFusionGroups(Node *consumer_group,Node *producer_group)', '    mergeNodeIntoGroup(Node *group,Node *n)', '    optimizeFusedGraphs', '    promoteChunkToBroadcastingChunk(Node *chunk)', '    refreshAliasDb', '    removeOutputsUsedOnlyInSize(Node *fusion_group)', '    replaceIntermediateBroadcastingChunks', '    run', '    scanNode(Node *consumer)', '    scanNodeForChunks(Node *consumer)', '    setInputArgLimit(size_t limit)', '    sortReverseTopological(ArrayRef inputs)', '    tensorInputs(Node *node)', '    tryFuse(Node *consumer,Value *producer)', '    tryToMoveChunk(Node *consumer,Value *producer)', '    usedOnlyInSize(Value *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\cuda_graph_fuser.h', [], ['    CudaFuseGraph(std::shared_ptr & graph)', '    registerCudaFuseGraph']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\cuda_half_support.h', ['    CudaHalfChecker'], ['    hasHalf', '    hasHalf_', '    visit(const Load *v)', '    visit(const Store *v)', '    dtype']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\cuda_lazy_init.cpp', [], ['    cuda_lazy_init', '    set_run_yet_variable_to_false']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\cuda_lazy_init.h', [], ['    maybe_initialize_cuda(const at::TensorOptions & options)', '    cuda_lazy_init', '    set_run_yet_variable_to_false']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\nccl\\cuda_nccl_gpu.cc', ['    NCCLContext', '    ncclTypeWrapper', '    ncclTypeWrapper'], ['    gContextsMutex', '    destroyContexts', '    getDevices(const NCCLExecution & ex)', '    getNCCLContext(const NCCLExecution & ex)', '    ncclKey(const NCCLExecution & ex)', '    runNCCL(const NCCLExecution & ex,InitF,F)', '    NCCLContext(const NCCLExecution & ex)', '    ~NCCLContext', '    AllGather(const NCCLExecution & ex)', '    AllReduce(const NCCLExecution & ex)', '    Reduce(const NCCLExecution & ex)', '    ReduceScatter(const NCCLExecution & ex)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\nccl\\cuda_nccl_gpu.h', ['    NCCL'], ['    destroyContexts', '    AllGather(const NCCLExecution & ex)', '    AllReduce(const NCCLExecution & ex)', '    Broadcast(const NCCLExecution & ex)', '    Reduce(const NCCLExecution & ex)', '    ReduceScatter(const NCCLExecution & ex)', '    device', '    dst', '    src', '    root', '    stream', '    stream_gpu_id']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\nccl\\cuda_nccl_op_gpu.cc', ['    final', '    final', '    final', '    final', '    final', '    NCCLBaseOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLAllGather', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLReduceScatter', '    AllInputsAre(OperatorBase *op)', '    getNCCLElements(OperatorBase *op,const CUDAContext & context)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLAllGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLAllreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLBroadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLReduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLReduceScatter', '    CostInference(const OperatorDef & def,const vector & inputs)', '    ShapeInference(const OperatorDef & def,const std::vector & in)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    NCCLBaseOp(const OperatorDef & operator_def,Workspace *ws)', '    ~NCCLBaseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\prof\\cuda_profile_ops.cc', ['    CudaProfileInitializeOp', '    CudaProfileStartOp', '    CudaProfileStopOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileInitialize', '    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileStart', '    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileStop', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileInitialize', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileStart', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileStop', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileInitialize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileStart', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileStop', '    CudaProfileInitializeOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    ~CudaProfileInitializeOp', '    CudaProfileStartOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    CudaProfileStopOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\cuda_random.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cuda_stream_test.cpp', [], ['    cuda_stream', '    cuda_stream', '    i', '    streams', '    TEST(TestStream,CopyAndMoveTest)', '    TEST(TestStream,GetAndSetTest)', '    TEST(TestStream,MultithreadGetAndSetTest)', '    TEST(TestStream,CUDAGuardTest)', '    TEST(TestStream,StreamPoolTest)', '    TEST(TestStream,MultiGPUTest)', '    TEST(TestStream,CUDAEventSyncTest)', '    TEST(TestStream,CrossDeviceTest)', '    TEST(TestStream,GenericInlineCUDAEventTest)', '    TEST(TestStream,GenericVirtualCUDAEventTest)', '    thread_fun(at::optional & cur_thread_stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\cuda_tensor_interop_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDABlas.cpp', [], ['    _cublasAdjustLdLevel2(int64_t m,int64_t n,int64_t *lda)', '    _cublasAdjustLdLevel3(char transa,char transb,int64_t m,int64_t n,int64_t k,int64_t *lda,int64_t *ldb,int64_t *ldc)', '    _cublasOpFromChar(char op)', '    _cublasGetErrorEnum(cublasStatus_t error)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *a,int64_t lda,const double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *a,int64_t lda,const float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    gemv(char trans,int64_t m,int64_t n,double alpha,const double *a,int64_t lda,const double *x,int64_t incx,double beta,double *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,float alpha,const float *a,int64_t lda,const float *x,int64_t incx,float beta,float *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *x,int64_t incx,at::Half beta,at::Half *y,int64_t incy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDABlas.h', [], ['    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,Dtype alpha,const Dtype *a,int64_t lda,const Dtype *b,int64_t ldb,Dtype beta,Dtype *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *a,int64_t lda,const double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *a,int64_t lda,const float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    gemv(char trans,int64_t m,int64_t n,Dtype alpha,const Dtype *a,int64_t lda,const Dtype *x,int64_t incx,Dtype beta,Dtype *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,double alpha,const double *a,int64_t lda,const double *x,int64_t incx,double beta,double *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,float alpha,const float *a,int64_t lda,const float *x,int64_t incx,float beta,float *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *x,int64_t incx,at::Half beta,at::Half *y,int64_t incy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDACachingAllocator.cpp', ['    THCCachingAllocator'], ['    assertValidDevice(int device)', '    BlockComparator(const Block *a,const Block *b)', '    format_size(uint64_t size)', '    cacheInfo(int dev_id,size_t *cachedAndFree,size_t *largestBlock)', '    emptyCache', '    get', '    getBaseAllocation(void *ptr,size_t *size)', '    getDeviceStats(int device)', '    getFreeMutex', '    getIpcDevPtr(std::string handle)', '    raw_alloc(size_t nbytes)', '    raw_alloc_with_stream(size_t nbytes,cudaStream_t stream)', '    raw_delete(void *ptr)', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    reset_accumulated_stat(Stat & stat)', '    reset_peak_stat(Stat & stat)', '    resetAccumulatedStats(int device)', '    resetPeakStats(int device)', '    snapshot', '    update_stat(Stat & stat,int64_t amount)', '    update_stat_array(StatArray & stat_array,int64_t amount,const StatTypes & stat_types)', '    RegistryName', '    find_free_block', '    Block(int device,cudaStream_t stream,size_t size,BlockPool *pool,void *ptr)', '    Block(int device,cudaStream_t stream,size_t size)', '    is_split', '    allocate(size_t size)', '    raw_deleter', '    cache_info_aux(BlockPool & blocks,int dev_id,size_t *total,size_t *largest)', '    cacheInfo(int dev_id,size_t *total,size_t *largest)', '    cuda_malloc_with_retry(int device,void **devPtr,size_t size)', '    emptyCache', '    find_allocated_block(void *ptr)', '    free(void *ptr)', '    free_block(Block *block)', '    free_blocks(BlockPool & blocks,BlockPool::iterator it,BlockPool::iterator end)', '    free_cached_blocks(int device)', '    get_all_blocks', '    get_allocation_size(size_t size)', '    get_pool(size_t size)', '    get_stat_type_for_pool(const BlockPool & pool)', '    get_stats_for_device(int device)', '    getBaseAllocation(void *ptr,size_t *outSize)', '    getCudaFreeMutex', '    getStatsForDevice(int dev_id)', '    insert_events(Block *block)', '    malloc(void **devPtr,size_t size,cudaStream_t stream)', '    process_events', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    resetAccumulatedStats(int dev_id)', '    resetPeakStats(int dev_id)', '    round_size(size_t size)', '    should_split(const Block *block,size_t size)', '    snapshot', '    synchronize_and_free_events(optional device)', '    THCCachingAllocator', '    try_merge_blocks(Block *dst,Block *src,BlockPool & pool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDACachingAllocator.h', ['    CUDAOutOfMemoryError', '    FreeMemoryCallback'], ['    cacheInfo(int dev_id,size_t *cachedAndFree,size_t *largestBlock)', '    emptyCache', '    get', '    getBaseAllocation(void *ptr,size_t *size)', '    getDeviceStats(int device)', '    getFreeMutex', '    getIpcDevPtr(std::string handle)', '    raw_alloc(size_t nbytes)', '    raw_alloc_with_stream(size_t nbytes,cudaStream_t stream)', '    raw_delete(void *ptr)', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    resetAccumulatedStats(int device)', '    resetPeakStats(int device)', '    snapshot', '    RegistryName', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)', '    Execute', '    ~FreeMemoryCallback']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAContext.cpp', [], ['    getCUDADeviceAllocator', '    getCurrentDeviceProperties', '    getDeviceProperties(int64_t device)', '    initCUDAContextVectors', '    initDeviceProperty(DeviceIndex device_index)', '    warp_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAContext.h', [], ['    getCUDADeviceAllocator', '    getCurrentCUDABlasHandle', '    getCurrentCUDASparseHandle', '    getCurrentDeviceProperties', '    getDeviceProperties(int64_t device)', '    getNumGPUs', '    is_available', '    warp_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDADevice.h', [], ['    getDeviceFromPtr(void *ptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAEvent.h', [], ['    block(const CUDAStream & stream)', '    createEvent(DeviceIndex device_index)', '    CUDAEvent(DeviceIndex device_index,const cudaIpcEventHandle_t *handle)', '    CUDAEvent(const CUDAEvent &)', '    CUDAEvent(CUDAEvent)', '    device', '    device_index', '    elapsed_time(const CUDAEvent & other)', '    event', '    ipc_handle(cudaIpcEventHandle_t *handle)', '    isCreated', '    moveHelper(CUDAEvent)', '    operator cudaEvent_t', '    operator=(const CUDAEvent &)', '    operator=(CUDAEvent)', '    query', '    record', '    record(const CUDAStream & stream)', '    recordOnce(const CUDAStream & stream)', '    synchronize', '    ~CUDAEvent', '    operator<(const CUDAEvent & left,const CUDAEvent & right)', '    CUDAEvent', '    CUDAEvent(unsigned int flags)', '    isCreated']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAException.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAFunctions.h', [], ['    current_device', '    device_count', '    set_device(DeviceIndex device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAGenerator.cpp', [], ['    initCUDAGenVector', '    createCUDAGenerator(DeviceIndex device_index)', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    clone', '    clone_impl', '    CUDAGenerator(DeviceIndex device_index)', '    current_seed', '    device_type', '    philox_engine_inputs(uint64_t increment)', '    philox_offset_per_thread', '    seed', '    set_current_seed(uint64_t seed)', '    set_philox_offset_per_thread(uint64_t offset)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\CUDAGenerator.h', [], ['    createCUDAGenerator(DeviceIndex device_index)', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    device_type', '    clone', '    clone_impl', '    CUDAGenerator(DeviceIndex device_index)', '    current_seed', '    philox_engine_inputs(uint64_t increment)', '    philox_offset_per_thread', '    seed', '    set_current_seed(uint64_t seed)', '    set_philox_offset_per_thread(uint64_t offset)', '    ~CUDAGenerator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAGuard.h', [], ['    CUDAGuard(DeviceIndex device_index)', '    CUDAGuard(Device device)', '    CUDAGuard', '    CUDAGuard', '    CUDAGuard', '    current_device', '    operator=', '    operator=', '    original_device', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    CUDAStreamGuard', '    CUDAStreamGuard(Stream stream)', '    CUDAStreamGuard', '    CUDAStreamGuard', '    current_device', '    current_stream', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    current_device', '    operator=', '    operator=', '    OptionalCUDAGuard', '    OptionalCUDAGuard', '    OptionalCUDAGuard', '    OptionalCUDAGuard(optional device_opt)', '    OptionalCUDAGuard(optional device_index_opt)', '    original_device', '    reset', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_stream', '    operator=', '    operator=', '    OptionalCUDAStreamGuard', '    OptionalCUDAStreamGuard(Stream stream)', '    OptionalCUDAStreamGuard(optional stream_opt)', '    OptionalCUDAStreamGuard', '    OptionalCUDAStreamGuard', '    original_stream', '    reset', '    reset_stream(Stream stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\impl\\CUDAGuardImpl.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\impl\\CUDAGuardImpl.h', [], ['    cs(s)', '    cuda_stream', '    cuda_stream', '    block(void *event,const Stream & stream)', '    createEvent(cudaEvent_t *cuda_event,const EventFlag flag)', '    CUDAGuardImpl', '    CUDAGuardImpl(DeviceType t)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDefaultStream(Device d)', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\detail\\CUDAHooks.cpp', [], ['    load_nvrtc', '    batchnormMinEpsilonCuDNN', '    compiledWithCuDNN', '    compiledWithMIOpen', '    cuFFTClearPlanCache(int64_t device_index)', '    cuFFTGetPlanCacheMaxSize(int64_t device_index)', '    cuFFTGetPlanCacheSize(int64_t device_index)', '    cuFFTSetPlanCacheMaxSize(int64_t device_index,int64_t max_size)', '    current_device', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    getDevceIndexWithPrimaryContext', '    getDeviceFromPtr(void *data)', '    getNumGPUs', '    getPinnedMemoryAllocator', '    hasCUDA', '    hasCuDNN', '    hasMAGMA', '    hasPrimaryContext(int64_t device_index)', '    initCUDA', '    isPinnedPtr(void *data)', '    nvrtc', '    showConfig', '    supportsDepthwiseConvolutionWithCuDNN', '    supportsDilatedConvolutionWithCuDNN', '    versionCuDNN']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\detail\\CUDAHooks.h', [], ['    batchnormMinEpsilonCuDNN', '    compiledWithCuDNN', '    compiledWithMIOpen', '    CUDAHooks(at::CUDAHooksArgs)', '    cuFFTClearPlanCache(int64_t device_index)', '    cuFFTGetPlanCacheMaxSize(int64_t device_index)', '    cuFFTGetPlanCacheSize(int64_t device_index)', '    cuFFTSetPlanCacheMaxSize(int64_t device_index,int64_t max_size)', '    current_device', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    getDevceIndexWithPrimaryContext', '    getDeviceFromPtr(void *data)', '    getNumGPUs', '    getPinnedMemoryAllocator', '    hasCUDA', '    hasCuDNN', '    hasMAGMA', '    hasPrimaryContext(int64_t device_index)', '    initCUDA', '    isPinnedPtr(void *data)', '    nvrtc', '    showConfig', '    supportsDepthwiseConvolutionWithCuDNN', '    supportsDilatedConvolutionWithCuDNN', '    versionCuDNN']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\CUDAHooksInterface.cpp', [], ['    getCUDAHooks', '    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\CUDAHooksInterface.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\CudaIPCTypes.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\CudaIPCTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAMacros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAMathCompat.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAMultiStreamGuard.h', ['    final'], ['    CUDAMultiStreamGuard(ArrayRef streams)', '    CUDAMultiStreamGuard', '    CUDAMultiStreamGuard', '    operator=', '    operator=', '    original_streams', '    ~CUDAMultiStreamGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\shared\\cudart.cpp', [], ['    initCudartBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAStream.cpp', ['    StreamIdType'], ['    check_gpu(DeviceIndex device_index)', '    CUDAStream_getStreamId(const LeakyStreamInternals *ptr)', '    get_idx(std::atomic & counter)', '    initCUDAStreamsOnce', '    initDeviceStreamState(DeviceIndex device_index)', '    initGlobalStreamState', '    pointer_within(const T *ptr,const A & arr)', '    streamIdIndex(StreamId s)', '    streamIdType(StreamId s)', '    CUDAStream_fromInternals(const LeakyStreamInternals *ptr)', '    CUDAStream_internals(CUDAStream s)', '    getCurrentCUDAStream(DeviceIndex device_index)', '    getDefaultCUDAStream(DeviceIndex device_index)', '    getStreamFromPool(const bool isHighPriority,DeviceIndex device_index)', '    makeStreamId(StreamIdType st,size_t si)', '    operator<<(std::ostream & stream,StreamIdType s)', '    operator<<(std::ostream & stream,const CUDAStream & s)', '    setCurrentCUDAStream(CUDAStream stream)', '    device_guard', '    i', '    i', '    i', '    stream', '    ~LeakyStreamInternals']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\CUDAStream.h', ['    CUDAStream'], ['    getCurrentCUDAStream(DeviceIndex device_index)', '    getDefaultCUDAStream(DeviceIndex device_index)', '    getStreamFromPool(const bool isHighPriority,DeviceIndex device_index)', '    operator<<(std::ostream & stream,const CUDAStream & s)', '    setCurrentCUDAStream(CUDAStream stream)', '    guard', '    guard', '    guard', '    priority_range', '    unpack(uint64_t bits)', '    CUDAStream(Stream stream)', '    CUDAStream(Unchecked,Stream stream)', '    device', '    device_index', '    id', '    operator cudaStream_t', '    operator Stream', '    operator!=(const CUDAStream & other)', '    operator==(const CUDAStream & other)', '    pack', '    priority', '    query', '    stream', '    synchronize', '    unwrap', '    operator()(c10::cuda::CUDAStream s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\test\\impl\\CUDATest.cpp', [], ['    TEST(CUDATest,SmokeTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\impl\\CUDATest.cpp', [], ['    c10_cuda_private_test', '    c10_cuda_test', '    has_cuda_gpu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\cuda\\impl\\CUDATest.h', [], ['    c10_cuda_test']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\CUDATest.hpp', [], ['    cudaNumDevices', '    cudaSleep(at::cuda::CUDAStream & stream,uint64_t clocks)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\CUDAUnaryOps.cpp', [], ['    _atan__cuda(Tensor & self)', '    _atan_out_cuda(Tensor & result,const Tensor & self)', '    _clamp__cuda(Tensor & self,optional min,optional max)', '    _clamp_max__cuda(Tensor & self,Scalar max)', '    _clamp_max_out_cuda(Tensor & result,const Tensor & self,Scalar max)', '    _clamp_min__cuda(Tensor & self,Scalar min)', '    _clamp_min_out_cuda(Tensor & result,const Tensor & self,Scalar min)', '    _clamp_out_cuda(Tensor & result,const Tensor & self,optional min,optional max)', '    _cos__cuda(Tensor & self)', '    _cos_out_cuda(Tensor & result,const Tensor & self)', '    _cosh__cuda(Tensor & self)', '    _cosh_out_cuda(Tensor & result,const Tensor & self)', '    _erf__cuda(Tensor & self)', '    _erf_out_cuda(Tensor & result,const Tensor & self)', '    _erfc__cuda(Tensor & self)', '    _erfc_out_cuda(Tensor & result,const Tensor & self)', '    _exp__cuda(Tensor & self)', '    _exp_out_cuda(Tensor & result,const Tensor & self)', '    _tan__cuda(Tensor & self)', '    _tan_out_cuda(Tensor & result,const Tensor & self)', '    _tanh__cuda(Tensor & self)', '    _tanh_out_cuda(Tensor & result,const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CUDAUtils.h', [], ['    check_device(ArrayRef ts)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\cudnn-wrapper.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\shared\\cudnn.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\cudnn_extension.cpp', [], ['    cudnn_relu(const torch::Tensor & inputs,const torch::Tensor & outputs)', '    cudnn_relu_check(const torch::Tensor & inputs,const torch::Tensor & outputs)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\cudnn_wrappers.h', ['    CuDNNState', '    CuDNNWrapper'], ['    f(this)', '    cudnn_states', '    after_', '    before_', '    cudnn_handle', '    cudnn_handle_', '    CuDNNState(size_t gpu_id)', '    CuDNNState', '    execute(cudaStream_t stream,F)', '    gpu_id_', '    operator=', '    stream_', '    workspace', '    ~CuDNNState', '    clear', '    data_', '    get(size_t nbytes)', '    nbytes_', '    reset', '    ~CuDNNWorkspace', '    CuDNNWrapper(CUDAContext *context)', '    CuDNNWrapper', '    inline_cudnn_handle', '    operator=', '    with_cudnn_state(size_t state_idx,F)', '    cudnn_handle', '    New']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\CuFFTPlanCache.h', ['    CuFFTConfig', '    CuFFTParamsLRUCache'], ['    is_pow_of_two(int64_t x)', '    setCuFFTParams(CuFFTParams *params,const Tensor & input,int64_t signal_ndim,bool complex_input,bool complex_output,IntArrayRef checked_signal_sizes,bool onesided)', '    cufft_clear_plan_cache_impl(int64_t device_index)', '    cufft_get_plan_cache_max_size_impl(int64_t device_index)', '    cufft_get_plan_cache_size_impl(int64_t device_index)', '    cufft_set_plan_cache_max_size_impl(int64_t device_index,int64_t max_size)', '    static_assert(CUFFT_MAX_PLAN_NUM,)', '    static_assert(CUFFT_DEFAULT_CACHE_SIZE,)', '    CuFFTConfig', '    CuFFTConfig(Tensor & input,int64_t signal_ndim,bool complex_input,bool complex_output,IntArrayRef checked_signal_sizes,bool onesided,IntArrayRef output_sizes)', '    operator=', '    plan', '    should_clone_input', '    workspace_size', '    operator()(cufftHandle *x)', '    _set_max_size(int64_t new_size)', '    clear', '    CuFFTParamsLRUCache', '    CuFFTParamsLRUCache(int64_t max_size)', '    CuFFTParamsLRUCache(CuFFTParamsLRUCache)', '    max_size', '    operator=(CuFFTParamsLRUCache)', '    resize(int64_t new_size)', '    size', '    try_emplace_value(K,VArgs,...)', '    prod_intlist', '    dim', '    is_contiguous', '    scalar_type', '    size', '    sizes', '    slice', '    stride', '    strides', '    forward_as_tuple']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\CuFFTUtils.h', [], ['    _cudaGetErrorEnum(cufftResult error)', '    CUFFT_CHECK(cufftResult error)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\CuSparseHandlePool.cpp', [], ['    createCusparseHandle(cusparseHandle_t *handle)', '    destroyCusparseHandle(cusparseHandle_t handle)', '    getCurrentCUDASparseHandle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\custom_batch_request.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\custom_class.cpp', [], ['    registerCustomClassMethod(std::unique_ptr fn)', '    customClasses', '    getCustomClass(const std::string & name)', '    isCustomClass(const c10::IValue & v)', '    registerCustomClass(at::ClassTypePtr class_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\custom_class.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\custom_class_detail.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\custom_function.cpp', [], ['    _wrap_outputs(const variable_list & input_vars,const std::unordered_set & non_differentiable,const std::unordered_set & dirty_inputs,const at::ArrayRef raw_outputs,const std::shared_ptr & cdata)', '    check_variable_result(const Variable & original,const Variable & result,std::string hook_name)', '    get_and_bump_dirty', '    get_non_differentiable', '    get_saved_variables', '    mark_dirty(const variable_list & inputs)', '    mark_non_differentiable(const variable_list & outputs)', '    save_for_backward(variable_list to_save)', '    save_variables', '    VariableInfo(const Variable & var)', '    zeros(at::OptionalDeviceGuard & device_guard)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\custom_function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\custom_operator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\cvtsh_ss_bugfix.h', [], ['    _cvtsh_ss(unsigned short x)', '    _cvtss_sh(float x,int imm8)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\data_couple.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDataCouple', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DataCouple']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\data_couple.h', ['    DataCoupleOp'], ['    DataCoupleOp(Args,...)', '    RunOnDevice', '    ~DataCoupleOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\data_filler.cc', [], ['    fill_with_type(const TensorFiller & filler,const std::string & type,TensorCPU *output)', '    fillRandomNetworkInputs(const NetDef & net,const std::vector,const std::vector,Workspace *workspace)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    DataRandomFiller(const NetDef & run_net,const std::vector,const std::vector)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    fillInputToWorkspace(Workspace *workspace)', '    TestDataRandomFiller(const NetDef & net,const std::vector,const std::vector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\data_filler.h', ['    DataNetFiller', '    DataRandomFiller', '    Filler', '    TestDataRandomFiller'], ['    fill_with_type(const TensorFiller & filler,const std::string & type,TensorCPU *output)', '    fillRandomNetworkInputs(const NetDef & net,const std::vector,const std::vector,Workspace *workspace)', '    get_tensor_filler(const OperatorDef & op_def,int input_index,const std::vector)', '    DataNetFiller(const NetDef,const NetDef)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    DataRandomFiller(const NetDef & run_net,const std::vector,const std::vector)', '    DataRandomFiller', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    fill_input(TensorList_t *input_data)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    get_input_names', '    ~Filler', '    fillInputToWorkspace(Workspace *workspace)', '    TestDataRandomFiller(const NetDef & net,const std::vector,const std::vector)', '    CreateBlob', '    InputFillers', '    Schema']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\data_filler_test.cc', [], ['    TEST(DataFiller,FillNetInputTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\parallel\\data_parallel.h', [], ['    data_parallel(ModuleType module,Tensor input,optional,optional output_device,int64_t dim)', '    parallel_apply(std::vector & modules,const std::vector & inputs,const optional)', '    replicate_grad_edges(const std::shared_ptr & module,const std::vector,const std::vector & devices)', '    replicate_grad_edges(module,replicas,devices)', '    Gather', '    current_exception', '    device', '    forward', '    size', '    to', '    collect_next_edges', '    apply(autograd::variable_list)', '    ReduceAdd(const at::Device & destination_device)', '    ~ReduceAdd']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\detail\\data_shuttle.h', ['    DataShuttle'], ['    drain', '    in_flight_jobs', '    pop_job', '    pop_result(optional timeout)', '    push_job(Job job)', '    push_result(Result result)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\dataloader.cpp', ['    S'], ['    counter', '    d', '    getter', '    output1', '    output1', '    output2', '    output2', '    rand_gen', '    sorting_policy', '    TEST(DataTest,DatasetCallsGetCorrectly)', '    TEST(DataTest,TransformCallsGetApplyCorrectly)', '    TEST(DataTest,ChunkDataSetWithInvalidInitParameter)', '    TEST(DataTest,InfiniteStreamDataset)', '    TEST(DataTest,NoSequencerIsIdentity)', '    TEST(DataTest,OrderedSequencerIsSetUpWell)', '    TEST(DataTest,OrderedSequencerReOrdersValues)', '    TEST(DataTest,BatchLambdaAppliesFunctionToBatch)', '    TEST(DataTest,LambdaAppliesFunctionToExample)', '    TEST(DataTest,CollateReducesBatch)', '    TEST(DataTest,CollationReducesBatch)', '    TEST(DataTest,SequentialSamplerReturnsIndicesInOrder)', '    TEST(DataTest,SequentialSamplerReturnsLessValuesForLastBatch)', '    TEST(DataTest,SequentialSamplerResetsWell)', '    TEST(DataTest,SequentialSamplerResetsWithNewSizeWell)', '    TEST(DataTest,CanSaveAndLoadSequentialSampler)', '    TEST(DataTest,RandomSamplerReturnsIndicesInCorrectRange)', '    TEST(DataTest,RandomSamplerReturnsLessValuesForLastBatch)', '    TEST(DataTest,RandomSamplerResetsWell)', '    TEST(DataTest,RandomSamplerResetsWithNewSizeWell)', '    TEST(DataTest,SavingAndLoadingRandomSamplerYieldsSameSequence)', '    TEST(DataTest,StreamSamplerReturnsTheBatchSizeAndThenRemainder)', '    TEST(DataTest,StreamSamplerResetsWell)', '    TEST(DataTest,StreamSamplerResetsWithNewSizeWell)', '    TEST(DataTest,TensorDatasetConstructsFromSingleTensor)', '    TEST(DataTest,TensorDatasetConstructsFromInitializerListOfTensors)', '    TEST(DataTest,StackTransformWorksForExample)', '    TEST(DataTest,StackTransformWorksForTensorExample)', '    TEST(DataTest,TensorTransformWorksForAnyTargetType)', '    TEST(DataTest,TensorLambdaWorksforAnyTargetType)', '    TEST(DataTest,NormalizeTransform)', '    TEST(DataTest,MapDoesNotCopy)', '    TEST(DataTest,QueuePushAndPopFromSameThread)', '    TEST(DataTest,QueuePopWithTimeoutThrowsUponTimeout)', '    TEST(DataTest,QueuePushAndPopFromDifferentThreads)', '    TEST(DataTest,QueueClearEmptiesTheQueue)', '    TEST(DataTest,DataShuttleCanPushAndPopJob)', '    TEST(DataTest,DataShuttleCanPushAndPopResult)', '    TEST(DataTest,DataShuttlePopResultReturnsNulloptWhenNoJobsInFlight)', '    TEST(DataTest,DataShuttleDrainMeansPopResultReturnsNullopt)', '    TEST(DataTest,DataShuttlePopResultTimesOut)', '    TEST(DataTest,SharedBatchDatasetReallyIsShared)', '    TEST(DataTest,SharedBatchDatasetDoesNotIncurCopyWhenPassedDatasetObject)', '    TEST(DataTest,CanUseCustomTypeAsIndexType)', '    TEST(DataTest,DistributedRandomSamplerSingleReplicaProduceCorrectSamples)', '    TEST(DataTest,DistributedRandomSamplerMultiReplicaProduceCorrectSamples)', '    TEST(DataTest,CanSaveAndLoadDistributedRandomSampler)', '    TEST(DataTest,DistributedSequentialSamplerSingleReplicaProduceCorrectSamples)', '    TEST(DataTest,DistributedSequentialSamplerMultiReplicaProduceCorrectSamples)', '    TEST(DataTest,CanSaveAndLoadDistributedSequentialSampler)', '    TEST(DataLoaderTest,DataLoaderOptionsDefaultAsExpected)', '    TEST(DataLoaderTest,DataLoaderOptionsCoalesceOptionalValues)', '    TEST(DataLoaderTest,MakeDataLoaderDefaultsAsExpected)', '    TEST(DataLoaderTest,MakeDataLoaderThrowsWhenConstructingSamplerWithUnsizedDataset)', '    TEST(DataLoaderTest,IteratorsCompareEqualToThemselves)', '    TEST(DataLoaderTest,ValidIteratorsCompareUnequalToEachOther)', '    TEST(DataLoaderTest,SentinelIteratorsCompareEqualToEachOther)', '    TEST(DataLoaderTest,IteratorsCompareEqualToSentinelWhenExhausted)', '    TEST(DataLoaderTest,IteratorsShareState)', '    TEST(DataLoaderTest,CanDereferenceIteratorMultipleTimes)', '    TEST(DataLoaderTest,CanUseIteratorAlgorithms)', '    TEST(DataLoaderTest,CallingBeginWhileOtherIteratorIsInFlightThrows)', '    TEST(DataLoaderTest,IncrementingExhaustedValidIteratorThrows)', '    TEST(DataLoaderTest,DereferencingExhaustedValidIteratorThrows)', '    TEST(DataLoaderTest,IncrementingSentinelIteratorThrows)', '    TEST(DataLoaderTest,DereferencingSentinelIteratorThrows)', '    TEST(DataLoaderTest,YieldsCorrectBatchSize)', '    TEST(DataLoaderTest,ReturnsLastBatchWhenSmallerThanBatchSizeWhenDropLastIsFalse)', '    TEST(DataLoaderTest,DoesNotReturnLastBatchWhenSmallerThanBatchSizeWhenDropLastIsTrue)', '    TEST(DataLoaderTest,RespectsTimeout)', '    TEST(DataLoaderTest,EnforcesOrderingAmongThreadsWhenConfigured)', '    TEST(DataLoaderTest,Reset)', '    TEST(DataLoaderTest,TestExceptionsArePropagatedFromWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithNoWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithManyWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithMap)', '    TEST(DataLoaderTest,StatefulDatasetWithCollate)', '    TEST(DataLoaderTest,ChunkDataSetGetBatch)', '    TEST(DataLoaderTest,ChunkDataSetWithBatchSizeMismatch)', '    TEST(DataLoaderTest,ChunkDataSetWithEmptyBatch)', '    TEST(DataLoaderTest,ChunkDataSetGetBatchWithUnevenBatchSize)', '    TEST(DataLoaderTest,CanAccessChunkSamplerWithChunkDataSet)', '    TEST(DataLoaderTest,ChunkDatasetDoesNotHang)', '    TEST(DataLoaderTest,ChunkDatasetSave)', '    TEST(DataLoaderTest,ChunkDatasetLoad)', '    TEST(DataLoaderTest,ChunkDatasetCrossChunkShuffle)', '    TEST(DataLoaderTest,CustomPreprocessPolicy)', '    Barrier(size_t target)', '    wait', '    chunk_count', '    chunk_count', '    chunk_count', '    D(std::shared_ptr b)', '    D(size_t chunk_count)', '    D(size_t chunk_count)', '    get(size_t index)', '    get(size_t index)', '    get(size_t index)', '    get_batch(torch::ArrayRef indices)', '    get_batch(size_t)', '    get_batch(size_t)', '    get_batch(size_t)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    override', '    read_chunk(size_t chunk_index)', '    read_chunk(size_t chunk_index)', '    read_chunk(size_t chunk_index)', '    reset', '    reset', '    reset', '    reset', '    reset', '    reset', '    reset', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    size', '    size', '    size', '    size', '    size', '    size', '    size', '    size', '    tensor', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    DummyDataset(size_t size)', '    get(size_t index)', '    size', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    get(size_t index)', '    size', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    get_batch(size_t batch_size)', '    size', '    Dataset(const Dataset & other)', '    get_batch(torch::ArrayRef indices)', '    size', '    index_', '    load(torch::serialize::InputArchive & archive)', '    override', '    reset(torch::optional new_size)', '    S(size_t size)', '    save(torch::serialize::OutputArchive & archive)', '    vector', '    apply_batch(std::vector input)', '    apply(int input)', '    operator()(torch::Tensor input)', '    get(size_t index)', '    size', '    size', '    TestIndex(size_t offset,std::vector index)', '    get_batch(TestIndex index)', '    size', '    TestIndexDataset(size_t size)', '    load(torch::serialize::InputArchive & archive)', '    next(size_t batch_size)', '    reset(torch::optional new_size)', '    save(torch::serialize::OutputArchive & archive)', '    TestIndexSampler(size_t size)', '    get(size_t index)', '    get(size_t index)', '    size', '    size', '    UncopyableDataset(const std::string &)', '    get(size_t i)', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\DataLoader.cpp', [], ['    THPModule_errorIfAnyWorkerFails(PyObject *module,PyObject *_ignored)', '    THPModule_removeWorkerPIDs(PyObject *module,PyObject *_ignored)', '    THPModule_setWorkerPIDs(PyObject *module,PyObject *_ignored)', '    THPModule_setWorkerSignalHandlers(PyObject *module,PyObject *_ignored)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\dataloader.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\DataLoader.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\dataloader_options.h', [], ['    drop_last(const bool & new_drop_last)', '    drop_last(bool)', '    drop_last', '    drop_last', '    enforce_ordering(const bool & new_enforce_ordering)', '    enforce_ordering(bool)', '    enforce_ordering', '    enforce_ordering', '    max_jobs(const optional & new_max_jobs)', '    max_jobs(optional)', '    max_jobs', '    max_jobs', '    timeout(const optional & new_timeout)', '    timeout(optional)', '    timeout', '    timeout', '    batch_size', '    batch_size', '    batch_size(size_t)', '    workers(const size_t & new_workers)', '    workers(size_t)', '    workers', '    workers', '    FullDataLoaderOptions(DataLoaderOptions options)', '    batch_size(const size_t & new_batch_size)', '    DataLoaderOptions', '    DataLoaderOptions(size_t batch_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dataset_ops.cc', ['    CheckDatasetConsistencyOp', '    ComputeOffsetOp', '    CreateTreeCursorOp', '    final', '    final', '    final', '    final', '    final', '    final', '    GetCursorOffsetOp', '    PackRecordsOp', '    ReadNextBatchOp', '    ReadRandomBatchOp', '    ResetCursorOp', '    SortAndShuffleOp', '    TreeCursorDeserializer', '    TreeCursorSerializer', '    TrimDatasetOp', '    UnPackRecordsOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAppend', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicAppend', '    CAFFE_ANONYMOUS_VARIABLE_CPUCheckDatasetConsistency', '    CAFFE_ANONYMOUS_VARIABLE_CPUCollectTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUComputeOffset', '    CAFFE_ANONYMOUS_VARIABLE_CPUConcatTensorVector', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTensorVector', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTreeCursor', '    CAFFE_ANONYMOUS_VARIABLE_CPUGetCursorOffset', '    CAFFE_ANONYMOUS_VARIABLE_CPUPackRecords', '    CAFFE_ANONYMOUS_VARIABLE_CPUReadNextBatch', '    CAFFE_ANONYMOUS_VARIABLE_CPUReadRandomBatch', '    CAFFE_ANONYMOUS_VARIABLE_CPUResetCursor', '    CAFFE_ANONYMOUS_VARIABLE_CPUSortAndShuffle', '    CAFFE_ANONYMOUS_VARIABLE_CPUTensorVectorSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUTrimDataset', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnPackRecords', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Append', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicAppend', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckDatasetConsistency', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ComputeOffset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatTensorVector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTensorVector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTreeCursor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetCursorOffset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackRecords', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReadNextBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReadRandomBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResetCursor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortAndShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorVectorSize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TrimDataset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnPackRecords', '    noexcept', '    CheckDatasetConsistencyOp(Args,...)', '    RunOnDevice', '    ComputeOffsetOp(Args,...)', '    RunOnDevice', '    CreateTreeCursorOp(Args,...)', '    RunOnDevice', '    AppendOp(Args,...)', '    AtomicAppendOp(Args,...)', '    CollectTensorOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    TensorVectorSizeOp(Args,...)', '    ~TensorVectorSizeOp', '    GetCursorOffsetOp(Args,...)', '    RunOnDevice', '    PackRecordsOp(Args,...)', '    RunOnDevice', '    ReadNextBatchOp(Args,...)', '    RunOnDevice', '    ReadRandomBatchOp(Args,...)', '    RunOnDevice', '    ResetCursorOp(Args,...)', '    RunOnDevice', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    RunOnDevice', '    SortAndShuffleOp(Args,...)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    TreeCursorSerializer', '    ~TreeCursorSerializer', '    advance(const std::vector & lengths,std::vector & offsets,std::vector & sizes,std::vector & limits,TOffset num)', '    TreeIterator(const std::vector & fields)', '    advance', '    fieldDim(int fieldId)', '    fieldPtr(int fieldId)', '    gatherLengthData', '    gatherSizeLimits', '    TreeWalker(const vector & inputs,TreeCursor & cursor)', '    RunOnDevice', '    TrimDatasetOp(Args,...)', '    getShapeAndMetaFromInput(std::vector,std::vector & metas)', '    getShapeAndMetaFromPrototypeBlobs(std::vector,std::vector & metas)', '    RunOnDevice', '    UnPackRecordsOp(Args,...)', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dataset_ops.h', ['    SharedTensorVectorPtrDeserializer', '    SharedTensorVectorPtrSerializer', '    TreeCursor', '    TreeIterator', '    TreeWalker', '    Field'], ['    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    TreeCursor(const TreeIterator & iterator)', '    advance(const std::vector & lengths,std::vector & offsets,std::vector & sizes,std::vector & limits,TOffset num)', '    fields', '    lengthField(int lengthFieldId)', '    lengthFieldFor(const FieldDesc & desc)', '    lengthFieldIds', '    numLengthFields', '    numOffsetFields', '    offsetFieldIdFor(const FieldDesc & fieldDesc)', '    TreeIterator(const std::vector & fields)', '    advance', '    field(int idx)', '    dim', '    Field(TreeWalker & walker,int fieldId)', '    fieldId', '    meta', '    offset', '    ptr', '    size', '    fieldDim(int fieldId)', '    fieldPtr(int fieldId)', '    fields', '    gatherLengthData', '    gatherSizeLimits', '    input(int32_t idx)', '    lengthIdx(int fieldId)', '    offset(int fieldId)', '    size', '    TreeWalker(const vector & inputs,TreeCursor & cursor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\db.cc', ['    MiniDB', '    MiniDBCursor', '    MiniDBTransaction'], ['    RegistryName', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Close', '    MiniDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    ~MiniDB', '    key', '    MiniDBCursor(FILE *f,std::mutex *mutex)', '    Next', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    ~MiniDBCursor', '    Commit', '    MiniDBTransaction(FILE *f,std::mutex *mutex)', '    Put(const string & key,const string & value)', '    ~MiniDBTransaction', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\db.h', ['    Cursor', '    DB', '    DBReader', '    DBReaderDeserializer', '    DBReaderSerializer', '    Transaction'], ['    CreateDB(const string & db_type,const string & source,Mode mode)', '    DBExists(const string & db_type,const string & full_db_name)', '    RegistryName', '    Cursor', '    Cursor', '    key', '    Next', '    operator=', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~Cursor', '    Close', '    DB(const string &,Mode mode)', '    DB', '    NewCursor', '    NewTransaction', '    operator=', '    ~DB', '    cursor', '    DBReader', '    DBReader(const string & db_type,const string & source,const int32_t num_shards,const int32_t shard_id)', '    DBReader(const DBReaderProto & proto)', '    DBReader(std::unique_ptr db)', '    DBReader', '    InitializeCursor(const int32_t num_shards,const int32_t shard_id)', '    MoveToBeginning', '    num_shards_', '    Open(const string & db_type,const string & source,const int32_t num_shards,const int32_t shard_id)', '    Open(unique_ptr,const int32_t num_shards,const int32_t shard_id)', '    operator=', '    Read(string *key,string *value)', '    SeekToFirst', '    shard_id_', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Commit', '    operator=', '    Put(const string & key,const string & value)', '    Transaction', '    Transaction', '    ~Transaction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\db_test.cc', [], ['    CreateAndFill(const string & db_type,const string & name)', '    DBSeekTestWrapper(const string & db_type)', '    TestCursor(Cursor *cursor)', '    TEST(DBSeekTest,RocksDB)', '    TEST(DBSeekTest,LevelDB)', '    TEST(DBSeekTest,LMDB)', '    TEST(DBReaderTest,Reader)', '    TEST(DBReaderShardedTest,Reader)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\db_throughput.cc', ['    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_num_read_threads', '    C10FlagParser_repeat', '    C10FlagParser_report_interval', '    C10FlagParser_use_reader'], ['    main(int argc,char **argv)', '    TestThroughputWithDB', '    TestThroughputWithReader', '    TestThroughputWithReaderWorker(const DBReader *reader,int thread_id)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_num_read_threads(const std::string & content)', '    C10FlagParser_repeat(const std::string & content)', '    C10FlagParser_report_interval(const std::string & content)', '    C10FlagParser_use_reader(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\ddp.cpp', [], ['    copyBroadcastTensorsToReplicas(const std::vector,std::vector)', '    distBroadcastCoalesced(ProcessGroup & processGroup,std::vector & tensors,int64_t bufferSize,bool fineGrained)', '    queueReduction(ProcessGroup & processGroup,std::vector,const std::vector & devices)', '    syncParams(ProcessGroup & processGroup,std::vector,std::vector,const std::vector & devices,int64_t broadcastBucketSize,bool broadcastBuffers)', '    syncReduction(std::shared_ptr & reductionWork,std::vector & gradsBatch,at::Tensor & gradsBatchCoalesced)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\ddp.h', [], ['    distBroadcastCoalesced(ProcessGroup & processGroup,std::vector & tensors,int64_t bufferSize,bool fineGrained)', '    queueReduction(ProcessGroup & processGroup,std::vector,const std::vector & devices)', '    syncParams(ProcessGroup & processGroup,std::vector,std::vector,const std::vector & devices,int64_t broadcastBucketSize,bool broadcastBuffers)', '    syncReduction(std::shared_ptr & reductionWork,std::vector & gradsBatch,at::Tensor & gradsBatchCoalesced)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\dead_code_elim.cc', ['    DeadCodeElim'], ['    deadCodeElim(NNModule *nn)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\dead_code_elim_test.cc', [], ['    TEST(DeadCodeElim,BasicElim)', '    TEST(DeadCodeElim,BasicNoElim)', '    TEST(DeadCodeElim,PartiallyUsedNoElim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\dead_code_elimination.cpp', ['    DeadCodeEliminator'], ['    EliminateDeadCode(const std::shared_ptr & graph,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,bool recurse,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,std::function cb,DCESideEffectPolicy sideEffectPolicy)', '    DeadCodeEliminator(std::shared_ptr graph,DCESideEffectPolicy sideEffectPolicy)', '    DeadCodeEliminator(DCESideEffectPolicy sideEffectPolicy)', '    eliminateDeadForkInputs(Block *block,bool recurse)', '    hasSideEffects(Node *node)', '    hasUntrackedMutation(Node *node)', '    logDeadLoopOutputs(Node *node,size_t i,size_t loop_input_offset,size_t loop_body_offset)', '    mark(Block *block)', '    mark(Node *node)', '    markIfLive(Node *node)', '    markLoop(Node *node)', '    markReturnNode(Node *node)', '    removeDeadBlockOutputs(Node *node)', '    removeDeadLoopOutputs(Node *node)', '    run(Block *block,bool recurse)', '    setDeleteCallback(std::function deleteCallback)', '    sweep(Block *block,bool recurse)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\dead_code_elimination.h', ['    DCESideEffectPolicy'], ['    EliminateDeadCode(const std::shared_ptr & graph,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,bool recurse,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,std::function cb,DCESideEffectPolicy sideEffectPolicy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\decompose_ops.cpp', [], ['    inputs', '    inputs', '    insert_guard', '    insert_guard', '    DecomposeOps(Block *block,CompilationUnit & decompose_funcs)', '    DecomposeOps(std::shared_ptr & graph)', '    aliasAnalysisFromSchema', '    isDecomposableNorm(Node *normalize_op)', '    isDefined(Value *tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\decompose_ops.h', [], ['    DecomposeOps(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\deconvolution-operator-tester.h', ['    DeconvolutionOperatorTester'], ['    adjustmentHeight(uint32_t adjustmentHeight)', '    adjustmentHeight', '    adjustmentHeight_', '    adjustmentWidth(uint32_t adjustmentWidth)', '    adjustmentWidth', '    adjustmentWidth_', '    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    dilatedKernelHeight', '    dilatedKernelWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    groupInputChannels(size_t groupInputChannels)', '    groupInputChannels', '    groupInputChannels_', '    groupOutputChannels(size_t groupOutputChannels)', '    groupOutputChannels', '    groupOutputChannels_', '    groups(uint32_t groups)', '    groups', '    groups_', '    inputHeight(uint32_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(uint32_t inputHeight,uint32_t inputWidth)', '    inputWidth(uint32_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize(uint32_t kernelSize)', '    kernelSize(uint32_t kernelHeight,uint32_t kernelWidth)', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingHeight', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    paddingWidth', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\deconvolution.c', [], ['    compute_output_dimension(size_t input_dimension,size_t input_padding_dimension,size_t adjustment_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_deconvolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t adjustment_height,uint32_t adjustment_width,uint32_t kernel_height,uint32_t kernel_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *deconvolution_out)', '    pytorch_qnnp_setup_deconvolution2d_nhwc_q8(pytorch_qnnp_operator_t deconvolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\deconvolution.cc', [], ['    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP,zero_batch)', '    TEST(DECONVOLUTION_OP,grouped_1x1)', '    TEST(DECONVOLUTION_OP,grouped_1x3)', '    TEST(DECONVOLUTION_OP,grouped_3x1)', '    TEST(DECONVOLUTION_OP,grouped_3x3)', '    TEST(DECONVOLUTION_OP)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DefaultDtype.cpp', [], ['    get_default_complex_dtype', '    get_default_dtype', '    set_default_dtype(caffe2::TypeMeta dtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DefaultDtype.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DefaultTensorOptions.h', [], ['    getDefaultTensorOptions', '    device', '    dtype', '    layout', '    requires_grad']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\deform_conv_gradient_op.cc', ['    GetDeformConvGradient'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DeformConvGradient', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\deform_conv_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DeformConv']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\deform_conv_op.h', ['    DeformConvOpBase', '    final', '    final'], ['    DeformableCol2im(const T *data_col,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *grad_im)', '    DeformableCol2imCoord(const T *data_col,const T *data_im,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *grad_offset)', '    DeformableIm2col(const T *data_im,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *data_col)', '    DeformConvOpBase(const OperatorDef & operator_def,Workspace *ws)', '    ~DeformConvOpBase', '    col_buffer_', '    col_buffer_shape_device_', '    col_buffer_shape_device_', '    DeformConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    DeformConvOp(const OperatorDef & operator_def,Workspace *ws)', '    img_shape_device_', '    img_shape_device_', '    RunOnDeviceWithOrderNCHW', '    ~DeformConvGradientOp', '    ~DeformConvOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\deform_conv_op_impl.h', [], ['    ComputePads', '    SetOutputSize', '    GetDims', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    Gemm', '    Gemv', '    Set', '    dim', '    dim32', '    end', '    numel', '    sizes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\torch_ops\\defs.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dense_vector_to_id_list_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDenseVectorToIdList', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DenseVectorToIdList']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dense_vector_to_id_list_op.h', ['    DenseVectorToIdListOp'], ['    DenseVectorToIdListOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    ~DenseVectorToIdListOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Deprecated.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DeprecatedTypeProperties.cpp', [], ['    copy(const Tensor & src,bool non_blocking,c10::optional to_device)', '    unsafeStorageFromTH(void *th_pointer,bool retain)', '    unsafeTensorFromTH(void *th_pointer,bool retain)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DeprecatedTypeProperties.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DeprecatedTypePropertiesRegistry.cpp', [], ['    globalDeprecatedTypePropertiesRegistry', '    operator()(DeprecatedTypeProperties *ptr)', '    DeprecatedTypePropertiesRegistry', '    getDeprecatedTypeProperties(Backend p,ScalarType s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DeprecatedTypePropertiesRegistry.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\depthwise\\depthwise3x3_conv_op.cc', ['    C10FlagParser_caffe2_profile_depthwise', '    final'], ['    psimd_transpose4x4_f32(const psimd_f32 row0,const psimd_f32 row1,const psimd_f32 row2,const psimd_f32 row3,psimd_f32 *col0,psimd_f32 *col1,psimd_f32 *col2,psimd_f32 *col3)', '    winograd_f2k3_input_transform(const psimd_f32 d0,const psimd_f32 d1,const psimd_f32 d2,const psimd_f32 d3,psimd_f32 *transform0,psimd_f32 *transform1,psimd_f32 *transform2,psimd_f32 *transform3)', '    winograd_f2k3_kernel_transform(const psimd_f32 g0,const psimd_f32 g1,const psimd_f32 g2,psimd_f32 *transform0,psimd_f32 *transform1,psimd_f32 *transform2,psimd_f32 *transform3)', '    winograd_f2k3_output_transform(const psimd_f32 m0,const psimd_f32 m1,const psimd_f32 m2,const psimd_f32 m3,psimd_f32 *output0,psimd_f32 *output1)', '    runDepthwise3x3Conv(const DepthwiseArgs & args,const float *input,const float *kernel,const float *bias,float *output)', '    C10FlagParser_caffe2_profile_depthwise(const std::string & content)', '    batch', '    in_cols', '    in_rows', '    out_cols', '    out_rows', '    pad_cols', '    pad_rows', '    stride', '    bias_', '    Depthwise3x3ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\depthwise\\depthwise3x3_conv_op_test.cc', [], ['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int group,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    relativeError(float a,float b)', '    runConv(int kernelH,int kernelW,int strideH,int strideW,int group,int planesIn,int planesOut,int n)', '    TEST(DEPTHWISE3x3,Conv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\DepthwiseConvKernel.cpp', [], ['    args', '    _convolution_depthwise3x3_winograd(const Tensor & input,const Tensor & kernel,const Tensor & bias_potentially_undefined,const IntArrayRef stride,const IntArrayRef padding,const int64_t groups)', '    calculate_conv_output_size(const IntArrayRef input_size,const IntArrayRef weight_size,const IntArrayRef stride,const IntArrayRef padding)', '    convolution_depthwise3x3_winograd_impl(const Arguments &,const float *const,const float *const,const float *const,float *const)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\DepthwiseConvKernel.h', [], ['    convolution_depthwise3x3_winograd_stub', '    convolution_depthwise3x3_winograd_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dequantize_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Dequantize', '    DequantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dequantize_dnnlowp_op.h', ['    final'], ['    DequantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Descriptors.cpp', [], ['    getDataType(const at::Tensor & t)', '    miopenTypeToString(miopenDataType_t dtype)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    i', '    i', '    set(const at::Tensor & t,int64_t pad)', '    print', '    set(miopenDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad)', '    set(const at::Tensor & t,size_t pad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Descriptors.cpp', [], ['    cudnnTypeToString(cudnnDataType_t dtype)', '    getDataType(const at::Tensor & t)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    i', '    i', '    set(const at::Tensor & t,int64_t pad,bool force_nhwc)', '    print', '    set(cudnnDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad)', '    set(cudnnDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad,bool nhwc)', '    set(const at::Tensor & t,size_t pad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Descriptors.h', ['    Descriptor', '    FilterDescriptor', '    TensorDescriptor'], ['    fixSizeOneDimStride(int dim,const int *size,int *stride)', '    dataSize(miopenDataType_t dataType)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    Constant(miopenDataType_t dataType,double value)', '    miopenDataType_t', '    desc', '    desc', '    init', '    mut_desc', '    operator()(T *x)', '    miopenDataType_t', '    int64_t', '    miopenDataType_t', '    print', '    TensorDescriptor(const at::Tensor & t,size_t pad)', '    TensorDescriptor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Descriptors.h', ['    Descriptor', '    FilterDescriptor', '    TensorDescriptor'], ['    fixSizeOneDimStride(int dim,const int *size,int *stride,bool nhwc)', '    dataSize(cudnnDataType_t dataType)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    empty', '    Constant(cudnnDataType_t dataType,double value)', '    cudnnDataType_t', '    cudnnDataType_t', '    desc', '    desc', '    init', '    mut_desc', '    operator()(T *x)', '    cudnnHandle_t', '    initialize_rng(cudnnHandle_t handle,float dropout,long long int seed,const TensorOptions & options)', '    set_no_dropout(cudnnHandle_t handle)', '    cudnnDataType_t', '    cudnnHandle_t', '    cudnnDataType_t', '    cudnnDataType_t', '    print', '    TensorDescriptor(const at::Tensor & t,size_t pad)', '    TensorDescriptor', '    data_ptr', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\mkl\\Descriptors.h', ['    DftiDescriptor'], ['    get', '    init(DFTI_CONFIG_VALUE precision,DFTI_CONFIG_VALUE signal_type,MKL_LONG signal_ndim,MKL_LONG *sizes)', '    operator()(DFTI_DESCRIPTOR *desc)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\device.cc', [], ['    Device(const std::string & spec)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\device.cc', [], ['    getInputEdges(const NNGraph::SubgraphType & sg,const NNGraph & g)', '    getOutputEdges(const NNGraph::SubgraphType & sg,const NNGraph & g)', '    insertCopies(NNModule *nn,std::function supported,std::function copyToFn,std::function copyFromFn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Device.cpp', [], ['    THPDevice_hash(THPDevice *self)', '    ret', '    self', '    THPDevice_index(THPDevice *self,PyObject *noargs)', '    THPDevice_init(PyObject *module)', '    THPDevice_New(const at::Device & device)', '    THPDevice_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPDevice_rc(PyObject *a,PyObject *b,int op)', '    THPDevice_reduce(THPDevice *self,PyObject *noargs)', '    THPDevice_repr(THPDevice *self)', '    THPDevice_str(THPDevice *self)', '    THPDevice_type(THPDevice *self,PyObject *noargs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Device.cpp', [], ['    operator<<(std::ostream & stream,const Device & device)', '    parse_type(const std::string & device_string)', '    Device(const std::string & device_string)', '    str']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\device.h', ['    DeviceType'], ['    Device(const std::string & spec)', '    device_id', '    operator()(const caffe2::onnx::DeviceType & k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Device.h', [], ['    operator<<(std::ostream & stream,const Device & device)', '    Device(DeviceType type,DeviceIndex index)', '    Device(const std::string & device_string)', '    has_index', '    index', '    is_cpu', '    is_cuda', '    operator!=(const Device & other)', '    operator==(const Device & other)', '    set_index(DeviceIndex index)', '    str', '    type', '    validate', '    operator()(c10::Device d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Device.h', [], ['    THPDevice_Check(PyObject *obj)', '    THPDevice_init(PyObject *module)', '    THPDevice_New(const at::Device & device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Device.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\device.h', [], ['    insertCopies(NNModule *nn,std::function supported,std::function copyToFn,std::function copyFromFn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\device_set.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\device_test.cc', [], ['    TEST(DeviceTest,InsertCopies)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DeviceGuard.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DeviceGuard.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\core\\DeviceGuard_test.cpp', [], ['    TEST(DeviceGuard,ResetDeviceDifferentDeviceType)', '    TEST(OptionalDeviceGuard,ResetDeviceDifferentDeviceType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\DeviceGuardImplInterface.cpp', [], ['    DeviceGuardImplRegistrar(DeviceType type,const DeviceGuardImplInterface *impl)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\DeviceGuardImplInterface.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\detail\\DeviceThreadHandles.h', ['    PoolWindow'], ['    Handle(bool create)', '    Handle', '    Handle(Handle)', '    operator=(Handle rhs)', '    ~Handle', '    newPoolWindow', '    PoolWindow(DeviceThreadHandlePool & parent)', '    release', '    reserve(int device)', '    ~PoolWindow']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DeviceType.cpp', [], ['    DeviceTypeName(DeviceType d,bool lower_case)', '    isValidDeviceType(DeviceType d)', '    operator<<(std::ostream & stream,DeviceType type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DeviceType.h', ['    DeviceType'], ['    DeviceTypeName(DeviceType d,bool lower_case)', '    isValidDeviceType(DeviceType d)', '    operator<<(std::ostream & stream,DeviceType type)', '    static_assert(COMPILE_TIME_MAX_DEVICE_TYPES,)', '    operator()(c10::DeviceType k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Dict.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Dict_inl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\Dict_test.cpp', [], ['    TEST(DictTest,givenEmptyDict_whenCallingEmpty_thenReturnsTrue)', '    TEST(DictTest,givenNonemptyDict_whenCallingEmpty_thenReturnsFalse)', '    TEST(DictTest,givenEmptyDict_whenCallingSize_thenReturnsZero)', '    TEST(DictTest,givenNonemptyDict_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(DictTest,givenNonemptyDict_whenCallingClear_thenIsEmpty)', '    TEST(DictTest,whenInsertingNewKey_thenReturnsTrueAndIteratorToNewElement)', '    TEST(DictTest,whenInsertingExistingKey_thenReturnsFalseAndIteratorToExistingElement)', '    TEST(DictTest,whenInsertingExistingKey_thenDoesNotModifyDict)', '    TEST(DictTest,whenInsertOrAssigningNewKey_thenReturnsTrueAndIteratorToNewElement)', '    TEST(DictTest,whenInsertOrAssigningExistingKey_thenReturnsFalseAndIteratorToChangedElement)', '    TEST(DictTest,whenInsertOrAssigningExistingKey_thenDoesModifyDict)', '    TEST(DictTest,givenEmptyDict_whenIterating_thenBeginIsEnd)', '    TEST(DictTest,givenMutableDict_whenIterating_thenFindsElements)', '    TEST(DictTest,givenMutableDict_whenIteratingWithForeach_thenFindsElements)', '    TEST(DictTest,givenConstDict_whenIterating_thenFindsElements)', '    TEST(DictTest,givenConstDict_whenIteratingWithForeach_thenFindsElements)', '    TEST(DictTest,givenIterator_thenCanModifyValue)', '    TEST(DictTest,givenOneElementDict_whenErasingByIterator_thenDictIsEmpty)', '    TEST(DictTest,givenOneElementDict_whenErasingByKey_thenReturnsOneAndDictIsEmpty)', '    TEST(DictTest,givenOneElementDict_whenErasingByNonexistingKey_thenReturnsZeroAndDictIsUnchanged)', '    TEST(DictTest,whenCallingAtWithExistingKey_thenReturnsCorrectElement)', '    TEST(DictTest,whenCallingAtWithNonExistingKey_thenReturnsCorrectElement)', '    TEST(DictTest,givenMutableDict_whenCallingFindOnExistingKey_thenFindsCorrectElement)', '    TEST(DictTest,givenMutableDict_whenCallingFindOnNonExistingKey_thenReturnsEnd)', '    TEST(DictTest,givenConstDict_whenCallingFindOnExistingKey_thenFindsCorrectElement)', '    TEST(DictTest,givenConstDict_whenCallingFindOnNonExistingKey_thenReturnsEnd)', '    TEST(DictTest,whenCallingContainsWithExistingKey_thenReturnsTrue)', '    TEST(DictTest,whenCallingContainsWithNonExistingKey_thenReturnsFalse)', '    TEST(DictTest,whenCallingReserve_thenDoesntCrash)', '    TEST(DictTest,whenCopyConstructingDict_thenAreEqual)', '    TEST(DictTest,whenCopyAssigningDict_thenAreEqual)', '    TEST(DictTest,whenCopyingDict_thenAreEqual)', '    TEST(DictTest,whenMoveConstructingDict_thenNewIsCorrect)', '    TEST(DictTest,whenMoveAssigningDict_thenNewIsCorrect)', '    TEST(DictTest,whenMoveConstructingDict_thenOldIsEmpty)', '    TEST(DictTest,whenMoveAssigningDict_thenOldIsEmpty)', '    TEST(DictTest,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(DictTest,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(DictTest,givenEqualIterators_thenAreEqual)', '    TEST(DictTest,givenDifferentIterators_thenAreNotEqual)', '    TEST(DictTest,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(DictTest,givenIterator_whenWritingToValue_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenWritingToValueFromIterator_thenChangesValue)', '    TEST(DictTest,isReferenceType)', '    TEST(DictTest,copyHasSeparateStorage)', '    TEST(DictTest,dictTensorAsKey)', '    TEST(DictTest,dictEquality)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DilatedConvolutionUtils.h', [], ['    all_nonnegative(std::vector & arr)', '    all_positive(IntArrayRef & arr)', '    get_output_size(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    get_output_size(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_shape_check(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DilatedMaxPool2d.cpp', [], ['    max_pool2d_with_indices_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int dW,int dH)', '    max_pool2d_with_indices_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int dW,int dH)', '    max_pool2d_with_indices_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,int dilationW,int dilationH)', '    max_pool2d_with_indices_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int kW,int kH,int dW,int dH,int padW,int padH,int dilationW,int dilationH)', '    max_pool2d_with_indices_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool2d_with_indices_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool2d_with_indices_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DilatedMaxPool3d.cpp', [], ['    max_pool3d_with_indices_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t nbatch,int64_t nslices,int64_t istride,int64_t ostride,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *indz_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t nbatch,int64_t nslices,int64_t istride,int64_t ostride,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *indz_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool3d_with_indices_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool3d_with_indices_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Dimname.cpp', [], ['    check_valid_identifier(const std::string & name)', '    operator<<(std::ostream & out,const Dimname & dimname)', '    fromSymbol(Symbol name)', '    isValidName(const std::string & name)', '    matches(Dimname other)', '    unify(Dimname other)', '    wildcard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Dimname.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Dimname.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\Dimname_test.cpp', [], ['    check_unify_and_match(const std::string & dimname,const std::string & other,at::optional expected)', '    TEST(DimnameTest,isValidIdentifier)', '    TEST(DimnameTest,wildcardName)', '    TEST(DimnameTest,createNormalName)', '    TEST(DimnameTest,unifyAndMatch)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DimVector.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DimVector.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\disallow_copy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\dispatch.cpp', [], ['    ints', '    ints', '    ints', '    TEST_F(DispatchTest,TestAVX2)', '    TEST_F(DispatchTest,TestAVX)', '    TEST_F(DispatchTest,TestDefault)', '    vector', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Dispatch.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\Dispatcher.cpp', ['    final'], ['    addListener(std::unique_ptr listener)', '    callOnOperatorDeregistered(const OperatorHandle & op)', '    callOnOperatorRegistered(const OperatorHandle & op)', '    addRegistrationListener(std::unique_ptr listener)', '    checkInvariants', '    checkSchemaCompatibility(const OperatorHandle & op,const FunctionSchema & schema)', '    cleanup(const OperatorHandle & op,const OperatorName & op_name)', '    deregisterDef_(const OperatorHandle & op,const OperatorName & op_name)', '    deregisterFallback_(DispatchKey dispatchKey)', '    deregisterImpl_(const OperatorHandle & op,const OperatorName & op_name,c10::optional dispatch_key,std::list::iterator handle)', '    Dispatcher', '    findOp(const OperatorName & overload_name)', '    findOrRegisterName_(const OperatorName & op_name)', '    findSchema(const OperatorName & overload_name)', '    findSchemaOrThrow(const char *name,const char *overload_name)', '    registerDef(FunctionSchema schema)', '    registerFallback(DispatchKey dispatchKey,KernelFunction kernel)', '    registerImpl(OperatorName op_name,c10::optional dispatch_key,KernelFunction kernel,std::unique_ptr inferred_function_schema,std::string debug)', '    singleton', '    ~Dispatcher', '    ~OpRegistrationListener']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\Dispatcher.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DispatchKey.cpp', [], ['    operator<<(std::ostream & str,DispatchKey rhs)', '    toString(DispatchKey t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DispatchKey.h', ['    DispatchKey'], ['    XLATensorId', '    operator<<(std::ostream & str,DispatchKey rhs)', '    static_assert(,)', '    toString(DispatchKey t)', '    operator()(c10::DispatchKey x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\DispatchKeyExtractor.cpp', [], ['    checkInvariants(const FunctionSchema & schema)', '    dumpState', '    setOperatorHasKernelForBackend(DispatchKey k,bool has_kernel)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\DispatchKeyExtractor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DispatchKeySet.cpp', [], ['    operator<<(std::ostream & os,DispatchKeySet ts)', '    toString(DispatchKeySet ts)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\DispatchKeySet.h', ['    final'], ['    legacyExtractDispatchKey(DispatchKeySet s)', '    operator<<(std::ostream & os,DispatchKeySet ts)', '    toString(DispatchKeySet ts)', '    add(DispatchKey t)', '    DispatchKeySet', '    DispatchKeySet(Full)', '    DispatchKeySet(Raw,uint64_t x)', '    DispatchKeySet(DispatchKey t)', '    DispatchKeySet(std::initializer_list ks)', '    empty', '    has(DispatchKey t)', '    highestPriorityTypeId', '    operator&(DispatchKeySet other)', '    operator-(DispatchKeySet other)', '    operator==(DispatchKeySet other)', '    operator|(DispatchKeySet other)', '    raw_repr', '    remove(DispatchKey t)', '    uint64_t', '    max']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\core\\DispatchKeySet_test.cpp', [], ['    TEST(DispatchKeySet,Empty)', '    TEST(DispatchKeySet,Singleton)', '    TEST(DispatchKeySet,Doubleton)', '    TEST(DispatchKeySet,Full)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DispatchStub.cpp', [], ['    compute_cpu_capability', '    get_cpu_capability']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DispatchStub.h', ['    CPUCapability'], ['    get_cpu_capability', '    choose_cpu_impl', '    cpu_dispatch_ptr', '    DispatchStub', '    DispatchStub', '    operator()(DeviceType device_type,ArgTypes,...)', '    operator=', '    RegisterCUDADispatch(DispatchStub & stub,FnPtr value)', '    RegisterHIPDispatch(DispatchStub & stub,FnPtr value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\DispatchTable.cpp', [], ['    dumpState', '    dumpState']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\DispatchTable.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\engine\\dist_engine.cpp', [], ['    getInstance', '    cleanupBackwardPass(const ContextPtr & autogradContext)', '    computeDependencies(const ContextPtr & autogradContext,const edge_list & rootEdges,const variable_list & grads,const std::shared_ptr & graphRoot,edge_list & outputEdges,bool retainGraph)', '    DistEngine', '    execute(int64_t contextId,const variable_list & roots,bool retainGraph)', '    executeSendFunctionAsync(const ContextPtr & autogradContext,const std::shared_ptr & sendFunction,bool retainGraph)', '    getDebugInfo', '    numBackwardPasses', '    runEngineAndAccumulateGradients(const ContextPtr & autogradContext,const std::shared_ptr & graphRoot,const edge_list & outputEdges)', '    validateRootsAndRetrieveEdges(const variable_list & roots,edge_list & rootEdges,variable_list & grads)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\engine\\dist_engine.h', ['    BackwardPassCleanupGuard', '    DistEngine'], ['    getInstance', '    BackwardPassCleanupGuard(const ContextPtr & autogradContext)', '    ~BackwardPassCleanupGuard', '    cleanupBackwardPass(const ContextPtr & autogradContext)', '    computeDependencies(const ContextPtr & context,const torch::autograd::edge_list & rootEdges,const torch::autograd::variable_list & grads,const std::shared_ptr & graphRoot,torch::autograd::edge_list & outputEdges,bool retainGraph)', '    DistEngine', '    DistEngine', '    DistEngine', '    execute(int64_t context_id,const torch::autograd::variable_list & roots,bool retainGraph)', '    executeSendFunctionAsync(const ContextPtr & autogradContext,const std::shared_ptr & sendFunction,bool retainGraph)', '    getDebugInfo', '    numBackwardPasses', '    operator=', '    operator=', '    runEngineAndAccumulateGradients(const ContextPtr & autogradContext,const std::shared_ptr & graphRoot,const torch::autograd::edge_list & outputEdges)', '    validateRootsAndRetrieveEdges(const torch::autograd::variable_list & roots,torch::autograd::edge_list & rootEdges,torch::autograd::variable_list & grads)', '    ~DistEngine']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Distance.cpp', [], ['    cdist_impl(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    _cdist_backward(const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & cdist)', '    _cdist_forward(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    _pdist_backward(const Tensor & grad,const Tensor & self,const double p,const Tensor & pdist)', '    _pdist_forward(const Tensor & self,const double p)', '    cdist(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    cosine_similarity(const Tensor & x1,const Tensor & x2,int64_t dim,double eps)', '    euclidean_dist_out(const Tensor & x1,const Tensor & x2)', '    pairwise_distance(const Tensor & x1,const Tensor & x2,double p,double eps,bool keepdim)', '    pdist(const Tensor & self,const double p)', '    result', '    result', '    tensor1_view', '    tensor2_view']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\distance.cpp', [], ['    CosineSimilarityImpl(const CosineSimilarityOptions & options_)', '    forward(const Tensor & x1,const Tensor & x2)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & x1,const Tensor & x2)', '    PairwiseDistanceImpl(const PairwiseDistanceOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\distance.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\distance.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\distance.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Distance.h', [], ['    cdist_backward_stub', '    cdist_backward_stub', '    operator=', '    cdist_stub', '    cdist_stub', '    operator=', '    operator=', '    pdist_backward_stub', '    pdist_backward_stub', '    operator=', '    pdist_forward_stub', '    pdist_forward_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\distance_op.cc', ['    GetCosineSimilarityGradient', '    GetDotProductGradient', '    GetDotProductWithPaddingGradient', '    GetL1DistanceGradient', '    GetSquaredL2DistanceGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCosineSimilarity', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosineSimilarityGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProduct', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductWithPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductWithPaddingGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUL1Distance', '    CAFFE_ANONYMOUS_VARIABLE_CPUL1DistanceGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSquaredL2Distance', '    CAFFE_ANONYMOUS_VARIABLE_CPUSquaredL2DistanceGradient', '    TensorInferenceForDotProduct(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineSimilarity', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineSimilarityGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProduct', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductWithPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductWithPaddingGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_L1Distance', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_L1DistanceGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquaredL2Distance', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquaredL2DistanceGradient', '    CostInferenceForDotProduct(const OperatorDef & def,const vector & in)', '    dot_arg', '    vector', '    vector', '    vector', '    vector', '    vector', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\distance_op.h', ['    CosineSimilarityOp', '    DotProductOp', '    DotProductWithPaddingOp', '    final', '    final', '    final', '    final', '    L1DistanceGradientOp', '    L1DistanceOp', '    SquaredL2DistanceOp'], ['    CosineSimilarityOp(Args,...)', '    RunOnDevice', '    DotProductOp(Args,...)', '    RunOnDevice', '    DotProductWithPaddingOp(Args,...)', '    RunOnDevice', '    CosineSimilarityGradientOp(Args,...)', '    DotProductGradientOp(Args,...)', '    DotProductWithPaddingGradientOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SquaredL2DistanceGradientOp(Args,...)', '    L1DistanceGradientOp(Args,...)', '    RunOnDevice', '    L1DistanceOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    SquaredL2DistanceOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\DistanceOpsKernel.cpp', [], ['    apply_backward_cdist(Tensor & result,const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & dist)', '    apply_backward_pdist(Tensor & result,const Tensor & grad,const Tensor & self,const double p,const Tensor & dist)', '    apply_cdist(Tensor & result,const Tensor & x1,const Tensor & x2,const scalar_t p)', '    apply_pdist(Tensor & result,const Tensor & self,const scalar_t p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward_down_column_cdist(const scalar_t *t1,const scalar_t *t2,scalar_t *res,const scalar_t *grad_k,const scalar_t *dist_k,const Vec & pvec,int64_t r1,int64_t r2,int64_t m,int64_t d,int64_t gs,int64_t l1_size,int64_t l2_size,int64_t count)', '    backward_down_column_pdist(const scalar_t *self_i,scalar_t *res_i,const scalar_t *grad_k,const scalar_t *dist_k,const Vec & pvec,int64_t n,int64_t m,int64_t gs,int64_t count)', '    cdist_backward_kernel_impl(Tensor & result,const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & dist)', '    cdist_kernel_impl(Tensor & result,const Tensor & x1,const Tensor & x2,const double p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    pdist_backward_kernel_impl(Tensor & result,const Tensor & grad,const Tensor & self,const double p,const Tensor & dist)', '    run_backward_parallel_cdist(Tensor & result,const Tensor & grad,const Tensor & t1,const Tensor & t2,const scalar_t p,const Tensor & dist)', '    run_backward_parallel_pdist(Tensor & result,const Tensor & grad,const Tensor & self,const scalar_t p,const Tensor & dist)', '    run_parallel_cdist(Tensor & result,const Tensor & t1,const Tensor & t2,const scalar_t p)', '    run_parallel_pdist(Tensor & result,const Tensor & self,const scalar_t p)', '    pdist_forward_kernel_impl(Tensor & result,const Tensor & self,const double p)', '    abs(Vec val)', '    abs(scalar_t val)', '    ceil(Vec val)', '    ceil(scalar_t val)', '    max(Vec val,Vec other)', '    max(scalar_t val,scalar_t)', '    min(Vec val,scalar_t)', '    min(scalar_t val,scalar_t)', '    pow(Vec val,Vec p)', '    pow(scalar_t val,scalar_t p)', '    sign(Vec val)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\distributed.cc', [], ['    addBlobDeviceOptions(std::map blobMap,NNModule *nn)', '    convertToNNModule(caffe2::NetDef & net,std::map blobMap)', '    injectDataEdgeIndicators(nom::repr::NNModule *nn)', '    removeDataEdgeIndicators(nom::repr::NNModule *nn)', '    setDeviceOption(NNGraph::NodeRef n,caffe2::DeviceOption & d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\data\\samplers\\distributed.cpp', [], ['    DistributedRandomSampler(size_t size,size_t num_replicas,size_t rank,bool allow_duplicates)', '    index', '    load(serialize::InputArchive & archive)', '    populate_indices', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    DistributedSequentialSampler(size_t size,size_t num_replicas,size_t rank,bool allow_duplicates)', '    index', '    load(serialize::InputArchive & archive)', '    populate_indices', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\distributed.h', [], ['    addBlobDeviceOptions(std::map blobMap,NNModule *nn)', '    injectDataEdgeIndicators(nom::repr::NNModule *nn)', '    removeDataEdgeIndicators(nom::repr::NNModule *nn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\distributed.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\distributed_converter.cc', ['    DeclareConverter', '    ExportConverter'], ['    convertToNeuralNetOperator(const OperatorDef & op)', '    ~DeclareConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ExportConverter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\distributed_test.cc', [], ['    fakeNet', '    ns', '    ns', '    TEST(Converter,DeclareExport)', '    TEST(Distributed,InsertDeviceOptions)', '    TEST(Distributed,InsertDeviceOptionsFailureCase)', '    TEST(Converter,OverloadedConvertToNNModule)', '    TEST(Converter,OverloadedConvertToNNModuleFailure)', '    TEST(Converter,InjectDataEdgeIndicators)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Distributions.cpp', [], ['    _dirichlet_grad_cpu(const Tensor & x,const Tensor & alpha,const Tensor & total)', '    _s_dirichlet_cpu(const Tensor & alpha,Generator gen)', '    _s_gamma_cpu(const Tensor & alpha,Generator gen)', '    _s_poisson_cpu(const Tensor & lambda,Generator gen)', '    _standard_gamma_grad_cpu(const Tensor & self,const Tensor & output)', '    bernoulli(const Tensor & self,Generator gen)', '    bernoulli(const Tensor & self,double p,Generator gen)', '    bernoulli_out(Tensor & result,const Tensor & self,Generator gen)', '    bernoulli_scalar_cpu_(Tensor & self,double p,Generator gen)', '    bernoulli_tensor_cpu_(Tensor & self,const Tensor & p_,Generator gen)', '    cauchy_(Tensor & self,double median,double sigma,Generator gen)', '    exponential_(Tensor & self,double lambda,Generator gen)', '    geometric_(Tensor & self,double p,Generator gen)', '    log_normal_(Tensor & self,double mean,double std,Generator gen)', '    multinomial(const Tensor & self,int64_t n_sample,bool with_replacement,Generator gen)', '    multinomial_out(Tensor & result,const Tensor & self,int64_t n_sample,bool with_replacement,Generator gen)', '    normal(const Tensor & mean,double std,Generator gen)', '    normal(double mean,const Tensor & std,Generator gen)', '    normal(const Tensor & mean,const Tensor & std,Generator gen)', '    normal_(Tensor & self,double mean,double std,Generator gen)', '    normal_out(Tensor & output,const Tensor & mean,double std,Generator gen)', '    normal_out(Tensor & output,double mean,const Tensor & std,Generator gen)', '    normal_out(Tensor & output,const Tensor & mean,const Tensor & std,Generator gen)', '    random_(Tensor & self,Generator gen)', '    random_(Tensor & self,int64_t from,optional to,Generator gen)', '    random_(Tensor & self,int64_t to,Generator gen)', '    sample_poisson(double lambda,at::CPUGenerator *generator)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t from,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Distributions.h', [], ['    _beta_grad_alpha_mid(accscalar_t,accscalar_t alpha,accscalar_t beta)', '    _beta_grad_alpha_small(scalar_t x,scalar_t alpha,scalar_t beta)', '    _beta_grad_beta_small(scalar_t x,scalar_t alpha,scalar_t beta)', '    digamma_one(scalar_t x)', '    dirichlet_grad_one(scalar_t x,scalar_t alpha,scalar_t total)', '    polevl(const scalar_t x,const scalar_t [] A,size_t len)', '    sample_gamma(scalar_t alpha,BaseSampler & standard_uniform,BaseSampler & standard_normal)', '    standard_gamma_grad_one(scalar_t alpha_,scalar_t x_)', '    BaseSampler(const sampler_t & sampler)', '    sample', '    tan']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\DistributionsHelper.h', [], ['    bernoulli_distribution(T p_in)', '    operator()(RNG *generator)', '    cauchy_distribution(T median_in,T sigma_in)', '    operator()(RNG *generator)', '    exponential_distribution(T lambda_in)', '    operator()(RNG *generator)', '    geometric_distribution(T p_in)', '    operator()(RNG *generator)', '    lognormal_distribution(T mean_in,T stdv_in)', '    operator()(RNG *generator)', '    normal_distribution(T mean_in,T stdv_in)', '    operator()(RNG *generator)', '    operator()(RNG *generator)', '    uniform_real_distribution(T a_in,T b_in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\DistributionTemplates.h', [], ['    check_from_to_in_range(int64_t from,int64_t to_inc,caffe2::TypeMeta dtype)', '    resize_output_for_normal(at::Tensor & output,const at::Tensor & mean,const at::Tensor & std)', '    torch_warn_once_177', '    normal_impl(const Tensor & mean,double std,Generator gen)', '    normal_impl(double mean,const Tensor & std,Generator gen)', '    normal_impl(const Tensor & mean,const Tensor & std,Generator gen)', '    normal_impl_(Tensor & self,double mean,double std,Generator gen)', '    normal_out_impl(Tensor & output,const Tensor & mean,double std,Generator gen)', '    normal_out_impl(Tensor & output,double mean,const Tensor & std,Generator gen)', '    normal_out_impl(Tensor & output,const Tensor & mean,const Tensor & std,Generator gen)', '    random_from_to_impl(at::Tensor & self,int64_t from,c10::optional to_opt,at::Generator generator)', '    random_impl(at::Tensor & self,at::Generator generator)', '    update_from(int64_t from)', '    update_to(int64_t to)', '    are_expandable', '    full', '    resize_', '    dtype', '    equals', '    has_value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\DistributionTemplates.h', [], ['    normal_fill_16(scalar_t *data,const scalar_t mean,const scalar_t)', '    cauchy_kernel(TensorIterator & iter,double median,double sigma,RNG generator)', '    normal_fill(Tensor & self,const scalar_t mean,const scalar_t,RNG generator)', '    normal_kernel(Tensor & self,double mean,double std,RNG generator)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,RNG generator)', '    random_full_64_bits_range_kernel(TensorIterator & iter,RNG generator)', '    random_kernel(TensorIterator & iter,RNG generator)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t base,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    cos', '    sin']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\DistributionTemplates.h', [], ['    normal_kernel(Tensor & self,double mean_,double std_,RNG gen)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,RNG gen)', '    random_full_64_bits_range_kernel(TensorIterator & iter,RNG gen)', '    random_kernel(TensorIterator & iter,RNG gen)', '    calc_execution_policy(int64_t total_elements)', '    distribution_nullary_kernel(at::TensorIterator & iter,RNG gen,const dist_t & dist_func,const transform_t transform_func)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t base,RNG gen)', '    operator()(TensorIterator & iter,RNG gen)', '    operator()(TensorIterator & iter,RNG gen)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\div_rtn.h', [], ['    div_rtn(T x,T y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\dl.c', [], ['    PyInit__dl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DLConvertor.cpp', [], ['    getATenDevice(const DLContext & ctx)', '    deleter(DLManagedTensor *arg)', '    fromDLPack(const DLManagedTensor *src)', '    getDLContext(const Tensor & tensor,const int64_t & device_id)', '    getDLDataType(const Tensor & t)', '    toDLPack(const Tensor & src)', '    toScalarType(const DLDataType & dtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DLConvertor.h', [], ['    fromDLPack(const DLManagedTensor *src)', '    getDLContext(const Tensor & tensor,const int64_t & device_id)', '    getDLDataType(const Tensor & t)', '    toDLPack(const Tensor & src)', '    toScalarType(const DLDataType & dtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\dlconvertor_test.cpp', [], ['    TEST(TestDlconvertor,TestDlconvertor)', '    TEST(TestDlconvertor,TestDlconvertorNoStrides)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\dlnnapi.c', [], ['    dlnnapi_free(struct dlnnapi *nnapi)', '    dlnnapi_load(struct dlnnapi *nnapi,uint32_t flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\dlnnapi.h', [], ['    dlnnapi_free(struct dlnnapi *nnapi)', '    dlnnapi_load(struct dlnnapi *nnapi,uint32_t flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\dlpack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\dlpack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dnnlowp.cc', ['    C10FlagParser_caffe2_dnnlowp_activation_p99_threshold', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_kind', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_precision', '    C10FlagParser_caffe2_dnnlowp_copy_to_32bit_frequency', '    C10FlagParser_caffe2_dnnlowp_eltwise_quantization_precision', '    C10FlagParser_caffe2_dnnlowp_force_scale_power_of_two', '    C10FlagParser_caffe2_dnnlowp_force_slow_path', '    C10FlagParser_caffe2_dnnlowp_nbits_in_non_outlier', '    C10FlagParser_caffe2_dnnlowp_preserve_activation_sparsity', '    C10FlagParser_caffe2_dnnlowp_preserve_weight_sparsity', '    C10FlagParser_caffe2_dnnlowp_requantization_multiplier_precision', '    C10FlagParser_caffe2_dnnlowp_weight_p99_threshold', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_kind', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_precision'], ['    adjust_hist_to_include_zero(const Histogram & hist,float *min,float *max)', '    StringToKind(const string & s)', '    GetDefaultInstance', '    C10FlagParser_caffe2_dnnlowp_activation_p99_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_kind(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_copy_to_32bit_frequency(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_eltwise_quantization_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_force_scale_power_of_two(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_force_slow_path(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_nbits_in_non_outlier(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_preserve_activation_sparsity(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_preserve_weight_sparsity(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_requantization_multiplier_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_p99_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_kind(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_precision(const std::string & content)', '    ChooseQuantizationParams(const float *values,int len,QuantizationKind kind,int precision,bool preserve_sparsity)', '    ChooseQuantizationParams(const float *values,int len,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,QuantizationKind kind,int precision,bool preserve_sparsity,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,bool is_weight)', '    ChooseRequantizationMultiplier(float real_multiplier,TensorQuantizationParams target_qparams)', '    QuantizationFactory(int activation_precision,int weight_precision,int requantization_multiplier_precision,int eltwise_quantize_precision,bool preserve_activation_sparsity,bool preserve_weight_sparsity,bool force_scale_power_of_two,QuantizationKind activation_kind,QuantizationKind weight_kind,float weight_p99_threshold,float activation_p99_threshold)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dnnlowp.h', ['    QuantizationFactory'], ['    adjust_hist_to_include_zero(const Histogram & hist,float *min,float *max)', '    StringToKind(const string & s)', '    GetDefaultInstance', '    ChooseQuantizationParams(float min,float max,int precision,bool preserve_sparsity,bool is_signed)', '    ChooseQuantizationParams(float min,float max,bool is_weight)', '    ChooseQuantizationParams(const float *values,int len,QuantizationKind kind,int precision,bool preserve_sparsity)', '    ChooseQuantizationParams(const float *values,int len,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,QuantizationKind kind,int precision,bool preserve_sparsity,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,bool is_weight)', '    ChooseRequantizationMultiplier(float real_multiplier,TensorQuantizationParams target_qparams)', '    GetActivationKind', '    GetActivationPrecision', '    GetEltwiseQuantizePrecision', '    GetPreserveActivationSparsity', '    GetPreserveWeightSparsity', '    GetWeightKind', '    GetWeightPrecision', '    QuantizationFactory(int activation_precision,int weight_precision,int requantization_multiplier_precision,int eltwise_quantize_precision,bool preserve_activation_sparsity,bool preserve_weight_sparsity,bool force_scale_power_of_two,QuantizationKind activation_kind,QuantizationKind weight_kind,float weight_p99_threshold,float activation_p99_threshold)', '    SetActivationP99Threshold(float threshold)', '    SetWeightP99Threshold(float threshold)', '    ChooseQuantizationParams']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dnnlowp_op.h', ['    DNNLowPOp'], ['    dnnlowp_get_max_threads', '    dnnlowp_get_num_threads', '    dnnlowp_get_thread_num', '    arguments_parsed_', '    debug_def', '    dequantize_output_', '    DNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    engine', '    Fp32Op_', '    GetOutputQuantizationParams_', '    GetQuantizedOutputData_', '    InputTensorCPU_(int idx)', '    measure_quantization_error_', '    MeasureQuantizationError_', '    OutputTensorCPU_(int idx)', '    OutputTensorCPU_(int idx,at::IntArrayRef dims,at::TensorOptions options)', '    ParseDNNLowPOperatorArguments_', '    RunOnDeviceEpilogue_', '    static_assert(std::is_integral,)', '    type', '    ~DNNLowPOp', '    Output', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dnnlowp_partition.cc', [], ['    GetWorkPerThread_(size_t work,int nthreads,int work_align)', '    Get1DPartition(size_t work,int nthreads,int tid,int work_align)', '    Get1DPartitionOf2D(int m,int n,int nthreads,int tid,int *m_begin,int *m_end,int *n_begin,int *n_end,int n_align)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dnnlowp_partition.h', [], ['    Get1DPartition(size_t work,int nthreads,int tid,int work_align)', '    Get1DPartitionOf2D(int m,int n,int nthreads,int tid,int *m_begin,int *m_end,int *n_begin,int *n_end,int n_align)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\do_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDo', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Do']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\do_op.h', ['    final'], ['    checkAndGetOuterNames(const OperatorDef & operator_def)', '    DoOp(const OperatorDef & operator_def,Workspace *ws)', '    getInputBlobNames(const OperatorDef & operator_def)', '    getOutputBlobNames(const OperatorDef & operator_def)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    Output', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\do_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDADo']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Converters\\Dot.h', ['    DotGenerator'], ['    convertToDotRecordString(GraphT *g,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(GraphT *g,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(GraphT *g,const std::vector & subgraphs,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(const GraphT::SubgraphType & sg,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    defaultEdgePrinter(GraphT::EdgeRef)', '    createSubgraph', '    convert(const GraphT::SubgraphType & sg,const std::vector & subgraphs)', '    convert(const GraphT::SubgraphType & sg)', '    convertStruct(const GraphT::SubgraphType & sg)', '    DotGenerator(NodePrinter nodePrinter,EdgePrinter edgePrinter)', '    generateNode(GraphT::NodeRef node,const GraphT::SubgraphType & sg,std::ostringstream & output)', '    getOperatorDotString(GraphT::NodeRef op)', '    getOperatorSubtreeDotString(std::vector ops)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\doubler.h', [], ['    Doubler(int A,int B)', '    forward', '    get']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\dropout.cpp', [], ['    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\dropout.cpp', [], ['    DropoutOptions(double p)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Dropout.cpp', [], ['    _alpha_dropout(Args,...)', '    _dropout(Args,...)', '    _dropout_impl(T & input,double p,bool train)', '    _feature_alpha_dropout(Args,...)', '    _feature_dropout(Args,...)', '    alpha_dropout(const Tensor & input,double p,bool train)', '    alpha_dropout_(Tensor & input,double p,bool train)', '    dropout(const Tensor & input,double p,bool train)', '    dropout_(Tensor & input,double p,bool train)', '    feature_alpha_dropout(const Tensor & input,double p,bool train)', '    feature_alpha_dropout_(Tensor & input,double p,bool train)', '    feature_dropout(const Tensor & input,double p,bool train)', '    feature_dropout_(Tensor & input,double p,bool train)', '    is_fused_kernel_acceptable(const Tensor & input,double p)', '    make_feature_noise(const Tensor & input)', '    multiply(Tensor & input,const Tensor & noise)', '    multiply(const Tensor & input,const Tensor & noise)', '    result']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\dropout.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\dropout.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\dropout.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dropout_op.cc', ['    GetDropoutGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUDropout', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Dropout', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DropoutGrad', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\dropout_op.cc', ['    final', '    final'], ['    IDEEPDropoutGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPDropoutOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPDropoutGradientOp', '    ~IDEEPDropoutOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dropout_op.h', ['    final', '    final'], ['    DropoutGradientOp(Args,...)', '    DropoutOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\dropout_op_cudnn.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Dtype.cpp', [], ['    self', '    THPDtype_init(PyObject *module)', '    THPDtype_is_complex(THPDtype *self,PyObject *noargs)', '    THPDtype_is_floating_point(THPDtype *self,PyObject *noargs)', '    THPDtype_is_signed(THPDtype *self,PyObject *noargs)', '    THPDtype_New(at::ScalarType scalar_type,const std::string & name)', '    THPDtype_reduce(THPDtype *self,PyObject *noargs)', '    THPDtype_repr(THPDtype *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Dtype.h', [], ['    THPDtype_Check(PyObject *obj)', '    THPDtype_init(PyObject *module)', '    THPDtype_New(at::ScalarType scalar_type,const std::string & name)', '    THPPythonScalarType_Check(PyObject *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\dummy.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\dump_operator_names.cc', ['    C10FlagParser_model', '    C10FlagParser_output'], ['    main(int argc,char **argv)', '    dump_opnames(const Module & m,std::unordered_set & opnames)', '    C10FlagParser_model(const std::string & content)', '    C10FlagParser_output(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\dwconv-microkernel-tester.h', ['    DWConvMicrokernelTester'], ['    channels(uint32_t channels)', '    channels', '    channels_', '    cr(uint32_t cr)', '    cr', '    cr_', '    inputStride(uint32_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    kernelZeroPoint(uint8_t kernelZeroPoint)', '    kernelZeroPoint', '    kernelZeroPoint_', '    outputStride(uint32_t outputStride)', '    outputStride', '    outputStride_', '    packedChannels', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    subsampling(uint32_t subsampling)', '    subsampling', '    subsampling_', '    test(pytorch_q8dwconv_up_ukernel_function q8dwconv)', '    test(pytorch_q8dwconv_mp_ukernel_function q8dwconv)', '    width(uint32_t width)', '    width', '    width_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dynamic_histogram.cc', [], ['    RemapHistograms(Histogram & src_hist,Histogram & dst_hist)', '    Add(float f)', '    Add(const float *f,int len)', '    DynamicHistogram(int nbins)', '    Finalize', '    Add(float f,uint64_t cnt)', '    Add(const float *f,int len)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dynamic_histogram.h', ['    DynamicHistogram', '    Histogram'], ['    Add(float f)', '    Add(const float *f,int len)', '    DynamicHistogram(int nbins)', '    Finalize', '    Add(float f,uint64_t cnt)', '    Add(const float *f,int len)', '    GetHistogram', '    Histogram(int nbins,float min,float max)', '    Histogram(float min,float max,const std::vector & bins)', '    Max', '    Min']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\dynamic_histogram_test.cc', [], ['    TEST(DynamicHistogram,HistSimilar)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DynamicLibrary.cpp', [], ['    DynamicLibrary(const char *name)', '    sym(const char *name)', '    ~DynamicLibrary']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\DynamicLibrary.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\DynamicTypes.cpp', [], ['    createPyObject(const at::Storage & storage)', '    createStorage(PyObject *obj)', '    get_backend(bool is_cuda,bool is_sparse)', '    get_type(at::Backend backend,at::ScalarType scalarType)', '    getDtype(at::ScalarType scalarType)', '    getLayout(at::Backend backend)', '    getPyTypeObject(const at::Storage & storage)', '    isStorage(PyObject *obj)', '    registerDtypeObject(THPDtype *dtype,at::ScalarType scalarType)', '    registerLayoutObject(THPLayout *layout,at::Backend backend)', '    registerStoragePyTypeObject(PyTypeObject *pytype,at::Backend backend,at::ScalarType scalarType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\DynamicTypes.h', [], ['    createPyObject(const at::Storage & storage)', '    createStorage(PyObject *obj)', '    isStorage(PyObject *obj)', '    registerDtypeObject(THPDtype *dtype,at::ScalarType scalarType)', '    registerLayoutObject(THPLayout *layout,at::Backend backend)', '    registerStoragePyTypeObject(PyTypeObject *pytype,at::Backend backend,at::ScalarType scalarType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\edge.h', [], ['    operator()(const argument_type & edge)', '    move', '    Edge', '    Edge(std::shared_ptr function_,uint32_t input_nr_)', '    is_valid', '    operator!=(const Edge & other)', '    operator==(const Edge & other)', '    get_hash']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\edit_distance.cpp', [], ['    ComputeEditDistance(const char *word1,const char *word2,size_t maxEditDistance)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\edit_distance.h', [], ['    ComputeEditDistance(const char *word1,const char *word2,size_t maxEditDistance)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\eigen_utils.h', [], ['    GetArrayIndices(const Eigen::ArrayBase & array)', '    GetSubArray(const Eigen::ArrayBase & array,const Eigen::ArrayBase & indices,Eigen::ArrayBase *out_array)', '    GetSubArray(const Eigen::ArrayBase & array,const Eigen::ArrayBase & indices)', '    GetSubArray(const Eigen::ArrayBase & array,const std::vector & indices)', '    GetSubArrayRows(const Eigen::ArrayBase & array2d,const Eigen::ArrayBase & row_indices,Eigen::ArrayBase *out_array)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\either.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\either_test.cpp', ['    ClassWithDestructorCallback', '    DestructorCallback', '    final', '    OnlyMoveableClassWithDestructorCallback'], ['    operator==(const MovableOnly & lhs,const MovableOnly & rhs)', '    TEST(EitherTest,SpaceUsage)', '    TEST(EitherTest,givenLeft)', '    TEST(EitherTest,givenRight)', '    TEST(EitherTest,givenMakeLeft)', '    TEST(EitherTest,givenMakeLeftWithSameType)', '    TEST(EitherTest,givenMakeRight)', '    TEST(EitherTest,givenMakeRightWithSameType)', '    TEST(EitherTest,givenMovableOnlyMakeLeft)', '    TEST(EitherTest,givenMovableOnlyMakeRight)', '    TEST(EitherTest,givenMultiParamMakeLeft)', '    TEST(EitherTest,givenMultiParamMakeRight)', '    TEST(EitherTest,givenLeftCopyConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeft_whenModified_thenValueIsChanged)', '    TEST(EitherTest,givenRight_whenModified_thenValueIsChanged)', '    TEST(EitherTest,canEmplaceConstructLeft)', '    TEST(EitherTest,canEmplaceConstructRight)', '    TEST(EitherTest,givenEqualLefts_thenAreEqual)', '    TEST(EitherTest,givenEqualLefts_thenAreNotUnequal)', '    TEST(EitherTest,givenEqualRights_thenAreEqual)', '    TEST(EitherTest,givenEqualRights_thenAreNotUnequal)', '    TEST(EitherTest,givenLeftAndRight_thenAreNotEqual)', '    TEST(EitherTest,givenLeftAndRight_thenAreUnequal)', '    TEST(EitherTest,OutputLeft)', '    TEST(EitherTest,OutputRight)', '    TEST(EitherTest,givenLeftAndRightWithSameType_thenAreNotEqual)', '    TEST(EitherTest,givenLeftAndRightWithSameType_thenAreUnequal)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalled)', '    TEST(EitherTest_Destructor,RightDestructorIsCalled)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterCopying)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterCopying)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterMoving)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterMoving)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterAssignment)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterAssignment)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterMoveAssignment)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterMoveAssignment)', '    test_with_matrix(std::vector,std::vector)', '    TestSpaceUsage', '    ClassWithDestructorCallback(const DestructorCallback *destructorCallback)', '    ClassWithDestructorCallback(const ClassWithDestructorCallback & rhs)', '    ~ClassWithDestructorCallback', '    EXPECT_CALLED(int times)', '    MovableOnly(int value)', '    MovableOnly', '    operator=(MovableOnly)', '    value', '    OnlyMoveableClassWithDestructorCallback(const DestructorCallback *destructorCallback)', '    OnlyMoveableClassWithDestructorCallback(OnlyMoveableClassWithDestructorCallback)', '    ~OnlyMoveableClassWithDestructorCallback']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\cuda_rtc\\elemenntwise_rtc_gpu.cc', ['    ElementwiseRTCFunction', '    final'], ['    ElementwiseRTCFunction', '    GetSource(int input_size,int output_size,const string command_string)', '    KernelName(Args,...)', '    ElementwiseRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~ElementwiseRTCOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\elementwise.cc', [], ['    Abs(const int N,const float *X,float *Y,CPUContext *)', '    Abs(const int N,const double *X,double *Y,CPUContext *)', '    Abs(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Abs(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Acos(const int N,const float *X,float *Y,CPUContext *)', '    Acos(const int N,const double *X,double *Y,CPUContext *)', '    Add(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Add(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Add(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Add(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    And(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    Asin(const int N,const float *X,float *Y,CPUContext *)', '    Asin(const int N,const double *X,double *Y,CPUContext *)', '    Atan(const int N,const float *X,float *Y,CPUContext *)', '    Atan(const int N,const double *X,double *Y,CPUContext *)', '    Axpby(const std::int64_t N,const float alpha,const float *X,const float beta,float *Y,CPUContext *)', '    Axpby(const std::int64_t N,const float *alpha,const float *X,const float *beta,float *Y,CPUContext *)', '    Axpy(const std::int64_t N,const float alpha,const float *X,float *Y,CPUContext *)', '    Axpy(const std::int64_t N,const float *alpha,const float *X,float *Y,CPUContext *)', '    BitwiseAnd(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseAnd(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseAnd(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    BitwiseOr(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseOr(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseOr(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    BitwiseXor(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseXor(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseXor(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Cbrt(const int N,const float *X,float *Y,CPUContext *)', '    Cbrt(const int N,const double *X,double *Y,CPUContext *)', '    CdfNorm(const int N,const float *X,float *Y,CPUContext *)', '    CdfNorm(const int N,const double *X,double *Y,CPUContext *)', '    Cos(const int N,const float *X,float *Y,CPUContext *)', '    Cos(const int N,const double *X,double *Y,CPUContext *)', '    Cosh(const int N,const float *X,float *Y,CPUContext *)', '    Cosh(const int N,const double *X,double *Y,CPUContext *)', '    Cube(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Cube(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Cube(const int N,const float *X,float *Y,CPUContext *)', '    Cube(const int N,const double *X,double *Y,CPUContext *)', '    Div(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Div(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Div(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Div(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    EQ(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    EQ(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    EQ(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    EQ(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    EQ(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Erf(const int N,const float *X,float *Y,CPUContext *)', '    Erf(const int N,const double *X,double *Y,CPUContext *)', '    Exp(const int N,const float *X,float *Y,CPUContext *)', '    Exp(const int N,const double *X,double *Y,CPUContext *)', '    GE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    GE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    GE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    GE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    GE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    GT(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    GT(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    GT(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    GT(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    GT(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Inv(const int N,const float *X,float *Y,CPUContext *)', '    Inv(const int N,const double *X,double *Y,CPUContext *)', '    LE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    LE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    LE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    LE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    LE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Log(const int N,const float *X,float *Y,CPUContext *)', '    Log(const int N,const double *X,double *Y,CPUContext *)', '    LT(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    LT(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    LT(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    LT(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    LT(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Max(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Max(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Max(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Max(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Min(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Min(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Min(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Min(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Mul(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Mul(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Mul(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Mul(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    NE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    NE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    NE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    NE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    NE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Neg(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Neg(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Neg(const int N,const float *X,float *Y,CPUContext *)', '    Neg(const int N,const double *X,double *Y,CPUContext *)', '    Or(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    Powx(const int N,const float *A,const float b,float *Y,CPUContext *)', '    Powx(const int N,const double *A,const double b,double *Y,CPUContext *)', '    Rsqrt(const int N,const float *X,float *Y,CPUContext *)', '    Rsqrt(const int N,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float alpha,const float *X,float *Y,CPUContext *)', '    Scale(const int N,const float *alpha,const float *X,float *Y,CPUContext *)', '    Scale(const int N,const double alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const double *alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float *alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Scale(const int N,const std::int32_t *alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Scale(const int N,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Scale(const int N,const std::int64_t *alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Set(const std::int64_t N,const float alpha,float *Y,CPUContext *)', '    Set(const std::int64_t N,const double alpha,double *Y,CPUContext *)', '    Set(const std::int64_t N,const int alpha,int *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int8_t alpha,std::int8_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int16_t alpha,std::int16_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int64_t alpha,std::int64_t *Y,CPUContext *)', '    Set(const std::int64_t N,const bool alpha,bool *Y,CPUContext *)', '    Set(const std::int64_t N,const char alpha,char *Y,CPUContext *)', '    Set(const std::int64_t N,const std::uint8_t alpha,std::uint8_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::uint16_t alpha,std::uint16_t *Y,CPUContext *)', '    Sign(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Sign(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Sign(const int N,const float *X,float *Y,CPUContext *)', '    Sign(const int N,const double *X,double *Y,CPUContext *)', '    Sin(const int N,const float *X,float *Y,CPUContext *)', '    Sin(const int N,const double *X,double *Y,CPUContext *)', '    SinCos(const int N,const float *X,float *S,float *C,CPUContext *)', '    SinCos(const int N,const double *X,double *S,double *C,CPUContext *)', '    Sinh(const int N,const float *X,float *Y,CPUContext *)', '    Sinh(const int N,const double *X,double *Y,CPUContext *)', '    Sqr(const int N,const float *X,float *Y,CPUContext *)', '    Sqr(const int N,const double *X,double *Y,CPUContext *)', '    Sqrt(const int N,const float *X,float *Y,CPUContext *)', '    Sqrt(const int N,const double *X,double *Y,CPUContext *)', '    Sub(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Sub(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Sub(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Sub(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Tan(const int N,const float *X,float *Y,CPUContext *)', '    Tan(const int N,const double *X,double *Y,CPUContext *)', '    Tanh(const int N,const float *X,float *Y,CPUContext *)', '    Tanh(const int N,const double *X,double *Y,CPUContext *)', '    Xor(const int N,const bool *A,const bool *B,bool *C,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\elementwise.h', [], ['    Abs(int N,const T *X,T *Y,Context *context)', '    Acos(int N,const T *X,T *Y,Context *context)', '    Add(int N,const T *A,const T *B,T *C,Context *context)', '    And(int N,const T *A,const T *B,T *C,Context *context)', '    Asin(int N,const T *X,T *Y,Context *context)', '    Atan(int N,const T *X,T *Y,Context *context)', '    Axpby(std::int64_t N,TAlpha alpha,const TData *X,TAlpha beta,TData *Y,Context *context)', '    Axpby(std::int64_t N,const TAlpha *alpha,const TData *X,const TAlpha *beta,TData *Y,Context *context)', '    Axpy(std::int64_t N,TAlpha alpha,const TData *X,TData *Y,Context *context)', '    Axpy(std::int64_t N,const TAlpha *alpha,const TData *X,TData *Y,Context *context)', '    BitwiseAnd(int N,const T *A,const T *B,T *C,Context *context)', '    BitwiseOr(int N,const T *A,const T *B,T *C,Context *context)', '    BitwiseXor(int N,const T *A,const T *B,T *C,Context *context)', '    Cbrt(int N,const T *X,T *Y,Context *context)', '    CdfNorm(int N,const T *X,T *Y,Context *context)', '    Cos(int N,const T *X,T *Y,Context *context)', '    Cosh(int N,const T *X,T *Y,Context *context)', '    Cube(int N,const T *X,T *Y,Context *context)', '    Div(int N,const T *A,const T *B,T *C,Context *context)', '    EQ(int N,const T *A,const T *B,bool *C,Context *context)', '    Erf(int N,const T *X,T *Y,Context *context)', '    Exp(int N,const T *X,T *Y,Context *context)', '    GE(int N,const T *A,const T *B,bool *C,Context *context)', '    GT(int N,const T *A,const T *B,bool *C,Context *context)', '    Inv(int N,const T *X,T *Y,Context *context)', '    LE(int N,const T *A,const T *B,bool *C,Context *context)', '    Log(int N,const T *X,T *Y,Context *context)', '    LT(int N,const T *A,const T *B,bool *C,Context *context)', '    Max(int N,const T *A,const T *B,T *C,Context *context)', '    Min(int N,const T *A,const T *B,T *C,Context *context)', '    Mul(int N,const T *A,const T *B,T *C,Context *context)', '    NE(int N,const T *A,const T *B,bool *C,Context *context)', '    Neg(int N,const T *X,T *Y,Context *context)', '    Not(int N,const T *X,T *Y,Context *context)', '    Or(int N,const T *A,const T *B,T *C,Context *context)', '    Powx(int N,const T *A,const T b,T *Y,Context *context)', '    Rsqrt(int N,const T *X,T *Y,Context *context)', '    Scale(int N,TAlpha alpha,const TData *X,TData *Y,Context *context)', '    Scale(int N,const TAlpha *alpha,const TData *X,TData *Y,Context *context)', '    Set(std::int64_t N,T alpha,T *X,Context *context)', '    Sign(int N,const T *X,T *Y,Context *context)', '    Sin(int N,const T *X,T *Y,Context *context)', '    SinCos(int N,const T *X,T *S,T *C,Context *context)', '    Sinh(int N,const T *X,T *Y,Context *context)', '    Sqr(int N,const T *X,T *Y,Context *context)', '    Sqrt(int N,const T *X,T *Y,Context *context)', '    Sub(int N,const T *A,const T *B,T *C,Context *context)', '    Tan(int N,const T *X,T *Y,Context *context)', '    Tanh(int N,const T *X,T *Y,Context *context)', '    Xor(int N,const T *A,const T *B,T *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_add_dnnlowp_op.cc', ['    AddDNNLowPOp'], ['    AddDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_add_gradient_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAddGradient', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_add_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAdd']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_add_op.h', [], ['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *,const TOut *,TGrad *dA,TGrad *dB,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_add_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAAdd', '    CAFFE_ANONYMOUS_VARIABLE_CUDAAddGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_div_gradient_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDivGradient', '    BinaryElementwiseWithArgsGradientOp(Args,...)', '    ComputeDivGradient(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const TGrad *dC,const TIn *B,const TOut *C,TGrad *dA,TGrad *dB,CPUContext *context)', '    DoRunWithType', '    RunOnDevice', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *B,const TOut *C,TGrad *dA,TGrad *dB,CPUContext *context)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_div_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDiv']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_div_op.h', [], ['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_dnnlowp_op.h', ['    BinaryElementwiseDNNLowPOp', '    UnaryElementwiseWithArgsDNNLowPOp'], ['    BinaryElementwiseDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    arguments_parsed_', '    RunOnDevice', '    UnaryElementwiseWithArgsDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\elementwise_fp16_fake_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAddFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUDivFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUMulFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSubFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumFakeFp16', '    getSizeFromDims(const std::vector & dims)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const float *A,const float *B,float *C,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_linear_dnnlowp_op.cc', [], ['    ElementwiseLinearDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_linear_dnnlowp_op.h', ['    final'], ['    ElementwiseLinearDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_linear_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUElementwiseLinear', '    CAFFE_ANONYMOUS_VARIABLE_CPUElementwiseLinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ElementwiseLinear', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ElementwiseLinearGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_linear_op.h', ['    final', '    final'], ['    ElementwiseLinearGradientOp(Args,...)', '    ElementwiseLinearOp(Args,...)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_logical_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIsMemberOf', '    CAFFE_ANONYMOUS_VARIABLE_CPUWhere', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsMemberOf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Where', '    get', '    get', '    get', '    get']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_logical_ops.h', ['    final', '    IsMemberOfValueHolder', '    final'], ['    has_values', '    DoRunWithType', '    RunOnDevice', '    WhereOp(Args,...)', '    get', '    DoRunWithType', '    GetRepeatedArgument', '    IsMemberOfOp(Args,...)', '    RunOnDevice', '    ~IsMemberOfOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_mul_dnnlowp_op.cc', ['    MulDNNLowPOp'], ['    GetQuantizationParameters_', '    MulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_mul_gradient_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMulGradient', '    ComputeMulGradient(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const TGrad *dC,const TIn *A,const TIn *B,TGrad *dA,TGrad *dB,CPUContext *context)', '    ComputeMulGradient(const int common_size,const int broadcast_size,const float *dC,const float *A,const float *B,float *dA,float *dB,CPUContext *context)', '    ComputeMulGradient(const int size,const float *dC,const float *A,const float *B,float *dA,float *dB)', '    GetGradientDefs', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *A,const TIn *B,const TOut *,TGrad *dA,TGrad *dB,CPUContext *context)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_mul_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMul']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_mul_op.h', [], ['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_op_gpu_test.cc', [], ['    CopyVector(const int N,const bool *x,bool *y)', '    CreateOperatorDef', '    TEST(ElementwiseGPUTest,And)', '    TEST(ElementwiseGPUTest,Or)', '    TEST(ElementwiseGPUTest,Xor)', '    TEST(ElementwiseGPUTest,Not)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_op_test.cc', [], ['    CopyVector(const int N,const bool *x,bool *y)', '    CopyVector(const int N,const int32_t *x,int32_t *y)', '    TEST(ElementwiseCPUTest,And)', '    TEST(ElementwiseTest,Or)', '    TEST(ElementwiseTest,Xor)', '    TEST(ElementwiseTest,Not)', '    TEST(ElementwiseTest,EQ)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_op_test.h', [], ['    CopyVector(const int N,const T *x,T *y)', '    CreateOperatorDef', '    DefineOperator(const std::string & op_type)', '    elementwiseAnd', '    elementwiseEQ', '    elementwiseNot', '    elementwiseOr', '    elementwiseXor', '    FillTensor(caffe2::Workspace *ws,const std::string & name,const std::vector & shape,const std::vector & values)', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    CreateBlob', '    GetBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseAnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseOr', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseXor', '    CAFFE_ANONYMOUS_VARIABLE_CPUEQ', '    CAFFE_ANONYMOUS_VARIABLE_CPUGE', '    CAFFE_ANONYMOUS_VARIABLE_CPUGT', '    CAFFE_ANONYMOUS_VARIABLE_CPULE', '    CAFFE_ANONYMOUS_VARIABLE_CPULT', '    CAFFE_ANONYMOUS_VARIABLE_CPUNE', '    CAFFE_ANONYMOUS_VARIABLE_CPUNot', '    CAFFE_ANONYMOUS_VARIABLE_CPUOr', '    CAFFE_ANONYMOUS_VARIABLE_CPUSign', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumReduceLike', '    CAFFE_ANONYMOUS_VARIABLE_CPUXor', '    RunWithBroadcast2(const T *a,T *y,size_t pre,size_t n,size_t post,CPUContext *)', '    RunWithBroadcastBack(const T *x,T *y,size_t post,size_t n,CPUContext *)', '    RunWithBroadcastFront(const T *x,T *y,size_t pre,size_t n,CPUContext *)', '    sum2one(const T *x,T *y,size_t n)', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_ops.h', ['    final', '    final', '    final', '    final'], ['    RunWithBroadcast2(const T *a,T *y,size_t pre,size_t n,size_t post,CPUContext *)', '    RunWithBroadcastBack(const T *x,T *y,size_t post,size_t n,CPUContext *)', '    RunWithBroadcastFront(const T *x,T *y,size_t pre,size_t n,CPUContext *)', '    sum2one(const T *x,T *y,size_t n)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    BinaryFunctorWithDefaultCtor(OperatorBase &)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A_data,const TIn *B_data,TOut *C_data,Context *context)', '    functor', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    BinaryElementwiseWithArgsGradientOp(Args,...)', '    BinaryElementwiseWithArgsOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    ones_', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    sum_buffer_', '    SumReduceLikeOp(Args,...)', '    UnaryElementwiseWithArgsOp(Args,...)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    operator()(const int N,const bool *X,bool *Y,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    functor', '    operator()(const int size,const TIn *X,TOut *Y,Context *context)', '    UnaryFunctorWithDefaultCtor(OperatorBase &)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    call', '    back_inserter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_ops_schema.cc', [], ['    BitwiseDocGenerator(const char *name)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Add', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AddGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_And', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseAnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseOr', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseXor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Div', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DivGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EQ', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MulGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Not', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Or', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sub', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SubGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumReduceLike', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Xor', '    ComparisonDocGenerator(const char *name,const char *desc,const char *extra)', '    ElementwiseOpShapeInference(const OperatorDef & def,const std::vector & in)', '    LogicalDocGenerator(const char *name,const char *extra)', '    MathDocGenerator(const char *name,const char *extra)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_ops_utils.cc', [], ['    ComputeBinaryBroadcastBackwardAxes(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_axes,std::vector *B_axes)', '    ComputeBinaryBroadcastBackwardDims(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_back_dims,std::vector *B_back_dims)', '    ComputeBinaryBroadcastForwardDims(const std::vector & A_dims,const std::vector & B_dims)', '    ComputeLegacyBroadcastSizes(const Tensor & A,const Tensor & B,int axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_ops_utils.h', [], ['    ComputeBinaryBroadcastBackwardAxes(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_axes,std::vector *B_axes)', '    ComputeBinaryBroadcastBackwardDims(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_back_dims,std::vector *B_back_dims)', '    ComputeBinaryBroadcastForwardDims(const std::vector & A_dims,const std::vector & B_dims)', '    ComputeLegacyBroadcastSizes(const Tensor & A,const Tensor & B,int axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_sub_gradient_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSubGradient', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_sub_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_sub_op.h', [], ['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *,const TOut *,TGrad *dA,TGrad *dB,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_sub_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDASub', '    CAFFE_ANONYMOUS_VARIABLE_CUDASubGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_sum_benchmark.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_sum_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumRelu', '    GetQuantizationParameters_', '    SumDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_sum_dnnlowp_op_avx2.cc', [], ['    ElementWiseSumAVX2(const T *input0,const T *input1,T *output,int len,float a_scale,int32_t a_zero_point,float b_scale,int32_t b_zero_point,float c_scale,int32_t c_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\elementwise_sum_op.cc', ['    final'], ['    IDEEPSumOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPSumOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elementwise_sum_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sum']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\elementwise_sum_relu_op.cc', ['    SumReluOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSumRelu', '    DoRunWithType', '    RunOnDevice', '    SumReluOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elu_op.cc', ['    GetEluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUElu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Elu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EluGradient', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elu_op.h', [], ['    EluFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    EluGradientFunctor(OperatorBase & op)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\elu_op_cudnn.cc', [], ['    final', '    final', '    CuDNNActivationGradientOp(Args,...)', '    CuDNNActivationOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\embedding.cpp', [], ['    EmbeddingBagImpl(const EmbeddingBagOptions & options_)', '    forward(const Tensor & input,const Tensor & offsets,const Tensor & per_sample_weights)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    EmbeddingImpl(const EmbeddingOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Embedding.cpp', [], ['    embedding(const Tensor & weight,const Tensor & indices,int64_t padding_idx,bool scale_grad_by_freq,bool sparse)', '    embedding_backward(const Tensor & grad,const Tensor & indices,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq,bool sparse)', '    embedding_dense_backward_cpu(const Tensor & grad_,const Tensor & indices,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq)', '    embedding_renorm_cpu_(Tensor & self,const Tensor & indices,double max_norm,double norm_type)', '    embedding_sparse_backward(const Tensor & grad_,const Tensor & indices_,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq)', '    weight_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\embedding.cpp', [], ['    EmbeddingBagOptions(int64_t num_embeddings,int64_t embedding_dim)', '    EmbeddingOptions(int64_t num_embeddings,int64_t embedding_dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\embedding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\embedding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\embedding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup.cc', [], ['    EmbeddingLookupGenericSlow(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup.h', [], ['    EmbeddingLookup(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_avx2.cc', [], ['    EmbeddingLookup_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_fused_8bit_rowwise_avx2.cc', [], ['    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_fused_8bit_rowwise_idx_avx2.cc', [], ['    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_idx.cc', [], ['    EmbeddingLookupGenericSlowIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_idx.h', [], ['    EmbeddingLookupIdx(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\embedding_lookup_idx_avx2.cc', [], ['    EmbeddingLookupIdx_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\EmbeddingBag.cpp', [], ['    _embedding_bag_dense_backward_cpu_max(const Tensor & grad,const Tensor & bag_size,const Tensor & max_indices,int64_t num_weights)', '    compute_counts(int64_t num_weights,int64_t *indices_data,int64_t indices_length)', '    compute_counts_uniq(int64_t num_weights,int64_t *indices_data,int64_t indices_length,const std::vector & counts)', '    apply_bag_size(const Tensor & offsets,const Tensor & indices,const int64_t mode,Tensor & output,const Tensor & bag_size)', '    apply_bag_size_backward(const Tensor & offsets,const Tensor & indices,const int64_t mode,Tensor & output,const Tensor & offset2bag,const Tensor & bag_size)', '    index_select_scale_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & scale,const Tensor & src,Tensor & output,const Tensor &,bool)', '    make_bag_size(const Tensor & offsets,const Tensor & indices,const int64_t mode,const bool requires_grad)', '    make_offset2bag(const Tensor & offsets,const Tensor & indices,Tensor & offset2bag)', '    _embedding_bag_sparse_backward(const Tensor & grad_,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,const Tensor & bag_size_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights)', '    _embedding_bag_backward(const Tensor & grad,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,const Tensor & bag_size_,const Tensor & max_indices_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,bool sparse,const Tensor & per_sample_weights)', '    _embedding_bag_dense_backward_cpu(const Tensor & grad_,const Tensor & indices_,const Tensor & offsets_,const Tensor & offset2bag__,const Tensor & bag_size_,const Tensor & max_indices_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights_)', '    _embedding_bag_dense_backward_cpu_sum_mean(const Tensor & grad,const Tensor & indices_,const Tensor & offsets_,const Tensor & offset2bag__,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights_,Tensor & index_grad_weight)', '    _embedding_bag_per_sample_weights_backward_cpu(const Tensor & grad,const Tensor & weight,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,int64_t mode)', '    _embedding_bag_per_sample_weights_backward_cpu_template(const Tensor & grad,const Tensor & weight,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,int64_t mode)', '    _embedding_bag_cpu(const Tensor & weight,const Tensor & indices,const Tensor & offsets,const bool scale_grad_by_freq,const int64_t mode,bool sparse,const Tensor & per_sample_weights,bool include_last_offset)', '    embedding_bag(const Tensor & weight,const Tensor & indices,const Tensor & offsets,const bool scale_grad_by_freq,const int64_t mode,bool sparse,const Tensor & per_sample_weights,bool include_last_offset)', '    embedding_bag_cpu_max(const Tensor & weight,const Tensor & indices,const Tensor & offset2bag,const Tensor & output,const Tensor & bag_size,const Tensor & offsets)', '    index_select_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & src,Tensor & output,const Tensor &,bool)', '    index_select_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & src,Tensor & output,const Tensor & offsets,bool include_last_offset)', '    index_select_scale_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & scale,const Tensor & src,Tensor & output,const Tensor & offsets,bool include_last_offset)', '    isFastPathIndexSelect(const Tensor & src,Tensor & output)', '    isFastPathIndexSelectScale(const Tensor & src,const Tensor & scale,Tensor & output)', '    fast_path_sum']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\empty.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\emulator.h', ['    Emulator'], ['    init', '    run(const uint64_t iterations)', '    ~Emulator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\enforce_finite_cpu.cc', [], ['    enforce_finite_op_impl_cpu(const at::Tensor & input_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\enforce_finite_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUEnforceFinite', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnforceFinite', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\enforce_finite_op.h', ['    final'], ['    buffer_', '    DoRunWithType', '    EnforceFiniteOp(Args,...)', '    EnforceOnCPU(const Tensor & input)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\engine.cpp', [], ['    call_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputBuffer)', '    call_post_hooks(Node & fn,variable_list outputs,const variable_list & inputs)', '    call_pre_hooks(Node & fn,variable_list inputs)', '    is_compatible_type(const at::TensorOptions & expected,const at::TensorOptions & actual)', '    forked_autograd_child', '    track_bad_autograd_forks', '    event', '    guard', '    parent_stream_guard', '    queue', '    set_default_engine_stub(EngineStub stub)', '    graph_task_completed(const std::shared_ptr & graph_task)', '    validate_outputs(const edge_list & edges,variable_list & grads,const std::function & format_error)', '    add_thread_pool_task(const std::weak_ptr & graph_task)', '    compute_dependencies(Node *root,GraphTask & task)', '    Engine', '    enqueue_blocked_task_on_cpu(NodeTask task)', '    evaluate_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputs)', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_graph_task_with_continuation(const std::shared_ptr & graph_task)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    get_base_engine', '    get_default_engine', '    graph_task_exec_post_processing(const std::shared_ptr & graph_task)', '    init_local_ready_queue(std::shared_ptr ready_queue)', '    initialize_device_threads_pool', '    is_checkpoint_valid', '    mark_graph_task_completed(const std::shared_ptr & graph_task)', '    queue_callback(std::function callback)', '    ready_queue(const std::shared_ptr & graph_task,at::Device device)', '    ready_queue_by_index(const std::shared_ptr & graph_task,int device_index)', '    ready_queue_size(const std::shared_ptr & graph_task,at::Device device)', '    reentrant_thread_init', '    release_workers', '    set_device(int device)', '    start_device_threads', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_main(const std::shared_ptr & graph_task,bool reentrant_thread)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)', '    ~Engine', '    Frame(Node *fn)', '    get_next_fn', '    init_to_execute(Node & graph_root,const edge_list & outputs)', '    set_exception(std::exception & e,const std::shared_ptr & fn)', '    set_exception_without_signal(const std::shared_ptr & fn)', '    GraphTaskGuard(std::shared_ptr graph_task)', '    restore_current_graph_task', '    ~GraphTaskGuard', '    getReentrantDepth', '    empty', '    pop', '    push(NodeTask item,bool incrementOutstandingTasks)', '    pushShutdownTask', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\engine.h', [], ['    set_default_engine_stub(EngineStub stub)', '    validate_outputs(const edge_list & edges,variable_list & grads,const std::function & format_error)', '    get_base_engine', '    get_default_engine', '    add_thread_pool_task(const std::weak_ptr & graph_task)', '    compute_dependencies(Node *root,GraphTask & task)', '    Engine', '    Engine', '    Engine', '    enqueue_blocked_task_on_cpu(NodeTask task)', '    evaluate_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputs)', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_graph_task_with_continuation(const std::shared_ptr & graph_task)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    graph_task_exec_post_processing(const std::shared_ptr & graph_task)', '    init_local_ready_queue(std::shared_ptr ready_queue)', '    initialize_device_threads_pool', '    is_checkpoint_valid', '    make_anomaly_metadata', '    mark_graph_task_completed(const std::shared_ptr & graph_task)', '    queue_callback(std::function callback)', '    ready_queue(const std::shared_ptr & graph_task,at::Device device)', '    ready_queue_by_index(const std::shared_ptr & graph_task,int device_index)', '    ready_queue_size(const std::shared_ptr & graph_task,at::Device device)', '    reentrant_thread_init', '    release_workers', '    set_device(int device)', '    start_device_threads', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_main(const std::shared_ptr & task,bool reentrant_thread)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)', '    ThreadPoolShared', '    ~Engine', '    can_checkpoint', '    Capture(int input_idx,int output_idx)', '    should_execute', '    GraphTask(bool keep_graph,bool grad_mode,int reentrant_depth,std::shared_ptr cpu_ready_queue,bool exit_on_error)', '    init_to_execute(Node & graph_root,const edge_list & outputs)', '    set_exception(std::exception & e,const std::shared_ptr & fn)', '    set_exception_without_signal(const std::shared_ptr & fn)', '    getReentrantDepth', '    NodeTask(std::weak_ptr base,std::shared_ptr fn,InputBuffer inputs,bool isShutdownTask)', '    operator()(NodeTask const & t1,NodeTask const & t2)', '    empty', '    pop', '    push(NodeTask item,bool incrementOutstandingTasks)', '    pushShutdownTask', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ensure_clipped_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureClipped', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureClipped', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ensure_clipped_op.h', ['    final'], ['    DoRunWithType', '    EnsureClippedOp(Args,...)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ensure_cpu_output_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureCPUOutput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureCPUOutput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ensure_cpu_output_op.h', ['    EnsureCPUOutputOp'], ['    CopyWithContext', '    EnsureCPUOutputOp(Args,...)', '    Input', '    InputIsTensorType', '    Output', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\enum.cpp', [], ['    TEST(EnumTest,AllEnums)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\enum.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\enum.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\erase_number_types.cpp', [], ['    EraseNumberTypesOnBlock(Block *block)', '    EraseNumberTypes(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\erase_number_types.h', [], ['    EraseNumberTypes(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\erf_op.cc', ['    GetErfGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUErf', '    CAFFE_ANONYMOUS_VARIABLE_CPUErfGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Erf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ErfGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\erf_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\err.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\utils\\error_messages.h', [], ['    requires_grad_leaf_error(bool requires_grad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\error_report.cpp', [], ['    get_stacked_errors(const std::vector & error_stack)', '    update_pending_range(const SourceRange & range)', '    current_call_stack', '    CallStack(const std::string & name)', '    ~CallStack', '    ErrorReport(const ErrorReport & e)', '    ErrorReport(SourceRange r)', '    what']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\error_report.h', [], ['    operator<<(const ErrorReport & e,const T & t)', '    update_pending_range(const SourceRange & range)', '    current_call_stack', '    CallStack(const std::string & name)', '    ~CallStack', '    ErrorReport(const ErrorReport & e)', '    ErrorReport(SourceRange r)', '    ErrorReport(const TreeRef & tree)', '    ErrorReport(const Token & tok)', '    what']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\eval.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\eval.h', ['    ExprEval', '    SimpleIREvaluator', '    Value', '    VarSubMutator'], ['    evaluateOp(const Expr *v)', '    args(,...)', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    div_value(T lhs,T rhs)', '    div_value(T lhs,T rhs)', '    div_value(bool lhs,bool rhs)', '    handle(v)', '    mod_value(T lhs,T rhs)', '    mod_value(T lhs,T rhs)', '    mod_value(bool lhs,bool rhs)', '    Substitute(const Expr *expr,const VarMapping & var_mapping)', '    Substitute(Stmt *stmt,const VarMapping & var_mapping)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    compute_intrinsics(IntrinsicsOp op_type,float v)', '    compute_intrinsics(IntrinsicsOp op_type,float v1,float v2)', '    accept', '    accept_mutator', '    call(Ts,...)', '    call(const std::vector & call_args)', '    dtype', '    ExprEval(const ExprHandle & expr,Ts,...)', '    ExprEval(const ExprHandle & expr,const std::vector & buffer_args)', '    operator()(Ts,...)', '    operator()(const std::vector & call_args)', '    value(std::vector & args)', '    value(Ts,...)', '    body', '    var', '    dtype', '    binary_op(const Value & lhs,const Value & rhs,IRNodeType op_type,bool option)', '    bind(const BufferArg & buf,const CallArg & data)', '    bitwise_binary_op(const Value & lhs,const Value & rhs,IRNodeType op_type)', '    call(const std::vector & args)', '    castValues(const Dtype & src_dtype,const Value & v)', '    compare_select_op(const Value & lhs,const Value & rhs,const Value & retval1,const Value & retval2,CompareSelectOperation cmp_op)', '    doCastFromSrc(const Dtype & src_dtype,const Dtype & dst_dtype,const Value & v)', '    operator()(const Ts &,...)', '    value', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Var *v)', '    visit(const Cast *v)', '    visit(const For *v)', '    visit(const Ramp *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit_binary_op(const BinaryOpNode *v,bool option)', '    visit_compare_select_op(const CompareSelect *v,CompareSelectOperation cmp_op)', '    ~SimpleIREvaluator', '    modf', '    remainderf', '    accept', '    accept_mutator', '    base_handle', '    make', '    value', '    as', '    as', '    as', '    as', '    as', '    as', '    as', '    as', '    as_vec', '    dtype', '    Value(const std::vector & v)', '    Value', '    Value(uint8_t v)', '    Value(int8_t v)', '    Value(int16_t v)', '    Value(int v)', '    Value(int64_t v)', '    Value(float v)', '    Value(double v)', '    Value((*) () decltype)', '    Value((*) () decltype)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    name_hint', '    mutate(const Var *var)', '    VarSubMutator(const VarMapping & var_mapping)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event.cc', [], ['    EventCreateCPU(const DeviceOption & option,Event *event)', '    EventErrorMessageCPU(const Event *event)', '    EventFinishCPU(const Event *event)', '    EventQueryCPU(const Event *event)', '    EventRecordCPU(Event *event,const void *,const char *err_msg)', '    EventResetCPU(Event *event)', '    EventSetCallbackCPU(Event *event,EventCallbackFunction callback)', '    EventSetFinishedCPU(const Event *event,const char *err_msg)', '    EventWaitCPUCPU(const Event *event,void *)', '  Static Member Variables', '    event_callback_setter_', '    event_creator_', '    event_err_msg_getter_', '    event_finished_setter_', '    event_finisher_', '    event_querier_', '    event_recorder_', '    event_resetter_', '    event_waiter_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Event.cpp', [], ['    THCPEvent_dealloc(THCPEvent *self)', '    THCPEvent_elapsed_time(THCPEvent *self,THCPEvent *other)', '    THCPEvent_from_ipc_handle(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPEvent_get_cuda_event(THCPEvent *self,void *unused)', '    THCPEvent_get_device(THCPEvent *self,void *unused)', '    THCPEvent_ipc_handle(THCPEvent *self,PyObject *noargs)', '    THCPEvent_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPEvent_query(THCPEvent *self,PyObject *noargs)', '    THCPEvent_record(THCPEvent *self,THCPStream *stream)', '    THCPEvent_synchronize(THCPEvent *self,PyObject *noargs)', '    THCPEvent_wait(THCPEvent *self,THCPStream *stream)', '    THCPEvent_init(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Event.h', [], ['    THCPEvent_Check(PyObject *obj)', '    THCPEvent_init(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event.h', ['    Event'], ['    CanSchedule(int parent_type,EventStatus parent_status,int child_type,bool child_supports_async)', '    CanSchedule(const Event & child_event,bool supports_async)', '    ErrorMessage', '    Event(const DeviceOption & option)', '    ExceptionTimestamp', '    Finish', '    GetDeviceOption', '    GetType', '    HasException', '    IsFinished', '    IsScheduled', '    Query', '    Record(DeviceType recorder_type,const void *context,const char *err_msg)', '    Reset', '    RethrowException', '    SetCallback(EventCallbackFunction callback)', '    SetFinished(const char *err_msg)', '    SetFinishedWithException(const char *err_msg)', '    SupportsCallback', '    Wait(DeviceType waiter_type,void *context)', '    ~Event', '    EventCreateFunctionRegisterer(EventCreateFunction f)', '    EventErrorMessageFunctionRegisterer(EventErrorMessageFunction f)', '    EventFinishFunctionRegisterer(EventFinishFunction f)', '    EventQueryFunctionRegisterer(EventQueryFunction f)', '    EventRecordFunctionRegisterer(EventRecordFunction f)', '    EventResetFunctionRegisterer(EventResetFunction f)', '    EventSetCallbackFunctionRegisterer(EventSetCallbackFunction f)', '    EventSetFinishedFunctionRegisterer(EventSetFinishedFunction f)', '    EventWaitFunctionRegisterer(EventWaitFunction f)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Event.h', [], ['    block(const Stream & stream)', '    Event(const Event &)', '    Event', '    operator=(const Event &)', '    device_index', '    device_type', '    flag', '    operator=(Event)', '    query', '    record(const Stream & stream)', '    recordOnce(const Stream & stream)', '    was_marked_for_recording', '    ~Event', '    Event', '    Event(const DeviceType _device_type,const EventFlag _flag)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event_cpu.h', [], ['    EventCanScheduleCPU(const Event *,const Event *)', '    EventCreateCPU(const DeviceOption & option,Event *event)', '    EventErrorMessageCPU(const Event *event)', '    EventFinishCPU(const Event *event)', '    EventQueryCPU(const Event *event)', '    EventRecordCPU(Event *event,const void *,const char *err_msg)', '    EventResetCPU(Event *event)', '    EventSetFinishedCPU(const Event *event,const char *err_msg)', '    EventWaitCPUCPU(const Event *event,void *)', '    CPUEventWrapper(const DeviceOption & option)', '    ~CPUEventWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event_gpu.cc', [], ['    EventCreateCUDA(const DeviceOption & option,Event *event)', '    EventErrorMessageCUDA(const Event *event)', '    EventFinishCUDA(const Event *event)', '    EventQueryCUDA(const Event *event)', '    EventRecordCUDA(Event *event,const void *context,const char *err_msg)', '    EventResetCUDA(Event *event)', '    EventSetFinishedCUDA(const Event *event,const char *err_msg)', '    EventWaitCPUCUDA(const Event *event,void *context)', '    EventWaitCUDACPU(const Event *event,void *context)', '    EventWaitCUDACUDA(const Event *event,void *context)', '    CudaEventWrapper(const DeviceOption & option)', '    ~CudaEventWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event_gpu_test.cc', [], ['    TEST(EventCUDATest,EventBasics)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\event_test.cc', [], ['    TEST(EventCPUTest,EventBasics)', '    TEST(EventCPUTest,EventErrors)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\example.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example1.c', [], ['    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example2.c', [], ['    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example3.c', [], ['    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example4.c', [], ['    tinfl_put_buf_func(const void *pBuf,int len,void *pUser)', '    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example5.c', [], ['    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\examples\\example6.c', [], ['    hsv_to_rgb(int hue,int min,int max,rgb_t *p)', '    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Exception.cpp', ['    ThreadWarningHandler'], ['    caller_(caller)', '    getBaseHandler', '    warn(SourceLocation source_location,const std::string & msg)', '    GetExceptionString(const std::exception & e)', '    get_handler', '    set_handler(WarningHandler *handler)', '    AppendMessage(const std::string & new_msg)', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    msg', '    msg_without_backtrace', '    process(const SourceLocation & source_location,const std::string & msg)', '  Static Member Variables', '    warning_handler_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Exception.h', ['    Error', '    WarningHandler', '    EnforceFiniteError', '    IndexError', '    ValueError'], ['    deprecated_AT_ASSERT', '    deprecated_AT_ASSERTM', '    deprecated_AT_ERROR', '    process(const SourceLocation & source_location,const std::string & msg)', '    if_empty_then(std::string x,std::string y)', '    GetExceptionString(const std::exception & e)', '    get_warning_handler', '    warn(SourceLocation source_location,const std::string & msg)', '    AppendMessage(const std::string & new_msg)', '    caller', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)', '    msg', '    msg_stack', '    msg_without_backtrace', '    what', '    what_without_backtrace', '    ~WarningHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\exception_message.h', [], ['    operator<<(std::ostream & out,const ExceptionMessage & msg)', '    ExceptionMessage(const std::exception & e)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\exception_test.cpp', [], ['    TEST(ExceptionTest,TORCH_INTERNAL_ASSERT_DEBUG_ONLY)', '    throw_func']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Exceptions.cpp', [], ['    formatMessage(const char *format,va_list fmt_args)', '    THPException_init(PyObject *module)', '    processErrorMsg(std::string str)', '    replaceAll(std::string & str,const std::string & old_str,const std::string & new_str)', '    vector', '    IndexError(const char *format,...)', '    process(const c10::SourceLocation & source_location,const std::string & msg)', '    TypeError(const char *format,...)', '    ValueError(const char *format,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Exceptions.h', [], ['    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    THPException_init(PyObject *module)', '    wrap_pybind_function_impl_(Func,std::index_sequence)', '    processErrorMsg(std::string str)', '    wrap_pybind_function(Func)', '    build_message', '    persist', '    python_error', '    python_error(const python_error & other)', '    python_error(python_error)', '    restore', '    what', '    ~python_error', '    IndexError(const char *format,...)', '    python_type', '    python_type', '    what', '    process(const at::SourceLocation & source_location,const std::string & msg)', '    PyWarningHandler', '    set_in_exception', '    ~PyWarningHandler', '    python_type', '    TypeError(const char *format,...)', '    python_type', '    ValueError(const char *format,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\Exceptions.h', ['    CuDNNError'], ['    _cublasGetErrorEnum(cublasStatus_t error)', '    cusparseGetErrorString(cusparseStatus_t status)', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\exceptions.h', ['    malformed_input', '    out_of_range_index', '    unimplemented_lowering', '    unsupported_dtype'], ['    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    malformed_input', '    malformed_input(const std::string & err)', '    malformed_input(const Expr *expr)', '    malformed_input(const Stmt *stmt)', '    out_of_range_index', '    out_of_range_index(const std::string & err)', '    unimplemented_lowering', '    unimplemented_lowering(const Expr *expr)', '    unimplemented_lowering(const Stmt *stmt)', '    unsupported_dtype', '    unsupported_dtype(const std::string & err)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\mkl\\Exceptions.h', [], ['    MKL_DFTI_CHECK(MKL_INT status)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Exceptions.h', ['    miopen_exception'], ['    HIP_CHECK(hipError_t error)', '    MIOPEN_CHECK(miopenStatus_t status)', '    miopen_exception(miopenStatus_t status,const char *msg)', '    miopen_exception(miopenStatus_t status,const std::string & msg)', '    string']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Exceptions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\execution_counter.h', ['    ExecutionCounter', '    ExecutionTrigger', '    ExecutionTriggerList'], ['    GetInstance', '    elapsed_value', '    ExecutionCounter(ExecutionTrigger & trigger)', '    ExecutionTrigger(const std::string & name)', '    ExecutionTrigger', '    operator=', '    trigger', '    value', '    AddTrigger(const std::string & name,ExecutionTrigger *trigger)', '    ExecutionTriggerList', '    ExecutionTriggerList', '    FindByName(const std::string & name)', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\executor.cpp', [], ['    compressContiguous(const at::IntArrayRef & sizes,const at::IntArrayRef & strides,const std::vector & cont,uint32_t *c_sizes,uint32_t *c_strides)', '    computeMapSize(const at::Tensor & tensor,const PartitionDesc & chunkDesc)', '    computeNumel(const at::ArrayRef sizes)', '    expandArgs(const KernelSpec & spec,std::vector & args,std::vector & map_size,bool dry_run)', '    shouldExpandArgs(const KernelSpec & spec,std::vector & args,std::vector & map_size)', '    arg_spec', '    launchFusion(const FusedKernel & fusion,const at::Device device,const at::ArrayRef & inputs,const at::ArrayRef & all_inputs,std::vector & outputs)', '    runFusion(const int64_t key,Stack & stack,std::string *code_out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\executor.h', [], ['    runFusion(const int64_t key,Stack & stack,std::string *code_out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\exit_transforms.cpp', ['    ExitStatus', '    Transform'], ['    TransformExits(std::shared_ptr & graph)', '    addIfOutputs(Node *n,at::ArrayRef true_outs,at::ArrayRef false_outs)', '    isGraphOrClosureBlock(Block *block)', '    owningNodeKind(Block *block)', '    registerBlockOutputs(Block *b,at::ArrayRef outs)', '    removeOutputs(Block *b)', '    replaceBlockOutputs(Block *b,at::ArrayRef outs)', '    ExitPair(Value *exit_v,at::ArrayRef exit_val_ref)', '    exitValues', '    hasExited', '    calcIfExitStatus(ExitStatus then_status,ExitStatus else_status)', '    constructThrowsExitPair', '    constructWillExitPair(at::ArrayRef exit_val_ref)', '    constructWontExitPair', '    deleteAfterExitNodes(Block *block,graph_node_list_iterator & iter)', '    destroyNodeAfterExit(Node *n)', '    ExitTransformer(std::shared_ptr graph)', '    getExitStatus(ExitPair & exit_pair)', '    getUnitValue(const TypePtr & type)', '    guardBlockNodes(Block *block,const ExitPair & exit_pair,graph_node_list_iterator & iter)', '    matchValuesWithUnitialized(at::ArrayRef values_to_match)', '    transformExits(Block *block)', '    transformIf(Node *node)', '    transformLoop(Node *node)', '    transformLoopContinuations', '    transformReturnStmts', '    updateTargetBlock(Block *block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\exit_transforms.h', [], ['    TransformExits(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\exp_op.cc', ['    GetExpGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUExp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Exp', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\exp_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\exp_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAExp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\expand_dims_cpu.cc', ['    final'], ['    operator()(const at::Tensor & input_,const at::Tensor & output_,c10::List)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUExpand', '    CAFFE_ANONYMOUS_VARIABLE_CPUExpandGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Expand', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExpandGradient', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_op.h', ['    final', '    final'], ['    DoRunWithType', '    DoRunWithType', '    ExpandGradientOp(Args,...)', '    ExpandOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAExpand', '    CAFFE_ANONYMOUS_VARIABLE_CUDAExpandGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_squeeze_dims_op.cc', ['    GetSqueezeGradient', '    GetExpandDimsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUExpandDims', '    CAFFE_ANONYMOUS_VARIABLE_CPUSqueeze', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExpandDims', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Squeeze', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\expand_squeeze_dims_op.cc', ['    final', '    final'], ['    IDEEPExpandDimsOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSqueezeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPExpandDimsOp', '    ~IDEEPSqueezeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_squeeze_dims_op.h', ['    ExpandDimsOp', '    SqueezeOp'], ['    ComputeDims(at::IntArrayRef inputDims,std::vector)', '    ExpandDimsOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    GetRepeatedArgument', '    operator=', '    RunOnDevice', '    SqueezeOp(Args,...)', '    SqueezeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\expand_squeeze_dims_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAExpandDims', '    CAFFE_ANONYMOUS_VARIABLE_CUDASqueeze']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\expanding-array.cpp', [], ['    TEST_F(ExpandingArrayTest,CanConstructFromInitializerList)', '    TEST_F(ExpandingArrayTest,CanConstructFromVector)', '    TEST_F(ExpandingArrayTest,CanConstructFromArray)', '    TEST_F(ExpandingArrayTest,CanConstructFromSingleValue)', '    TEST_F(ExpandingArrayTest,ThrowsWhenConstructedWithIncorrectNumberOfArgumentsInInitializerList)', '    TEST_F(ExpandingArrayTest,ThrowsWhenConstructedWithIncorrectNumberOfArgumentsInVector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\expanding_array.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ExpandUtils.cpp', [], ['    infer_size(IntArrayRef a,IntArrayRef b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ExpandUtils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\export.cpp', ['    EncoderBase', '    GraphEncoder'], ['    ATenTypeToOnnxType(at::ScalarType at_type)', '    check_onnx_proto(const std::string & proto_string)', '    CloseFile(FILE *fp)', '    CreateExternalFile(const at::Tensor & tensor,const std::string & tensorName,const std::string & onnx_file_path)', '    dump(const onnx::TensorProto & tensor,std::ostream & stream)', '    dump(const onnx::TensorShapeProto & shape,std::ostream & stream)', '    dump(const onnx::TypeProto_Tensor & tensor_type,std::ostream & stream)', '    dump(const onnx::TypeProto & type,std::ostream & stream)', '    dump(const onnx::ValueInfoProto & value_info,std::ostream & stream)', '    dump(const onnx::GraphProto & graph,std::ostream & stream,size_t indent)', '    dump(const onnx::AttributeProto & attr,std::ostream & stream,size_t indent)', '    dump(const onnx::NodeProto & node,std::ostream & stream,size_t indent)', '    dump(const onnx::OperatorSetIdProto & operator_set_id,std::ostream & stream)', '    dump(const onnx::ModelProto & model,std::ostream & stream,size_t indent)', '    export_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool strip_doc_string,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    export_opnames(const script::Module & m,std::set & opnames)', '    export_opnames(const script::Module & m)', '    GetExternalFileName(const c10::optional external_ref)', '    GetFileRootPath(const std::string & rootPath)', '    getNodeStackTraceString(const Node *n)', '    idt(size_t indent)', '    nlidt(size_t indent)', '    pretty_print_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool google_printer,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names)', '    prettyPrint(const onnx::ModelProto & model)', '    validateBlock(Block *b,onnx_torch::OperatorExportTypes operator_export_type)', '    validateGraph(const std::shared_ptr & graph,onnx_torch::OperatorExportTypes operator_export_type)', '    writeArchiveAndTensors(const std::string & archive_name,const char *data,size_t size,const std::vector & tensors,caffe2::serialize::PyTorchStreamWriter & out)', '    AddAttribute(onnx::NodeProto *node_proto,const jit::Node *node,const jit::Symbol name)', '    EncodeBlock(onnx::GraphProto *graph_proto,const Block *block,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool keep_initializers_as_inputs,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    EncodeGraph(onnx::GraphProto *graph_proto,const std::shared_ptr & graph,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool keep_initializers_as_inputs,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    EncodeIntermediateValueInfo(onnx::GraphProto *graph_proto,const Value *n)', '    EncoderBase(onnx_torch::OperatorExportTypes operator_export_type,bool strip_doc)', '    EncodeValueInfo(onnx::GraphProto *graph_proto,onnx::ValueInfoProto *v,const Value *n,const std::unordered_map,std::unordered_map,std::string)', '    get_model_proto', '    EncodeTensor(onnx::TensorProto *tensor_proto,const at::Tensor & tensor,const c10::optional external_ref,const bool use_external_data_format,const std::string & onnx_file_path)', '    get_raw_data_export_map', '    GraphEncoder(const std::shared_ptr & graph,int64_t onnx_opset_version,onnx_torch::OperatorExportTypes operator_export_type,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,bool strip_doc,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\macros\\Export.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\export.h', [], ['    check_onnx_proto(const std::string & proto_string)', '    export_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool strip_doc_string,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    export_opnames(const Module & m)', '    ExportModule(const Module & module,std::ostream & out,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::string & filename,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::function & writer_func,const ExtraFilesMap & extra_files,bool bytecode_format)', '    pretty_print_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool google_printer,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names)', '    SetExportModuleExtraFilesHook(ExportModuleExtraFilesHook hook)', '    writeArchiveAndTensors(const std::string & archive_name,const char *data,size_t size,const std::vector & tensors,caffe2::serialize::PyTorchStreamWriter & out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\export_c10_op_to_caffe2.cc', [], ['    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\export_c10_op_to_caffe2.h', ['    final'], ['    createC10OperatorWrapper(const c10::OperatorName & op_name)', '    has_value', '    to', '    array_inputs_', '    C10OperatorWrapper(const c10::OperatorHandle & op,const OperatorDef & operator_def,Workspace *ws)', '    callKernel_', '    get_nontensor_argument_(const c10::Argument & argument)', '    get_nontensor_argument_(const std::string & name,const c10::optional & default_value)', '    GetSingleArgument', '    HasSingleArgumentOfType', '    popOutputs_', '    preallocated_outputs_', '    pushInputs_', '    RunOnDevice', '    singleton']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\export_caffe2_op_to_c10.h', [], ['    _call_caffe2_op(const c10::FunctionSchema & schema,std::vector,c10::List)', '    _call_caffe2_op_from_c10(c10::Stack *stack,const c10::FunctionSchema & schema,_CallCaffe2OpFunc *call_op)', '    call_caffe2_op_from_c10(const c10::OperatorHandle &,c10::Stack *stack)', '    make_function_schema_for_c10(const char *schema_str)', '    op(schema,std::move inputs,std::move outputs)', '    ofTensors', '    create']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\export_module.cpp', ['    ScriptModuleSerializer'], ['    Table(const std::vector,IValue)', '    Tup(std::vector ivalues)', '    new_instr', '    ExportModule(const Module & module,std::ostream & out,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::string & filename,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::function & writer_func,const ExtraFilesMap & extra_files,bool bytecode_format)', '    GetExtraFilesHook', '    getFunctionTuple(const Function & func)', '    moduleMethodsTuple(const Module & module,std::vector & elements)', '    SetExportModuleExtraFilesHook(ExportModuleExtraFilesHook hook)', '    setstateTuple(const IValue & ivalue,std::vector & elements)', '    convertNamedType(const c10::NamedTypePtr & class_type)', '    ScriptModuleSerializer(const std::string & filename)', '    ScriptModuleSerializer(const std::function & writer_func)', '    serialize(const Module & module,const ExtraFilesMap & extra_files,bool bytecode_format)', '    writeArchive(const std::string & archive_name,const IValue & value)', '    writeByteCode(const Module & module)', '    writeCode(const at::NamedTypePtr & root_type)', '    writeExtraFiles(const Module & module,const ExtraFilesMap & extra_files)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\expr.cpp', [], ['    acos(const ExprHandle & v)', '    asin(const ExprHandle & v)', '    atan(const ExprHandle & v)', '    atan2(const ExprHandle & v1,const ExprHandle & v2)', '    ceil(const ExprHandle & v)', '    cos(const ExprHandle & v)', '    cosh(const ExprHandle & v)', '    erf(const ExprHandle & v)', '    erfc(const ExprHandle & v)', '    exp(const ExprHandle & v)', '    expm1(const ExprHandle & v)', '    fabs(const ExprHandle & v)', '    floor(const ExprHandle & v)', '    fmod(const ExprHandle & v1,const ExprHandle & v2)', '    frac(const ExprHandle & v)', '    ifThenElse(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    lgamma(const ExprHandle & v)', '    log(const ExprHandle & v)', '    log10(const ExprHandle & v)', '    log1p(const ExprHandle & v)', '    log2(const ExprHandle & v)', '    pow(const ExprHandle & v1,const ExprHandle & v2)', '    remainder(const ExprHandle & v1,const ExprHandle & v2)', '    round(const ExprHandle & v)', '    rsqrt(const ExprHandle & v)', '    sin(const ExprHandle & v)', '    sinh(const ExprHandle & v)', '    sqrt(const ExprHandle & v)', '    tan(const ExprHandle & v)', '    tanh(const ExprHandle & v)', '    trunc(const ExprHandle & v)', '    ExprHandle((*) () decltype)', '    ExprHandle(uint8_t v)', '    ExprHandle(int8_t v)', '    ExprHandle(int16_t v)', '    ExprHandle(int v)', '    ExprHandle(int64_t v)', '    ExprHandle(float v)', '    ExprHandle(double v)', '    ExprHandle((*) () decltype)', '    operator!=(const ExprHandle & other)', '    operator%(const ExprHandle & other)', '    operator&(const ExprHandle & other)', '    operator*(const ExprHandle & other)', '    operator+(const ExprHandle & other)', '    operator-(const ExprHandle & other)', '    operator/(const ExprHandle & other)', '    operator<(const ExprHandle & other)', '    operator<<(const ExprHandle & other)', '    operator<=(const ExprHandle & other)', '    operator==(const ExprHandle & other)', '    operator>(const ExprHandle & other)', '    operator>=(const ExprHandle & other)', '    operator>>(const ExprHandle & other)', '    operator^(const ExprHandle & other)', '    operator|(const ExprHandle & other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\expr.h', ['    Expr', '    ExprHandle', '    ExprNode', '    Var', '    VarHandle'], ['    acos(const ExprHandle & v)', '    asin(const ExprHandle & v)', '    atan(const ExprHandle & v)', '    atan2(const ExprHandle & v1,const ExprHandle & v2)', '    ceil(const ExprHandle & v)', '    cos(const ExprHandle & v)', '    cosh(const ExprHandle & v)', '    erf(const ExprHandle & v)', '    erfc(const ExprHandle & v)', '    exp(const ExprHandle & v)', '    expm1(const ExprHandle & v)', '    fabs(const ExprHandle & v)', '    floor(const ExprHandle & v)', '    fmod(const ExprHandle & v1,const ExprHandle & v2)', '    frac(const ExprHandle & v)', '    ifThenElse(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    lgamma(const ExprHandle & v)', '    log(const ExprHandle & v)', '    log10(const ExprHandle & v)', '    log1p(const ExprHandle & v)', '    log2(const ExprHandle & v)', '    pow(const ExprHandle & v1,const ExprHandle & v2)', '    remainder(const ExprHandle & v1,const ExprHandle & v2)', '    round(const ExprHandle & v)', '    rsqrt(const ExprHandle & v)', '    same_node(const ExprHandle & expr1,const ExprHandle & expr2)', '    sin(const ExprHandle & v)', '    sinh(const ExprHandle & v)', '    sqrt(const ExprHandle & v)', '    tan(const ExprHandle & v)', '    tanh(const ExprHandle & v)', '    trunc(const ExprHandle & v)', '    make(const std::string & name_hint,Dtype dtype)', '    make(Dtype dtype)', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    dtype', '    Expr(Dtype dtype,IRNodeType expr_type)', '    expr_type', '    isConstant', '    AsNode', '    AsNode', '    dtype', '    empty', '    ExprHandle', '    ExprHandle(decltype)', '    ExprHandle(const Expr *node)', '    ExprHandle(uint8_t v)', '    ExprHandle(int8_t v)', '    ExprHandle(int16_t v)', '    ExprHandle(int v)', '    ExprHandle(int64_t v)', '    ExprHandle(float v)', '    ExprHandle(double v)', '    node', '    node', '    operator!=(const ExprHandle & other)', '    operator%(const ExprHandle & other)', '    operator&(const ExprHandle & other)', '    operator*(const ExprHandle & other)', '    operator+(const ExprHandle & other)', '    operator-(const ExprHandle & other)', '    operator/(const ExprHandle & other)', '    operator<(const ExprHandle & other)', '    operator<<(const ExprHandle & other)', '    operator<=(const ExprHandle & other)', '    operator==(const ExprHandle & other)', '    operator>(const ExprHandle & other)', '    operator>=(const ExprHandle & other)', '    operator>>(const ExprHandle & other)', '    operator^(const ExprHandle & other)', '    operator|(const ExprHandle & other)', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    name_hint', '    Var(const std::string & name_hint,Dtype dtype)', '    empty', '    name_hint', '    node', '    operator!=(const VarHandle & other)', '    operator==(const VarHandle & other)', '    VarHandle', '    VarHandle(Dtype dtype)', '    VarHandle(const std::string & name_hint,Dtype dtype)', '    VarHandle(const Var *node)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\benchmarks\\operator_benchmark\\pt_extension\\extension.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\extension.cpp', [], ['    function_taking_optional(c10::optional tensor)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    sigmoid_add(torch::Tensor x,torch::Tensor y)', '    forward(torch::Tensor weights)', '    get', '    MatrixMultiplier(int A,int B)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\extension.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\extension_backend_test.cpp', [], ['    add_override(const Tensor & a,const Tensor & b,Scalar)', '    empty_override(IntArrayRef size,const TensorOptions & options,c10::optional optional_memory_format)', '    TEST(BackendExtensionTest,TestRegisterOp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Factory.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Factory.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\fake_quant_affine.h', [], ['    fake_quant_grad_per_channel_stub', '    fake_quant_grad_per_channel_stub', '    operator=', '    fake_quant_grad_tensor_stub', '    fake_quant_grad_tensor_stub', '    operator=', '    fake_quant_per_channel_stub', '    fake_quant_per_channel_stub', '    operator=', '    fake_quant_tensor_stub', '    fake_quant_tensor_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\fake_quant_per_channel_affine.cpp', [], ['    fake_quantize_per_channel_affine(const Tensor & self,const Tensor & scale,const Tensor & zero_point,int64_t axis,int64_t quant_min,int64_t quant_max)', '    fake_quantize_per_channel_affine_backward(const Tensor & dY,const Tensor & X,const Tensor & scale,const Tensor & zero_point,int64_t axis,int64_t quant_min,int64_t quant_max)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\fake_quant_per_tensor_affine.cpp', [], ['    fake_quantize_per_tensor_affine(const Tensor & self,double scale,int64_t zero_point,int64_t quant_min,int64_t quant_max)', '    fake_quantize_per_tensor_affine_backward(const Tensor & dY,const Tensor & X,double scale,int64_t zero_point,int64_t quant_min,int64_t quant_max)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\fakefp16_transform.cc', ['    C10FlagParser_fake_fp16_conversion_use_fp16_acc', '    C10FlagParser_fake_fp16_conversion_use_nnpi'], ['    fakeFp16Transform(NetDef *net)', '    getFakeFp16OpMapping(bool use_fp16_acc,bool use_nnpi)', '    C10FlagParser_fake_fp16_conversion_use_fp16_acc(const std::string & content)', '    C10FlagParser_fake_fp16_conversion_use_nnpi(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\fakefp16_transform.h', [], ['    getFakeFp16OpMapping(bool use_fp16_acc,bool use_nnpi)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\FakeGuardImpl.h', [], ['    getCurrentStreamIdFor(DeviceIndex i)', '    getDeviceIndex', '    resetStreams', '    setDeviceIndex(DeviceIndex i)', '    block(void *event,const Stream & stream)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    FakeGuardImpl(DeviceType)', '    FakeGuardImpl', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\fallback.cpp', [], ['    aliasAnalysisIsSpecialCase', '    runFallback(int64_t key,Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\fallback.h', [], ['    runFallback(int64_t key,Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\fatal_signal_asan_no_sig_test.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\testing\\faulty_process_group_agent.cpp', [], ['    fromVec(const std::vector & vec)', '    FaultyProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout,const std::vector & messagesToFail,int failNumSends)', '    parseMessagesToFailInput(const std::vector & messagesToFail)', '    send(const WorkerInfo & to,Message)', '    shouldFailMessage(MessageType type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\testing\\faulty_process_group_agent.h', ['    FaultyProcessGroupAgent'], ['    FaultyProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout,const std::vector & messagesToFail,int failNumSends)', '    parseMessagesToFailInput(const std::vector & messagesToFail)', '    send(const WorkerInfo & to,Message)', '    shouldFailMessage(MessageType type)', '    FaultyProcessGroupRpcBackendOptions(int num_send_recv_threads,std::chrono::milliseconds rpc_timeout,std::string init_method,std::vector messages_to_fail,int num_fail_sends)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fbgemm_pack_blob.h', [], ['    original_tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fbgemm_pack_matrix_cache.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fbgemm_pack_matrix_cache.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fbgemm_pack_op.cc', [], ['    QuantizeConvBias(const Blob & blob,int M,const TensorQuantizationParams & in_qparams,const vector & filter_qparams,vector & b_quantized)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvPackWeight', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FCPackWeight', '    ComputeColumnOffsets(int num_rows,int num_cols,const T *W,const vector & qparams,vector & col_offsets)', '    CountOutliers(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    ExtractOutlierMatrix(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    QuantizeWeight(const Blob & blob,int kernel_dim,int M,vector & qparams,vector & W_quantized,dnnlowp::QuantizationFactory *qfactory)', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ConvDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    GetConv3DParam_', '    GetConvParam_', '    RunOnDevice', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    FullyConnectedDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fbgemm_pack_op.h', ['    final', '    final', '    Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    Int8FCDNNLowpPackedWeightBlobShapeFunctions'], ['    ComputeColumnOffsets(int num_rows,int num_cols,const T *W,const vector & qparams,vector & col_offsets)', '    CountOutliers(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    ExtractOutlierMatrix(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    QuantizeWeight(const Blob & blob,int kernel_dim,int M,vector & qparams,vector & W_quantized,dnnlowp::QuantizationFactory *qfactory)', '    ConvDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    FullyConnectedDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    GetConv3DParam_', '    GetConvParam_', '    RunOnDevice', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    Int8FCDNNLowpPackedWeightBlobShapeFunctions', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~Int8FCDNNLowpPackedWeightBlobShapeFunctions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\fbgemm_utils.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\fbgemm_utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\fc-dynamic-run.cc', [], ['    compute_q8gemm_dq(const struct q8gemm_dq_context *context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    qnnpackLinearDynamic(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *input,const size_t input_stride,void *packed_weights,const float *bias,float *output,const size_t output_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\fc-prepack.cc', [], ['    PackBMatrix(const size_t input_channels,const size_t output_channels,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *kernel,const int32_t *bias)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\fc-run.cc', [], ['    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    qnnpackLinear(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t output_zero_point,const float output_scale,const uint8_t output_min,const uint8_t output_max,const uint8_t *input,const size_t input_stride,void *packed_weights,uint8_t *output,const size_t output_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\fc_cpu.cc', ['    final'], ['    dimErrorString', '    operator()(const at::Tensor & X_,const at::Tensor & W_,const at::Tensor & b_,const at::Tensor & Y_,int64_t axis,int64_t axis_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fc_fake_lowp_test.cc', [], ['    test_case(const float v,const float v_fp16,const float v_bfp16)', '    test_vector_case(const float v,const float v_fp16,const float v_bfp16)', '    isclose(float x,float y)', '    isrelclose(float x,float y)', '    mse(std::array & a1,std::array & a2)', '    TEST(FP16Quant,fp32_to_fp16)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fc_inference.cc', [], ['    CostInferenceForFC(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fc_inference.h', [], ['    CostInferenceForFC(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\feature_maps_ops.cc', ['    GetMergeMultiListFeatureTensorsGradient', '    GetMergeMultiMapFeatureTensorsGradient', '    GetMergeMultiScalarFeatureTensorsGradient', '    GetMergeSingleListFeatureTensorsGradient', '    GetMergeSingleMapFeatureTensorsGradient', '    GetMergeSingleScalarFeatureTensorsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiListFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiListFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiMapFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiMapFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiScalarFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiScalarFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleListFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleListFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleMapFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleMapFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleScalarFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleScalarFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiListFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiListFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiMapFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiMapFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiScalarFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiScalarFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleListFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleListFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleMapFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleMapFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleScalarFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleScalarFeatureTensorsGradient', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\feature_maps_ops.h', ['    MergeMultiListFeatureTensorsOp', '    MergeMultiListOrMapFeatureTensorsGradientOp', '    MergeMultiMapFeatureTensorsOp', '    MergeMultiScalarFeatureTensorsGradientOp', '    MergeMultiScalarFeatureTensorsOp', '    MergeSingleListFeatureTensorsOp', '    MergeSingleListOrMapFeatureTensorsGradientOp', '    MergeSingleMapFeatureTensorsOp', '    MergeSingleScalarFeatureTensorsGradientOp', '    MergeSingleScalarFeatureTensorsOp'], ['    DoRunWithType', '    MergeMultiListFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiListFeatureTensorsOp', '    DoRunWithType', '    MergeMultiListOrMapFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeMultiListOrMapFeatureTensorsGradientOp', '    DoRunWithType', '    DoRunWithType2', '    MergeMultiMapFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiMapFeatureTensorsOp', '    DoRunWithType', '    MergeMultiScalarFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeMultiScalarFeatureTensorsGradientOp', '    DoRunWithType', '    MergeMultiScalarFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiScalarFeatureTensorsOp', '    DoRunWithType', '    GetRepeatedArgument', '    MergeSingleListFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleListFeatureTensorsOp', '    DoRunWithType', '    MergeSingleListOrMapFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeSingleListOrMapFeatureTensorsGradientOp', '    DoRunWithType', '    DoRunWithType2', '    GetRepeatedArgument', '    MergeSingleMapFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleMapFeatureTensorsOp', '    DoRunWithType', '    MergeSingleScalarFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeSingleScalarFeatureTensorsGradientOp', '    DoRunWithType', '    GetRepeatedArgument', '    MergeSingleScalarFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleScalarFeatureTensorsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\feed_blob_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFeedBlob', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FeedBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\feed_blob_op.h', ['    FeedBlobOp'], ['    FeedBlobOp(Args,...)', '    GetSingleArgument', '    HasSingleArgumentOfType', '    Output', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\file_adapter.cc', [], ['    ~FileAdapter', '    FileAdapter(const std::string & file_name)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\file_adapter.h', ['    final'], ['    FileAdapter', '    operator=', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    ~FileAdapter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\testing\\file_check.cpp', [], ['    assertFind(const SourceRange & search_range,const std::string & sub,std::function extra_msg)', '    assertFind(const SourceRange & search_range,const std::string & sub,const Check & check)', '    assertFind(const std::shared_ptr & source,const std::string & sub,size_t start,const Check & check)', '    assertNotFind(const SourceRange & search_range,const std::string & sub,const Check & check)', '    operator<<(std::ostream & out,const Check & c)', '    operator<<(std::ostream & out,const FileCheckImpl & fc)', '    Check(CheckType type,std::string str,c10::optional count)', '    check(const std::string & str)', '    check_count(const std::string & str,size_t count,bool exactly)', '    check_dag(const std::string & str)', '    check_next(const std::string & str)', '    check_not(const std::string & str)', '    check_same(const std::string & str)', '    FileCheck', '    run(const std::string & test_file)', '    run(const Graph & graph)', '    run(const std::string & input_checks_string,const std::string & test_string)', '    run(const std::string & input_checks_string,const Graph & graph)', '    ~FileCheck', '    addCheck(Check check)', '    addCheck(CheckType type,const std::string & s,c10::optional count)', '    doCheckNot(const std::vector & nots,const std::shared_ptr & source,const SourceRange & prev,const SourceRange & next)', '    doChecks(const std::shared_ptr & source)', '    findNextStart(const std::shared_ptr & source,size_t prev_end)', '    matchDagGroup(const std::vector & group,const std::shared_ptr & source,const SourceRange & prev)', '    matchGroup(const std::vector & group,const std::shared_ptr & source,const SourceRange & prev)', '    parseSingleCheck(const std::shared_ptr & source,size_t *start)', '    parseStrings(const std::shared_ptr & source)', '    run(const std::string & test_file)', '    run(const std::string & checks_file,const std::string & test_file)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\testing\\file_check.h', [], ['    check(const std::string & str)', '    check_count(const std::string & str,size_t count,bool exactly)', '    check_dag(const std::string & str)', '    check_next(const std::string & str)', '    check_not(const std::string & str)', '    check_same(const std::string & str)', '    FileCheck', '    reset', '    run(const std::string & test_file)', '    run(const Graph & graph)', '    run(const std::string & input_checks_string,const std::string & test_string)', '    run(const std::string & input_checks_string,const Graph & graph)', '    ~FileCheck']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\file_store_handler.cc', [], ['    encodeName(const std::string & name)', '    add(const std::string &,int64_t)', '    check(const std::vector & names)', '    FileStoreHandler(const std::string & path,const std::string & prefix)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    objectPath(const std::string & name)', '    realPath(const std::string & path)', '    set(const std::string & name,const std::string & data)', '    tmpPath(const std::string & name)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~FileStoreHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\file_store_handler.h', ['    FileStoreHandler'], ['    add(const std::string &,int64_t)', '    check(const std::vector & names)', '    FileStoreHandler(const std::string & path,const std::string & prefix)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    objectPath(const std::string & name)', '    realPath(const std::string & path)', '    set(const std::string & name,const std::string & data)', '    tmpPath(const std::string & name)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~FileStoreHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\file_store_handler_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFileStoreHandlerCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FileStoreHandlerCreate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\file_store_handler_op.h', ['    final'], ['    FileStoreHandlerCreateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\file_store_handler_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAFileStoreHandlerCreate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\FileStore.cpp', ['    File', '    Lock'], ['    refresh(File & file,off_t pos,std::unordered_map,std::vector)', '    syscall(F fn)', '    File(const std::string & path,int flags,std::chrono::milliseconds timeout)', '    lockExclusive', '    lockShared', '    read(void *buf,size_t count)', '    read(std::string & str)', '    read(std::vector & data)', '    seek(off_t offset,int whence)', '    size', '    tell', '    write(const void *buf,size_t count)', '    write(const std::string & str)', '    write(const std::vector & data)', '    ~File', '    add(const std::string & key,int64_t i)', '    addHelper(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    FileStore(const std::string & path,int numWorkers)', '    get(const std::string & key)', '    set(const std::string & key,const std::vector & value)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~FileStore', '    flock(int operation)', '    Lock(int fd,int operation)', '    Lock(Lock)', '    unlock', '    ~Lock']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\FileStore.hpp', ['    FileStore'], ['    add(const std::string & key,int64_t i)', '    addHelper(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    FileStore(const std::string & path,int numWorkers)', '    get(const std::string & key)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~FileStore']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\FileStoreTest.cpp', [], ['    main(int argc,char **argv)', '    testHelper(const std::string prefix)', '    tmppath']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Fill.cpp', [], ['    fill_(Tensor & self,Scalar value)', '    fill_(Tensor & self,const Tensor & value)', '    fill_diagonal_(Tensor & self,Scalar fill_value,bool wrap)', '    fill_fast(Tensor & self,Scalar value_scalar)', '    fill_out(Tensor & self,Scalar value)', '    zero_(Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Fill.h', [], ['    fill_stub', '    fill_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\filler.h', ['    TensorFiller'], ['    DebugString', '    Dist(FillerDistribution dist)', '    Fill(Tensor *tensor,Context *context)', '    FixedSum(Type fixed_sum)', '    Max(Type max)', '    Min(Type min)', '    Shape(const std::vector & shape)', '    SparseLengths(Type total_length)', '    SparseSegments(Type max_segment)', '    TensorFiller(const std::vector & shape,Type fixed_sum)', '    TensorFiller(const std::vector & shape)', '    TensorFiller']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\filler_cpu.cc', [], ['    constant_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,int64_t dtype,c10::Scalar value)', '    filler_init(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape)', '    given_tensor_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,const at::Tensor & values_)', '    uniform_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,double min,double max)', '    real_shape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\filler_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUConstantFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUDiagonalFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGaussianFill', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsRangeFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUMSRAFill', '    CAFFE_ANONYMOUS_VARIABLE_CPURangeFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniformIntFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniqueUniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUXavierFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConstantFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DiagonalFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GaussianFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsRangeFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MSRAFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RangeFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniformIntFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniqueUniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_XavierFill', '    Fill(Tensor *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\filler_op.h', ['    FillerOp', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    LengthsRangeFillOp'], ['    FillerTensorInference(const OperatorDef & def,const vector & in)', '    shape', '    Fill(Tensor *output)', '    FillerOp(Args,...)', '    GetRepeatedArgument', '    InputIsTensorType', '    RunOnDevice', '    ~FillerOp', '    CheckRange', '    ConstantFillOp(Args,...)', '    DiagonalFillOp(Args,...)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    FillWithString(Tensor *output)', '    FillWithType(Tensor *output)', '    FillWithType(Tensor *output)', '    GaussianFillOp(Args,...)', '    GetStepSize(Tensor *output)', '    MSRAFillOp(Args,...)', '    RangeFillOp(Args,...)', '    UniformFillOp(Args,...)', '    UniqueUniformFillOp(Args,...)', '    VerifyOutputShape(Tensor *output)', '    XavierFillOp(Args,...)', '    LengthsRangeFillOp(Args,...)', '    RunOnDevice', '    ~LengthsRangeFillOp', '    dim', '    dim32', '    size', '    vec', '    partial_sum']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\FillKernel.cpp', [], ['    fill_non_native_type(TensorIterator & iter,Scalar value_scalar)', '    fill_kernel(TensorIterator & iter,Scalar value_scalar)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\find_duplicate_elements_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFindDuplicateElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FindDuplicateElements']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\find_duplicate_elements_op.h', ['    final'], ['    DoRunWithType', '    FindDuplicateElementsOp(Args,...)', '    RunOnDevice', '    ~FindDuplicateElementsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\find_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFind', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Find']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\find_op.h', ['    final'], ['    DoRunWithType', '    FindOp(Args,...)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\fixed_divisor.h', ['    FixedDivisor', '    FixedDivisor'], ['    CalcSignedMagic', '    d', '    Div(const std::int32_t n)', '    DivMod(const std::int32_t n,std::int32_t *q,int32_t *r)', '    FixedDivisor', '    FixedDivisor(const std::int32_t d)', '    magic', '    Mod(const std::int32_t n)', '    shift']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\fixed_divisor_test.cc', [], ['    CompareDivMod(int32_t v,int32_t divisor)', '    TEST(FixedDivisorTest,FixedDivisorInt32Test)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\fixup_onnx_conditionals.cpp', [], ['    FixupONNXConditionals(std::shared_ptr & graph)', '    FixupONNXIfs(Block *block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\fixup_onnx_conditionals.h', [], ['    FixupONNXConditionals(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\fixup_onnx_loop.cpp', [], ['    FuseSequenceSplitConcat(Block *b)', '    ConvertSequenceDependencies(Block *block)', '    CreateCastToBoolNode(Value *val,Graph *graph)', '    FixupONNXLoops(Block *block)', '    FixupONNXLoops(std::shared_ptr & graph)', '    InsertCastForCond(Value *cond_val,Graph *graph,Node *consumer_node)', '    IsCondCastRequired(Value *cond_val)', '    IsErasableSequence(const Node *loop_node,size_t i)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\fixup_onnx_loop.h', [], ['    FixupONNXLoops(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\fixup_trace_scope_blocks.cpp', [], ['    convertReturnsToTuples(Block *b)', '    convertTracedForksToRealForks(const std::shared_ptr & g)', '    createMethodCalls(const std::shared_ptr & g)', '    FixupTraceScopeBlocks(std::shared_ptr & graph,Module *self)', '    inlineScopeBlocks(Block *b)', '    isEligibleNode(Node *n)', '    lambdaLiftBlocksAndConvertToGraph(Block *b)', '    mangleMethodName(const std::string & method_name,const ClassTypePtr & mod_type)', '    runCleanupPasses(const std::shared_ptr & g)', '    runCleanupPasses(Module *m)', '    addSelfArgToTracedForwardNodes(Block *b)', '    buildAttrMap(const std::shared_ptr & graph)', '    convertAttrReferencesToLocalGetAttrs(Block *b,const c10::QualifiedName & prefix,Value *self)', '    destroyTracedAttrNodes(const std::shared_ptr & graph)', '    replaceTracedAttrInputOnNode(Node *n,size_t inp_idx,const c10::QualifiedName & prefix,Value *self,std::unordered_map & local_remaps,std::vector & unresolved_tracedattrs)', '    run(const std::shared_ptr & graph)', '    MakeDefsDominateUses', '    processNode(Node *n,Block *b)', '    run(Block *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\fixup_trace_scope_blocks.h', [], ['    FixupTraceScopeBlocks(std::shared_ptr & graph,Module *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Flags.h', ['    C10FlagParser'], ['    CommandLineFlagsHasBeenParsed', '    ParseCommandLineFlags(int *pargc,char ***pargv)', '    RegistryName', '    SetUsageMessage(const string & str)', '    UsageMessage', '    C10FlagParser', '    Parse(const std::string & content,T *value)', '    success']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\flags.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\flags_test.cpp', ['    C10FlagParser_c10_flags_test_only_flag'], ['    TEST(FlagsTest,TestGflagsCorrectness)', '    C10FlagParser_c10_flags_test_only_flag(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\flags_use_gflags.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\flags_use_no_gflags.cpp', [], ['    CommandLineFlagsHasBeenParsed', '    GlobalInitStream', '    ParseCommandLineFlags(int *pargc,char ***pargv)', '    RegistryName', '    SetUsageMessage(const string & str)', '    UsageMessage', '    Parse(const string & content,bool *value)', '    Parse(const string & content,double *value)', '    Parse(const string & content,int64_t *value)', '    Parse(const string & content,int *value)', '    Parse(const string & content,string *value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\flat_hash_map.h', ['    flat_hash_map', '    flat_hash_set', '    sherwood_v3_table'], ['    operator!=(const templated_iterator & lhs,const templated_iterator & rhs)', '    operator!=(const flat_hash_map & lhs,const flat_hash_map & rhs)', '    operator!=(const flat_hash_set & lhs,const flat_hash_set & rhs)', '    operator==(const templated_iterator & lhs,const templated_iterator & rhs)', '    operator==(const flat_hash_map & lhs,const flat_hash_map & rhs)', '    operator==(const flat_hash_set & lhs,const flat_hash_set & rhs)', '    log2(uint64_t value)', '    next_power_of_two(uint64_t i)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    to_insert(std::forward key,std::forward args,...)', '    mod0(uint64_t)', '    mod1009(uint64_t hash)', '    mod10193(uint64_t hash)', '    mod102877(uint64_t hash)', '    mod1037059(uint64_t hash)', '    mod10453007(uint64_t hash)', '    mod105359939(uint64_t hash)', '    mod1061961721(uint64_t hash)', '    mod10703903591(uint64_t hash)', '    mod107888587883(uint64_t hash)', '    mod1087448823553(uint64_t hash)', '    mod10960797308051(uint64_t hash)', '    mod11(uint64_t hash)', '    mod110477914016779(uint64_t hash)', '    mod1113547595345903(uint64_t hash)', '    mod11223856443489329(uint64_t hash)', '    mod113129383953203213(uint64_t hash)', '    mod1140272737634240411(uint64_t hash)', '    mod11493228998133068689(uint64_t hash)', '    mod1259(uint64_t hash)', '    mod127(uint64_t hash)', '    mod12853(uint64_t hash)', '    mod129607(uint64_t hash)', '    mod13(uint64_t hash)', '    mod1306601(uint64_t hash)', '    mod13169977(uint64_t hash)', '    mod132745199(uint64_t hash)', '    mod1337987929(uint64_t hash)', '    mod13486073473(uint64_t hash)', '    mod135931102921(uint64_t hash)', '    mod1370099663459(uint64_t hash)', '    mod13809739252051(uint64_t hash)', '    mod139193449418173(uint64_t hash)', '    mod1402982055436147(uint64_t hash)', '    mod14141172994150357(uint64_t hash)', '    mod142534092204280003(uint64_t hash)', '    mod1436653624766633509(uint64_t hash)', '    mod14480561146010017169(uint64_t hash)', '    mod151(uint64_t hash)', '    mod1597(uint64_t hash)', '    mod16193(uint64_t hash)', '    mod163307(uint64_t hash)', '    mod1646237(uint64_t hash)', '    mod16593127(uint64_t hash)', '    mod167248483(uint64_t hash)', '    mod1685759167(uint64_t hash)', '    mod16991387857(uint64_t hash)', '    mod17(uint64_t hash)', '    mod171262457903(uint64_t hash)', '    mod1726217406467(uint64_t hash)', '    mod17399181177241(uint64_t hash)', '    mod175372756929481(uint64_t hash)', '    mod1767646624268779(uint64_t hash)', '    mod17816761525534927(uint64_t hash)', '    mod179581703095829107(uint64_t hash)', '    mod1810070143251252131(uint64_t hash)', '    mod18446744073709551557(uint64_t hash)', '    mod197(uint64_t hash)', '    mod2(uint64_t hash)', '    mod2011(uint64_t hash)', '    mod20399(uint64_t hash)', '    mod205759(uint64_t hash)', '    mod2074129(uint64_t hash)', '    mod20906033(uint64_t hash)', '    mod210719881(uint64_t hash)', '    mod2123923447(uint64_t hash)', '    mod21407807219(uint64_t hash)', '    mod215777175787(uint64_t hash)', '    mod2174897647073(uint64_t hash)', '    mod21921594616111(uint64_t hash)', '    mod220955828033581(uint64_t hash)', '    mod2227095190691797(uint64_t hash)', '    mod22447712886978529(uint64_t hash)', '    mod226258767906406483(uint64_t hash)', '    mod2280545475268481167(uint64_t hash)', '    mod23(uint64_t hash)', '    mod251(uint64_t hash)', '    mod2539(uint64_t hash)', '    mod25717(uint64_t hash)', '    mod259229(uint64_t hash)', '    mod2613229(uint64_t hash)', '    mod26339969(uint64_t hash)', '    mod265490441(uint64_t hash)', '    mod2675975881(uint64_t hash)', '    mod26972146961(uint64_t hash)', '    mod271862205833(uint64_t hash)', '    mod2740199326961(uint64_t hash)', '    mod27619478504183(uint64_t hash)', '    mod278386898836457(uint64_t hash)', '    mod2805964110872297(uint64_t hash)', '    mod28282345988300791(uint64_t hash)', '    mod285068184408560057(uint64_t hash)', '    mod2873307249533267101(uint64_t hash)', '    mod29(uint64_t hash)', '    mod3(uint64_t hash)', '    mod313(uint64_t hash)', '    mod3203(uint64_t hash)', '    mod32401(uint64_t hash)', '    mod326617(uint64_t hash)', '    mod3292489(uint64_t hash)', '    mod33186281(uint64_t hash)', '    mod334496971(uint64_t hash)', '    mod3371518343(uint64_t hash)', '    mod33982775741(uint64_t hash)', '    mod342524915839(uint64_t hash)', '    mod3452434812973(uint64_t hash)', '    mod34798362354533(uint64_t hash)', '    mod350745513859007(uint64_t hash)', '    mod3535293248537579(uint64_t hash)', '    mod35633523051069991(uint64_t hash)', '    mod359163406191658253(uint64_t hash)', '    mod3620140286502504283(uint64_t hash)', '    mod37(uint64_t hash)', '    mod397(uint64_t hash)', '    mod4027(uint64_t hash)', '    mod40823(uint64_t hash)', '    mod411527(uint64_t hash)', '    mod4148279(uint64_t hash)', '    mod41812097(uint64_t hash)', '    mod421439783(uint64_t hash)', '    mod4247846927(uint64_t hash)', '    mod42815614441(uint64_t hash)', '    mod431554351609(uint64_t hash)', '    mod4349795294267(uint64_t hash)', '    mod43843189232363(uint64_t hash)', '    mod441911656067171(uint64_t hash)', '    mod4454190381383713(uint64_t hash)', '    mod44895425773957261(uint64_t hash)', '    mod452517535812813007(uint64_t hash)', '    mod4561090950536962147(uint64_t hash)', '    mod47(uint64_t hash)', '    mod499(uint64_t hash)', '    mod5(uint64_t hash)', '    mod5087(uint64_t hash)', '    mod51437(uint64_t hash)', '    mod518509(uint64_t hash)', '    mod5226491(uint64_t hash)', '    mod52679969(uint64_t hash)', '    mod530980861(uint64_t hash)', '    mod5351951779(uint64_t hash)', '    mod53944293929(uint64_t hash)', '    mod543724411781(uint64_t hash)', '    mod5480398654009(uint64_t hash)', '    mod55238957008387(uint64_t hash)', '    mod556773797672909(uint64_t hash)', '    mod5611928221744609(uint64_t hash)', '    mod56564691976601587(uint64_t hash)', '    mod570136368817120201(uint64_t hash)', '    mod5746614499066534157(uint64_t hash)', '    mod59(uint64_t hash)', '    mod631(uint64_t hash)', '    mod6421(uint64_t hash)', '    mod64811(uint64_t hash)', '    mod653267(uint64_t hash)', '    mod6584983(uint64_t hash)', '    mod66372617(uint64_t hash)', '    mod668993977(uint64_t hash)', '    mod6743036717(uint64_t hash)', '    mod67965551447(uint64_t hash)', '    mod685049831731(uint64_t hash)', '    mod6904869625999(uint64_t hash)', '    mod69596724709081(uint64_t hash)', '    mod7(uint64_t hash)', '    mod701491027718027(uint64_t hash)', '    mod7070586497075177(uint64_t hash)', '    mod71267046102139967(uint64_t hash)', '    mod718326812383316683(uint64_t hash)', '    mod7240280573005008577(uint64_t hash)', '    mod73(uint64_t hash)', '    mod797(uint64_t hash)', '    mod8089(uint64_t hash)', '    mod81649(uint64_t hash)', '    mod823117(uint64_t hash)', '    mod8296553(uint64_t hash)', '    mod83624237(uint64_t hash)', '    mod842879579(uint64_t hash)', '    mod8495693897(uint64_t hash)', '    mod85631228929(uint64_t hash)', '    mod863108703229(uint64_t hash)', '    mod8699590588571(uint64_t hash)', '    mod87686378464759(uint64_t hash)', '    mod883823312134381(uint64_t hash)', '    mod8908380762767489(uint64_t hash)', '    mod89790851547914507(uint64_t hash)', '    mod905035071625626043(uint64_t hash)', '    mod9122181901073924329(uint64_t hash)', '    mod97(uint64_t hash)', '    compute_max_lookups(uint64_t num_buckets)', '    allocate', '    deallocate', '    max_size', '    select_on_container_copy_construction', '    log2', '    next_power_of_two', '    commit(int8_t shift)', '    index_for_hash(uint64_t hash,uint64_t)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    at(const K & key)', '    at(const K & key)', '    operator flat_hash_map::V', '    emplace', '    end', '    find', '    flat_hash_map', '    insert_or_assign(const key_type & key,M)', '    insert_or_assign(key_type,M)', '    insert_or_assign(Table::const_iterator,const key_type & key,M)', '    insert_or_assign(Table::const_iterator,key_type,M)', '    operator[](const K & key)', '    operator[](K)', '    size', '    emplace(key_type)', '    emplace(const key_type)', '    emplace(Args,...)', '    emplace(const key_type & arg)', '    emplace(key_type & arg)', '    end', '    find', '    flat_hash_set', '    size', '    commit(int8_t)', '    index_for_hash(uint64_t hash,uint64_t num_slots_minus_one)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    commit(mod_function new_mod_function)', '    index_for_hash(uint64_t hash,uint64_t)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    operator()(T &,T)', '    operator()(T & lhs,T)', '    operator()(T &,const T &)', '    operator()(T & lhs,const T & rhs)', '    functor_storage', '    functor_storage(const Functor & functor)', '    functor_storage(function_ptr function)', '    operator const ska::detailv3::functor_storage::function_ptr &', '    operator ska::detailv3::functor_storage::function_ptr &', '    operator()(Args,...)', '    operator()(Args,...)', '    operator()(Args,...)', '    KeyOrValueEquality', '    KeyOrValueEquality(const key_equal & equality)', '    operator()(const key_type & lhs,const key_type & rhs)', '    operator()(const key_type & lhs,const value_type & rhs)', '    operator()(const value_type & lhs,const key_type & rhs)', '    operator()(const value_type & lhs,const value_type & rhs)', '    operator()(const key_type & lhs,const std::pair & rhs)', '    operator()(const std::pair & lhs,const key_type & rhs)', '    operator()(const value_type & lhs,const std::pair & rhs)', '    operator()(const std::pair & lhs,const value_type & rhs)', '    operator()(const std::pair & lhs,const std::pair & rhs)', '    KeyOrValueHasher', '    KeyOrValueHasher(const hasher & hash)', '    operator()(const key_type & key)', '    operator()(const key_type & key)', '    operator()(const value_type & value)', '    operator()(const value_type & value)', '    operator()(const std::pair & value)', '    operator()(const std::pair & value)', '    destroy_value', '    emplace(int8_t distance,Args,...)', '    has_value', '    is_at_desired_position', '    is_empty', '    sherwood_v3_entry', '    sherwood_v3_entry(int8_t distance_from_desired)', '    ~sherwood_v3_entry', '    begin', '    begin', '    bucket(const FindKey & key)', '    bucket_count', '    cbegin', '    cend', '    clear', '    compares_equal(const L & lhs,const R & rhs)', '    operator const_iterator', '    operator iterator', '    count(const FindKey & key)', '    deallocate_data(EntryPointer begin,uint64_t num_slots_minus_one,int8_t max_lookups)', '    emplace(Key,Args,...)', '    emplace_hint(const_iterator,Args,...)', '    emplace_new_key(int8_t distance_from_desired,EntryPointer current_entry,Key,Args,...)', '    empty', '    empty_default_table', '    end', '    end', '    equal_range(const FindKey & key)', '    equal_range(const FindKey & key)', '    erase(const_iterator to_erase)', '    erase(const_iterator begin_it,const_iterator end_it)', '    erase(const FindKey & key)', '    find(const FindKey & key)', '    find(const FindKey & key)', '    get_allocator', '    grow', '    hash_function', '    hash_object(const U & key)', '    hash_object(const U & key)', '    insert(const value_type & value)', '    insert(value_type)', '    insert(const_iterator,const value_type & value)', '    insert(const_iterator,value_type)', '    insert(It begin,It end)', '    insert(std::initializer_list il)', '    key_eq', '    load_factor', '    max_bucket_count', '    max_load_factor(float value)', '    max_load_factor', '    max_size', '    num_buckets_for_reserve(uint64_t num_elements)', '    operator=(const sherwood_v3_table & other)', '    operator=(sherwood_v3_table)', '    rehash(uint64_t num_buckets)', '    rehash_for_other_container(const sherwood_v3_table & other)', '    reserve(uint64_t num_elements)', '    reset_to_empty_state', '    sherwood_v3_table', '    sherwood_v3_table(size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(const sherwood_v3_table & other)', '    sherwood_v3_table(const sherwood_v3_table & other,const ArgumentAlloc & alloc)', '    sherwood_v3_table(sherwood_v3_table)', '    sherwood_v3_table(sherwood_v3_table,const ArgumentAlloc & alloc)', '    shrink_to_fit', '    size', '    swap(sherwood_v3_table & other)', '    swap_pointers(sherwood_v3_table & other)', '    operator ska::sherwood_v3_table::templated_iterator', '    operator*', '    operator++', '    operator++(int)', '    operator->', '    templated_iterator', '    templated_iterator(EntryPointer current)', '    ~sherwood_v3_table', '    addressof', '    ceil', '    lower_bound', '    next', '    swap', '    emplace']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\flatten_cpu.cc', [], ['    flatten_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_,int64_t axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\flatten_op.cc', ['    GetFlattenGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFlatten', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Flatten', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\flatten_op.h', ['    FlattenOp'], ['    TensorInferenceForFlatten(const OperatorDef & def,const std::vector & in)', '    FlattenOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\flexible_top_k.cc', ['    GetFlexibleTopKGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFlexibleTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPUFlexibleTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlexibleTopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlexibleTopKGradient', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    operator()(const std::pair & lhs,const std::pair & rhs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\flexible_top_k.h', ['    FlexibleTopKGradientOp', '    FlexibleTopKOp'], ['    FlexibleTopKGradientOp(Args,...)', '    RunOnDevice', '    FlexibleTopKOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\floor_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Floor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\floor_op.h', ['    final'], ['    FloorOp(Args,...)', '    RunOnDevice', '    ~FloorOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\FlushDenormal.cpp', [], ['    set_flush_denormal(bool on)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\FlushDenormal.h', [], ['    set_flush_denormal(bool on)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\fold.cpp', [], ['    FoldImpl(const FoldOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    UnfoldImpl(const UnfoldOptions & options_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\fold.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\fold.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\fold.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Formatting.cpp', [], ['    __printFormat(std::ostream & stream,const Tensor & self)', '    __printIndent(std::ostream & stream,int64_t indent)', '    __printMatrix(std::ostream & stream,const Tensor & self,int64_t linesize,int64_t indent)', '    printScale(std::ostream & stream,double scale)', '    __printTensor(std::ostream & stream,Tensor & self,int64_t linesize)', '    defaultfloat(std::ios_base & __base)', '    operator<<(std::ostream & out,const DeprecatedTypeProperties & t)', '    print(std::ostream & stream,const Tensor & tensor_,int64_t linesize)', '    operator<<(std::ostream & out,Backend b)', '    FormatGuard(std::ostream & out)', '    ~FormatGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Formatting.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Formatting.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\fp16_fma.cc', [], ['    fma_fp16(int N,const float *A,const float *B,float *Out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\fp16_fma.h', [], ['    fma_fp16(int N,const float *A,const float *B,float *Out)', '    fma_fp16_slow(int N,const float *A,const float *B,float *Out)', '    fma_fp16_slow(const float A,const float B,float Out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\fp16_fma_slow.cc', [], ['    countLeadingZeros32(bits32 a)', '    extractFloat16Exp(float16 a)', '    extractFloat16Frac(float16 a)', '    extractFloat16Sign(float16 a)', '    fake_fma_fp16_slow(float v1,float v2,float v3)', '    fake_fma_fp16_slow(int N,const float *A,const float *B,float *Out)', '    float16_is_quiet_nan(float16 a)', '    float16_is_signaling_nan(float16 a)', '    float16_muladd(float16 a,float16 b,float16 c,flag negate_product)', '    float_raise(int8 flags)', '    fma16(const Word16 input,const Word16 a,const Word16 b,const Word32 fcr,const Word32 fsr_i,Word16 *result,Word32 *fsr_o)', '    fp_mac_h(Word16 d0,Word16 d1,Word16 d2,Word32 negate_product,Word32 fcr,Word32 fsr_i,Word16 *res,Word32 *fsr_o)', '    GetException(Word32 fsr)', '    GetRound(Word32 fcr)', '    normalizeFloat16Subnormal(bits16 aSig,int16 *zExpPtr,bits16 *zSigPtr)', '    packFloat16(flag zSign,int16 zExp,bits16 zSig)', '    pickNaNMulAdd(flag aIsQNaN,flag aIsSNaN,flag bIsQNaN,flag bIsSNaN,flag cIsQNaN,flag cIsSNaN,flag infzero)', '    propagateFloat16MulAddNaN(float16 a,float16 b,float16 c,flag infzero)', '    roundAndPackFloat16(flag zSign,int16 zExp,bits16 zSig)', '    shift16RightJamming(bits16 a,int16 count,bits16 *zPtr)', '    shift32RightJamming(bits32 a,int16 count,bits32 *zPtr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\fp16_fma_test.cc', [], ['    TEST(FP16_FMA,Simple)', '    TEST(FP16_FMA,Comprehensive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\fp16_momentum_sgd_op.h', ['    final'], ['    fp16_momentum_sgd_update(int N,const at::Half *g,const at::Half *m,at::Half *ng,at::Half *nm,const float *lr,float momentum,bool nesterov,float weight_decay,bool fp32_update,at::Half *param,Context *)', '    FP16MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    momentum_', '    RunOnDevice', '    weight_decay_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\fp32-neon.c', [], ['    pytorch_qnnp_requantize_fp32__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\fp32-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\fp32-psimd.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\fp32-psimd.c', [], ['    pytorch_qnnp_requantize_fp32__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\fp32-scalar.c', [], ['    pytorch_qnnp_requantize_fp32__scalar_lrintf(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_magic(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\fp32-scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\fp32-sse2.c', [], ['    pytorch_qnnp_requantize_fp32__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\fp32-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\fp32_momentum_sgd_op.h', ['    final'], ['    fp32_momentum_sgd_update(int N,const float *g,const float *m,float *ng,float *nm,const float *lr,float momentum,bool nesterov,float weight_decay,float *param,Context *)', '    FP32MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    momentum_', '    RunOnDevice', '    weight_decay_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\FractionalMaxPool2d.cpp', [], ['    fractional_max_pool2d_backward_out_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int numBatch,int numPlanes,int inputW,int inputH,int outputW,int outputH)', '    fractional_max_pool2d_backward_out_single_batch_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int numPlanes,int inputW,int inputH,int outputW,int outputH)', '    fractional_max_pool2d_generate_intervals(scalar_t sample,int inputSize,int outputSize,int poolSize)', '    fractional_max_pool2d_out_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int numBatch,int numPlanes,int inputW,int inputH,int outputW,int outputH,int poolSizeW,int poolSizeH)', '    fractional_max_pool2d_out_single_batch_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int numPlanes,int inputW,int inputH,int outputW,int outputH,int poolSizeW,int poolSizeH)', '    fractional_max_pool2d_backward_cpu(const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool2d_backward_out_cpu(at::Tensor & gradInput,const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool2d_backward_out_cpu_template(const at::Tensor & input,const at::Tensor & gradOutput_,at::Tensor & gradInput,IntArrayRef output_size,IntArrayRef pool_size,const at::Tensor & indices)', '    fractional_max_pool2d_cpu(const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool2d_out_cpu(at::Tensor & output,at::Tensor & indices,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool2d_out_cpu_template(const at::Tensor & input_,at::Tensor & output,IntArrayRef output_size,IntArrayRef pool_size,at::Tensor & indices,const at::Tensor & randomSamples)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\FractionalMaxPool3d.cpp', [], ['    fractional_max_pool3d_backward_out_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int64_t numBatch,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW)', '    fractional_max_pool3d_backward_out_single_batch_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW)', '    fractional_max_pool3d_out_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int64_t numBatch,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW,int64_t poolSizeT,int64_t poolSizeH,int64_t poolSizeW)', '    fractional_max_pool3d_out_single_batch_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW,int64_t poolSizeT,int64_t poolSizeH,int64_t poolSizeW)', '    generate_intervals(scalar_t sample,int64_t inputSize,int64_t outputSize,int64_t poolSize)', '    fractional_max_pool3d_backward_cpu(const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool3d_backward_out_cpu(at::Tensor & gradInput,const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool3d_backward_out_cpu_template(const Tensor & input,const Tensor & gradOutput_,Tensor & gradInput,IntArrayRef output_size,IntArrayRef pool_size,const Tensor & indices)', '    fractional_max_pool3d_cpu(const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool3d_out_cpu(at::Tensor & output,at::Tensor & indices,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool3d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef pool_size,IntArrayRef output_size,const Tensor & randomSamples)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\free_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFree', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Free']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\free_op.h', ['    FreeOp'], ['    Reset', '    FreeOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\free_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAFree']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\freeze_module.cpp', ['    AttributePropagator'], ['    freeze_module(const Module & module)', '    AttributePropagator(Module & module)', '    cleanupFrozenModule(std::shared_ptr & graph)', '    findConstantAttr(Value *input,std::string & name,Module & attrModule)', '    insertMutableAttr(const std::string & name,const IValue & attr,Module & attrModule)', '    overrideGradient(IValue)', '    propagateAttributes(std::shared_ptr & graph)', '    recordMutableAttrs(std::shared_ptr & graph)', '    recordReferencedAttrs(std::shared_ptr & graph)', '    run(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\freeze_module.h', [], ['    freeze_module(const Module & module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\ftrl_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFtrl', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFtrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Ftrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFtrl', '    ftrl_compute(const T w,const T n,const T z,const T g,T & nw,T & nn,T & nz,const FtrlParams & params)', '    ftrl_update(int N,const T *w,const T *nz,const T *g,T *new_w,T *new_nz,const FtrlParams & params,Context *)', '    sgn(const T x)', '    RunOnDevice', '    DoRun']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\ftrl_op.h', ['    final', '    final'], ['    DoRun', '    FtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    SparseFtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    FtrlParams(OperatorBase *op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\fully-connected-operator-tester.h', ['    FullyConnectedOperatorTester', '    Mode'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    inputChannels(size_t inputChannels)', '    inputChannels', '    inputChannels_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputChannels(size_t outputChannels)', '    outputChannels', '    outputChannels_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8(const Mode mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\fully-connected.c', [], ['    pytorch_qnnp_create_fully_connected_nc_q8(size_t input_channels,size_t output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *fully_connected_out)', '    pytorch_qnnp_setup_fully_connected_nc_q8(pytorch_qnnp_operator_t fully_connected,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\fully-connected.cc', [], ['    TEST(FULLY_CONNECTED_OP,integration_test_static)', '    TEST(FULLY_CONNECTED_OP,integration_test_runtime)', '    TEST(FULLY_CONNECTED_OP,integration_test_dynamic)', '    TEST(FULLY_CONNECTED_OP,zero_batch_static)', '    TEST(FULLY_CONNECTED_OP,zero_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,zero_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_input_stride_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_output_stride_static)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_dnnlowp_acc16_op.cc', [], ['    block', '    FullyConnectedDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_dnnlowp_acc16_op.h', ['    final'], ['    FullyConnectedDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_dnnlowp_op.cc', ['    C10FlagParser_caffe2_dnnlowp_enforce_default_operators'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FCRelu', '    C10FlagParser_caffe2_dnnlowp_enforce_default_operators(const std::string & content)', '    FullyConnectedDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_dnnlowp_op.h', ['    FullyConnectedDNNLowPOp'], ['    axis_', '    axis_w_', '    b_dequantized_data_', '    b_quantized_data_', '    FullyConnectedDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    is_weight_constant_', '    requantization_param_selected_', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_fake_lowp_op.cc', [], ['    dimErrorString', '    DoRunWithType', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_fake_lowp_op.h', ['    final', '    FullyConnectedGradientFakeLowpFPOp'], ['    fp32_to_bfp14(const float *source,size_t size,float *dest)', '    fp32_to_bfp16(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_round(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_scalar(const float *source,size_t size,float *dest)', '    fp32_to_bfp24(const float *source,size_t size,float *dest)', '    fp32_to_fp16(const float *source,size_t size,float *dest)', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedFakeLowpFPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedFakeLowpFPOp', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedGradientFakeLowpFPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedGradientFakeLowpFPOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\fully_connected_fake_lowp_op_avx2.cc', [], ['    fp32_to_bfp14(const float *source,size_t size,float *dest)', '    fp32_to_bfp16(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_round(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_scalar(const float *source,size_t size,float *dest)', '    fp32_to_bfp24(const float *source,size_t size,float *dest)', '    fp32_to_fp16(const float *source,size_t size,float *dest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fully_connected_op.cc', ['    GetFCGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUFC', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCTransposed', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCTransposed', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCTransposedGradient', '    CostInferenceForFCGradient(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCGradientShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\fully_connected_op.cc', ['    final', '    final'], ['    axis_', '    axis_', '    axis_w_', '    axis_w_', '    IDEEPFullyConnectedGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPFullyConnectedOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPFullyConnectedGradientOp', '    ~IDEEPFullyConnectedOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fully_connected_op.h', ['    final', '    FullyConnectedGradientOp'], ['    dimErrorString', '    dimErrorString', '    has_value', '    numel', '    Resize', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedOp', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedGradientOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_decomposition.cc', ['    GetFCDecompGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Decomp', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCGradient_Decomp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Decomp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient_Decomp', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_decomposition.h', ['    final', '    FullyConnectedDecompGradientOp'], ['    bias_multiplier_', '    FullyConnectedOpDecomp(const OperatorDef & operator_def,Workspace *ws)', '    multi_buffer_', '    RunOnDevice', '    ~FullyConnectedOpDecomp', '    bias_multiplier_', '    du_buffer_', '    dv_buffer_', '    dx_buffer_', '    FullyConnectedDecompGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedDecompGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_decomposition_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAFC_Decomp', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCGradient_Decomp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fully_connected_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAFC', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCTransposed', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCTransposedGradient', '    RunFullyConnectedGradientOpOnCUDADevice(const bool float16_compute,FullyConnectedGradientOp *op)', '    RunFullyConnectedOpOnCUDADevice(const bool float16_compute,FullyConnectedOp *op)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_prune.cc', ['    GetFCPruneGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Prune', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCGradient_Prune', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Prune', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient_Prune', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_prune.h', ['    final', '    FullyConnectedPruneGradientOp'], ['    AggrDW(T *ag_dw,const T *dw,int N,int K,Context *context)', '    AggrDW(float *ag_dw,const float *dw,int N,int K,CPUContext *context)', '    MaskMatrix(const T *mask,T *mat,int M,int N)', '    MaskMatrix(const float *mask,float *mat,int M,int N)', '    MaskMatrix_Inc(T *mask_seq,T *mat,int M,int N,int seq_len,T target)', '    MaskMatrix_Inc(float *mask_seq,float *mat,int,int,int seq_len,float target)', '    MatrixCompare_LT(const T *mat,float thres,T *mask_seq,int M,int N)', '    MatrixCompare_LT(const float *mat,float thres,float *mask_seq,int M,int N)', '    shape(int i,int j)', '    shape(Shape vs)', '    shape(int i)', '    bias_multiplier_', '    FullyConnectedOpPrune(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedOpPrune', '    bias_multiplier_', '    comp_r_buf_', '    FullyConnectedPruneGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    sum_buffer_', '    ~FullyConnectedPruneGradientOp', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_sparse.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Sparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Sparse']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\fully_connected_op_sparse.h', ['    final'], ['    shape(int i,int j)', '    shape(int i)', '    shape(Shape vs)', '    Sparse_mm(const T *acsr,const int *ia,const int *ja,int m,int k,int n,const T *b,T *c,Context *context)', '    Sparse_mm(const float *acsr,const int *ia,const int *ja,int m,int k,int n,const float *b,float *c,CPUContext *)', '    trans_mat(const T *o,T *t,int m,int n,Context *context)', '    trans_mat(const float *o,float *t,int m,int n,CPUContext *)', '    bias_multiplier_', '    FullyConnectedOp_SPARSE(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedOp_SPARSE']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\function.cpp', [], ['    gatherFunctions(Node *func,std::vector)', '    deleteNode(Node *function)', '    get_next_sequence_nr', '    metadata', '    name', '    peek_at_next_sequence_nr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\function.cpp', [], ['    append_constant(const c10::IValue & constant)', '    append_instruction(OpCode op,int X,int N)', '    append_operator(const std::string & name,const std::string & overload_name)', '    append_type(const at::TypePtr & type)', '    Function(c10::QualifiedName name)', '    run(Stack & stack)', '    set_register_size(size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\function.cpp', [], ['    unpack_dim_args(const std::vector & dim_args,std::vector *dims,std::vector *vars)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    total_index', '    ElementStmt(size_t index)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\function.h', ['    Function'], ['    append_constant(const c10::IValue & constant)', '    append_instruction(OpCode op,int X,int N)', '    append_operator(const std::string & name,const std::string & overload_name)', '    append_type(const c10::TypePtr & type)', '    Function(c10::QualifiedName name)', '    name', '    qualname', '    run(Stack & stack)', '    set_register_size(size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\function.h', ['    Function'], ['    arg(int index)', '    args', '    bodies', '    body(size_t index)', '    dim(int index)', '    dims', '    ElementStmt(size_t index)', '    func_var(size_t index)', '    func_vars', '    Function(const std::string & func_name,const std::vector & dims,const std::vector & args,const Expr *body)', '    Function(const std::vector & func_names,const std::vector & dims,const std::vector & args,const std::vector & bodies)', '    ndim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\function_hook.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\function_hook.h', [], ['    operator()(const variable_list & outputs,const variable_list & inputs)', '    ~FunctionPostHook', '    operator()(const variable_list & grads)', '    ~FunctionPreHook']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\function_impl.cpp', [], ['    ensure_defined', '    getSchema', '    run(Stack)', '    run(Stack & stack)', '    defaultSchemaFor(const Function & function)', '    placeholderCreator(GraphFunction &)', '    preoptimizeGraph(std::shared_ptr & graph)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\function_impl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\function_schema.cpp', [], ['    dump']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\function_schema.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\function_schema_inl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\function_schema_parser.cpp', [], ['    convertToList(TypeKind kind,const SourceRange & range,std::vector vs)', '    parseArgument(size_t idx,bool is_return,bool kwarg_only)', '    parseConstantList(TypeKind kind)', '    parseDefaultValue(const TypePtr & arg_type,c10::optional arg_N)', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseName(const std::string & name)', '    parseSchema(const std::string & schema)', '    parseSchemaOrName(const std::string & schemaOrName)', '    parseSingleConstant(TypeKind kind)', '    parseTensorDefault(const SourceRange & range)', '    parseDeclaration', '    parseName', '    SchemaParser(const std::string & str)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\function_schema_parser.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\functional.cpp', [], ['    align_corners', '    align_corners', '    alpha', '    alpha', '    beta', '    dim', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    lambda', '    lambda', '    lower', '    max_val', '    min_val', '    negative_slope', '    rate', '    rate', '    rate', '    rate', '    rate', '    scale_factor', '    scale_factor', '    test_allclose(const at::Device & device)', '    TEST_F(FunctionalTest,Conv1d)', '    TEST_F(FunctionalTest,Conv2dEven)', '    TEST_F(FunctionalTest,Conv2dUneven)', '    TEST_F(FunctionalTest,Conv3d)', '    TEST_F(FunctionalTest,MaxPool1d)', '    TEST_F(FunctionalTest,MaxPool2d)', '    TEST_F(FunctionalTest,MaxPool3d)', '    TEST_F(FunctionalTest,AvgPool1d)', '    TEST_F(FunctionalTest,AvgPool2d)', '    TEST_F(FunctionalTest,AvgPool3d)', '    TEST_F(FunctionalTest,FractionalMaxPool2d)', '    TEST_F(FunctionalTest,FractionalMaxPool3d)', '    TEST_F(FunctionalTest,LPPool1d)', '    TEST_F(FunctionalTest,LPPool2d)', '    TEST_F(FunctionalTest,CosineSimilarity)', '    TEST_F(FunctionalTest,SmoothL1LossDefaultOptions)', '    TEST_F(FunctionalTest,SmoothL1LossNoReduction)', '    TEST_F(FunctionalTest,SoftMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,MultiLabelSoftMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,SoftMarginLossNoReduction)', '    TEST_F(FunctionalTest,MultiLabelSoftMarginLossWeightedNoReduction)', '    TEST_F(FunctionalTest,PairwiseDistance)', '    TEST_F(FunctionalTest,PDist)', '    TEST_F(FunctionalTest,AdaptiveMaxPool1d)', '    TEST_F(FunctionalTest,AdaptiveMaxPool2d)', '    TEST_F(FunctionalTest,AdaptiveMaxPool3d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool1d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool2d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool3d)', '    TEST_F(FunctionalTest,L1Loss)', '    TEST_F(FunctionalTest,MSELoss)', '    TEST_F(FunctionalTest,BCELoss)', '    TEST_F(FunctionalTest,KLDivLoss)', '    TEST_F(FunctionalTest,HingeEmbeddingLoss)', '    TEST_F(FunctionalTest,GridSample)', '    TEST_F(FunctionalTest,AffineGrid)', '    TEST_F(FunctionalTest,MultiMarginLoss)', '    TEST_F(FunctionalTest,CosineEmbeddingLoss)', '    TEST_F(FunctionalTest,MultiLabelMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,MultiLabelMarginLossNoReduction)', '    TEST_F(FunctionalTest,TripletMarginLoss)', '    TEST_F(FunctionalTest,NLLLoss)', '    TEST_F(FunctionalTest,CrossEntropy)', '    TEST_F(FunctionalTest,MaxUnpool1d)', '    TEST_F(FunctionalTest,MaxUnpool2d)', '    TEST_F(FunctionalTest,MaxUnpool3d)', '    TEST_F(FunctionalTest,ELU)', '    TEST_F(FunctionalTest,SELU)', '    TEST_F(FunctionalTest,GLU)', '    TEST_F(FunctionalTest,GELU)', '    TEST_F(FunctionalTest,Hardshrink)', '    TEST_F(FunctionalTest,OneHot)', '    TEST_F(FunctionalTest,Hardtanh)', '    TEST_F(FunctionalTest,LeakyReLU)', '    TEST_F(FunctionalTest,LogSigmoid)', '    TEST_F(FunctionalTest,GumbelSoftmax)', '    TEST_F(FunctionalTest,Softmax)', '    TEST_F(FunctionalTest,Softmin)', '    TEST_F(FunctionalTest,LogSoftmax)', '    TEST_F(FunctionalTest,PReLU)', '    TEST_F(FunctionalTest,LayerNorm)', '    TEST_F(FunctionalTest,GroupNorm)', '    TEST_F(FunctionalTest,LocalResponseNorm)', '    TEST_F(FunctionalTest,Linear)', '    TEST_F(FunctionalTest,Embedding)', '    TEST_F(FunctionalTest,EmbeddingBag)', '    TEST_F(FunctionalTest,Bilinear)', '    TEST_F(FunctionalTest,Normalize)', '    TEST_F(FunctionalTest,ReLU)', '    TEST_F(FunctionalTest,ReLUDefaultOptions)', '    TEST_F(FunctionalTest,ReLU6)', '    TEST_F(FunctionalTest,ReLU6DefaultOptions)', '    TEST_F(FunctionalTest,RReLU)', '    TEST_F(FunctionalTest,RReLUDefaultOptions)', '    TEST_F(FunctionalTest,CELU)', '    TEST_F(FunctionalTest,CELUDefaultOptions)', '    TEST_F(FunctionalTest,PixelShuffle)', '    TEST_F(FunctionalTest,Softplus)', '    TEST_F(FunctionalTest,SoftplusDefaultOptions)', '    TEST_F(FunctionalTest,Fold)', '    TEST_F(FunctionalTest,Unfold)', '    TEST_F(FunctionalTest,Softshrink)', '    TEST_F(FunctionalTest,SoftshrinkDefaultOptions)', '    TEST_F(FunctionalTest,Softsign)', '    TEST_F(FunctionalTest,Tanhshrink)', '    TEST_F(FunctionalTest,Threshold)', '    TEST_F(FunctionalTest,BatchNorm1d)', '    TEST_F(FunctionalTest,BatchNorm1dDefaultOptions)', '    TEST_F(FunctionalTest,BatchNorm2d)', '    TEST_F(FunctionalTest,BatchNorm2dDefaultOptions)', '    TEST_F(FunctionalTest,BatchNorm3d)', '    TEST_F(FunctionalTest,BatchNorm3dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm1d)', '    TEST_F(FunctionalTest,InstanceNorm1dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm2d)', '    TEST_F(FunctionalTest,InstanceNorm2dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm3d)', '    TEST_F(FunctionalTest,InstanceNorm3dDefaultOptions)', '    TEST_F(FunctionalTest,Interpolate)', '    TEST_F(FunctionalTest,Pad)', '    TEST_F(FunctionalTest,CTCLoss)', '    TEST_F(FunctionalTest,PoissonNLLLoss)', '    TEST_F(FunctionalTest,MarginRankingLoss)', '    TEST_F(FunctionalTest,ConvTranspose1d)', '    TEST_F(FunctionalTest,ConvTranspose2dEven)', '    TEST_F(FunctionalTest,ConvTranspose2dUneven)', '    TEST_F(FunctionalTest,ConvTranspose3d)', '    TEST_F(FunctionalTest,AlphaDropout)', '    TEST_F(FunctionalTest,FeatureAlphaDropout)', '    TEST_F(FunctionalTest,Dropout)', '    TEST_F(FunctionalTest,Dropout2d)', '    TEST_F(FunctionalTest,Dropout3d)', '    TEST_F(FunctionalTest,isfinite)', '    TEST_F(FunctionalTest,isfinite_CUDA)', '    TEST_F(FunctionalTest,isinf)', '    TEST_F(FunctionalTest,isinf_CUDA)', '    TEST_F(FunctionalTest,AllClose)', '    TEST_F(FunctionalTest,AllClose_CUDA)', '    TEST_F(FunctionalTest,BCEWithLogitsLoss)', '    test_isfinite(const at::Device & device)', '    test_isinf(const at::Device & device)', '    threshold', '    threshold', '    upper', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\container\\functional.cpp', [], ['    forward(Tensor input)', '    FunctionalImpl(Function)', '    is_serializable', '    operator()(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\functional.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\functional.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\functional.h', [], ['    map2_reduce_all(const MapOp & map_fun,const ReduceOp & red_fun,const scalar_t *data,const scalar_t *data2,int64_t size)', '    map_reduce_all(const MapOp & map_fun,const ReduceOp & red_fun,scalar_t *data,int64_t size)', '    reduce_all(const Op & vec_fun,scalar_t *data,int64_t size)', '    vec_reduce_all(const Op & vec_fun,vec256::Vec256 acc_vec,int64_t size)', '    map2(const Op & vec_fun,scalar_t *output_data,scalar_t *input_data,scalar_t *input_data2,int64_t size)', '    store', '    set']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\FunctionRef.h', ['    function_ref'], ['    callback_fn(intptr_t callable,Params,...)', '    function_ref', '    function_ref(std::nullptr_t)', '    function_ref(Callable,std::enable_if::type *,std::enable_if::type *)', '    operator bool', '    operator()(Params,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\Functions.cpp', [], ['    _maybe_overlapping_memory(IntArrayRef sizes,IntArrayRef strides)', '    _min_storage_size(IntArrayRef sizes,IntArrayRef strides,int64_t storage_offset)', '    $', '    _cudnn_ctc_loss_backward(const Tensor & grad_out,const Tensor & loss,const Tensor & raw_grad,bool zero_infinity)', '    _trilinear_backward(const Tensor & grad_out,const Tensor & i1,const Tensor & i2,const Tensor & i3,IntArrayRef expand1,IntArrayRef expand2,IntArrayRef expand3,IntArrayRef sumdim,int64_t unroll_dim,std::array grad_mask)', '    batchnorm_double_backward(const Tensor & input,const Tensor & gamma,const Tensor & ggI,const Tensor & ggG,const Tensor & ggB,const Tensor & gO,const Tensor & running_mean,const Tensor & running_var,bool training,double eps,const Tensor & save_mean,const Tensor & save_invstd,std::array output_mask)', '    constant_pad_nd_backward(const Tensor & grad,IntArrayRef pad)', '    embedding_dense_double_backward(const Tensor & grad,const Tensor & indices)', '    expand_as_dim1(const Tensor & src,const Tensor & target)', '    fft_backward(const Tensor & self,const Tensor & grad,int64_t signal_ndim,bool complex_input,bool complex_output,bool inverse,IntArrayRef checked_signal_sizes,bool normalized,bool onesided,IntArrayRef output_sizes)', '    first_back_grad_input', '    index_backward(Tensor zeros_like_self,TensorList indices,const Tensor & grad)', '    infinitely_differentiable_native_layer_norm_backward(const Tensor & dY,const Tensor & dmean,const Tensor & drstd,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,double eps,std::array grad_input_mask)', '    log1p_backward(const Tensor & grad,const Tensor & self)', '    nonsingular_case_backward', '    nonsingular_case_backward', '    nonsingular_case_backward', '    singular_case_backward', '    singular_case_backward', '    singular_case_backward', '    sparse_constructor_values_backward(const Tensor & sparse_grad_out,const Tensor & indices,IntArrayRef values_shape)', '    sum_exclude_dim1(const Tensor & to_sum,bool keepdim)', '    det_backward(const Tensor & grad,const Tensor & self,const Tensor & det)', '    eig_backward(const std::vector & grads,const Tensor & self,bool eigenvectors,const Tensor & lambda,const Tensor & v)', '    _fused_dropout_backward(Tensor grad,Tensor mask,double p1m)', '    _safe_size(IntArrayRef sizes,IntArrayRef dim)', '    _sparse_addmm_sparse_backward(const Tensor & grad,const Tensor & sparse_,const Tensor & dense,const Scalar & alpha)', '    as_strided_backward(Tensor grad,TensorGeometry input_geometry,IntArrayRef sizes,IntArrayRef strides,optional storage_offset_)', '    atan2_backward(const Tensor & grad,const Tensor & self,const Tensor & other,std::array output_mask)', '    binary_cross_entropy_double_backward(const Tensor & grad_output,const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_with_logits_target_backward(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    cat_tensors_backward(const Tensor & grad,const std::vector,int64_t dim)', '    cholesky_backward(Tensor grad,bool upper,Tensor L)', '    cholesky_inverse_backward(Tensor grad,Tensor L,bool upper,Tensor inverse)', '    clamp_backward(const Tensor & grad,const Tensor & self,const optional & min,const optional & max)', '    copy_range(variable_list & out,IndexRange range,const Tensor & t)', '    copy_range(variable_list & out,IndexRange range,at::ArrayRef)', '    cummax_backward(const Tensor & indices,const Tensor & grad,const Tensor & input,int64_t dim)', '    cummin_backward(const Tensor & indices,const Tensor & grad,const Tensor & input,int64_t dim)', '    cumprod_backward(const Tensor & grad,const Tensor & input,int64_t dim)', '    cumprod_backward(const Tensor & grad,const Tensor & input,int64_t dim,optional dtype)', '    cumsum_backward(const Tensor & x,int64_t dim)', '    diag_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t diagonal)', '    diagonal_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t offset,int64_t dim1,int64_t dim2)', '    glu_double_backward(const Tensor & grad,const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_double_backward_grad_output(const Tensor & grad,const Tensor & input,int64_t dim)', '    index_select_backward(Tensor grad,int64_t dim,Tensor indices,IntArrayRef sizes,bool keepdim)', '    infinitely_differentiable_gelu_backward(const Tensor & grad,const Tensor & self)', '    kl_div_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    kl_div_target_backward(Tensor grad_output,Tensor self,Tensor target,int64_t reduction)', '    l1_loss_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    log_sigmoid_double_backward(const Tensor & grad,const Tensor & input)', '    log_softmax_double_backward(const Tensor & grad,const Tensor & grad_output,int dim,const Tensor & output)', '    logsumexp_backward(Tensor grad,const Tensor & self,Tensor result,IntArrayRef dim,bool keepdim)', '    masked_scatter_backward(const Tensor & grad,const Tensor & mask,IntArrayRef sizes)', '    max_pool_double_backward(const Tensor & grad,const Tensor & indices,int dim)', '    maybe_multiply(const Tensor & t,const Scalar & s)', '    mean_backward(Tensor grad,const IntArrayRef sizes,IntArrayRef dim,bool keepdim)', '    mean_backward(Tensor grad,const IntArrayRef sizes,int numel)', '    mm_mat1_backward(const Tensor & grad,const Tensor & mat2,const Tensor & mat1,const Scalar & alpha)', '    mm_mat2_backward(const Tensor & grad,const Tensor & mat1,IntArrayRef sizes,IntArrayRef strides,const Scalar & alpha)', '    mse_loss_double_backward(const Tensor & grad,const Tensor & input,int64_t reduction)', '    mse_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mvlgamma_backward(Tensor grad,const Tensor & self,int64_t p)', '    norm_backward(const Tensor & grad,const Tensor & self,const optional & p_,const Tensor & norm)', '    norm_backward(Tensor grad,const Tensor & self,const optional & p_,Tensor norm,IntArrayRef dim,bool keepdim)', '    not_implemented(const char *name)', '    permute_backwards(const Tensor & grad,IntArrayRef fwd_dims)', '    pow_backward(Tensor grad,const Tensor & self,const Scalar & exponent_)', '    pow_backward_exponent(Tensor grad,const Tensor & self,const Tensor & exponent,Tensor result)', '    pow_backward_exponent(Tensor grad,const Scalar & base,const Tensor & exponent,Tensor result)', '    pow_backward_self(Tensor grad,const Tensor & self,const Tensor & exponent)', '    prelu_double_backward(const Tensor & grad_grad_input,const Tensor & grad_grad_weight,const Tensor & grad_out,const Tensor & input_,const Tensor & weight_)', '    prod_backward(const Tensor & grad,const Tensor & input,const Tensor & result)', '    prod_backward(Tensor grad,const Tensor & input,Tensor result,int64_t dim,bool keepdim)', '    prod_safe_zeros_backward(const Tensor & grad,const Tensor & inp,int64_t dim)', '    renorm_backward(const Tensor & grad,const Tensor & self,Scalar p,int64_t dim,Scalar maxnorm)', '    repeat_backward(Tensor grad,int64_t input_dims,IntArrayRef repeats)', '    reverse_dim(const Tensor & t,int64_t dim)', '    reverse_list(const IntArrayRef list)', '    select_backward(Tensor grad,IntArrayRef input_sizes,int64_t dim,int64_t index)', '    select_equals_backward(Tensor grad,const Tensor & input,const Tensor & value)', '    slice_backward(Tensor grad,IntArrayRef input_sizes,int64_t dim,int64_t start,int64_t end,int64_t step)', '    smooth_l1_loss_double_backward(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_double_backward(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    softmax_double_backward(const Tensor & grad,const Tensor & grad_output,int dim,const Tensor & output)', '    softplus_double_backward(const Tensor & grad,const Tensor & input,Scalar beta,Scalar threshold)', '    solve_backward_A(const Tensor & grad,const Tensor & self,const Tensor & A,const Tensor & solution)', '    solve_backward_self(const Tensor & grad,const Tensor & self,const Tensor & A)', '    split_backward(const std::vector & grads,int64_t split_size,int64_t dim,IntArrayRef sizes,const at::TensorOptions & options)', '    split_with_sizes_backward(const std::vector & grads,IntArrayRef split_sizes,int64_t dim,IntArrayRef sizes,const at::TensorOptions & options)', '    std_backward(const Tensor & result,const Tensor & grad,const Tensor & self,bool unbiased)', '    std_backward(const Tensor & result,Tensor grad,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    sum_backward(const Tensor & grad,IntArrayRef sizes,IntArrayRef dims,bool keepdim)', '    sum_scan_exclusive(const Tensor & x,int64_t dim)', '    sum_tensorlist(TensorList tl)', '    trace_backward(const Tensor & grad,IntArrayRef sizes)', '    unbind_backward(const variable_list & grads,int64_t dim)', '    unfold_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t dim,int64_t size,int64_t step)', '    unsqueeze_multiple(const Tensor & t,IntArrayRef dim,size_t n_dims)', '    unsqueeze_to(const Tensor & self,IntArrayRef sizes)', '    unsqueeze_to(const Tensor & self,int64_t dim,IntArrayRef sizes)', '    var_backward(const Tensor & grad,const Tensor & self,bool unbiased)', '    var_backward(Tensor grad,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_std_mean_backward(const variable_list & grads,const Tensor & self,const Tensor & r1,const Tensor & r2,IntArrayRef dim,bool unbiased,bool keepdim,bool is_std)', '    var_std_mean_backward(const variable_list & grads,const Tensor & self,const Tensor & r1,const Tensor & r2,bool unbiased,bool is_std)', '    logdet_backward(const Tensor & grad,const Tensor & self,const Tensor & logdet)', '    qr_backward(const std::vector & grads,const Tensor & self,bool some,const Tensor & Q,const Tensor & R)', '    slogdet_backward(const Tensor & grad_logabsdet,const Tensor & self,const Tensor & signdet,const Tensor & logabsdet)', '    svd_backward(const std::vector & grads,const Tensor & self,bool some,bool compute_uv,const Tensor & raw_u,const Tensor & sigma,const Tensor & raw_v)', '    symeig_backward(const std::vector & grads,const Tensor & self,bool eigenvectors,bool upper,const Tensor & lambda,const Tensor & v)', '    triangular_solve_backward(const Tensor & grad_x,const Tensor & grad_m,const Tensor & b,const Tensor & a,const Tensor & x,const bool upper,const bool transpose,const bool unitriangular,std::array output_mask)', '    cholesky_solve_backward(const Tensor & grad_x,const Tensor & self,const Tensor & input2,const Tensor & result,const bool upper)', '    unsqueeze_dim1(const Tensor & src,const Tensor & target)', '    range(size_t range_size)', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\Functions.h', [], ['    Tensor', '    Tensor', '    optional', '    optional(c10::in_place,)', '    optional(dummyTensor)', '    optional(c10::nullopt)', '    optional', '    optional', '    $', '    unpack_list(at::ArrayRef xs)', '    Scalar', '    options', '    sizes', '    TypeAndSize', '    TypeAndSize(const Tensor & t)', '    zeros']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\Functions.h', [], ['    $', '    $', '    from_blob(void *data,IntArrayRef sizes,const std::function & deleter,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,IntArrayRef strides,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,IntArrayRef strides,const std::function & deleter,const TensorOptions & options)', '    numel(const Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\FunctionTraits.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\funhash_op.cc', ['    GetFunHashGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFunHash', '    CAFFE_ANONYMOUS_VARIABLE_CPUFunHashGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FunHash', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FunHashGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\funhash_op.h', ['    FunHashGradientOp', '    FunHashOp'], ['    FunHashGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    FunHashOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\fuse_linear.cpp', [], ['    FuseLinear(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\fuse_linear.h', [], ['    FuseLinear(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_conversion.cc', [], ['    FloatToFused8BitRowwiseQuantized(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantized__base(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf__base(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat__base(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat__base(const std::uint8_t *input,int input_rows,int input_columns,float *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_conversion.h', [], ['    FloatToFused8BitRowwiseQuantized(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_conversion_avx2.cc', [], ['    FloatToFused8BitRowwiseQuantized__avx2_fma(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedToFloat__avx2_fma(const std::uint8_t *input,int input_rows,int input_columns,float *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_embedding_lookup.cc', [], ['    Fused8BitRowwiseEmbeddingLookupGenericSlow(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,bool normalize_by_lengths,OutType *out)', '    Fused8BitRowwiseEmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_embedding_lookup.h', [], ['    Fused8BitRowwiseEmbeddingLookup(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,bool normalize_by_lengths,OutType *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_embedding_lookup_idx.cc', [], ['    Fused8BitRowwiseEmbeddingLookupGenericSlowIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,OutType *out)', '    Fused8BitRowwiseEmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\fused_8bit_rowwise_embedding_lookup_idx.h', [], ['    Fused8BitRowwiseEmbeddingLookupIdx(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,OutType *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cuda\\fused_kernel.cpp', [], ['    ceilDiv(const int a,const int b)', '    createFusionKernel(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    getMajorMinor(const cudaDeviceProp *const prop,int & major,int & minor)', '    nvrtc', '    FusedKernelCUDA(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    ~FusedKernelCUDA']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cpu\\fused_kernel.cpp', [], ['    createFusionKernel(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    disas(const std::string & so_file)', '    getArchFlags', '    getConfig', '    getTempPath', '    programExists(const std::string & program)', '    runCompiler(const std::string & cpp_file,const std::string & so_file)', '    activate', '    exec(const std::string & cmd)', '    rtrim(std::string & s,const char *t)', '    run(const std::string & cmd)', '    CompilerConfig', '    FusedKernelCPU(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cuda\\fused_kernel.h', [], ['    backend', '    FusedKernelCUDA(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    ~FusedKernelCUDA']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\fused_kernel.h', [], ['    backend', '    chunkDesc', '    code', '    concatDesc', '    FusedKernel(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    FusedKernel', '    hasRandom', '    inputDesc', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    name', '    operator=', '    outputDesc', '    ~FusedKernel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cpu\\fused_kernel.h', [], ['    data', '    backend', '    FusedKernelCPU(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\operator_test\\fused_nbit_rowwise_test.cc', [], ['    bit_rate', '    bit_rate', '    bit_rate', '    bit_rate', '    TEST(OperatorSchemaTest,TensorInferenceNbit)', '    TEST(OperatorSchemaTest,TensorInferenceNbitHalf)', '    TEST(OperatorSchemaTest,TensorInferenceNbitBack)', '    TEST(OperatorSchemaTest,TensorInferenceNbitHalfBack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_8bit_conversion_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused8BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedHalfScaleBiasToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedHalfScaleBiasToHalfFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedToHalfFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfFloatToFused8BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused8BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused8BitRowwiseQuantizedHalfScaleBias', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedHalfScaleBiasToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedHalfScaleBiasToHalfFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedToHalfFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfFloatToFused8BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp16(at::Half *dst,const float *src,size_t N)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_8bit_conversion_ops.h', ['    FloatToFused8BitRowwiseQuantizedOp', '    Fused8BitRowwiseQuantizedToFloatOp'], ['    schema_Fused8BitRowwiseQuantizedToFloat', '    convert(tmp,input_data,input_columns)', '    convert(output_data,tmp,output_columns)', '    FloatToFused8BitRowwiseQuantizedOp(Args,...)', '    RunOnDevice', '    ~FloatToFused8BitRowwiseQuantizedOp', '    Fused8BitRowwiseQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~Fused8BitRowwiseQuantizedToFloatOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_nbit_conversion_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused2BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused4BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused2BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused2BitRowwiseQuantizedToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused4BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused4BitRowwiseQuantizedToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused2BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused4BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused2BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused4BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused2BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused2BitRowwiseQuantizedToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused4BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused4BitRowwiseQuantizedToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused2BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused4BitRowwiseQuantized', '    convertfp32fp16(at::Half *dst,const float *src,size_t N)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_nbit_conversion_ops.h', ['    final', '    final'], ['    convert(tmp,input_data,input_columns)', '    convert(output_data,tmp,output_columns)', '    FloatToFusedNBitRowwiseQuantizedOp(const OperatorDef & def,Workspace *ws)', '    FusedNBitRowwiseQuantizedToFloatOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~FloatToFusedNBitRowwiseQuantizedOp', '    ~FusedNBitRowwiseQuantizedToFloatOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_nbitfake_conversion_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused2BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused4BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused2BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused4BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused2BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused4BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused2BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused4BitFakeRowwiseQuantized', '    compress_uniform_simplified_(const float *X,int N,float xmin,float xmax,float *Xq,int bit_rate)', '    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp32(float *dst,const float *src,size_t N)', '    param_search_greedy(const float *X,int N,const int n_bins,const float ratio,float & Xmin,float & Xmax,int bit_rate)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_nbitfake_conversion_ops.h', ['    final'], ['    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp32(float *dst,const float *src,size_t N)', '    is_little_endian', '    param_search_greedy(const float *X,int N,const int n_bins,const float ratio,float & Xmin,float & Xmax,int bit_rate)', '    convert(tmp,input_data,input_columns)', '    FloatToFusedNBitFakeRowwiseQuantizedOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    ~FloatToFusedNBitFakeRowwiseQuantizedOp', '    lrintf']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_random_quantization_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFusedRandRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFusedRandRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFusedRandRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FusedRandRowwiseQuantizedToFloat', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\fused_rowwise_random_quantization_ops.h', ['    FloatToFusedRandRowwiseQuantizedOp', '    FusedRandRowwiseQuantizedToFloatOp'], ['    bitwidth_', '    FloatToFusedRandRowwiseQuantizedOp(Args,...)', '    random_', '    RunOnDevice', '    ~FloatToFusedRandRowwiseQuantizedOp', '    FusedRandRowwiseQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~FusedRandRowwiseQuantizedToFloatOp', '    now']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\fusion.cc', ['    FuseConvBN'], ['    fuseConvBN(nom::repr::NNModule *nn,caffe2::Workspace *ws)', '    fuseConvBNHelper(repr::NNModule *nn,caffe2::Workspace *ws)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\fusion.h', [], ['    fuseActivation(repr::NNModule *nn,std::function should_fuse,std::function postprocess)', '    fuseConvBN(repr::NNModule *nn,caffe2::Workspace *ws)', '    get', '    getConsumers', '    getInputs', '    getOutputs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\future.h', ['    final', '    final'], ['    addCallback(const Callback & callback)', '    completed', '    completed_', '    error', '    hasError', '    markCompleted(T value)', '    setError(std::string errorMsg)', '    setErrorIfNeeded(std::string errorMsg)', '    setErrorInternal(std::string errorMsg,std::unique_lock & lock)', '    swap', '    Future', '    Future(T)', '    FutureError(std::string errorMsg)', '    FutureError', '    lock(mutex_)', '    wait', '    waitNoThrow', '    what']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\GatedLinearUnit.cpp', [], ['    glu(const Tensor & self,int64_t dim)', '    glu_backward(const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_out(Tensor & result,const Tensor & self,int64_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_fused_8bit_rowwise_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherFused8BitRowwise']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_fused_8bit_rowwise_op.h', ['    GatherFused8BitRowwiseOp'], ['    DoRunWithType', '    GatherFused8BitRowwiseOp(Args,...)', '    Input', '    RunOnDevice', '    ~GatherFused8BitRowwiseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_op.cc', ['    GetGatherGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Gather', '    vector', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_op.h', ['    GatherOp'], ['    calc_output_shape_vector(const DataDimsVec & data_dims,const IndexDimsVec & indices_dims,int axis,bool match_outer)', '    check_indexarray_range(const IndexType *indices,int64_t n,IndexType indexing_axis_dim,bool wrap_indices)', '    gather_impl(Operator *op,int dataIdx,int indicesIdx,int outputIdx,int axis,bool wrap_indices,bool match_outer)', '    DoRunWithType', '    GatherOp(Args,...)', '    RunOnDevice', '    ~GatherOp', '    dim', '    raw_data', '    size', '    size_from_dim', '    size_to_dim', '    getContext', '    Input', '    Output']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_ranges_to_dense_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherRangesToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherRangesToDense']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gather_ranges_to_dense_op.h', ['    final'], ['    outputDims', '    debug_def', '    DoRunWithType', '    GatherRangesToDenseOp(Args,...)', '    GetRepeatedArgument', '    GetSingleArgument', '    has_debug_def', '    Input', '    RunOnDevice', '    ~GatherRangesToDenseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\gavgpool-microkernel-tester.h', ['    GAvgPoolMicrokernelTester'], ['    iterations(size_t iterations)', '    iterations', '    iterations_', '    m(size_t m)', '    m', '    m_', '    n(size_t n)', '    n', '    n_', '    nr(size_t nr)', '    nr', '    nr_', '    packedN', '    test(pytorch_q8gavgpool_up_ukernel_function q8gavgpool)', '    test(pytorch_q8gavgpool_mp_ukernel_function q8gavgpool)', '    xScale(float xScale)', '    xScale', '    xScale_', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    xZeroPoint(uint8_t xZeroPoint)', '    xZeroPoint', '    xZeroPoint_', '    yMax(uint8_t yMax)', '    yMax', '    yMax_', '    yMin(uint8_t yMin)', '    yMin', '    yMin_', '    yScale(float yScale)', '    yScale', '    yScale_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gelu_op.cc', ['    GetGeluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUGeluGradient', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Gelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GeluGradient', '    CostInferenceForGelu(const OperatorDef & def,const vector & in)', '    operator()(const int N,const T *X,T *Y,CPUContext *context)', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *X,T *dX,CPUContext *context)', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gelu_op.h', [], ['    schema_Gelu', '    GeluFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)', '    GeluGradientFunctor(OperatorBase & op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\gemm-microkernel-tester.h', ['    GemmMicrokernelTester'], ['    q8gemm_compute_row_sum(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *row_sum,pytorch_q8sum_rows_ukernel_function q8sum_rows)', '    aStride(size_t aStride)', '    aStride', '    aStride_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    biasN', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    cStride(size_t cStride)', '    cStride', '    cStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    k(size_t k)', '    k', '    k_', '    kr(size_t kr)', '    kr', '    kr_', '    ks(size_t ks)', '    ks', '    ks_', '    m(size_t m)', '    m', '    m_', '    mr(size_t mr)', '    mr', '    mr_', '    multiplier(const float multiplier)', '    multiplier', '    multiplier_', '    n(size_t n)', '    n', '    n_', '    np(size_t np)', '    np', '    np_', '    nr(size_t nr)', '    nr', '    nr_', '    packedK', '    packedN', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_q8gemm_ukernel_function qgemm)', '    test(pytorch_q8gemm_dq_ukernel_function qgemm)', '    test(pytorch_q8conv_ukernel_function qconv)', '    test(pytorch_q8gemm_xzp_ukernel_function qgemm)', '    test(pytorch_hgemm_ukernel_function hgemm)', '    test(pytorch_sgemm_ukernel_function sgemm)', '    test(pytorch_sconv_ukernel_function sconv)', '    aZeroPoint', '    bZeroPoint', '    multiplier', '    shuffle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-neon.c', [], ['    pytorch_qnnp_requantize_gemmlowp__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\gemmlowp-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\gemmlowp-scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-scalar.c', [], ['    pytorch_qnnp_requantize_gemmlowp__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-scalar.h', [], ['    gemmlowp_scalar_rdivbypo2_s32(int32_t x,int exponent)', '    gemmlowp_scalar_vqrdmulh_s32(int32_t a,int32_t b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-sse.h', [], ['    gemmlowp_sse_mul_s32(__m128i a,__m128i b)', '    gemmlowp_sse_rdivbypo2_s32(__m128i x,int exponent)', '    gemmlowp_sse_vqrdmulh_s32(__m128i a,__m128i b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\gemmlowp-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-sse2.c', [], ['    pytorch_qnnp_requantize_gemmlowp__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-sse4.c', [], ['    pytorch_qnnp_requantize_gemmlowp__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\gemmlowp-sse4.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\gemmlowp-ssse3.c', [], ['    pytorch_qnnp_requantize_gemmlowp__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\gemmlowp-ssse3.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op.cc', [], ['    bbox_weights', '    CAFFE_ANONYMOUS_VARIABLE_CPUGenerateProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUGenerateProposalsCPP', '    schema_OperatorName', '    schema_OperatorName', '    ComputeStartIndex(const TensorCPU & tensor,const std::vector & index)', '    GetSubTensorView(const TensorCPU & tensor,int dim0_start_index)', '    ComputeAllAnchors(const TensorCPU & anchors,int height,int width,float feat_stride)', '    ComputeSortedAnchors(const Eigen::Map & anchors,int height,int width,float feat_stride,const vector & order)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GenerateProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GenerateProposalsCPP', '    ProposalsForOneImage(const Eigen::Array3f & im_info,const Eigen::Map & anchors,const utils::ConstTensorView & bbox_deltas_tensor,const utils::ConstTensorView & scores_tensor,ERArrXXf *out_boxes,EArrXf *out_probs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op.h', ['    final', '    ConstTensorView'], ['    schema_GenerateProposals', '    ComputeAllAnchors(const TensorCPU & anchors,int height,int width,float feat_stride)', '    ComputeSortedAnchors(const Eigen::Map & anchors,int height,int width,float feat_stride,const vector & order)', '    angle_bound_hi_', '    angle_bound_lo_', '    angle_bound_on_', '    clip_angle_thresh_', '    dev_boxes_', '    dev_boxes_keep_flags_', '    dev_conv_layer_indexes_', '    dev_cub_select_buffer_', '    dev_cub_sort_buffer_', '    dev_image_boxes_keep_list_', '    dev_image_offset_', '    dev_image_prenms_boxes_', '    dev_image_prenms_scores_', '    dev_nms_mask_', '    dev_postnms_rois_', '    dev_postnms_rois_probs_', '    dev_prenms_nboxes_', '    dev_sorted_conv_layer_indexes_', '    dev_sorted_scores_', '    feat_stride_', '    GenerateProposalsOp(Args,...)', '    host_nms_mask_', '    host_prenms_nboxes_', '    legacy_plus_one_', '    ProposalsForOneImage(const Eigen::Array3f & im_info,const Eigen::Map & anchors,const utils::ConstTensorView & bbox_deltas_tensor,const utils::ConstTensorView & scores_tensor,ERArrXXf *out_boxes,EArrXf *out_probs)', '    rpn_min_size_', '    rpn_nms_thresh_', '    rpn_post_nms_topN_', '    rpn_pre_nms_topN_', '    RunOnDevice', '    spatial_scale_', '    ~GenerateProposalsOp', '    ConstTensorView(const T *data,const std::vector & dims)', '    data', '    dim(int i)', '    dims', '    ndim', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_gpu_test.cc', [], ['    AddLinSpacedInput(const vector & shape,const float min_val,const float max_val,const string & name,Workspace *ws)', '    anchors', '    bbx', '    AddConstInput(const vector & shape,const float value,const string & name,Context *context,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    scores', '    TEST(GenerateProposalsTest,TestRealDownSampledGPU)', '    im_info', '    rois', '    rois_probs', '    rois_probs_gt']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddLinSpacedInput(const vector & shape,const float min_val,const float max_val,const string & name,Workspace *ws)', '    anchors', '    angles', '    angles', '    bbx', '    TEST(GenerateProposalsTest,TestComputeAllAnchors)', '    TEST(GenerateProposalsTest,TestComputeSortedAnchors)', '    TEST(GenerateProposalsTest,TestComputeAllAnchorsRotated)', '    TEST(GenerateProposalsTest,TestComputeSortedAnchorsRotated)', '    TEST(GenerateProposalsTest,TestEmpty)', '    TEST(GenerateProposalsTest,TestRealDownSampled)', '    im_info', '    rois_probs_gt', '    scores', '    TEST(GenerateProposalsTest,TestRealDownSampledRotatedAngle0)', '    TEST(GenerateProposalsTest,TestRealDownSampledRotated)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_boxes.h', [], ['    bbox_ctrwh_to_xyxy(const Eigen::ArrayBase & boxes,const bool legacy_plus_one)', '    bbox_transform(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool legacy_plus_one,const bool angle_bound_on,const int angle_bound_lo,const int angle_bound_hi)', '    bbox_transform_rotated(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool angle_bound_on,const int angle_bound_lo,const int angle_bound_hi)', '    bbox_transform_upright(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool legacy_plus_one)', '    bbox_xyxy_to_ctrwh(const Eigen::ArrayBase & boxes,bool legacy_plus_one)', '    clip_boxes(const Eigen::ArrayBase & boxes,int height,int width,float angle_thresh,bool legacy_plus_one)', '    clip_boxes_rotated(const Eigen::ArrayBase & boxes,int height,int width,float angle_thresh,bool legacy_plus_one)', '    clip_boxes_upright(const Eigen::ArrayBase & boxes,int height,int width,bool legacy_plus_one)', '    filter_boxes(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info,const bool legacy_plus_one)', '    filter_boxes_rotated(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info)', '    filter_boxes_upright(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info,const bool legacy_plus_one)', '    col', '    Zero']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_boxes_test.cc', [], ['    TEST(UtilsBoxesTest,TestBboxTransformRandom)', '    TEST(UtilsBoxesTest,TestBboxTransformRotated)', '    TEST(UtilsBoxesTest,TestBboxTransformRotatedNormalized)', '    TEST(UtilsBoxesTest,ClipRotatedBoxes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_nms.h', ['    RotatedRect'], ['    bbox_intersection_rotated(const Eigen::ArrayBase & box1,const Eigen::ArrayBase & box2)', '    bbox_overlaps_rotated(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & query_boxes)', '    bbox_to_rotated_rect(const Eigen::ArrayBase & box)', '    convex_hull_graham(const Eigen::Vector2f *p,const int & num_in,Eigen::Vector2f *q,bool shift_to_zero)', '    cross_2d(const Eigen::Vector2f & A,const Eigen::Vector2f & B)', '    nms_cpu_upright(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN,bool legacy_plus_one)', '    rotated_rect_intersection_pts(const RotatedRect & rect1,const RotatedRect & rect2,Eigen::Vector2f *intersections,int & num)', '    soft_nms_cpu_upright(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    nms_cpu(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN,bool legacy_plus_one)', '    nms_cpu(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,float thres,bool legacy_plus_one)', '    nms_cpu_rotated(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN)', '    polygon_area(const Eigen::Vector2f *q,const int & m)', '    rotated_rect_intersection(const RotatedRect & rect1,const RotatedRect & rect2)', '    soft_nms_cpu(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    soft_nms_cpu(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    soft_nms_cpu_rotated(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN)', '    get_vertices(Eigen::Vector2f *pt)', '    RotatedRect', '    RotatedRect(const Eigen::Vector2f & p_center,const Eigen::Vector2f & p_size,float p_angle)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_nms_gpu.h', [], ['    nms_gpu(const float *d_desc_sorted_boxes,const int N,const float thresh,const bool legacy_plus_one,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context,const int box_dim)', '    nms_gpu_rotated(const float *d_desc_sorted_boxes,const int N,const float thresh,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context)', '    nms_gpu_upright(const float *d_desc_sorted_boxes,const int N,const float thresh,const bool legacy_plus_one,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_nms_gpu_test.cc', [], ['    generateRandomBoxes(float *h_boxes,float *h_scores,const int nboxes)', '    generateRandomRotatedBoxes(float *h_boxes,float *h_scores,const int nboxes)', '    TEST(UtilsNMSTest,TestNMSGPU)', '    TEST(UtilsNMSTest,TestPerfNMS)', '    TEST(UtilsNMSTest,GPUEqualsCPUCorrectnessTest)', '    TEST(UtilsNMSTest,TestNMSGPURotatedAngle0)', '    TEST(UtilsNMSTest,TestPerfRotatedNMS)', '    dev_boxes', '    dev_boxes', '    dev_boxes', '    dev_boxes_valid_flags', '    dev_boxes_valid_flags', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_list', '    dev_list', '    dev_list', '    dev_list', '    dev_list', '    dev_list_nitems', '    dev_list_nitems', '    dev_scores', '    dev_scores', '    dev_sorted_boxes', '    dev_sorted_boxes', '    host_boxes', '    host_boxes', '    host_boxes', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_list', '    host_list', '    host_scores', '    host_scores', '    host_scores', '    input_thresh', '    input_thresh', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\generate_proposals_op_util_nms_test.cc', [], ['    TEST(UtilsNMSTest,TestNMS)', '    TEST(UtilsNMSTest,TestNMS1)', '    TEST(UtilsNMSTest,TestSoftNMS)', '    TEST(UtilsNMSTest,TestNMSRotatedAngle0)', '    TEST(UtilsNMSTest,TestSoftNMSRotatedAngle0)', '    TEST(UtilsNMSTest,RotatedBBoxOverlaps)', '    input_thresh', '    input_thresh', '    keep_gt', '    keep_gt', '    method', '    method', '    output_gt', '    overlap_thresh', '    overlap_thresh', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\generate_test_asset.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Generator.cpp', [], ['    THPGenerator_dealloc(THPGenerator *self)', '    THPGenerator_get_device(THPGenerator *self,void *unused)', '    THPGenerator_getState(THPGenerator *self,PyObject *noargs)', '    THPGenerator_initialSeed(THPGenerator *self,PyObject *noargs)', '    THPGenerator_manualSeed(THPGenerator *self,PyObject *seed)', '    THPGenerator_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPGenerator_seed(THPGenerator *self,PyObject *noargs)', '    THPGenerator_setState(THPGenerator *self,PyObject *_new_state)', '    pyobj(const Generator & self)', '    self', '    set_pyobj(const Generator & self,PyObject *pyobj)', '    THPGenerator_init(PyObject *module)', '    THPGenerator_initDefaultGenerator(at::Generator cdata)', '    THPGenerator_NewWithVar(PyTypeObject *type,Generator gen)', '    THPGenerator_Wrap(Generator gen)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Generator.h', [], ['    make_generator(Args,...)', '    clone', '    defined', '    Generator', '    Generator(std::shared_ptr gen_impl)', '    Generator(std::nullptr_t gen_impl)', '    get', '    operator!=(const Generator & rhs)', '    operator->', '    operator==(const Generator & rhs)', '    make_shared', '    runtime_error']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Generator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Generator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\GeneratorImpl.cpp', [], ['    getNonDeterministicRandom(bool is_cuda)', '    key_set_(key_set)', '    clone', '    device', '    GeneratorImpl(Device device_in,DispatchKeySet key_set)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\GeneratorImpl.h', [], ['    getNonDeterministicRandom(bool is_cuda)', '    clone', '    clone_impl', '    current_seed', '    device', '    GeneratorImpl(Device device_in,DispatchKeySet key_set)', '    GeneratorImpl', '    GeneratorImpl', '    key_set', '    operator=', '    pyobj', '    seed', '    set_current_seed(uint64_t seed)', '    set_pyobj(PyObject *pyobj)', '    ~GeneratorImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\gftrl_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGFtrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GFtrl', '    gftrl_compute(const T & w,const T & n,const T & z,const T & g,T & nw,T & nn,T & nz,const T & z_norm,const int OutputDim,const GFtrlParams & params)', '    gftrl_update(int OutputDim,int InputDim,const T *w,const T *nz,const T *g,T *new_w,T *new_nz,const GFtrlParams & params,Context *)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\gftrl_op.h', ['    final'], ['    GFtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    GFtrlParams(OperatorBase *op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\given_tensor_byte_string_to_uint8_fill_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorByteStringToUInt8Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorByteStringToUInt8Fill']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\given_tensor_byte_string_to_uint8_fill_op.h', ['    final'], ['    Extract', '    Fill(Tensor *output)', '    GivenTensorByteStringToUInt8FillOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\given_tensor_fill_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorBoolFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorDoubleFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorInt16Fill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorInt64Fill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorIntFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorStringFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorBoolFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorDoubleFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorInt16Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorInt64Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorIntFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorStringFill']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\given_tensor_fill_op.h', ['    final'], ['    ExtractValues', '    Fill(Tensor *output)', '    FillWithType(Tensor *output)', '    GivenTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    Make']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\global-average-pooling-operator-tester.h', ['    GlobalAveragePoolingOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputMax(uint8_t outputMax)', '    outputMax', '    outputMax_', '    outputMin(uint8_t outputMin)', '    outputMin', '    outputMin_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    testQ8', '    width(size_t width)', '    width', '    width_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\global-average-pooling.c', [], ['    pytorch_qnnp_create_global_average_pooling_nwc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *global_average_pooling_out)', '    pytorch_qnnp_setup_global_average_pooling_nwc_q8(pytorch_qnnp_operator_t global_average_pooling_op,size_t batch_size,size_t width,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\global-average-pooling.cc', [], ['    global_average_pooling_q8(benchmark::State & state)', '    ImageNetArguments(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\global-average-pooling.cc', [], ['    TEST(GLOBAL_AVERAGE_POOLING_OP,zero_batch)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width_with_output_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width_with_output_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels_with_output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\GlooDeviceFactory.cpp', [], ['    RegistryName', '    makeDeviceForHostname(const std::string & hostname)', '    makeDeviceForInterface(const std::string & interface)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\GlooDeviceFactory.hpp', ['    GlooDeviceFactory'], ['    RegistryName', '    makeDeviceForHostname(const std::string & hostname)', '    makeDeviceForInterface(const std::string & interface)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\glow_net_transform.cc', ['    C10FlagParser_merge_fp32_inputs_into_fp16', '    C10FlagParser_onnxifi_adjust_batch', '    C10FlagParser_onnxifi_blacklist', '    C10FlagParser_onnxifi_blacklist_ops', '    C10FlagParser_onnxifi_debug_mode', '    C10FlagParser_onnxifi_input_output_observe_list', '    C10FlagParser_onnxifi_loop_test_mode', '    C10FlagParser_onnxifi_min_ops', '    C10FlagParser_onnxifi_shape_hints'], ['    onnxifi(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const std::unordered_set & blacklist,const ShapeInfoMap & shape_hints,bool use_onnx,size_t max_batch_size,size_t max_seq_size,bool load_model_by_blob,bool predictor_net_ssa_rewritten)', '    ParseBlackListOps(const std::string & str)', '    ParseNetPositionList(const std::string & str)', '    C10FlagParser_merge_fp32_inputs_into_fp16(const std::string & content)', '    C10FlagParser_onnxifi_adjust_batch(const std::string & content)', '    C10FlagParser_onnxifi_blacklist(const std::string & content)', '    C10FlagParser_onnxifi_blacklist_ops(const std::string & content)', '    C10FlagParser_onnxifi_debug_mode(const std::string & content)', '    C10FlagParser_onnxifi_input_output_observe_list(const std::string & content)', '    C10FlagParser_onnxifi_loop_test_mode(const std::string & content)', '    C10FlagParser_onnxifi_min_ops(const std::string & content)', '    C10FlagParser_onnxifi_shape_hints(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\glow_net_transform.h', [], ['    onnxifi(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const std::unordered_set & blacklist,const ShapeInfoMap & shape_hints,bool use_onnx,size_t max_batch_size,size_t max_seq_size,bool load_model_by_blob,bool predictor_net_ssa_rewritten)', '    ParseBlackListOps(const std::string & str)', '    ParseNetPositionList(const std::string & str)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\glu_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGlu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Glu', '    sigmoid(const float x)', '    ComputeGlu(const int M,const int split_dim,const int N,const float *Xdata,float *Ydata)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\glu_op.h', ['    final'], ['    ComputeGlu(const int M,const int split_dim_size,const int N,const T *X,T *output)', '    GetSingleArgument', '    GluOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\grad_mode.cpp', [], ['    is_enabled', '    set_enabled(bool enabled)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\grad_mode.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\grad_mode.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\graph.cc', [], ['    AddOp(NetDef *netdef_ptr,string op_type,std::vector inputs,std::vector outputs)', '    MatchArguments(const OperatorDef & p_op,const OperatorDef & g_op)', '    MatchStrings(string p,string s)', '    Graph(const NetDef & net)', '    DeactivateSubgraph(std::vector subgraph)', '    GetNetDef']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Graph\\Graph.h', ['    Edge', '    Graph', '    Node', '    Subgraph'], ['    Edge(NodeRef tail,NodeRef head,U,...)', '    head', '    setHead(NodeRef n)', '    setTail(NodeRef n)', '    tail', '    createEdge(NodeRef tail,NodeRef head,U,...)', '    createNode(T)', '    createNode(Arg)', '    createNode', '    createNodeInternal(Node)', '    deleteEdge(EdgeRef e)', '    deleteNode(NodeRef n)', '    deleteNodes(const std::unordered_set & nodes)', '    getEdge(NodeRef tail,NodeRef head)', '    getEdgeIfExists(NodeRef tail,NodeRef head)', '    getEdgesCount', '    getMutableEdges', '    getMutableNodes', '    getNodesCount', '    Graph', '    Graph', '    Graph', '    hasEdge(NodeRef tail,NodeRef head)', '    hasEdge(EdgeRef e)', '    hasNode(NodeRef node)', '    isValid', '    moveEdge(EdgeRef edge,Graph *destGraph)', '    moveNode(NodeRef node,Graph *destGraph)', '    moveSubgraph(const Subgraph & subgraph,Graph *destGraph)', '    operator=', '    printEdges', '    printNodes', '    replaceInEdges(const NodeRef & oldNode,const NodeRef & newNode)', '    replaceNode(const NodeRef & oldNode,const NodeRef & newNode)', '    replaceOutEdges(const NodeRef & oldNode,const NodeRef & newNode)', '    swapNodes(NodeRef n1,NodeRef n2)', '    ~Graph', '    addInEdge(EdgeRef e)', '    addOutEdge(EdgeRef e)', '    getInEdges', '    getOutEdges', '    Node(T)', '    Node', '    Node', '    Node', '    operator=', '    removeEdgeInternal(std::vector & edges,EdgeRef e)', '    removeInEdge(EdgeRef e)', '    removeOutEdge(EdgeRef e)', '    setInEdges(std::vector edges)', '    setOutEdges(std::vector edges)', '    addEdge(EdgeRef e)', '    addNode(NodeRef n)', '    getEdges', '    getNodes', '    getNodesCount', '    hasEdge(EdgeRef e)', '    hasNode(NodeRef n)', '    printEdges', '    printNodes', '    removeEdge(EdgeRef e)', '    removeNode(NodeRef n)', '    Subgraph']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\graph.h', [], ['    AddOp(NetDef *netdef_ptr,string op_type,std::vector inputs,std::vector outputs)', '    MatchArguments(const OperatorDef & p_op,const OperatorDef & g_op)', '    MatchStrings(string p,string s)', '    DeactivateSubgraph(std::vector subgraph)', '    external_input', '    external_output', '    GetNetDef', '    Graph(const NetDef & net)', '    is_node_active(size_t idx)', '    node(size_t idx)', '    node(size_t idx)', '    push_node(const Node & new_node)', '    resize_nodes(size_t new_size)', '    size', '    Node', '    Node(const OperatorDef & op,bool active,std::map,std::vector,std::map,std::vector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\graph_executor.cpp', [], ['    mayIntroduceGradient(const Block *b)', '    unpackReturnTuple(Stack & stack)', '    getGradExecutor(Operation & op)', '    needsGradient(const std::shared_ptr & graph)', '    packGradient(const Gradient & gradient,Node *dnode)', '    runNondiffOptimization(std::shared_ptr & graph,bool strict_fuser_check)', '    runOptimization(std::shared_ptr & graph,bool unroll)', '    runRequiredPasses(const std::shared_ptr & g)', '    getGradient(const Node *n)', '    aliasAnalysisInternalSpecialCase', '    debugSetAutodiffSubgraphInlining(bool state)', '    getAutodiffSubgraphInlining', '    lastExecutedOptimizedGraph', '    getDebugState', '    getDefaultNumBailOuts', '    getPlanFor(Stack & inputs,size_t remaining_bailout_depth)', '    graph', '    GraphExecutor(std::shared_ptr graph,std::string function_name)', '    run(Stack & inputs)', '    compileSpec(const ArgumentSpec & spec)', '    getDebugState', '    getOrCompile(const Stack & stack)', '    getOrCompileFallback', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    GraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    run(Stack & stack)', '    addInputIValue(const IValue & v)', '    addInputVariable(Variable output)', '    addOutputForIValue(const IValue & value)', '    addOutputForTensor(const at::Tensor & tensor)', '    apply(variable_list)', '    capture(const IValue & val,bool is_output)', '    DifferentiableGraphBackward(GraphExecutor executor,size_t input_size,size_t capture_size)', '    produceOutput(size_t i,at::Tensor output,variable_list & outputs)', '    captureInputs(DifferentiableGraphBackward & grad_fn,at::ArrayRef inputs)', '    captureOutputs(DifferentiableGraphBackward & grad_fn,at::ArrayRef outputs)', '    detach(at::Tensor t)', '    detach(IValue & v)', '    detachVariables(Stack & stack)', '    DifferentiableGraphOp(Gradient grad)', '    operator()(Stack & stack)', '    capture(const IValue & val,bool is_output)', '    CaptureList(size_t capture_size)', '    captureTensor(const at::Tensor & tensor,bool is_output)', '    size', '    unpack(Stack & stack,const std::shared_ptr & saved_for)', '    pushTensor', '    pushTensorList(size_t size)', '    unpack(variable_list,Stack & stack)', '    UnpackInstructions(size_t num_inputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\graph_executor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\graph_executor_impl.h', [], ['    debugSetAutodiffSubgraphInlining(bool state)', '    getAutodiffSubgraphInlining', '    needsGradient(const std::shared_ptr & graph)', '    packGradient(const Gradient & gradient,Node *dnode)', '    runNondiffOptimization(std::shared_ptr & graph,bool strict_fuser_check)', '    runOptimization(std::shared_ptr & graph,bool unroll)', '    prepareGraph(const std::shared_ptr & graph)', '    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    GraphExecutorImplBase(const std::shared_ptr & graph,std::string function_name)', '    run(Stack & stack)', '    ~GraphExecutorImplBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\graph_fuser.cpp', [], ['    simple_mappable', '    CustomFuseGraph(std::shared_ptr & graph,std::function fn,Symbol kind,size_t arg_limit)', '    FuseGraph(std::shared_ptr & graph,bool strict_fuser_check)', '    insert_guard', '    insert_guard', '    insert_guard', '    PeepholeOptimizeShapeExpressions(Block *block)', '    broadcastSizes(at::ArrayRef sizes)', '    isSimpleMap(Node *node)', '    allUsersAreThisConsumerOrCalcSizes(Node *consumer,Value *producer)', '    broadcast_tensors(value_list inputs)', '    buildShapeExpressions(Node *fusion_group)', '    calculatesSize(Node *node)', '    canFuseChunk(Node *consumer,Value *producer)', '    canFuseWithConcat(Value *producer,Node *before_check)', '    createFusedConcat(Node *node)', '    createSingletonFusionGroup(Node *n)', '    findFusedChunk(Node *group,Value *input)', '    fuseChunk(Node *consumer,Value *producer)', '    fuseChunkByReusingExistingFusedChunk(Node *group,Node *chunk,Node *existingFusedChunk)', '    fuseConcats', '    getSubgraph(Node *n)', '    GraphFuser(Block *block,std::shared_ptr graph,FusionCallback callback,Symbol kind)', '    GraphFuser(Block *block,std::shared_ptr graph,bool strict_fuser_check)', '    insertExplicitBroadcast(Node *node)', '    isFusable(Node *node)', '    isFusableCatNode(Node *node)', '    isFusableDefault(Node *node,bool strict_fuser_check)', '    isFusableDevice(Value *v,bool strict_fuser_check)', '    isFusableMap(Node *node)', '    mergeFusionGroups(Node *consumer_group,Node *producer_group)', '    mergeNodeIntoGroup(Node *group,Node *n)', '    optimizeFusedGraphs', '    promoteChunkToBroadcastingChunk(Node *chunk)', '    refreshAliasDb', '    removeOutputsUsedOnlyInSize(Node *fusion_group)', '    replaceIntermediateBroadcastingChunks', '    run', '    scanNode(Node *consumer)', '    scanNodeForChunks(Node *consumer)', '    setInputArgLimit(size_t limit)', '    sortReverseTopological(ArrayRef inputs)', '    tensorInputs(Node *node)', '    tryFuse(Node *consumer,Value *producer)', '    tryToMoveChunk(Node *consumer,Value *producer)', '    usedOnlyInSize(Value *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\graph_fuser.h', [], ['    CustomFuseGraph(std::shared_ptr & graph,std::function is_fusable,Symbol kind,size_t arg_limit)', '    FuseGraph(std::shared_ptr & graph,bool strict_fuser_check)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\graph_node_list.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\graph_rewrite_helper.cpp', [], ['    getFuncName(Value *func_value)', '    getIValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    getValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    replaceConvolutionWithConv2d(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\graph_rewrite_helper.h', [], ['    getFuncName(Value *func_value)', '    getIValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    getValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    replaceConvolutionWithConv2d(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\graph_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp3', '    compare_netdefs(const NetDef & net_a,const NetDef & net_b)', '    TEST(GraphTest,TestGenerateGraphChain)', '    TEST(GraphTest,TestGenerateGraphChainInPlace)', '    TEST(GraphTest,TestGenerateGraphBranch)', '    TEST(GraphTest,TestReusedInputs)', '    TEST(GraphTest,TestGetPerimeter)', '    Run(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\nql\\graphmatcher.cc', [], ['    computeDedupRenameMap(const std::vector & nodes)', '    getNameForBlob(NNGraph::NodeRef node,const std::unordered_map & renameMap)', '    getNQLStringForBlob(NNGraph::NodeRef node,const std::unordered_map & renameMap)', '    convertToNQLString(NNGraph & g)', '    getNodeName(const NNGraph::NodeRef node)', '    deallocTokenStrings', '    testMatchPredicate(const Criteria & criteria)', '    getMatches(nom::repr::NNGraph & df)', '    genMatcherFromASTExpr(ASTExpr *expr,bool insertTemp)', '    genMatcherFromASTGraph(ASTGraph *ast)', '    genMatcherFromASTStmt(ASTStmt *stmt)', '    genMatcherFromIRFile(const char *fname)', '    genMatcherFromIRStr(const char *str)', '    operator[](const std::string & key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\nql\\graphmatcher.h', ['    GraphMatcher'], ['    deallocTokenStrings', '    getNodeName(const nom::repr::NNGraph::NodeRef)', '    testMatchPredicate(const Criteria & criteria)', '    doesMatch(nom::repr::NNGraph & df)', '    findSubgraph(nom::repr::NNGraph & df)', '    genMatcherFromASTExpr(ASTExpr *expr,bool insertTemp)', '    genMatcherFromASTGraph(ASTGraph *ast)', '    genMatcherFromASTStmt(ASTStmt *stmt)', '    genMatcherFromIRFile(const char *fname)', '    genMatcherFromIRStr(const char *str)', '    getMatcher', '    getMatcherGraph', '    getMatches(nom::repr::NNGraph & df)', '    getMatchMap', '    initFromFile(const char *fname)', '    initFromString(const char *str)', '    replaceSubgraphWith', '    operator[](const std::string & key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\nql\\tests\\GraphMatcherTest.cc', [], ['    genTensors(NNGraph & graph,std::vector names)', '    TEST(Basic,MatchSingleNode)', '    TEST(Basic,SyntaxError)', '    TEST(Basic,Diamond)', '    TEST(Basic,BadDiamond)', '    TEST(Basic,StarInputs)', '    TEST(Basic,StarOutputs)', '    TEST(Caffe2ToNQL,Basic)', '    TEST(Caffe2ToNQL,TensorsNameDeduplication)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\GraphTest.cc', [], ['    TEST(Basic,CreateNodeAndEdge)', '    TEST(Basic,DeleteNode)', '    TEST(Basic,DeleteEdge)', '    TEST(Basic,ReplaceEdges)', '    TEST(Basic,HasNode)', '    TEST(Basic,Moves)', '    TEST(Basic,MoveSubgraph)', '    TEST(Basic,DotGenerator)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\GridSampler.cpp', [], ['    grid_sampler_2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_2d_cpu(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_backward_cpu_impl(const Tensor & grad_output,const Tensor & input,const Tensor & grid,GridSamplerInterpolation interpolation_mode,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler_3d_cpu(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_cpu_impl(const Tensor & input,const Tensor & grid,GridSamplerInterpolation interpolation_mode,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\GridSampler.cpp', [], ['    checkGridSize(CheckedFrom,TensorArg grid,TensorArg input)', '    cudnn_grid_sampler_backward(const Tensor & input_t,const Tensor & grid_t,const Tensor & grad_output_t)', '    cudnn_grid_sampler_forward(const Tensor & input_t,const Tensor & grid_t)', '    setSamplerDescriptor(SpatialTransformerDescriptor & desc,cudnnDataType_t dataType,const at::Tensor & tensor)', '    gdesc', '    idesc', '    idesc', '    input', '    input', '    odesc', '    odesc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\GridSampler.h', ['    GridSamplerInterpolation', '    GridSamplerPadding'], ['    clip_coordinates(scalar_t in,int64_t clip_limit)', '    clip_coordinates_set_grad(scalar_t in,int64_t clip_limit,scalar_t *grad_in)', '    grid_sampler_compute_source_index(scalar_t coord,int64_t size,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler_compute_source_index_set_grad(scalar_t coord,int64_t size,GridSamplerPadding padding_mode,bool align_corners,scalar_t *grad_in)', '    grid_sampler_unnormalize(scalar_t coord,int64_t size,bool align_corners)', '    grid_sampler_unnormalize_set_grad(scalar_t coord,int64_t size,bool align_corners,scalar_t *grad_in)', '    reflect_coordinates(scalar_t in,int64_t twice_low,int64_t twice_high)', '    reflect_coordinates_set_grad(scalar_t in,int64_t twice_low,int64_t twice_high,scalar_t *grad_in)', '    safe_add_2d(scalar_t *data,int64_t h,int64_t w,int64_t sH,int64_t sW,int64_t H,int64_t W,scalar_t delta)', '    safe_add_3d(scalar_t *data,int64_t d,int64_t h,int64_t w,int64_t sD,int64_t sH,int64_t sW,int64_t D,int64_t H,int64_t W,scalar_t delta)', '    within_bounds_2d(int64_t h,int64_t w,int64_t H,int64_t W)', '    within_bounds_3d(int64_t d,int64_t h,int64_t w,int64_t D,int64_t H,int64_t W)', '    fmod']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\GridSamplerKernel.cpp', [], ['    grid_sample_2d_grid_slice_iterator(const TensorAccessor & grid_slice,const ApplyFn & apply_fn)', '    mask_scatter_add(const scalar_t *src,scalar_t *base_addr,const int_same_size_t *offsets,const int_same_size_t *mask,int64_t len)', '    grid_sampler_2d_backward_cpu_kernel_impl(const Tensor & grad_output_,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_2d_cpu_kernel_impl(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    ApplyGridSample(const TensorAccessor & input)', '    ApplyGridSample(const TensorAccessor & input)', '    backward(TensorAccessor & gInp_slice,TensorAccessor & gGrid_slice,const TensorAccessor & gOut_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    backward(TensorAccessor & gInp_slice,TensorAccessor & gGrid_slice,const TensorAccessor & gOut_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    compute_interp_params(const Vec & x,const Vec & y)', '    forward(TensorAccessor & out_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    forward(TensorAccessor & out_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    apply(const Vec & in)', '    apply(const Vec & in)', '    apply(const Vec & in)', '    apply_get_grad(const Vec & in)', '    apply_get_grad(const Vec & in)', '    apply_get_grad(const Vec & in)', '    clip_coordinates(const Vec & in)', '    clip_coordinates(const Vec & in)', '    clip_coordinates_get_grad(const Vec & in)', '    clip_coordinates_get_grad(const Vec & in)', '    ComputeLocationBase(int64_t size)', '    ComputeLocationBase(int64_t size)', '    reflect_coordinates(const Vec & in)', '    reflect_coordinates(const Vec & in)', '    reflect_coordinates_get_grad(const Vec & in)', '    reflect_coordinates_get_grad(const Vec & in)', '    unnormalize(const Vec & in)', '    unnormalize(const Vec & in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\GridSamplerKernel.h', [], ['    grid_sampler_2d_backward_cpu_kernel', '    grid_sampler_2d_backward_cpu_kernel', '    operator=', '    grid_sampler_2d_cpu_kernel', '    grid_sampler_2d_cpu_kernel', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\group_norm_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GroupNorm', '    AffineBatchChannelDequantizedNCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelDequantizedNHWC(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelQuantizedNCHW(const int N,const int C,const int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelQuantizedNHWC(const int N,const int C,const int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeDequantizedFusedParams(const int N,const int G,const int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    ComputeQuantizedFusedParams(const int N,const int G,const int K,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,const int32_t *beta,int32_t *scale,int32_t *bias)', '    ComputeQuantizedInvStd(const int N,const float *var,float *rsig,int32_t *rsig_quantized)', '    DequantizedGroupMomentsNCHW(const int N,const int G,const int K,const int HxW,const T *X,float *mu,float *rsig)', '    DequantizedGroupMomentsNHWC(const int N,const int G,const int K,const int HxW,const T *X,float *mu,float *rsig)', '    GetQuantizationParameters', '    GroupNormDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    QuantizeBeta', '    QuantizedGroupMomentsNCHW(const int N,const int G,const int K,const int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizedGroupMomentsNHWC(const int N,const int G,const int K,const int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizeGamma', '    QuantizeGammaImpl', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\group_norm_dnnlowp_op.h', ['    final'], ['    AffineBatchChannelAndRequantizeNCHWAVX2(const int N,const int C,const int HxW,const dnnlowp::RequantizationParams & params,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelAndRequantizeNHWCAVX2(const int N,const int C,const int HxW,const dnnlowp::RequantizationParams & params,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeQuantizedFusedParamsAVX2(const int N,const int G,const int K,const int32_t X_zero_point,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,int32_t *scale,int32_t *bias)', '    VectorMomentsAVX2(const int N,const T *src,int64_t *sum,int64_t *sumsq)', '    AffineBatchChannelDequantizedNCHW(int N,int C,int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelDequantizedNHWC(int N,int C,int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelQuantizedNCHW(int N,int C,int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelQuantizedNHWC(int N,int C,int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeDequantizedFusedParams(int N,int G,int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    ComputeQuantizedFusedParams(int N,int G,int K,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,const int32_t *beta,int32_t *scale,int32_t *bias)', '    ComputeQuantizedInvStd(int N,const float *var,float *rsig,int32_t *rsig_quantized)', '    DequantizedGroupMomentsNCHW(int N,int G,int K,int HxW,const T *X,float *mu,float *rsig)', '    DequantizedGroupMomentsNHWC(int N,int G,int K,int HxW,const T *X,float *mu,float *rsig)', '    GetQuantizationParameters', '    GroupNormDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    QuantizeBeta', '    QuantizedGroupMomentsNCHW(int N,int G,int K,int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizedGroupMomentsNHWC(int N,int G,int K,int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizeGamma', '    QuantizeGammaImpl', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\group_norm_dnnlowp_op_avx2.cc', [], ['    AffineBatchChannelAndRequantizeNCHWAVX2(const int N,const int C,const int HxW,const fbgemm::RequantizationParams & params,const uint8_t *X,const int32_t *scale,const int32_t *bias,uint8_t *Y)', '    AffineBatchChannelAndRequantizeNHWCAVX2(const int N,const int C,const int HxW,const fbgemm::RequantizationParams & params,const uint8_t *X,const int32_t *scale,const int32_t *bias,uint8_t *Y)', '    ComputeQuantizedFusedParamsAVX2(const int N,const int G,const int K,const int32_t X_zero_point,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,int32_t *scale,int32_t *bias)', '    SegmentMomentsAVX2(const int N,const uint8_t *src,int64_t *sum,int64_t *sumsq)', '    VectorMomentsAVX2(const int N,const uint8_t *src,int64_t *sum,int64_t *sumsq)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\group_norm_op.cc', ['    GetGroupNormGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGroupNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPUGroupNormGradient', '    ComputeGradientFusedParams(const int N,const int G,const int K,const int HxW,const T *ds,const T *db,const T *mu,const T *rsig,const T *gamma,T *dY_scale,T *X_scale,T *bias)', '    ComputeInternalGradients(const int N,const int C,const int HxW,const float *dY,const float *X,float *ds,float *db)', '    ComputeInternalGradients(const int N,const int C,const int HxW,const float *dY,const float *X,float *ds,float *db)', '    GammaBetaBackward(const int N,const int G,const int K,const T *ds,const T *db,const T *mu,const T *rsig,T *dgamma,T *dbeta)', '    GroupNormBackward(const int N,const int G,const int K,const int HxW,const float *dY_scale,const float *dY,const float *X_scale,const float *X,const float *bias,float *dX)', '    GroupNormBackward(const int N,const int G,const int K,const int HxW,const float *dY_scale,const float *dY,const float *X_scale,const float *X,const float *bias,float *dX)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupNormGradient', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW(const int N,const int G,const int K,const int HxW,const float *dY_data,const float *X_data,const float *mu_data,const float *rsig_data,const float *gamma_data,float *dX_data,float *dgamma_data,float *dbeta_data)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)', '    ComputeFusedParams(const int N,const int G,const int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    GroupNormForwardNHWC(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const float *X,const float *gamma,const float *beta,float *Y,float *mu,float *rsig)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\group_norm_op.h', ['    final', '    final'], ['    ComputeFusedParams(int N,int G,int K,const T *mu,const T *rsig,const T *gamma,const T *beta,T *scale,T *bias)', '    GetSingleArgument', '    GroupNormForwardNCHW(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y)', '    GroupNormForwardNHWC(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y)', '    GroupNormGradientOp(Args,...)', '    GroupNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(const int N,const int G,const int K,const int HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mu,T *rsig)', '    RunOnDeviceWithOrderNCHW(int N,int G,int K,int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mu,T *rsig)', '    RunOnDeviceWithOrderNHWC(int N,int G,int K,int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\group_spatial_softmax_op.cc', ['    GetGroupSpatialSoftmaxGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGroupSpatialSoftmax', '    CAFFE_ANONYMOUS_VARIABLE_CPUGroupSpatialSoftmaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupSpatialSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupSpatialSoftmaxGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\group_spatial_softmax_op.h', ['    final', '    final'], ['    GetSingleArgument', '    GroupSpatialSoftmaxGradientOp(const OperatorDef & def,Workspace *ws)', '    GroupSpatialSoftmaxOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gru_unit_op.cc', ['    GetGRUUnitGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGRUUnit', '    CAFFE_ANONYMOUS_VARIABLE_CPUGRUUnitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GRUUnit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GRUUnitGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\gru_unit_op.h', ['    GRUUnitGradientOp', '    GRUUnitOp'], ['    GRUUnit(int N,int D,int t,const T *H_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *H,Context *)', '    GRUUnitGradient(int N,int D,int t,const T *H_prev,const T *X,const int32_t *seqLengths,const T *H,const T *H_diff,bool drop_states,T *H_prev_diff,T *X_diff,Context *)', '    host_tanh(T x)', '    sigmoid(T x)', '    GetSingleArgument', '    GRUUnitGradientOp(Args,...)', '    RunOnDevice', '    GetSingleArgument', '    GRUUnitOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\gtest.cpp', [], ['    TEST(JitTest,ADFormulas)', '    TEST(JitTest,Attributes)', '    TEST(JitTest,Blocks)', '    TEST(JitTest,CallStack)', '    TEST(JitTest,CallStackCaching)', '    TEST(JitTest,CodeTemplate)', '    TEST(JitTest,ControlFlow)', '    TEST(JitTest,CreateAutodiffSubgraphs)', '    TEST(JitTest,CustomOperators)', '    TEST(JitTest,CustomOperatorAliasing)', '    TEST(JitTest,IValueKWargs)', '    TEST(JitTest,CustomFusion)', '    TEST(JitTest,SchemaMatching)', '    TEST(JitTest,Differentiate)', '    TEST(JitTest,DifferentiateWithRequiresGrad)', '    TEST(JitTest,FromQualString)', '    TEST(JitTest,InternedStrings)', '    TEST(JitTest,PassManagement)', '    TEST(JitTest,Proto)', '    TEST(JitTest,RegisterFusionCachesKernel)', '    TEST(JitTest,SchemaParser)', '    TEST(JitTest,TopologicalIndex)', '    TEST(JitTest,TopologicalMove)', '    TEST(JitTest,SubgraphUtils)', '    TEST(JitTest,AliasAnalysis)', '    TEST(JitTest,ContainerAliasing)', '    TEST(JitTest,AliasRegistration)', '    TEST(JitTest,WriteTracking)', '    TEST(JitTest,Wildcards)', '    TEST(JitTest,MemoryDAG)', '    TEST(JitTest,IRParser)', '    TEST(JitTest,ConstantPooling)', '    TEST(JitTest,THNNConv)', '    TEST(JitTest,ATenNativeBatchNorm)', '    TEST(JitTest,NoneSchemaMatch)', '    TEST(JitTest,ClassParser)', '    TEST(JitTest,UnifyTypes)', '    TEST(JitTest,Profiler)', '    TEST(JitTest,InsertAndEliminateRedundantGuards)', '    TEST(JitTest,InsertBailOuts)', '    TEST(JitTest,PeepholeOptimize)', '    TEST(JitTest,RecordFunction)', '    TEST(JitTest,ThreadLocalDebugInfo)', '    TEST(JitTest,SubgraphMatching)', '    TEST(JitTest,SubgraphRewriter)', '    TEST(JitTest,ModuleClone)', '    TEST(JitTest,ModuleCloneInstance)', '    TEST(JitTest,ModuleConstant)', '    TEST(JitTest,ModuleParameter)', '    TEST(JitTest,ModuleDefine)', '    TEST(JitTest,QualifiedName)', '    TEST(JitTest,ClassImport)', '    TEST(JitTest,ProfiledTensorTypeHashing)', '    TEST(JitTest,ScriptObject)', '    TEST(JitTest,SaveExtraFilesHook)', '    TEST(JitTest,TypeTags)', '    TEST(JitTest,DCE)', '    TEST(JitTest,CustomFusionNestedBlocks)', '    TEST(JitTest,ClassDerive)', '    TEST(JitTest,SaveLoadTorchbind)', '    TEST(JitTest,ModuleInterfaceSerialization)', '    TEST(JitTest,ClassTypeAddRemoveAttr)', '    TEST(JitTest,Inliner)', '    TEST(JitTest,LiteInterpreterAdd)', '    TEST(JitTest,LiteInterpreterConv)', '    TEST(JitTest,LiteInterpreterInline)', '    TEST(JitTest,LiteInterpreterTuple)', '    TEST(JitTest,LiteInterpreterUpsampleNearest2d)', '    TEST(JitTest,CommonAncestor)', '    TEST(JitTest,AutogradSymbols)', '    TEST(JitTest,MobileTypeParser)', '    TEST(JitTest,LiteInterpreterBuiltinFunction)', '    TEST(JitTest,LiteInterpreterPrim)', '    TEST(JitTest,LiteInterpreterLoadOrigJit)', '    TEST(JitTest,LiteInterpreterWrongMethodName)', '    TEST(JitTest,LiteInterpreterParams)', '    TEST(JitTest,LiteInterpreterSetState)', '    TEST(JitTest,TorchbindIValueAPI)', '    TEST(JitTest,ArgumentSpec_CUDA)', '    TEST(JitTest,CompleteArgumentSpec_CUDA)', '    TEST(JitTest,Fusion_CUDA)', '    TEST(JitTest,GraphExecutor_CUDA)', '    TEST(JitTest,ModuleConversion_CUDA)', '    TEST(JitTest,Interp_CUDA)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\gtest.cpp', [], ['    TEST(TensorExprTest,ExprBasicValueTest)', '    TEST(TensorExprTest,ExprBasicValueTest02)', '    TEST(TensorExprTest,ExprLetTest01)', '    TEST(TensorExprTest,ExprLetStmtTest01)', '    TEST(TensorExprTest,ExprLetTest02)', '    TEST(TensorExprTest,ExprIntTest)', '    TEST(TensorExprTest,ExprFloatTest)', '    TEST(TensorExprTest,ExprByteTest)', '    TEST(TensorExprTest,ExprCharTest)', '    TEST(TensorExprTest,ExprShortTest)', '    TEST(TensorExprTest,ExprLongTest)', '    TEST(TensorExprTest,ExprHalfTest)', '    TEST(TensorExprTest,ExprDoubleTest)', '    TEST(TensorExprTest,ExprVectorAdd01)', '    TEST(TensorExprTest,ExprCompareSelectEQ)', '    TEST(TensorExprTest,ExprSubstitute01)', '    TEST(TensorExprTest,ExprMath01)', '    TEST(TensorExprTest,ExprUnaryMath01)', '    TEST(TensorExprTest,ExprBinaryMath01)', '    TEST(TensorExprTest,ExprDynamicShapeAdd)', '    TEST(TensorExprTest,ExprBitwiseOps)', '    TEST(TensorExprTest,IRPrinterBasicValueTest)', '    TEST(TensorExprTest,IRPrinterBasicValueTest02)', '    TEST(TensorExprTest,IRPrinterLetTest01)', '    TEST(TensorExprTest,IRPrinterLetTest02)', '    TEST(TensorExprTest,IRPrinterCastTest)', '    TEST(TensorExprTest,ExprSimple01)', '    TEST(TensorExprTest,ExprLower01)', '    TEST(TensorExprTest,ExprSimple02)', '    TEST(TensorExprTest,ExprSplitWithTailNone)', '    TEST(TensorExprTest,ExprSplitWithMask01)', '    TEST(TensorExprTest,ScheduleBroadcastAddBuffer)', '    TEST(TensorExprTest,ScheduleFunctionCall01)', '    TEST(TensorExprTest,ScheduleInlineFunc01)', '    TEST(TensorExprTest,ScheduleFuserStyle)', '    TEST(TensorExprTest,ScheduleFuserThreeArg)', '    TEST(TensorExprTest,ScheduleDynamicShape2D)', '    TEST(TensorExprTest,TypeTest01)', '    TEST(TensorExprTest,TypePropagation)', '    TEST(TensorExprTest,Cond01)', '    TEST(TensorExprTest,IfThenElse01)', '    TEST(TensorExprTest,IfThenElse02)', '    TEST(TensorExprTest,ATen_cast_Float)', '    TEST(TensorExprTest,ATennegInt)', '    TEST(TensorExprTest,ATennegFloat)', '    TEST(TensorExprTest,ATenaddInt)', '    TEST(TensorExprTest,ATenaddFloat)', '    TEST(TensorExprTest,ATensubInt)', '    TEST(TensorExprTest,ATensubFloat)', '    TEST(TensorExprTest,ATenlerp)', '    TEST(TensorExprTest,ATenaddcmulInt)', '    TEST(TensorExprTest,ATenaddcmulFloat)', '    TEST(TensorExprTest,ATenmulInt)', '    TEST(TensorExprTest,ATenmulFloat)', '    TEST(TensorExprTest,ATendivInt)', '    TEST(TensorExprTest,ATendivFloat)', '    TEST(TensorExprTest,ATenmaxInt)', '    TEST(TensorExprTest,ATenmaxFloat)', '    TEST(TensorExprTest,ATenminInt)', '    TEST(TensorExprTest,ATenminFloat)', '    TEST(TensorExprTest,ATen_sigmoid_backward)', '    TEST(TensorExprTest,ATen_tanh_backward)', '    TEST(TensorExprTest,ATenreciprocal)', '    TEST(TensorExprTest,ATenreluInt)', '    TEST(TensorExprTest,ATenreluFloat)', '    TEST(TensorExprTest,ATenlogFloat)', '    TEST(TensorExprTest,ATenlog10Float)', '    TEST(TensorExprTest,ATenlog2Float)', '    TEST(TensorExprTest,ATenexpFloat)', '    TEST(TensorExprTest,ATenerfFloat)', '    TEST(TensorExprTest,ATencosFloat)', '    TEST(TensorExprTest,ATeneqInt)', '    TEST(TensorExprTest,ATengeInt)', '    TEST(TensorExprTest,ATengtInt)', '    TEST(TensorExprTest,ATenleInt)', '    TEST(TensorExprTest,ATenltInt)', '    TEST(TensorExprTest,ConstantFoldSimple)', '    TEST(TensorExprTest,ConstantFoldTwoLayer)', '    TEST(TensorExprTest,ConstantFoldShifts)', '    TEST(TensorExprTest,ConstantFoldBitwise)', '    TEST(TensorExprTest,ConstantFoldMultiOp)', '    TEST(TensorExprTest,ConstantFoldMinMax)', '    TEST(TensorExprTest,ConstantFoldIntrinsics)', '    TEST(TensorExprTest,ConstantFoldWithVar)', '    TEST(TensorExprTest,UnFoldableExpr)', '    TEST(TensorExprTest,HashSimple)', '    TEST(TensorExprTest,HashEquivalence)', '    TEST(TensorExprTest,HashEquivalenceAfterFolding)', '    TEST(TensorExprTest,HashDifferenceTypes)', '    TEST(TensorExprTest,HashLargeExpression)', '    TEST(TensorExprTest,SimplifyAdd)', '    TEST(TensorExprTest,SimplifySub)', '    TEST(TensorExprTest,SimplifyMultiLayer)', '    TEST(TensorExprTest,SimplifyMultiTerm)', '    TEST(TensorExprTest,SimplifyCasts)', '    TEST(TensorExprTest,SimplifyEliminatesNoOps)', '    TEST(TensorExprTest,SimplifyMultiVar)', '    TEST(TensorExprTest,SimplifyEliminatesVar)', '    TEST(TensorExprTest,SimplifyAdds)', '    TEST(TensorExprTest,SimplifyMuls)', '    TEST(TensorExprTest,SimplifySubs)', '    TEST(TensorExprTest,SimplifyMultiOp)', '    TEST(TensorExprTest,SimplifyManyOps)', '    TEST(TensorExprTest,SimplifyFactorization)', '    TEST(TensorExprTest,SimplifyFactorizeUneven)', '    TEST(TensorExprTest,SimplifyDeeperTerms)', '    TEST(TensorExprTest,SimplifyDeeperDifference)', '    TEST(TensorExprTest,SimplifyFoldComplexDifference)', '    TEST(TensorExprTest,SimplifyIfComponents)', '    TEST(TensorExprTest,SimplifyOpaqueTerms)', '    TEST(TensorExprTest,SimplifyWontReorderFloat)', '    TEST(TensorExprTest,StmtClone)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\gtest_assert_float_eq.h', [], ['    DistanceBetweenSignAndMagnitudeNumbers(const Bits & sam1,const Bits & sam2)', '    SignAndMagnitudeToBiased(const Bits & sam)', '    AlmostEquals(float lhs,float rhs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\guard_elimination.cpp', [], ['    no_exceptions', '    EliminateRedundantGuards(std::shared_ptr graph)', '    isLoweredGradOf(Node *n)', '    checkInputs(Node *n,const std::unordered_set & except,bool allow_numbers)', '    coalesceGuards(Block *b)', '    eliminateRedundantGuards(Block *b)', '    GuardElimination(std::shared_ptr graph)', '    guardsOutput(Node *guard)', '    moveGuardsToDefs(Block *b)', '    removableGuard(Node *n)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\guard_elimination.h', [], ['    EliminateRedundantGuards(std::shared_ptr graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\h_softmax_op.cc', ['    GetHSoftmaxGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmax', '    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmaxSearch', '    CAFFE_ANONYMOUS_VARIABLE_CPUHuffmanTreeHierarchy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmaxSearch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HuffmanTreeHierarchy', '    get_next_node', '    intermediate_data', '    vector', '    RunForwardSingle(const float *X,const float *W,const float *b,int target,float *int_output,const float *bias_multiplier,int dim_out,int dim_in,int & int_output_offset)', '    RunOnDevice', '    GetGradientDefs', '    RunBackwardSingle(const float *X,const float *dY,const float *W,int target,const float *int_output,float *dX,float *dW,float *db,float *dint_output,int dim_in,int dim_out,int & int_output_offset)', '    extractNodes(const NodeProto & node,std::vector,float)', '    pruning(const float *X,int sample,int K,const float *W,const float *b,const NodeProto & src_node,NodeProto & dst_node,float parent_score,float beam)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\h_softmax_op.h', ['    final', '    final', '    HSoftmaxOp', '    HSoftmaxOpBase', '    HuffmanTreeHierarchyOp'], ['    getHierarchyForLabels(int M,const int *labels,const std::unordered_map & hierarchy_all_map)', '    kLOG_THRESHOLD', '    extractNodes(const NodeProto & node,std::vector,float)', '    HSoftmaxSearchOp(Args,...)', '    pruning(const float *X,int sample,int K,const float *W,const float *b,const NodeProto & src_node,NodeProto & dst_node,float parent_score,float beam)', '    RunBackwardSingle(const float *X,const float *dY,const float *W,int target,const float *int_output,float *dX,float *dW,float *db,float *dOutput,int dim_in,int w_length,int & output_offset)', '    RunOnDevice', '    RunForwardSingle(const float *X,const float *W,const float *b,int target,float *int_output,const float *bias_multiplier,int dim_out,int dim_in,int & int_output_offset)', '    RunOnDevice', '    getIntermediateOutputSize(const int *labels,int M,std::unordered_map & hierarchy)', '    GetSingleArgument', '    HSoftmaxOpBase(Args,...)', '    GetSingleArgument', '    HuffmanTreeHierarchyOp(Args,...)', '    Node(T l,int count)', '    operator()(const Node & node_a,const Node & node_b)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Half-inl.h', [], ['    denorm_min', '    epsilon', '    infinity', '    lowest', '    max', '    min', '    quiet_NaN', '    round_error', '    signaling_NaN', '    operator float', '    operator*(const Half & a,const Half & b)', '    operator*(Half a,float b)', '    operator*(float a,Half b)', '    operator*(Half a,double b)', '    operator*(double a,Half b)', '    operator*(Half a,int b)', '    operator*(int a,Half b)', '    operator*(Half a,int64_t b)', '    operator*(int64_t a,Half b)', '    operator*=(Half & a,const Half & b)', '    operator*=(float & a,const Half & b)', '    operator+(const Half & a,const Half & b)', '    operator+(Half a,float b)', '    operator+(float a,Half b)', '    operator+(Half a,double b)', '    operator+(double a,Half b)', '    operator+(Half a,int b)', '    operator+(int a,Half b)', '    operator+(Half a,int64_t b)', '    operator+(int64_t a,Half b)', '    operator+=(Half & a,const Half & b)', '    operator+=(float & a,const Half & b)', '    operator-(const Half & a,const Half & b)', '    operator-(const Half & a)', '    operator-(Half a,float b)', '    operator-(float a,Half b)', '    operator-(Half a,double b)', '    operator-(double a,Half b)', '    operator-(Half a,int b)', '    operator-(int a,Half b)', '    operator-(Half a,int64_t b)', '    operator-(int64_t a,Half b)', '    operator-=(Half & a,const Half & b)', '    operator-=(float & a,const Half & b)', '    operator/(const Half & a,const Half & b)', '    operator/(Half a,float b)', '    operator/(float a,Half b)', '    operator/(Half a,double b)', '    operator/(double a,Half b)', '    operator/(Half a,int b)', '    operator/(int a,Half b)', '    operator/(Half a,int64_t b)', '    operator/(int64_t a,Half b)', '    operator/=(Half & a,const Half & b)', '    operator/=(float & a,const Half & b)', '    Half(float value)', '    fp16_ieee_from_fp32_value', '    from_bits']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Half.cpp', [], ['    operator<<(std::ostream & out,const Half & value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Half.h', [], ['    from_bits', '    fp16_ieee_from_fp32_value(float f)', '    fp16_ieee_to_fp32_bits(uint16_t h)', '    fp16_ieee_to_fp32_value(uint16_t h)', '    fp32_from_bits(uint32_t w)', '    fp32_to_bits(float f)', '    Half', '    Half(unsigned short bits,from_bits_t)', '    Half(float value)', '    operator float', '    ComplexHalf', '    ComplexHalf(std::complex value)', '    imag', '    operator std::complex', '    operator<<(std::ostream & out,const Half & value)', '    overflows(From f)', '    overflows(From f)', '    overflows(From f)', '    overflows(From f)', '    real', '    lowest', '    max', '    isinf']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\half_float_ops.cc', ['    GetFloatToHalfGradient', '    GetHalfToFloatGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloat16ConstantFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloat16UniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Float16ConstantFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Float16UniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFloat', '    Float16ToFloat_ref(const at::Half *in,float *out,size_t N)', '    FloatToFloat16_ref(const float *in,at::Half *out,size_t N,bool do_clip)', '    vector', '    vector', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    RunOnDevice', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\half_float_ops.h', ['    Float16ConstantFillOp', '    Float16UniformFillOp', '    FloatToHalfOp', '    HalfToFloatOp'], ['    Float16FillerTensorInference(const OperatorDef & def,const vector & in)', '    Float16ConstantFillOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    ~Float16ConstantFillOp', '    Float16UniformFillOp(Args,...)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    RunOnDevice', '    ~Float16UniformFillOp', '    FloatToHalfOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    HalfToFloatOp(Args,...)', '    RunOnDevice', '    ~HalfToFloatOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\half_float_ops_test.cc', [], ['    TEST(Float16,SimpleTest)', '    TEST(Float16,UniformDistributionTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\Half_test.cpp', [], ['    float2halfbits(float src)', '    halfbits2float(unsigned short h)', '    TEST(HalfDoubleConversionTest,Half2Double)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\half_test.cpp', [], ['    to_string(const Half & h)', '    TEST(TestHalf,Arithmetic)', '    TEST(TestHalf,Comparisions)', '    TEST(TestHalf,Cast)', '    TEST(TestHalf,Construction)', '    TEST(TestHalf,Half2String)', '    TEST(TestHalf,HalfNumericLimits)', '    TEST(TestHalf,CommonMath)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\half_utils.h', [], ['    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Handle.cpp', [], ['    createCuDNNHandle(cudnnHandle_t *handle)', '    destroyCuDNNHandle(cudnnHandle_t handle)', '    getCudnnHandle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Handle.cpp', [], ['    getMiopenHandle', '    Handle', '    ~Handle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Handle.h', [], ['    getMiopenHandle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Handle.h', [], ['    getCudnnHandle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Handles.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\hard_sigmoid_op.cc', ['    GetHardSigmoidGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUHardSigmoid', '    CAFFE_ANONYMOUS_VARIABLE_CPUHardSigmoidGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HardSigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HardSigmoidGradient', '    CostInferenceForHardSigmoid(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\hard_sigmoid_op.h', [], ['    HardSigmoidFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)', '    HardSigmoidGradientFunctor(OperatorBase & op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\hash.h', [], ['    simple_get_hash(const T & o)', '    get_hash(const Types &,...)', '    operator()(const std::tuple & t)', '    operator()(const std::vector & v)', '    dispatch_hash(const T & o)', '    simple_get_hash(const T & o)', '    type_if_not_enum', '    dispatch_hash(const T & o)', '    hash_combine(size_t seed,size_t value)', '    size_t', '    dispatch_hash', '    simple_get_hash', '    operator()(const T & o)', '    get', '    hash', '    tie', '    hash', '    operator()(const std::tuple & t)', '    operator()(const std::tuple & t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\hash_provider.cpp', [], ['    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Block *v)', '    visit(const For *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    operator!=(const SimplifierHashType & other)', '    operator!=(const size_t other)', '    operator<(const SimplifierHashType & other)', '    operator==(const SimplifierHashType & other)', '    operator==(const size_t other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\hash_provider.h', ['    HashProvider'], ['    hash', '    intval', '    operator()(const torch::jit::tensorexpr::SimplifierHashType & k)', '    value', '    value', '    _hash_combine(SimplifierHashType & seed,const T & val)', '    _hash_combine(SimplifierHashType & seed,const char *val)', '    _hash_combine(SimplifierHashType & seed,const at::Half & val)', '    _hash_combine(SimplifierHashType & seed,const Dtype & val)', '    _hash_combine(SimplifierHashType & seed,const Expr *e)', '    _hash_combine(SimplifierHashType & seed,const T & val,const Types &,...)', '    cachedHash(const KernelScopedObject *e)', '    hash(const T *e)', '    hash_combine(const Types &,...)', '    hashOf(const Expr *e)', '    hashOf(const Stmt *s)', '    putHash(const KernelScopedObject *e,SimplifierHashType h)', '    te_hash(SimplifierHashType val)', '    te_hash(int64_t val)', '    te_hash(int32_t val)', '    te_hash(uint32_t val)', '    te_hash(uint64_t val)', '    te_hash(int16_t val)', '    te_hash(std::string val)', '    te_hash(double d)', '    te_hash(float d)', '    te_hash(at::Half d)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Block *v)', '    visit(const For *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    _h', '    operator!=(const SimplifierHashType & other)', '    operator!=(const size_t other)', '    operator<(const SimplifierHashType & other)', '    operator==(const SimplifierHashType & other)', '    operator==(const size_t other)', '    SimplifierHashType', '    SimplifierHashType(size_t s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\HashStore.cpp', [], ['    pred', '    pred', '    add(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    set(const std::string & key,const std::vector & data)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\HashStore.hpp', ['    HashStore'], ['    add(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    wait(const std::vector & keys)', '    ~HashStore']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\HashStoreTest.cpp', [], ['    main(int,char **)', '    testHelper(std::string prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\heatmap_max_keypoint_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUHeatmapMaxKeypoint', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HeatmapMaxKeypoint', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\heatmap_max_keypoint_op.h', ['    final'], ['    schema_HeatmapMaxKeypoint', '    GetSingleArgument', '    HeatmapMaxKeypointOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\helper.cc', [], ['    ExtraTypeProto(const ::ONNX_NAMESPACE::TensorProto & tensor)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::vector & attributes,const std::string & name)', '    NewDummyName', '    Reset(const std::unordered_set & used_names)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\helper.cpp', [], ['    buildValueToParamsMap(Block *b,const ParamMap & paramsDict)', '    eraseUnusedValuesFromMap(ValueToParamPairMap & valsToParamsMap)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\helper.h', ['    DummyName'], ['    ExtraTypeProto(const ::ONNX_NAMESPACE::TensorProto & tensor)', '    MakeAttribute(const std::string & name,const std::vector & vals)', '    MakeAttribute(const std::string & name,const std::vector & vals)', '    MakeAttribute(const std::string & name,int64_t val)', '    MakeAttribute(const std::string & name,const std::string & val)', '    MakeAttribute(const std::string & name,::ONNX_NAMESPACE::TensorProto & val)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::vector & attributes,const std::string & name)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::string & name)', '    MakeTensor(const string & name,const std::vector & v,const ::ONNX_NAMESPACE::TensorProto_DataType & data_type_)', '    AddName(const std::string & new_used)', '    counter_', '    NewDummyName', '    Reset(const std::unordered_set & used_names)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\helper.h', [], ['    buildValueToParamsMap(Block *b,const ParamMap & paramsDict)', '    eraseUnusedValuesFromMap(ValueToParamPairMap & valsToParamsMap)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\hgemm.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\hgemm.cc', ['    HGEMM', '    HGEMM_L1', '    HGEMM_Op'], ['    GemmArguments(benchmark::internal::Benchmark *b)', '    MobileNetV1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8GemmArguments(benchmark::internal::Benchmark *b)', '    SqueezeNetV10GemmArguments(benchmark::internal::Benchmark *b)', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)', '    a', '    b', '    c', '    clampingParams', '    clampingParams_', '    HGEMM(uint32_t mr,uint32_t nr,uint32_t kr)', '    k', '    kc', '    kc_', '    kcStride', '    kr', '    kr_', '    mc', '    mc_', '    mr', '    mr_', '    nc', '    nc_', '    ncStride', '    nr', '    nr_', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    w', '    w', '    HGEMM_L1', '    HGEMM_Op', '    SetUp(const benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\hgemm.h', [], ['    pytorch_hgemm_ukernel_8x8__aarch32_neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params *clamping_params)', '    pytorch_hgemm_ukernel_8x8__neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPAllocatorMasqueradingAsCUDA.h', ['    final'], ['    device', '    unsafe_set_device', '    allocate(size_t size)', '    HIPAllocatorMasqueradingAsCUDA(Allocator *allocator)', '    raw_deleter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPCachingAllocatorMasqueradingAsCUDA.cpp', [], ['    get', '    recordStreamMasqueradingAsCUDA(const DataPtr & ptr,HIPStreamMasqueradingAsCUDA stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPCachingAllocatorMasqueradingAsCUDA.h', [], ['    get', '    recordStreamMasqueradingAsCUDA(const DataPtr & ptr,HIPStreamMasqueradingAsCUDA stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPGuardImplMasqueradingAsCUDA.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPGuardImplMasqueradingAsCUDA.h', [], ['    hip_stream', '    hip_stream', '    block(void *event,const Stream & stream)', '    createEvent(hipEvent_t *hip_event,const EventFlag flag)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDefaultStream(Device d)', '    getDevice', '    getStream(Device d)', '    HIPGuardImplMasqueradingAsCUDA', '    HIPGuardImplMasqueradingAsCUDA(DeviceType t)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)', '    current_device', '    HIPGuardMasqueradingAsCUDA', '    HIPGuardMasqueradingAsCUDA(DeviceIndex device_index)', '    HIPGuardMasqueradingAsCUDA(Device device)', '    HIPGuardMasqueradingAsCUDA', '    HIPGuardMasqueradingAsCUDA', '    operator=', '    operator=', '    original_device', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_device', '    current_stream', '    HIPStreamGuardMasqueradingAsCUDA', '    HIPStreamGuardMasqueradingAsCUDA(Stream stream)', '    HIPStreamGuardMasqueradingAsCUDA', '    HIPStreamGuardMasqueradingAsCUDA', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    current_device', '    operator=', '    operator=', '    OptionalHIPGuardMasqueradingAsCUDA(optional device_index_opt)', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA(optional device_opt)', '    original_device', '    reset', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_stream', '    operator=', '    operator=', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    OptionalHIPStreamGuardMasqueradingAsCUDA(Stream stream)', '    OptionalHIPStreamGuardMasqueradingAsCUDA(optional stream_opt)', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    original_stream', '    reset', '    reset_stream(Stream stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\HIPHooksInterface.cpp', [], ['    getHIPHooks', '    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\detail\\HIPHooksInterface.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\hip\\impl\\HIPStreamMasqueradingAsCUDA.h', ['    HIPStreamMasqueradingAsCUDA'], ['    getCurrentHIPStreamMasqueradingAsCUDA(DeviceIndex device_index)', '    getDefaultHIPStreamMasqueradingAsCUDA(DeviceIndex device_index)', '    getStreamFromPoolMasqueradingAsCUDA(const bool isHighPriority,DeviceIndex device)', '    operator<<(std::ostream & stream,const HIPStreamMasqueradingAsCUDA & s)', '    setCurrentHIPStreamMasqueradingAsCUDA(HIPStreamMasqueradingAsCUDA stream)', '    priority_range', '    unpack(uint64_t bits)', '    device', '    device_index', '    hip_stream', '    HIPStreamMasqueradingAsCUDA(Stream stream)', '    HIPStreamMasqueradingAsCUDA(Unchecked,Stream stream)', '    HIPStreamMasqueradingAsCUDA(HIPStream stream)', '    id', '    operator hipStream_t', '    operator Stream', '    operator!=(const HIPStreamMasqueradingAsCUDA & other)', '    operator==(const HIPStreamMasqueradingAsCUDA & other)', '    pack', '    priority', '    query', '    stream', '    synchronize', '    unwrap', '    operator()(c10::hip::HIPStreamMasqueradingAsCUDA s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\testing\\hooks_for_testing.cpp', [], ['    didFinishEmitFunction(StrongFunctionPtr fn)', '    didFinishEmitModule(Module module)', '    getEmitHooks', '    setEmitHooks(ModuleHook for_mod,FunctionHook for_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\testing\\hooks_for_testing.h', [], ['    didFinishEmitFunction(StrongFunctionPtr fn)', '    didFinishEmitModule(Module module)', '    getEmitHooks', '    setEmitHooks(ModuleHook for_mod,FunctionHook for_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\utils\\ideep_context.h', ['    final'], ['    GetDeviceType', '    HasAsyncPartDefault', '    IsStreamFree(const DeviceOption &,int)', '    SupportsAsyncScheduling', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyItems(const TypeMeta & meta,size_t n,const void *src,void *dst)', '    device', '    device_type', '    override', '    random_seed_', '    size_t', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    FinishDeviceComputation', '    IDEEPContext', '    IDEEPContext(const DeviceOption & option)', '    IDEEPContext(const at::Device & device)', '    RandGenerator', '    Record(Event *ev,const char *err_msg)', '    SwitchToDevice(int)', '    WaitEvent(const Event & ev)', '    ~IDEEPContext', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(size_t nbytes,const void *src,void *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\utils\\ideep_operator.h', ['    IDEEPOperator'], ['    CanonicalDims(ideep::tensor::dims adims,int32_t axis)', '    ConvertScales(const std::vector scales_z)', '    RegistryName', '    getErrorMsg', '    IDEEPOperator(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    Output(int index)', '    RecordEvent(const char *err_msg)', '    Run(int)', '    RunOnDevice', '    WaitEvent(const Event & ev,int)', '    WaitEvents(const std::vector & events,int)', '    ~IDEEPOperator', '    Record', '    WaitEvent']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\utils\\ideep_register.cc', [], ['    CopyBytesWrapper(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device)', '    RegistryName', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\ideep_utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\IDeepRegistration.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\IdWrapper.h', ['    IdWrapper'], ['    noexcept((*) () noexcept)', '    hash_value(const concrete_type & v)', '    operator!=(const concrete_type & lhs,const concrete_type & rhs)', '    operator==(const concrete_type & lhs,const concrete_type & rhs)', '    IdWrapper(underlying_type id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\if_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_If']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\if_op.h', ['    final'], ['    GetSingleArgument', '    HasSingleArgumentOfType', '    IfOp(const OperatorDef & operator_def,Workspace *ws)', '    InputIsTensorType', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\if_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAIf']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Im2Col.cpp', [], ['    im2col_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_backward_cpu(const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\im2col.h', [], ['    col2im(const T *data_col,const int64_t channels,const int64_t height,const int64_t width,const int64_t output_height,const int64_t output_width,const int64_t kernel_h,const int64_t kernel_w,const int64_t pad_h,const int64_t pad_w,const int64_t stride_h,const int64_t stride_w,const int64_t dilation_h,const int64_t dilation_w,T *data_im)', '    im2col(const T *data_im,const int64_t channels,const int64_t height,const int64_t width,const int64_t output_height,const int64_t output_width,const int64_t kernel_h,const int64_t kernel_w,const int64_t pad_h,const int64_t pad_w,const int64_t stride_h,const int64_t stride_w,const int64_t dilation_h,const int64_t dilation_w,T *data_col)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\im2col_dnnlowp.h', [], ['    Im2Col3DNHWC(const int channels,const int num_frames,const int height,const int width,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const int groups,const T & zero_point)', '    Im2ColNCHW(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const T & zero_point)', '    Im2ColNdNCHW(const int N,const int,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *X_data,T *Y_data,CPUContext *,const T & zero_point)', '    Im2ColNHWC(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const int groups,const T & zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\im2col_op.cc', ['    GetIm2ColGradient', '    GetCol2ImGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCol2Im', '    CAFFE_ANONYMOUS_VARIABLE_CPUIm2Col', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Col2Im', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Im2Col', '    GetGradientDefs', '    GetGradientDefs', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\im2col_op.h', ['    final', '    final'], ['    Col2ImOp(Args,...)', '    GetSingleArgument', '    Im2ColOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\im2col_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACol2Im', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIm2Col']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\im2col_shape_check.h', [], ['    col2im_shape_check(const Tensor & input,const Tensor & grad_output,int64_t output_height,int64_t output_width,int64_t kernel_height,int64_t kernel_width,int64_t dilation_height,int64_t dilation_width,int64_t pad_height,int64_t pad_width,int64_t stride_height,int64_t stride_width)', '    im2col_shape_check(const Tensor & input,const Tensor & grad_output,int64_t kernel_height,int64_t kernel_width,int64_t dilation_height,int64_t dilation_width,int64_t pad_height,int64_t pad_width,int64_t stride_height,int64_t stride_width)', '    ndimension', '    numel', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\image\\image_input_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUImageInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ImageInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\image\\image_input_op.h', ['    final'], ['    ApplyTransformOnGPU(const std::vector & dims,const c10::Device & type)', '    Brightness(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    MessageLogger(,,INFO)', '    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    color_lighting_eigvals_', '    ColorJitter(float *img,const int img_size,const float saturation,const float brightness,const float contrast,std::mt19937 *randgen)', '    ColorLighting(float *img,const int img_size,const float alpha_std,const std::vector,const std::vector & eigvals,std::mt19937 *randgen)', '    ColorNormalization(float *img,const int img_size,const int channels,const std::vector & mean,const std::vector & std)', '    Contrast(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    CropTransposeImage(const cv::Mat & scaled_img,const int channels,uint8_t *cropped_data,const int crop,const bool mirror,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_image,bool is_test)', '    DecodeAndTransform(const std::string & value,float *image_data,int item_id,const int channels,std::size_t thread_index)', '    DecodeAndTransposeOnly(const std::string & value,uint8_t *image_data,int item_id,const int channels,std::size_t thread_index)', '    dims', '    GetImageAndLabelAndInfoFromDBValue(const string & value,cv::Mat *img,PerImageArg & info,int item_id,std::mt19937 *randgen)', '    jitter_order', '    num_decode_errors_in_batch_', '    OutputTensorCopyFrom(,type,prefetched_image_on_device_,)', '    OutputTensorCopyFrom(,type,prefetched_label_on_device_,)', '    OutputTensorCopyFrom(i,type,[i-2] prefetched_additional_outputs_on_device_,)', '    RandomSizedCropping(cv::Mat *img,const int crop,std::mt19937 *randgen)', '    ReinitializeTensor(& prefetched_image_,,int64_t crop_,int64_t crop_,int64_t color_,at::dtype)', '    ReinitializeTensor(& prefetched_label_,sizes,at::dtype)', '    Saturation(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    sizes', '    sizes', '    TransformImage(const cv::Mat & scaled_img,const int channels,float *image_data,const bool color_jitter,const float saturation,const float brightness,const float contrast,const bool color_lighting,const float color_lighting_std,const std::vector,const std::vector & color_lighting_eigvals,const int crop,const bool mirror,const std::vector & mean,const std::vector & std,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_image,bool is_test)', '    CopyPrefetched', '    ImageInputOp(const OperatorDef & operator_def,Workspace *ws)', '    Prefetch', '    ~ImageInputOp', '    GetCastDataType', '    cvtColor', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *image_data,int item_id,const int channels,std::size_t thread_index)', '    DecodeAndTransposeOnly(const std::string & value,uint8_t *image_data,int item_id,const int channels,std::size_t thread_index)', '    GetImageAndLabelAndInfoFromDBValue(const string & value,cv::Mat *img,PerImageArg & info,int item_id,std::mt19937 *randgen)', '    ImageInputOp(const OperatorDef & operator_def,Workspace *ws)', '    Prefetch', '    srand', '    time', '    now', '    byte_data', '    data_type', '    dims', '    dims_size', '    float_data', '    float_data_size', '    int32_data', '    int32_data_size', '    size', '    string_data', '    string_data_size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\image\\image_input_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAImageInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import.cpp', ['    final'], ['    obj_loader', '    reader', '    import_ir_module(std::shared_ptr cu,std::istream & in,c10::optional device,ExtraFilesMap & extra_files)', '    import_ir_module(std::shared_ptr cu,const std::string & filename,c10::optional device,ExtraFilesMap & extra_files)', '    import_ir_module(std::shared_ptr cu,std::unique_ptr rai,c10::optional device,ExtraFilesMap & extra_files)', '    load(const std::string & filename,c10::optional device,ExtraFilesMap & extra_files)', '    load(std::unique_ptr rai,c10::optional device,ExtraFilesMap & extra_files)', '    load(std::istream & in,c10::optional device,ExtraFilesMap & extra_files)', '    postSetStateValidate(const IValue & v)', '    readArchiveAndTensors(const std::string & archive_name,c10::optional type_resolver,c10::optional obj_loader,c10::optional device,PyTorchStreamReader & stream_reader)', '    deserialize(c10::optional device,ExtraFilesMap & extra_files)', '    readArchive(const std::string & archive_name)', '    ScriptModuleDeserializer(std::shared_ptr cu,std::unique_ptr reader)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\import.cpp', ['    final'], ['    find_custom_class_with_setstate', '    obj_loader', '    reader', '    _load_for_mobile(std::istream & in,c10::optional device)', '    _load_for_mobile(const std::string & filename,c10::optional device)', '    _load_for_mobile(std::unique_ptr rai,c10::optional device)', '    expect_field(IValue tup,const std::string & expected_name,size_t entry)', '    parseMethods(const std::vector & vals,mobile::CompilationUnit & mcu)', '    print_unsupported_ops_and_throw(const std::unordered_set & unsupported_ops)', '    BytecodeDeserializer(std::unique_ptr reader)', '    deserialize(c10::optional device)', '    readArchive(const std::string & archive_name,std::shared_ptr mcu)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\import.h', [], ['    _load_for_mobile(std::istream & in,c10::optional device)', '    _load_for_mobile(const std::string & filename,c10::optional device)', '    _load_for_mobile(std::unique_ptr rai,c10::optional device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_export_constants.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_export_functions.h', [], ['    expect_field(IValue tup,const std::string & expected_name,size_t entry)', '    moduleMethodsTuple(const Module & module,std::vector & elements)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_export_helpers.cpp', [], ['    findSourceInArchiveFromQualifier(caffe2::serialize::PyTorchStreamReader & reader,const std::string & export_prefix,const std::string & qualifier)', '    qualifierToArchivePath(const std::string & qualifier,const std::string & export_prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_export_helpers.h', [], ['    findSourceInArchiveFromQualifier(caffe2::serialize::PyTorchStreamReader & reader,const std::string & export_prefix,const std::string & qualifier)', '    qualifierToArchivePath(const std::string & qualifier,const std::string & export_prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_legacy.cpp', ['    final'], ['    LEGACY_deserialize(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)', '    LEGACY_convertModule(const torch::ModuleDef & module_def)', '    LEGACY_deserialize', '    LEGACY_loadPickleArchive(const std::string & name)', '    LEGACY_loadTensor(const torch::TensorDef & tensor_proto,std::unordered_map & storageMap)', '    LEGACY_loadTensorTable(torch::ModelDef *model_def)', '    LEGACY_moduleSetState(const Module & module,IValue state)', '    ClassResolver(SourceImporter source_importer)', '    resolveType(const std::string & name,const SourceRange & loc)', '    ScriptModuleDeserializer(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_legacy.h', [], ['    LEGACY_deserialize(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_source.cpp', [], ['    definitions', '    resolvers', '    attr(const SourceRange & loc,Function & m,const std::string & name)', '    ClassNamespaceValue(c10::QualifiedName name,std::shared_ptr si)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    ConstantTableValue(const std::vector *constants)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    OpsValue(size_t version)', '    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    loadNamedType(const QualifiedName & name)', '    SourceImporter(std::shared_ptr cu,const std::vector *tensor_table,SourceLoader loader,size_t version)', '    findFunction(const QualifiedName & name)', '    findNamedType(const QualifiedName & name)', '    importClass(const QualifiedName & qualified_classname,const ClassDef & class_def,bool is_module)', '    importFunction(const std::string & qualifier,const Def & def)', '    importNamedTuple(const QualifiedName & qualified_name,const ClassDef & named_tuple_def)', '    importNamedType(const std::string & qualifier,const ClassDef & class_def)', '    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    parseImports(Lexer & L)', '    parsePossibleVersionNumber(Lexer & L)', '    parseSourceIfNeeded(const std::string & qualifier)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    SourceImporterImpl(const std::shared_ptr cu,const std::vector *tensor_table,SourceLoader source_loader,size_t version)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\import_source.h', [], ['    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    loadNamedType(const QualifiedName & name)', '    SourceImporter(std::shared_ptr cu,const std::vector *tensor_table,SourceLoader loader,size_t version)', '    ~SourceImporter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\in_place.h', [], ['    in_place', '    in_place_index_t', '    in_place_t', '    in_place_type_t']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\index_hash_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIndexHash', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexHash']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\index_hash_ops.h', ['    IndexHashOp'], ['    schema_IndexHash', '    DoRunWithType', '    GetSingleArgument', '    hash(T id)', '    IndexHashOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\index_ops.cc', ['    IndexCreateOp', '    IndexDeserializer', '    IndexFreezeOp', '    IndexGetOp', '    IndexLoadOp', '    IndexSerializer', '    IndexSizeOp', '    IndexStoreOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIndexFreeze', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexLoad', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexStore', '    CAFFE_ANONYMOUS_VARIABLE_CPUIntIndexCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPULongIndexCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPUStringIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexFreeze', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexLoad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexSize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexStore', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LongIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StringIndexCreate', '    noexcept', '    isFrozen', '    maxElements', '    IndexCreateOp(Args,...)', '    RunOnDevice', '    Deserialize(const BlobProto & proto,Blob *blob)', '    doLoad(std::unique_ptr *base,int64_t maxElements,const Tensor & tensor_in)', '    IndexFreezeOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexGetOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexLoadOp(Args,...)', '    RunOnDevice', '    doStore(const std::unique_ptr & base,Tensor *tensor_out)', '    IndexSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~IndexSerializer', '    IndexSizeOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexStoreOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\index_ops.h', [], ['    Freeze', '    frozen_', '    isFrozen', '    maxElements', '    nextId_', '    Size', '    Type', '    ~IndexBase', '    frozen_', '    IndexBase(int64_tValue maxElements,const TypeMeta & type)', '    FrozenGet(const T *keys,int64_tValue *values,size_t numKeys)', '    Get(const T *keys,int64_tValue *values,size_t numKeys)', '    Index(int64_tValue maxElements)', '    Load(const T *keys,size_t numKeys)', '    Store(Tensor *out)', '    Resize', '    Make']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\IndexingUtils.h', [], ['    checkIndexTensorTypes(TensorList indices)', '    expandTensors(const Tensor & self,TensorList indices)', '    hasContiguousSubspace(TensorList tl)', '    if_empty_then(::c10::str __VA_ARGS__,)', '    AdvancedIndex(const Tensor & src,TensorList indices_list)', '    find_if', '    move(transposedIndices)', '    move(invPerm)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\IndexKernel.cpp', [], ['    is_constant_index(int ntensor,const int64_t *strides)', '    cpu_masked_fill_kernel(TensorIterator & iter,scalar_t value)', '    index_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride)', '    index_put_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride,bool accumulate)', '    masked_fill_kernel(TensorIterator & iter,Scalar value)', '    cpu_index_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride,const func_t & f,bool serial_execution)', '    get(int64_t idx)', '    Indexer(int64_t num_indexers,char **indexers,const int64_t *indexer_strides,IntArrayRef original_sizes,IntArrayRef original_strides)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\indirection.c', [], ['    pytorch_qnnp_indirection_init_conv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_deconv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_dwconv2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)', '    pytorch_qnnp_indirection_init_maxpool2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\indirection.h', [], ['    pytorch_qnnp_indirection_init_conv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_deconv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_dwconv2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)', '    pytorch_qnnp_indirection_init_maxpool2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\op_registration\\infer_schema.cpp', [], ['    findSchemaDifferences(const FunctionSchema & lhs,const FunctionSchema & rhs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\op_registration\\infer_schema.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\inference_lstm_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInferenceLSTM', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InferenceLSTM', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\inference_lstm_op.h', ['    InferenceLSTMOp'], ['    _lstm_impl(const Tensor & input,const std::vector & params,const Tensor & hx,const Tensor & cx,int64_t num_layers,bool bidirectional,CPUContext *context)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    schema_LSTMOp', '    gather_params(const std::vector & params,bool has_biases,CPUContext *context)', '    CellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,CPUContext *_context)', '    CellParams(const CellParams & rhs)', '    initParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,CPUContext *_context)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    operator=(const CellParams & rhs)', '    FullBidirectionalLSTMLayer(LSTMCell & cell,CPUContext *context)', '    operator()(const Tensor & input,const bidir_hidden_type & input_hidden,const param_type & params)', '    reverse(std::vector)', '    FullLSTMLayer(LSTMCell & cell,CPUContext *context)', '    operator()(const std::vector & step_inputs,const std::tuple & input_hidden,const CellParams & params)', '    operator()(const Tensor & inputs,const std::tuple & input_hidden,const CellParams & params)', '    operator()(const Tensor & input,const hidden_type & input_hidden,const param_type & params)', '    ~Layer', '    LayerOutput(const output_type & _outputs,const hidden_type & _hidden)', '    LSTMCell(CPUContext *context)', '    operator()(const Tensor & input,const t_tuple & hidden,const CellParams & params)', '    GetSingleArgument', '    InferenceLSTMOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\InferenceGraph.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\InferSize.h', [], ['    infer_size(IntArrayRef shape,int64_t numel)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\init.c', [], ['    init', '    init_win(PINIT_ONCE InitOnce,PVOID Parameter,PVOID *lpContex)', '    pytorch_qnnp_deinitialize', '    pytorch_qnnp_initialize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init.cc', ['    C10FlagParser_caffe2_version', '    State'], ['    GlobalInit(int *pargc,char ***pargv)', '    GlobalInitAlreadyRun', '    GlobalInitState', '    GlobalInit', '    init_state_guard', '    unsafeRunCaffe2InitFunction(const char *name,int *pargc,char ***pargv)', '    Registry', '    C10FlagParser_caffe2_version(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\python\\init.cpp', [], ['    cast(Item src,return_value_policy policy,handle parent)', '    load(handle src,bool convert)', '    bind_ordered_dict(py::module module,const char *dict_name)', '    init_bindings(PyObject *module)', '    cast(Item src,return_value_policy policy,handle parent)', '    load(handle src,bool convert)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\init.cpp', ['    PythonStore'], ['    python_functions', '    c10d_init(PyObject *_unused)', '    add(const std::string & key,int64_t value)', '    split(char separator,const std::string & string)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\init.cpp', ['    BufferAdapter'], ['    initJITBindings(PyObject *module)', '    loadPythonClasses', '    BufferAdapter(const py::object & buffer)', '    getMemview(void *buf,size_t n)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\init.cpp', [], ['    python_functions', '    rpc_init(PyObject *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Init.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\init.cpp', [], ['    initThroughputBenchmarkBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\init.cpp', [], ['    _calculate_fan_in_and_fan_out(const Tensor & tensor)', '    calculate_gain(NonlinearityType nonlinearity,double param)', '    calculate_kaiming_std(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    constant_(Tensor tensor,Scalar)', '    dirac_(Tensor tensor)', '    eye_(Tensor matrix)', '    Fan(Tensor & tensor)', '    kaiming_normal_(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    kaiming_uniform_(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    normal_(Tensor tensor,double mean,double std)', '    ones_(Tensor tensor)', '    orthogonal_(Tensor tensor,double gain)', '    sparse_(Tensor tensor,double sparsity,double std)', '    uniform_(Tensor tensor,double low,double high)', '    xavier_normal_(Tensor tensor,double gain)', '    xavier_uniform_(Tensor tensor,double gain)', '    zeros_(Tensor tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\multiprocessing\\init.cpp', [], ['    multiprocessing_init(PyObject *_unused,PyObject *noargs)', '    python_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\init.cpp', [], ['    autocast_decrement_nesting(PyObject *_unused,PyObject *arg)', '    autocast_increment_nesting(PyObject *_unused,PyObject *arg)', '    clear_autocast_cache(PyObject *_unused,PyObject *arg)', '    is_anomaly_mode_enabled(PyObject *_unused,PyObject *arg)', '    is_autocast_enabled(PyObject *_unused,PyObject *arg)', '    is_grad_enabled(PyObject *_unused,PyObject *arg)', '    set_anomaly_mode_enabled(PyObject *_unused,PyObject *arg)', '    set_autocast_enabled(PyObject *_unused,PyObject *arg)', '    set_grad_enabled(PyObject *_unused,PyObject *arg)', '    THPAutograd_initExtension(PyObject *_unused,PyObject *unused)', '    python_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\init.cpp', [], ['    accumulateGradVar(PyObject *_self,void *_unused)', '    addClass(PyObject *module,PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    getTupleAttr(PyObject *obj,void *_unused)', '    getValueAttr(PyObject *obj,void *_unused)', '    THPAutograd_initFunctions', '    operator()(PyObject *args)', '    operator()(PyObject *args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\init.cpp', [], ['    check_exact_values(const std::vector & parameters,const std::vector)', '    check_initializer_against_baseline(std::function initializer,std::vector)', '    initializer', '    initializer', '    initializer', '    initializer', '    parameters', '    TEST(InitTest,ProducesPyTorchValues_XavierUniform)', '    TEST(InitTest,ProducesPyTorchValues_XavierNormal)', '    TEST(InitTest,ProducesPyTorchValues_KaimingNormal)', '    TEST(InitTest,ProducesPyTorchValues_KaimingUniform)', '    TEST(InitTest,CanInitializeTensorThatRequiresGrad)', '    TEST(InitTest,CalculateGainWithTanh)', '    TEST(InitTest,CalculateGainWithRelu)', '    TEST(InitTest,CalculateGainWithLeakyRelu)', '    TEST(InitTest,CanInitializeCnnWithOrthogonal)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\onnx\\init.cpp', [], ['    initONNXBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\testing\\init.cpp', [], ['    faulty_agent_init(PyObject *)', '    python_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\init.cpp', [], ['    python_functions', '    dist_autograd_init(PyObject *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init.h', ['    GlobalInitIsCalledGuard', '    InitRegisterer', '    Caffe2InitializeRegistry'], ['    GlobalInit(int *pargc,char ***pargv)', '    GlobalInit', '    GlobalInitAlreadyRun', '    unsafeRunCaffe2InitFunction(const char *name,int *pargc,char ***pargv)', '    Registry', '    GlobalInitIsCalledGuard', '    InitRegisterer(internal::Caffe2InitializeRegistry::InitFunction function,bool run_early,const char *description,const char *name)', '    Caffe2InitializeRegistry', '    Register(InitFunction function,bool run_early,const char *description,const char *name)', '    RunNamedFunction(const char *name,int *pargc,char ***pargv)', '    RunRegisteredEarlyInitFunctions(int *pargc,char ***pargv)', '    RunRegisteredInitFunctions(int *pargc,char ***pargv)', '    RunRegisteredInitFunctionsInternal(vector,const char *,int *pargc,char ***pargv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\python\\init.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\init.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\multiprocessing\\init.h', [], ['    python_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\init.h', [], ['    initJITBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\onnx\\init.h', [], ['    initONNXBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\init.h', [], ['    initThroughputBenchmarkBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\init_baseline.h', [], ['    tensor(,,,,,,)', '    tensor(,,,,,,,,,,,,,,)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init_denormals.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init_intrinsics_check.cc', ['    C10FlagParser_caffe2_quit_on_unsupported_cpu_feature'], ['    WarnIfFeatureUnused(const bool cpu_has_feature,const string & feature)', '    Caffe2CheckIntrinsicsFeatures(int *,char ***)', '    QuitIfFeatureUnsupported(const bool cpu_has_feature,const string & feature)', '    C10FlagParser_caffe2_quit_on_unsupported_cpu_feature(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init_omp.cc', ['    C10FlagParser_caffe2_mkl_num_threads', '    C10FlagParser_caffe2_omp_num_threads'], ['    C10FlagParser_caffe2_mkl_num_threads(const std::string & content)', '    C10FlagParser_caffe2_omp_num_threads(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\init_qnnpack.cc', [], ['    initQNNPACK']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\init_qnnpack.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\init_qnnpack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\init_test.cc', [], ['    LateRegisterEarlyInitFunction', '    LateRegisterFailInitFunction', '    LateRegisterInitFunction', '    TEST(InitTest,TestInitFunctionHasRun)', '    TEST(InitTest,CanRerunGlobalInit)', '    TEST(InitTest,FailLateRegisterInitFunction)', '    TestFailInitFunction(int *,char ***)', '    TestInitFunction(int *,char ***)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\InitialTensorOptions.h', [], ['    initialTensorOptions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_autodiff_subgraphs.cpp', [], ['    canRunWithAutograd(Node *node)', '    InlineAutodiffSubgraphs(Block *block,size_t threshold)', '    InlineAutodiffSubgraphs(std::shared_ptr & graph,size_t threshold)', '    scanNode(Node *node,size_t threshold)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_autodiff_subgraphs.h', [], ['    canRunWithAutograd(Node *node)', '    InlineAutodiffSubgraphs(std::shared_ptr & graph,size_t threshold)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\inline_container.cc', [], ['    basename(const std::string & name)', '    getPadding(size_t cursor,size_t filename_size,size_t size,std::string & padding_buf)', '    read_le_16(uint8_t *buf)', '    istream_read_func(void *pOpaque,mz_uint64 file_ofs,void *pBuf,size_t n)', '    ostream_write_func(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    ~PyTorchStreamReader', '    ~PyTorchStreamWriter', '    getAllRecords', '    getRecord(const std::string & name)', '    getRecordID(const std::string & name)', '    getRecordOffset(const std::string & name)', '    hasRecord(const std::string & name)', '    init', '    PyTorchStreamReader(const std::string & file_name)', '    PyTorchStreamReader(std::istream *in)', '    PyTorchStreamReader(std::unique_ptr in)', '    PyTorchStreamWriter(std::string file_name)', '    PyTorchStreamWriter(const std::function & writer_func)', '    read(uint64_t pos,char *buf,size_t n)', '    setup(const string & file_name)', '    valid(const char *what,const char *info)', '    valid(const char *what,const char *info)', '    writeEndOfFile', '    writeRecord(const std::string & name,const void *data,size_t size,bool compress)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\inline_container.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\inline_container_test.cc', [], ['    TEST(PyTorchStreamWriterAndReader,SaveAndLoad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_fork_wait.cpp', [], ['    InlineForkWait(const std::shared_ptr & graph)', '    InlineForkWait(Block *b,std::unordered_map & future_remap)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_fork_wait.h', [], ['    InlineForkWait(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_forked_closures.cpp', [], ['    inlineForkedClosure(Node *fork_closure)', '    inlineForkedClosures(Block *block)', '    inlineForkedClosures(std::shared_ptr & to_clean)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inline_forked_closures.h', [], ['    inlineForkedClosures(std::shared_ptr & to_clean)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\inline_loop_condition.cpp', [], ['    InlineBlockBeforeNode(Node *before_node,Block *block)', '    inlineLoopCondition(Node *n)', '    inlineLoopCondition(Block *block)', '    InlineLoopCondition(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\inline_loop_condition.h', [], ['    InlineBlockBeforeNode(Node *before_node,Block *block)', '    InlineLoopCondition(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\InlineDeviceGuard.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\core\\impl\\InlineDeviceGuard_test.cpp', [], ['    dev(DeviceIndex index)', '    i', '    i', '    TEST(InlineDeviceGuard,Constructor)', '    TEST(InlineDeviceGuard,ConstructorError)', '    TEST(InlineDeviceGuard,SetDevice)', '    TEST(InlineDeviceGuard,ResetDevice)', '    TEST(InlineDeviceGuard,SetIndex)', '    TEST(InlineOptionalDeviceGuard,Constructor)', '    TEST(InlineOptionalDeviceGuard,NullaryConstructor)', '    TEST(InlineOptionalDeviceGuard,SetDevice)', '    TEST(InlineOptionalDeviceGuard,SetIndex)', '    test_body', '    test_body', '    test_body']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\InlineEvent.h', [], ['    block(const Stream & stream)', '    device_index', '    device_type', '    flag', '    InlineEvent(const InlineEvent &)', '    InlineEvent', '    operator=(const InlineEvent &)', '    operator=(InlineEvent)', '    query', '    record(const Stream & stream)', '    recordOnce(const Stream & stream)', '    swap(InlineEvent)', '    was_marked_for_recording', '    ~InlineEvent', '    device_type_', '    flag_', '    InlineEvent', '    InlineEvent(const DeviceType _device_type,const EventFlag _flag)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inliner.cpp', [], ['    Inline(Graph & graph)', '    inlineCalls(Block *block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inliner.h', [], ['    Inline(Graph & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\InlineStreamGuard.h', ['    InlineOptionalStreamGuard', '    InlineStreamGuard'], ['    current_stream', '    InlineOptionalStreamGuard', '    InlineOptionalStreamGuard(optional stream_opt)', '    InlineOptionalStreamGuard(Args,...)', '    InlineOptionalStreamGuard', '    operator=', '    original_stream', '    reset', '    reset_stream(Stream stream)', '    current_device', '    current_stream', '    InlineStreamGuard(Stream stream)', '    InlineStreamGuard(Stream stream,const DeviceGuardImplInterface *impl)', '    InlineStreamGuard', '    InlineStreamGuard', '    InlineStreamGuard', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_device', '    reset_stream(Stream stream)', '    ~InlineStreamGuard', '    has_value', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\core\\impl\\InlineStreamGuard_test.cpp', [], ['    dev(DeviceIndex index)', '    stream(DeviceIndex index,StreamId sid)', '    TEST(InlineStreamGuard,Constructor)', '    TEST(InlineStreamGuard,ResetStreamSameSameDevice)', '    TEST(InlineStreamGuard,ResetStreamDifferentSameDevice)', '    TEST(InlineStreamGuard,ResetStreamDifferentDevice)', '    TEST(InlineOptionalStreamGuard,Constructor)', '    TEST(InlineOptionalStreamGuard,ResetStreamSameDevice)', '    TEST(InlineOptionalStreamGuard,ResetStreamDifferentDevice)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inplace_check.cpp', [], ['    CheckInplace(Block *block)', '    CheckInplace(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\inplace_check.h', [], ['    CheckInplace(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\serialize\\input-archive.cpp', ['    OurAdapter', '    OurAdapter'], ['    OurAdapter(const char *data,size_t size)', '    OurAdapter(const std::function & read_func,const std::function & size_func)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    size', '    InputArchive', '    keys', '    load_from(const std::string & filename,c10::optional device)', '    load_from(std::istream & stream,c10::optional device)', '    load_from(const char *data,size_t size,c10::optional device)', '    load_from(const std::function & read_func,const std::function & size_func,c10::optional device)', '    read(const std::string & key,c10::IValue & ivalue)', '    read(const std::string & key,Tensor & tensor,bool is_buffer)', '    read(const std::string & key,InputArchive & archive)', '    try_read(const std::string & key,c10::IValue & ivalue)', '    try_read(const std::string & key,Tensor & tensor,bool is_buffer)', '    try_read(const std::string & key,InputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\serialize\\input-archive.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\input_buffer.cpp', [], ['    accumulate(std::vector & buffer,const size_t pos,Variable)', '    event', '    event', '    guard', '    stream_guard', '    variables(InputBuffer)', '    add(size_t pos,Variable,const c10::optional & opt_producer_stream,const c10::optional & opt_consumer_stream)', '    device']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\input_buffer.h', [], ['    variables(InputBuffer)', '    add(size_t pos,Variable,const c10::optional & opt_producer_stream,const c10::optional & opt_consumer_stream)', '    device', '    InputBuffer(size_t size)', '    InputBuffer', '    InputBuffer', '    operator=', '    operator[](size_t pos)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\input_metadata.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\insert_guards.cpp', [], ['    InsertGuards(std::shared_ptr graph)', '    GuardInserter(std::shared_ptr graph)', '    insertGuards(Block *b)', '    removeProfilingNodes(Block *b)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\insert_guards.h', [], ['    InsertGuards(std::shared_ptr graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\inspect_gpu.cc', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\instance_norm_gradient_op.cc', ['    GetInstanceNormGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInstanceNormGradient', '    ComputeInternalGradientsNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,T *ds,T *db)', '    GammaBetaBackward(const int64_t N,const int64_t C,const T *ds,const T *db,const T *mean,const T *rstd,T *dgamma,T *dbeta)', '    InstanceNormBackwardNCHW(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *ds,T *db)', '    InstanceNormBackwardNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,const T *ds,const T *db,const T *mean,const T *rstd,const T *gamma,T *dX,T *c1,T *c2,T *c3)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InstanceNormGradient', '    GetGradientDefs', '    ComputeMoments(const int64_t N,const int64_t C,const int64_t HxW,const float *X,float *mean,float *rstd)', '    RunOnDeviceWithOrderNHWC(const int64_t N,const int64_t C,const int64_t HxW,const float *dY,const float *X,const float *mean,const float *rstd,const float *gamma,float *dX,float *dgamma,float *dbeta)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\instance_norm_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInstanceNorm', '    ComputeFusedParams(const int64_t N,const int64_t C,const T *mean,const T *rstd,const T *gamma,const T *beta,T *scale,T *bias)', '    InstanceNormForwardNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *X,const T *scale,const T *bias,T *Y)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InstanceNorm', '    RunOnDeviceWithOrderNCHW(const int64_t N,const int64_t C,const int64_t HxW,const float *X,const float *gamma,const float *beta,float *Y,float *mean,float *rstd)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\instance_norm_op.h', ['    final', '    final'], ['    ComputeMoments(int64_t N,int64_t C,int64_t HxW,const T *X,T *mean,T *rstd)', '    GetSingleArgument', '    InstanceNormGradientOp(Args,...)', '    InstanceNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mean,T *rstd)', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *dgamma,T *dbeta)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mean,T *rstd)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *dgamma,T *dbeta)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\instancenorm.cpp', [], ['    InstanceNormOptions(int64_t num_features)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\instancenorm.cpp', [], ['    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    pretty_print(std::ostream & stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\instancenorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\instancenorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\instancenorm.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\instruction.cpp', [], ['    supported_ops_in_mobile', '    isOpSupportedInMobile(OpCode op)', '    operator<<(std::ostream & out,Instruction inst)', '    operator<<(std::ostream & out,OpCode op)', '    OpInfo(OpCode op)', '    parseOpCode(const char *str)', '    toString(OpCode op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\instruction.h', [], ['    isOpSupportedInMobile(OpCode op)', '    Instruction(OpCode op,int32_t X,uint16_t N)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_add_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Add', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AddRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Sum', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8SumRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Add', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AddRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Sum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SumRelu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_add_op.cc', ['    final'], ['    IDEEPInt8SumReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8SumReluOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_add_op.h', ['    final'], ['    GetSingleArgument', '    Int8AddOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8AddOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_average_pool_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AveragePool', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AveragePoolRelu', '    AveragePoolDocGenerator(const char *dim,bool relu_fused)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AveragePool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AveragePoolRelu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_average_pool_op.h', ['    final'], ['    Int8AveragePoolOp(Args,...)', '    qnnpackGlobalOperator_', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8AveragePoolOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_channel_shuffle_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ChannelShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ChannelShuffle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_channel_shuffle_op.h', ['    final'], ['    Int8ChannelShuffleOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ChannelShuffleOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_concat_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Concat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Concat']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_concat_op.h', ['    final'], ['    GetSingleArgument', '    Int8ConcatOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_conv_op.cc', ['    final', '    final', '    final', '    IDEEPInt8ConvOp'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvSumRelu', '    IDEEPInt8ConvReluOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8ConvSumOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8ConvSumReluOp(const OperatorDef & operator_def,Workspace *ws)', '    ~IDEEPInt8ConvReluOp', '    ~IDEEPInt8ConvSumOp', '    ~IDEEPInt8ConvSumReluOp', '    IDEEPInt8ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPInt8ConvOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_conv_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvRelu', '    ConvDocGenerator(const char *dim,bool relu_fused)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_conv_op.h', ['    final'], ['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    Int8ConvOp(Args,...)', '    lastBatchSize_', '    lastInputHeight_', '    lastInputPointer_', '    lastInputWidth_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ConvOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_conv_op_relu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ConvRelu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_conv_transpose_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ConvTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvTranspose']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_conv_transpose_op.h', ['    final'], ['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    Int8ConvTransposeOp(Args,...)', '    lastBatchSize_', '    lastInputHeight_', '    lastInputPointer_', '    lastInputWidth_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ConvTransposeOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_dequantize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Dequantize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Dequantize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_dequantize_op.cc', ['    final'], ['    IDEEPInt8DequantizeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    Y_fmt_', '    ~IDEEPInt8DequantizeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_dequantize_op.h', ['    final'], ['    Int8Dequantize(const uint8_t *in,float *out,const int64_t N,const float X_scale,const int32_t X_offset)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_fc_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8FC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_fc_op.h', ['    final'], ['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    GetSingleArgument', '    Int8FCOp(const OperatorDef & operator_def,Workspace *ws)', '    lastBatchSize_', '    lastInputPointer_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDevice', '    ~Int8FCOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_flatten_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Flatten', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Flatten']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_flatten_op.h', ['    Int8FlattenOp'], ['    GetSingleArgument', '    Int8FlattenOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_fully_connected_op.cc', ['    final'], ['    axis_', '    axis_w_', '    IDEEPInt8FullyConnectedOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8FullyConnectedOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_given_tensor_fill_op.cc', ['    final', '    final'], ['    IDEEPInt8GivenIntTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8GivenTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    values_', '    values_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_given_tensor_fill_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8GivenIntTensorFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8GivenTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GivenIntTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GivenTensorFill']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_given_tensor_fill_op.h', ['    final', '    final'], ['    dtype', '    ExtractValues', '    Fill(Int8TensorCPU *output)', '    Int8GivenTensorFillOp(Args,...)', '    RunOnDevice', '    ExtractValues', '    Fill(Int8TensorCPU *output)', '    Int8GivenIntTensorFillOp(Args,...)', '    RunOnDevice', '    numel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_leaky_relu_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8LeakyRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8LeakyRelu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_leaky_relu_op.h', ['    final'], ['    GetSingleArgument', '    Int8LeakyReluOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8LeakyReluOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_max_pool_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8MaxPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8MaxPoolRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8MaxPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8MaxPoolRelu', '    MaxPoolDocGenerator(const char *dim,bool relu_fused)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_max_pool_op.h', ['    final'], ['    Int8MaxPoolOp(Args,...)', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8MaxPoolOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_pool_op.cc', ['    final'], ['    IDEEPInt8PoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPInt8PoolOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_quantize_op.cc', ['    final'], ['    IDEEPInt8QuantizeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    Y_fmt_', '    ~IDEEPInt8QuantizeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_quantize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Quantize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Quantize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_quantize_op.h', ['    final'], ['    Int8Quantize(const float *in,uint8_t *out,const int64_t N,const float Y_scale,const int32_t Y_offset)', '    GetSingleArgument', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\quantization\\int8_relu_op.cc', ['    final'], ['    IDEEPInt8ReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8ReluOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_relu_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Relu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Relu', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_relu_op.h', ['    final'], ['    GetSingleArgument', '    Int8ReluOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8ReluOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_reshape_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Reshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Reshape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_reshape_op.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    Int8ReshapeOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_resize_nearest_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ResizeNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ResizeNearest']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_resize_nearest_op.h', ['    final'], ['    GetRepeatedArgument', '    GetSingleArgument', '    Int8ResizeNearestOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_roi_align_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8RoIAlign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8RoIAlign']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_roi_align_op.h', ['    final'], ['    pre_calc_for_bilinear_interpolate(const int height,const int width,const int pooled_height,const int pooled_width,const int iy_upper,const int ix_upper,float roi_start_h,float roi_start_w,float bin_size_h,float bin_size_w,int roi_bin_grid_h,int roi_bin_grid_w,std::vector & pre_calc)', '    ROIAlignForward(const int nthreads,const uint8_t *bottom_data,const float & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,const float *bottom_rois,int roi_cols,uint8_t *top_data,const float x_scale,const float y_scale,const int32_t x_offset,const int32_t y_offset,StorageOrder order,bool continuous_coordinate)', '    ROIAlignForward(output_size,X,spatial_scale_,X,X,X,pooled_height_,pooled_width_,sampling_ratio_,R,R,Y,X,Y_scale,X,Y_offset,order_,aligned_)', '    GetSingleArgument', '    Int8RoIAlignOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_roi_align_op_test.cc', [], ['    TEST(Int8RoIAlign,RoIAlign)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\int8_serialization.cc', ['    Int8TensorCPUDeserializer', '    Int8TensorCPUSerializer'], ['    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_sigmoid_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Sigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Sigmoid']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_sigmoid_op.h', ['    final'], ['    GetSingleArgument', '    Int8SigmoidOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8SigmoidOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_simd.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_slice_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Slice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Slice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_slice_op.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    Int8SliceOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_softmax_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Softmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Softmax']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_softmax_op.h', ['    final'], ['    GetSingleArgument', '    Int8SoftmaxOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8SoftmaxOp', '    GetThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_test.cc', [], ['    biassetq(int8::Int8TensorCPU *dst,const std::vector & vs)', '    TEST(Int8,ReLU)', '    setq(int8::Int8TensorCPU *dst,const std::vector & vs)', '    TEST(Int8,DISABLED_LeakyReLU)', '    TEST(Int8,Softmax)', '    TEST(Int8,Sigmoid)', '    TEST(Int8,MaxPool)', '    TEST(Int8,AveragePool)', '    TEST(Int8,ResizeNearest)', '    TEST(Int8,ChannelShuffle)', '    TEST(Int8,Concat)', '    TEST(Int8,Add)', '    TEST(Int8,SumRelu)', '    TEST(Int8,Conv)', '    TEST(Int8,Grouped1x1Conv)', '    TEST(Int8,Conv2)', '    TEST(Int8,DepthwiseConv)', '    TEST(Int8,DepthwiseConv3x3)', '    TEST(Int8,DepthwiseConv5x5)', '    TEST(Int8,ConvTranspose)', '    TEST(Int8,FC)', '    TEST(Int8,GivenTensorFill)', '    TEST(Int8,GivenIntTensorFill)', '    TEST(Int8,QuantDeQuant)', '    TEST(Int8,Reshape)', '    TEST(Int8,Flatten)', '    TEST(Int8,Slice)', '    TEST(Int8,DISABLED_Transpose)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_test_utils.h', [], ['    add_input(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    addErrorTolerance(float scale)', '    biasdq(const int8::Int8TensorCPU & XQ)', '    biasq(const std::vector & dims,double scale)', '    dq(const int8::Int8TensorCPU & XQ)', '    int8Copy(int8::Int8TensorCPU *dst,const int8::Int8TensorCPU & src)', '    q(const std::vector & dims)', '    randomInt(int a,int b)', '    CreateBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_transpose_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Transpose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Transpose']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_transpose_op.h', ['    final'], ['    GetSingleArgument', '    Int8TransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantized\\int8_utils.h', ['    Activation'], ['    initQNNPACK', '    activationLimits(float scale,int32_t zero_point,Activation Ac)', '    CalculateInputRadius(int input_integer_bits,int input_left_shift)', '    MultiplyByQuantizedMultiplierGreaterThanOne(int32_t x,int32_t quantized_multiplier,int left_shift)', '    MultiplyByQuantizedMultiplierSmallerThanOne(int32_t x,int32_t quantized_multiplier,int right_shift)', '    QuantizeMultiplierGreaterThanOne(double double_multiplier,int32_t *quantized_multiplier,int *left_shift)', '    QuantizeMultiplierSmallerThanOne(double double_multiplier,int32_t *quantized_multiplier,int *right_shift)', '    QuantizeUint8(float scale,int32_t zero_point,float value)', '    Round(const T x)', '    frexp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\integral_image_op.cc', ['    GetIntegralImageGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIntegralImage', '    CAFFE_ANONYMOUS_VARIABLE_CPUIntegralImageGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntegralImage', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntegralImageGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\integral_image_op.h', ['    final', '    final'], ['    IntegralImageGradientOp(Args,...)', '    IntegralImageOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\integration.cpp', ['    CartPole'], ['    finishEpisode', '    forward', '    forward', '    forward', '    selectAction', '    TEST_F(IntegrationTest,CartPole)', '    TEST_F(IntegrationTest,MNIST_CUDA)', '    TEST_F(IntegrationTest,MNISTBatchNorm_CUDA)', '    test_mnist(size_t batch_size,size_t number_of_epochs,bool with_cuda,M,F,O)', '    CartPole', '    getReward', '    getState', '    isDone', '    reset', '    step(int action)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Integration.cpp', [], ['    do_trapz(const Tensor & y,const Tensor & dx,int64_t dim)', '    do_trapz(const Tensor & y,double dx,int64_t dim)', '    trapz(const Tensor & y,const Tensor & x,int64_t dim)', '    trapz(const Tensor & y,double dx,int64_t dim)', '    zeros_like_except(const Tensor & y,int64_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\interface.cpp', [], ['    canFuseOnCPU', '    canFuseOnGPU', '    debugGetFusedKernelCode(Graph & graph,at::ArrayRef inputs)', '    debugLaunchGraph(Graph & graph,at::ArrayRef inputs)', '    nCompiledKernels', '    overrideCanFuseOnCPU(bool value)', '    overrideCanFuseOnGPU(bool value)', '    registerFusion(const Node *fusion_group)', '    runFusion(const int64_t key,Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\interface.h', [], ['    canFuseOnCPU', '    canFuseOnGPU', '    debugGetFusedKernelCode(Graph & graph,at::ArrayRef inputs)', '    debugLaunchGraph(Graph & graph,at::ArrayRef inputs)', '    nCompiledKernels', '    overrideCanFuseOnCPU(bool value)', '    overrideCanFuseOnGPU(bool value)', '    registerFusion(const Node *fusion_group)', '    runFusion(const int64_t key,Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\interned_strings.cpp', [], ['    globalStrings', '    domain_prefix', '    domainString', '    fromDomainAndUnqualString(const std::string & d,const std::string & s)', '    fromQualString(const std::string & s)', '    ns', '    toDisplayString', '    toQualString', '    toUnqualString', '    _symbol(const std::string & s)', '    customString(Symbol sym)', '    ns(Symbol sym)', '    string(Symbol sym)', '    symbol(const std::string & s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\interned_strings.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\interned_strings_class.h', [], ['    _symbol(const std::string & s)', '    customString(Symbol sym)', '    InternedStrings', '    ns(Symbol sym)', '    symbol(const std::string & s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\interpreter.cpp', [], ['    InterpreterState(std::shared_ptr code)', '    reg(size_t reg)', '    run(Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\interpreter.cpp', [], ['    build_bailout_graph', '    Code(const std::shared_ptr & graph,std::string function_name,size_t remaining_bailout_depth)', '    constant_table', '    createDropIfUnused', '    dump(std::ostream & out,const Stack & stack)', '    enterFrame(const Code & code,size_t base_pointer)', '    formatStackTrace(std::ostream & out)', '    getFuture', '    grad_executors', '    handleError(const ExceptionMessage & msg,bool is_jit_exception)', '    instructions', '    instructions_source', '    InterpreterState(const Code & code)', '    InterpreterState(c10::intrusive_ptr pImpl_)', '    leaveFrame', '    location', '    num_bailouts', '    num_inputs', '    num_outputs', '    operator()', '    operator<<(std::ostream & out,const Code & code)', '    register_size', '    request_bailout(size_t index)', '    run(Stack & stack)', '    runAsync(Stack & stack)', '    runBuiltinFunction(Stack & stack,Function *fn,ActiveFrame *af)', '    runGraphFunction(Stack & stack,Function *fn,ActiveFrame *af)', '    runImpl(Stack & stack)', '    dropUnused(Block *b)', '    insertLastUses(Graph & g)', '    tensorTypeInCurrentExecutionContext(const at::Tensor & t)', '    run(Stack & stack)', '    runAsync(Stack & stack)', '    type_table', '    ActiveFrame(const Frame & frame)', '    Callback(c10::intrusive_ptr state,Stack stack)', '    operator()', '    addToDropIfNotExists(Node *drop,Value *v)', '    findOrCreateDropInstructionForNode(Node *n)', '    findOwnerInBlock(Node *n,Block *block)', '    InsertLastUses(Graph & g)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanUse(Node *n,size_t i)', '    CanEmitInline(const std::shared_ptr & graph)', '    canInline(Value *v)', '    previousNonConstant(Node *n)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanValue(Node *block_point,Value *v)', '    allocRegs(at::ArrayRef vs)', '    CodeImpl(const std::shared_ptr & graph,std::string function_name,size_t remaining_bailout_depth)', '    constant_table', '    createBailoutBlock(size_t jf_index)', '    dump(std::ostream & out,size_t i)', '    dump(std::ostream & out)', '    emitBailOut(Node *node)', '    emitCall(Function *func,at::ArrayRef inputs)', '    emitCodeForBlock(Block *block)', '    emitConstant(Node *node)', '    emitContainerConstruct(OpCode op,Node *node)', '    emitCreateObject(Node *node)', '    emitDrop(at::ArrayRef to_drop)', '    emitFork(Node *node)', '    emitGetAttr(Node *node)', '    emitGuard(Node *node)', '    emitIf(Node *node)', '    emitInterfaceCall(std::string method_name_str,c10::ArrayRef inputs)', '    emitIsinstance(Node *node)', '    emitListUnpack(Node *node)', '    emitLoadInputs(at::ArrayRef inputs)', '    emitLoop(Node *loop)', '    emitNode(Node *node)', '    emitNodeAtBlockLevel(Node *node)', '    emitOperator(Node *node)', '    emitSetAttr(Node *node)', '    emitStoreOutputs(Node *node)', '    emitTupleConstruct(Node *node)', '    emitTupleSlice(Node *node)', '    emitType(TypePtr t)', '    emitUse(Value *input,bool drop)', '    emitWait(Node *node)', '    emitWarn(Node *node)', '    grad_executors', '    insertBailoutBlocks', '    insertConstant(IValue value)', '    insertInstruction(OpCode op,int64_t X,uint64_t N)', '    instructions', '    instructions_source', '    registerFor(Value *v)', '    request_bailout(size_t index)', '    truncateInstructions(size_t size)', '    PreprocessGraph(Graph & g)', '    WithCurrentNode(Node **loc,Node *new_value)', '    ~WithCurrentNode']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\interpreter.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\interpreter.h', [], ['    InterpreterState(std::shared_ptr code)', '    reg(size_t reg)', '    run(Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\intra_inter_benchmark.cc', ['    C10FlagParser_benchmark_iter', '    C10FlagParser_extra_stats', '    C10FlagParser_inter_op_threads', '    C10FlagParser_intra_op_threads', '    C10FlagParser_iter_pow', '    C10FlagParser_sub_iter', '    C10FlagParser_task_type', '    C10FlagParser_tensor_dim', '    C10FlagParser_warmup_iter_pow'], ['    _launch_tasks_tree(int level,int end_level,at::Tensor & left,at::Tensor & right)', '    counter', '    launch_tasks_and_wait(at::Tensor & left,at::Tensor & right,int iter_pow)', '    main(int argc,char **argv)', '    print_extra_stats', '    print_runtime_stats(const std::vector & runtimes)', '    reset_extra_stats', '    wait', '    C10FlagParser_benchmark_iter(const std::string & content)', '    C10FlagParser_extra_stats(const std::string & content)', '    C10FlagParser_inter_op_threads(const std::string & content)', '    C10FlagParser_intra_op_threads(const std::string & content)', '    C10FlagParser_iter_pow(const std::string & content)', '    C10FlagParser_sub_iter(const std::string & content)', '    C10FlagParser_task_type(const std::string & content)', '    C10FlagParser_tensor_dim(const std::string & content)', '    C10FlagParser_warmup_iter_pow(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\intrinsics.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\Intrinsics.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\intrusive_ptr.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\intrusive_ptr.h', ['    intrusive_ptr_target'], ['    assign_ptr_(TTarget *rhs)', '    incref(intrusive_ptr_target *self)', '    incref(intrusive_ptr_target *self)', '    singleton', '    intrusive_ptr_target', '    intrusive_ptr_target(intrusive_ptr_target)', '    intrusive_ptr_target(const intrusive_ptr_target & other)', '    operator=(intrusive_ptr_target)', '    operator=(const intrusive_ptr_target & other)', '    release_resources', '    ~intrusive_ptr_target']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\benchmark\\intrusive_ptr_benchmark.cpp', ['    Bar', '    Foo'], ['    BM_IntrusivePtrArray(benchmark::State & state)', '    BM_IntrusivePtrCtorDtor(benchmark::State & state)', '    BM_SharedPtrArray(benchmark::State & state)', '    BM_SharedPtrCtorDtor(benchmark::State & state)', '    Bar(int param_)', '    Foo(int param_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\intrusive_ptr_test.cpp', ['    DestructableMock', '    final', '    final', '    final', '    SomeClass0Parameters', '    SomeClass1Parameter', '    SomeClass2Parameters'], ['    make_weak_intrusive(Args,...)', '    make_weak_only(Args,...)', '    TEST(MakeIntrusiveTest,ClassWith0Parameters)', '    TEST(MakeIntrusiveTest,ClassWith1Parameter)', '    TEST(MakeIntrusiveTest,ClassWith2Parameters)', '    TEST(MakeIntrusiveTest,TypeIsAutoDeductible)', '    TEST(MakeIntrusiveTest,CanAssignToBaseClassPtr)', '    TEST(IntrusivePtrTargetTest,whenAllocatedOnStack_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCallingGet_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCallingConstGet_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCallingGet_thenReturnsNullptr)', '    TEST(IntrusivePtrTest,givenValidPtr_whenDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenConstDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenArrowDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenConstArrowDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigning_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToSelf_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToSelf_thenStaysValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToSelf_thenStaysInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigning_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningFromInvalidPtr_thenNewInstanceIsInvalid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningInvalidPtrToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenMoveAssigningToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigning_thenOldInstanceValid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToSelf_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToSelf_thenStaysValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToSelf_thenStaysInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigning_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssigningInvalidPtrToBaseClass_thenNewInstanceIsInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenCopyAssigningToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClassFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenMoveConstructingToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenOldInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClassFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenCopyConstructingToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,SwapFunction)', '    TEST(IntrusivePtrTest,SwapMethod)', '    TEST(IntrusivePtrTest,SwapFunctionFromInvalid)', '    TEST(IntrusivePtrTest,SwapMethodFromInvalid)', '    TEST(IntrusivePtrTest,SwapFunctionWithInvalid)', '    TEST(IntrusivePtrTest,SwapMethodWithInvalid)', '    TEST(IntrusivePtrTest,SwapFunctionInvalidWithInvalid)', '    TEST(IntrusivePtrTest,SwapMethodInvalidWithInvalid)', '    TEST(IntrusivePtrTest,CanBePutInContainer)', '    TEST(IntrusivePtrTest,CanBePutInSet)', '    TEST(IntrusivePtrTest,CanBePutInUnorderedSet)', '    TEST(IntrusivePtrTest,CanBePutInMap)', '    TEST(IntrusivePtrTest,CanBePutInUnorderedMap)', '    TEST(IntrusivePtrTest,Equality_AfterCopyConstructor)', '    TEST(IntrusivePtrTest,Equality_AfterCopyAssignment)', '    TEST(IntrusivePtrTest,Equality_Nullptr)', '    TEST(IntrusivePtrTest,Nonequality)', '    TEST(IntrusivePtrTest,Nonequality_NullptrLeft)', '    TEST(IntrusivePtrTest,Nonequality_NullptrRight)', '    TEST(IntrusivePtrTest,HashIsDifferent)', '    TEST(IntrusivePtrTest,HashIsDifferent_ValidAndInvalid)', '    TEST(IntrusivePtrTest,HashIsSame_AfterCopyConstructor)', '    TEST(IntrusivePtrTest,HashIsSame_AfterCopyAssignment)', '    TEST(IntrusivePtrTest,HashIsSame_BothNullptr)', '    TEST(IntrusivePtrTest,OneIsLess)', '    TEST(IntrusivePtrTest,NullptrIsLess1)', '    TEST(IntrusivePtrTest,NullptrIsLess2)', '    TEST(IntrusivePtrTest,NullptrIsNotLessThanNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenIsInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenHoldsNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenDestructed_thenDestructsObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructed_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructedToBaseClass_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssigned_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssignedToBaseClass_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenMoveAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithBaseClassCopy_whenMoveAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenMoveAssignedToBaseClass_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssigned_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssignedToBaseClass_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedToBaseClassAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedToBaseClassAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClassAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClassAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssigned_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClass_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCopyAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithBaseClassCopy_whenCopyAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCopyAssignedToBaseClass_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenDestructs)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCallingReset_thenDestructsAfterCopyDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCallingResetOnCopy_thenDestructsAfterOriginalDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithMoved_whenCallingReset_thenDestructsAfterMovedDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithMoved_whenCallingResetOnMoved_thenDestructsImmediately)', '    TEST(IntrusivePtrTest,AllowsMoveConstructingToConst)', '    TEST(IntrusivePtrTest,AllowsCopyConstructingToConst)', '    TEST(IntrusivePtrTest,AllowsMoveAssigningToConst)', '    TEST(IntrusivePtrTest,AllowsCopyAssigningToConst)', '    TEST(IntrusivePtrTest,givenNewPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenNewPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenEmptyPtr_thenHasUseCount0)', '    TEST(IntrusivePtrTest,givenEmptyPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenResetPtr_thenHasUseCount0)', '    TEST(IntrusivePtrTest,givenResetPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenOldHasUseCount0)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenOldHasUseCount0)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenOldHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenDestructingCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenDestructingCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenReassigningCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenReassigningCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_thenHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenDestructingCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenDestructingCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenReassigningCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenReassigningCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenPtr_whenReleasedAndReclaimed_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenPtr_whenReleasedAndReclaimed_thenIsDestructedAtEnd)', '    TEST(IntrusivePtrTest,givenPtr_whenNonOwningReclaimed_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenPtr_whenNonOwningReclaimed_thenIsDestructedAtEnd)', '    singleton', '    singleton', '    DestructableMock(bool *resourcesReleased,bool *wasDestructed)', '    release_resources', '    ~DestructableMock', '    ChildDestructableMock(bool *resourcesReleased,bool *wasDestructed)', '    IntrusiveAndWeak(intrusive_ptr ptr_)', '    SomeBaseClass(int v_)', '    SomeChildClass(int v)', '    SomeClass1Parameter(int param_)', '    SomeClass2Parameters(int param1_,int param2_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\invalid_arguments.cpp', [], ['    _argcountMatch(const Option & option,const std::vector & arguments,const std::unordered_map & kwargs)', '    _argDesc(const std::vector & arguments,const std::unordered_map & kwargs)', '    _buildType(std::string type_name,bool is_nullable)', '    _formattedArgDesc(const Option & option,const std::vector & arguments,const std::unordered_map & kwargs)', '    _parseOption(const std::string & _option_str,const std::unordered_map & kwargs)', '    _splitString(const std::string & s,const std::string & delim)', '    _tryMatchKwargs(const Option & option,const std::unordered_map & kwargs)', '    format_invalid_args(PyObject *given_args,PyObject *given_kwargs,const std::string & function_name,const std::vector & options)', '    py_typename(PyObject *object)', '    Argument(std::string name,std::unique_ptr type)', '    is_matching(PyObject *object)', '    MultiType(std::initializer_list accepted_types)', '    is_matching(PyObject *object)', '    NullableType(std::unique_ptr type)', '    Option(std::vector arguments,bool is_variadic,bool has_out)', '    Option(bool is_variadic,bool has_out)', '    Option(Option)', '    is_matching(PyObject *object)', '    SequenceType(std::unique_ptr type)', '    is_matching(PyObject *object)', '    SimpleType(std::string & name)', '    is_matching(PyObject *object)', '    TupleType(std::vector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\invalid_arguments.h', [], ['    format_invalid_args(PyObject *given_args,PyObject *given_kwargs,const std::string & function_name,const std::vector & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\ios_caffe.cc', [], ['    GenerateStylizedImage(std::vector & originalImage,const std::string & init_net_str,const std::string & predict_net_str,int height,int width,std::vector & dataOut)', '    MakeCaffe2Predictor(const std::string & init_net_str,const std::string & predict_net_str,bool disableMultithreadProcessing,bool allowMetalOperators,std::string & errorMessage)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\ios_caffe.h', [], ['    __attribute__(visibility)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\ios_caffe_defines.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\ios_caffe_predictor.cc', [], ['    Caffe2IOSPredictor(const caffe2::NetDef & init_net,const caffe2::NetDef & predict_net,bool disableMultithreadProcessing,bool usingMetalOperators)', '    NewCaffe2IOSPredictor(const caffe2::NetDef & init_net,const caffe2::NetDef & predict_net,bool disableMultithreadProcessing,bool allowMetalOperators)', '    run(const Tensor & inData,Tensor & outData,std::string & errorMessage)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\ios_caffe_predictor.h', [], ['    run(const Tensor & inData,Tensor & outData,std::string & errorMessage)', '    visibility']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\ir.cpp', [], ['    checkSameDevice(const Node *node)', '    indent(std::ostream & out,size_t level)', '    printAttribute(std::ostream & out,const at::Tensor & tensor)', '    printAttribute(std::ostream & out,const IValue & ival)', '    printTypeList(std::ostream & out,const std::vector & items)', '    printValueRef(std::ostream & out,const Value *n)', '    printValueRefs(std::ostream & out,const at::ArrayRef nodes)', '    allocNewInstance(Graph *g)', '    cloneFrom(Node *other_)', '    createTupleUnpack(Value *v)', '    env', '    fakeRange', '    findArgument(const FunctionSchema & the_schema,Symbol name)', '    inlineCallTo(Node *to_replace,Function *callee)', '    inputs_set', '    insertGraph(Graph & g,Graph & callee,ArrayRef inputs,std::unordered_map & value_map)', '    insertGraph(Graph & g,Graph & callee,ArrayRef inputs)', '    OperatorSet(std::initializer_list sig_literals)', '    output_set', '    tensor_s', '    LintGraph(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,const at::ArrayRef nodes)', '    operator<<(std::ostream & out,const const_value_list_with_types & l)', '    operator<<(std::ostream & out,const Node & n)', '    operator<<(std::ostream & out,const Graph & g)', '    operator<<(std::ostream & out,const std::vector & nodes)', '    operator<<(std::ostream & out,const at::ArrayRef nodes)', '    type', '    unpackOutputs(const std::vector & outputs)', '    create(NodeKind kind,ArrayRef inputs,size_t num_outputs)', '    create(NodeKind kind,size_t num_outputs)', '    createAutogradZero', '    createClone(Node *n,const std::function & value_map,bool copy_blocks)', '    createDict(const TypePtr & key_type,const TypePtr & value_type,at::ArrayRef keys,at::ArrayRef values)', '    createGetAttr(Value *obj,const std::string & field)', '    createIsInstance(Value *v,at::ArrayRef types)', '    createList(const TypePtr & elem_type,at::ArrayRef values)', '    createListUnpack(Value *v,size_t size)', '    createLoad(const std::string & name,const TypePtr & type)', '    createNone', '    createNumToTensor(Value *value)', '    createObject(const ClassTypePtr & type)', '    createSetAttr(Value *obj,const std::string & field,Value *newValue)', '    createStore(const std::string & name,Value *v)', '    createTuple(at::ArrayRef values,TupleTypePtr tuple_type)', '    createTupleIndex(Value *tup,Value *idx,const TypePtr & output_type)', '    createTupleSlice(Value *tup,int64_t beg,int64_t end)', '    createTupleUnpack(Value *v)', '    createUninitialized(TypePtr typ)', '    createWithSubgraph(Symbol kind)', '    freeBlock(Block *b)', '    freeNode(Node *n)', '    freeValue(Value *v)', '    insert(Symbol opname,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & range)', '    insertConstant(const IValue & val,c10::optional loc,c10::optional scope)', '    insertFunctionCall(Function *callee,const MatchedSchema & matched)', '    insertMethodCall(std::string method_name,const MatchedSchema & matched)', '    insertToList(Value *v,TypePtr type)', '    insertUncheckedCast(Value *v,TypePtr type)', '    toString(bool print_source_locations)', '    ~Graph', '    check_block(const Block *b)', '    check_graph', '    check_node(const Node *n)', '    check_value(const Value *v)', '    LintImpl(const Graph & g)', '    contains(const Value *v)', '    contains(const Node *n)', '    insert(const Value *v)', '    insert(const Node *n)', '    LintScope(std::unique_ptr parent)', '    addBlock', '    addInput(Value *value)', '    addOutput', '    assignTopoPosition', '    blocksFromGraphBlock', '    cloneFrom(Node *s)', '    destroy', '    dropInput(size_t i)', '    dump', '    eraseBlock(size_t i)', '    eraseOutput(size_t i)', '    findCommonAncestorBlockWith(Node *n)', '    findUseForInput(size_t i)', '    get(Symbol name)', '    getOperation', '    getOperator', '    hasSideEffects', '    insertAfter(Node *n)', '    insertBefore(Node *n)', '    insertInput(size_t i,Value *value)', '    insertOutput(size_t i)', '    isAfter(const Node *n)', '    isBefore(const Node *n)', '    isBeforeOrAfter(const Node *n,MoveSide moveSide)', '    isMemberOf(const OperatorSet & os)', '    isNondeterministic', '    matches(const FunctionSchema & schema)', '    matches(const char *signature_literal,at::ArrayRef const_inputs)', '    maybeOperator', '    maybeSchema', '    moveAfter(Node *n)', '    moveBefore(Node *n)', '    mustBeNone', '    namedInput(Symbol name)', '    Node(Graph *graph_,NodeKind kind_)', '    permuteInputs(const std::vector & new_order)', '    permuteOutputs(const std::vector & new_order)', '    removeAllInputs', '    removeFromList', '    removeInput(size_t i)', '    replaceAllUsesWith(Node *n)', '    replaceInput(size_t i,Value *newValue)', '    replaceInputWith(Value *from,Value *to)', '    schema', '    const_value_list_with_types(ArrayRef values,std::string delim_)', '    copy', '    dump', '    lint', '    pop_scope', '    print(std::ostream & out,bool print_source_locations)', '    push_scope(const std::string & scope_name)', '    remapTypes(const std::function & type_map)', '    lint', '    print(std::ostream & out,size_t level,std::vector *groups,bool print_source_locations,bool print_attributes,bool print_scopes,bool print_body)', '    printAttributes(std::ostream & out,bool ignore_subgraph)', '    printAttrValue(std::ostream & out,const Symbol & name)', '    sourceRange', '    Block(Graph *graph_,Node *node_)', '    cloneFrom(Block *src,std::function value_map)', '    destroy', '    reIndexTopology', '    remapTypes(const std::function & type_map)', '    copyMetadata(Value *from)', '    debugNameBase', '    inferTypeFrom(const at::Tensor & output)', '    isValidName(const std::string & name)', '    mustBeNone', '    mustNotBeNone', '    replaceAllUsesAfterNodeWith(const Node *node,Value *newValue)', '    replaceAllUsesWith(Value *newValue)', '    replaceFirstUseWith(Value *newValue)', '    setDebugName(const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir.cpp', [], ['    ChooseDtype(const Dtype & buffer_dtype,const Dtype & index_dtype)', '    ExprHandleVectorToExprVector(const std::vector & v)', '    ExprVectorToExprHandleVector(const std::vector & v)', '    VarHandleVectorToVarVector(const std::vector & v)', '    VarVectorToVarHandleVector(const std::vector & v)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1,Dtype dt2)', '    IntrinsicsDtype(IntrinsicsOp op_type,const std::vector & params)', '    OpArgCount(IntrinsicsOp op_type)', '    Load(const Buffer & buffer,const Expr *index,const Expr *mask)', '    Load(Dtype dtype,const Var *base_handle,const Expr *index,const Expr *mask)', '    Store(const Buffer & buffer,const Expr *index,const Expr *value,const Expr *mask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\ir.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir.h', ['    BaseCallNode', '    Broadcast', '    CallNode', '    CompareSelect', '    IfThenElse', '    Intrinsics', '    Let', '    Load', '    Ramp', '    HalfImm', '    Add', '    And', '    BinaryOpNode', '    BoolImm', '    ByteImm', '    Cast', '    CharImm', '    Div', '    DoubleImm', '    FloatImm', '    IntImm', '    LongImm', '    Lshift', '    Max', '    Min', '    Mod', '    Mul', '    Or', '    Rshift', '    ShortImm', '    Sub', '    Xor'], ['    newBinaryOpOfType(IRNodeType expr_type,const Expr *lhs,const Expr *rhs,bool option)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    ExprHandleVectorToExprVector(const std::vector &)', '    ExprVectorToExprHandleVector(const std::vector &)', '    getImmediateByType(ScalarType immType,T initialVal)', '    getImmediateByType(Dtype dtype,T initialVal)', '    immediateAs(const Expr *e)', '    immediateEquals(const Expr *e,T val)', '    immediateIsNegative(const T *e)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    cast(const ExprHandle & src_value)', '    getPrecedence(IRNodeType ty)', '    VarHandleVectorToVarVector(const std::vector &)', '    VarVectorToVarHandleVector(const std::vector &)', '    make(const ExprHandle & value,int lanes)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,CompareSelectOperation cmp_op)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,const ExprHandle & ret_val1,const ExprHandle & ret_val2,CompareSelectOperation cmp_op)', '    make(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1,Dtype dt2)', '    IntrinsicsDtype(IntrinsicsOp op_type,const std::vector & params)', '    make(IntrinsicsOp op_type,const ExprHandle & v1)', '    make(IntrinsicsOp op_type,const ExprHandle & v1,const ExprHandle & v2)', '    make(IntrinsicsOp op_type,const std::vector & params)', '    make(IntrinsicsOp op_type,Dtype dtype)', '    OpArgCount(IntrinsicsOp op_type)', '    make(const ExprHandle & var,const ExprHandle & value,const ExprHandle & body)', '    make(const Buffer & buffer,const ExprHandle & index,const ExprHandle & mask)', '    make(Dtype dtype,const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & mask)', '    make(const ExprHandle & base,const ExprHandle & stride,int lanes)', '    CastIfNeeded(const Expr *expr,Dtype dst_dtype)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(uint8_t value)', '    make(Dtype dtype,const ExprHandle & src_value)', '    make(int8_t value)', '    make(double value)', '    make(float value)', '    make(int value)', '    make(int64_t value)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,bool propagate_nans)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,bool propagate_nans)', '    make(int16_t value)', '    BaseCallNode(Dtype dtype,CallType call_type,const std::vector & params)', '    call_type', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    nparams', '    param(int index)', '    params', '    Broadcast(const Expr *value,int lanes)', '    lanes', '    value', '    compare_select_op', '    CompareSelect(const Expr *lhs,const Expr *rhs,const Expr *ret_val1,const Expr *ret_val2,CompareSelectOperation cmp_op)', '    lhs', '    ret_val1', '    ret_val2', '    rhs', '    dtype', '    lanes', '    scalar_type', '    condition', '    false_value', '    IfThenElse(const Expr *c,const Expr *t,const Expr *f)', '    true_value', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    Intrinsics(IntrinsicsOp op_type,Dtype dtype)', '    Intrinsics(IntrinsicsOp op_type,const Expr *v1)', '    Intrinsics(IntrinsicsOp op_type,const Expr *v1,const Expr *v2)', '    Intrinsics(IntrinsicsOp op_type,const std::vector & params)', '    isPure', '    op_type', '    body', '    Let(const Expr *var,const Expr *value,const Expr *body)', '    value', '    var', '    base_handle', '    index', '    Load(const Buffer & buffer,const Expr *index,const Expr *mask)', '    Load(Dtype dtype,const Var *base_handle,const Expr *index,const Expr *mask)', '    mask', '    base', '    lanes', '    Ramp(const Expr *base,const Expr *stride,int lanes)', '    stride', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    HalfImm((*) () decltype)', '    isConstant', '    Add(const Expr *lhs,const Expr *rhs)', '    And(const Expr *lhs,const Expr *rhs)', '    BinaryOpNode(const Expr *lhs_v,const Expr *rhs_v,IRNodeType expr_type,ScalarType ret_type)', '    lhs', '    rhs', '    BoolImm((*) () decltype)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    isConstant', '    ByteImm(uint8_t value)', '    isConstant', '    value', '    Cast(Dtype dtype,const Expr *src_value)', '    isConstant', '    src_value', '    CharImm(int8_t value)', '    isConstant', '    value', '    Div(const Expr *lhs,const Expr *rhs)', '    DoubleImm(double value)', '    isConstant', '    value', '    dtype', '    FloatImm(float value)', '    isConstant', '    value', '    IntImm(int value)', '    isConstant', '    value', '    isConstant', '    LongImm(int64_t value)', '    value', '    Lshift(const Expr *lhs,const Expr *rhs)', '    Max(const Expr *lhs,const Expr *rhs,bool propagate_nans)', '    propagate_nans', '    Min(const Expr *lhs,const Expr *rhs,bool propagate_nans)', '    propagate_nans', '    Mod(const Expr *lhs,const Expr *rhs)', '    Mul(const Expr *lhs,const Expr *rhs)', '    Or(const Expr *lhs,const Expr *rhs)', '    Rshift(const Expr *lhs,const Expr *rhs)', '    isConstant', '    ShortImm(int16_t value)', '    value', '    Sub(const Expr *lhs,const Expr *rhs)', '    Xor(const Expr *lhs,const Expr *rhs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\ir_emitter.cpp', ['    LoopStatus'], ['    asSimple(const SugaredValuePtr & value)', '    makeMagic(const std::string & name,SugaredValuePtr base)', '    materializeConstant(T val,Graph & graph,const SourceRange & r,std::unordered_map & map)', '    emit_body', '    emit_body', '    emit_body', '    emitBasicSlice(const SourceRange & loc,Value *sliceable,const List & subscript_exprs)', '    emitMultidimSlicing(const SourceRange & loc,Value *sliceable,const List & subscript_exprs)', '    emitSubscript(const Subscript & subscript)', '    emitTupleIndex(const SourceRange & loc,Value *tuple_val,Value *idx_val)', '    emitTupleSlice(const SourceRange & loc,const NamedValue & tuple_val,const NamedValue & beg_val,const at::optional & end_val)', '    false_expr', '    get_const_expr', '    get_continue_expr', '    getAdjTupleIndex(const SourceRange & loc,const TupleTypePtr & tuple_type,int64_t input_index,bool allow_out_of_bounds)', '    getSliceInd(Value *idx_val,const SourceRange & loc)', '    meaningfulName(const std::string & name)', '    runCleanupPasses(std::shared_ptr & to_clean)', '    canBeNone(Value *v)', '    isSupportedListElementType(const TypePtr & type)', '    true_expr', '    intersectSet(const Refinements & a,const Refinements & b)', '    sameVar(const Refinement & a,const Refinement & b)', '    unionSet(const Refinements & a,const Refinements & b)', '    getTypeForSetStateArg(const Def & def,const Self *self)', '    shouldDeriveSetStateType(const Def & def,const FunctionSchema & schema)', '    CompilationUnit(const std::string & source)', '    define(const c10::optional & prefix,const std::vector & definitions,const std::vector & resolvers,const Self *self,bool shouldMangle)', '    define(const c10::optional & prefix,const std::string & source,const ResolverPtr & resolver,const Self *self)', '    define(const c10::optional & prefix,const Def & def,const ResolverPtr & resolver,const Self *self,const std::unordered_map & function_table,bool shouldMangle)', '    define_interface(const c10::QualifiedName & qualifiedName,const ClassDef & classDef,ResolverPtr rcb,bool is_module)', '    mangle(const c10::QualifiedName & name)', '    FunctionResolver(Resolver *otherResolver,const std::unordered_map & functionTable)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    gather(Expr classinfo)', '    GatheredTypes(ScriptTypeParser parser)', '    maybeOfKind(TypeKind kind,const TypePtr & actual_type)', '    staticallyFalse(const TypePtr & actual_type)', '    staticallyTrue(const TypePtr & actual_type)', '    CondValue(Value *value,RefinementSet refinements,c10::optional static_if)', '    CondValue(Graph & g,const SourceRange & loc,bool static_value,RefinementSet refinements)', '    refinements', '    staticIf', '    value', '    block', '    definedVariables', '    Environment(Function & method,ResolverPtr resolver,Block *b,std::shared_ptr next)', '    findInAnyFrame(const std::string & name)', '    findInParentFrame(const std::string & name)', '    findInThisFrame(const std::string & name)', '    findVariableTypeError(const std::string & name)', '    getSugaredVar(const Ident & ident,bool required)', '    getSugaredVar(const std::string & ident,const SourceRange & range,bool required)', '    getVar(const Ident & ident)', '    getVar(const std::string & ident,const SourceRange & range)', '    insertLoad(const std::string & name,const TypePtr & type)', '    insertStore(const std::string & name,const SourceRange & loc,Value *v,TypePtr type)', '    setSugaredVar(const SourceRange & loc,const std::string & name,SugaredValuePtr value,TypePtr annotated_type)', '    setType(const std::string & name,TypePtr type)', '    setVar(const SourceRange & loc,const std::string & name,Value *value)', '    setVariableTypeError(const std::string & name,std::function msg)', '    identifier', '    Refinement(std::string identifier,TypePtr type)', '    type', '    activeRefinements', '    And(const RefinementSet & rhs)', '    Not', '    Or(const RefinementSet & rhs)', '    RefinementSet(Refinements true_refinements,Refinements false_refinements)', '    RefinementSet(Refinement single)', '    RefinementSet(Refinement single_true,Refinement single_false)', '    RefinementSet', '    checkApplyNumInputs(Apply & apply,size_t expected_inputs)', '    checkBreakContinue(const SourceRange & loc,const std::string & stmt_name)', '    create(Symbol kind,const SourceRange & loc,size_t n_outputs)', '    createTempName(const std::string & prefix)', '    emitApplyExpr(Apply & apply,size_t n_binders,const TypePtr & type_hint)', '    emitApplySpecialForm(Symbol form,Apply & apply,const TypePtr & type_hint)', '    emitAssert(const Assert & stmt)', '    emitAssignment(const Assign & stmt)', '    emitAttributes(const List & attributes)', '    emitAugAssignment(const AugAssign & stmt)', '    emitAugAssignmentGeneric(const AugAssign & stmt,const Subscript & lhs,Value *sliceable)', '    emitAugAssignmentHelper(const AugAssign & stmt,Value *lhs)', '    emitAugAssignmentToSelectVar(const AugAssign & stmt)', '    emitAugAssignmentToSubscript(const AugAssign & stmt)', '    emitAugAssignmentToVar(const AugAssign & stmt)', '    emitBreak(const Break & stmt)', '    emitClosure(const std::function & emit_body)', '    emitClosure(const Def & def)', '    emitCondExpr(const Expr & expr)', '    emitConst(const Const & c)', '    emitContinue(const Continue & stmt)', '    emitDef(const Def & def,const Self *self,Block *block)', '    emitDelete(const Delete & stmt)', '    emitExpr(const Expr & tree,const TypePtr & type_hint)', '    emitExprsAssign(const List & lhs_exprs,const at::ArrayRef outputs,const SourceRange & rhs_loc,size_t n_binders)', '    emitFor(const List & targets,const List & itrs,const SourceRange & loc,const std::function & emit_body)', '    emitFor(const For & stmt)', '    emitForkExpr(SourceRange loc,const std::shared_ptr & forked,at::ArrayRef inputs,at::ArrayRef attributes)', '    emitFormalArguments(const Def & def,const Self *self,const FunctionSchema & schema,Block *block)', '    emitHasAttr(const Expr & objExpr,const Expr & attrExpr)', '    emitIf(const If & stmt)', '    emitIfElseBlocks(const SourceRange & loc,const CondValue & cond_value,const List & trueBranch,const List & falseBranch)', '    emitIfExpr(const SourceRange & range,const CondValue & cond_value,std::function true_expr,std::function false_expr)', '    emitIndex(const SourceRange & loc,Value *input,at::ArrayRef indices)', '    emitIsInstance(const Expr & obj,const Expr & classinfo)', '    emitListComprehension(const ListComp & lc,const TypePtr & type_hint)', '    emitLoopCommon(SourceRange range,const std::function & emit_body,const SugaredValuePtr & iter_val,c10::optional,c10::optional cond)', '    emitOutput(const SourceRange & range,const FunctionSchema & schema,Block *block)', '    emitRaise(const SourceRange & loc)', '    emitReturn(const Return & stmt)', '    emitRpcAsyncExpr(const Apply & apply)', '    emitSelect(const SourceRange & loc,Value *input,Value *dim,Value *index)', '    emitSelectAssign(const Assign & stmt)', '    emitShortCircuitLogical(const SourceRange & loc,const Expr & first_expr,const Expr & second_expr,bool is_or)', '    emitSimpleExpr(const TreeRef & tree,const TypePtr & type_hint)', '    emitSingleAssignment(const Assign & stmt)', '    emitSingleIfBranch(Block *b,const List & branch,const RefinementSet & refinements)', '    emitSlice(const SourceRange & loc,Value *input,Value *dim,const SliceExpr & slice)', '    emitStatements(const List & statements)', '    emitStatements(List::const_iterator begin,List::const_iterator end)', '    emitStringLiteral(const StringLiteral & c)', '    emitSubscriptAssign(const SourceRange & stmtRange,const Subscript & lhs,const Expr & rhs)', '    emitSubscriptAssign(const SourceRange & stmtRange,const Subscript & lhs,const NamedValue & rhs)', '    emitSugaredExpr(const Expr & tree,size_t n_binders,const TypePtr & type_hint)', '    emitTernaryIf(const TernaryIf & expr)', '    emitToBool(Value *v)', '    emitTupleAssign(const TupleLiteral & tl,const Expr & rhs)', '    emitTupleAssign(const TupleLiteral & tl,const SugaredValuePtr & rhs_output,const SourceRange & rhs_loc,size_t n_binders,bool starred_unpack)', '    emitUnaryOp(const TreeRef & tree,const std::string & magicMethod,const c10::Symbol & opSymbol)', '    emitUnrolledLoop(const SourceRange & loc,const std::function & emit_body,SugaredValuePtr iterable,const List & targets)', '    emitUnsqueeze(const SourceRange & loc,Value *input,Value *dim_val)', '    emitWhile(const While & stmt)', '    findIsNoneRefinements(Expr lhs,Value *lhs_value,Expr rhs,Value *rhs_value,int tok)', '    getAugMagicMethod(const AugAssign & stmt)', '    getAugOp(const AugAssign & stmt,const TypePtr & type)', '    getNamedValues(const TreeList & trees,bool maybe_unpack)', '    getNamedValues(const List & trees,bool maybe_unpack)', '    getNodeKind(int kind,int ninputs)', '    getOperatorOverload(int kind,int ninputs)', '    getValues(const TreeList & trees,bool maybe_unpack)', '    getValues(const List & trees,bool maybe_unpack)', '    handleMaybeNoReturn(const Def & def,Block *block)', '    insertRefinements(const SourceRange & loc,const RefinementSet & ref)', '    popFrame(bool ends_def)', '    pushFrame(Block *b,bool starts_def)', '    reverseComparision(NodeKind kind)', '    to_ir(const Def & def,ResolverPtr resolver_,const Self *self,Function & method)', '    validateAssignLhsExpr(const List & lhs,const SourceRange & r)', '    WithLoopStatus(LoopStatus *prev,LoopStatus new_status)', '    ~WithLoopStatus']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\ir_emitter.h', [], ['    meaningfulName(const std::string & name)', '    runCleanupPasses(std::shared_ptr & to_clean)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_mutator.cpp', ['    StmtClone'], ['    mutate_binary_op(const BinaryOpNode *v,IRMutator *mutator,bool option)', '    clone(Stmt *s)', '    DefaultMutator(const BaseCallNode *v,std::vector & params)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Or *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const ByteImm *v)', '    mutate(const CharImm *v)', '    mutate(const ShortImm *v)', '    mutate(const IntImm *v)', '    mutate(const LongImm *v)', '    mutate(const FloatImm *v)', '    mutate(const DoubleImm *v)', '    mutate(const BoolImm *v)', '    mutate(const HalfImm *v)', '    mutate(const Intrinsics *v)', '    mutate(const FunctionCall *v)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    mutate(const Block *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    mutate(const LetStmt *v)', '    mutate(const For *v)', '    mutate(const Block *v)', '    mutate(const Store *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    mutate(const Cond *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_mutator.h', ['    IRMutator'], ['    DefaultMutator(const BaseCallNode *v,std::vector & params)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Or *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const ByteImm *v)', '    mutate(const CharImm *v)', '    mutate(const ShortImm *v)', '    mutate(const IntImm *v)', '    mutate(const LongImm *v)', '    mutate(const FloatImm *v)', '    mutate(const DoubleImm *v)', '    mutate(const BoolImm *v)', '    mutate(const HalfImm *v)', '    mutate(const Intrinsics *v)', '    mutate(const FunctionCall *v)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    mutate(const Block *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    ~IRMutator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_printer.cpp', [], ['    formatFPSuffix(std::ostream & os,double v)', '    formatFPSuffix(std::ostream & os,T v)', '    formatImm(std::ostream & os,T v)', '    formatImm(std::ostream & os,T v)', '    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    operator<<(std::ostream & stream,const Expr & expr)', '    operator<<(std::ostream & stream,const ExprHandle & expr)', '    operator<<(std::ostream & stream,const Stmt & stmt)', '    print(const Expr *expr)', '    print(const Stmt *stmt)', '    visitBinaryOp(const BinaryOpNode *v,const std::string & op_str,IRPrinter *printer,bool parens)', '    emitIndent', '    print(ExprHandle expr)', '    print(const Expr & expr)', '    print(const Stmt & stmt)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_printer.h', ['    IRPrinter', '    PrinterStream'], ['    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    operator<<(std::ostream & stream,const Expr & expr)', '    operator<<(std::ostream & stream,const ExprHandle & expr)', '    operator<<(std::ostream & stream,const Stmt & stmt)', '    operator<<(std::ostream & stream,Stmt *)', '    print(const Expr *expr)', '    print(const Stmt *stmt)', '    emitIndent', '    IRPrinter(std::ostream & os)', '    name_manager', '    os', '    print(ExprHandle expr)', '    print(const Expr & expr)', '    print(const Stmt & stmt)', '    printer', '    PrinterStream(IRPrinter *printer,std::ostream & os)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_simplifier.cpp', [], ['    lastNode', '    lastNode', '    lastNode', '    combineMultilane(const Expr *lhs,const Expr *rhs)', '    gcd(T a,T b)', '    mulMultilane(const Expr *lhs,const Expr *rhs)', '    polyGCD(const Polynomial *poly)', '    hashVars', '    sort', '    addOrUpdateTerm(std::unordered_map & varmap,const Term *term)', '    addPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    insertTerm(const Polynomial *poly,const Term *term)', '    mulTerms(const Term *lhs,const Term *rhs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Intrinsics *v)', '    mutate(const Cast *v)', '    polyByTerm(const Polynomial *poly,const Term *term)', '    subPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    subTerms(const Term *lhs,const Term *rhs,bool negated)', '    hashVars', '    sort', '    factorizePolynomial(const Polynomial *poly)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_simplifier.h', ['    IRSimplifier', '    Polynomial', '    PolynomialTransformer', '    Term', '    TermExpander'], ['    isMultilanePrimitive(const Expr *e)', '    promoteTypesMap(const Expr *s,std::unordered_map & m)', '    promoteTypesVar(const ExprType *e)', '    promoteTypesVar(const ExprType *e,Args,...)', '    promoteTypesVec(const Expr *s,std::vector & v)', '    promoteTypesVec(std::vector & v)', '    simplify(const Expr *e)', '    simplify(const ExprHandle & e)', '    simplify(Stmt *s)', '    mutateBinaryOp(const BinaryOpNode *v,IRMutator *mutator,bool option)', '    simplify(const Expr *e)', '    simplify(const ExprHandle & e)', '    simplify(Stmt *e)', '    dtype', '    expr_type', '    addTerm(const Term *t)', '    addTerm(const Term *t,Ts,...)', '    hasher', '    hashVars', '    Polynomial(HashProvider & hasher,const Expr *s,Args,...)', '    Polynomial(HashProvider & hasher,const Expr *s,std::vector)', '    Polynomial(HashProvider & hasher,std::vector terms)', '    Polynomial(HashProvider & hasher,const Expr *s,std::unordered_map varmap)', '    scalar', '    sort', '    variables', '    addOrUpdateTerm(std::unordered_map & varmap,const Term *term)', '    addPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    insertTerm(const Polynomial *poly,const Term *term)', '    mulTerms(const Term *lhs,const Term *rhs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const Intrinsics *v)', '    mutate(const Cast *v)', '    polyByTerm(const Polynomial *poly,const Term *term)', '    subPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    subTerms(const Term *lhs,const Term *rhs,bool negated)', '    addComponent', '    addComponent(const Expr *e)', '    addComponent(const Expr *e,Es,...)', '    hasher', '    hashVars', '    scalar', '    sort', '    Term(HashProvider & hasher,const Expr *s,Args,...)', '    Term(HashProvider & hasher,const Expr *s,std::vector)', '    Term(HashProvider & hasher,const Expr *s,std::unordered_map varmap)', '    variables', '    factorizePolynomial(const Polynomial *poly)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    TermExpander(PolynomialTransformer *simplifier)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\ir_views.h', [], ['    adjustIndices(size_t adjust,const std::vector & index_ordering)', '    push_back', '    reserve', '    size', '    cond', '    elseBlock', '    elseOutputs', '    IfView(Node *node)', '    node', '    operator torch::jit::Node *', '    outputs', '    permuteOutputs(const std::vector & new_output_order)', '    thenBlock', '    thenOutputs', '    bodyBlock', '    bodyCarriedInputs', '    bodyCarriedOutputs', '    carriedInputs', '    carriedInputsWithCond', '    carriedOutputs', '    cond', '    currentTripCount', '    inputCond', '    loopType', '    LoopView(Node *node)', '    maxTripCount', '    nextCond', '    node', '    operator torch::jit::Node *', '    permuteLoopCarried(const std::vector & new_output_order)', '    replaceInputCondition(Value *new_input_condition)', '    replaceMaxTripCount(Value *new_max_trip_count)', '    at', '    blocks', '    input', '    inputs', '    outputs', '    permuteInputs', '    permuteOutputs', '    replaceInput', '    slice', '    at', '    inputs', '    outputs', '    permuteInputs', '    permuteOutputs', '    slice', '    uses']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_visitor.cpp', [], ['    visit_binary_op(const BinaryOpNode *v,IRVisitor *visitor)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const FunctionCall *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\ir_visitor.h', ['    IRVisitor'], ['    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const FunctionCall *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    ~IRVisitor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\irparser.cpp', ['    IRParser'], ['    parseIR(const std::string & str,torch::jit::Graph *graph)', '    parseIR(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)', '    findValueInVMap(const std::string & name)', '    parse', '    parseAttr(Node *n)', '    parseAttrs(Node *n)', '    parseBlock(Node *parentNode)', '    parseBlockInputs(Block *b)', '    parseBlockOutputs(Block *b)', '    parseBlocks(Node *parentNode)', '    parseGraphInputs', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseOperator(Block *b)', '    parseOperatorInputs(Node *n)', '    parseOperatorName', '    parseOperatorsList(Block *b)', '    parseReturnOperator', '    parseScalarLiteral(Node *n)', '    IRParser(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)', '    parseOperatorOutputs(std::vector *outs)', '    parseVar', '    parseVarWithType(bool allow_optional)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\irparser.h', [], ['    parseIR(const std::string & str,torch::jit::Graph *graph)', '    parseIR(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\is_empty_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIsEmpty', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsEmpty']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\is_empty_op.h', ['    IsEmptyOp'], ['    IsEmptyOp(Args,...)', '    RunOnDevice', '    ~IsEmptyOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\isa-checks.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\IsContiguous.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\istream_adapter.cc', [], ['    IStreamAdapter(std::istream *istream)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    validate(const char *what)', '    ~IStreamAdapter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\istream_adapter.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\iter_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicIter', '    CAFFE_ANONYMOUS_VARIABLE_CPUIter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicIter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Iter', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\iter_op.h', ['    final', '    final', '    MutexDeserializer', '    MutexSerializer'], ['    IncrementIter(TensorCPU *output)', '    AtomicIterOp(const OperatorDef & operator_def,Workspace *ws)', '    AtomicIterOpStats(std::string name)', '    num_iter', '    IterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\iter_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAAtomicIter', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\iterator.h', ['    Iterator'], ['    get', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const ValidIterator & other)', '    operator==(const SentinelIterator & other)', '    ~IteratorImpl', '    get', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const ValidIterator & other)', '    operator==(const SentinelIterator & other)', '    get', '    lazy_initialize', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const SentinelIterator &)', '    operator==(const ValidIterator & other)', '    ValidIterator(BatchProducer next_batch)', '    Iterator(std::unique_ptr)', '    operator!=(const Iterator & other)', '    operator*', '    operator++', '    operator->', '    operator==(const Iterator & other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Itertools.cpp', [], ['    _triu_mask(int64_t n,int64_t dims,bool diagonal,TensorOptions opt)', '    cartesian_prod(TensorList tensors)', '    combinations(const Tensor & self,int64_t r,bool with_replacement)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ivalue.cpp', [], ['    CompareKeys(const std::pair & aWrap,const std::pair & bWrap)', '    checkCustomClassType(TypePtr expected_type,TypePtr actual_type)', '    operator<<(std::ostream & out,const IValue & v)', '    printDict(std::ostream & out,const Dict & v,IValueFormatter formatter)', '    printList(std::ostream & out,const T & list,const std::string start,const std::string finish,IValueFormatter formatter)', '    printMaybeAnnotatedDict(std::ostream & out,const IValue & the_dict,IValueFormatter formatter)', '    printMaybeAnnotatedList(std::ostream & out,const IValue & the_list,IValueFormatter formatter)', '    dump', '    getCustomClassTypeMap', '    getSubValues(HashAliasedIValues & subValues)', '    overlaps(const IValue & rhs)', '    repr(std::ostream & out,std::function customFormatter)', '    type', '    create(std::string str_)', '    getAttr(const std::string & name)', '    name', '    resizeObject(size_t slot)', '    setAttr(const std::string & name,IValue v)', '    type', '    unsafeRemoveAttr(const std::string & name)', '    StrongTypePtr(std::shared_ptr cu,std::shared_ptr type)', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ivalue.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ivalue_inl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\ivalue_test.cpp', [], ['    bar', '    TEST(IValueTest,Basic)', '    TEST(IValueTest,Tuple)', '    TEST(IValueTest,unsafeRemoveAttr)', '    TEST(IValueTest,TuplePrint)', '    TEST(IValueTest,BasicFuture)', '    TEST(IValueTest,FutureCallbacks)', '    TEST(IValueTest,FutureExceptions)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\jit.cpp', [], ['    TEST(TorchScriptTest,CanCompileMultipleFunctions)', '    TEST(TorchScriptTest,TestNestedIValueModuleArgMatching)', '    TEST(TorchScriptTest,TestDictArgMatching)', '    TEST(TorchScriptTest,TestTupleArgMatching)', '    TEST(TorchScriptTest,TestOptionalArgMatching)', '    TEST(TorchScriptTest,TestPickle)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\jit.cpp', [], ['    compile(const std::string & source)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\jit.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\jit_exception.cpp', [], ['    JITException(const std::string & msg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\jit_exception.h', [], ['    JITException(const std::string & msg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\jit_extension.cpp', [], ['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    tanh_add(Tensor x,Tensor y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\jit_extension2.cpp', [], ['    exp_add(Tensor x,Tensor y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\jit_log.cpp', [], ['    parseJITLogOption(const char *option)', '    fname', '    getHeader(const Node *node)', '    is_enabled(const char *cfname,JitLoggingLevels level)', '    jit_log_prefix(const std::string & prefix,const std::string & in_str)', '    jit_log_prefix(JitLoggingLevels level,const char *fn,int l,const std::string & in_str)', '    log_function(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,JitLoggingLevels level)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\jit_log.h', ['    JitLoggingLevels'], ['    getHeader(const Node *node)', '    is_enabled(const char *cfname,JitLoggingLevels level)', '    jit_log_level', '    jit_log_prefix(const std::string & prefix,const std::string & in_str)', '    jit_log_prefix(JitLoggingLevels level,const char *fn,int l,const std::string & in_str)', '    log_function(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,JitLoggingLevels level)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\jit_type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\.circleci\\docker\\java\\jni.h', ['    _jarray', '    _jbooleanArray', '    _jbyteArray', '    _jcharArray', '    _jclass', '    _jdoubleArray', '    _jfloatArray', '    _jintArray', '    _jlongArray', '    _jobject', '    _jobjectArray', '    _jshortArray', '    _jstring', '    _jthrowable'], ['    __attribute__(visibility)', '    JNI_CreateJavaVM(JavaVM **,JNIEnv **,void *)', '    JNI_GetCreatedJavaVMs(JavaVM **,jsize,jsize *)', '    JNI_GetDefaultJavaVMInitArgs(void *)', '    AttachCurrentThread(JNIEnv **p_env,void *thr_args)', '    AttachCurrentThreadAsDaemon(JNIEnv **p_env,void *thr_args)', '    DestroyJavaVM', '    DetachCurrentThread', '    GetEnv(void **env,jint version)', '    AllocObject(jclass clazz)', '    CallBooleanMethod(jobject obj,jmethodID methodID,...)', '    CallBooleanMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallBooleanMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallByteMethod(jobject obj,jmethodID methodID,...)', '    CallByteMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallByteMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallCharMethod(jobject obj,jmethodID methodID,...)', '    CallCharMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallCharMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallDoubleMethod(jobject obj,jmethodID methodID,...)', '    CallDoubleMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallDoubleMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallFloatMethod(jobject obj,jmethodID methodID,...)', '    CallFloatMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallFloatMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallIntMethod(jobject obj,jmethodID methodID,...)', '    CallIntMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallIntMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallLongMethod(jobject obj,jmethodID methodID,...)', '    CallLongMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallLongMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallNonvirtualBooleanMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualBooleanMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualBooleanMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualByteMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualByteMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualByteMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualCharMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualCharMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualCharMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualDoubleMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualDoubleMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualDoubleMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualFloatMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualFloatMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualFloatMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualIntMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualIntMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualIntMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualLongMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualLongMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualLongMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualObjectMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualObjectMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualObjectMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualShortMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualShortMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualShortMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualVoidMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualVoidMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualVoidMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallObjectMethod(jobject obj,jmethodID methodID,...)', '    CallObjectMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallObjectMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallShortMethod(jobject obj,jmethodID methodID,...)', '    CallShortMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallShortMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallStaticBooleanMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticBooleanMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticBooleanMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticByteMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticByteMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticByteMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticCharMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticCharMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticCharMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticDoubleMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticDoubleMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticDoubleMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticFloatMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticFloatMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticFloatMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticIntMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticIntMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticIntMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticLongMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticLongMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticLongMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticObjectMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticObjectMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticObjectMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticShortMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticShortMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticShortMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticVoidMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticVoidMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticVoidMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallVoidMethod(jobject obj,jmethodID methodID,...)', '    CallVoidMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallVoidMethodV(jobject obj,jmethodID methodID,va_list args)', '    DefineClass(const char *name,jobject loader,const jbyte *buf,jsize bufLen)', '    DeleteGlobalRef(jobject globalRef)', '    DeleteLocalRef(jobject localRef)', '    DeleteWeakGlobalRef(jweak obj)', '    EnsureLocalCapacity(jint capacity)', '    ExceptionCheck', '    ExceptionClear', '    ExceptionDescribe', '    ExceptionOccurred', '    FatalError(const char *msg)', '    FindClass(const char *name)', '    FromReflectedField(jobject field)', '    FromReflectedMethod(jobject method)', '    GetArrayLength(jarray array)', '    GetBooleanArrayElements(jbooleanArray array,jboolean *isCopy)', '    GetBooleanArrayRegion(jbooleanArray array,jsize start,jsize len,jboolean *buf)', '    GetBooleanField(jobject obj,jfieldID fieldID)', '    GetByteArrayElements(jbyteArray array,jboolean *isCopy)', '    GetByteArrayRegion(jbyteArray array,jsize start,jsize len,jbyte *buf)', '    GetByteField(jobject obj,jfieldID fieldID)', '    GetCharArrayElements(jcharArray array,jboolean *isCopy)', '    GetCharArrayRegion(jcharArray array,jsize start,jsize len,jchar *buf)', '    GetCharField(jobject obj,jfieldID fieldID)', '    GetDirectBufferAddress(jobject buf)', '    GetDirectBufferCapacity(jobject buf)', '    GetDoubleArrayElements(jdoubleArray array,jboolean *isCopy)', '    GetDoubleArrayRegion(jdoubleArray array,jsize start,jsize len,jdouble *buf)', '    GetDoubleField(jobject obj,jfieldID fieldID)', '    GetFieldID(jclass clazz,const char *name,const char *sig)', '    GetFloatArrayElements(jfloatArray array,jboolean *isCopy)', '    GetFloatArrayRegion(jfloatArray array,jsize start,jsize len,jfloat *buf)', '    GetFloatField(jobject obj,jfieldID fieldID)', '    GetIntArrayElements(jintArray array,jboolean *isCopy)', '    GetIntArrayRegion(jintArray array,jsize start,jsize len,jint *buf)', '    GetIntField(jobject obj,jfieldID fieldID)', '    GetJavaVM(JavaVM **vm)', '    GetLongArrayElements(jlongArray array,jboolean *isCopy)', '    GetLongArrayRegion(jlongArray array,jsize start,jsize len,jlong *buf)', '    GetLongField(jobject obj,jfieldID fieldID)', '    GetMethodID(jclass clazz,const char *name,const char *sig)', '    GetObjectArrayElement(jobjectArray array,jsize index)', '    GetObjectClass(jobject obj)', '    GetObjectField(jobject obj,jfieldID fieldID)', '    GetObjectRefType(jobject obj)', '    GetPrimitiveArrayCritical(jarray array,jboolean *isCopy)', '    GetShortArrayElements(jshortArray array,jboolean *isCopy)', '    GetShortArrayRegion(jshortArray array,jsize start,jsize len,jshort *buf)', '    GetShortField(jobject obj,jfieldID fieldID)', '    GetStaticBooleanField(jclass clazz,jfieldID fieldID)', '    GetStaticByteField(jclass clazz,jfieldID fieldID)', '    GetStaticCharField(jclass clazz,jfieldID fieldID)', '    GetStaticDoubleField(jclass clazz,jfieldID fieldID)', '    GetStaticFieldID(jclass clazz,const char *name,const char *sig)', '    GetStaticFloatField(jclass clazz,jfieldID fieldID)', '    GetStaticIntField(jclass clazz,jfieldID fieldID)', '    GetStaticLongField(jclass clazz,jfieldID fieldID)', '    GetStaticMethodID(jclass clazz,const char *name,const char *sig)', '    GetStaticObjectField(jclass clazz,jfieldID fieldID)', '    GetStaticShortField(jclass clazz,jfieldID fieldID)', '    GetStringChars(jstring string,jboolean *isCopy)', '    GetStringCritical(jstring string,jboolean *isCopy)', '    GetStringLength(jstring string)', '    GetStringRegion(jstring str,jsize start,jsize len,jchar *buf)', '    GetStringUTFChars(jstring string,jboolean *isCopy)', '    GetStringUTFLength(jstring string)', '    GetStringUTFRegion(jstring str,jsize start,jsize len,char *buf)', '    GetSuperclass(jclass clazz)', '    GetVersion', '    IsAssignableFrom(jclass clazz1,jclass clazz2)', '    IsInstanceOf(jobject obj,jclass clazz)', '    IsSameObject(jobject ref1,jobject ref2)', '    MonitorEnter(jobject obj)', '    MonitorExit(jobject obj)', '    NewBooleanArray(jsize length)', '    NewByteArray(jsize length)', '    NewCharArray(jsize length)', '    NewDirectByteBuffer(void *address,jlong capacity)', '    NewDoubleArray(jsize length)', '    NewFloatArray(jsize length)', '    NewGlobalRef(jobject obj)', '    NewIntArray(jsize length)', '    NewLocalRef(jobject ref)', '    NewLongArray(jsize length)', '    NewObject(jclass clazz,jmethodID methodID,...)', '    NewObjectA(jclass clazz,jmethodID methodID,const jvalue *args)', '    NewObjectArray(jsize length,jclass elementClass,jobject initialElement)', '    NewObjectV(jclass clazz,jmethodID methodID,va_list args)', '    NewShortArray(jsize length)', '    NewString(const jchar *unicodeChars,jsize len)', '    NewStringUTF(const char *bytes)', '    NewWeakGlobalRef(jobject obj)', '    PopLocalFrame(jobject result)', '    PushLocalFrame(jint capacity)', '    RegisterNatives(jclass clazz,const JNINativeMethod *methods,jint nMethods)', '    ReleaseBooleanArrayElements(jbooleanArray array,jboolean *elems,jint mode)', '    ReleaseByteArrayElements(jbyteArray array,jbyte *elems,jint mode)', '    ReleaseCharArrayElements(jcharArray array,jchar *elems,jint mode)', '    ReleaseDoubleArrayElements(jdoubleArray array,jdouble *elems,jint mode)', '    ReleaseFloatArrayElements(jfloatArray array,jfloat *elems,jint mode)', '    ReleaseIntArrayElements(jintArray array,jint *elems,jint mode)', '    ReleaseLongArrayElements(jlongArray array,jlong *elems,jint mode)', '    ReleasePrimitiveArrayCritical(jarray array,void *carray,jint mode)', '    ReleaseShortArrayElements(jshortArray array,jshort *elems,jint mode)', '    ReleaseStringChars(jstring string,const jchar *chars)', '    ReleaseStringCritical(jstring string,const jchar *carray)', '    ReleaseStringUTFChars(jstring string,const char *utf)', '    SetBooleanArrayRegion(jbooleanArray array,jsize start,jsize len,const jboolean *buf)', '    SetBooleanField(jobject obj,jfieldID fieldID,jboolean value)', '    SetByteArrayRegion(jbyteArray array,jsize start,jsize len,const jbyte *buf)', '    SetByteField(jobject obj,jfieldID fieldID,jbyte value)', '    SetCharArrayRegion(jcharArray array,jsize start,jsize len,const jchar *buf)', '    SetCharField(jobject obj,jfieldID fieldID,jchar value)', '    SetDoubleArrayRegion(jdoubleArray array,jsize start,jsize len,const jdouble *buf)', '    SetDoubleField(jobject obj,jfieldID fieldID,jdouble value)', '    SetFloatArrayRegion(jfloatArray array,jsize start,jsize len,const jfloat *buf)', '    SetFloatField(jobject obj,jfieldID fieldID,jfloat value)', '    SetIntArrayRegion(jintArray array,jsize start,jsize len,const jint *buf)', '    SetIntField(jobject obj,jfieldID fieldID,jint value)', '    SetLongArrayRegion(jlongArray array,jsize start,jsize len,const jlong *buf)', '    SetLongField(jobject obj,jfieldID fieldID,jlong value)', '    SetObjectArrayElement(jobjectArray array,jsize index,jobject value)', '    SetObjectField(jobject obj,jfieldID fieldID,jobject value)', '    SetShortArrayRegion(jshortArray array,jsize start,jsize len,const jshort *buf)', '    SetShortField(jobject obj,jfieldID fieldID,jshort value)', '    SetStaticBooleanField(jclass clazz,jfieldID fieldID,jboolean value)', '    SetStaticByteField(jclass clazz,jfieldID fieldID,jbyte value)', '    SetStaticCharField(jclass clazz,jfieldID fieldID,jchar value)', '    SetStaticDoubleField(jclass clazz,jfieldID fieldID,jdouble value)', '    SetStaticFloatField(jclass clazz,jfieldID fieldID,jfloat value)', '    SetStaticIntField(jclass clazz,jfieldID fieldID,jint value)', '    SetStaticLongField(jclass clazz,jfieldID fieldID,jlong value)', '    SetStaticObjectField(jclass clazz,jfieldID fieldID,jobject value)', '    SetStaticShortField(jclass clazz,jfieldID fieldID,jshort value)', '    Throw(jthrowable obj)', '    ThrowNew(jclass clazz,const char *message)', '    ToReflectedField(jclass cls,jfieldID fieldID,jboolean isStatic)', '    ToReflectedMethod(jclass cls,jmethodID methodID,jboolean isStatic)', '    UnregisterNatives(jclass clazz)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\jsd_op.cc', ['    GetBernoulliJSDGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBernoulliJSD', '    CAFFE_ANONYMOUS_VARIABLE_CPUBernoulliJSDGradient', '    kLOG_THRESHOLD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BernoulliJSD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BernoulliJSDGradient', '    entropy(float p)', '    logit(float p)', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\jsd_op.h', ['    final', '    final'], ['    BernoulliJSDGradientOp(Args,...)', '    BernoulliJSDOp(Args,...)', '    RunOnDevice', '    ~BernoulliJSDGradientOp', '    ~BernoulliJSDOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\kernel.cpp', [], ['    broadcastShapes(const std::vector & a,const std::vector & b)', '    broadcastShapes(const std::vector & a,const std::vector & b,Args,...)', '    checkInputs(const at::ArrayRef & inputs,std::vector & inputTypes)', '    isOne(ExprHandle e)', '    isValidPrimProperty(const c10::optional & a,T b)', '    isValidVaryingShape(const c10::VaryingShape & vs,at::IntArrayRef sz)', '    tensorType(Tensor *t)', '    texprDims(const torch::jit::Value *v)', '    texprSizes(const c10::VaryingShape & shape)', '    bufferSize(T t)', '    newOut', '    getTECudaPointwiseBlockCount', '    getTECudaPointwiseBlockSize', '    getTECudaPointwiseLoopLevels', '    v', '    bindInput(const torch::jit::Value *input)', '    codeGenRun(const std::vector & runArgs)', '    compile', '    computeConditionWithTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeFourOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeOneOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeThreeOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperandWithAlpha(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeValue(const torch::jit::Value *v)', '    constant(const torch::jit::Value *v)', '    createInputIndexExpr(const Buffer & buffer,const std::vector & axes,const c10::VaryingShape & sizes,const c10::VaryingStrides & strides,const c10::VaryingStrides & contiguity,const std::unordered_map & sizeVars)', '    demoteOutput(const ExprHandle & e,const torch::jit::Value *v)', '    lowerToBackend(BackendType backendType)', '    pickAndCheckBackendType(const at::ArrayRef & inputs)', '    promoteInputs(std::vector & inputs)', '    run(Stack & stack)', '    runKernel(Stack & stack)', '    TensorExprKernel(const std::shared_ptr & subgraph)', '    valueShape(const torch::jit::Value *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\kernel.h', ['    TensorExprKernel'], ['    bufferSizes(const T & t)', '    computeIndicesToBroadcast(const std::vector & outputAxes,const std::vector & inputSizes)', '    getTECudaPointwiseBlockCount', '    getTECudaPointwiseBlockSize', '    getTECudaPointwiseLoopLevels', '    rbegin', '    rend', '    bindInput(const torch::jit::Value *input)', '    broadcast(const T & t,const std::vector & axes)', '    chunk(const T & t,size_t chunkIdx,size_t dim,size_t chunks,const std::vector & axes)', '    codeGenRun(const std::vector & runArgs)', '    compile', '    computeConditionWithTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeFourOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeOneOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeThreeOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperandWithAlpha(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeValue(const torch::jit::Value *v)', '    constant(const torch::jit::Value *v)', '    createInputIndexExpr(const Buffer & buffer,const std::vector & axes,const c10::VaryingShape & sizes,const c10::VaryingStrides & strides,const c10::VaryingStrides & contiguity,const std::unordered_map & sizeVars)', '    demoteOutput(const ExprHandle & e,const torch::jit::Value *v)', '    fallback(Stack & stack)', '    fallback_', '    hasBroadcast_', '    hasRandom_', '    buffer', '    KernelArg(B)', '    KernelArg(B,T,T)', '    sizes', '    strides', '    lowerToBackend(BackendType backendType)', '    pickAndCheckBackendType(const at::ArrayRef & inputs)', '    promoteInputs(std::vector & inputs)', '    run(Stack & stack)', '    runKernel(Stack & stack)', '    ShapeArg(size_t i,VarHandle v)', '    TensorExprKernel(const std::shared_ptr & subgraph)', '    tensorOrConstant(const torch::jit::Value *v,const std::vector & axes)', '    valueShape(const torch::jit::Value *v)', '    unique']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\kernel_cache.cpp', [], ['    getKernelCache', '    nolock_retrieve(KernelCacheImpl & cache,const int64_t key)', '    debugNumCachedKernelSpecs', '    lookupGraph(std::shared_ptr graph)', '    normalizeGraphForCache(const std::shared_ptr & graph)', '    retrieve(const int64_t key)', '    store(std::shared_ptr graph)', '    kernel_counter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\kernel_cache.h', [], ['    debugNumCachedKernelSpecs', '    lookupGraph(std::shared_ptr graph)', '    normalizeGraphForCache(const std::shared_ptr & graph)', '    retrieve(const int64_t key)', '    store(std::shared_ptr graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_function_legacy_test.cpp', [], ['    func(Args,...)', '    concatKernel(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    decrementKernel(const Tensor & tensor,int64_t input)', '    errorKernel(const Tensor & tensor,int64_t input)', '    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    final', '    incrementKernel(const Tensor & tensor,int64_t input)', '    kernelForSchemaInference(Tensor arg1,int64_t arg2,const std::vector & arg3)', '    kernelWithDictInputWithoutOutput(Dict input1)', '    kernelWithDictInputWithOutput(Dict input1)', '    kernelWithDictOutput(Dict input)', '    kernelWithIntInputWithoutOutput(Tensor,int64_t input1)', '    kernelWithIntInputWithOutput(Tensor,int64_t input1)', '    kernelWithIntListInputWithoutOutput(Tensor,const std::vector & input1)', '    kernelWithIntListInputWithOutput(Tensor,const std::vector & input1)', '    kernelWithIntListOutput(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    kernelWithIntOutput(Tensor,int64_t a,int64_t b)', '    kernelWithLegacyTensorListInputWithoutOutput(std::vector input1)', '    kernelWithLegacyTensorListInputWithOutput(std::vector input1)', '    kernelWithLegacyTensorVectorInputWithoutOutput(const std::vector & input1)', '    kernelWithLegacyTensorVectorInputWithOutput(const std::vector & input1)', '    kernelWithOptInputWithoutOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithOptInputWithOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithoutInputs', '    kernelWithoutOutput(const Tensor &)', '    kernelWithoutTensorInputs(int64_t arg)', '    kernelWithStringListOutput(std::vector input)', '    kernelWithTensorInputByReferenceWithoutOutput(const Tensor & input1)', '    kernelWithTensorInputByReferenceWithOutput(const Tensor & input1)', '    kernelWithTensorInputByValueWithoutOutput(Tensor input1)', '    kernelWithTensorInputByValueWithOutput(Tensor input1)', '    kernelWithTensorListInputWithoutOutput(const std::vector & input1)', '    kernelWithTensorListInputWithOutput(const std::vector & input1)', '    kernelWithTensorListOutput(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    kernelWithTensorOutput(const Tensor & input)', '    kernelWithUnorderedMapInputWithoutOutput(std::unordered_map input1)', '    kernelWithUnorderedMapInputWithOutput(std::unordered_map input1)', '    kernelWithUnorderedMapOutput(std::unordered_map input)', '    kernelWithZeroOutputs(const Tensor &)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegisteredInConstructor_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorVectorInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithStringListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMapOfList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMapOfListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithListOfMapOfIntList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    func(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_function_test.cpp', [], ['    func(Args,...)', '    concatKernel(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    decrementKernel(const Tensor & tensor,int64_t input)', '    errorKernel(const Tensor & tensor,int64_t input)', '    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectCannotCallConcatBoxed(DispatchKey dispatch_key)', '    final', '    incrementKernel(const Tensor & tensor,int64_t input)', '    kernelForSchemaInference(Tensor arg1,int64_t arg2,const c10::List & arg3)', '    kernelWithDictInputWithoutOutput(Dict input1)', '    kernelWithDictInputWithOutput(Dict input1)', '    kernelWithDictOutput(Dict input)', '    kernelWithIntInputWithoutOutput(Tensor,int64_t input1)', '    kernelWithIntInputWithOutput(Tensor,int64_t input1)', '    kernelWithIntListInputWithoutOutput(Tensor,const c10::List & input1)', '    kernelWithIntListInputWithOutput(Tensor,const c10::List & input1)', '    kernelWithIntListOutput(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    kernelWithIntOutput(Tensor,int64_t a,int64_t b)', '    kernelWithOptInputWithoutOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithOptInputWithOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithoutInputs', '    kernelWithoutOutput(const Tensor &)', '    kernelWithoutTensorInputs(int64_t arg)', '    kernelWithTensorInputByReferenceWithoutOutput(const Tensor & input1)', '    kernelWithTensorInputByReferenceWithOutput(const Tensor & input1)', '    kernelWithTensorInputByValueWithoutOutput(Tensor input1)', '    kernelWithTensorInputByValueWithOutput(Tensor input1)', '    kernelWithTensorListInputWithoutOutput(const c10::List & input1)', '    kernelWithTensorListInputWithOutput(const c10::List & input1)', '    kernelWithTensorListOutput(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    kernelWithTensorOutput(const Tensor & input)', '    kernelWithZeroOutputs(const Tensor &)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredUnboxedOnly_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredUnboxedOnly_thenCannotBeCalledBoxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    func(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_functor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_functor_test.cpp', ['    final', '    final', '    final'], ['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectThrows', '    expectThrows', '    final', '    operator()(Args,...)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTupleInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithCache_thenCacheIsKeptCorrectly)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithConstructorArg_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithMultipleConstructorArgs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegisteredCatchAllWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    ConcatKernel(std::string prefix)', '    KernelWithCache', '    KernelWithConstructorArg(int64_t offset)', '    KernelWithMultipleConstructorArgs(int64_t offset1,int64_t offset2)', '    operator()(const Tensor & input1)', '    operator()(const Tensor & input1)', '    operator()(const Tensor & input)', '    operator()(Dict input)', '    operator()(Dict input1)', '    operator()(Tensor,int64_t a,int64_t b)', '    operator()(Dict input1)', '    operator()(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    operator()(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    operator()(const Tensor &,int64_t input)', '    operator()(const Tensor &,int64_t input)', '    operator()(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    operator()(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    operator()(Tensor,int64_t input1)', '    operator()(Tensor,int64_t input1)', '    operator()(const Tensor & tensor,int64_t input)', '    operator()(std::tuple input1)', '    operator()(const Tensor &)', '    operator()(const Tensor &)', '    operator()', '    operator()(int64_t arg)', '    operator()(Tensor,const c10::List & input1)', '    operator()(Tensor,const c10::List & input1)', '    operator()(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    operator()(Tensor arg1,int64_t arg2,const c10::List & arg3)', '    operator()(Args,...)', '    operator()(Tensor input1)', '    operator()(const Tensor & tensor,int64_t input)', '    operator()(const Tensor &,int64_t)', '    operator()(Tensor)', '    operator()(Tensor input1)', '    operator()(const c10::List & input1)', '    operator()(const c10::List & input1)', '    Tensor', '    Tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_lambda.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_lambda_legacy_test.cpp', [], ['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegisteredInConstructor_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorVectorInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithStringListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMapOfList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMapOfListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithListOfMapOfIntList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_lambda_test.cpp', [], ['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    my_kernel', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenOutOfLineKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\kernel_spec.h', [], ['    cacheKernel(const ArgSpec & arg_spec,std::shared_ptr kernel)', '    code', '    graph', '    guard', '    hasRandom', '    inputChunks', '    inputChunks', '    key', '    nInputs', '    nTensorInputs', '    dim', '    nSubTensors', '    dim_', '    PartitionInfo(const int64_t _nSubTensors,const int64_t _dim)', '    code_', '    graph_', '    inputBroadcastGroups_', '    inputChunks_', '    kernels_', '    KernelSpec(const int64_t _key,const std::shared_ptr & _graph)', '    nInputs_', '    nTensorInputs_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\kernel_stackbased_test.cpp', [], ['    decrementKernel(const OperatorHandle &,Stack *stack)', '    errorKernel(const OperatorHandle &,Stack *stack)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectCallsIncrementUnboxed(DispatchKey dispatch_key)', '    incrementKernel(const OperatorHandle &,Stack *stack)', '    kernelForSchemaInference(const OperatorHandle &,Stack *stack)', '    kernelWithoutInputs(const OperatorHandle &,Stack *)', '    kernelWithoutTensorInputs(const OperatorHandle &,Stack *stack)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenFailsBecauseItCannotInferFromStackBasedKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistered_thenCanAlsoBeCalledUnboxed)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\KernelFunction.cpp', [], ['    fallthrough_kernel(OperatorKernel *,const OperatorHandle &,Stack *)', '    _equalsBoxedAndUnboxed(const KernelFunction & other)', '    dumpState']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\KernelFunction.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\KernelFunction_impl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\KernelFunction_test.cpp', [], ['    expectUnboxedCallingWithoutReturnWorks(const KernelFunction & func)', '    expectUnboxedCallingWithReturnWorks(const KernelFunction & func)', '    boxed_func_with_return(const OperatorHandle &,Stack *stack)', '    boxed_func_without_return(const OperatorHandle &,Stack *stack)', '    expectBoxedCallingFailsWith(const KernelFunction & func,const char *errorMessage)', '    expectBoxedCallingWithoutReturnWorks(const KernelFunction & func)', '    expectBoxedCallingWithReturnWorks(const KernelFunction & func)', '    makeDummyOperatorHandle', '    unboxed_function_with_return(int64_t a,int64_t b)', '    unboxed_function_without_return(int64_t a,int64_t b)', '    unboxed_lambda_with_return', '    unboxed_lambda_without_return', '    stack', '    stack', '    stack', '    TEST(KernelFunctionTest,givenBoxedFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withoutReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withoutReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withoutReturn_whenCallingUnboxed_thenWorks)', '    operator()(int64_t a,int64_t b)', '    operator()(int64_t a,int64_t b)', '    operator()', '    operator()']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\detail\\KernelUtils.h', [], ['    GET_BLOCKS(const int N)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\key_split_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUKeySplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_KeySplit']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\key_split_ops.h', ['    KeySplitOp'], ['    GetSingleArgument', '    KeySplitOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\kl_minimization.cc', [], ['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\kl_minimization.h', ['    final'], ['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\kl_minimization_example.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\l1_minimization_example.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\l2_minimization.h', ['    L2ErrorMinimization'], ['    L2MinimizationKernelAVX2(int precision,float *bins,int nbins,float bin_width,float dst_bin_width,int start_bin)', '    L2ErrorMinimization']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\l2_minimization_approx_example.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\l2_minimization_example.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\l2_minimization_test.cc', ['    ChooseQuantizationTest'], ['    TEST_P(ChooseQuantizationTest,L2MinimizationTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms\\lambda.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\lars_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULars', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Lars', '    ComputeLearningRate(const float *wd,const float *trust,const float *lr_max,float offset,float lr_min,float *X_norm,float *dX_norm,float *lr_rescaled)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\lars_op.h', ['    final'], ['    ComputeLearningRate(const T *wd,const T *trust,const T *lr_max,T offset,T lr_min,T *X_norm,T *dX_norm,T *lr_rescaled)', '    ComputeNorms(int64_t N,const T *X_data,const T *dX_data,T *X_norm,T *dX_norm)', '    GetSingleArgument', '    LarsOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\last_n_window_collector.cc', ['    LastNWindowCollectorOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULastNWindowCollector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LastNWindowCollector', '    collect', '    LastNWindowCollectorOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\LaunchUtils.h', [], ['    lastPow2(unsigned int n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\layer_norm.cpp', [], ['    layer_norm(const Tensor & input,IntArrayRef normalized_shape,const Tensor & weight,const Tensor & bias,double eps,bool)', '    layer_norm_backward_cpu(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,std::array grad_input_mask)', '    layer_norm_cpu(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,double eps)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\layer_norm.h', [], ['    LayerNormBackwardKernel', '    LayerNormBackwardKernel', '    operator=', '    LayerNormKernel', '    LayerNormKernel', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\layer_norm_kernel.cpp', [], ['    LayerNormBackwardKernelImpl(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,Tensor *dX,Tensor *dgamma,Tensor *dbeta)', '    LayerNormBackwardKernelImplInternal(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,Tensor *dX,Tensor *dgamma,Tensor *dbeta)', '    LayerNormKernelImpl(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,double eps,Tensor *Y,Tensor *mean,Tensor *rstd)', '    LayerNormKernelImplInternal(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,T eps,Tensor *Y,Tensor *mean,Tensor *rstd)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\layer_norm_op.cc', ['    GetLayerNormGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULayerNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPULayerNormGradient', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LayerNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LayerNormGradient', '    GetGradientDefs', '    ComputeFusedParams(const int M,const int N,const T *mean,const T *sigma,const T *ds,const T *db,T *rstd,T *X_scale,T *bias,T *g_scale)', '    ComputeInternalGradients(const int M,const int N,const T *dY,const T *X,const T *gamma,T *dYxX,T *ds,T *db)', '    GammaBetaBackward(const int M,const int N,const T *dYxX,const T *dY,const T *rstd,const T *g_scale,T *dgamma,T *dbeta)', '    LayerNormBackward(const int M,const int N,const T *dY,const T *X,const T *gamma,const T *dY_scale,const T *X_scale,const T *bias,T *dX)', '    ComputeSigmaAndFusedParams(const int N,const float eps,const T *mean,const T *var,T *sigma,T *scale,T *bias)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\layer_norm_op.h', ['    final', '    final'], ['    schema_LayerNorm', '    bias_', '    ComputeFusedParams(const int M,const int N,const T *mean,const T *sigma,const T *ds,const T *db,T *rstd,T *X_scale,T *bias,T *g_scale)', '    ComputeInternalGradients(const int M,const int N,const T *dY,const T *X,const T *gamma,T *dYxX,T *ds,T *db)', '    ComputeSigmaAndFusedParams(const int N,const float eps,const T *mean,const T *var,T *stddev,T *scale,T *bias)', '    DoRunWithType', '    DoRunWithType', '    GammaBetaBackward(const int M,const int N,const T *dYxX,const T *dY,const T *rstd,const T *g_scale,T *dgamma,T *dbeta)', '    LayerNormBackward(const int M,const int N,const T *dY,const T *X,const T *gamma,const T *dY_scale,const T *X_scale,const T *bias,T *dX)', '    LayerNormForward(const int M,const int N,const T *X,const T *scale,const T *bias,const T *gamma,const T *beta,T *Y)', '    LayerNormGradientOp(Args,...)', '    LayerNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    scale_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Layout.cpp', [], ['    self', '    THPLayout_init(PyObject *module)', '    THPLayout_New(at::Layout layout,const std::string & name)', '    THPLayout_repr(THPLayout *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Layout.h', [], ['    THPLayout_Check(PyObject *obj)', '    THPLayout_init(PyObject *module)', '    THPLayout_New(at::Layout layout,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Layout.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Layout.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\lbfgs.cpp', [], ['    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    _cubic_interpolate(double x1,double f1,double g1,double x2,double f2,double g2,c10::optional,double)', '    _strong_wolfe(const Function & obj_func,const std::vector & x,double t,const Tensor & d,double f,Tensor g,const Tensor & gtd,double c1,double c2,double tolerance_change,double max_ls)', '    if_container_equal(T lhs,T rhs)', '    operator==(const LBFGSOptions & lhs,const LBFGSOptions & rhs)', '    operator==(const LBFGSParamState & lhs,const LBFGSParamState & rhs)', '    _add_grad(const double step_size,const Tensor & update)', '    _clone_param', '    _directional_evaluate(const LossClosure & closure,const std::vector & x,double t,const Tensor & d)', '    _gather_flat_grad', '    _numel', '    _set_param(const std::vector & params_data)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    LBFGSOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\lbfgs.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\leaky-relu-operator-tester.h', ['    LeakyReLUOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    negativeSlope(float negativeSlope)', '    negativeSlope', '    negativeSlope_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\leaky-relu.c', [], ['    pytorch_qnnp_create_leaky_relu_nc_q8(size_t channels,float negative_slope,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *leaky_relu_out)', '    pytorch_qnnp_setup_leaky_relu_nc_q8(pytorch_qnnp_operator_t leaky_relu,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\leaky-relu.cc', [], ['    TEST(LEAKY_RELU_OP,zero_batch)', '    TEST(LEAKY_RELU_OP,unit_batch)', '    TEST(LEAKY_RELU_OP,unit_batch_with_qmin)', '    TEST(LEAKY_RELU_OP,unit_batch_with_qmax)', '    TEST(LEAKY_RELU_OP,unit_batch_with_negative_slope)', '    TEST(LEAKY_RELU_OP,unit_batch_with_input_scale)', '    TEST(LEAKY_RELU_OP,unit_batch_with_input_zero_point)', '    TEST(LEAKY_RELU_OP,unit_batch_with_output_scale)', '    TEST(LEAKY_RELU_OP,unit_batch_with_output_zero_point)', '    TEST(LEAKY_RELU_OP,small_batch)', '    TEST(LEAKY_RELU_OP,small_batch_with_input_stride)', '    TEST(LEAKY_RELU_OP,small_batch_with_output_stride)', '    TEST(LEAKY_RELU_OP,small_batch_with_input_and_output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\leaky_relu_op.cc', ['    GetLeakyReluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULeakyRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPULeakyReluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LeakyRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LeakyReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\leaky_relu_op.h', ['    final', '    LeakyReluOp'], ['    LeakyReluGradientOp(Args,...)', '    RunOnDevice', '    LeakyReluOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_adaption_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULearningRateAdaption', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LearningRateAdaption']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_adaption_op.h', ['    final'], ['    lr_update(int n,const float *grad,const float *effgrad,const float *lr,float *nlr,float lr_alpha,bool normalized_lr_adaption,Context *)', '    GetSingleArgument', '    LearningRateAdaptionOp(const OperatorDef & operator_def,Workspace *ws)', '    lr_alpha_', '    normalized_lr_adaption_', '    RunOnDevice', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_functors.h', ['    AlternateLearningRate', '    CompositeCosineLearningRate', '    CompositeCyclicalLearningRate', '    CompositeLearningRate', '    CompositeLearningRateItem', '    ConstantThenLinearWarmupLearningRate', '    ConstantWarmupLearningRate', '    CosineLearningRate', '    CyclicalLearningRate', '    ExpLearningRate', '    FixedLearningRate', '    GateLearningRate', '    HillLearningRate', '    InvLearningRate', '    LearningRateFunctor', '    LinearWarmupLearningRate', '    PieceWarmupLearningRate', '    PolyLearningRate', '    StepLearningRate'], ['    AlternateLearningRate(const int64_t active_period,const int64_t inactive_period,const bool active_first)', '    operator()(const int64_t iter)', '    CompositeCosineLearningRate(const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter,const T cosine_min_lr,const T cosine_max_lr,const int64_t cosine_period,const T consine_t_mult,const T cosine_lr_shrink)', '    operator()(const int64_t iter)', '    CompositeCyclicalLearningRate(const T base_lr,const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter,const T cyclical_max_lr,const int cyclical_step_size,const T cyclical_decay)', '    operator()(const int64_t iter)', '    CompositeLearningRate(const std::list)', '    operator()(const int64_t iter)', '    CompositeLearningRateItem(int64_t num_iter,float lr_scale,LearningRateFunctor *policy)', '    ConstantThenLinearWarmupLearningRate(const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter)', '    operator()(const int64_t iter)', '    ConstantWarmupLearningRate(const T multiplier,const int64_t num_iter)', '    operator()(const int64_t iter)', '    CosineLearningRate(const T min_lr,const T max_lr,const int64_t period,const T t_mult,const T lr_shrink)', '    operator()(const int64_t iter)', '    CyclicalLearningRate(const T base_lr,const T max_lr,const int stepsize,const T)', '    operator()(const int64_t iter)', '    ExpLearningRate(const T gamma)', '    operator()(const int64_t iter)', '    operator()(const int64_t)', '    GateLearningRate(const T multiplier_1,const T multiplier_2,const int64_t num_iter)', '    operator()(const int64_t iter)', '    HillLearningRate(const int64_t num_iter,const T start_multiplier,const T gamma,const T,const T end_multiplier)', '    operator()(const int64_t iter)', '    InvLearningRate(const T gamma,const T)', '    operator()(const int64_t iter)', '    operator()(const int64_t iter)', '    ~LearningRateFunctor', '    LinearWarmupLearningRate(const T start_multiplier,const int64_t num_iter)', '    operator()(const int64_t iter)', '    operator()(const int64_t iter)', '    PieceWarmupLearningRate(const T m1,const int64_t n1,const T m2,const int64_t n2,const T m3)', '    operator()(const int64_t iter)', '    PolyLearningRate(const T,const int64_t max_iter)', '    operator()(const int64_t iter)', '    StepLearningRate(const int stepsize,const T gamma)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULearningRate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LearningRate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_op.h', ['    final'], ['    createLearningRateFunctor(const string & policy,const string & arg_prefix)', '    LearningRateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\learning_rate_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDALearningRate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\LeftRight.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\LeftRight.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\LeftRight_test.cpp', ['    MyException'], ['    TEST(LeftRightTest,givenInt_whenWritingAndReading_thenChangesArePresent)', '    TEST(LeftRightTest,givenVector_whenWritingAndReading_thenChangesArePresent)', '    TEST(LeftRightTest,givenVector_whenWritingReturnsValue_thenValueIsReturned)', '    TEST(LeftRightTest,readsCanBeConcurrent)', '    TEST(LeftRightTest,writesCanBeConcurrentWithReads_readThenWrite)', '    TEST(LeftRightTest,writesCanBeConcurrentWithReads_writeThenRead)', '    TEST(LeftRightTest,writesCannotBeConcurrentWithWrites)', '    TEST(LeftRightTest,whenReadThrowsException_thenThrowsThrough)', '    TEST(LeftRightTest,whenWriteThrowsException_thenThrowsThrough)', '    TEST(LeftRightTest,givenInt_whenWriteThrowsExceptionOnFirstCall_thenResetsToOldState)', '    TEST(LeftRightTest,givenInt_whenWriteThrowsExceptionOnSecondCall_thenKeepsNewState)', '    TEST(LeftRightTest,givenVector_whenWriteThrowsException_thenResetsToOldState)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LegacyBridge.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp', [], ['    gather_cuda(const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    gather_out_cuda(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    masked_fill__cuda(Tensor & self,const Tensor & mask,Scalar value)', '    masked_fill__cuda(Tensor & self,const Tensor & mask,const Tensor & value)', '    masked_scatter__cuda(Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_select_cuda(const Tensor & self,const Tensor & mask)', '    masked_select_out_cuda(Tensor & result,const Tensor & self,const Tensor & mask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp', [], ['    argsort(const Tensor & self,int64_t dim,bool descending)', '    masked_scatter__cpu(Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_select_cpu(const Tensor & self,const Tensor & mask)', '    masked_select_out_cpu(Tensor & result,const Tensor & self,const Tensor & mask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\LegacyDeviceTypeInit.cpp', [], ['    getLegacyDeviceTypeInit', '    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\LegacyDeviceTypeInit.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LegacyNNDefinitions.cpp', [], ['    log_sigmoid(const Tensor & self)', '    log_sigmoid_out(Tensor & output,const Tensor & self)', '    multilabel_margin_loss(const Tensor & self,const Tensor & target,int64_t reduction)', '    multilabel_margin_loss_out(Tensor & output,const Tensor & self,const Tensor & target,int64_t reduction)', '    nll_loss(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_out(Tensor & output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_out(Tensor & output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    thnn_conv2d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    thnn_conv2d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    thnn_conv_depthwise2d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)', '    thnn_conv_depthwise2d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\LegacyTHFunctions.cpp', [], ['    $', '    $', '    $', '    allocator', '    infer_scalar_type(const TensorList & tl)', '    options(ScalarType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\LegacyTHFunctions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\LegacyTypeDispatch.cpp', [], ['    globalLegacyTypeDispatch']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\LegacyTypeDispatch.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\length_split_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsSplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsSplit']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\length_split_op.h', ['    final'], ['    LengthsSplitOp(Args,...)', '    RunOnDevice', '    ~LengthsSplitOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_pad_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsPad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsPad']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_pad_op.h', ['    LengthsPadOp'], ['    DoRunWithType', '    lengths_host_', '    LengthsPadOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_fused_4bit_rowwise_fp16_fake_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwiseFakeFP16NNPI']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_fused_4bit_rowwise_fp16_fake_op.h', ['    final'], ['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused4BitRowwiseFakeFP16Op(const OperatorDef & operator_def,Workspace *ws)', '    ~SparseLengthsFused4BitRowwiseFakeFP16Op']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_fused_8bit_rowwise_fp16_fake_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP32NNPI']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_fused_8bit_rowwise_fp16_fake_op.h', ['    final'], ['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused8BitRowwiseFakeFP16Op(const OperatorDef & operator_def,Workspace *ws)', '    static_assert(,)', '    ~SparseLengthsFused8BitRowwiseFakeFP16Op']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_fused_8bit_rowwise_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwise']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_fused_8bit_rowwise_ops.h', ['    SparseLengthsFused8BitRowwiseOp'], ['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused8BitRowwiseOp(Args,...)', '    static_assert(,)', '    ~SparseLengthsFused8BitRowwiseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_fused_nbit_rowwise_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused4BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwise']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_fused_nbit_rowwise_ops.h', ['    final', '    final'], ['    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SparseLengthsFusedNBitRowwiseOp(const OperatorDef & def,Workspace *ws)', '    SparseLengthsNBitRowwiseSparseOp(const OperatorDef & def,Workspace *ws)', '    static_assert(,)', '    ~SparseLengthsFusedNBitRowwiseOp', '    ~SparseLengthsNBitRowwiseSparseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsPositionalWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumGradient', '    FormatDoc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_ops.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_ops.h', ['    CPUSparseLengthsReductionOp'], ['    CPUSparseLengthsReductionOp(Args,...)', '    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    ~CPUSparseLengthsReductionOp', '    call']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\lengths_reducer_ops.h', ['    final'], ['    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    SparseLengthsReductionFakeFp16Op(Args,...)', '    ~SparseLengthsReductionFakeFp16Op', '    call']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_rowwise_8bit_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToRowwiseQuantized8Bits', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwise8BitQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedMean8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToRowwiseQuantized8Bits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Rowwise8BitQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedMean8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum8BitsRowwise']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_reducer_rowwise_8bit_ops.h', ['    FloatToRowwiseQuantized8BitsOp', '    Rowwise8BitQuantizedToFloatOp', '    SparseLengths8BitsRowwiseOp'], ['    FloatToRowwiseQuantized8BitsOp(Args,...)', '    RunOnDevice', '    ~FloatToRowwiseQuantized8BitsOp', '    Rowwise8BitQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~Rowwise8BitQuantizedToFloatOp', '    DoRunWithType', '    RunOnDevice', '    SparseLengths8BitsRowwiseOp(Args,...)', '    ~SparseLengths8BitsRowwiseOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_tile_op.cc', ['    GetLengthsTileGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTile', '    vector', '    GetGradientDefs', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_tile_op.h', ['    LengthsTileOp'], ['    lengths_host_', '    LengthsTileOp(Args,...)', '    RunOnDevice', '    ~LengthsTileOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_top_k_op.cc', ['    GetLengthsTopKGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTopKGradient', '    vector', '    cmp', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lengths_top_k_op.h', ['    LengthsTopKGradientOp', '    LengthsTopKOp'], ['    LengthsTopKGradientOp(Args,...)', '    RunOnDevice', '    LengthsTopKOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Lerp.cpp', [], ['    lerp_cpu_scalar(const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_scalar_(Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_scalar_out(Tensor & result,const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_tensor(const Tensor & self,const Tensor & end,const Tensor & weight)', '    lerp_cpu_tensor_(Tensor & self,const Tensor & end,const Tensor & weight)', '    lerp_cpu_tensor_out(Tensor & result,const Tensor & self,const Tensor & end,const Tensor & weight)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Lerp.h', [], ['    lerp_kernel_scalar_weight', '    lerp_kernel_scalar_weight', '    operator=', '    lerp_kernel_tensor_weight', '    lerp_kernel_tensor_weight', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\LerpKernel.cpp', [], ['    lerp_kernel_scalar(Tensor & ret,const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_kernel_tensor(Tensor & ret,const Tensor & self,const Tensor & end,const Tensor & weights)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\leveldb.cc', ['    C10FlagParser_caffe2_leveldb_block_size', '    LevelDB', '    LevelDBCursor', '    LevelDBTransaction'], ['    C10FlagParser_caffe2_leveldb_block_size(const std::string & content)', '    Close', '    LevelDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    key', '    LevelDBCursor(leveldb::DB *db)', '    Next', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~LevelDBCursor', '    Commit', '    LevelDBTransaction(leveldb::DB *db)', '    Put(const string & key,const string & value)', '    ~LevelDBTransaction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\lexer.cpp', [], ['    kindToString(int kind)', '    sharedParserData', '    stringToKind(const std::string & str)', '    isBinary(int kind,int *prec)', '    isUnary(int kind,int *prec)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\lexer.h', [], ['    cur', '    expect(int kind)', '    expected(what,cur)', '    lex', '    lexRaw(bool whitespace_token)', '    lookahead', '    kindToString(int kind)', '    sharedParserData', '    stringToKind(const std::string & str)', '    back', '    emplace_back', '    get', '    insert', '    size', '    Lexer(const std::shared_ptr & source)', '    next', '    nextIf(int kind)', '    reportError(what,cur)', '    isBinary(int kind,int *prec)', '    isblank(int n)', '    isCharCount(char c,const std::string & str,size_t start,int len)', '    isNumber(const std::string & str,size_t start,size_t *len)', '    isRightAssociative(int kind)', '    isString(const std::string & str,size_t start,size_t *len)', '    isTypeComment(const std::string & str,size_t pos)', '    isUnary(int kind,int *prec)', '    match(const std::string & str,size_t pos,bool continuation,bool whitespace_token,int *kind,size_t *start,size_t *len)', '    SharedParserData', '    validIdent(size_t i,char n)', '    kindString', '    text', '    Token(int kind,SourceRange range)', '    insert(const char *str,int tok)', '    TokenTrie']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\src\\libopencl.c', [], ['    access_file(const char *filename)', '    clBuildProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCompileProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_headers,const cl_program *input_headers,const char **header_include_names,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCreateBuffer(cl_context context,cl_mem_flags flags,size_t size,void *host_ptr,cl_int *errcode_ret)', '    clCreateCommandQueue(cl_context context,cl_device_id device,cl_command_queue_properties properties,cl_int *errcode_ret)', '    clCreateContext(const cl_context_properties *properties,cl_uint num_devices,const cl_device_id *devices,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateContextFromType(const cl_context_properties *properties,cl_device_type device_type,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateFromGLBuffer(cl_context context,cl_mem_flags flags,cl_GLuint bufobj,int *errcode_ret)', '    clCreateFromGLRenderbuffer(cl_context context,cl_mem_flags flags,cl_GLuint renderbuffer,cl_int *errcode_ret)', '    clCreateFromGLTexture(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture2D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture3D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateImage(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,const cl_image_desc *image_desc,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage2D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_row_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage3D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_depth,size_t image_row_pitch,size_t image_slice_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateKernel(cl_program program,const char *kernel_name,cl_int *errcode_ret)', '    clCreateKernelsInProgram(cl_program program,cl_uint num_kernels,cl_kernel *kernels,cl_uint *num_kernels_ret)', '    clCreateProgramWithBinary(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const size_t *lengths,const unsigned char **binaries,cl_int *binary_status,cl_int *errcode_ret)', '    clCreateProgramWithBuiltInKernels(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *kernel_names,cl_int *errcode_ret)', '    clCreateProgramWithSource(cl_context context,cl_uint count,const char **strings,const size_t *lengths,cl_int *errcode_ret)', '    clCreateSampler(cl_context context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *errcode_ret)', '    clCreateSubBuffer(cl_mem buffer,cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *errcode_ret)', '    clCreateSubDevices(cl_device_id in_device,const cl_device_partition_property *properties,cl_uint num_devices,cl_device_id *out_devices,cl_uint *num_devices_ret)', '    clCreateUserEvent(cl_context context,cl_int *errcode_ret)', '    clEnqueueAcquireGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueBarrier(cl_command_queue command_queue)', '    clEnqueueBarrierWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBuffer(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,size_t src_offset,size_t dst_offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferRect(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,const size_t *src_origin,const size_t *dst_origin,const size_t *region,size_t src_row_pitch,size_t src_slice_pitch,size_t dst_row_pitch,size_t dst_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferToImage(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_image,size_t src_offset,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImage(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_image,const size_t *src_origin,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImageToBuffer(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_buffer,const size_t *src_origin,const size_t *region,size_t dst_offset,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillBuffer(cl_command_queue command_queue,cl_mem buffer,const void *pattern,size_t pattern_size,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillImage(cl_command_queue command_queue,cl_mem image,const void *fill_color,const size_t *origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMapBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_map,cl_map_flags map_flags,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMapImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_map,cl_map_flags map_flags,const size_t *origin,const size_t *region,size_t *image_row_pitch,size_t *image_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMarker(cl_command_queue command_queue,cl_event *event)', '    clEnqueueMarkerWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMigrateMemObjects(cl_command_queue command_queue,cl_uint num_mem_objects,const cl_mem *mem_objects,cl_mem_migration_flags flags,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNativeKernel(cl_command_queue command_queue,void (*) (void *) user_func,void *args,size_t cb_args,cl_uint num_mem_objects,const cl_mem *mem_list,const void **args_mem_loc,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNDRangeKernel(cl_command_queue command_queue,cl_kernel kernel,cl_uint work_dim,const size_t *global_work_offset,const size_t *global_work_size,const size_t *local_work_size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,size_t offset,size_t size,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_read,const size_t *origin,const size_t *region,size_t row_pitch,size_t slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReleaseGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueTask(cl_command_queue command_queue,cl_kernel kernel,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueUnmapMemObject(cl_command_queue command_queue,cl_mem memobj,void *mapped_ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWaitForEvents(cl_command_queue command_queue,cl_uint num_events,const cl_event *event_list)', '    clEnqueueWriteBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,size_t offset,size_t size,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_write,const size_t *origin,const size_t *region,size_t input_row_pitch,size_t input_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clFinish(cl_command_queue command_queue)', '    clFlush(cl_command_queue command_queue)', '    clGetCommandQueueInfo(cl_command_queue command_queue,cl_command_queue_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetContextInfo(cl_context context,cl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetDeviceIDs(cl_platform_id platform,cl_device_type device_type,cl_uint num_entries,cl_device_id *devices,cl_uint *num_devices)', '    clGetDeviceInfo(cl_device_id device,cl_device_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventInfo(cl_event event,cl_event_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventProfilingInfo(cl_event event,cl_profiling_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetExtensionFunctionAddress(const char *func_name)', '    clGetExtensionFunctionAddressForPlatform(cl_platform_id platform,const char *func_name)', '    clGetGLContextInfoKHR(const cl_context_properties *properties,cl_gl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetGLObjectInfo(cl_mem memobj,cl_gl_object_type *gl_object_type,cl_GLuint *gl_object_name)', '    clGetGLTextureInfo(cl_mem memobj,cl_gl_texture_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetImageInfo(cl_mem image,cl_image_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelArgInfo(cl_kernel kernel,cl_uint arg_indx,cl_kernel_arg_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelInfo(cl_kernel kernel,cl_kernel_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelWorkGroupInfo(cl_kernel kernel,cl_device_id device,cl_kernel_work_group_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetMemObjectInfo(cl_mem memobj,cl_mem_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetPlatformIDs(cl_uint num_entries,cl_platform_id *platforms,cl_uint *num_platforms)', '    clGetPlatformInfo(cl_platform_id platform,cl_platform_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramBuildInfo(cl_program program,cl_device_id device,cl_program_build_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramInfo(cl_program program,cl_program_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSamplerInfo(cl_sampler sampler,cl_sampler_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSupportedImageFormats(cl_context context,cl_mem_flags flags,cl_mem_object_type image_type,cl_uint num_entries,cl_image_format *image_formats,cl_uint *num_image_formats)', '    clLinkProgram(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_programs,const cl_program *input_programs,void (*) (cl_program, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clReleaseCommandQueue(cl_command_queue command_queue)', '    clReleaseContext(cl_context context)', '    clReleaseDevice(cl_device_id device)', '    clReleaseEvent(cl_event event)', '    clReleaseKernel(cl_kernel kernel)', '    clReleaseMemObject(cl_mem memobj)', '    clReleaseProgram(cl_program program)', '    clReleaseSampler(cl_sampler sampler)', '    clRetainCommandQueue(cl_command_queue command_queue)', '    clRetainContext(cl_context context)', '    clRetainDevice(cl_device_id device)', '    clRetainEvent(cl_event event)', '    clRetainKernel(cl_kernel kernel)', '    clRetainMemObject(cl_mem memobj)', '    clRetainProgram(cl_program program)', '    clRetainSampler(cl_sampler sampler)', '    clSetEventCallback(cl_event event,cl_int command_exec_callback_type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    clSetKernelArg(cl_kernel kernel,cl_uint arg_index,size_t arg_size,const void *arg_value)', '    clSetMemObjectDestructorCallback(cl_mem memobj,void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    clSetUserEventStatus(cl_event event,cl_int execution_status)', '    clUnloadCompiler', '    clUnloadPlatformCompiler(cl_platform_id platform)', '    clWaitForEvents(cl_uint num_events,const cl_event *event_list)', '    get_libopencl_path(char **cl_path)', '    open_libopencl_so', '    stubOpenclReset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\libopencl.h', [], ['    get_libopencl_path(char **cl_path)', '    open_libopencl_so', '    stubOpenclReset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\libshm.h', ['    THManagedMapAllocator', '    THManagedMapAllocatorInit'], ['    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr &)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    close', '    manager_handle', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    ~THManagedMapAllocator', '    THManagedMapAllocatorInit(const char *manager_handle,const char *filename)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm_windows\\libshm.h', ['    THManagedMapAllocator'], ['    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr &)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    manager_handle', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\ios\\LibTorch.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libvulkan-stub\\src\\libvulkan-stub.c', [], ['    vulkanSymbolWrapperInit(PFN_vkGetInstanceProcAddr getInstanceProcAddr)', '    vulkanSymbolWrapperInitLoader', '    vulkanSymbolWrapperInstanceProcAddr', '    vulkanSymbolWrapperLoadCoreDeviceSymbols(VkDevice device)', '    vulkanSymbolWrapperLoadCoreInstanceSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadCoreSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadDeviceSymbol(VkDevice device,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperLoadGetPhysicalDeviceProperties2ExtensionSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadGlobalSymbols', '    vulkanSymbolWrapperLoadInstanceSymbol(VkInstance instance,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperReset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libvulkan-stub\\include\\libvulkan-stub.h', [], ['    vulkanSymbolWrapperInit(PFN_vkGetInstanceProcAddr getInstanceProcAddr)', '    vulkanSymbolWrapperInitLoader', '    vulkanSymbolWrapperInstanceProcAddr', '    vulkanSymbolWrapperLoadCoreDeviceSymbols(VkDevice device)', '    vulkanSymbolWrapperLoadCoreInstanceSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadCoreSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadDeviceSymbol(VkDevice device,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperLoadGetPhysicalDeviceProperties2ExtensionSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadGlobalSymbols', '    vulkanSymbolWrapperLoadInstanceSymbol(VkInstance instance,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperReset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lift_closures.cpp', [], ['    env', '    liftClosure(Node *closure)', '    liftClosures(Block *block)', '    liftClosures(const std::shared_ptr & to_clean)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lift_closures.h', [], ['    liftClosures(const std::shared_ptr & to_clean)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\mkl\\Limits.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Linear.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\linear.cpp', [], ['    BilinearImpl(const BilinearOptions & options_)', '    forward(const Tensor & input1,const Tensor & input2)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    FlattenImpl(const FlattenOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    LinearImpl(const LinearOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Linear.cpp', [], ['    mkldnn_linear(const Tensor & self,const Tensor & weight,const Tensor & bias)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Linear.cpp', [], ['    sumproduct_pair(const Tensor & left_,const Tensor & right_,IntArrayRef sum_dims_,bool keepdim)', '    _trilinear(const Tensor & i1_,const Tensor & i2_,const Tensor & i3_,IntArrayRef expand1_,IntArrayRef expand2_,IntArrayRef expand3_,IntArrayRef sumdim_,int64_t unroll_dim)', '    bilinear(const Tensor & input1,const Tensor & input2,const Tensor & weight,const Tensor & bias)', '    einsum(std::string eqn,TensorList tensors)', '    linear(const Tensor & input,const Tensor & weight,const Tensor & bias)', '    tensordot(const Tensor & input1,const Tensor & input2,IntArrayRef dims1,IntArrayRef dims2)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\linear.cpp', [], ['    BilinearOptions(int64_t in1_features,int64_t in2_features,int64_t out_features)', '    LinearOptions(int64_t in_features,int64_t out_features)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\linear.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\linear.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\linear.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Linear.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LinearAlgebra.cpp', [], ['    _chain_matmul_general(TensorList matrices,std::vector,int64_t i,int64_t j)', '    _chain_matmul_three_matrices(TensorList matrices)', '    _lu_det_P_diag_U(const Tensor & self)', '    _matrix_rank_helper(const Tensor & self,bool symmetric)', '    bmm_out_or_baddbmm_(Tensor & self_or_result,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha,bool is_bmm_out)', '    check_1d(const Tensor & t,const char *arg,const char *fn)', '    baddbmm__cpu(Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    bmm_cpu(const Tensor & self,const Tensor & mat2)', '    bmm_out_cpu(Tensor & result,const Tensor & batch1,const Tensor & batch2)', '    chain_matmul(TensorList matrices)', '    dot_out(Tensor & result,const Tensor & self,const Tensor & tensor)', '    frobenius_norm(const Tensor & self)', '    frobenius_norm(const Tensor & self,IntArrayRef dim,bool keepdim)', '    frobenius_norm_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim)', '    matmul(c10::optional out_opt,const Tensor & tensor1,const Tensor & tensor2)', '    matmul(const Tensor & tensor1,const Tensor & tensor2)', '    matmul_out(Tensor & result,const Tensor & tensor1,const Tensor & tensor2)', '    matrix_power(const Tensor & a,int64_t n)', '    addr(const Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    addr_(Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    addr_out(Tensor & result,const Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    baddbmm_cpu(const Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    baddbmm_cpu_kernel(const Tensor & result,const Tensor & self,const Tensor & mat2,Scalar beta_,Scalar alpha_)', '    baddbmm_out_cpu(Tensor & result,const Tensor & self_,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    det(const Tensor & self)', '    ger(const Tensor & self,const Tensor & vec2)', '    ger_out(Tensor & result,const Tensor & self,const Tensor & vec2)', '    logdet(const Tensor & self)', '    matrix_rank(const Tensor & self,double tol,bool symmetric)', '    matrix_rank(const Tensor & self,bool symmetric)', '    pinverse(const Tensor & self,double rcond)', '    slogdet(const Tensor & self)', '    nuclear_norm(const Tensor & self,bool keepdim)', '    nuclear_norm(const Tensor & self,IntArrayRef dim,bool keepdim)', '    nuclear_norm_out(Tensor & result,const Tensor & self,bool keepdim)', '    nuclear_norm_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkl\\LinearAlgebra.cpp', [], ['    baddbmm_mkl_template(const Tensor & res,const Tensor & mat1,const Tensor & mat2,Scalar beta_,Scalar alpha_)', '    gemm_batched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float **A,const int lda,const float **B,const int ldb,const float beta,float **C,const int ldc)', '    gemm_batched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const double alpha,const double **A,const int lda,const double **B,const int ldb,const double beta,double **C,const int ldc)', '    _baddbmm_mkl_(Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LinearAlgebraUtils.h', [], ['    _compute_geometry_for_Q(const Tensor & input,bool some)', '    _create_U_S_VT(const Tensor & input,bool some,bool compute_uv)', '    _move_to_end(const Tensor & self,IntArrayRef axes)', '    _get_epsilon(const ScalarType & sc_type)', '    _linalg_broadcast_batch_dims(const Tensor & arg1,const Tensor & arg2,const char *name)', '    batchCheckErrors(std::vector & infos,const char *name,bool allow_singular)', '    batchCheckErrors(const Tensor & infos,const char *name,bool allow_singular)', '    batchCount(const Tensor & batched_matrices)', '    checkAllSameDim(TensorList tensors,int64_t dim)', '    cloneBatchedColumnMajor(const Tensor & src)', '    linearSolveCheckInputs(const Tensor & self,const Tensor & A,const char *name)', '    matrixStride(const Tensor & batched_matrices)', '    singleCheckErrors(int64_t info,const char *name,bool allow_singular)', '    squareCheckInputs(const Tensor & self)', '    same_stride_to(const Tensor & original_tensor,const at::TensorOptions & options)', '    empty_strided', '    device', '    size', '    to', '    transpose']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\List.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\List_inl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\List_test.cpp', [], ['    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingEmpty_thenReturnsTrue)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingEmpty_thenReturnsFalse)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingSize_thenReturnsZero)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingClear_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,whenCallingGetWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenCallingGetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithExistingPosition_thenListElementBecomesInvalid)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingCopyingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_IValueBasedList,whenCallingMovingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_IValueBasedList,whenCallingCopyingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingMovingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingAccessOperatorWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenAssigningToAccessOperatorWithExistingPosition_thenSetsElement)', '    TEST(ListTest_IValueBasedList,whenAssigningToAccessOperatorFromAccessOperator_thenSetsElement)', '    TEST(ListTest_IValueBasedList,whenSwappingFromAccessOperator_thenSwapsElements)', '    TEST(ListTest_IValueBasedList,whenCallingAccessOperatorWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingInsertOnIteratorWithLValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertOnIteratorWithRValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertWithLValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertWithRValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithLValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithRValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithConstructorArg_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingPushBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingPushBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithConstructorArg_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenIterating_thenBeginIsEnd)', '    TEST(ListTest_IValueBasedList,whenIterating_thenFindsElements)', '    TEST(ListTest_IValueBasedList,whenIteratingWithForeach_thenFindsElements)', '    TEST(ListTest_IValueBasedList,givenOneElementList_whenErasing_thenListIsEmpty)', '    TEST(ListTest_IValueBasedList,givenList_whenErasing_thenReturnsIterator)', '    TEST(ListTest_IValueBasedList,givenList_whenErasingFullRange_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,whenCallingReserve_thenDoesntCrash)', '    TEST(ListTest_IValueBasedList,whenCopyConstructingList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenCopyAssigningList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenCopyingList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenMoveConstructingList_thenNewIsCorrect)', '    TEST(ListTest_IValueBasedList,whenMoveAssigningList_thenNewIsCorrect)', '    TEST(ListTest_IValueBasedList,whenMoveConstructingList_thenOldIsEmpty)', '    TEST(ListTest_IValueBasedList,whenMoveAssigningList_thenOldIsEmpty)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPostfixDecrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPrefixDecrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenIncreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenDecreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAdding_thenReturnsNewIterator)', '    TEST(ListTest_IValueBasedList,givenIterator_whenSubtracting_thenReturnsNewIterator)', '    TEST(ListTest_IValueBasedList,givenIterator_whenCalculatingDifference_thenReturnsCorrectNumber)', '    TEST(ListTest_IValueBasedList,givenEqualIterators_thenAreEqual)', '    TEST(ListTest_IValueBasedList,givenDifferentIterators_thenAreNotEqual)', '    TEST(ListTest_IValueBasedList,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAssigningNewValue_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAssigningNewValueFromIterator_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenSwappingValuesFromIterator_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenOneElementList_whenCallingPopBack_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingResize_thenResizesAndSetsEmptyValue)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingResizeWithValue_thenResizesAndSetsValue)', '    TEST(ListTest_IValueBasedList,isReferenceType)', '    TEST(ListTest_IValueBasedList,copyHasSeparateStorage)', '    TEST(ListTest_IValueBasedList,givenEqualLists_thenIsEqual)', '    TEST(ListTest_IValueBasedList,givenDifferentLists_thenIsNotEqual)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingEmpty_thenReturnsTrue)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingEmpty_thenReturnsFalse)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingSize_thenReturnsZero)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingClear_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenCallingGetWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingGetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingExtractWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingExtractWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingCopyingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingMovingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingCopyingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingMovingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingAccessOperatorWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenAssigningToAccessOperatorWithExistingPosition_thenSetsElement)', '    TEST(ListTest_NonIValueBasedList,whenAssigningToAccessOperatorFromAccessOperator_thenSetsElement)', '    TEST(ListTest_NonIValueBasedList,whenSwappingFromAccessOperator_thenSwapsElements)', '    TEST(ListTest_NonIValueBasedList,whenCallingAccessOperatorWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertOnIteratorWithLValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertOnIteratorWithRValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertWithLValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertWithRValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithLValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithRValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithConstructorArg_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingPushBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingPushBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithConstructorArg_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenIterating_thenBeginIsEnd)', '    TEST(ListTest_NonIValueBasedList,whenIterating_thenFindsElements)', '    TEST(ListTest_NonIValueBasedList,whenIteratingWithForeach_thenFindsElements)', '    TEST(ListTest_NonIValueBasedList,givenOneElementList_whenErasing_thenListIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenList_whenErasing_thenReturnsIterator)', '    TEST(ListTest_NonIValueBasedList,givenList_whenErasingFullRange_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenCallingReserve_thenDoesntCrash)', '    TEST(ListTest_NonIValueBasedList,whenCopyConstructingList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenCopyAssigningList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenCopyingList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenMoveConstructingList_thenNewIsCorrect)', '    TEST(ListTest_NonIValueBasedList,whenMoveAssigningList_thenNewIsCorrect)', '    TEST(ListTest_NonIValueBasedList,whenMoveConstructingList_thenOldIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenMoveAssigningList_thenOldIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPostfixDecrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPrefixDecrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenIncreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenDecreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAdding_thenReturnsNewIterator)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenSubtracting_thenReturnsNewIterator)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenCalculatingDifference_thenReturnsCorrectNumber)', '    TEST(ListTest_NonIValueBasedList,givenEqualIterators_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,givenDifferentIterators_thenAreNotEqual)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAssigningNewValue_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAssigningNewValueFromIterator_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenSwappingValuesFromIterator_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenOneElementList_whenCallingPopBack_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingResize_thenResizesAndSetsEmptyValue)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingResizeWithValue_thenResizesAndSetsValue)', '    TEST(ListTest_NonIValueBasedList,isReferenceType)', '    TEST(ListTest_NonIValueBasedList,copyHasSeparateStorage)', '    TEST(ListTest_NonIValueBasedList,givenEqualLists_thenIsEqual)', '    TEST(ListTest_NonIValueBasedList,givenDifferentLists_thenIsNotEqual)', '    TEST(ListTest_NonIValueBasedList,isChecksIdentity)', '    TEST(ListTest_NonIValueBasedList,sameValueDifferentStorage_thenIsReturnsFalse)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\listwise_l2r_op.cc', ['    GetLambdaRankNdcgGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULambdaRankNdcg', '    CAFFE_ANONYMOUS_VARIABLE_CPULambdaRankNdcgGradient', '    arg_sort(const TDATA *data,TIDX *idx,const size_t N,bool reverse)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LambdaRankNdcg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LambdaRankNdcgGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    LambdaRankNdcgSession(int start_index,int end_index,const Tensor & y,const Tensor & r,Tensor **dy)', '    ResizeInvLogITensor(int size)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\listwise_l2r_op.h', ['    final', '    final'], ['    ComputeDiscounts(int *,int)', '    GetSingleArgument', '    LambdaRankNdcgGradientOp(Args,...)', '    LambdaRankNdcgOp(Args,...)', '    LambdaRankNdcgSession(int start_index,int end_index,const Tensor & y,const Tensor & r,Tensor **dy)', '    ResizeInvLogITensor(int)', '    RunOnDevice', '    ~LambdaRankNdcgGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\lite_interpreter_model_load.cc', ['    C10FlagParser_model'], ['    main(int argc,char **argv)', '    C10FlagParser_model(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\liveness.cpp', [], ['    dump(const std::unordered_map,std::vector)', '    dump(const std::vector & set)', '    processBlock(Block *b,SparseBitVector liveness)', '    toSparseBitVector(at::ArrayRef values)', '    toValueVector(const SparseBitVector & sbv)', '    LivenessAnalyzer(std::shared_ptr graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\liveness.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\llvm_codegen.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\llvm_codegen.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\llvm_jit.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\llvm_jit.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\llvmMathExtras.h', [], ['    _BitScanForward(unsigned long *_Index,unsigned long _Mask)', '    _BitScanForward64(unsigned long *_Index,unsigned __int64 _Mask)', '    _BitScanReverse(unsigned long *_Index,unsigned long _Mask)', '    _BitScanReverse64(unsigned long *_Index,unsigned __int64 _Mask)', '    AbsoluteDifference(T X,T Y)', '    alignAddr(const void *Addr,size_t Alignment)', '    alignDown(uint64_t Value,uint64_t Align,uint64_t Skew)', '    alignmentAdjustment(const void *Ptr,size_t Alignment)', '    alignTo(uint64_t Value,uint64_t Align,uint64_t Skew)', '    alignTo(uint64_t Value)', '    BitsToDouble(uint64_t Bits)', '    BitsToFloat(uint32_t Bits)', '    countLeadingOnes(T Value,ZeroBehavior ZB)', '    countLeadingZeros(T Val,ZeroBehavior ZB)', '    countPopulation(T Value)', '    countTrailingOnes(T Value,ZeroBehavior ZB)', '    countTrailingZeros(T Val,ZeroBehavior ZB)', '    divideCeil(uint64_t Numerator,uint64_t Denominator)', '    DoubleToBits(double Double)', '    findFirstSet(T Val,ZeroBehavior ZB)', '    findLastSet(T Val,ZeroBehavior ZB)', '    FloatToBits(float Float)', '    GreatestCommonDivisor64(uint64_t A,uint64_t B)', '    Hi_32(uint64_t Value)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isIntN(unsigned N,int64_t x)', '    isMask_32(uint32_t Value)', '    isMask_64(uint64_t Value)', '    isPowerOf2_32(uint32_t Value)', '    isPowerOf2_64(uint64_t Value)', '    isShiftedInt(int64_t x)', '    isShiftedMask_32(uint32_t Value)', '    isShiftedMask_64(uint64_t Value)', '    isShiftedUInt(uint64_t x)', '    isUInt(uint64_t X)', '    isUInt(uint64_t x)', '    isUInt(uint64_t x)', '    isUInt(uint64_t x)', '    isUInt(uint64_t X)', '    isUIntN(unsigned N,uint64_t x)', '    Lo_32(uint64_t Value)', '    Log2(double Value)', '    Log2_32(uint32_t Value)', '    Log2_32_Ceil(uint32_t Value)', '    Log2_64(uint64_t Value)', '    Log2_64_Ceil(uint64_t Value)', '    Make_64(uint32_t High,uint32_t Low)', '    maskLeadingOnes(unsigned N)', '    maskLeadingZeros(unsigned N)', '    maskTrailingOnes(unsigned N)', '    maskTrailingZeros(unsigned N)', '    maxIntN(int64_t N)', '    maxUIntN(uint64_t N)', '    MinAlign(uint64_t A,uint64_t B)', '    minIntN(int64_t N)', '    NextPowerOf2(uint64_t A)', '    OffsetToAlignment(uint64_t Value,uint64_t Align)', '    PowerOf2Ceil(uint64_t A)', '    PowerOf2Floor(uint64_t A)', '    reverseBits(T Val)', '    SaturatingAdd(T X,T Y,bool *ResultOverflowed)', '    SaturatingMultiply(T X,T Y,bool *ResultOverflowed)', '    SaturatingMultiplyAdd(T X,T Y,T A,bool *ResultOverflowed)', '    SignExtend32(uint32_t X)', '    SignExtend32(uint32_t X,unsigned B)', '    SignExtend64(uint64_t x)', '    SignExtend64(uint64_t X,unsigned B)', '    count(T Val,ZeroBehavior ZB)', '    count(T Val,ZeroBehavior)', '    count(T Value)', '    count(T Value)', '    count(T Val,ZeroBehavior ZB)', '    count(T Val,ZeroBehavior)', '    static_assert(Align,)', '    max', '    max', '    memcpy', '    min']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\lmdb.cc', ['    final', '    LMDB', '    LMDBCursor'], ['    MDB_CHECK(int mdb_status)', '    Put(const string & key,const string & value)', '    Commit', '    LMDBTransaction(MDB_env *mdb_env)', '    ~LMDBTransaction', '    Close', '    LMDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    ~LMDB', '    key', '    LMDBCursor(MDB_env *mdb_env)', '    Next', '    Seek(const string & key)', '    SeekLMDB(MDB_cursor_op op)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~LMDBCursor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\load_save_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCheckpoint', '    CAFFE_ANONYMOUS_VARIABLE_CPUDBExists', '    CAFFE_ANONYMOUS_VARIABLE_CPULoad', '    CAFFE_ANONYMOUS_VARIABLE_CPUSave', '    CAFFE_ANONYMOUS_VARIABLE_CPUSnapshot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Checkpoint', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DBExists', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Load', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Save', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Snapshot', '    LoadTensorInference(const OperatorDef & def,const vector &)', '    SetCurrentDevice(BlobProto *proto)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\load_save_op.h', ['    final', '    final', '    final', '    final'], ['    FormatString(const string & pattern,Ts,...)', '    CheckpointOp(const OperatorDef & operator_def,Workspace *ws)', '    DBExistsOp(const OperatorDef & operator_def,Workspace *ws)', '    extract(int db_id,Cursor *cursor,std::unordered_map *blob_states,int *total_loaded_blobs)', '    extractAll(int db_id,Cursor *cursor,std::unordered_map *blob_states,int *total_loaded_blobs)', '    extractFrom(int db_id,Cursor *cursor,const vector & outputs,std::unordered_map *blob_states,int *total_loaded_blobs)', '    LoadOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SaveOp(const OperatorDef & operator_def,Workspace *ws)', '    SetCurrentDevice(BlobProto *proto)', '    CreateBlob', '    RootFolder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\load_save_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACheckpoint', '    CAFFE_ANONYMOUS_VARIABLE_CUDALoad', '    CAFFE_ANONYMOUS_VARIABLE_CUDASave']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\load_save_op_util.cc', [], ['    buildBlobNameFromDbKey(const std::string & dbKey,const std::string & strip_prefix,const std::string & add_prefix)', '    ProcessBlob(Blob *blob,const BlobProto & proto,std::unordered_map *blob_states_ptr,const std::string & key,int *loaded_blobs)', '    validateBlobStates(const std::unordered_map & blob_states)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\load_save_op_util.h', [], ['    buildBlobNameFromDbKey(const std::string & dbKey,const std::string & strip_prefix,const std::string & add_prefix)', '    ProcessBlob(Blob *blob,const BlobProto & proto,std::unordered_map *blob_states_ptr,const std::string & key,int *loaded_blobs)', '    validateBlobStates(const std::unordered_map & blob_states)', '    BlobState(int64_t total_size,int64_t current_size,bool is_tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\local_response_normalization_op.cc', ['    GetLRNGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULRN', '    CAFFE_ANONYMOUS_VARIABLE_CPULRNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LRN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LRNGradient', '    vector', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\local_response_normalization_op.cc', ['    final', '    final'], ['    IDEEPLRNGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPLRNOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPLRNGradientOp', '    ~IDEEPLRNOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\local_response_normalization_op.h', ['    final', '    final', '    LRNOpBase'], ['    local_scale_tensor_', '    local_scale_tensor_', '    LRNGradientOp(Args,...)', '    LRNOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    GetSingleArgument', '    LRNOpBase(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\local_response_normalization_op_cudnn.cc', ['    final', '    final'], ['    CuDNNLRNGradientOp(Args,...)', '    CuDNNLRNOp(Args,...)', '    ~CuDNNLRNGradientOp', '    ~CuDNNLRNOp', '    DoRunWithType', '    RunOnDevice', '    DoRunWithType', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\LocalDispatchKeySet.cpp', ['    C10FlagParser_disable_variable_dispatch'], ['    tls_is_dispatch_key_excluded(DispatchKey x)', '    tls_is_dispatch_key_included(DispatchKey x)', '    tls_local_dispatch_key_set', '    tls_set_dispatch_key_excluded(DispatchKey x,bool desired_state)', '    tls_set_dispatch_key_included(DispatchKey x,bool desired_state)', '    C10FlagParser_disable_variable_dispatch(const std::string & content)', '    ExcludeDispatchKeyGuard(DispatchKey x)', '    ~ExcludeDispatchKeyGuard', '    IncludeDispatchKeyGuard(DispatchKey x)', '    ~IncludeDispatchKeyGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\LocalDispatchKeySet.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op.cc', ['    GetLocallyConnectedGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULC', '    CAFFE_ANONYMOUS_VARIABLE_CPULC1D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULC2D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULC3D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULCGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LCGradient', '    LCDocGenerator(const char *dim)', '    GetGradientDefs', '    vector', '    vector', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op.h', ['    final', '    final'], ['    bias_multiplier_', '    bias_multiplier_', '    column_buffer_', '    column_buffer_', '    column_transposed_buffer_', '    column_transposed_buffer_', '    dY_transposed_buffer_', '    LocallyConnectedGradientOp(Args,...)', '    LocallyConnectedOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *output_buffer)', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    Y_transposed_buffer_', '    ~LocallyConnectedGradientOp', '    ~LocallyConnectedOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDALC', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC1D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC2D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC3D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALCGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op_impl.h', [], ['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    RunOnDeviceWithOrderNHWCImpl(shape,X_data,filter_data,bias_data,Y_data,& column_buffer_,& column_transposed_buffer_,& Y_transposed_buffer_)', '    SetBiasMultiplier(shape,& bias_multiplier_)', '    ComputePads', '    SetOutputSize', '    SetOutputSize(X,Y,shape)', '    SetColumnBufferShape', '    SetColumnBufferShape(shape,shape,shape,output_image_dims,order_,& shape,& shape,& shape,& shape)', '    SetYBufferShape', '    SetYBufferShape(shape,shape,shape,order_,& shape,& shape,& shape)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    Col2Im', '    Col2ImNd', '    Gemm', '    GemmStridedBatched', '    Gemv', '    Im2Col', '    Im2ColNd', '    Transpose', '    Resize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op_util.cc', [], ['    SetColumnBufferShape(const int N,const int kernel_size,const int output_image_size,const std::vector & output_image_dims,const StorageOrder order,std::vector *column_slice_dims,std::vector *column_dims,std::vector *column_transposed_dims,std::vector *column_axes)', '    SetYBufferShape(const int N,const int M,const int output_image_size,const StorageOrder order,std::vector *Y_dims,std::vector *Y_transposed_dims,std::vector *Y_axes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\locally_connected_op_util.h', [], ['    SetColumnBufferShape(const int N,const int kernel_size,const int output_image_size,const std::vector & output_image_dims,const StorageOrder order,std::vector *column_slice_dims,std::vector *column_dims,std::vector *column_transposed_dims,std::vector *column_axes)', '    SetYBufferShape(const int N,const int M,const int output_image_size,const StorageOrder order,std::vector *Y_dims,std::vector *Y_transposed_dims,std::vector *Y_axes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\log.h', [], ['    pytorch_qnnp_log_debug(const char *format,...)', '    pytorch_qnnp_log_error(const char *format,...)', '    pytorch_qnnp_log_fatal(const char *format,...)', '    pytorch_qnnp_log_info(const char *format,...)', '    pytorch_qnnp_log_warning(const char *format,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\log_op.cc', ['    GetLogGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULog', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Log', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\log_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\log_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDALog']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\logging.cpp', [], ['    getLogger', '    global_logger', '    setLogger(LoggerBase *logger)', '    timePoint', '    recordDurationSince(const std::string & name,JITTimePoint tp)', '    addStatValue(const std::string & stat_name,int64_t val)', '    getCounterValue(const std::string & name)', '    setAggregationType(const std::string & stat_name,AggregationType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Logging.cpp', ['    C10FlagParser_caffe2_log_level', '    C10FlagParser_caffe2_use_fatal_for_enforce', '    C10FlagParser_logtostderr', '    C10FlagParser_minloglevel', '    C10FlagParser_v'], ['    func', '    APIUsageDebug(const string & event)', '    LogAPIUsageFakeReturn(const std::string & event)', '    GetAPIUsageLogger', '    GetFetchStackTrace', '    InitCaffeLogging(int *argc,char **argv)', '    IsAPIUsageDebugMode', '    LogAPIUsage(const std::string & event)', '    SetAPIUsageLogger(std::function logger)', '    SetStackTraceFetcher(std::function fetcher)', '    ShowLogInfoToStderr', '    ThrowEnforceFiniteNotMet(const char *file,const int line,const char *condition,const std::string & msg,const void *caller)', '    ThrowEnforceNotMet(const char *file,const int line,const char *condition,const std::string & msg,const void *caller)', '    UpdateLoggingLevelsFromFlags', '    C10FlagParser_caffe2_log_level(const std::string & content)', '    C10FlagParser_caffe2_use_fatal_for_enforce(const std::string & content)', '    C10FlagParser_logtostderr(const std::string & content)', '    C10FlagParser_minloglevel(const std::string & content)', '    C10FlagParser_v(const std::string & content)', '    EnforceFailMessage(std::string)', '    Error(SourceLocation source_location,const std::string & msg)', '    MessageLogger(const char *file,int line,int severity)', '    ~MessageLogger']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Logging.h', ['    EnforceFailMessage'], ['    LogAPIUsageFakeReturn(const std::string & event)', '    Equals(const T1 & x,const T2 & y)', '    Greater(const T1 & x,const T2 & y)', '    GreaterEquals(const T1 & x,const T2 & y)', '    Less(const T1 & x,const T2 & y)', '    LessEquals(const T1 & x,const T2 & y)', '    NotEquals(const T1 & x,const T2 & y)', '    InitCaffeLogging(int *argc,char **argv)', '    IsUsingGoogleLogging', '    LogAPIUsage(const std::string & event)', '    ShowLogInfoToStderr', '    UpdateLoggingLevelsFromFlags', '    bad', '    EnforceFailMessage(std::string)', '    EnforceFailMessage(EnforceOK)', '    EnforceFailMessage', '    EnforceFailMessage', '    EnforceFailMessage(Args,...)', '    get_message_and_free(std::string)', '    msg_', '    operator=', '    operator=', '    max']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\logging.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\logging.h', ['    LockingLogger', '    AggregationType', '    LoggerBase', '    NoopLogger'], ['    getLogger', '    recordDurationSince(const std::string & name,JITTimePoint tp)', '    allRuntimeCounters', '    setLogger(LoggerBase *logger)', '    timePoint', '    addStatValue(const std::string & stat_name,int64_t val)', '    getCounterValue(const std::string & name)', '    RawCounter', '    setAggregationType(const std::string & stat_name,AggregationType)', '    ~LockingLogger', '    addStatValue(const std::string & stat_name,int64_t val)', '    ~LoggerBase', '    addStatValue(const std::string & stat_name,int64_t val)', '    ~NoopLogger']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\logging_is_google_glog.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\logging_is_not_google_glog.h', ['    LoggerVoidify', '    MessageLogger'], ['    CheckNotNull(const char *file,int line,const char *names,T *t)', '    CheckNotNull(const char *file,int line,const char *names,T & t)', '    CheckNotNullCommon(const char *file,int line,const char *names,T & t)', '    LogMessageFatal(const char *file,int line,const T & message)', '    PrintSequence(std::ostream & out,Iter begin,Iter end)', '    static_assert(INT_MIN,)', '    operator<<(std::ostream & out,const std::pair & p)', '    operator<<(std::ostream & out,const std::vector & seq)', '    operator<<(std::ostream & out,const std::map & seq)', '    operator<<(std::ostream & out,const std::set & seq)', '    operator<<(std::ostream & out,const std::nullptr_t &)', '    LoggerVoidify', '    operator&(const std::ostream & s)', '    DealWithFatal', '    MessageLogger(const char *file,int line,int severity)', '    stream', '    ~MessageLogger']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\logging_test.cpp', [], ['    TEST(LoggingTest,TestEnforceTrue)', '    TEST(LoggingTest,TestEnforceFalse)', '    TEST(LoggingTest,TestEnforceEquals)', '    TEST(LoggingTest,EnforceShowcase)', '    TEST(LoggingTest,Join)', '    TEST(LoggingTest,TestDanglingElse)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\logit_op.cc', ['    GetLogitGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULogit', '    CAFFE_ANONYMOUS_VARIABLE_CPULogitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Logit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LogitGradient', '    GetGradientDefs', '    operator()(const int size,const T *X,T *Y,CPUContext *)', '    RunOnDevice', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\logit_op.h', ['    final'], ['    LogitGradientOp(Args,...)', '    RunOnDevice', '    ~LogitGradientOp', '    LogitFunctor(OperatorBase & op)', '    operator()(const int size,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\loop_unrolling.cpp', [], ['    insert_point_guard', '    insert_point_guard', '    insertPointGuard', '    inlineBody(Node *loop)', '    insertBlockCopy(Graph & graph,Block *body,at::ArrayRef inputs)', '    isForLoop(Node *node)', '    isSmallBlock(Block *body)', '    isTrueConstant(Value *val)', '    limitedBlockSize(Block *body,int64_t limit)', '    repeatBody(Block *body,size_t times,Block *dest)', '    replaceLoopCounter(Node *loop)', '    unroll(Node *loop)', '    UnrollLoops(std::shared_ptr & graph)', '    UnrollLoops(Block *block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\loop_unrolling.h', [], ['    UnrollLoops(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\loopnest.cpp', ['    DepTracker', '    Flattener', '    FunctionInliner', '    RandomInliner', '    Vectorizer'], ['    InjectInlines(Stmt *stmt,const std::vector & inlined_funcs)', '    InlineRandom(Stmt *stmt,const std::vector & funcs)', '    EvalConstExpr(const ExprHandle & expr)', '    findUsedTensors(Tensor *tensor)', '    visit(const FunctionCall *v)', '    mutate(const FunctionCall *v)', '    FunctionInliner(const std::vector & funcs)', '    mutate(const FunctionCall *v)', '    mutate(const Var *v)', '    mutate(const Store *v)', '    should_inline(Function *func)', '    computeInline(Stmt *s)', '    computeInlineWithRandom(Stmt *s)', '    findAllNeededTensors(const std::vector & tensors)', '    getLoopBodyFor(Tensor *t)', '    getLoopStmtsFor(Tensor *t)', '    hasLoopBodyFor(Tensor *t)', '    insertAllocFree(Stmt *stmt)', '    LoopNest(const std::vector & output_tensors)', '    lowerToStmt(Tensor *t)', '    prepareForCodegen', '    setGPUBlockIndex(For *f,int block_index)', '    setGPUThreadIndex(For *f,int thread_index)', '    splitWithMask(For *f,int factor,For **outer,For **inner)', '    splitWithTail(For *f,int factor,For **outer,For **inner,For **tail)', '    vectorize(Stmt *stmt)', '    bind_random_vars(Stmt *s)', '    mutate(const Cond *v)', '    mutate(const For *v)', '    mutate(const FunctionCall *v)', '    mutate(const Intrinsics *v)', '    RandomInliner(const std::vector & funcs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    try_vectorize(const Expr *e,std::vector & inputs,T)', '    try_vectorize(const Stmt *s,std::vector & inputs,T)', '    vectorize(const For *v)', '    vectorize_inputs(std::vector & inputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\loopnest.h', ['    LoopNest', '    Range'], ['    computeInline(Stmt *s)', '    computeInlineWithRandom(Stmt *s)', '    findAllNeededTensors(const std::vector & tensors)', '    getLoopBodyFor(Tensor *)', '    getLoopStmtsFor(Tensor *)', '    hasLoopBodyFor(Tensor *)', '    insertAllocFree(Stmt *stmt)', '    LoopNest(const std::vector & output_tensors)', '    lowerToStmt(Tensor *t)', '    prepareForCodegen', '    root_stmt', '    setGPUBlockIndex(For *f,int idx)', '    setGPUThreadIndex(For *f,int idx)', '    splitWithMask(For *f,int factor,For **outer,For **inner)', '    splitWithTail(For *f,int factor,For **outer,For **inner,For **tail)', '    vectorize(Stmt *)', '    Range', '    Range(const Expr *start,const Expr *stop)', '    start', '    stop']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\Loops.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\loss.cpp', [], ['    BCELossImpl(const BCELossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    BCEWithLogitsLossImpl(const BCEWithLogitsLossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CosineEmbeddingLossImpl(const CosineEmbeddingLossOptions & options_)', '    forward(const Tensor & input1,const Tensor & input2,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CrossEntropyLossImpl(const CrossEntropyLossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CTCLossImpl(const CTCLossOptions & options_)', '    forward(const Tensor & log_probs,const Tensor & targets,const Tensor & input_lengths,const Tensor & target_lengths)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    HingeEmbeddingLossImpl(const HingeEmbeddingLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    KLDivLossImpl(const KLDivLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    L1LossImpl(const L1LossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input1,const Tensor & input2,const Tensor & target)', '    MarginRankingLossImpl(const MarginRankingLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MSELossImpl(const MSELossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiLabelMarginLossImpl(const torch::nn::MultiLabelMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiLabelSoftMarginLossImpl(const torch::nn::MultiLabelSoftMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiMarginLossImpl(const MultiMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    NLLLossImpl(const NLLLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & log_input,const Tensor & target)', '    PoissonNLLLossImpl(const PoissonNLLLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    SmoothL1LossImpl(const torch::nn::SmoothL1LossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftMarginLossImpl(const torch::nn::SoftMarginLossOptions & options_)', '    forward(const Tensor & anchor,const Tensor & positive,const Tensor & negative)', '    pretty_print(std::ostream & stream)', '    reset', '    TripletMarginLossImpl(const TripletMarginLossOptions & options_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Loss.cpp', [], ['    apply_loss_reduction(const at::Tensor & unreduced,int64_t reduction)', '    binary_cross_entropy_backward_cpu(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_backward_out_cpu(Tensor & grad_input,const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_cpu(const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_out_cpu(Tensor & loss,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_with_logits(const Tensor & input,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    binary_cross_entropy_with_logits_backward(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    cosine_embedding_loss(const Tensor & input1,const Tensor & input2,const Tensor & target,double margin,int64_t reduction)', '    hinge_embedding_loss(const Tensor & self,const Tensor & target,double margin,int64_t reduction)', '    kl_div(const Tensor & input,const Tensor & target,int64_t reduction)', '    kl_div_backward_cpu(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    margin_ranking_loss(const Tensor & input1,const Tensor & input2,const Tensor & target,double margin,int64_t reduction)', '    mse_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    poisson_nll_loss(const Tensor & input,const Tensor & target,const bool log_input,const bool full,const double eps,const int64_t reduction)', '    smooth_l1_loss(const Tensor & input,const Tensor & target,const int64_t reduction)', '    smooth_l1_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_out(Tensor & output,const Tensor & input,const Tensor & target,int64_t reduction)', '    triplet_margin_loss(const Tensor & anchor,const Tensor & positive,const Tensor & negative,double margin,double p,double eps,bool swap,int64_t reduction)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\loss.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\loss.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\loss.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\loss_op.cc', ['    GetAveragedLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragedLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragedLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragedLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragedLossGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\loss_op.h', ['    final', '    final'], ['    AveragedLoss(Args,...)', '    AveragedLossGradient(Args,...)', '    ~AveragedLoss', '    ~AveragedLossGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LossCTC.cpp', [], ['    get_target_prime(target_t *target,int64_t offset,int64_t stride,int64_t idx,int64_t BLANK)', '    ctc_loss_backward_cpu(const Tensor & grad,const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,const Tensor & neg_log_likelihood,const Tensor & log_alpha,int64_t BLANK,bool zero_infinity)', '    ctc_loss_backward_cpu_template(const Tensor & grad_out,const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,const Tensor & neg_log_likelihood,const Tensor & log_alpha,int64_t BLANK,bool zero_infinity)', '    ctc_loss_cpu(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK,bool zero_infinity)', '    ctc_loss_cpu_template(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK)', '    ctc_loss(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK,int64_t reduction,bool zero_infinity)', '    ctc_loss(const Tensor & log_probs,const Tensor & targets,const Tensor & input_lengths,const Tensor & target_lengths,int64_t BLANK,int64_t reduction,bool zero_infinity)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\LossCTC.cpp', [], ['    _cudnn_ctc_loss(const Tensor & log_probs_t,const Tensor & targets_t,IntArrayRef input_lengths_,IntArrayRef target_lengths_,int64_t BLANK,bool deterministic,bool zero_infinity)', '    _use_cudnn_ctc_loss(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK)', '    grad_desc', '    log_probs', '    log_probs_desc', '    targets']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LossMultiLabelMargin.cpp', [], ['    multilabel_margin_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input_contiguous,const Tensor & target_contiguous,int64_t reduction,const Tensor & is_target_contiguous,int64_t nframe,int64_t dim)', '    multilabel_margin_loss_forward_out_cpu_template(const Tensor & input,const Tensor & target,Tensor & output,Tensor & is_target,int64_t reduction)', '    multilabel_margin_loss_forward_out_frame(const Tensor & input_contiguous,const Tensor & target_contiguous,Tensor & output,Tensor & is_target,int64_t reduction,int64_t nframe,int64_t dim)', '    multilabel_margin_loss_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_backward_cpu_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_forward_cpu(const Tensor & self,const Tensor & target,int64_t reduction)', '    multilabel_margin_loss_forward_inner_sum_cpu(scalar_t *input_data,int64_t *target_data,scalar_t *is_target_data,int64_t dim)', '    multilabel_margin_loss_forward_out_cpu(Tensor & output,Tensor & is_target,const Tensor & self,const Tensor & target,int64_t reduction)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LossMultiMargin.cpp', [], ['    multi_margin_loss_backward_cpu_kernel(scalar_t *grad_input_data,const Tensor & grad_output,scalar_t *input_data,int64_t *target_data,int p,scalar_t margin,scalar_t g,scalar_t *weight_data,int64_t nframe,int64_t dim,int64_t reduction)', '    multi_margin_loss_cpu_kernel(Tensor & output,scalar_t *input_data,int64_t *target_data,const int p,scalar_t margin,scalar_t *weight_data,const int64_t nframe,const int64_t dim,const int64_t reduction)', '    multi_margin_inner_sum_cpu(const scalar_t *input_data,const scalar_t *weight_data,const int p,const scalar_t margin,const int64_t dim,const int64_t target_idx)', '    multi_margin_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu(const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_out(Tensor & output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_out_cpu_template(Tensor & output,const Tensor & input,const Tensor & target,int p,Scalar margin,const Tensor & weight,int64_t reduction)', '    target_index_checked(const int64_t *target_data,const int64_t index,const int64_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LossNLL.cpp', [], ['    nll_loss_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_out_frame(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_forward_cpu(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_forward_out_cpu(Tensor & output,Tensor & total_weight,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_forward_out_cpu_template(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    optional_contiguous(const Tensor & source)', '    optional_data(const Tensor & source)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\LossNLL2d.cpp', [], ['    nll_loss2d_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_forward_out_frame(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    check_gradout_shape_nll_loss2d(const Tensor & grad_output,const Tensor & target)', '    check_inputs_nll_loss2d(const Tensor & input,const Tensor & target,const Tensor & weight)', '    nll_loss2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_forward_cpu(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_forward_out_cpu(Tensor & output,Tensor & total_weight,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_forward_out_cpu_template(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    optional_contiguous(const Tensor & source)', '    optional_data(const Tensor & source)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_grad_of.cpp', [], ['    LowerGradOf(Graph & g)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_grad_of.h', [], ['    LowerGradOf(Graph & g)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_graph.cpp', [], ['    loadTensors(const std::vector & slots)', '    obj_hash', '    offset_hash', '    getOrAddSlot', '    operator==(const Slot & other)', '    operator()(const Slot & slot)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_graph.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_tuples.cpp', [], ['    EnsureNoTuples(ArrayRef values)', '    EnsureNoTuples(Block *block)', '    LowerAllTuples(Block *block)', '    RemoveTupleConstants(Node *n)', '    VisitNode(Node *n,Node *insert_point)', '    LowerAllTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(Block *block)', '    removeTupleNodes(Node *n,bool must_remove_tuples)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\lower_tuples.h', [], ['    LowerAllTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(Block *block)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lp_pool_op.cc', ['    GetPoolGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULpPool', '    CAFFE_ANONYMOUS_VARIABLE_CPULpPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpPoolGradient', '    vector', '    LpPoolFunctor(const OperatorBase &)', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lpnorm_op.cc', ['    GetLpNormGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULpNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPULpNormGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpNormGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lpnorm_op.h', ['    LpNormGradientOp', '    LpNormOp'], ['    LpNormGradientOp(Args,...)', '    RunOnDevice', '    LpNormOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\lstm_unit_dnnlowp_op.cc', [], ['    LSTMUnit(int N,int D,int t,const T *H_prev,const T *C_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *C,T *H,const int32_t forget_bias,const Sigmoid & sigmoid,const Tanh & tanh,const TensorQuantizationParams & X_qparams,const TensorQuantizationParams & C_in_qparams,const TensorQuantizationParams & C_out_qparams,const TensorQuantizationParams & H_in_qparams,const TensorQuantizationParams & H_out_qparams,QuantizationFactory *qfactory)', '    Fp32Op_', '    GetQuantizationParameters_', '    InputTensorCPU_(int idx)', '    LSTMUnitDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    OutputTensorCPU_(int idx)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\lstm_unit_dnnlowp_op.h', ['    final'], ['    arguments_parsed_', '    dequantize_output_', '    Fp32Op_', '    GetQuantizationParameters_', '    InputTensorCPU_(int idx)', '    LSTMUnitDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    measure_quantization_error_', '    OutputTensorCPU_(int idx)', '    RunOnDevice', '    static_assert(std::is_integral,)', '    ~LSTMUnitDNNLowPOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lstm_unit_op.cc', ['    GetLSTMUnitGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPULSTMUnit', '    CAFFE_ANONYMOUS_VARIABLE_CPULSTMUnitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LSTMUnit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LSTMUnitGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lstm_unit_op.h', ['    LSTMUnitGradientOp', '    LSTMUnitOp'], ['    host_tanh(T x)', '    LSTMUnit(int N,int D,int t,const T *H_prev,const T *C_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *C,T *H,const float forget_bias,Context *)', '    LSTMUnitGradient(int N,int D,int t,const T *C_prev,const T *X,const int32_t *seqLengths,const T *C,const T *H,const T *C_diff,const T *H_diff,bool drop_states,T *H_prev_diff,T *C_prev_diff,T *X_diff,const float forget_bias,Context *)', '    sigmoid(T x)', '    DoRunWithType', '    GetSingleArgument', '    LSTMUnitGradientOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    GetSingleArgument', '    LSTMUnitOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\lstm_utils.h', [], ['    unpair_vec(std::vector,T)', '    add(const Tensor & X,const Tensor & Y,CPUContext *context)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    copy_ctor(const std::vector & X)', '    copy_ctor(const std::vector & X)', '    copy_ctor(const T & x)', '    copy_ctor(const Tensor & X)', '    copy_ctor(const t_tuple & X)', '    copy_ctor(const std::pair & X)', '    cat(const std::vector & tensorList,int axis,CPUContext *context)', '    chunk(const Tensor & input,int chunks,int axis,CPUContext *context)', '    copy_ctor([i+1] vals)', '    linear(const Tensor & X,const Tensor & W,const Tensor & B,CPUContext *context)', '    matmul(const Tensor & X,const Tensor & W,CPUContext *context)', '    mul(const Tensor & X,const Tensor & Y,CPUContext *context)', '    sigmoid(const Tensor & X)', '    stack(const std::vector & tensorList,int axis,CPUContext *context)', '    transform(X,X,Y,[])', '    tanh(const Tensor & X,CPUContext *context)', '    transpose(const Tensor & X,int dim0,int dim1,CPUContext *context)', '    unbind(const Tensor & input,int axis,CPUContext *context)', '    Add', '    CopyMatrix', '    Gemm', '    Mul', '    Set', '    Tanh', '    Transpose', '    canonical_axis_index', '    copy', '    dim', '    dim32', '    dtype', '    itemsize', '    numel', '    raw_data', '    raw_mutable_data', '    size_from_dim', '    size_to_dim', '    sizes', '    vec']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\lut-microkernel-tester.h', ['    LUTMicrokernelTester'], ['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_x8lut_ukernel_function x8lut)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\lut-norm-microkernel-tester.h', ['    LUTNormMicrokernelTester'], ['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_u8lut32norm_ukernel_function u8lut32norm)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\macros\\Macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\Macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\main.cc', [], ['    main']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\test_install\\main.cpp', [], ['    main']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\common\\main.cpp', [], ['    add_negative_flag(const std::string & flag)', '    main(int argc,char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\make_cifar_db.cc', ['    C10FlagParser_db', '    C10FlagParser_input_folder', '    C10FlagParser_is_cifar100', '    C10FlagParser_output_test_db_name', '    C10FlagParser_output_train_db_name'], ['    ConvertCIFAR', '    ReadImage(std::ifstream *file,int *label,char *buffer)', '    WriteToDB(const string & filename,const int num_items,const int & offset,db::DB *db)', '    main(int argc,char **argv)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_input_folder(const std::string & content)', '    C10FlagParser_is_cifar100(const std::string & content)', '    C10FlagParser_output_test_db_name(const std::string & content)', '    C10FlagParser_output_train_db_name(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\make_image_db.cc', ['    C10FlagParser_color', '    C10FlagParser_db', '    C10FlagParser_input_folder', '    C10FlagParser_list_file', '    C10FlagParser_num_threads', '    C10FlagParser_output_db_name', '    C10FlagParser_raw', '    C10FlagParser_scale', '    C10FlagParser_shuffle', '    C10FlagParser_warp', '    Converter'], ['    ConvertImageDataset(const string & input_folder,const string & list_filename,const string & output_db_name,const bool)', '    main(int argc,char **argv)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_input_folder(const std::string & content)', '    C10FlagParser_list_file(const std::string & content)', '    C10FlagParser_num_threads(const std::string & content)', '    C10FlagParser_output_db_name(const std::string & content)', '    C10FlagParser_raw(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_shuffle(const std::string & content)', '    C10FlagParser_warp(const std::string & content)', '    Converter', '    get', '    queue(const std::pair & pair)', '    run', '    start', '    ~Converter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\make_mnist_db.cc', ['    C10FlagParser_channel_first', '    C10FlagParser_data_limit', '    C10FlagParser_db', '    C10FlagParser_image_file', '    C10FlagParser_label_file', '    C10FlagParser_output_file'], ['    convert_dataset(const char *image_filename,const char *label_filename,const char *db_path,const int data_limit)', '    swap_endian(uint32_t val)', '    main(int argc,char **argv)', '    C10FlagParser_channel_first(const std::string & content)', '    C10FlagParser_data_limit(const std::string & content)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_image_file(const std::string & content)', '    C10FlagParser_label_file(const std::string & content)', '    C10FlagParser_output_file(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\manager.cpp', [], ['    free_used_object(const std::string & name)', '    main(int argc,char *[] argv)', '    object_exists(const char *name)', '    print_init_message(const char *message)', '    register_fd(int fd)', '    unregister_fd(int fd)', '    ClientSession(ManagerSocket s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\map.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\map_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateMap', '    CAFFE_ANONYMOUS_VARIABLE_CPUKeyValueToMap', '    CAFFE_ANONYMOUS_VARIABLE_CPUMapToKeyValue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateMap', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_KeyValueToMap', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MapToKeyValue', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\map_ops.h', ['    final', '    final', '    final', '    MapDeserializer', '    MapSerializer'], ['    dtype', '    MapTypeName', '    CreateMapOp(Args,...)', '    DoRunWithOtherType2', '    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2', '    DoRunWithType2', '    GetSingleArgument', '    KeyValueToMapOp(Args,...)', '    MapToKeyValueOp(Args,...)', '    Output', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~CreateMapOp', '    ~KeyValueToMapOp', '    ~MapToKeyValueOp', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    MapTypeName', '    numel', '    Resize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\map_utils.h', [], ['    get_default(const Map & map,const Key & key,Value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\margin_ranking_criterion_op.cc', ['    GetMarginRankingCriterionGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMarginRankingCriterion', '    CAFFE_ANONYMOUS_VARIABLE_CPUMarginRankingCriterionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MarginRankingCriterion', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MarginRankingCriterionGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\margin_ranking_criterion_op.h', ['    final', '    final'], ['    MarginRankingCriterionGradientOp(Args,...)', '    MarginRankingCriterionOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Transformations\\Match.h', [], ['    equal(const T & a,const T & b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\MatchTest.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math-detail.h', [], ['    AxpyFixedSize(const int N,const float alpha,const T *x,T *y,Context *context)', '    ScaleFixedSize(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,CPUContext *)', '    operator()(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math.h', ['    DefaultEngine'], ['    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    AddStripedBatch(const int N,const T *first,T *y,const int stripe,const int batch,Context *context)', '    And(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BiasCHW(const T *bias,const T *bias_multiplier,const int bias_channels,const int image_size,T *image,Context *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    Col2Im(const int channels,const int height,const int width,const int patch_h,const int patch_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *col_data,T *img_data,Context *context,const int groups)', '    Col2ImNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *col_data,T *img_data,Context *context,const int groups)', '    ColwiseAdd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseDiv(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseEQ(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseGE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseGT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseLE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseLT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseMax(const int N,const int D,const T *x,T *y,Context *context)', '    ColwiseMul(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseNE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseSub(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    CopyMatrix(const size_t item_size,const int M,const int N,const void *A,const int lda,void *B,const int ldb,Context *context,TypeMeta::Copy copy)', '    CopyMatrix(const int M,const int N,const T *A,const int lda,T *B,const int ldb,Context *context)', '    CopyMatrix(const int M,const int N,const T *A,const int A_outer_stride,const int A_inner_stride,T *B,const int B_outer_stride,const int B_inner_stride,Context *context)', '    CopyVector(const int N,const T *A,T *B,Context *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Dot(const int N,const T *a,const T *b,T *y,Context *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Gemm(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const T *A,const T *B,const float beta,T *C,Context *context,TensorProto::DataType math_type)', '    GemmBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const T **A,const T **B,const float beta,T **C,Context *context,TensorProto::DataType math_type)', '    GemmEx(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const T alpha,const T *A,const int lda,const T *B,const int ldb,const T beta,T *C,const int ldc,Context *context)', '    GemmStridedBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const T *A,const int A_stride,const T *B,const int B_stride,const float beta,T *C,const int C_stride,Context *context,TensorProto::DataType math_type)', '    Gemv(const CBLAS_TRANSPOSE trans_A,const int M,const int N,const float alpha,const T *A,const T *x,const float beta,T *y,Context *context,TensorProto::DataType math_type)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Im2Col(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *img_data,T *col_data,Context *context,const int groups)', '    Im2ColNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *img_data,T *col_data,Context *context,const int groups)', '    InvStd(const int N,const T epsilon,const T *var,T *inv_std,Context *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Maximum(const int N,const float alpha,const T *x,T *y,Context *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Or(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    RandFixedSum(const size_t n,const T a,const T b,const T sum,T *r,Context *context)', '    RandGaussian(const size_t n,const T mean,const T std,T *r,Context *context)', '    RandSyntheticData(const size_t n,const T a,const T b,T *r,Context *context)', '    RandUniform(const size_t n,const T a,const T b,T *r,Context *context)', '    RandUniformUnique(const size_t n,const T a,const T b,T *r,const size_t m,const T *avoid,Context *context)', '    RowwiseAdd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseDiv(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseEQ(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseGE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseGT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseLE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseLT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseMax(const int N,const int D,const T *x,T *y,Context *context)', '    RowwiseMul(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseNE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseSub(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    Select(const int N,const int D,const T *x,const int *idx,T *y,Context *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Sum(const int N,const T *x,T *y,Context *context,Tensor *scratch_ptr)', '    SumSqr(const int N,const T *x,T *y,Context *context,Tensor *scratch_ptr)', '    Xor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\math.h', [], ['    divide_round_up(size_t n,size_t q)', '    doz(size_t a,size_t b)', '    max(size_t a,size_t b)', '    min(size_t a,size_t b)', '    round_up(size_t n,size_t q)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\math.h', [], ['    decompress_and_dequantize(const std::uint8_t *input_data,float *output_data,std::uint64_t input_size)', '    quantize_and_compress(const float *input_data,std::uint8_t *output_data,std::uint64_t input_size,std::uint64_t bitwidth,bool random,const float *random_buffer)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Math.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\hip\\math_blas_gpu_test.cc', [], ['    TEST(MathROCBLASTest,GemmNoTransNoTrans)', '    TEST(MathROCBLASTest,GemmNoTransTrans)', '    TEST(MathROCBLASTest,GemvNoTrans)', '    TEST(MathROCBLASTest,GemvTrans)', '    shapeA', '    shapeA', '    shapeW', '    shapeW', '    shapeX', '    shapeX', '    shapeX', '    shapeX', '    shapeY', '    shapeY', '    shapeY', '    shapeY']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\math_compat.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math_cpu.cc', [], ['    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    AddStripedBatch(const int N,const float *first,float *y,const int stripe,const int batch,CPUContext *context)', '    And(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BiasCHW(const float *bias,const float *,const int bias_channels,const int image_size,float *image,CPUContext *)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    BroadcastBinaryOpImpl(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    BroadcastImpl(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    Col2Im(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *col_data,float *img_data,CPUContext *context,const int groups)', '    Col2Im(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *col_data,float *img_data,CPUContext *context,const int)', '    Col2Im3dNHWCImpl(const int C,const int T,const int H,const int W,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const TData *col_data,TData *img_data,CPUContext *context,const int groups)', '    Col2ImNd(const int N,const int,const int,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *col_data,float *img_data,CPUContext *context,const int groups)', '    Col2ImNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *col_data,float *img_data,CPUContext *,const int)', '    Col2ImZeroPaddingAndNoDilationNCHW(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *col_data,T *img_data,CPUContext *context)', '    Col2ImZeroPaddingAndNoDilationNHWC(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *col_data,T *img_data,CPUContext *context)', '    ColwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBinaryOp(const int rows,const int cols,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    ColwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseMax(const int N,const int D,const float *x,float *y,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    CopyMatrix(const size_t itemsize,const int M,const int N,const void *A,const int lda,void *B,const int ldb,CPUContext *,TypeMeta::Copy copy)', '    CopyMatrix(const int M,const int N,const float *A,const int lda,float *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const float *A,const int A_outer_stride,const int A_inner_stride,float *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const double *A,const int lda,double *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const double *A,const int A_outer_stride,const int A_inner_stride,double *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const int *A,const int lda,int *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const int *A,const int A_outer_stride,const int A_inner_stride,int *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const int64_t *A,const int lda,int64_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const int64_t *A,const int A_outer_stride,const int A_inner_stride,int64_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const std::uint8_t *A,const int lda,std::uint8_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const std::uint8_t *A,const int A_outer_stride,const int A_inner_stride,std::uint8_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const std::uint16_t *A,const int lda,std::uint16_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const std::uint16_t *A,const int A_outer_stride,const int A_inner_stride,std::uint16_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyVector(const int N,const float *src,float *dst,CPUContext *)', '    CopyVector(const int N,const int32_t *src,int32_t *dst,CPUContext *)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Dot(const int N,const float *a,const float *b,float *y,CPUContext *)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Gemm(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const float *A,const float *B,const float beta,float *C,CPUContext *,TensorProto::DataType)', '    GemmBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float **A,const float **B,const float beta,float **C,CPUContext *context,TensorProto::DataType)', '    GemmEx(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc,CPUContext *)', '    GemmStridedBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float *A,const int A_stride,const float *B,const int B_stride,const float beta,float *C,const int C_stride,CPUContext *context,TensorProto::DataType)', '    Gemv(const CBLAS_TRANSPOSE trans_A,const int M,const int N,const float alpha,const float *A,const float *x,const float beta,float *y,CPUContext *,TensorProto::DataType)', '    generate_stack_distance(std::vector & cum_val,std::vector & cum_dis,std::vector & cum_map,Ind_t max_i,Ind_t i,Context_t *context)', '    generate_trace_lru(std::vector & uni_ref,std::vector & cum_val,std::vector & cum_dis,std::vector & cum_map,Context_t *context,Ind_t cache_line_size,Ind_t n,Type min,Type max,Type *syn_ref)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Im2Col(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *img_data,float *col_data,CPUContext *context,const int groups)', '    Im2Col(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *img_data,float *col_data,CPUContext *context,const int)', '    Im2Col3dNCHWImpl(const int channels,const int clip_len,const int height,const int width,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_a,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const T *img_data,T *col_data)', '    Im2Col3dNHWCImpl(const int C,const int T,const int H,const int W,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const TData *img_data,TData *col_data,const int groups)', '    Im2ColNd(const int N,const int,const int,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *img_data,float *col_data,CPUContext *,const int groups)', '    Im2ColNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *img_data,float *col_data,CPUContext *,const int)', '    Im2ColNdNCHWImpl(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *X_data,float *Y_data)', '    Im2ColZeroPaddingAndNoDilationNCHW(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *img_data,T *col_data,CPUContext *context)', '    Im2ColZeroPaddingAndNoDilationNHWC(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *img_data,T *col_data,CPUContext *context)', '    InvStd(const int N,const float epsilon,const float *var,float *inv_std,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Maximum(const int N,const float alpha,const float *x,float *y,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Not(const int N,const bool *x,bool *y,CPUContext *)', '    Or(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    RandFixedSum(const size_t n,const float a,const float b,const float sum,float *r,CPUContext *context)', '    RandFixedSum(const size_t n,const double a,const double b,const double sum,double *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int8_t a,const int8_t b,const int8_t sum,int8_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int16_t a,const int16_t b,const int16_t sum,int16_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int32_t a,const int32_t b,const int32_t sum,int32_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int64_t a,const int64_t b,const int64_t sum,int64_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint8_t a,const uint8_t b,const uint8_t sum,uint8_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint16_t a,const uint16_t b,const uint16_t sum,uint16_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint32_t a,const uint32_t b,const uint32_t sum,uint32_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint64_t a,const uint64_t b,const uint64_t sum,uint64_t *r,CPUContext *context)', '    RandGaussian(const size_t n,const float mean,const float std,float *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const float a,const float b,float *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const double a,const double b,double *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int8_t a,const int8_t b,int8_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int16_t a,const int16_t b,int16_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int32_t a,const int32_t b,int32_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int64_t a,const int64_t b,int64_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint8_t a,const uint8_t b,uint8_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint16_t a,const uint16_t b,uint16_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint32_t a,const uint32_t b,uint32_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint64_t a,const uint64_t b,uint64_t *r,CPUContext *context)', '    RandUniform(const size_t n,const float a,const float b,float *r,CPUContext *context)', '    RandUniform(const size_t n,const double a,const double b,double *r,CPUContext *context)', '    RandUniform(const size_t n,const int8_t a,const int8_t b,int8_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint8_t a,const uint8_t b,uint8_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int16_t a,const int16_t b,int16_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int32_t a,const int32_t b,int32_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int64_t a,const int64_t b,int64_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint16_t a,const uint16_t b,uint16_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint32_t a,const uint32_t b,uint32_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint64_t a,const uint64_t b,uint64_t *r,CPUContext *context)', '    RandUniformUnique(const size_t n,const int32_t a,const int32_t b,int32_t *r,const size_t m,const int32_t *avoid,CPUContext *context)', '    RandUniformUnique(const size_t n,const int64_t a,const int64_t b,int64_t *r,const size_t m,const int64_t *avoid,CPUContext *context)', '    RowwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBinaryOp(const int rows,const int cols,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    RowwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseMax(const int N,const int D,const float *x,float *y,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    Select(const int N,const int D,const float *x,const int *idx,float *y,CPUContext *)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Sum(const int N,const float *x,float *y,CPUContext *,Tensor *)', '    Sum(const int N,const int32_t *x,int32_t *y,CPUContext *,Tensor *)', '    Sum(const int N,const int64_t *x,int64_t *y,CPUContext *,Tensor *)', '    SumSqr(const int N,const float *x,float *y,CPUContext *,Tensor *)', '    Xor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\math_cpu_avx2.cc', [], ['    decompress_and_dequantize__avx2(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    quantize_and_compress__avx2(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\math_cpu_base.cc', [], ['    decompress_and_dequantize(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    decompress_and_dequantize__base(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    quantize_and_compress(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)', '    quantize_and_compress__base(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math_gpu_test.cc', ['    BroadcastGPUTest', '    GemmBatchedGPUTest'], ['    executeGpuBinaryOpTest(int shapex0,int shapex1,int shapey,std::function input0,std::function input1,std::function operation,std::function correct_output)', '    TEST(MathUtilGPUTest,testAddStripedBatch)', '    TEST(MathUtilGPUTest,testReduceMin)', '    TEST(MathUtilGPUTest,testReduceMax)', '    TEST(MathUtilGPUTest,testCopyVector)', '    TEST_F(BroadcastGPUTest,BroadcastGPUFloatTest)', '    TEST_P(GemmBatchedGPUTest,GemmBatchedGPUFloatTest)', '    TEST_P(GemmBatchedGPUTest,GemmStridedBatchedGPUFloatTest)', '    shapex', '    shapex0_vector', '    shapex1_vector', '    shapey', '    shapey_vector', '    RunBroadcastTest(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data,const std::vector & Y_data)', '    SetUp', '    SetUpData(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data)', '    VerifyResult(const std::vector & expected_output)', '    RunGemmBatched(const float alpha,const float beta)', '    RunGemmStridedBatched(const float alpha,const float beta)', '    SetUp', '    VerifyOutput(const float value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\math_lp.cc', [], ['    dot(const int N,const float *x,const float *y,float *z,CPUContext *ctx)', '    dot(const int N,const float *x,const at::Half *y,float *z,CPUContext *ctx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\math_lp.h', [], ['    dot(const int N,const XT *x,const YT *y,ZT *z,CPUContext *ctx)', '    dot(const int N,const float *x,const float *y,float *z,CPUContext *ctx)', '    dot(const int N,const float *x,const at::Half *y,float *z,CPUContext *ctx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math_test.cc', ['    BroadcastTest', '    GemmBatchedTest', '    RandFixedSumTest'], ['    TEST(MathTest,GemmNoTransNoTrans)', '    TEST(MathTest,GemmNoTransTrans)', '    TEST(MathTest,GemvNoTrans)', '    TEST(MathTest,GemvTrans)', '    TEST(MathTest,FloatToHalfConversion)', '    TEST_F(BroadcastTest,BroadcastFloatTest)', '    TEST_F(RandFixedSumTest,UpperBound)', '    TEST_P(GemmBatchedTest,GemmBatchedFloatTest)', '    TEST_P(GemmBatchedTest,GemmStridedBatchedFloatTest)', '    RunBroadcastTest(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data,const std::vector & Y_data)', '    SetUp', '    RunGemmBatched(const float alpha,const float beta)', '    RunGemmStridedBatched(const float alpha,const float beta)', '    SetUp', '    VerifyOutput(const float value)', '    SetUp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\matmul_op.cc', ['    GetMatMulGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMatMul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MatMul', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\matmul_op.h', ['    final'], ['    dimErrorString', '    axis_a_', '    axis_b_', '    GetSingleArgument', '    MatMulOp(Args,...)', '    RunOnDevice', '    Y_shape_cache_', '    ~MatMulOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\matmul_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAMatMul']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\MatrixRef.h', ['    MatrixRef'], ['    data', '    empty', '    equals(MatrixRef RHS)', '    MatrixRef', '    MatrixRef(ArrayRef arr,size_type stride0)', '    numel', '    operator[](size_t Index)', '    size(size_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\max-pooling-operator-tester.h', ['    MaxPoolingOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    dilatedPoolingHeight', '    dilatedPoolingWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    inputHeight(size_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(size_t inputHeight,size_t inputWidth)', '    inputWidth(size_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    nextBatchSize(size_t nextBatchSize)', '    nextBatchSize', '    nextBatchSize_', '    nextInputHeight(uint32_t nextInputHeight)', '    nextInputHeight', '    nextInputHeight_', '    nextInputSize(uint32_t nextInputHeight,uint32_t nextInputWidth)', '    nextInputWidth(uint32_t nextInputWidth)', '    nextInputWidth', '    nextInputWidth_', '    nextOutputHeight', '    nextOutputWidth', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    poolingHeight(uint32_t poolingHeight)', '    poolingHeight', '    poolingHeight_', '    poolingSize(uint32_t poolingSize)', '    poolingSize(uint32_t poolingHeight,uint32_t poolingWidth)', '    poolingWidth(uint32_t poolingWidth)', '    poolingWidth', '    poolingWidth_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testSetupU8', '    testU8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\max-pooling.c', [], ['    compute_output_dimension(size_t padded_input_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_max_pooling2d_nhwc_u8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *max_pooling_out)', '    pytorch_qnnp_setup_max_pooling2d_nhwc_u8(pytorch_qnnp_operator_t max_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\max-pooling.cc', [], ['    TEST(MAX_POOLING_OP,zero_batch)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_qmax)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_qmax)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_qmax)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,small_batch_few_channels)', '    TEST(MAX_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_few_channels_with_output_stride)', '    TEST(MAX_POOLING_OP,setup_increasing_batch)', '    TEST(MAX_POOLING_OP,setup_decreasing_batch)', '    TEST(MAX_POOLING_OP,setup_changing_height)', '    TEST(MAX_POOLING_OP,setup_changing_width)', '    TEST(MAX_POOLING_OP,setup_swap_height_and_width)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\max-pooling.cc', [], ['    max_pooling_u8(benchmark::State & state,const char *net)', '    ShuffleNet(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\max_pool_with_index_gpu.h', ['    final', '    final'], ['    MaxPoolWithIndexGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolWithIndexOp(const OperatorDef & operator_def,Workspace *ws)', '    ~MaxPoolWithIndexGradientOp', '    ~MaxPoolWithIndexOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\maxpool-microkernel-tester.h', ['    MaxPoolMicrokernelTester'], ['    iterations(size_t iterations)', '    iterations', '    iterations_', '    kc(size_t kc)', '    kc', '    kc_', '    kh(size_t kh)', '    kh', '    kh_', '    kr(size_t kr)', '    kr', '    kr_', '    ks', '    kw(size_t kw)', '    kw', '    kw_', '    mr(size_t mr)', '    mr', '    mr_', '    n(size_t n)', '    n', '    n_', '    packedKs', '    packedN', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    qr(size_t qr)', '    qr', '    qr_', '    s(size_t s)', '    s', '    s_', '    test(pytorch_u8maxpool_ukernel_function u8maxpool)', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    yStride(size_t yStride)', '    yStride', '    yStride_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\MaxUnpooling.cpp', [], ['    max_unpooling2d_backward_out_cpu_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nslices,int64_t iheight,int64_t iwidth,int64_t oheight,int64_t owidth)', '    max_unpooling3d_backward_out_cpu_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nslices,int64_t iT,int64_t iH,int64_t iW,int64_t oT,int64_t oH,int64_t oW)', '    max_unpooling3d_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & indices,IntArrayRef output_size)', '    max_unpooling2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output_,const Tensor & self,const Tensor & indices_,IntArrayRef output_size)', '    max_unpooling2d_forward_cpu(const Tensor & self,const Tensor & indices,IntArrayRef output_size)', '    max_unpooling2d_forward_out_cpu(Tensor & output,const Tensor & self_,const Tensor & indices_,IntArrayRef output_size)', '    max_unpooling2d_forward_out_cpu_frame(Tensor & output,const Tensor & input,const Tensor & indices,int64_t oheight,int64_t owidth)', '    max_unpooling3d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output_,const Tensor & self,const Tensor & indices_,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_cpu(const Tensor & self,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_out_cpu(Tensor & output,const Tensor & self_,const Tensor & indices_,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_out_cpu_frame(Tensor & output,const Tensor & input,const Tensor & indices,int64_t oT,int64_t oH,int64_t oW,int64_t dT,int64_t dH,int64_t dW,int64_t pT,int64_t pH,int64_t pW)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\mean_op.cc', ['    GetMeanGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MeanGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\mean_op.h', ['    final', '    MeanGradientOp'], ['    DoRunWithType', '    MeanOp(Args,...)', '    RunOnDevice', '    ~MeanOp', '    DoRunWithType', '    MeanGradientOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\mem_arena.cpp', [], ['    GetKernelArenaStack', '    GetCurrentKernelArena', '    SetCurrentKernelArena(KernelArena *new_kernel_arena)', '    ~KernelArena', '    KernelScope', '    KernelScope(KernelArena *arena_)', '    ~KernelScope', '    KernelScopedObject']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\mem_arena.h', ['    KernelArena', '    KernelScope', '    KernelScopedObject'], ['    GetCurrentKernelArena', '    SetCurrentKernelArena(KernelArena *new_kernel_arena)', '    KernelArena', '    KernelArena', '    operator=', '    ~KernelArena', '    KernelScope', '    KernelScope(KernelArena *arena_)', '    KernelScope', '    operator=', '    ~KernelScope', '    KernelScopedObject', '    KernelScopedObject', '    operator=', '    ~KernelScopedObject']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\memonger.cc', ['    ComputeBlobRecyclingForDag'], ['    compute_blob_recycling_for_dag(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    optimize_inference_net(const NetDef & net,const std::set & static_blobs)', '    apply_assignments(const NetDef & net)', '    apply_recurrent_blob_assignments(OperatorDef *op)', '    can_use_blob(const string & blob_name,std::unordered_set *tokens,const DeviceOption & device_option)', '    ComputeBlobRecyclingForDag(const int size)', '    get_blob_or_mapped_blob(const string & blob_name)', '    get_free_blob(const string & blob_name,const std::unordered_map,vector,std::unordered_set *tokens,std::vector,string,const DeviceOption & device)', '    has_key(const std::unordered_map & in_map,const K & key)', '    has_key(const std::unordered_set & in_set,const K & key)', '    infer_blob_size(const string & blob_name,const std::unordered_map,vector)', '    OptimizeNet(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    process_op(const NetDef & net,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector,int op_index,std::vector,string,std::unordered_set *tokens)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\memonger.h', [], ['    compute_blob_recycling_for_dag(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    optimize_inference_net(const NetDef & net,const std::set & static_blobs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\memory.cpp', [], ['    TEST(MakeUniqueTest,ForwardRvaluesCorrectly)', '    TEST(MakeUniqueTest,ForwardLvaluesCorrectly)', '    TEST(MakeUniqueTest,CanConstructUniquePtrOfArray)', '    TestValue(const int & x)', '    TestValue(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Memory.cpp', [], ['    _debug_has_internal_overlap(const Tensor & self)', '    is_pinned(const Tensor & self)', '    pin_memory(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\memory.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\memory_dag.cpp', [], ['    bfs(BfsDirection dir,MemoryLocations & res)', '    Element(MemoryDAG & dag_,const Value *value_,unsigned index_)', '    getMemoryLocations', '    addToContainedElements(Element *elem,Element *container)', '    collectAllContainedMemoryLocations(const Element *elem,MemoryLocations & cont)', '    fromIndex(unsigned x)', '    fromIndex(unsigned x)', '    makeFreshValue(const Value *v)', '    makePointerTo(Element *from,Element *to)', '    mayAlias(const Element *a,const Element *b)', '    mayAlias(Element *a,Element *b)', '    mayAliasImpl(const Element *a,const Element *b)', '    mayContainAlias(const Element *a,const Element *b)', '    mayContainAlias(Element *a,Element *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    mayContainAliasImpl(const Element *a,const Element *b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\memory_dag.h', ['    BfsDirection', '    MemoryDAG'], ['    bfs(BfsDirection dir,MemoryLocations & res)', '    Element(MemoryDAG & dag_,const Value *value_,unsigned index_)', '    getMemoryLocations', '    addToContainedElements(Element *elem,Element *container)', '    collectAllContainedMemoryLocations(const Element *elem,MemoryLocations & cont)', '    fromIndex(unsigned x)', '    fromIndex(unsigned x)', '    makeFreshValue(const Value *v)', '    makePointerTo(Element *from,Element *to)', '    mayAlias(const Element *a,const Element *b)', '    mayAlias(Element *a,Element *b)', '    mayAliasImpl(const Element *a,const Element *b)', '    mayContainAlias(const Element *a,const Element *b)', '    mayContainAlias(Element *a,Element *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    mayContainAliasImpl(const Element *a,const Element *b)', '    MemoryDAG', '    MemoryDAG', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\memory_format_test.cpp', [], ['    memory_format', '    sliceFirst(Tensor & t,int dim,at::MemoryFormat format)', '    sliceStepTwo(Tensor & t,int dim,at::MemoryFormat format)', '    TEST(MemoryFormatTest,SetMemoryFormat)', '    TEST(MemoryFormatTest,TransposeMemoryFormat)', '    TEST(MemoryFormatTest,SliceStepTwoMemoryFormat)', '    TEST(MemoryFormatTest,SliceFirstMemoryFormat)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\memory_overlapping_test.cpp', [], ['    size_to_add', '    size_to_add', '    TEST(MemoryOverlapTest,TensorExpanded)', '    TEST(MemoryOverlapTest,ScalarExpanded)', '    TEST(MemoryOverlapTest,NonContiguousTensor)', '    TEST(MemoryOverlapTest,NonContiguousExpandedTensor)', '    TEST(MemoryOverlapTest,ContiguousTensor)', '    TEST(MemoryOverlapTest,ContiguousExpandedTensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\MemoryFormat.cpp', [], ['    self', '    THPMemoryFormat_init(PyObject *module)', '    THPMemoryFormat_New(at::MemoryFormat memory_format,const std::string & name)', '    THPMemoryFormat_repr(THPMemoryFormat *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\MemoryFormat.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\MemoryFormat.h', [], ['    THPMemoryFormat_Check(PyObject *obj)', '    THPMemoryFormat_init(PyObject *module)', '    THPMemoryFormat_New(at::MemoryFormat memory_format,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\MemoryOverlap.cpp', [], ['    assert_no_internal_overlap(const Tensor & t)', '    assert_no_internal_overlap(TensorImpl *t)', '    assert_no_partial_overlap(const Tensor & a,const Tensor & b)', '    assert_no_partial_overlap(TensorImpl *a,TensorImpl *b)', '    get_overlap_status(const Tensor & a,const Tensor & b)', '    get_overlap_status(TensorImpl *a,TensorImpl *b)', '    has_internal_overlap(const Tensor & tensor)', '    has_internal_overlap(TensorImpl *t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\MemoryOverlap.h', ['    MemOverlap', '    MemOverlapStatus'], ['    assert_no_internal_overlap(const Tensor & t)', '    assert_no_partial_overlap(const Tensor & a,const Tensor & b)', '    get_overlap_status(const Tensor & a,const Tensor & b)', '    has_internal_overlap(const Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\merge_id_lists_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeIdLists', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeIdLists']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\merge_id_lists_op.h', ['    MergeIdListsOp'], ['    DoRunWithType', '    MergeIdListsOp(Args,...)', '    RunOnDevice', '    ~MergeIdListsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\message.cpp', [], ['    id', '    isRequest', '    isResponse', '    Message(std::vector,std::vector,MessageType type)', '    Message(std::vector,std::vector,MessageType type,int64_t id)', '    operator=(Message const & rhs)', '    operator=(Message)', '    payload', '    setId(int64_t id)', '    swap(Message & rhs)', '    tensors', '    tensors', '    createExceptionResponse(const std::exception & e,int64_t id)', '    createExceptionResponse(const std::string & exceptionStr,int64_t id)', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\message.h', ['    final'], ['    createExceptionResponse(const std::exception & e,int64_t id)', '    createExceptionResponse(const std::string & exceptionStr,int64_t id)', '    id', '    isRequest', '    isResponse', '    isShutdown', '    Message(std::vector,std::vector,MessageType type)', '    Message(std::vector,std::vector,MessageType type,int64_t id)', '    Message(const Message & other)', '    operator=(Message const & rhs)', '    operator=(Message)', '    payload', '    setId(int64_t id)', '    swap(Message & rhs)', '    tensors', '    tensors', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Metaprogramming.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Metaprogramming.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\Metaprogramming_test.cpp', ['    MyClass', '    MyClass'], ['    expected', '    expected', '    expected', '    expected', '    expected', '    operator==(const MovableOnly & lhs,const MovableOnly & rhs)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_singleInput)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_movableOnly)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_onlyCopiesIfNecessary)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_onlyMovesIfNecessary)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_keepsLValueReferencesIntact)', '    TEST(MetaprogrammingTest,FilterMap)', '    TEST(MetaprogrammingTest,FilterMap_emptyInput)', '    TEST(MetaprogrammingTest,FilterMap_emptyOutput)', '    TEST(MetaprogrammingTest,FilterMap_movableOnly_byRValue)', '    TEST(MetaprogrammingTest,FilterMap_movableOnly_byValue)', '    TEST(MetaprogrammingTest,DISABLED_FilterMap_onlyCopiesIfNecessary)', '    TEST(MetaprogrammingTest,DISABLED_FilterMap_onlyMovesIfNecessary_1)', '    TEST(MetaprogrammingTest,FilterMap_onlyMovesIfNecessary_2)', '    CopyCounting', '    CopyCounting(const CopyCounting & rhs)', '    CopyCounting(CopyCounting)', '    operator=(const CopyCounting & rhs)', '    operator=(CopyCounting)', '    operator()(CopyCounting v)', '    operator()(CopyCounting)', '    operator()(const CopyCounting & v)', '    operator()(MovableOnly a)', '    operator()(MovableOnly)', '    MovableOnly(int val_)', '    operator()(T a)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\method.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\mini_environment.h', [], ['    begin', '    definedVariables', '    findInAnyFrame(const std::string & name)', '    findInThisFrame(const std::string & name)', '    MiniEnvironment(Block *b,std::shared_ptr next)', '    setVar(const std::string & name,T value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\miniz.c', [], ['    mz_write_le16(mz_uint8 *p,mz_uint16 v)', '    mz_write_le32(mz_uint8 *p,mz_uint32 v)', '    mz_write_le64(mz_uint8 *p,mz_uint64 v)', '    mz_zip_array_clear(mz_zip_archive *pZip,mz_zip_array *pArray)', '    mz_zip_array_ensure_capacity(mz_zip_archive *pZip,mz_zip_array *pArray,size_t min_new_capacity,mz_uint growing)', '    mz_zip_array_ensure_room(mz_zip_archive *pZip,mz_zip_array *pArray,size_t n)', '    mz_zip_array_init(mz_zip_array *pArray,mz_uint32 element_size)', '    mz_zip_array_push_back(mz_zip_archive *pZip,mz_zip_array *pArray,const void *pElements,size_t n)', '    mz_zip_array_reserve(mz_zip_archive *pZip,mz_zip_array *pArray,size_t new_capacity,mz_uint growing)', '    mz_zip_array_resize(mz_zip_archive *pZip,mz_zip_array *pArray,size_t new_size,mz_uint growing)', '    mz_zip_compute_crc32_callback(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    mz_zip_file_stat_internal(mz_zip_archive *pZip,mz_uint file_index,const mz_uint8 *pCentral_dir_header,mz_zip_archive_file_stat *pStat,mz_bool *pFound_zip64_extra_data)', '    mz_zip_filename_compare(const mz_zip_array *pCentral_dir_array,const mz_zip_array *pCentral_dir_offsets,mz_uint l_index,const char *pR,mz_uint r_len)', '    mz_zip_get_cdh(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_heap_write_func(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    mz_zip_locate_file_binary_search(mz_zip_archive *pZip,const char *pFilename,mz_uint32 *pIndex)', '    mz_zip_mem_read_func(void *pOpaque,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end_internal(mz_zip_archive *pZip,mz_bool set_last_error)', '    mz_zip_reader_filename_less(const mz_zip_array *pCentral_dir_array,const mz_zip_array *pCentral_dir_offsets,mz_uint l_index,mz_uint r_index)', '    mz_zip_reader_init_internal(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_reader_locate_header_sig(mz_zip_archive *pZip,mz_uint32 record_sig,mz_uint32 record_size,mz_int64 *pOfs)', '    mz_zip_reader_read_central_dir(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_reader_sort_central_dir_offsets_by_filename(mz_zip_archive *pZip)', '    mz_zip_set_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_string_equal(const char *pA,const char *pB,mz_uint len,mz_uint flags)', '    mz_zip_writer_add_put_buf_callback(const void *pBuf,int len,void *pUser)', '    mz_zip_writer_add_to_central_dir(mz_zip_archive *pZip,const char *pFilename,mz_uint16 filename_size,const void *pExtra,mz_uint16 extra_size,const void *pComment,mz_uint16 comment_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date,mz_uint64 local_header_ofs,mz_uint32 ext_attributes,const char *user_extra_data,mz_uint user_extra_data_len)', '    mz_zip_writer_compute_padding_needed_for_file_alignment(mz_zip_archive *pZip)', '    mz_zip_writer_create_central_dir_header(mz_zip_archive *pZip,mz_uint8 *pDst,mz_uint16 filename_size,mz_uint16 extra_size,mz_uint16 comment_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date,mz_uint64 local_header_ofs,mz_uint32 ext_attributes)', '    mz_zip_writer_create_local_dir_header(mz_zip_archive *pZip,mz_uint8 *pDst,mz_uint16 filename_size,mz_uint16 extra_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date)', '    mz_zip_writer_create_zip64_extra_data(mz_uint8 *pBuf,mz_uint64 *pUncomp_size,mz_uint64 *pComp_size,mz_uint64 *pLocal_header_ofs)', '    mz_zip_writer_end_internal(mz_zip_archive *pZip,mz_bool set_last_error)', '    mz_zip_writer_update_zip64_extension_block(mz_zip_array *pNew_ext,mz_zip_archive *pZip,const mz_uint8 *pExt,uint32_t ext_len,mz_uint64 *pComp_size,mz_uint64 *pUncomp_size,mz_uint64 *pLocal_header_ofs,mz_uint32 *pDisk_start)', '    mz_zip_writer_validate_archive_name(const char *pArchive_name)', '    mz_zip_writer_write_zeros(mz_zip_archive *pZip,mz_uint64 cur_file_ofs,mz_uint32 n)', '    tdefl_calculate_minimum_redundancy(tdefl_sym_freq *A,int n)', '    tdefl_compress_block(tdefl_compressor *d,mz_bool static_block)', '    tdefl_compress_lz_codes(tdefl_compressor *d)', '    tdefl_compress_normal(tdefl_compressor *d)', '    tdefl_find_match(tdefl_compressor *d,mz_uint lookahead_pos,mz_uint max_dist,mz_uint max_match_len,mz_uint *pMatch_dist,mz_uint *pMatch_len)', '    tdefl_flush_block(tdefl_compressor *d,int flush)', '    tdefl_flush_output_buffer(tdefl_compressor *d)', '    tdefl_huffman_enforce_max_code_size(int *pNum_codes,int code_list_len,int max_code_size)', '    tdefl_optimize_huffman_table(tdefl_compressor *d,int table_num,int table_len,int code_size_limit,int static_table)', '    tdefl_output_buffer_putter(const void *pBuf,int len,void *pUser)', '    tdefl_radix_sort_syms(mz_uint num_syms,tdefl_sym_freq *pSyms0,tdefl_sym_freq *pSyms1)', '    tdefl_record_literal(tdefl_compressor *d,mz_uint8 lit)', '    tdefl_record_match(tdefl_compressor *d,mz_uint match_len,mz_uint match_dist)', '    tdefl_start_dynamic_block(tdefl_compressor *d)', '    tdefl_start_static_block(tdefl_compressor *d)', '    miniz_def_alloc_func(void *opaque,size_t items,size_t size)', '    miniz_def_free_func(void *opaque,void *address)', '    miniz_def_realloc_func(void *opaque,void *address,size_t items,size_t size)', '    mz_adler32(mz_ulong adler,const unsigned char *ptr,size_t buf_len)', '    mz_compress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_compress2(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len,int level)', '    mz_compressBound(mz_ulong source_len)', '    mz_crc32(mz_ulong crc,const mz_uint8 *ptr,size_t buf_len)', '    mz_deflate(mz_streamp pStream,int flush)', '    mz_deflateBound(mz_streamp pStream,mz_ulong source_len)', '    mz_deflateEnd(mz_streamp pStream)', '    mz_deflateInit(mz_streamp pStream,int level)', '    mz_deflateInit2(mz_streamp pStream,int level,int method,int window_bits,int mem_level,int strategy)', '    mz_deflateReset(mz_streamp pStream)', '    mz_error(int err)', '    mz_free(void *p)', '    mz_inflate(mz_streamp pStream,int flush)', '    mz_inflateEnd(mz_streamp pStream)', '    mz_inflateInit(mz_streamp pStream)', '    mz_inflateInit2(mz_streamp pStream,int window_bits)', '    mz_uncompress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_version', '    mz_zip_clear_last_error(mz_zip_archive *pZip)', '    mz_zip_end(mz_zip_archive *pZip)', '    mz_zip_get_archive_file_start_offset(mz_zip_archive *pZip)', '    mz_zip_get_archive_size(mz_zip_archive *pZip)', '    mz_zip_get_central_dir_size(mz_zip_archive *pZip)', '    mz_zip_get_cfile(mz_zip_archive *pZip)', '    mz_zip_get_error_string(mz_zip_error mz_err)', '    mz_zip_get_last_error(mz_zip_archive *pZip)', '    mz_zip_get_mode(mz_zip_archive *pZip)', '    mz_zip_get_type(mz_zip_archive *pZip)', '    mz_zip_is_zip64(mz_zip_archive *pZip)', '    mz_zip_peek_last_error(mz_zip_archive *pZip)', '    mz_zip_read_archive_data(mz_zip_archive *pZip,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end(mz_zip_archive *pZip)', '    mz_zip_reader_extract_file_iter_new(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_reader_extract_file_to_callback(mz_zip_archive *pZip,const char *pFilename,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_file_to_heap(mz_zip_archive *pZip,const char *pFilename,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem_no_alloc(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_extract_iter_free(mz_zip_reader_extract_iter_state *pState)', '    mz_zip_reader_extract_iter_new(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_reader_extract_iter_read(mz_zip_reader_extract_iter_state *pState,void *pvBuf,size_t buf_size)', '    mz_zip_reader_extract_to_callback(mz_zip_archive *pZip,mz_uint file_index,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_to_heap(mz_zip_archive *pZip,mz_uint file_index,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_to_mem(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_to_mem_no_alloc(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_file_stat(mz_zip_archive *pZip,mz_uint file_index,mz_zip_archive_file_stat *pStat)', '    mz_zip_reader_get_filename(mz_zip_archive *pZip,mz_uint file_index,char *pFilename,mz_uint filename_buf_size)', '    mz_zip_reader_get_num_files(mz_zip_archive *pZip)', '    mz_zip_reader_init(mz_zip_archive *pZip,mz_uint64 size,mz_uint flags)', '    mz_zip_reader_init_mem(mz_zip_archive *pZip,const void *pMem,size_t size,mz_uint flags)', '    mz_zip_reader_is_file_a_directory(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_encrypted(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_supported(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_locate_file(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags)', '    mz_zip_reader_locate_file_v2(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags,mz_uint32 *pIndex)', '    mz_zip_set_last_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_validate_archive(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_validate_file(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_validate_mem_archive(const void *pMem,size_t size,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_writer_add_from_zip_reader(mz_zip_archive *pZip,mz_zip_archive *pSource_zip,mz_uint src_file_index)', '    mz_zip_writer_add_mem(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,mz_uint level_and_flags)', '    mz_zip_writer_add_mem_ex(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32)', '    mz_zip_writer_add_mem_ex_v2(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32,mz_dummy_time_t *last_modified,const char *user_extra_data,mz_uint user_extra_data_len,const char *user_extra_data_central,mz_uint user_extra_data_central_len)', '    mz_zip_writer_end(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_archive(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_heap_archive(mz_zip_archive *pZip,void **ppBuf,size_t *pSize)', '    mz_zip_writer_init(mz_zip_archive *pZip,mz_uint64 existing_size)', '    mz_zip_writer_init_from_reader(mz_zip_archive *pZip,const char *pFilename)', '    mz_zip_writer_init_from_reader_v2(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_writer_init_heap(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size)', '    mz_zip_writer_init_heap_v2(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size,mz_uint flags)', '    mz_zip_writer_init_v2(mz_zip_archive *pZip,mz_uint64 existing_size,mz_uint flags)', '    mz_zip_zero_struct(mz_zip_archive *pZip)', '    tdefl_compress(tdefl_compressor *d,const void *pIn_buf,size_t *pIn_buf_size,void *pOut_buf,size_t *pOut_buf_size,tdefl_flush flush)', '    tdefl_compress_buffer(tdefl_compressor *d,const void *pIn_buf,size_t in_buf_size,tdefl_flush flush)', '    tdefl_compress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tdefl_compress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tdefl_compress_mem_to_output(const void *pBuf,size_t buf_len,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_compressor_alloc', '    tdefl_compressor_free(tdefl_compressor *pComp)', '    tdefl_create_comp_flags_from_zip_params(int level,int window_bits,int strategy)', '    tdefl_get_adler32(tdefl_compressor *d)', '    tdefl_get_prev_return_status(tdefl_compressor *d)', '    tdefl_init(tdefl_compressor *d,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_write_image_to_png_file_in_memory(const void *pImage,int w,int h,int num_chans,size_t *pLen_out)', '    tdefl_write_image_to_png_file_in_memory_ex(const void *pImage,int w,int h,int num_chans,size_t *pLen_out,mz_uint level,mz_bool flip)', '    tinfl_decompress(tinfl_decompressor *r,const mz_uint8 *pIn_buf_next,size_t *pIn_buf_size,mz_uint8 *pOut_buf_start,mz_uint8 *pOut_buf_next,size_t *pOut_buf_size,const mz_uint32 decomp_flags)', '    tinfl_decompress_mem_to_callback(const void *pIn_buf,size_t *pIn_buf_size,tinfl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tinfl_decompress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tinfl_decompress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tinfl_decompressor_alloc', '    tinfl_decompressor_free(tinfl_decompressor *pDecomp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\third_party\\miniz-2.0.8\\miniz.h', [], ['    miniz_def_alloc_func(void *opaque,size_t items,size_t size)', '    miniz_def_free_func(void *opaque,void *address)', '    miniz_def_realloc_func(void *opaque,void *address,size_t items,size_t size)', '    mz_adler32(mz_ulong adler,const unsigned char *ptr,size_t buf_len)', '    mz_compress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_compress2(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len,int level)', '    mz_compressBound(mz_ulong source_len)', '    mz_crc32(mz_ulong crc,const mz_uint8 *ptr,size_t buf_len)', '    mz_deflate(mz_streamp pStream,int flush)', '    mz_deflateBound(mz_streamp pStream,mz_ulong source_len)', '    mz_deflateEnd(mz_streamp pStream)', '    mz_deflateInit(mz_streamp pStream,int level)', '    mz_deflateInit2(mz_streamp pStream,int level,int method,int window_bits,int mem_level,int strategy)', '    mz_deflateReset(mz_streamp pStream)', '    mz_error(int err)', '    mz_free(void *p)', '    mz_inflate(mz_streamp pStream,int flush)', '    mz_inflateEnd(mz_streamp pStream)', '    mz_inflateInit(mz_streamp pStream)', '    mz_inflateInit2(mz_streamp pStream,int window_bits)', '    mz_uncompress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_version', '    mz_zip_add_mem_to_archive_file_in_place(const char *pZip_filename,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags)', '    mz_zip_add_mem_to_archive_file_in_place_v2(const char *pZip_filename,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_zip_error *pErr)', '    mz_zip_clear_last_error(mz_zip_archive *pZip)', '    mz_zip_end(mz_zip_archive *pZip)', '    mz_zip_extract_archive_file_to_heap(const char *pZip_filename,const char *pArchive_name,size_t *pSize,mz_uint flags)', '    mz_zip_extract_archive_file_to_heap_v2(const char *pZip_filename,const char *pArchive_name,const char *pComment,size_t *pSize,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_get_archive_file_start_offset(mz_zip_archive *pZip)', '    mz_zip_get_archive_size(mz_zip_archive *pZip)', '    mz_zip_get_central_dir_size(mz_zip_archive *pZip)', '    mz_zip_get_cfile(mz_zip_archive *pZip)', '    mz_zip_get_error_string(mz_zip_error mz_err)', '    mz_zip_get_last_error(mz_zip_archive *pZip)', '    mz_zip_get_mode(mz_zip_archive *pZip)', '    mz_zip_get_type(mz_zip_archive *pZip)', '    mz_zip_is_zip64(mz_zip_archive *pZip)', '    mz_zip_peek_last_error(mz_zip_archive *pZip)', '    mz_zip_read_archive_data(mz_zip_archive *pZip,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end(mz_zip_archive *pZip)', '    mz_zip_reader_extract_file_iter_new(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_reader_extract_file_to_callback(mz_zip_archive *pZip,const char *pFilename,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_file_to_heap(mz_zip_archive *pZip,const char *pFilename,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem_no_alloc(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_extract_iter_free(mz_zip_reader_extract_iter_state *pState)', '    mz_zip_reader_extract_iter_new(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_reader_extract_iter_read(mz_zip_reader_extract_iter_state *pState,void *pvBuf,size_t buf_size)', '    mz_zip_reader_extract_to_callback(mz_zip_archive *pZip,mz_uint file_index,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_to_heap(mz_zip_archive *pZip,mz_uint file_index,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_to_mem(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_to_mem_no_alloc(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_file_stat(mz_zip_archive *pZip,mz_uint file_index,mz_zip_archive_file_stat *pStat)', '    mz_zip_reader_get_filename(mz_zip_archive *pZip,mz_uint file_index,char *pFilename,mz_uint filename_buf_size)', '    mz_zip_reader_get_num_files(mz_zip_archive *pZip)', '    mz_zip_reader_init(mz_zip_archive *pZip,mz_uint64 size,mz_uint flags)', '    mz_zip_reader_init_mem(mz_zip_archive *pZip,const void *pMem,size_t size,mz_uint flags)', '    mz_zip_reader_is_file_a_directory(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_encrypted(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_supported(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_locate_file(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags)', '    mz_zip_reader_locate_file_v2(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags,mz_uint32 *pIndex)', '    mz_zip_set_last_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_validate_archive(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_validate_file(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_validate_file_archive(const char *pFilename,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_validate_mem_archive(const void *pMem,size_t size,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_writer_add_from_zip_reader(mz_zip_archive *pZip,mz_zip_archive *pSource_zip,mz_uint src_file_index)', '    mz_zip_writer_add_mem(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,mz_uint level_and_flags)', '    mz_zip_writer_add_mem_ex(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32)', '    mz_zip_writer_add_mem_ex_v2(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32,mz_dummy_time_t *last_modified,const char *user_extra_data,mz_uint user_extra_data_len,const char *user_extra_data_central,mz_uint user_extra_data_central_len)', '    mz_zip_writer_end(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_archive(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_heap_archive(mz_zip_archive *pZip,void **ppBuf,size_t *pSize)', '    mz_zip_writer_init(mz_zip_archive *pZip,mz_uint64 existing_size)', '    mz_zip_writer_init_from_reader(mz_zip_archive *pZip,const char *pFilename)', '    mz_zip_writer_init_from_reader_v2(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_writer_init_heap(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size)', '    mz_zip_writer_init_heap_v2(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size,mz_uint flags)', '    mz_zip_writer_init_v2(mz_zip_archive *pZip,mz_uint64 existing_size,mz_uint flags)', '    mz_zip_zero_struct(mz_zip_archive *pZip)', '    tdefl_compress(tdefl_compressor *d,const void *pIn_buf,size_t *pIn_buf_size,void *pOut_buf,size_t *pOut_buf_size,tdefl_flush flush)', '    tdefl_compress_buffer(tdefl_compressor *d,const void *pIn_buf,size_t in_buf_size,tdefl_flush flush)', '    tdefl_compress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tdefl_compress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tdefl_compress_mem_to_output(const void *pBuf,size_t buf_len,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_compressor_alloc', '    tdefl_compressor_free(tdefl_compressor *pComp)', '    tdefl_create_comp_flags_from_zip_params(int level,int window_bits,int strategy)', '    tdefl_get_adler32(tdefl_compressor *d)', '    tdefl_get_prev_return_status(tdefl_compressor *d)', '    tdefl_init(tdefl_compressor *d,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_write_image_to_png_file_in_memory(const void *pImage,int w,int h,int num_chans,size_t *pLen_out)', '    tdefl_write_image_to_png_file_in_memory_ex(const void *pImage,int w,int h,int num_chans,size_t *pLen_out,mz_uint level,mz_bool flip)', '    tinfl_decompress(tinfl_decompressor *r,const mz_uint8 *pIn_buf_next,size_t *pIn_buf_size,mz_uint8 *pOut_buf_start,mz_uint8 *pOut_buf_next,size_t *pOut_buf_size,const mz_uint32 decomp_flags)', '    tinfl_decompress_mem_to_callback(const void *pIn_buf,size_t *pIn_buf_size,tinfl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tinfl_decompress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tinfl_decompress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tinfl_decompressor_alloc', '    tinfl_decompressor_free(tinfl_decompressor *pDecomp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\minmax_gradient_ops.cc', ['    GetMaxGradient', '    GetMinGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MinGradient', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\minmax_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Max', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Min']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\minmax_ops.h', ['    final', '    final', '    final', '    final', '    SelectGradientOpBase'], ['    MaxGradientOp(Args,...)', '    MaxOp(Args,...)', '    MinGradientOp(Args,...)', '    MinOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~MaxGradientOp', '    ~MaxOp', '    ~MinGradientOp', '    ~MinOp', '    RunOnDevice', '    SelectGradientOpBase(Args,...)', '    ~SelectGradientOpBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\miopen-wrapper.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\hip\\miopen_wrapper.h', ['    MIOPENState', '    MIOPENWrapper'], ['    after_', '    before_', '    execute(hipStream_t stream,F)', '    gpu_id_', '    miopen_handle', '    miopen_handle_', '    MIOPENState(size_t gpu_id)', '    stream_', '    workspace', '    ~MIOPENState', '    get(size_t nbytes)', '    nbytes_', '    reset', '    ~MIOPENWorkspace', '    inline_miopen_handle', '    MIOPENWrapper(HIPContext *context)', '    with_miopen_state(size_t state_idx,F)', '  Static Member Variables', '    CAFFE2_COMPILE_TIME_MAX_MIOPEN_STATES']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\misc.cpp', [], ['    torch_warn_once_12', '    torch_warn_once_16', '    TEST(UtilsTest,WarnOnce)', '    TEST(NoGradTest,SetsGradModeCorrectly)', '    TEST_F(AutogradTest,CanTakeDerivatives)', '    TEST_F(AutogradTest,CanTakeDerivativesOfZeroDimTensors)', '    TEST_F(AutogradTest,CanPassCustomGradientInputs)', '    torch_warn', '    torch_warn_once_A', '    torch_warn_once_B', '    AutogradTest']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\MiscUtils.h', [], ['    pin_memory(int64_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\MKLDNNCommon.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\MKLDNNCommon.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\MKLDNNConversions.cpp', [], ['    dense_to_mkldnn(const Tensor & cpu_tensor)', '    mkldnn_reorder_conv2d_weight(const Tensor & self,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    mkldnn_to_dense(const Tensor & mkldnn_tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\MkldnnTensorMath.cpp', [], ['    mkldnn_zero_(Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\mmio.h', [], ['    StoreMatrixInMatrixMarketFormat(int m,int n,const T *a,const std::string & matrix_name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\data\\datasets\\mnist.cpp', [], ['    check_is_little_endian', '    expect_int32(std::ifstream & stream,uint32_t expected)', '    flip_endianness(uint32_t value)', '    join_paths(std::string head,const std::string & tail)', '    read_images(const std::string & root,bool train)', '    read_int32(std::ifstream & stream)', '    read_targets(const std::string & root,bool train)', '    get(size_t index)', '    images', '    is_train', '    MNIST(const std::string & root,Mode mode)', '    size', '    targets']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\mnist.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\mobile.cc', ['    AddNNPACK', '    FuseNNPACKConvRelu'], ['    addNNPACK(repr::NNModule *nn,bool low_memory)', '    fuseNNPACKConvRelu(repr::NNModule *nn)', '    isNNPACKConvReluEfficient(const std::string & algo,const repr::Conv & conv)', '    postprocess', '    run', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\mobile.h', [], ['    addNNPACK(nom::repr::NNModule *nn,bool low_memory)', '    fuseNNPACKConvRelu(nom::repr::NNModule *nn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\mobile_test.cc', [], ['    TEST(MobileTest,Convolution)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\mod_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMod', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mod', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\mod_op.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    ModOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\module.cc', [], ['    CurrentModuleHandles', '    gModuleChangeMutex', '    MutableCurrentModules', '    CurrentModules', '    HasModule(const string & name)', '    LoadModule(const string & name,const string & filename)', '    ModuleSchema(const char *name,const char *description)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\module.cpp', [], ['    slot_params_recurse(const c10::intrusive_ptr & obj,std::vector *params)', '    find_function(const c10::QualifiedName & qn)', '    register_function(std::unique_ptr fn)', '    name', '    qualname', '    find_method(const std::string & basename)', '    parameters', '    run_method(const std::string & method_name,Stack stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Module.cpp', [], ['    LogAPIUsageOnceFromPython(const std::string & event)', '    THPModule_crashIfATenASAN(PyObject *module,PyObject *arg)', '    THPModule_crashIfCsrcASAN(PyObject *module,PyObject *arg)', '    THPModule_crashIfCsrcUBSAN(PyObject *module,PyObject *arg)', '    THPModule_getBackcompatBroadcastWarn(PyObject *module,PyObject *noargs)', '    THPModule_getBackcompatKeepdimWarn(PyObject *module,PyObject *noargs)', '    THPModule_getNumInteropThreads(PyObject *module,PyObject *noargs)', '    THPModule_getNumThreads(PyObject *module,PyObject *noargs)', '    THPModule_initExtension(PyObject *_unused,PyObject *shm_manager_path)', '    THPModule_initNames(PyObject *self,PyObject *arg)', '    THPModule_parallelInfo(PyObject *module,PyObject *noargs)', '    THPModule_setBackcompatBroadcastWarn(PyObject *module,PyObject *arg)', '    THPModule_setBackcompatKeepdimWarn(PyObject *module,PyObject *arg)', '    THPModule_setNumInteropThreads(PyObject *module,PyObject *arg)', '    THPModule_setNumThreads(PyObject *module,PyObject *arg)', '    THPModule_showConfig(PyObject *module,PyObject *noargs)', '    DLPack_Capsule_Destructor(PyObject *data)', '    initModule', '    pytorch_duplicate_guard', '    THPModule_addDocStr(PyObject *_unused,PyObject *args)', '    THPModule_benchmarkCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_deterministicCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_fromDLPack(PyObject *_unused,PyObject *data)', '    THPModule_getDefaultDevice(PyObject *_unused,PyObject *arg)', '    THPModule_getDefaultDtype(PyObject *_unused,PyObject *arg)', '    THPModule_hasDistributed(PyObject *_unused,PyObject *noargs)', '    THPModule_inferSize(PyObject *_unused,PyObject *args)', '    THPModule_isEnabledXNNPACK(PyObject *)', '    THPModule_qEngine(PyObject *)', '    THPModule_safeCall(PyObject *_unused,PyObject *args,PyObject *kwargs)', '    THPModule_setBenchmarkCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setDefaultDtype(PyObject *_unused,PyObject *dtype)', '    THPModule_setDefaultTensorType(PyObject *_unused,PyObject *type)', '    THPModule_setDeterministicCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setFlushDenormal(PyObject *_unused,PyObject *arg)', '    THPModule_setQEngine(PyObject *,PyObject *arg)', '    THPModule_setUserEnabledCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setUserEnabledMkldnn(PyObject *_unused,PyObject *arg)', '    THPModule_supportedQEngines(PyObject *)', '    THPModule_toDLPack(PyObject *_unused,PyObject *data)', '    THPModule_userEnabledCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_userEnabledMkldnn(PyObject *_unused,PyObject *noargs)', '    call_duplicate_guard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\module.cpp', [], ['    create_module_object(c10::QualifiedName class_name,std::shared_ptr cu,bool shouldMangle)', '    isModule', '    Method(ModulePtr owner,Function *function)', '    operator()(std::vector stack,const Kwargs & kwargs)', '    owner', '    run(Stack & stack)', '    toModule', '    getInlineEverythingMode', '    module_state_to(autograd::Variable variable,const c10::optional & device,const c10::optional & dtype,bool non_blocking)', '    apply(const std::function & fn)', '    attributes(bool recurse)', '    buffers(bool recurse)', '    children', '    clone', '    clone_impl(std::unordered_map & type_remap)', '    clone_instance', '    clone_method(const Module & orig,const Function & method,const std::unordered_map & type_remap)', '    clone_method(const Module & orig,const std::string & name)', '    create_class(const c10::QualifiedName & name,Stack stack)', '    dump(bool print_method_bodies,bool print_attr_values,bool print_param_values)', '    dump_to_str(bool print_method_bodies,bool print_attr_values,bool print_param_values,int level)', '    Module(c10::QualifiedName class_name)', '    Module(std::shared_ptr cu,const c10::ClassTypePtr & type)', '    Module(c10::QualifiedName class_name,std::shared_ptr cu,bool shouldMangle)', '    modules', '    named_attributes(bool recurse)', '    named_buffers(bool recurse)', '    named_children', '    named_modules', '    named_parameters(bool recurse)', '    parameters(bool recurse)', '    to(at::Device device,at::ScalarType dtype,bool non_blocking)', '    to(at::ScalarType dtype,bool non_blocking)', '    to(at::Device device,bool non_blocking)', '    to_impl(const c10::optional & device,const c10::optional & dtype,bool non_blocking)', '    train(bool on)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\module.cpp', ['    A', '    ModuleWithNonTensorForward'], ['    get_test_container_item(std::shared_ptr module)', '    make_deeply_nested_test_container', '    test_DeviceOrDtypeConversionSkipsUndefinedTensor(torch::Device to_device,torch::Dtype to_dtype)', '    TEST_F(ModuleTest,CanEnableAndDisableTrainingMode)', '    TEST_F(ModuleTest,ZeroGrad)', '    TEST_F(ModuleTest,ZeroGradWithUndefined)', '    TEST_F(ModuleTest,RegisterModuleThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterModuleThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,ReplaceModuleThrowsForUnknownModuleName)', '    TEST_F(ModuleTest,ReplaceModule)', '    TEST_F(ModuleTest,UnregisterModule)', '    TEST_F(ModuleTest,RegisterParameterThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterParameterThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,RegisterParameterUndefinedTensor)', '    TEST_F(ModuleTest,RegisterBufferThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterBufferThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,CanGetName)', '    TEST_F(ModuleTest,AsCastsModulesCorrectly)', '    TEST_F(ModuleTest,DeviceOrDtypeConversionSkipsUndefinedTensor)', '    TEST_F(ModuleTest,DeviceOrDtypeConversionSkipsUndefinedTensor_CUDA)', '    TEST_F(ModuleTest,ParametersAndBuffersAccessorSkipsUndefinedTensor)', '    TEST_F(ModuleTest,Conversion_MultiCUDA)', '    TEST_F(ModuleTest,CallingCloneOnModuleThatDoesNotOverrideCloneThrows)', '    TEST_F(ModuleTest,CallingCloneOnModuleThatDoesOverrideCloneDoesNotThrow)', '    TEST_F(ModuleTest,CloneCreatesDistinctParameters)', '    TEST_F(ModuleTest,CloneCreatesDistinctParametersExplicitDevice_CUDA)', '    TEST_F(ModuleTest,CloneCreatesDistinctParametersExplicitDevice_MultiCUDA)', '    TEST_F(ModuleTest,ClonePreservesExternalReferences)', '    TEST_F(ModuleTest,CloneCopiesTheValuesOfVariablesOfSubmodules)', '    TEST_F(ModuleTest,CloneToDevicePreservesTheDeviceOfParameters_CUDA)', '    TEST_F(ModuleTest,CloningToAParticularDevicePlacesAllParametersThere_MultiCUDA)', '    TEST_F(ModuleTest,HasCorrectNumberOfParameters)', '    TEST_F(ModuleTest,ContainsParametersWithTheCorrectName)', '    TEST_F(ModuleTest,HasCorrectNumberOfBuffers)', '    TEST_F(ModuleTest,ContainsBuffersWithTheCorrectName)', '    TEST_F(ModuleTest,DefaultConstructorOfModuleHolderCallsDefaultConstructorOfImpl)', '    TEST_F(ModuleTest,ValueConstructorOfModuleHolderCallsCorrectConstructorInImpl)', '    TEST_F(ModuleTest,NullptrConstructorLeavesTheModuleHolderInEmptyState)', '    TEST_F(ModuleTest,ModulesReturnsExpectedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,ModulesExcludesSelfWhenIncludeSelfSetToFalse)', '    TEST_F(ModuleTest,NamedModulesReturnsExpectedNamedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,NamedModulesExcludesSelfWhenIncludeSelfSetToFalse)', '    TEST_F(ModuleTest,ChildrenReturnsExpectedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,NamedChildrenReturnsExpectedNamedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,ParametersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,NamedParametersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,BuffersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,NamedBuffersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,ModulesReturnsExpectedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,NamedModulesReturnsExpectedNamedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,ChildrensReturnsExpectedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,NamedChildrensReturnsExpectedNamedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,ModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ConstModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,NamedModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ConstNamedModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ModulePointerApplyIteratesCorreclty)', '    TEST_F(ModuleTest,NamedModulePointerApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ThrowsWhenAttemptingtoGetTopLevelModuleAsSharedPtr)', '    TEST_F(ModuleTest,PrettyPrint)', '    TEST_F(ModuleTest,CanCallForwardOnNonTensorForwardThroughPimpl)', '    testDistinctParameters(std::shared_ptr m1,std::shared_ptr m2)', '    AImpl', '    AImpl(int x)', '    BufferTestModule', '    clone(const torch::optional & device)', '    forward(torch::Tensor x)', '    NestedModule', '    reset', '    ParameterTestModule', '    AGIUnit2', '    TestContainer(int64_t number,std::vector modules)', '    l1', '    l2', '    l3', '    reset', '    TestDistinctParametersModule', '    l1', '    TestModel', '    forward(torch::Tensor input)', '    l1', '    l1', '    l2', '    l2', '    l3', '    l3', '    pretty_print(std::ostream & stream)', '    reset', '    reset', '    reset', '    reset', '    TestModule', '    TestModule', '    TestModule', '    TestModule', '    TestModule', '    TestModule(int64_t size)', '    TestModule(int x,float y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\module.cpp', [], ['    apply_to_submodules(const NamedModulePointerApplyFunction & function,const std::string & name_prefix)', '    clone_(Module & other,const optional & device)', '    eval', '    is_serializable', '    is_training', '    load(serialize::InputArchive & archive)', '    operator<<(std::ostream & stream,const nn::Module & module)', '    operator<<(serialize::OutputArchive & archive,const std::shared_ptr & module)', '    operator>>(serialize::InputArchive & archive,const std::shared_ptr & module)', '    pretty_print(std::ostream & stream)', '    pretty_print_recursive(std::ostream & stream,const std::string & indentation)', '    register_buffer(std::string name,Tensor tensor)', '    register_parameter(std::string name,Tensor tensor,bool requires_grad)', '    save(serialize::OutputArchive & archive)', '    shared_from_this_checked', '    to(torch::Device device,torch::Dtype dtype,bool non_blocking)', '    to(torch::Dtype dtype,bool non_blocking)', '    to(torch::Device device,bool non_blocking)', '    join_name(const std::string & name_prefix,const std::string & name)', '    train(bool on)', '    unregister_module(const std::string & name)', '    zero_grad', '    apply(const ModuleApplyFunction & function)', '    apply(const ConstModuleApplyFunction & function)', '    apply(const NamedModuleApplyFunction & function,const std::string & name_prefix)', '    apply(const ConstNamedModuleApplyFunction & function,const std::string & name_prefix)', '    apply(const ModulePointerApplyFunction & function)', '    apply(const NamedModulePointerApplyFunction & function,const std::string & name_prefix)', '    buffers(bool recurse)', '    clone(const optional & device)', '    Module', '    Module(std::string name)', '    name', '    named_buffers(bool recurse)', '    named_parameters(bool recurse)', '    parameters(bool recurse)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Module.cpp', [], ['    bindCudaDeviceProperties(PyObject *module)', '    forked_child', '    poison_fork', '    THCPModule_initExtension(PyObject *self,PyObject *noargs)', '    THCPModule_isInBadFork(PyObject *self,PyObject *noargs)', '    THCPModule_cudaCachingAllocator_raw_alloc(PyObject *_unused,PyObject *args)', '    THCPModule_cudaCachingAllocator_raw_delete(PyObject *_unused,PyObject *obj)', '    THCPModule_cudaHostAllocator(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaIPCCollect(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaLockMutex(PyObject *module,PyObject *noargs)', '    THCPModule_cudaSleep(PyObject *_unused,PyObject *cycles)', '    THCPModule_cudaSynchronize(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaUnlockMutex(PyObject *module,PyObject *noargs)', '    THCPModule_emptyCache(PyObject *_unused,PyObject *noargs)', '    THCPModule_getCompiledVersion(PyObject *self,PyObject *noargs)', '    THCPModule_getCurrentBlasHandle_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getCurrentStream_wrap(PyObject *,PyObject *device_index)', '    THCPModule_getDefaultStream_wrap(PyObject *,PyObject *device_index)', '    THCPModule_getDevice_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getDeviceCount_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getDriverVersion(PyObject *self,PyObject *noargs)', '    THCPModule_hasPrimaryContext(PyObject *_unused,PyObject *arg)', '    THCPModule_isDriverSufficient(PyObject *self,PyObject *noargs)', '    THCPModule_memorySnapshot(PyObject *_unused,PyObject *noargs)', '    THCPModule_memoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_methods', '    THCPModule_resetAccumulatedMemoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_resetPeakMemoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_setDevice(int device)', '    THCPModule_setDevice_wrap(PyObject *self,PyObject *arg)', '    THCPModule_setStream_wrap(PyObject *self,PyObject *obj)', '    initModule(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\module.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\module.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\module.h', ['    CompilationUnit', '    Module'], ['    find_function(const c10::QualifiedName & qn)', '    register_function(std::unique_ptr fn)', '    find_method(const std::string & basename)', '    forward(std::vector inputs)', '    Module(c10::intrusive_ptr object,std::shared_ptr cu)', '    Module', '    name', '    parameters', '    run_method(const std::string & method_name,Stack stack)', '    slots']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\module.h', ['    ModuleSchema'], ['    CurrentModules', '    HasModule(const string & name)', '    LoadModule(const string & name,const string & filename)', '    ModuleSchema(const char *name,const char *description)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Module.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Module.h', [], ['    THCPModule_getCurrentBlasHandle_wrap(PyObject *self)', '    THCPModule_getDevice_wrap(PyObject *self)', '    THCPModule_getDeviceName_wrap(PyObject *self,PyObject *arg)', '    THCPModule_getDriverVersion(PyObject *self)', '    THCPModule_isDriverSufficient(PyObject *self)', '    THCPModule_setDevice(int device)', '    THCPModule_setDevice_wrap(PyObject *self,PyObject *arg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\module_python.h', [], ['    as_module(const py::object & obj)', '    import', '    isinstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\module_save.cpp', [], ['    _save_for_mobile(std::ostream & out,const ExtraFilesMap & extra_files)', '    _save_for_mobile(const std::string & filename,const ExtraFilesMap & extra_files)', '    save(std::ostream & out,const ExtraFilesMap & extra_files)', '    save(const std::string & filename,const ExtraFilesMap & extra_files)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\module_test.cc', ['    Caffe2ModuleTestStaticDummyOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCaffe2ModuleTestStaticDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Caffe2ModuleTestStaticDummy', '    TEST(ModuleTest,StaticModule)', '    gCaffe2ModuleSanityCheckcaffe2_module_test_static', '    Run(int)', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\module_test\\module_test_dynamic.cc', ['    Caffe2ModuleTestDynamicDummyOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCaffe2ModuleTestDynamicDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Caffe2ModuleTestDynamicDummy', '    gCaffe2ModuleSanityCheckcaffe2_module_test_dynamic', '    Run(int)', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\modulelist.cpp', ['    M'], ['    M(const M & other)', '    TEST_F(ModuleListTest,RangeBasedForLoop)', '    TEST_F(ModuleListTest,PrettyPrintModuleList)', '    TEST_F(ModuleListTest,CloneToDevice_CUDA)', '    TEST_F(ModuleListTest,NestingIsPossible)', '    TEST_F(ModuleListTest,RegistersElementsAsSubmodules)', '    TEST_F(ModuleListTest,IsCloneable)', '    TEST_F(ModuleListTest,HasReferenceSemantics)', '    TEST_F(ModuleListTest,ExtendPushesModulesFromOtherModuleList)', '    TEST_F(ModuleListTest,SanityCheckForHoldingStandardModules)', '    TEST_F(ModuleListTest,AccessWithPtr)', '    TEST_F(ModuleListTest,ConstructsFromSharedPointer)', '    TEST_F(ModuleListTest,ConstructsFromConcreteType)', '    TEST_F(ModuleListTest,ConstructsFromModuleHolder)', '    TEST_F(ModuleListTest,PushBackAddsAnElement)', '    TEST_F(ModuleListTest,Insertion)', '    TEST_F(ModuleListTest,AccessWithAt)', '    MImpl(int value_)', '    MImpl(int value_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\modulelist.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\modules.cpp', ['    NestedModel', '    TestModel'], ['    align_corners', '    align_corners', '    align_corners', '    align_corners', '    alpha', '    alpha', '    beta', '    _batchmatmul(const torch::Tensor & a,const torch::Tensor & b)', '    _combine_heads_ref(const torch::Tensor & X,at::IntArrayRef dims,int nheads,int d_head)', '    _fc(torch::Tensor X,torch::Tensor X_weight,torch::Tensor X_bias)', '    _multihead_attn_test_helper(bool add_key_padding_mask,bool add_bias_kv,bool add_zero_attn,bool saved_kv,bool same_embed_dim)', '    _scaled_dot_attn_ref(const torch::Tensor & Q,const torch::Tensor & K,const torch::Tensor & V,at::IntArrayRef dims,const torch::Tensor & unseen_mask,const torch::Tensor & key_padding_mask)', '    _softmax(const torch::Tensor & x)', '    _split_heads_ref(const torch::Tensor & X,at::IntArrayRef dims,int nheads,int d_head)', '    dims', '    ht', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    lambda', '    lambda', '    loss', '    loss', '    loss', '    loss', '    loss', '    loss', '    lower', '    max_val', '    min_val', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    negative_slope', '    pool', '    pool', '    pool', '    scale_factor', '    scale_factor', '    scale_factor', '    scale_factor', '    TEST_F(ModulesTest,Conv1d)', '    TEST_F(ModulesTest,Conv2dEven)', '    TEST_F(ModulesTest,Conv2dUneven)', '    TEST_F(ModulesTest,Conv3d)', '    TEST_F(ModulesTest,ConvTranspose1d)', '    TEST_F(ModulesTest,ConvTranspose2dEven)', '    TEST_F(ModulesTest,ConvTranspose2dUneven)', '    TEST_F(ModulesTest,ConvTranspose3d)', '    TEST_F(ModulesTest,MaxPool1d)', '    TEST_F(ModulesTest,MaxPool1dReturnIndices)', '    TEST_F(ModulesTest,MaxPool2dEven)', '    TEST_F(ModulesTest,MaxPool2dUneven)', '    TEST_F(ModulesTest,MaxPool2dReturnIndices)', '    TEST_F(ModulesTest,MaxPool3d)', '    TEST_F(ModulesTest,MaxPool3dReturnIndices)', '    TEST_F(ModulesTest,AvgPool1d)', '    TEST_F(ModulesTest,AvgPool2dEven)', '    TEST_F(ModulesTest,AvgPool2dUneven)', '    TEST_F(ModulesTest,AvgPool3d)', '    TEST_F(ModulesTest,FractionalMaxPool2d)', '    TEST_F(ModulesTest,FractionalMaxPool2dReturnIndices)', '    TEST_F(ModulesTest,FractionalMaxPool3d)', '    TEST_F(ModulesTest,FractionalMaxPool3dReturnIndices)', '    TEST_F(ModulesTest,LPPool1d)', '    TEST_F(ModulesTest,LPPool2d)', '    TEST_F(ModulesTest,Identity)', '    TEST_F(ModulesTest,Flatten)', '    TEST_F(ModulesTest,AdaptiveMaxPool1d)', '    TEST_F(ModulesTest,AdaptiveMaxPool1dReturnIndices)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dEven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dUneven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dReturnIndicesEven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dReturnIndicesUneven)', '    TEST_F(ModulesTest,AdaptiveMaxPool3d)', '    TEST_F(ModulesTest,AdaptiveMaxPool3dReturnIndices)', '    TEST_F(ModulesTest,AdaptiveAvgPool1d)', '    TEST_F(ModulesTest,AdaptiveAvgPool2dEven)', '    TEST_F(ModulesTest,AdaptiveAvgPool2dUneven)', '    TEST_F(ModulesTest,AdaptiveAvgPool3d)', '    TEST_F(ModulesTest,MaxUnpool1d)', '    TEST_F(ModulesTest,MaxPool1d_MaxUnpool1d)', '    TEST_F(ModulesTest,MaxUnpool2d)', '    TEST_F(ModulesTest,MaxPool2d_MaxUnpool2d)', '    TEST_F(ModulesTest,MaxUnpool3d)', '    TEST_F(ModulesTest,MaxUnpool3dOutputSize)', '    TEST_F(ModulesTest,MaxPool3d_MaxUnpool3d)', '    TEST_F(ModulesTest,Linear)', '    TEST_F(ModulesTest,LocalResponseNorm)', '    TEST_F(ModulesTest,LayerNorm)', '    TEST_F(ModulesTest,GroupNorm)', '    TEST_F(ModulesTest,Bilinear)', '    TEST_F(ModulesTest,Fold)', '    TEST_F(ModulesTest,Unfold)', '    TEST_F(ModulesTest,SimpleContainer)', '    TEST_F(ModulesTest,EmbeddingBasic)', '    TEST_F(ModulesTest,EmbeddingList)', '    TEST_F(ModulesTest,EmbeddingFromPretrained)', '    TEST_F(ModulesTest,EmbeddingBagFromPretrained)', '    TEST_F(ModulesTest,AlphaDropout)', '    TEST_F(ModulesTest,FeatureAlphaDropout)', '    TEST_F(ModulesTest,Dropout)', '    TEST_F(ModulesTest,Dropout2d)', '    TEST_F(ModulesTest,Dropout3d)', '    TEST_F(ModulesTest,Parameters)', '    TEST_F(ModulesTest,FunctionalCallsSuppliedFunction)', '    TEST_F(ModulesTest,FunctionalWithTorchFunction)', '    TEST_F(ModulesTest,FunctionalArgumentBinding)', '    TEST_F(ModulesTest,BatchNorm1dStateful)', '    TEST_F(ModulesTest,BatchNorm1dStateless)', '    TEST_F(ModulesTest,BatchNorm1d)', '    TEST_F(ModulesTest,BatchNorm2dStateful)', '    TEST_F(ModulesTest,BatchNorm2dStateless)', '    TEST_F(ModulesTest,BatchNorm2d)', '    TEST_F(ModulesTest,BatchNorm3dStateful)', '    TEST_F(ModulesTest,BatchNorm3dStateless)', '    TEST_F(ModulesTest,BatchNorm3d)', '    TEST_F(ModulesTest,InstanceNorm1dStateful)', '    TEST_F(ModulesTest,InstanceNorm1dStateless)', '    TEST_F(ModulesTest,InstanceNorm1d)', '    TEST_F(ModulesTest,InstanceNorm2dStateful)', '    TEST_F(ModulesTest,InstanceNorm2dStateless)', '    TEST_F(ModulesTest,InstanceNorm2d)', '    TEST_F(ModulesTest,InstanceNorm3dStateful)', '    TEST_F(ModulesTest,InstanceNorm3dStateless)', '    TEST_F(ModulesTest,InstanceNorm3d)', '    TEST_F(ModulesTest,Linear_CUDA)', '    TEST_F(ModulesTest,Linear2_CUDA)', '    TEST_F(ModulesTest,L1Loss)', '    TEST_F(ModulesTest,MSELoss)', '    TEST_F(ModulesTest,BCELoss)', '    TEST_F(ModulesTest,KLDivLoss)', '    TEST_F(ModulesTest,HingeEmbeddingLoss)', '    TEST_F(ModulesTest,MultiMarginLoss)', '    TEST_F(ModulesTest,CosineEmbeddingLoss)', '    TEST_F(ModulesTest,SmoothL1LossDefaultOptions)', '    TEST_F(ModulesTest,MultiLabelMarginLossDefaultOptions)', '    TEST_F(ModulesTest,SmoothL1LossNoReduction)', '    TEST_F(ModulesTest,MultiLabelMarginLossNoReduction)', '    TEST_F(ModulesTest,TripletMarginLoss)', '    TEST_F(ModulesTest,NLLLoss)', '    TEST_F(ModulesTest,CrossEntropyLoss)', '    TEST_F(ModulesTest,CosineSimilarity)', '    TEST_F(ModulesTest,SoftMarginLossDefaultOptions)', '    TEST_F(ModulesTest,MultiLabelSoftMarginLossDefaultOptions)', '    TEST_F(ModulesTest,SoftMarginLossNoReduction)', '    TEST_F(ModulesTest,MultiLabelSoftMarginLossWeightedNoReduction)', '    TEST_F(ModulesTest,PairwiseDistance)', '    TEST_F(ModulesTest,ELU)', '    TEST_F(ModulesTest,SELU)', '    TEST_F(ModulesTest,Hardshrink)', '    TEST_F(ModulesTest,Hardtanh)', '    TEST_F(ModulesTest,HardtanhMinValGEMaxVal)', '    TEST_F(ModulesTest,LeakyReLU)', '    TEST_F(ModulesTest,LogSigmoid)', '    TEST_F(ModulesTest,Softmax)', '    TEST_F(ModulesTest,Softmin)', '    TEST_F(ModulesTest,LogSoftmax)', '    TEST_F(ModulesTest,AdaptiveLogSoftmaxWithLoss)', '    TEST_F(ModulesTest,Softmax2d)', '    TEST_F(ModulesTest,PReLU)', '    TEST_F(ModulesTest,ReLU)', '    TEST_F(ModulesTest,ReLU6)', '    TEST_F(ModulesTest,RReLU)', '    TEST_F(ModulesTest,CELU)', '    TEST_F(ModulesTest,GLU)', '    TEST_F(ModulesTest,GELU)', '    TEST_F(ModulesTest,Sigmoid)', '    TEST_F(ModulesTest,PixelShuffle)', '    TEST_F(ModulesTest,Softplus)', '    TEST_F(ModulesTest,Softshrink)', '    TEST_F(ModulesTest,Softsign)', '    TEST_F(ModulesTest,Tanh)', '    TEST_F(ModulesTest,Tanhshrink)', '    TEST_F(ModulesTest,Threshold)', '    TEST_F(ModulesTest,Upsampling1D)', '    TEST_F(ModulesTest,Upsampling2D)', '    TEST_F(ModulesTest,Upsampling3D)', '    TEST_F(ModulesTest,CTCLoss)', '    TEST_F(ModulesTest,PoissonNLLLoss)', '    TEST_F(ModulesTest,MarginRankingLoss)', '    TEST_F(ModulesTest,BCEWithLogitsLoss)', '    TEST_F(ModulesTest,MultiheadAttention)', '    TEST_F(ModulesTest,PrettyPrintIdentity)', '    TEST_F(ModulesTest,PrettyPrintFlatten)', '    TEST_F(ModulesTest,ReflectionPad1d)', '    TEST_F(ModulesTest,ReflectionPad2d)', '    TEST_F(ModulesTest,ReplicationPad1d)', '    TEST_F(ModulesTest,ReplicationPad2d)', '    TEST_F(ModulesTest,ReplicationPad3d)', '    TEST_F(ModulesTest,ZeroPad2d)', '    TEST_F(ModulesTest,ConstantPad1d)', '    TEST_F(ModulesTest,ConstantPad2d)', '    TEST_F(ModulesTest,ConstantPad3d)', '    TEST_F(ModulesTest,CrossMapLRN2d)', '    TEST_F(ModulesTest,RNNCell)', '    TEST_F(ModulesTest,LSTMCell)', '    TEST_F(ModulesTest,GRUCell)', '    TEST_F(ModulesTest,PrettyPrintLinear)', '    TEST_F(ModulesTest,PrettyPrintBilinear)', '    TEST_F(ModulesTest,PrettyPrintConv)', '    TEST_F(ModulesTest,PrettyPrintConvTranspose)', '    TEST_F(ModulesTest,PrettyPrintUpsample)', '    TEST_F(ModulesTest,PrettyPrintFold)', '    TEST_F(ModulesTest,PrettyPrintUnfold)', '    TEST_F(ModulesTest,PrettyPrintMaxPool)', '    TEST_F(ModulesTest,PrettyPrintAvgPool)', '    TEST_F(ModulesTest,PrettyPrinFractionalMaxPool)', '    TEST_F(ModulesTest,PrettyPrintLPPool)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveMaxPool)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveAvgPool)', '    TEST_F(ModulesTest,PrettyPrintMaxUnpool)', '    TEST_F(ModulesTest,PrettyPrintDropout)', '    TEST_F(ModulesTest,PrettyPrintDropout2d)', '    TEST_F(ModulesTest,PrettyPrintDropout3d)', '    TEST_F(ModulesTest,PrettyPrintFunctional)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm1d)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm2d)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm3d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm1d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm2d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm3d)', '    TEST_F(ModulesTest,PrettyPrintLayerNorm)', '    TEST_F(ModulesTest,PrettyPrintGroupNorm)', '    TEST_F(ModulesTest,PrettyPrintLocalResponseNorm)', '    TEST_F(ModulesTest,PrettyPrintEmbedding)', '    TEST_F(ModulesTest,PrettyPrintEmbeddingBag)', '    TEST_F(ModulesTest,PrettyPrintL1Loss)', '    TEST_F(ModulesTest,PrettyPrintKLDivLoss)', '    TEST_F(ModulesTest,PrettyPrintMSELoss)', '    TEST_F(ModulesTest,PrettyPrintBCELoss)', '    TEST_F(ModulesTest,PrettyPrintHingeEmbeddingLoss)', '    TEST_F(ModulesTest,PrettyPrintCosineEmbeddingLoss)', '    TEST_F(ModulesTest,PrettyPrintTripletMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintNLLLoss)', '    TEST_F(ModulesTest,PrettyPrinCrossEntropyLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiLabelMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiLabelSoftMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintSoftMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintCosineSimilarity)', '    TEST_F(ModulesTest,PrettyPrintPairwiseDistance)', '    TEST_F(ModulesTest,PrettyPrintReflectionPad)', '    TEST_F(ModulesTest,PrettyPrintReplicationPad)', '    TEST_F(ModulesTest,PrettyPrintZeroPad2d)', '    TEST_F(ModulesTest,PrettyPrintConstantPad)', '    TEST_F(ModulesTest,PrettyPrintNestedModel)', '    TEST_F(ModulesTest,PrettyPrintELU)', '    TEST_F(ModulesTest,PrettyPrintSELU)', '    TEST_F(ModulesTest,PrettyPrintGLU)', '    TEST_F(ModulesTest,PrettyPrintHardshrink)', '    TEST_F(ModulesTest,PrettyPrintHardtanh)', '    TEST_F(ModulesTest,PrettyPrintLeakyReLU)', '    TEST_F(ModulesTest,PrettyPrintLogSigmoid)', '    TEST_F(ModulesTest,PrettyPrintSoftmax)', '    TEST_F(ModulesTest,PrettyPrintSoftmin)', '    TEST_F(ModulesTest,PrettyPrintLogSoftmax)', '    TEST_F(ModulesTest,PrettyPrintSoftmax2d)', '    TEST_F(ModulesTest,PrettyPrintPReLU)', '    TEST_F(ModulesTest,PrettyPrintReLU)', '    TEST_F(ModulesTest,PrettyPrintReLU6)', '    TEST_F(ModulesTest,PrettyPrintRReLU)', '    TEST_F(ModulesTest,PrettyPrintCELU)', '    TEST_F(ModulesTest,PrettyPrintSigmoid)', '    TEST_F(ModulesTest,PrettyPrintPixelShuffle)', '    TEST_F(ModulesTest,PrettyPrintSoftplus)', '    TEST_F(ModulesTest,PrettyPrintSoftshrink)', '    TEST_F(ModulesTest,PrettyPrintSoftsign)', '    TEST_F(ModulesTest,PrettyPrintTanh)', '    TEST_F(ModulesTest,PrettyPrintTanhshrink)', '    TEST_F(ModulesTest,PrettyPrintThreshold)', '    TEST_F(ModulesTest,PrettyPrintCTCLoss)', '    TEST_F(ModulesTest,PrettyPrintPoissonNLLLoss)', '    TEST_F(ModulesTest,PrettyPrintMarginRankingLoss)', '    TEST_F(ModulesTest,PrettyPrintCrossMapLRN2d)', '    TEST_F(ModulesTest,PrettyPrintAlphaDropout)', '    TEST_F(ModulesTest,PrettyPrintFeatureAlphaDropout)', '    TEST_F(ModulesTest,PrettyPrintBCEWithLogitsLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiheadAttention)', '    TEST_F(ModulesTest,PrettyPrintRNNCell)', '    TEST_F(ModulesTest,PrettyPrintLSTMCell)', '    TEST_F(ModulesTest,PrettyPrintGRUCell)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveLogSoftmaxWithLoss)', '    threshold', '    threshold', '    unpool', '    unpool', '    unpool', '    upper', '    value', '    InnerTestModule', '    NestedModel', '    TestModel', '    TestModule']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\moments_op.cc', ['    GetMomentsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMoments', '    CAFFE_ANONYMOUS_VARIABLE_CPUMomentsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Moments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentsGradient', '    GetGradientDefs', '    Compute(const std::vector & dY_dims,const std::vector & dX_dims,const T *dmean_data,const T *dvariance_data,const T *X_data,const T *mean_data,T *dX_data)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\moments_op.h', ['    final', '    final'], ['    Compute(const std::vector & dY_dims,const std::vector & dX_dims,const T *dmean_data,const T *dvariance_data,const T *X_data,const T *mean_data,T *dX_data)', '    GetRepeatedArgument', '    MomentsGradientOp(Args,...)', '    MomentsOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\momentum_sgd_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMomentumSGD', '    CAFFE_ANONYMOUS_VARIABLE_CPUMomentumSGDUpdate', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseMomentumSGDUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentumSGD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentumSGDUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseMomentumSGDUpdate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\momentum_sgd_op.cc', ['    final', '    final'], ['    momentum_sgd_update(const int N,const float *g,const float *m,float *ng,float *nm,const float *lr,const float momentum,const bool nesterov,float *param)', '    IDEEPMomentumSGDOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPMomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\momentum_sgd_op.h', ['    final', '    final', '    final'], ['    momentum_sgd_update(const int N,const float *g,const float *m,float *ng,float *nm,const float *lr,const float momentum,const bool nesterov,float *param,Context *)', '    DoRunWithType', '    GetSingleArgument', '    momentum_', '    momentum_', '    MomentumSGDOp(const OperatorDef & operator_def,Workspace *ws)', '    MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseMomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8dwconv\\mp8x25-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8dwconv\\mp8x25-neon.c', [], ['    pytorch_q8dwconv_ukernel_mp8x25__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8dwconv\\mp8x25-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8dwconv\\mp8x25-sse2.c', [], ['    pytorch_q8dwconv_ukernel_mp8x25__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\mp8x7p7q-neon.c', [], ['    pytorch_q8gavgpool_ukernel_mp8x7p7q__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\mp8x7p7q-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\mp8x7p7q-sse2.c', [], ['    pytorch_q8gavgpool_ukernel_mp8x7p7q__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\mp8x7p7q-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\mp8x9p8q-neon.c', [], ['    pytorch_q8avgpool_ukernel_mp8x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\mp8x9p8q-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\mp8x9p8q-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\mp8x9p8q-sse2.c', [], ['    pytorch_q8avgpool_ukernel_mp8x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_common.cc', [], ['    AssimilateComm(MPI_Comm intra,MPI_Comm inter)', '    GlobalMPIComm', '    MPICommRank(MPI_Comm comm)', '    MPICommSize(MPI_Comm comm)', '    MPIMutex', '    MPISetupPeers(const int replicas,const string & role,const string & job_path)', '    SetGlobalMPIComm(MPI_Comm new_comm)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_common.h', ['    MPICommonWorldWrapper', '    MPIDataTypeWrapper', '    MPIDataTypeWrapper', '    MPIDataTypeWrapper'], ['    CheckInitializedMPI', '    GlobalMPIComm', '    MPICommRank(MPI_Comm comm)', '    MPICommSize(MPI_Comm comm)', '    MPIMutex', '    MPISetupPeers(const int replicas,const string & role,const string & job_path)', '    SetGlobalMPIComm(MPI_Comm new_comm)', '    type', '    type', '    type', '    comm', '    MPICommonWorldWrapper(MPI_Comm src_comm,int color,int rank)', '    rank', '    size', '    ~MPICommonWorldWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_gpu_test.cc', ['    C10FlagParser_caffe_test_root'], ['    TEST(MPITest,TestMPIAllreduce)', '    TEST(MPITest,TestMPIBroadcast)', '    TEST(MPITest,TestInPlaceMPIAllreduce)', '    TEST(MPITest,TestMPIAllgather)', '    TEST(MPITest,TestMPIReduce)', '    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMPIAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPICreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIReduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPISendTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIAllgather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIAllreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIBroadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPICreateCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIReceiveTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIReduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPISendTensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_ops.h', ['    final', '    final', '    final', '    final', '    final', '    final', '    final'], ['    MPIAllgatherOp(Args,...)', '    MPIAllreduceOp(Args,...)', '    MPIBroadcastOp(const OperatorDef & operator_def,Workspace *ws)', '    MPICreateCommonWorldOp(const OperatorDef & operator_def,Workspace *ws)', '    MPIReceiveTensorOp(const OperatorDef & def,Workspace *ws)', '    MPIReduceOp(const OperatorDef & operator_def,Workspace *ws)', '    MPISendTensorOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~MPIAllgatherOp', '    ~MPIAllreduceOp', '    ~MPIBroadcastOp', '    ~MPIReduceOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_ops_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPICreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPISendTensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\mpi_python.cc', [], ['    PYBIND11_MODULE(mpi_utils,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mpi\\mpi_test.cc', ['    C10FlagParser_caffe_test_root'], ['    TEST(MPITest,TestMPIAllreduce)', '    TEST(MPITest,TestMPIBroadcast)', '    TEST(MPITest,TestInPlaceMPIAllreduce)', '    TEST(MPITest,TestMPIAllgather)', '    TEST(MPITest,TestMPIReduce)', '    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\mpscnn\\mpscnn.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\mpscnn\\mpscnn_context.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\mpscnn\\mpscnn_graph_mask.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\mpscnn\\mpscnn_kernels.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\mpscnn\\mpscnn_test.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\msnpu_extension.cpp', [], ['    add_override(const Tensor & a,const Tensor & b,Scalar c)', '    empty_override(IntArrayRef size,const TensorOptions & options)', '    fake_convolution(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    fake_convolution_backward(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups,std::array output_mask)', '    get_tensor(caffe2::TypeMeta dtype,IntArrayRef size)', '    get_test_int', '    init_msnpu_extension', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    block(void *event,const Stream & stream)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDevice', '    getStream(Device d)', '    MSNPUGuardImpl', '    MSNPUGuardImpl(DeviceType t)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\MT19937RNGEngine.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\mul_cpu.cc', [], ['    mul_op_cpu_impl(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & C_,bool legacy_broadcast,int64_t axis)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\multi_class_accuracy_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMultiClassAccuracy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MultiClassAccuracy', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\multi_class_accuracy_op.h', ['    final'], ['    MultiClassAccuracyOp(Args,...)', '    RunOnDevice', '    ~MultiClassAccuracyOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\MultinomialKernel.cpp', [], ['    multinomial_kernel_impl(Tensor & result,const Tensor & self,const int64_t n_sample,const bool with_replacement,Generator gen)', '    multinomial_apply(Tensor & result,const Tensor & self,const int64_t n_sample,const bool with_replacement,Generator generator)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\murmur_hash3.cc', [], ['    MurmurHash3_x64_128(const void *key,const int len,const uint32_t seed,void *out)', '    MurmurHash3_x86_128(const void *key,const int len,uint32_t seed,void *out)', '    MurmurHash3_x86_32(const void *key,int len,uint32_t seed,void *out)', '    fmix32(uint32_t h)', '    fmix64(uint64_t k)', '    getblock32(const uint32_t *p,int i)', '    getblock64(const uint64_t *p,int i)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\murmur_hash3.h', [], ['    MurmurHash3_x64_128(const void *key,int len,uint32_t seed,void *out)', '    MurmurHash3_x86_128(const void *key,int len,uint32_t seed,void *out)', '    MurmurHash3_x86_32(const void *key,int len,uint32_t seed,void *out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\NaiveConvolutionTranspose2d.cpp', [], ['    slow_conv_transpose2d_backward_out_cpu_template(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_input,const Tensor & weight_,const Tensor & grad_columns_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int kernel_height,int kernel_width,int stride_height,int stride_width,int pad_height,int pad_width,int output_padding_height,int output_padding_width,int dilation_height,int dilation_width,bool weight_nullable)', '    slow_conv_transpose2d_acc_grad_parameters_cpu(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_weight,Tensor & grad_bias,const Tensor & columns_,const Tensor & ones_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,int scale_)', '    slow_conv_transpose2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & columns,const Tensor & ones,std::array output_mask)', '    slow_conv_transpose2d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & columns,const Tensor & ones)', '    slow_conv_transpose2d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_out_cpu(Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_out_cpu_template(Tensor & output,const Tensor & input_,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias_,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,Tensor & columns_,Tensor & ones_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\NaiveConvolutionTranspose3d.cpp', [], ['    slow_conv_transpose3d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int kernel_depth,int kernel_width,int kernel_height,int stride_depth,int stride_width,int stride_height,int padding_depth,int padding_width,int padding_height,int dilation_depth,int dilation_width,int dilation_height,int output_padding_depth,int output_padding_width,int output_padding_height,int weight_nullable)', '    slow_conv_transpose3d_acc_grad_parameters_cpu(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_weight,Tensor & grad_bias,const Tensor & finput,const Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,int scale_)', '    slow_conv_transpose3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & finput,const Tensor & fgrad,std::array output_mask)', '    slow_conv_transpose3d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & finput,const Tensor & fgrad)', '    slow_conv_transpose3d_backward_out_cpu_template(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_input,const Tensor & weight_,const Tensor & finput,const Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_out_cpu(Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_out_cpu_template(Tensor & output,const Tensor & input_,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias_,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,Tensor & finput,Tensor & fgrad_input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\NaiveDilatedConvolution.cpp', [], ['    col2hvol(const Dtype *data_col,const int channels,const IntArrayRef input_size,const IntArrayRef output_size,const IntArrayRef kernel_size,const IntArrayRef stride_size,const IntArrayRef pad_size,const IntArrayRef dilation_size,Dtype *data_hvol)', '    hvol2col(const Dtype *data_hvol,const int channels,const IntArrayRef input_size,const IntArrayRef output_size,const IntArrayRef kernel_size,const IntArrayRef stride_size,const IntArrayRef pad_size,const IntArrayRef dilation_size,Dtype *data_col)', '    slow_conv_dilated2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size,const std::array output_mask)', '    slow_conv_dilated2d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size,const std::array output_mask)', '    slow_conv_dilated3d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_all_cpu_template(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output,Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_location_check(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\named_any.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\named_value.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\NamedTensor.cpp', [], ['    check_unique_names(DimnameList names)', '    get_named_tensor_meta(TensorImpl *impl)', '    get_named_tensor_meta(const TensorImpl *impl)', '    check_names_valid_for(const Tensor & tensor,DimnameList names)', '    check_names_valid_for(size_t tensor_dim,DimnameList names)', '    default_names(size_t len)', '    check_names_valid_for(TensorImpl *impl,DimnameList names)', '    get_names(const TensorImpl *impl)', '    get_opt_names(const TensorImpl *impl)', '    has_names(const TensorImpl *impl)', '    internal_set_names_inplace(TensorImpl *impl,optional names,bool validate_names)', '    internal_set_names_inplace(TensorImpl *impl,std::vector,bool validate_names)', '    internal_set_names_inplace(Tensor & tensor,optional names)', '    internal_set_names_inplace(Tensor & tensor,std::vector,bool validate_names)', '    has_names', '    is_enabled', '    set_enabled(bool enabled)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\NamedTensor.cpp', [], ['    align(const Tensor & tensor,DimnameList names,bool is_aligning_two_tensors)', '    align_tensors_to(TensorList tensors,DimnameList names)', '    aligned_size(IntArrayRef tensor_sizes,DimnameList tensor_names,DimnameList aligned_names,bool is_aligning_two_tensors)', '    countUnset(std::bitset,int64_t up_to_idx)', '    cumprod(IntArrayRef sizes)', '    report_moving_unnamed_dim_error(DimnameList names,DimnameList,bool is_aligning_two_tensors)', '    report_not_a_subsequence_error(DimnameList names,DimnameList other,bool is_aligning_two_tensors)', '    align_as(const Tensor & tensor,const Tensor & other)', '    align_tensors(TensorList tensors)', '    align_to(const Tensor & tensor,DimnameList order,int64_t ellipsis_idx)', '    align_to(const Tensor & tensor,DimnameList names)', '    gather(const Tensor & self,Dimname dim,const Tensor & index,bool sparse_grad)', '    gather_out(Tensor & result,const Tensor & self,Dimname dim,const Tensor & index,bool sparse_grad)', '    index_add(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_add_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_copy(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_copy_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_fill(const Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    index_fill(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_fill_(Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    index_fill_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_select(const Tensor & self,Dimname dim,const Tensor & index)', '    index_select_out(Tensor & out,const Tensor & self,Dimname dim,const Tensor & index)', '    refine_names(const Tensor & self,DimnameList names)', '    rename(const Tensor & self,optional names)', '    rename_(Tensor & self,optional names)', '    scatter(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter(const Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    scatter_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter_(Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    scatter_add(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter_add_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    sort(const Tensor & self,Dimname dim,bool keepdim)', '    sort_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    squeeze(const Tensor & self,Dimname dim)', '    squeeze_(Tensor & self,Dimname dim)', '    unflatten(const Tensor & self,int64_t dim,IntArrayRef sizes,DimnameList names)', '    unflatten(const Tensor & self,Dimname dim,IntArrayRef sizes,DimnameList names)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\NamedTensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\NamedTensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\NamedTensor_test.cpp', [], ['    check_unify(DimnameList names,DimnameList other_names,DimnameList expected)', '    check_unify_error(DimnameList names,DimnameList other_names)', '    dimnameFromString(const std::string & str)', '    dimnames_equal(at::DimnameList names,at::DimnameList other)', '    nchw', '    tensornames_unify_from_right(DimnameList names,DimnameList other_names)', '    TEST(NamedTensorTest,defaultMetadata)', '    TEST(NamedTensorTest,isNamed)', '    TEST(NamedTensorTest,attachMetadata)', '    TEST(NamedTensorTest,internalSetNamesInplace)', '    TEST(NamedTensorTest,empty)', '    TEST(NamedTensorTest,dimnameToPosition)', '    TEST(NamedTensorTest,unifyFromRight)', '    TEST(NamedTensorTest,alias)', '    TEST(NamedTensorTest,NoNamesGuard)', '    TEST(NamedTensorTest,TensorNamePrint)', '    TEST(NamedTensorTest,TensorNamesCheckUnique)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\NamedTensorUtils.cpp', [], ['    check_for_misalignment(const Dimname & name,DimnameList names,DimnameList other_names,const char *action)', '    are_distinct(DimnameList batch_dims,DimnameList feature_dims)', '    assert_names_equal(DimnameList a,DimnameList b)', '    batch_dims(DimnameList names)', '    check_feature_names_are_distinct(DimnameList self_names,DimnameList other_names,DimnameList outnames)', '    compute_dot_product_outnames(DimnameList tensor_names,int64_t tensor_dotted_dim,DimnameList other_names,int64_t other_dotted_dim)', '    compute_included_idxs(IntArrayRef excluded_idxs,int64_t ndims)', '    compute_matmul_outnames(DimnameList self_names,DimnameList other_names)', '    feature_dims(DimnameList names)', '    num_batch_dims(DimnameList names)', '    report_positional_error(const Dimname & name,const Dimname & other_name,DimnameList names,DimnameList other_names,const char *action)', '    toDimnameRepr(const Tensor & tensor)', '    dimname_to_position(const Tensor & tensor,Dimname dim)', '    dimnames_to_positions(const Tensor & tensor,DimnameList dims)', '    are_names_equal(TensorImpl *self,TensorImpl *other)', '    broadcast_to_outnames(const Tensor & tensor,const Tensor & reference_tensor,const char *op_name)', '    check_names_for_dot(TensorImpl *vec1,TensorImpl *vec2)', '    compute_baddbmm_outnames(TensorImpl *result,TensorImpl *batch1,TensorImpl *batch2,TensorImpl *bias)', '    compute_bmm_outnames(Tensor & result,const Tensor & self,const Tensor & other)', '    compute_broadcast_outnames(const Tensor & self,const Tensor & other)', '    compute_cat_outnames(TensorList tensors)', '    compute_cdist_outnames(const Tensor & self,const Tensor & other)', '    compute_diagonal_outnames(const Tensor & tensor,int64_t dim1,int64_t dim2)', '    compute_matmul_outnames(const Tensor & self,const Tensor & other)', '    compute_squeeze_outnames(const Tensor & tensor)', '    propagate_names(TensorImpl *result,DimnameList names,bool validate_names)', '    propagate_names(Tensor & result,const Tensor & src)', '    propagate_names(TensorImpl *result,TensorImpl *src)', '    propagate_names(Tensor & result,DimnameList names,bool validate_names)', '    propagate_names_except(Tensor & result,const Tensor & src,IntArrayRef excluded_idxs)', '    propagate_names_for_addmm(TensorImpl *result,TensorImpl *m1,TensorImpl *m2,TensorImpl *bias)', '    propagate_names_for_addmv(TensorImpl *result,TensorImpl *mat,TensorImpl *vec,TensorImpl *bias)', '    propagate_names_for_expand(Tensor & result,const Tensor & self)', '    propagate_names_for_reduction(Tensor & result,const Tensor & src,IntArrayRef reduced_dims,bool keepdim)', '    propagate_names_if_nonempty(TensorImpl *result,DimnameList maybe_names,bool validate_names)', '    propagate_names_if_nonempty(Tensor & result,DimnameList maybe_names,bool validate_names)', '    unify_from_right(DimnameList names,DimnameList other_names,const char *action)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\NamedTensorUtils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\namespace.cpp', [], ['    NotLeakingSymbolsFromTorchAutogradNamespace_test_func(Node *node)', '    TEST(NamespaceTests,NotLeakingSymbolsFromTorchAutogradNamespace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\native_test.cpp', [], ['    requireEqualTensorList(TensorList t1,TensorList t2)', '    test(TensorOptions T,TensorOptions AccT)', '    TEST(TestNative,NativeTestCPU)', '    TEST(TestNative,NativeTestGPU)', '    TestChunk(TensorOptions T,Tensor & t)', '    TestMatmul(TensorOptions T,Tensor & t,TensorOptions AccT)', '    TestSize(TensorOptions T,Tensor & t)', '    TestSplit(TensorOptions,Tensor & t)', '    TestStack(TensorOptions T,Tensor & t)', '    TestStandardGammaGrad(TensorOptions T,Tensor & t)', '    TestWhere(TensorOptions T,Tensor & t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\NativeFunctions.h', [], ['    $', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values)', '    tensor(uint8_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(uint8_t value)', '    tensor(std::initializer_list values)', '    tensor(int8_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(int8_t value)', '    tensor(std::initializer_list values)', '    tensor(int16_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(int16_t value)', '    tensor(std::initializer_list values)', '    tensor(int value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(int value)', '    tensor(std::initializer_list values)', '    tensor(int64_t value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(int64_t value)', '    tensor(std::initializer_list values)', '    tensor(float value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(float value)', '    tensor(std::initializer_list values)', '    tensor(double value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(double value)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\nccl.cpp', [], ['    get_device', '    broadcast(TensorList tensors,const stream_list & streams,const comm_list & user_comms)', '    check_inputs(TensorList inputs,TensorList outputs,int input_multiplier,int output_multiplier)', '    get_communicators(TensorList inputs)', '    get_data_type(const Tensor & t)', '    throw_nccl_error(ncclResult_t status)', '    get_max_count', '    is_available(TensorList tensors)', '    reduce(const std::vector & inputs,std::vector & outputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    reduce(std::vector & inputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    version', '    NcclCommList(const std::vector & devices)', '    ref', '    ~NcclCommList']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\nccl.h', [], ['    NCCL_CHECK(ncclResult_t status)', '    broadcast(at::TensorList tensors,const stream_list & streams,const comm_list & user_comms)', '    check_inputs(at::TensorList inputs,at::TensorList outputs,int input_multiplier,int output_multiplier)', '    get_data_type(const at::Tensor & t)', '    throw_nccl_error(ncclResult_t status)', '    get_max_count', '    reduce(const std::vector & inputs,std::vector & outputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    reduce(std::vector & inputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    version', '    AutoNcclGroup', '    ~AutoNcclGroup']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\NCCLUtils.cpp', [], ['    getNcclVersion', '    ncclGetErrorWithVersion(ncclResult_t error)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\NCCLUtils.hpp', ['    NCCLComm'], ['    getNcclVersion', '    ncclGetErrorWithVersion(ncclResult_t error)', '    create(int numRanks,int rank,ncclUniqueId commId)', '    checkForNcclError', '    getNcclComm', '    getNcclId', '    isAborted', '    NCCLComm(ncclComm_t ncclComm)', '    NCCLComm', '    NCCLComm', '    NCCLComm(NCCLComm)', '    ncclCommAbort', '    operator=', '    operator=', '    ~NCCLComm']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negate_gradient_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNegateGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NegateGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negate_gradient_op.h', ['    final'], ['    NegateGradientOp(Args,...)', '    RunOnDevice', '    ~NegateGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negate_gradient_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDANegateGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negative_op.cc', ['    GetNegativeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNegative', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Negative', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negative_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\negative_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDANegative']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8vadd\\neon.c', [], ['    pytorch_q8vadd_ukernel__neon(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8rmax\\neon.c', [], ['    pytorch_u8rmax_ukernel__neon(size_t n,const uint8_t *x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8clamp\\neon.c', [], ['    pytorch_u8clamp_ukernel__neon(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8clamp\\neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8rmax\\neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8vadd\\neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\vector\\NEON.cpp', [], ['    THFloatVector_fill_NEON(float *x,const float c,const ptrdiff_t n)', '    THFloatVector_muls_NEON(float *y,const float *x,const float c,const ptrdiff_t n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net.cc', ['    C10FlagParser_caffe2_override_executor'], ['    AddGlobalNetObserverCreator(NetObserverCreator creator)', '    ApplyPotentialExecutorOverride(std::string *net_type)', '    ClearGlobalNetObservers', '    CreateNet(const std::shared_ptr & net_def,Workspace *ws)', '    CreateNet(const NetDef & net_def,Workspace *ws)', '    defaultOverrides', '    GetNetObserverCreators', '    RegistryName', '    NetBase(const std::shared_ptr & def,Workspace *)', '    RunAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)', '    TEST_Benchmark_One_Run', '    C10FlagParser_caffe2_override_executor(const std::string & content)', '    GetNumWorkers', '    GetOperators', '    GetPool(const DeviceOption &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_base.cc', ['    C10FlagParser_caffe2_net_async_check_stream_status', '    C10FlagParser_caffe2_net_async_inference_mode', '    C10FlagParser_caffe2_net_async_max_gpus', '    C10FlagParser_caffe2_net_async_max_numa_nodes', '    C10FlagParser_caffe2_net_async_profile_operators', '    C10FlagParser_caffe2_net_async_run_root_tasks_inline', '    C10FlagParser_caffe2_net_async_thread_pool_size', '    C10FlagParser_caffe2_net_async_use_per_net_pools', '    C10FlagParser_caffe2_net_async_use_single_pool', '    C10FlagParser_caffe2_streams_per_gpu'], ['    getStreamCounters', '    GetOperatorStats', '    GetPerOperatorCost', '    GetProfReport', '    ~AsyncNetBase', '    C10FlagParser_caffe2_net_async_check_stream_status(const std::string & content)', '    C10FlagParser_caffe2_net_async_inference_mode(const std::string & content)', '    C10FlagParser_caffe2_net_async_max_gpus(const std::string & content)', '    C10FlagParser_caffe2_net_async_max_numa_nodes(const std::string & content)', '    C10FlagParser_caffe2_net_async_profile_operators(const std::string & content)', '    C10FlagParser_caffe2_net_async_run_root_tasks_inline(const std::string & content)', '    C10FlagParser_caffe2_net_async_thread_pool_size(const std::string & content)', '    C10FlagParser_caffe2_net_async_use_per_net_pools(const std::string & content)', '    C10FlagParser_caffe2_net_async_use_single_pool(const std::string & content)', '    C10FlagParser_caffe2_streams_per_gpu(const std::string & content)', '    AsyncNetBase(const std::shared_ptr & net_def,Workspace *ws)', '    asyncWait(int task_id,int stream_id,const std::vector & wait_task_ids)', '    canSchedule(int task_id,const std::vector *status,bool *parent_failed)', '    canSchedule(int parent_id,int child_id)', '    children(int task_id)', '    event(int task_id)', '    finalizeEvents', '    finishTasks(const std::unordered_set & task_ids)', '    firstTaskOp(int task_id)', '    firstTaskOp(int task_id)', '    firstTaskOpId(int task_id)', '    getParentCount(int child_id)', '    handleChainError(int task_id,OperatorBase *op,const char *err_str,bool save_exception)', '    handleRunError', '    isStreamFree(int task_id,int stream_id)', '    lastTaskOp(int task_id)', '    lastTaskOp(int task_id)', '    lastTaskOpId(int task_id)', '    numOps(int task_id)', '    parents(int task_id)', '    pool(const DeviceOption & device_option)', '    pool', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    query(int task_id)', '    reset', '    run(int task_id,int stream_id)', '    RunAsync', '    stream(int task_id)', '    tasksNum', '    testAndSetScheduled(int task_id)', '    updateParentCount(int child_id)', '    ExecutionOptions(const std::shared_ptr & net_def)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_base.h', ['    AsyncNetBase', '    AsyncNetExecutorHelper'], ['    GetAsyncNetThreadPool(int device_id,int pool_size,bool create_new)', '    getStreamCounters', '    AsyncNetBase(const std::shared_ptr & net_def,Workspace *ws)', '    AsyncNetBase', '    asyncWait(int task_id,int stream_id,const std::vector & wait_task_ids)', '    canSchedule(int task_id,const std::vector *status,bool *parent_failed)', '    canSchedule(int parent_id,int child_id)', '    children(int task_id)', '    event(int task_id)', '    finalizeEvents', '    finishTasks(const std::unordered_set & task_ids)', '    firstTaskOp(int task_id)', '    firstTaskOp(int task_id)', '    firstTaskOpId(int task_id)', '    GetOperators', '    GetOperatorStats', '    getParentCount(int child_id)', '    GetPerOperatorCost', '    GetProfReport', '    handleChainError(int task_id,OperatorBase *op,const char *err_str,bool save_exception)', '    handleRunError', '    isStreamFree(int task_id,int stream_id)', '    lastTaskOp(int task_id)', '    lastTaskOp(int task_id)', '    lastTaskOpId(int task_id)', '    numOps(int task_id)', '    operator=', '    parents(int task_id)', '    pool(const DeviceOption & device_option)', '    pool', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    query(int task_id)', '    reset', '    run(int task_id,int stream_id)', '    RunAsync', '    stream(int task_id)', '    SupportsAsync', '    tasksNum', '    TEST_execution_chains', '    testAndSetScheduled(int task_id)', '    updateParentCount(int child_id)', '    ~AsyncNetBase', '    AsyncNetExecutorHelper(AsyncNetBase *net)', '    GetPool(const DeviceOption & option)', '    ExecutionOptions(const std::shared_ptr & net_def)', '    hardware_concurrency']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_scheduling.cc', [], ['    schedule_func', '    AsyncSchedulingNet(const std::shared_ptr & net_def,Workspace *ws)', '    Cancel', '    CancelAndFinishAsyncTasks', '    finishRun', '    isInlineTask(int parent_id,int child_id)', '    parentCallback(int parent_id)', '    pollAndSchedule(int task_id)', '    reset', '    RunAsync', '    schedule(int task_id,bool run_inline)', '    Wait', '    ~AsyncSchedulingNet']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_scheduling.h', ['    AsyncSchedulingNet'], ['    AsyncSchedulingNet(const std::shared_ptr & net_def,Workspace *ws)', '    AsyncSchedulingNet', '    Cancel', '    CancelAndFinishAsyncTasks', '    finishRun', '    isInlineTask(int parent_id,int child_id)', '    operator=', '    parentCallback(int parent_id)', '    pollAndSchedule(int task_id)', '    reset', '    RunAsync', '    schedule(int task_id,bool run_inline)', '    Wait', '    ~AsyncSchedulingNet']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task.cc', [], ['    GetDeviceOption', '    GetFuture', '    GetFuture', '    Reset', '    AsyncTask(const std::vector & ops)', '    handleChainError(OperatorBase *op,const char *err_str,bool save_exception)', '    Run(const ExecutionOptions & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task.h', ['    AsyncTask'], ['    AsyncTask(const std::vector & ops)', '    GetDeviceOption', '    GetFuture', '    GetFuture', '    handleChainError(OperatorBase *op,const char *err_str,bool save_exception)', '    Reset', '    Run(const ExecutionOptions & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task_future.cc', [], ['    AsyncTaskFuture', '    AsyncTaskFuture(const std::vector & futures)', '    ErrorMessage', '    IsCompleted', '    IsFailed', '    ResetState', '    SetCallback(std::function callback)', '    SetCompleted(const char *err_msg)', '    Wait', '    ~AsyncTaskFuture']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task_future.h', ['    AsyncTaskFuture'], ['    AsyncTaskFuture', '    AsyncTaskFuture(const std::vector & futures)', '    AsyncTaskFuture', '    ErrorMessage', '    IsCompleted', '    IsFailed', '    operator=', '    ParentCounter(int init_parent_count)', '    Reset', '    ResetState', '    SetCallback(std::function callback)', '    SetCompleted(const char *err_msg)', '    Wait', '    ~AsyncTaskFuture']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task_graph.cc', [], ['    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    AsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    CreateNode(int node_id,const std::vector & ops)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_task_graph.h', ['    AsyncTaskGraph', '    AsyncTaskGraphBase'], ['    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    AsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    CreateNode(int node_id,const std::vector & ops)', '    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    CreateNode(int node_id,const std::vector & ops)', '    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    ~AsyncTaskGraphBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_tracing.cc', ['    C10FlagParser_caffe2_net_async_names_to_trace', '    C10FlagParser_caffe2_net_async_tracing_dumping_nth', '    C10FlagParser_caffe2_net_async_tracing_filepath', '    C10FlagParser_caffe2_net_async_tracing_nth'], ['    create(const NetBase *net,const std::string & net_name)', '    extractShardId(const std::string & name)', '    getCounterForNetName(const std::string & net_name)', '    getTracingConfigFromNet(const NetBase *net)', '    getUniqueShardId(const OperatorDef & op_def)', '    hasEnableTracingFlag(const NetBase *net)', '    isTraceableNetName(const std::string & net_name)', '    startIter(const std::shared_ptr & tracer)', '    names', '    getCurrentTracerGuard', '    C10FlagParser_caffe2_net_async_names_to_trace(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_dumping_nth(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_filepath(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_nth(const std::string & content)', '    bumpDumpingIter', '    bumpIter', '    dumpTracingResultAndClearEvents(const std::string & file_suffix)', '    getIter', '    isEnabled', '    linearizeEvents', '    opBlobsInfo(const OperatorBase & op)', '    opTraceName(const OperatorBase *op)', '    recordEvent(const TracerEvent & event)', '    renameThreads', '    serializeEvent(const TracerEvent & event)', '    setEnabled(bool enabled)', '    Tracer(const NetBase *net,const std::string & net_name,TracingConfig config)', '    ~Tracer', '    addArgument', '    addArgument(TracingField field,const char *value)', '    addArgument(TracingField field,int value)', '    disable', '    init(Tracer *tracer)', '    recordEventStart', '    ~TracerGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_tracing.h', ['    Tracer', '    TracerGuard', '    TracingMode'], ['    create(const NetBase *net,const std::string & net_name)', '    extractShardId(const std::string & name)', '    isTraceableNetName(const std::string & net_name)', '    startIter(const std::shared_ptr & tracer)', '    getCurrentTracerGuard', '    bumpDumpingIter', '    bumpIter', '    config', '    dumpTracingResultAndClearEvents(const std::string & file_suffix)', '    getIter', '    isEnabled', '    linearizeEvents', '    opBlobsInfo(const OperatorBase & op)', '    opTraceName(const OperatorBase *op)', '    recordEvent(const TracerEvent & event)', '    renameThreads', '    serializeEvent(const TracerEvent & event)', '    setEnabled(bool enabled)', '    Tracer(const NetBase *net,const std::string & net_name,TracingConfig config)', '    ~Tracer', '    addArgument', '    addArgument(TracingField field,const char *value)', '    addArgument(TracingField field,int value)', '    addArgument(TracingField field,const T & value,const Args &,...)', '    disable', '    init(Tracer *tracer)', '    recordEventStart', '    TracerGuard', '    ~TracerGuard', '    filepath', '    mode']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_async_tracing_test.cc', [], ['    TEST(NetAsyncTracingTest,ExtractShardId)', '    TEST(NetAsyncTracingTest,EveryKIteration)', '    TEST(NetAsyncTracingTest,GlobalTimeSlice)', '    testExtractShardId(const string & name,int expectedId)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_dag_utils.cc', [], ['    computeChains(std::vector & orig_nodes)', '    computeGroups(std::vector & orig_nodes)', '    prepareOperatorNodes(const std::shared_ptr & net_def,Workspace *ws)', '    prune(int node_idx,std::vector & nodes)', '    pruneOpNodeGraph(const std::vector & nodes)', '    singleChains(std::vector & nodes)', '    updateOperatorNodes(std::vector & nodes,const ExecutionChains & chains)', '    check_current_for_chaining', '    commit_chain', '    depth_traverse', '    prepareChainGraphNodes(const std::vector & operator_nodes,const std::vector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_dag_utils.h', [], ['    computeChains(std::vector & orig_nodes)', '    computeGroups(std::vector & orig_nodes)', '    prepareChainGraphNodes(const std::vector & operator_nodes,const std::vector)', '    prepareOperatorNodes(const std::shared_ptr & net_def,Workspace *ws)', '    singleChains(std::vector & nodes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_dag_utils_test.cc', ['    DagUtilTestContext', '    final', '    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDagUtilTestDummyAsync', '    CAFFE_ANONYMOUS_VARIABLE_CPUDagUtilTestDummySync', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DagUtilTestDummyAsync', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DagUtilTestDummySync', '    PrintChains(const dag_utils::ExecutionChains & chains)', '    TEST(DagUtilTest,Empty)', '    TEST(DagUtilTest,AllSync)', '    TEST(DagUtilTest,AllAsync)', '    TEST(DagUtilTest,Mixed0)', '    TEST(DagUtilTest,Mixed1)', '    TEST(DagUtilTest,Mixed2)', '    computeChains', '    DagUtilTestContext(const std::string & spec,Workspace *ws)', '    net_def_', '    DummyAsyncOp(const OperatorDef & operator_def,Workspace *ws)', '    DummySyncOp(const OperatorDef & operator_def,Workspace *ws)', '    HasAsyncPart', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_gpu_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy2', '    checkChainingAndRun(const char *spec,const dag_utils::ExecutionChains & expected)', '    TEST(NetTest,DISABLED_ChainingForDifferentDevices)', '    testExecution(std::unique_ptr & net,int num_ops)', '    HasAsyncPart', '    NetTestDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    SupportsAsyncScheduling']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\net_observer_reporter.h', ['    NetObserverReporter'], ['    report(NetBase *net,std::map &)', '    ~NetObserverReporter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\net_observer_reporter_print.cc', [], ['    get_op_args(PerformanceInformation p)', '    get_tensor_shapes(PerformanceInformation p)', '    sanatize(std::string json_s)', '    report(NetBase *net,std::map & info)', '  Static Member Variables', '    IDENTIFIER']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\net_observer_reporter_print.h', ['    NetObserverReporterPrint'], ['    report(NetBase *net,std::map &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_parallel.cc', ['    C10FlagParser_caffe2_task_graph_engine'], ['    GetAsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    RegistryName', '    C10FlagParser_caffe2_task_graph_engine(const std::string & content)', '    finishRun', '    GetOperators', '    handleRunError', '    ParallelNet(const std::shared_ptr & net_def,Workspace *ws)', '    Pool(const DeviceOption & device_option)', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    reset', '    RunAsync', '    SupportsAsync', '    Wait']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_parallel.h', ['    ParallelNet', '    ParallelNetExecutorHelper'], ['    GetAsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    RegistryName', '    finishRun', '    GetOperators', '    handleRunError', '    operator=', '    ParallelNet(const std::shared_ptr & net_def,Workspace *ws)', '    ParallelNet', '    Pool(const DeviceOption & device_option)', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    reset', '    RunAsync', '    SupportsAsync', '    Wait', '    GetNumWorkers', '    GetOperators', '    GetPool(const DeviceOption & option)', '    ParallelNetExecutorHelper(ParallelNet *net)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_simple.cc', ['    C10FlagParser_caffe2_simple_net_benchmark_run_whole_net'], ['    PairLargerThan(const std::pair & x,const std::pair & y)', '    C10FlagParser_caffe2_simple_net_benchmark_run_whole_net(const std::string & content)', '    SimpleNet(const std::shared_ptr & net_def,Workspace *ws)', '    Run', '    RunAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_simple.h', ['    SimpleNet'], ['    GetOperators', '    operator=', '    Run', '    RunAsync', '    SimpleNet(const std::shared_ptr & net_def,Workspace *ws)', '    SimpleNet', '    SupportsAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_simple_refcount.cc', [], ['    Run', '    SimpleRefCountNet(const std::shared_ptr & net_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_simple_refcount.h', ['    final'], ['    operator=', '    Run', '    SimpleRefCountNet(const std::shared_ptr & net_def,Workspace *ws)', '    SimpleRefCountNet']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_simple_refcount_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNetSimpleRefCountTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetSimpleRefCountTest', '    TEST(NetSimpleRefCountTest,TestCorrectness)', '    NetSimpleRefCountTestOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\net_supplier.h', ['    MutatingNetSupplier', '    NetSupplier', '    SingleLoadedNetSupplier', '    SingleNetSupplier'], ['    MutatingNetSupplier(std::unique_ptr,std::function m)', '    next', '    ~NetSupplier', '    RunnableNet(const caffe2::NetDef & netdef_,const Filler *filler_,const std::string & info_)', '    get_loaded_workspace', '    SingleLoadedNetSupplier(std::unique_ptr filler,caffe2::NetDef netdef,std::shared_ptr ws)', '    next', '    SingleNetSupplier(unique_ptr filler,caffe2::NetDef netdef)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\net_test.cc', ['    final', '    final', '    final', '    final', '    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUExecutorHelperDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CPUNotFinishingOp', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CPUAsyncErrorOp', '    CAFFE_ANONYMOUS_VARIABLE_CPUSyncErrorOp', '    AsyncErrorNet(Workspace *ws,const std::string & net_name,bool throw_,bool fail_in_sync)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExecutorHelperDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NotFinishingOp', '    checkChainingAndRun(const char *spec,const dag_utils::ExecutionChains & expected)', '    checkNumChainsAndRun(const char *spec,const int expected_num_chains)', '    CreateNetTestHelper(Workspace *ws,const vector & input,const vector & output)', '    TEST(NetTest,ConstructionNoDeclaredInputOutput)', '    TEST(NetTest,ConstructionDeclaredInput)', '    TEST(NetTest,ConstructionDeclaredOutput)', '    TEST(NetTest,DeclaredInputInsufficient)', '    TEST(NetDeathTest,DeclaredOutputNotMet)', '    TEST(NetTest,DISABLED_ChainingForLinearModel)', '    TEST(NetTest,DISABLED_ChainingForFork)', '    TEST(NetTest,DISABLED_ChainingForForkJoin)', '    TEST(NetTest,DISABLED_ChainingForwardBackward)', '    TEST(NetTest,DISABLED_ChainingForHogwildModel)', '    TEST(NetTest,DISABLED_FailingOperator)', '    TEST(NetTest,OperatorWithExecutorHelper)', '    TEST(NetTest,DISABLED_OperatorWithDisabledEvent)', '    TEST(NetTest,ExecutorOverride)', '    TEST(NetTest,AsyncEmptyNet)', '    TEST(NetTest,DISABLED_RunAsyncFailure)', '    TEST(NetTest,NoTypeNet)', '    TEST(NetTest,PendingOpsAndNetFailure)', '    testExecution(std::unique_ptr & net,int num_ops)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AsyncErrorOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SyncErrorOp', '    ChainErrorNet(Workspace *ws,const std::string & net_name,bool throw_)', '    TEST(NetTest,AsyncErrorOpTest)', '    TEST(NetTest,AsyncErrorTimingsTest)', '    TEST(NetTest,ChainErrorTest)', '    TEST(NetTest,ProfDAGNetErrorTest)', '    testProfDAGNetErrorCase(bool test_error)', '    AsyncErrorOp(const OperatorDef & operator_def,Workspace *ws)', '    CancelAsyncCallback', '    ExecutorHelperDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    HasAsyncPart', '    HasAsyncPart', '    HasAsyncPart', '    NetTestDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    NotFinishingOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    Run(int)', '    RunOnDevice', '    RunOnDevice', '    SupportsAsyncScheduling', '    ~AsyncErrorOp', '    RunOnDevice', '    SyncErrorOp(const OperatorDef & operator_def,Workspace *ws)', '    ~SyncErrorOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\Representations\\NeuralNet.cc', [], ['    coalesceInsertedDataDependenciesHelper(repr::NNModule *m)', '    getTrackedNodes(repr::NNCFGraph & cf)', '    coalesceInsertedDataDependencies(repr::NNModule *m)', '    createOutput(NNModule *nn,NNGraph::NodeRef producer,std::string name)', '    getConsumers(NNGraph::NodeRef n)', '    getInputs(NNGraph::NodeRef n)', '    getInputs(const NNSubgraph & subgraph)', '    getName(NNGraph::NodeRef n)', '    getOutputs(NNGraph::NodeRef n)', '    getOutputs(const NNSubgraph & subgraph)', '    getProducer(NNGraph::NodeRef n)', '    hasConsumer(NNGraph::NodeRef n)', '    hasInputs(NNGraph::NodeRef n)', '    hasProducer(NNGraph::NodeRef n)', '    hasSingleOutputAndConsumer(NNGraph::NodeRef nodeRef)', '    hasUniqueConsumer(NNGraph::NodeRef nodeRef)', '    matchExternalTensorNode', '    replaceAllUsesWith(NNGraph::NodeRef oldTensorNode,NNGraph::NodeRef newTensorNode)', '    replaceAsConsumer(NNGraph::NodeRef oldConsumer,NNGraph::NodeRef newConsumer)', '    replaceProducer(NNGraph::NodeRef tensorNode,NNGraph::NodeRef newProducer)', '    getName', '    ~NeuralNetData', '    getName', '    ~NeuralNetOperator', '    createUniqueDataNode(const std::string & s)', '    deleteSubgraph(const NNSubgraph & subgraph)', '    replaceSubgraph(const NNSubgraph & subgraph,const NNGraph::NodeRef & node,const std::vector & node_inputs,const std::vector & node_outputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Representations\\NeuralNet.h', ['    Annotation', '    AnnotationKind', '    GenericOperator', '    NeuralNetData', '    NNDataKind', '    NeuralNetOperator', '    NNKind', '    NNLayout', '    NNPhi', '    Tensor', '    DataType', '    Layout', '    While'], ['    impl(N n)', '    impl(N n)', '    impl(N n)', '    impl(N)', '    convertNode(NNGraph & g,NNGraph::NodeRef node)', '    createOperator(NNModule *nn,Args,...)', '    createOutput(NNModule *nn,NNGraph::NodeRef producer,std::string name)', '    filter(NNModule & nn)', '    get(N n)', '    getConsumers(NNGraph::NodeRef n)', '    getInputs(NNGraph::NodeRef n)', '    getInputs(const NNSubgraph & sg)', '    getName(NNGraph::NodeRef n)', '    getOutputs(NNGraph::NodeRef n)', '    getOutputs(const NNSubgraph & sg)', '    getProducer(NNGraph::NodeRef n)', '    hasConsumer(NNGraph::NodeRef n)', '    hasInputs(NNGraph::NodeRef n)', '    hasProducer(NNGraph::NodeRef n)', '    hasSingleOutputAndConsumer(NNGraph::NodeRef nodeRef)', '    hasUniqueConsumer(NNGraph::NodeRef nodeRef)', '    insertOp(NNGraph & g,NNGraph::NodeRef a,NNGraph::NodeRef b,Args,...)', '    matchExternalTensorNode', '    nodeIterator(G & g)', '    is(NNGraph::NodeRef n)', '    replaceAllUsesWith(NNGraph::NodeRef oldTensorNode,NNGraph::NodeRef newTensorNode)', '    replaceAsConsumer(NNGraph::NodeRef oldConsumer,NNGraph::NodeRef newConsumer)', '    replaceProducer(NNGraph::NodeRef tensorNode,NNGraph::NodeRef newProducer)', '    impl(N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    impl(N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetData *D)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    impl', '    impl', '    createEdge', '    createNode', '    deleteNode', '    replaceNode', '    Annotation(AnnotationKind kind)', '    Annotation', '    getKind', '    ~Annotation', '    GenericOperator', '    GenericOperator(std::string name)', '    getName', '    setName(std::string name)', '    ~GenericOperator', '    clone', '    getKind', '    getName', '    NeuralNetData(NNDataKind kind)', '    NeuralNetData', '    ~NeuralNetData', '    checkInputsAndOutputs(std::vector inputs,std::vector outputs)', '    getAnnotation', '    getKind', '    getLayout', '    getMutableAnnotation', '    getName', '    NeuralNetOperator(NNKind K,Opcode I,NNLayout L)', '    NeuralNetOperator(NNKind K,Opcode I)', '    NeuralNetOperator(NNKind K,NNLayout L)', '    NeuralNetOperator(NNKind K)', '    NeuralNetOperator', '    NeuralNetOperator', '    operator=', '    setAnnotation(std::unique_ptr extraAnnotation)', '    setLayout(NNLayout L)', '    ~NeuralNetOperator', '    createUniqueDataNode(const std::string & s)', '    deleteSubgraph(const NNGraph::SubgraphType & subgraph)', '    NNModule', '    NNModule', '    NNModule', '    replaceSubgraph(const NNGraph::SubgraphType & subgraph,const NNGraph::NodeRef & node,const std::vector & node_inputs,const std::vector & node_outputs)', '    replaceSubgraphWithOperator(const NNGraph::SubgraphType & sg,const std::vector & subgraph_inputs,const std::vector & subgraph_outputs,Args,...)', '    NNPhi', '    ~NNPhi', '    clone', '    getName', '    getType', '    setName(const std::string & name)', '    setType(DataType type)', '    Tensor(std::string name)', '    ~Tensor', '    While', '    ~While', '    make_unique']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\NeuralNetTest.cc', [], ['    TEST(NeuralNetGraph,ReplaceGraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\NeuralNetworks.h', [], ['    __BEGIN_DECLS', '    ANeuralNetworksCompilation_create(ANeuralNetworksModel *model,ANeuralNetworksCompilation **compilation)', '    ANeuralNetworksCompilation_finish(ANeuralNetworksCompilation *compilation)', '    ANeuralNetworksCompilation_free(ANeuralNetworksCompilation *compilation)', '    ANeuralNetworksCompilation_setPreference(ANeuralNetworksCompilation *compilation,int32_t preference)', '    ANeuralNetworksEvent_free(ANeuralNetworksEvent *event)', '    ANeuralNetworksEvent_wait(ANeuralNetworksEvent *event)', '    ANeuralNetworksExecution_create(ANeuralNetworksCompilation *compilation,ANeuralNetworksExecution **execution)', '    ANeuralNetworksExecution_free(ANeuralNetworksExecution *execution)', '    ANeuralNetworksExecution_setInput(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const void *buffer,size_t length)', '    ANeuralNetworksExecution_setInputFromMemory(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const ANeuralNetworksMemory *memory,size_t offset,size_t length)', '    ANeuralNetworksExecution_setOutput(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,void *buffer,size_t length)', '    ANeuralNetworksExecution_setOutputFromMemory(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const ANeuralNetworksMemory *memory,size_t offset,size_t length)', '    ANeuralNetworksExecution_startCompute(ANeuralNetworksExecution *execution,ANeuralNetworksEvent **event)', '    ANeuralNetworksMemory_createFromFd(size_t size,int protect,int fd,size_t offset,ANeuralNetworksMemory **memory)', '    ANeuralNetworksMemory_free(ANeuralNetworksMemory *memory)', '    ANeuralNetworksModel_addOperand(ANeuralNetworksModel *model,const ANeuralNetworksOperandType *type)', '    ANeuralNetworksModel_addOperation(ANeuralNetworksModel *model,ANeuralNetworksOperationType type,uint32_t inputCount,const uint32_t *inputs,uint32_t outputCount,const uint32_t *outputs)', '    ANeuralNetworksModel_create(ANeuralNetworksModel **model)', '    ANeuralNetworksModel_finish(ANeuralNetworksModel *model)', '    ANeuralNetworksModel_free(ANeuralNetworksModel *model)', '    ANeuralNetworksModel_identifyInputsAndOutputs(ANeuralNetworksModel *model,uint32_t inputCount,const uint32_t *inputs,uint32_t outputCount,const uint32_t *outputs)', '    ANeuralNetworksModel_setOperandValue(ANeuralNetworksModel *model,int32_t index,const void *buffer,size_t length)', '    ANeuralNetworksModel_setOperandValueFromMemory(ANeuralNetworksModel *model,int32_t index,const ANeuralNetworksMemory *memory,size_t offset,size_t length)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ngram_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNGramFromCategorical', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NGramFromCategorical']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\ngram_ops.h', ['    NGramFromCategoricalOp'], ['    GetRepeatedArgument', '    NGramFromCategoricalOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\nn_utils.cpp', [], ['    _compatibility_test', '    assert_is_equal_packed_sequence(const rnn_utils::PackedSequence & a,const rnn_utils::PackedSequence & b)', '    assert_is_same_packed_sequence(const rnn_utils::PackedSequence & a,const rnn_utils::PackedSequence & b)', '    batch_first', '    batch_first', '    batch_first', '    batch_first', '    compare_scaling', '    compute_norm', '    enforce_sorted', '    enforce_sorted', '    err_fn', '    generate_test_case', '    num_dim', '    num_dim', '    PackedSequenceTest_ordered_sequence(torch::ScalarType tensor_type)', '    PackedSequenceTest_padded_sequence(torch::ScalarType tensor_type)', '    pad', '    parameters', '    tensor_sizes', '    tensor_sizes', '    tensor_sizes', '    TEST_F(NNUtilsTest,ClipGradNorm)', '    TEST_F(NNUtilsTest,ClipGradValue)', '    TEST_F(NNUtilsTest,ConvertParameters)', '    TEST_F(PackedSequenceTest,WrongOrder)', '    TEST_F(PackedSequenceTest,TotalLength)', '    TEST_F(PackedSequenceTest,To)', '    TEST_F(NNUtilsTest,PackSequence)', '    TEST_F(NNUtilsTest,PackPaddedSequence)', '    TEST_F(NNUtilsTest,PadSequence)', '    total_length', '    total_length_delta', '    zero_parameters']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\nnapi.cc', [], ['    reportError(int result_code)', '    addConv(const OperatorDef & op,bool fuse_relu)', '    addFloatOperand(float val)', '    addPooling(const OperatorDef & op,OperationCode op_code,bool fuse_relu)', '    addRelu(const OperatorDef & op)', '    addScalarOperand(int32_t val)', '    addSoftmax(const OperatorDef & op)', '    addTensorOperand(const std::string & blob,OperandCode type,std::vector & dims,float scale,int32_t zero_point)', '    getConvPoolArgs(const ArgumentHelper & helper,ConvPoolArgs & args)', '    init(const TensorVector & inputs,TensorVector *outputs)', '    loadNNApiLibrary', '    run(const TensorVector & inputs,TensorVector *outputs)', '    ~NNApi']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\nnapi.h', ['    NNApi'], ['    addConv(const OperatorDef & op,bool fuse_relu)', '    addFloatOperand(float val)', '    addPooling(const OperatorDef & op,OperationCode op_code,bool fuse_relu)', '    addRelu(const OperatorDef & op)', '    addScalarOperand(int32_t val)', '    addSoftmax(const OperatorDef & op)', '    addTensorOperand(const std::string & blob,OperandCode type,std::vector & dims,float scale,int32_t zero_point)', '    compilation_', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    stride_x', '    stride_y', '    getConvPoolArgs(const ArgumentHelper & helper,ConvPoolArgs & args)', '    init(const TensorVector & inputs,TensorVector *outputs)', '    loadNNApiLibrary', '    model_', '    NNApi(const NetDef & init_net,const NetDef & run_net,Workspace *ws,const PreferenceCode pref)', '    operand_idx', '    operator_map_', '    run(const TensorVector & inputs,TensorVector *outputs)', '    run_', '    run_end_', '    ~NNApi', '    RunNetOnce']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\nnapi_benchmark.cc', [], ['    benchmark_conv_caffe2(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run,std::string engine)', '    benchmark_conv_nnapi(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run)', '    benchmark_conv_nnapi_int8(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run)', '    channel', '    input_channel', '    kernel', '    kernel', '    main(int argc,char **argv)', '    space', '    space']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\nnapi\\nnapi_test.cc', [], ['    test_conv_NHWC(int N,int C,int H,int W,int K,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_depthwise_conv_NHWC(int N,int C,int H,int W,int D,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_pooling(std::string type,int N,int C,int H,int W,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_relu(int N,int C,int H,int W)', '    test_softmax(int N,int C,int H,int W)', '    C', '    C', '    C', '    C', '    checkError(const TensorCPU & t1,const TensorCPU & t2,float error)', '    TEST(NNApi,TestConv)', '    TEST(NNApi,Depthwise)', '    TEST(NNApi,TestRelu)', '    TEST(NNApi,TestAveragePool)', '    TEST(NNApi,TestMaxPool)', '    TEST(NNApi,TestSoftmax)', '    K', '    K', '    K', '    K', '    M', '    P', '    P', '    P', '    P', '    S', '    S', '    S', '    S', '    W', '    W', '    W', '    W']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\NNPACK.cpp', [], ['    allocate_workspace', '    deallocate_workspace', '    init_nnpack', '    nnpack_threadpool', '    _nnpack_available', '    _nnpack_spatial_convolution(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,const IntArrayRef padding,const IntArrayRef stride)', '    _nnpack_spatial_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,std::array output_mask)', '    _nnpack_spatial_convolution_backward_input(const at::Tensor & input,const at::Tensor & gradOutput,const at::Tensor & weight,IntArrayRef padding)', '    _nnpack_spatial_convolution_backward_weight(const at::Tensor & input,IntArrayRef weight_size,const at::Tensor & gradOutput,IntArrayRef padding)', '    compute', '    run', '    run', '    size_and_allocate_ws', '    size_and_allocate_ws', '    size_and_allocate_ws']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\nnpack\\nnpack_ops.cc', ['    C10FlagParser_caffe2_nnpack_num_threads', '    C10FlagParser_caffe2_nnpack_use_mkl_num_threads', '    final', '    final', '    final', '    final'], ['    get_nnp_convolution_algorithm(const std::string & algo)', '    get_nnp_convolution_transform_strategy(const std::string & kts)', '    has_nnpack', '    nnpack_threadpool', '    C10FlagParser_caffe2_nnpack_num_threads(const std::string & content)', '    C10FlagParser_caffe2_nnpack_use_mkl_num_threads(const std::string & content)', '    NNPACKConvOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKLeakyReluOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKMaxPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\nnpack\\nnpack_test.cc', [], ['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int group,const std::string & algorithm,const std::string & convolutionTransformStrategy,const std::string & activation,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    relativeError(float a,float b)', '    runConv(int kernelH,int kernelW,int strideH,int strideW,int group,std::string algo,int planesIn,int planesOut,int n,std::string convolutionTransformStrategy,std::string activation)', '    TEST(NNPACK,Conv_3x3s1)', '    TEST(NNPACK,Conv_3x3s1_precompute)', '    TEST(NNPACK,Conv_3x3s1_FP16)', '    TEST(NNPACK,Conv_3x3s1_FP16_precompute)', '    TEST(NNPACK,Conv_NxNs1)', '    TEST(NNPACK,Conv_1x1s1)', '    TEST(NNPACK,ConvRelu_1x1s1)', '    TEST(NNPACK,Conv_1x1s1_precompute)', '    TEST(NNPACK,Conv_NxNs_grouped)', '    TEST(NNPACK,Conv_NxNs_grouped_precompute)', '    TEST(NNPACK,Conv_NxNsW)', '    TEST(NNPACK,ConvRelu_NxNsW)', '    TEST(NNPACK,Conv_HxWsHxW)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\no_default_engine_op.h', ['    final'], ['    NoDefaultEngineOp(Args,...)', '    RunOnDevice', '    ~NoDefaultEngineOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\no_python_abi_suffix_test\\no_python_abi_suffix_test.cpp', [], ['    dummy(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\node_hashing.cpp', [], ['    attributesEqual(attribute_type a1,attribute_type a2)', '    attributesEqual(const at::Tensor & a1,const at::Tensor & a2)', '    attributesEqual(const std::vector & lhs,const std::vector & rhs)', '    attributesEqual(at::ArrayRef a1,at::ArrayRef a2)', '    attributesEqual(const IValue & a1,const IValue & a2)', '    attributesEqualCSE(const Node *lhs,const Node *rhs)', '    ivaluesEqual(const IValue & a1,const IValue & a2)', '    tensorEqual(const at::Tensor & lhs,const at::Tensor & rhs)', '    typeListEqual(const std::vector & lhs,const std::vector & rhs)', '    operator()(const Node *lhs,const Node *rhs)', '    operator()(const Node *k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\node_hashing.h', [], ['    operator()(const Node *lhs,const Node *rhs)', '    operator()(const Node *k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\norm_minimization.cc', [], ['    GetNorm(float begin,float end,float density,NormMinimization::Kind kind)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    NonlinearQuantizationParamsSearch(const Histogram & hist,bool preserve_sparsity,int precision)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\norm_minimization_avx2.cc', [], ['    L2MinimizationKernelAVX2(int precision,float *bins,int nbins,float bin_width,float dst_bin_width,int start_bin)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\norm_planar_yuv_op.cc', ['    NormalizePlanarYUVOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNormalizePlanarYUV', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizePlanarYUV', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\normalization.cpp', [], ['    forward(const torch::Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    GroupNormImpl(const GroupNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    forward(const Tensor & input)', '    LayerNormImpl(const LayerNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    forward(const Tensor & input)', '    LocalResponseNormImpl(const LocalResponseNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Normalization.cpp', [], ['    mkldnn_batch_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool train,double momentum,double eps)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Normalization.cpp', [], ['    conditional_accessor_1d(const Tensor & t)', '    repeat_if_defined(const Tensor & t,int64_t repeat)', '    _batch_norm_impl_index(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool training,double momentum,double eps,bool cudnn_enabled)', '    _batch_norm_impl_index_backward(int64_t impl_index,const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_var_transform,bool train,double epsilon,std::array output_mask,const Tensor & reservedSpace)', '    batch_norm_backward_cpu_template(const Tensor & grad_out_,const Tensor & input,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_invstd,bool train,double eps,std::array grad_input_mask)', '    batch_norm_cpu_inference_channels_last(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_collect_linear_and_constant_terms(scalar_t *alpha,scalar_t *beta,int64_t n_channel,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_transform_input_template(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & save_mean,const Tensor & save_invstd,const Tensor & running_mean,const Tensor & running_var,bool train,double eps)', '    batch_norm_cpu_update_stats_template(const Tensor & input,const Tensor & running_mean,const Tensor & running_var,double momentum,double eps)', '    check_dims_match_num_input_features(const char *arg_name,int64_t expected,int64_t actual)', '    batch_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool training,double momentum,double eps,bool cudnn_enabled)', '    batch_norm_backward_cpu(const Tensor & grad_out,const Tensor & self,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_invstd,bool train,double eps,std::array grad_input_mask)', '    batch_norm_cpu(const Tensor & self,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool train,double momentum,double eps)', '    batch_norm_update_stats_cpu(const Tensor & self,const Tensor & running_mean,const Tensor & running_var,double momentum)', '    group_norm(const Tensor & input,int64_t num_groups,const Tensor & weight,const Tensor & bias,double eps,bool cudnn_enabled)', '    instance_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool use_input_stats,double momentum,double eps,bool cudnn_enabled)', '    operator()(T var,double epsilon)', '    operator()(T var,double epsilon)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\normalization.cpp', [], ['    CrossMapLRN2dOptions(int64_t size)', '    GroupNormFuncOptions(int64_t num_groups)', '    GroupNormOptions(int64_t num_groups,int64_t num_channels)', '    LayerNormFuncOptions(std::vector normalized_shape)', '    LayerNormOptions(std::vector normalized_shape)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\normalization.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\normalization.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\normalization.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\normalize_l1_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNormalizeL1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizeL1', '    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\normalize_l1_op.h', ['    final'], ['    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)', '    GetSingleArgument', '    NormalizeL1Op(Args,...)', '    RunOnDevice', '    ~NormalizeL1Op']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\normalize_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUNormalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Normalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizeGradient', '    vector', '    GetGradientDefs', '    DoNormalize(const T *xData,const T *gOutData,T *gInData,const int m,const int n,const int sf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\normalize_op.h', ['    final', '    final'], ['    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)', '    DoNormalize(const T *xData,const T *gOutData,T *gInData,const int m,const int n,const int sf)', '    NormalizeGradientOp(Args,...)', '    NormalizeOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\numa.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\numa.cpp', ['    C10FlagParser_caffe2_cpu_numa_enabled'], ['    GetCurrentNUMANode', '    GetNUMANode(const void *ptr)', '    GetNumNUMANodes', '    IsNUMAEnabled', '    NUMABind(int numa_node_id)', '    NUMAMove(void *ptr,size_t size,int numa_node_id)', '    C10FlagParser_caffe2_cpu_numa_enabled(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\numa.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\numa.h', [], ['    GetCurrentNUMANode', '    GetNUMANode(const void *ptr)', '    GetNumNUMANodes', '    IsNUMAEnabled', '    NUMABind(int numa_node_id)', '    NUMAMove(void *ptr,size_t size,int numa_node_id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\NumericUtils.h', [], ['    _isnan(T val)', '    _isnan(T val)', '    _isnan(at::BFloat16 val)', '    _isnan']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\numpy_stub.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\numpy_tile_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNumpyTile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NumpyTile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\numpy_tile_op.h', ['    NumpyTileOp'], ['    buffer', '    DoTile(const TypeMeta & meta,int item_size,int outer_dim,int inner_dim,int64_t num_tiles,const char *input_data,char *output_data)', '    NumpyTileOp(Args,...)', '    RunOnDevice', '    ~NumpyTileOp', '    itemsize', '    raw_data', '    Reshape', '    size_from_dim', '    size_to_dim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\shared\\nvtx.cpp', [], ['    initNvtxBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\object.cpp', [], ['    _ivalue', '    define(const std::string & src,const ResolverPtr & resolver)', '    find_method(const std::string & basename)', '    Object(std::shared_ptr cu,const c10::ClassTypePtr & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\api\\object.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\object_ptr.cpp', [], ['    free']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\object_ptr.h', ['    THPPointer'], ['    free', '    get', '    get', '    operator bool', '    operator THPPointer::T *', '    operator->', '    operator=(T *new_ptr)', '    operator=(THPPointer)', '    release', '    THPPointer', '    THPPointer(T *ptr)', '    THPPointer(THPPointer)', '    ~THPPointer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\observer.cpp', [], ['    observerConfig']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\observer.h', ['    MobileDebugInfo', '    MobileModuleObserver', '    MobileObserverConfig'], ['    observerConfig', '    getMethodName', '    getModelName', '    getOpIdx', '    setMethodName(const std::string & method_name)', '    setModelName(const std::string & model_name)', '    setOpIdx(size_t op_idx)', '    ~MobileDebugInfo', '    onEnter(const std::string & model_name,const std::string & method_name)', '    onExit', '    ~MobileModuleObserver', '    getModuleObserver', '    setModuleObserver(std::unique_ptr reporter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\observer.h', ['    ObserverBase', '    Observable'], ['    StartObserver(Observer *observer)', '    StopObserver(Observer *observer)', '    debugInfo', '    ObserverBase(T *subject)', '    Start', '    Stop', '    subject', '    ~ObserverBase', '    AttachObserver(std::unique_ptr observer)', '    DetachObserver(const Observer *observer_ptr)', '    NumObservers', '    Observable', '    Observable', '    Observable', '    operator=', '    operator=', '    StartAllObservers', '    StopAllObservers', '    UpdateCache', '    ~Observable']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\observer_config.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\observer_config.h', ['    ObserverConfig'], ['    getMarker', '    getNetFollowupSampleCount', '    getNetFollowupSampleRate', '    getNetInitSampleRate', '    getOpoeratorNetSampleRatio', '    getReporter', '    getSkipIters', '    initSampleRate(int netInitSampleRate,int netFollowupSampleRate,int netFollowupSampleCount,int operatorNetSampleRatio,int skipIters)', '    setMarker(int marker)', '    setReporter(unique_ptr reporter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\observer_test.cc', ['    final', '    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUObsTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDAObsTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ObsTestDummy', '    CreateNetTestHelper(Workspace *ws,bool isDAG)', '    TEST(ObserverTest,TestNotify)', '    TEST(ObserverTest,TestUniqueMap)', '    TEST(ObserverTest,TestNotifyAfterDetach)', '    TEST(ObserverTest,TestDAGNetBase)', '    DummyObserver(T *subject_)', '    ~DummyObserver', '    Start', '    Stop', '    Run(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\offline_tensor.cc', [], ['    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\offline_tensor.h', ['    OfflineTensorShapeFunctions'], ['    create_legacy', '    setShapeAndType(const std::vector & sizes,at::Device device,caffe2::TypeMeta data_type)', '    shape_tensor', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *,std::vector *,std::vector *,uint32_t *)', '    OfflineTensorShapeFunctions', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~OfflineTensorShapeFunctions', '    dtype_initialized', '    storage_initialized', '    unsafeGetTensorImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\one_hot_ops.cc', ['    SegmentOneHotOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBucketOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentOneHot', '    TensorInferenceForBatchOneHot(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBucketOneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchOneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentOneHot', '    CostInferenceForBatchOneHot(const OperatorDef & def,const vector & in)', '    TensorInferenceForBucketBatchOneHot(const OperatorDef &,const vector & in)', '    RunOnDevice', '    DoRunWithType', '    DoOneHotOp(int64_t batch_size,int64_t index_size,const Tensor & indices,Tensor *one_hots)', '    RunOnDevice', '    SegmentOneHotOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\one_hot_ops.h', ['    final', '    final', '    final'], ['    BatchBucketOneHotOp(Args,...)', '    BatchOneHotOp(Args,...)', '    DoOneHotOp(int64_t batch_size,int64_t index_size,const Tensor & indices,Tensor *output)', '    DoRunWithType', '    OneHotOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Onehot.cpp', [], ['    one_hot(const Tensor & self,int64_t num_classes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx.cpp', [], ['    ctx', '    envFn', '    BlockToONNX(Block *old_block,Block *new_block,::torch::onnx::OperatorExportTypes operator_export_type,std::unordered_map env)', '    checkONNXCompatibility(const c10::FunctionSchema & schema)', '    PreprocessCaffe2Ops(std::shared_ptr & graph)', '    preprocessCaffe2Ops(Block *block)', '    RemovePrintOps(std::shared_ptr & graph)', '    removePrintOps(Block *block)', '    ToONNX(std::shared_ptr & graph,::torch::onnx::OperatorExportTypes operator_export_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\onnx\\onnx.h', ['    OperatorExportTypes', '    TrainingMode'], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx.h', [], ['    BlockToONNX(Block *old_block,Block *new_block,::torch::onnx::OperatorExportTypes operator_export_type,std::unordered_map env)', '    PreprocessCaffe2Ops(std::shared_ptr & graph)', '    RemovePrintOps(std::shared_ptr & graph)', '    ToONNX(std::shared_ptr & graph,::torch::onnx::OperatorExportTypes operator_export_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\onnx_convert.h', ['    OnnxAnnotation'], ['    classof(const Annotation *A)', '    getDevice', '    getMutableOperatorDef', '    getOperatorDef', '    OnnxAnnotation', '    OnnxAnnotation(std::string device)', '    setDevice(std::string device)', '    setOperatorDef(caffe2::OperatorDef *opDef)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnx_exporter.cc', [], ['    kRenamedAttrs', '    kRenamedOperators', '    AddShapeNode(const std::string & input,const std::string & output)', '    ApplyTrans(std::unordered_map *attrs,bool global,const std::string & k,int dim,const std::string & ks)', '    Caffe2TypeToOnnxType(caffe2::TensorProto::DataType t)', '    collectExternalsFromIfOpSubnet(const NetDef *net,std::vector *input,std::vector *output)', '    CreateOnnxShapeTensor(std::shared_ptr dummy,const std::vector & shape)', '    DimProd(const caffe2::TensorShape & shape,int start,int end)', '    getArgumentFromName(OperatorDef *op,const std::string & name)', '    rewriteSubnet(Argument *arg,std::map oldname_to_newname)', '    SsaName(const std::string & n,int version)', '    SsaRewrite(caffe2::NetDef *init_net,caffe2::NetDef *pred_net)', '    ssaRewriteForIfOp(OperatorDef *op,std::unordered_map *blob_versions,std::set *is_initialized_tensor)', '    get_renamed_attrs', '    get_renamed_operators', '    Caffe2OpToOnnxNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CommonCaffe2OpToOnnxNodes(const caffe2::OperatorDef & def)', '    CopyCaffe2ArgToOnnxAttr(AttributeProto *attr,const std::string & op_type,const caffe2::Argument & arg)', '    CreateArgMaxMinOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateBinaryElementwiseOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateCastNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateChannelShuffleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConcatNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConvPoolNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateElementwiseLinearNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateGemmNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateLrnNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateMergeDimNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReduceMeanNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReshapeNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateSliceNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateUpsampleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    get_special_operators', '    InitOpToTensorProto(const caffe2::OperatorDef & op,TensorProto *tensor)', '    IsBlackListed(const caffe2::Argument & arg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnx_exporter.h', ['    OnnxExporter'], ['    Caffe2OpToOnnxNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CommonCaffe2OpToOnnxNodes(const caffe2::OperatorDef & def)', '    CopyCaffe2ArgToOnnxAttr(AttributeProto *attr,const std::string & op_type,const caffe2::Argument & arg)', '    CreateArgMaxMinOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateBinaryElementwiseOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateCastNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateChannelShuffleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConcatNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConvPoolNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateElementwiseLinearNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateGemmNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateLrnNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateMergeDimNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReduceMeanNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReshapeNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateSliceNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateUpsampleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    get_renamed_attrs', '    get_renamed_operators', '    get_special_operators', '    InitOpToTensorProto(const caffe2::OperatorDef & def,TensorProto *tensor)', '    IsBlackListed(const caffe2::Argument & arg)', '    OnnxExporter(DummyName *dummy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\onnx_while_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUONNXWhile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ONNXWhile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\onnx_while_op.h', ['    final', '    LocalScope'], ['    condition_true', '    valid_iter_num', '    get', '    DoRunWithType', '    GetSingleArgument', '    HasSingleArgumentOfType', '    iteration', '    lcd_tensor(int idx)', '    LocalScope(Workspace *loop_ws,const NetDef & body_net_def,size_t num_lcds)', '    net', '    output_condition', '    set_input_condition(bool cond_value)', '    set_iteration(int64_t itr)', '    workspace', '    ONNXWhileOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    itemsize', '    raw_data', '    vec', '    CreateBlob', '    CreateNet', '    GetBlob', '    GetNet']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnxifi_graph_info.cc', [], ['    getOnnxBackendGraphMap', '    insert(const std::string & key,std::function creator)', '    lookup(const std::string & key)', '    remove(const std::string & key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnxifi_graph_info.h', ['    OnnxBackendGraphMap'], ['    getOnnxBackendGraphMap', '    BackendGraphInfo(onnxBackendID backend_id,onnxBackend backend,onnxGraph graph,onnxifi_library *lib,std::unordered_map,ShapeInfo)', '    BackendGraphInfo', '    BackendGraphInfo(BackendGraphInfo)', '    lib', '    operator=', '    operator=(BackendGraphInfo)', '    ~BackendGraphInfo', '    insert(const std::string & key,std::function creator)', '    lookup(const std::string & key)', '    OnnxBackendGraphMap', '    OnnxBackendGraphMap', '    OnnxBackendGraphMap', '    operator=', '    operator=', '    remove(const std::string & key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnxifi_init.cc', [], ['    core', '    initOnnxifiLibrary']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\onnxifi_init.h', [], ['    initOnnxifiLibrary']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\onnxifi_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUOnnxifi', '    data_type_map', '    BlobToTensorDescriptor(const std::string & name,Workspace *ws,onnxTensorDescriptorV1 *desc,std::vector,std::vector,std::vector)', '    copyDescriptor(const ExternalTensorDescriptor *from,onnxTensorDescriptorV1 *to)', '    OnnxifiTypeToDataType(uint64_t onnxifi_type)', '    SetInputTensorDescriptorTypeAndBuffer(const Tensor & cpu_tensor,onnxTensorDescriptorV1 *desc)', '    SetInputTensorDescriptorTypeAndBuffer(const int8::Int8TensorCPU & cpu_int8tensor,onnxTensorDescriptorV1 *desc)', '    SetOutputTensorDescriptorTypeAndBuffer(uint64_t onnxifi_type,Tensor *cpu_tensor,onnxTensorDescriptorV1 *desc)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Onnxifi', '    buildInitializationList(Workspace *ws,const std::vector & initializers,std::vector *weight_names,std::vector,std::vector,std::vector)', '    maybeAdjustOutputBatchSizes', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\onnxifi_op.h', ['    final'], ['    backend', '    creator', '    graph', '    num_backends', '    adjust_output_batch_', '    backend_', '    backend_id_', '    buildBackendAndGraph(Workspace *ws,const std::vector & property_pointers,const std::string & onnx_model_str)', '    buildInitializationList(Workspace *ws,const std::vector & initializers,std::vector *weight_names,std::vector,std::vector,std::vector)', '    buildPropertyList(const OperatorDef &,std::vector *property_list,std::vector *,std::vector *)', '    enable_tracing_', '    extractOutputBatchSizes', '    getExtFunctionPointers', '    GetRepeatedArgument', '    GetSingleArgument', '    graph_', '    lib_', '    maybeAdjustOutputBatchSizes', '    nominal_batch_idx_', '    OnnxifiOp(const OperatorDef & operator_def,Workspace *ws)', '    skip', '    RunOnDevice', '    setEnableTracing(bool b)', '    SetOutputShapeAndType(int output_idx,std::vector *dims)', '    operator=', '    TensorInfo', '    TensorInfo', '    use_onnx_', '    ~OnnxifiOp', '    Blobs', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\onnxifi_transformer.cc', [], ['    addCast', '    buildLoopTestNet(const NetDef & net,const std::unordered_set & initialization_list,std::unordered_map *shape_hints,size_t batch_size)', '    collectInputsAndOutputs(const OperatorDef & op,std::set *inputs,std::set *outputs)', '    composeResultNet(const OperatorDef & onnxifi_op)', '    convertToValueInfo(const std::vector & names,const std::unordered_map & shape_hints,const std::unordered_map & extra_shape_hints)', '    fetchInputsToIfOpsSubnet(NetDef *net)', '    fillModelInfo(::ONNX_NAMESPACE::ModelProto *model)', '    getBlob1stDimSize(const ShapeInfo & shape_info)', '    getWeightsAndInputs(const NetDef & net,const std::unordered_set & weights_in_ws,const std::vector & extra_weights,std::unordered_set *initialization_list,std::vector *total_inputs_vec)', '    mergeFp32InputsAndConvertToFp16(size_t batch_size,const std::unordered_set & weights,NetDef *pred_net,ShapeInfoMap *shape_hints)', '    onnxifiDataType(caffe2::TensorProto::DataType t)', '    stripShapeInfoMap(const ShapeInfoMap & info_map)', '    MakeArgument', '    MakeArgument', '    MakeArgument', '    nominal_batch_idx', '    onnx_converter', '    applyFilteringRules(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    blacklistCpuPartition(const NetDef & net,std::unordered_set *blacklisted_ops)', '    buildOnnxifiOp(const std::string & onnx_model_str,const std::unordered_map & output_shape_hints,const std::unordered_set & initialization_list,const std::vector & external_inputs,const std::vector & external_outputs,const std::unordered_map & shape_hints)', '    extractPartitionInfo(const NetDef & net)', '    getBackendId', '    OnnxifiTransformer(const OnnxifiTransformerOptions & opts)', '    SubnetToOnnxifiOpViaC2(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,const ShapeInfoMap & shape_hints)', '    SubnetToOnnxifiOpViaOnnx(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,Workspace *ws,onnx::OnnxExporter *exporter,ShapeInfoMap *shape_hints)', '    supportOpC2(const caffe2::OperatorDef & op,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    supportOpOnnx(const caffe2::OperatorDef & op,onnx::OnnxExporter *exporter,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    tieGatherAndSparseLengthsWeightedSumOps(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & input_shape_hints,const std::unordered_set & blacklisted_ops)', '    TransformViaC2(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    TransformViaOnnx(Workspace *ws,NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,ShapeInfoMap *shape_hints)', '    ~OnnxifiTransformer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\onnxifi_transformer.h', ['    final'], ['    adjust_batch', '    applyFilteringRules(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    blacklistCpuPartition(const NetDef & net,std::unordered_set *blacklisted_ops)', '    buildOnnxifiOp(const std::string & onnx_model_str,const std::unordered_map & output_size_hints,const std::unordered_set & initialization_list,const std::vector & external_inputs,const std::vector & external_outputs,const std::unordered_map & shape_hints)', '    extractPartitionInfo(const NetDef & net)', '    getBackendId', '    idx_', '    lib_', '    load_model_by_blob', '    loop_test', '    merge_fp32_inputs_into_fp16', '    num_backends_', '    onnxifi_op_id_', '    OnnxifiTransformer(const OnnxifiTransformerOptions & opts)', '    OnnxifiTransformerOptions', '    predictor_net_ssa_rewritten', '    SubnetToOnnxifiOpViaC2(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,const ShapeInfoMap & shape_hints)', '    SubnetToOnnxifiOpViaOnnx(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,Workspace *ws,onnx::OnnxExporter *exporter,ShapeInfoMap *shape_hints)', '    supportOpC2(const caffe2::OperatorDef & op,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    supportOpOnnx(const caffe2::OperatorDef & op,onnx::OnnxExporter *exporter,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    tieGatherAndSparseLengthsWeightedSumOps(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    TransformViaC2(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    TransformViaOnnx(Workspace *ws,NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,ShapeInfoMap *shape_hints)', '    use_onnx', '    ~OnnxifiTransformer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\custom_operator\\op.cpp', [], ['    custom_op(torch::Tensor tensor,double scalar,int64_t repeat)', '    custom_op2(std::string s1,std::string s2)', '    custom_op_with_autograd(torch::Tensor var1,int64_t mul,torch::Tensor var2)', '    backward(torch::autograd::AutogradContext *ctx,torch::autograd::variable_list grad_output)', '    forward(torch::autograd::AutogradContext *ctx,torch::Tensor var1,int64_t mul,torch::Tensor var2)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\custom_operator\\op.h', [], ['    custom_op(torch::Tensor tensor,double scalar,int64_t repeat)', '    custom_op2(std::string s1,std::string s2)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\code_analyzer\\op_dependency.cpp', ['    OpDependency', '    OutputFormatType'], ['    callback', '    demangle(const std::string & mangled)', '    expand', '    expand', '    expandOperands', '    expandUsers', '    insert', '    extractOpSchema(Value *V)', '    extractStringValue(Value *V,const std::function & CB)', '    printAsDot(std::ostream & out,const SET & keys,const GRAPH & graph)', '    printAsPython(std::ostream & out,const SET & keys,const GRAPH & graph)', '    printAsYAML(std::ostream & out,const SET & keys,const GRAPH & graph,const PATH *path)', '    printDebugPath(const VALUE_MAP *debugPath,Value *src,Value *dest)', '    printDebugValue(Value *V)', '    scanAllFunctions(Module & M,GRAPH *deps,VALUE_SET *opRegistrationInsts,VALUE_SET *opInvocationInsts)', '    scanConnectedNodes(Value *src,const VALUE_SET & blocked,const std::function & CB,VALUE_MAP *debugPath)', '    scanOpInvocation(VALUE_SET & instructions,SET *opSchemaStrs,GRAPH *functionToSchemaStrs)', '    scanOpRegistration(VALUE_SET & instructions,SET *opSchemaStrs,GRAPH *schemaStrToFunctions)', '    scanOpSchemaStrAndFunction(Value *src,const VALUE_SET & blocked,SET *visitedOps,SET *visitedFunctions)', '    scanReferredFunctions(Instruction & I,const std::function & CB)', '    simplifyGraph(const GRAPH & input,SET & keyNodes,GRAPH *output,PATH *path)', '    OpDependency', '    runOnModule(Module & M)', '    operator=(const std::string & val)', '  Static Member Variables', '    ID']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\op_registration\\op_registration.cpp', [], ['    def(FunctionSchema)', '    def(c10::either,CppFunction)', '    fallback(CppFunction)', '    impl(const char *name_str,CppFunction)', '    Module(std::string ns)', '    Module', '    schema', '    CppFunction(KernelFunction func,std::unique_ptr schema,std::string debug)', '    checkNoDuplicateKernels_(const Options & options)', '    checkSchemaAndRegisterOp_(Options)', '    inferSchemaFromKernels_(const OperatorName & opName,const RegisterOperators::Options & options)', '    registerOp_(Options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\op_registration\\op_registration.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\op_registration\\op_registration_test.cpp', [], ['    autograd_kernel(Tensor a)', '    backend_fallback_kernel(const c10::OperatorHandle & op,c10::Stack *stack)', '    List', '    List', '    optional', '    optional', '    dummy_fn(const Tensor & x)', '    expectListEquals', '    expectListEquals', '    makeDeeplyNestedObject', '    nonautograd_kernel(Tensor a)', '    stackBasedKernel(const OperatorHandle &,c10::Stack *stack)', '    tuple', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithAliasAnalysisAfterRegisteringWithoutAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithoutAliasAnalysisAfterRegisteringWithAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithSameAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithNoAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithDifferentAliasAnalysis_thenShouldThrow)', '    TEST(OperatorRegistrationTest,whenRegisteringWithSchemaBeforeKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithSchemaAfterKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithNameBeforeKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithNameAfterKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithoutSchema_thenFails)', '    TEST(OperatorRegistrationTest,whenCallingOpWithWrongDispatchKey_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithCatchallKernel_whenCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithDispatchedKernelOutOfScope_whenRegisteringCatchallKernelAndCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithCatchallKernelOutOfScope_whenRegisteringDispatchedKernelAndCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringWithSchema_thenOnlyRegistersSchema)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringWithoutSchema_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRunningOutOfScope_thenSchemaIsGone)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwards_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwardsWithDifferentSchema_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwardsAndRunsOutOfScope_thenSchemaIsStillThereButCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernelsWithoutTensorInputs_whenRegistering_thenRegisters)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenRegistering_thenShowsWarning)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenRegisteringInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenRegistering_thenShowsWarning)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenRegisteringInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenNewerKernelDeletedAndOpCalled_thenCallsOlderKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenNewerKernelDeletedAndOpCalled_thenCallsOlderKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenOlderKernelDeletedAndOpCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenOlderKernelDeletedAndOpCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenOlderAndThenNewerKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenOlderAndThenNewerKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenNewerAndThenOlderKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenNewerAndThenOlderKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringCPUTensorType_thenCanOnlyCallUnboxedWithCPUTensorIdDispatchKey)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsInSameOpCallAndCalling_thenCallsCorrectKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsInSameOpCallOutOfScopeAndCalling_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsByNameAndNoneCanInferSchema_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsBySchemaAndNoneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsByNameAndOnlyOneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsBySchemaAndOnlyOneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMismatchingKernelsInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernel_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelForWrongBackend_thenCannotBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForDifferentBackend_thenRegularKernelCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForDifferentBackend_thenFallbackKernelCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForSameBackend_thenCallsRegularKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndCatchallKernelForSameBackend_thenCallsFallbackKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithRegularKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithRegularKernel_thenCanCallRegularKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithCatchAllKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithCatchAllKernel_thenCanCallCatchallKernel)', '    TEST(OperatorRegistrationTest,xlaPreAutogradOverridesAutogradKernel)', '    TEST(OperatorRegistrationTest,testAvailableArgTypes)', '    TEST(NewOperatorRegistrationTest,testBasics)', '    TEST(NewOperatorRegistrationTest,importTopLevel)', '    TEST(NewOperatorRegistrationTest,overload)', '    TEST(NewOperatorRegistrationTest,importNamespace)', '    TEST(NewOperatorRegistrationTest,schema)', '    TEST(NewOperatorRegistrationTest,dispatch)', '    TEST(NewOperatorRegistrationTest,dispatchMultiple)', '    TEST(NewOperatorRegistrationTest,fallback)', '    TEST(NewOperatorRegistrationTest,CppFunction)', '    TEST(NewOperatorRegistrationTest,testDelayedListener)', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    test(TestModernAndLegacyAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(TestModernAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(TestLegacyAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test_(std::function registration,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    ArgTypeTestKernel(InputType input,std::function inputExpectation,OutputType output)', '    MockKernel(bool *called)', '    operator()(Tensor)', '    operator()(Tensor)', '    operator()(Tensor,int64_t)', '    operator()(InputType input)', '    onOperatorDeregistered(const OperatorHandle & op)', '    onOperatorRegistered(const OperatorHandle & op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\op_utils_cudnn.h', [], ['    LogCuDNNPerfStats(const ArrayOfcudnnConvolutionAlgoPerf_t & perf_stat,int returned_algo_count)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\op_wrapper.h', ['    OpWrapper'], ['    DequantizeInput', '    Get', '    GetOutputQuantizationParams(dnnlowp::QuantizationFactory *qfactory,int index)', '    OpWrapper(OperatorBase *op,dnnlowp::QuantizationFactory *qfactory)', '    CreateBlob', '    GetBlob', '    Dequantize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\OpaqueTensorImpl.h', [], ['    copy_tensor_metadata(const OpaqueTensorImpl *src_opaque_impl,OpaqueTensorImpl *dest_opaque_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    has_storage', '    is_contiguous(c10::MemoryFormat memory_format)', '    OpaqueTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::Device device,OpaqueHandle opaque_handle,c10::IntArrayRef sizes)', '    release_resources', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    unsafe_opaque_handle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Generated\\OpClasses.h', ['    Add', '    AveragePool', '    AveragePoolRelu', '    BatchNormalization', '    ChannelShuffle', '    Clip', '    Concat', '    Conv', '    ConvRelu', '    ConvTranspose', '    CopyFromOpenCL', '    CopyToOpenCL', '    Declare', '    Export', '    FC', '    Flatten', '    GivenTensorFill', '    MaxPool', '    MaxPoolRelu', '    NCHW2NHWC', '    NHWC2NCHW', '    Receive', '    Relu', '    Reshape', '    Send', '    Softmax', '    Sum', '    SumRelu'], ['    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    Add(int broadcast)', '    getBroadcast', '    setBroadcast(int broadcast)', '    ~Add', '    AveragePool(vector kernelShape,vector pads,vector strides)', '    getKernelShape', '    getPads', '    getStrides', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~AveragePool', '    AveragePoolRelu(vector kernelShape,vector pads,vector strides)', '    AveragePoolRelu(const AveragePool & averagePool)', '    getKernelShape', '    getPads', '    getStrides', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~AveragePoolRelu', '    BatchNormalization(float epsilon,float momentum,bool spatial,bool isTest)', '    getEpsilon', '    getIsTest', '    getMomentum', '    getSpatial', '    setEpsilon(float epsilon)', '    setIsTest(bool isTest)', '    setMomentum(float momentum)', '    setSpatial(bool spatial)', '    ~BatchNormalization', '    ChannelShuffle', '    ~ChannelShuffle', '    Clip(float min,float max)', '    getMax', '    getMin', '    setMax(float max)', '    setMin(float min)', '    ~Clip', '    Concat(int axis,bool addAxis)', '    getAddAxis', '    getAxis', '    setAddAxis(bool addAxis)', '    setAxis(int axis)', '    ~Concat', '    Conv(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~Conv', '    ConvRelu(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    ConvRelu(const Conv & conv)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~ConvRelu', '    ConvTranspose(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~ConvTranspose', '    CopyFromOpenCL', '    ~CopyFromOpenCL', '    CopyToOpenCL', '    ~CopyToOpenCL', '    Declare', '    ~Declare', '    Export', '    ~Export', '    FC(int axis,int axisW)', '    getAxis', '    getAxisW', '    setAxis(int axis)', '    setAxisW(int axisW)', '    ~FC', '    Flatten', '    ~Flatten', '    GivenTensorFill', '    ~GivenTensorFill', '    getKernelShape', '    getPads', '    getStrides', '    MaxPool(vector kernelShape,vector pads,vector strides)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~MaxPool', '    getKernelShape', '    getPads', '    getStrides', '    MaxPoolRelu(vector kernelShape,vector pads,vector strides)', '    MaxPoolRelu(const MaxPool & maxPool)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~MaxPoolRelu', '    NCHW2NHWC', '    ~NCHW2NHWC', '    NHWC2NCHW', '    ~NHWC2NCHW', '    getSource', '    Receive(string source)', '    setSource(string source)', '    ~Receive', '    Relu', '    ~Relu', '    Reshape', '    ~Reshape', '    getDestination', '    Send(string destination)', '    setDestination(string destination)', '    ~Send', '    Softmax', '    ~Softmax', '    Sum', '    ~Sum', '    SumRelu', '    SumRelu(const Sum & sum)', '    ~SumRelu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\OpContext.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\OpContext.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libopencl-stub\\include\\CL\\opencl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Generated\\OpEnum.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\operator-delete.c', [], ['    pytorch_qnnp_delete_operator(pytorch_qnnp_operator_t op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\operator-run.c', [], ['    compute_average_pooling_multipass(const struct average_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_average_pooling_unipass(const struct average_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_channel_shuffle_fixed(const struct channel_shuffle_context [1] context,size_t index)', '    compute_channel_shuffle_variable(const struct channel_shuffle_context [1] context,size_t index)', '    compute_clamp_contiguous(const struct clamp_contiguous_context [1] context,size_t offset,size_t size)', '    compute_clamp_strided(const struct clamp_strided_context [1] context,size_t batch_index)', '    compute_dwconv_multiipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_dwconv_unipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_global_average_pooling_multipass(const struct global_average_pooling_context [1] context,size_t batch_index)', '    compute_global_average_pooling_unipass(const struct global_average_pooling_context [1] context,size_t batch_index)', '    compute_lut_contiguous(const struct lut_contiguous_context [1] context,size_t offset,size_t size)', '    compute_lut_strided(const struct lut_strided_context [1] context,size_t batch_index)', '    compute_max_pooling(const struct max_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_q8add_contiguous(const struct q8add_contiguous_context [1] context,size_t offset,size_t size)', '    compute_q8add_strided(const struct q8add_strided_context [1] context,size_t batch_offset,size_t batch_range)', '    compute_q8conv(const struct q8conv_context [1] context,size_t group_index,size_t image_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t image_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm_xzp(const struct q8gemm_xzp_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_sum_rows(const struct q8sum_rows_context [1] context,size_t group_index,size_t batch_index,size_t block_start,size_t group_range,size_t batch_range,size_t block_size)', '    compute_u8softargmax(const struct u8softargmax_context [1] context,size_t batch_index)', '    pytorch_qnnp_run_operator(pytorch_qnnp_operator_t op,pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator.cc', ['    C10FlagParser_caffe2_disable_implicit_engine_preference', '    C10FlagParser_caffe2_operator_max_engine_name_length', '    C10FlagParser_caffe2_operator_throw_if_fp_exceptions', '    C10FlagParser_caffe2_operator_throw_if_fp_overflow_exceptions'], ['    g_global_engine_pref_', '    argumentIndexWithName(const std::string & name)', '    _CreateOperator(const OperatorDef & operator_def,Workspace *ws)', '    compute_input_size_(const std::vector & inputs)', '    CreateOperator(const OperatorDef & operator_def,Workspace *ws,int net_position)', '    g_global_engine_pref', '    g_per_op_engine_pref', '    gDeviceTypeRegistry', '    GetGradientForOp(const OperatorDef & def,const vector & g_output)', '    GetTensorShapeOfBlob(const Blob *b)', '    InferBlobShapesAndTypes(CaffeMap & blob_desc,const vector & nets)', '    InferBlobShapesAndTypesFromMap(const CaffeMap,std::vector,const vector & nets)', '    InferBlobShapesAndTypesFromMap(const CaffeMap,std::vector,const CaffeMap & blob_types,const vector & nets)', '    InferBlobShapesAndTypesFromWorkspace(Workspace *ws,const vector & nets)', '    LoadInt8TensorInfoOfBlob(std::vector *scale,std::vector *offset,uint32_t *axis,const Blob *b)', '    OpRegistryKey(const std::string & op_type,const std::string & engine)', '    RegistryName', '    RegistryName', '    RegistryName', '    RegistryName', '    SetEnginePref(const PerOpEnginePrefType & per_op_engine_pref,const GlobalEnginePrefType & global_engine_pref)', '    SetGlobalEnginePref(const GlobalEnginePrefType & global_engine_pref)', '    SetOpEnginePref(const std::string & op_type,const CaffeMap & op_pref)', '    SetPerOpEnginePref(const PerOpEnginePrefType & per_op_engine_pref)', '    TryCreateOperator(const string & key,const OperatorDef & operator_def,Workspace *ws)', '    engines', '    GetOperatorLogger', '    GetRegisteredOperators', '    InputTensorShapes', '    OperatorBase(const OperatorDef & operator_def,Workspace *ws)', '    OperatorBase(const c10::FunctionSchema & fn_schema,std::vector inputs,c10::List outputs)', '    RegistryName', '    SetOperatorLogger(std::function tracer)', '    C10FlagParser_caffe2_disable_implicit_engine_preference(const std::string & content)', '    C10FlagParser_caffe2_operator_max_engine_name_length(const std::string & content)', '    C10FlagParser_caffe2_operator_throw_if_fp_exceptions(const std::string & content)', '    C10FlagParser_caffe2_operator_throw_if_fp_overflow_exceptions(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\operator.cpp', [], ['    aliasAnalysisHasSpecialCaseFor(Symbol symbol)', '    canonicalSchemaString(const FunctionSchema & schema)', '    deregisterOperator(const FunctionSchema & schema)', '    findOperatorFor(const c10::OperatorName & full_name)', '    findSimilarOperators(Symbol input_op)', '    getOperatorForLiteral(const char *signature)', '    getRegistry', '    printerHasSpecialCaseFor(Symbol sym)', '    registerOperator(Operator)', '    deregisterOperator(const FunctionSchema & schema)', '    lookupByLiteral(const char *name)', '    registerOperator(Operator)', '    registerPendingOperators']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\operator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\operator.h', [], ['    pytorch_qnnp_operator_get_log2_bias_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_input_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_kernel_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_output_element_size(const struct pytorch_qnnp_operator *convolution)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\operator_attaching_net_observer.h', ['    OperatorAttachingNetObserver'], ['    OperatorAttachingNetObserver(NetBase *subject_,TNetObserver *netObserver)', '    ~OperatorAttachingNetObserver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\operator_fallback_gpu.h', ['    final'], ['    debug_def', '    GPUFallbackOpEx(const OperatorDef & def,Workspace *ws)', '    InputIsTensorType', '    RunOnDevice', '    CreateBlob', '    GetBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\operator_fallback_gpu_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUIncrementByOne', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIncrementByOne', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IncrementByOne', '    TEST(OperatorFallbackTest,IncrementByOneOp)', '    TEST(OperatorFallbackTest,GPUIncrementByOneOp)', '    IncrementByOneOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\operator_fallback_ideep.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\operator_fallback_ideep.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_gpu_test.cc', ['    JustTest', '    JustTestCUDA', '    JustTestCUDNN'], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAJustTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTest', '    TEST(EnginePrefTest,GPUDeviceDefaultPreferredEngines)', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_gradient.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\operator_name.cpp', [], ['    operator<<(std::ostream & os,const OperatorName & opName)', '    toString(const OperatorName & opName)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\operator_name.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\operator_options.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_schema.cc', [], ['    operator<<(std::ostream & out,const OpSchema & schema)', '    SparseLengthsFillerHelper(const std::vector,size_t value_index,size_t length_index,std::vector *fillers)', '    SparseSegmentsFillerHelper(const std::vector,size_t value_index,size_t segment_index,std::vector *fillers)', '    SparseWeightsFillerHelper(const std::vector,size_t weight_index,std::vector *fillers)', '    AllowInplace(std::function inplace)', '    AllowInplace(set,int)', '    AllowOneToOneInplace', '    Arg(const char *name,const char *description,bool required)', '    ArgIsTest(const char *description)', '    CalculateOutput(int num_input)', '    CostInferenceFunction(CostInferenceFunctionType)', '    DeviceInferenceFunction(DeviceInferenceFunctionType)', '    DisallowInputFillers', '    EnforceInplace(std::function inplace)', '    EnforceInplace(set,int)', '    EnforceOneToOneInplace', '    FillUsing(std::function populator)', '    IdenticalTypeAndShape', '    IdenticalTypeAndShapeOfInput(int idx)', '    IdenticalTypeAndShapeOfInputDim(int idx,int dim)', '    IdenticalTypeAndShapeOfMultipleInputs(const vector & indices)', '    InheritOnnxSchema(const std::string & onnx_schema_name)', '    Input(const int n,const char *name,const char *description)', '    InputFillers(const std::vector)', '    InputsCanCrossDevices', '    NeedsAllInputShapes(TensorInferenceFunctionType f)', '    NumInputs(int min,int max)', '    NumInputs(int n)', '    NumInputs(std::function func)', '    NumInputs(set allowed_input_nums)', '    NumInputsOutputs(std::function func)', '    NumOutputs(int min,int max)', '    NumOutputs(int n)', '    NumOutputs(std::function func)', '    NumOutputs(set allowed_output_nums)', '    Output(const int n,const char *name,const char *description)', '    OutputCalculator(std::function calc)', '    Private', '    SameNumberOfOutput', '    ScalarType(::caffe2::TensorProto_DataType dt)', '    SetDoc(const string & doc)', '    SupplyDenseFillers(const std::vector)', '    TensorInferenceFunction(TensorInferenceFunctionType)', '    ValueKeyLengthInputFillers(size_t value_index,size_t key_index,size_t length_index)', '    ValueLengthInputFillers(size_t value_index,size_t length_index)', '    Verify(const OperatorDef & def)', '    WeightedValueKeyLengthInputFillers(size_t value_index,size_t key_index,size_t length_index,size_t weight_index)', '    map']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_schema.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_schema_test.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaArbitraryTensorInference', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaCalculateOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaInplace', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaInputOutputRelationOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSameInputOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSameInputOutputTensorInference', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSpecifiedInputOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaTestOp', '    TEST(OperatorSchemaTest,BasicSchema)', '    TEST(OperatorSchemaTest,SpecifiedInputOutput)', '    TEST(OperatorSchemaTest,InputOutputRelation)', '    TEST(OperatorSchemaTest,SameInputOutput)', '    TEST(OperatorSchemaTest,CalculateOutput)', '    TEST(OperatorSchemaTest,Inplace)', '    TEST(OperatorSchemaTest,TensorInferenceIdentical)', '    TEST(OperatorSchemaTest,TensorInferenceArbitrary)', '    TEST(OperatorSchemaTest,TestCastSchema)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaCostInference', '    TEST(OperatorSchemaTest,TestCostInference)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\torch_ops\\operator_sets.h', ['    OpSet_PyTorch_ver1'], ['    RegisterPyTorchOperatorSetSchema', '    ForEachSchema(std::function fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\operator_test.cc', ['    FooGradientDummyEngineOp', '    FooGradientOp', '    GetFooGradient', '    JustTest', '    JustTestAndDoesConstruct', '    JustTestAndNeverConstructs', '    JustTestWithSomeOutput', '    JustTestWithNonStandardIsTestArg', '    JustTestWithRequiredArg', '    JustTestWithStandardIsTestArg'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUJustTest', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestCPUOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithSomeOutput', '    CAFFE_ANONYMOUS_VARIABLE_CUDAJustTest', '    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithNonStandardIsTestArg', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithRequiredArg', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithStandardIsTestArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestCPUOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithSomeOutput', '    GetNetDefForTest', '    TEST(OperatorTest,DeviceTypeRegistryWorks)', '    TEST(OperatorTest,RegistryWorks)', '    TEST(OperatorTest,RegistryWrongDevice)', '    TEST(OperatorTest,ExceptionWorks)', '    TEST(OperatorTest,FallbackIfEngineDoesNotBuild)', '    TEST(OperatorTest,MultipleEngineChoices)', '    TEST(OperatorTest,CannotUseUninitializedBlob)', '    TEST(OperatorTest,TestParameterAccess)', '    TEST(OperatorTest,CannotAccessParameterWithWrongType)', '    TEST(OperatorTest,TestDefaultValue)', '    TEST(OperatorTest,TestSetUp)', '    TEST(OperatorTest,TestSetUpInputOutputCount)', '    TEST(OperatorTest,TestOutputValues)', '    TEST(NetTest,TestScaffoldingSimpleNet)', '    TEST(NetTest,TestScaffoldingDAGNet)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FooGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithNonStandardIsTestArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithRequiredArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithStandardIsTestArg', '    TEST(OperatorGradientRegistryTest,GradientSimple)', '    TEST(EnginePrefTest,PerOpEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePrefAndPerOpEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePrefAndPerOpEnginePrefAndOpDef)', '    TEST(EnginePrefTest,SetOpEnginePref)', '    TEST(EnginePrefTest,SetDefaultEngine)', '    TEST(RequiredArg,Basic)', '    TEST(IsTestArg,standard)', '    TEST(IsTestArg,non_standard)', '    type', '    type', '    GetGradientDefs', '    Run(int)', '    type', '    Run(int)', '    type', '    JustTestAndNeverConstructs(const OperatorDef & def,Workspace *ws)', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\OperatorEntry.cpp', [], ['    checkSchema(const OperatorName & name,const FunctionSchema & from_def,const FunctionSchema & inferred)', '    listAllDispatchKeys(const ska::flat_hash_map,std::list)', '    toString(c10::optional k)', '    checkInvariants', '    deregisterKernel_(c10::optional dispatch_key,std::list::iterator kernel)', '    deregisterSchema', '    dumpState', '    OperatorEntry(FunctionSchema)', '    OperatorEntry(OperatorName)', '    prepareForDeregistration', '    registerKernel(c10::optional dispatch_key,KernelFunction kernel,std::unique_ptr inferred_function_schema,std::string debug)', '    registerSchema(FunctionSchema)', '    updateDispatchTable_(c10::optional dispatch_key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\OperatorEntry.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\OperatorOptions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Generated\\OpNames.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\OpsAlreadyMovedToC10.cpp', [], ['    ops', '    is_aten_op(const c10::OperatorName & opName)', '    operator()(const std::pair & lhs,const std::pair & rhs)', '    operator()(const std::pair & p)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\OpsAlreadyMovedToC10.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\optical_flow.cc', [], ['    MergeOpticalFlow(cv::Mat & prev_flow,const cv::Mat & curr_flow)', '    MultiFrameOpticalFlowExtractor(const std::vector & grays,const int optical_flow_alg_type,cv::Mat & flow)', '    OpticalFlowExtractor(const cv::Mat & prev_gray,const cv::Mat & curr_gray,const int flow_alg_type,cv::Mat & flow)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\optical_flow.h', [], ['    MergeOpticalFlow(cv::Mat & prev_flow,const cv::Mat & curr_flow)', '    MultiFrameOpticalFlowExtractor(const std::vector & grays,const int optical_flow_alg_type,cv::Mat & flow)', '    OpticalFlowExtractor(const cv::Mat & prev_gray,const cv::Mat & curr_gray,const int flow_alg_type,cv::Mat & flow)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\optim.cpp', [], ['    assign_parameter(const Parameters & parameters,const char *name,torch::Tensor new_tensor)', '    check_exact_values(Options options,std::vector)', '    closure', '    closure', '    lr', '    lr', '    step', '    TEST(OptimTest,OptimizerAccessors)', '    TEST(OptimTest,OldInterface)', '    TEST(OptimTest,XORConvergence_SGD)', '    TEST(OptimTest,XORConvergence_LBFGS)', '    TEST(OptimTest,XORConvergence_Adagrad)', '    TEST(OptimTest,XORConvergence_RMSprop)', '    TEST(OptimTest,XORConvergence_RMSpropWithMomentum)', '    TEST(OptimTest,XORConvergence_Adam)', '    TEST(OptimTest,XORConvergence_AdamWithAmsgrad)', '    TEST(OptimTest,ProducesPyTorchValues_Adam)', '    TEST(OptimTest,ProducesPyTorchValues_AdamWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_AdamWithWeightDecayAndAMSGrad)', '    TEST(OptimTest,ProducesPyTorchValues_Adagrad)', '    TEST(OptimTest,ProducesPyTorchValues_AdagradWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_AdagradWithWeightDecayAndLRDecay)', '    TEST(OptimTest,ProducesPyTorchValues_RMSprop)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecayAndCentered)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecayAndCenteredAndMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_SGD)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecayAndMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecayAndNesterovMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_LBFGS)', '    TEST(OptimTest,ProducesPyTorchValues_LBFGS_with_line_search)', '    TEST(OptimTest,ZeroGrad)', '    TEST(OptimTest,ExternalVectorOfParameters)', '    TEST(OptimTest,AddParameter_LBFGS)', '    test_optimizer_xor(Options options)', '    MyOptimizer(std::vector params,MyOptimizerOptions defaults)', '    step(LossClosure closure)', '    MyOptimizerOptions(double lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\optim_baseline.h', [], ['    tensor(,,,,,)', '    tensor(,,)', '    tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\optimize_ideep.cc', [], ['    OptimizeForMkldnn(repr::NNModule *nn,caffe2::Workspace *ws,bool training_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\optimize_ideep.h', [], ['    OptimizeForMkldnn(nom::repr::NNModule *nn,caffe2::Workspace *ws,bool training_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\optimizer.cc', [], ['    graphOptimzations(nom::repr::NNModule *nn,int level)', '    optimize(NetDef net,Workspace *ws,int level)', '    optimize(NetDef net,int level)', '    workspaceOptimizations(nom::repr::NNModule *nn,Workspace *ws,int level)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\optimizer.cpp', [], ['    clone', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    noexcept', '    noexcept', '    operator<<(serialize::OutputArchive & archive,const Optimizer & optimizer)', '    operator>>(serialize::InputArchive & archive,Optimizer & optimizer)', '    add_param_group(const OptimizerParamGroup & param_group)', '    add_parameters(const std::vector & parameters)', '    defaults', '    defaults', '    load(serialize::InputArchive & archive)', '    param_groups', '    param_groups', '    parameters', '    parameters', '    save(serialize::OutputArchive & archive)', '    size', '    zero_grad', '    has_options', '    options', '    options', '    params', '    params', '    set_options(std::unique_ptr options)', '    clone', '    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\optimizer.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\optimizer.h', [], ['    optimize(NetDef net,Workspace *ws,int level)', '    optimize(NetDef net,int level)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Optional.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Optional.h', ['    optional', '    optional', '    optional'], ['    assert', '    assert(initialized)', '    bad_optional_access(const char *what_arg)', '    constexpr', '    convert(U v)', '    static_addressof(T & ref)', '    noexcept', '    noexcept', '    noexcept', '    nullopt', '    trivial_init', '    clear', '    contained_val', '    emplace(Args,...)', '    emplace(std::initializer_list il,Args,...)', '    has_value', '    initialize(Args,...)', '    initialize(std::initializer_list il,Args,...)', '    initialize(std::move *rhs)', '    initialize(std::forward v)', '    make_optional(T)', '    make_optional(std::reference_wrapper v)', '    operator bool', '    operator!=(const optional & x,const optional & y)', '    operator!=(const optional & x,nullopt_t)', '    operator!=(nullopt_t,const optional & x)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator()(argument_type const & arg)', '    operator*', '    operator*', '    operator->', '    operator->', '    operator<(const optional & x,const optional & y)', '    operator<(const optional &,nullopt_t)', '    operator<(nullopt_t,const optional & x)', '    operator<(const T & v,const optional & x)', '    operator<(const T & v,const optional & x)', '    operator<(const optional & x,const T & v)', '    operator<(const T & v,const optional & x)', '    operator<(const optional & x,const T & v)', '    operator<(const optional & x,const T & v)', '    operator<=(const optional & x,const optional & y)', '    operator<=(const optional & x,nullopt_t)', '    operator<=(nullopt_t,const optional &)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator=(nullopt_t)', '    operator=(const optional & rhs)', '    operator=(optional)', '    operator=(U)', '    operator==(const optional & x,const optional & y)', '    operator==(const optional & x,nullopt_t)', '    operator==(nullopt_t,const optional & x)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const optional & y)', '    operator>(const optional & x,nullopt_t)', '    operator>(nullopt_t,const optional &)', '    operator>(const T & v,const optional & x)', '    operator>(const T & v,const optional & x)', '    operator>(const T & v,const optional & x)', '    operator>=(const optional & x,const optional & y)', '    operator>=(const optional &,nullopt_t)', '    operator>=(nullopt_t,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    optional(U)', '    optional(U)', '    optional', '    optional(nullopt_t)', '    optional(const optional & rhs)', '    optional(optional)', '    optional(in_place_t,Args,...)', '    optional(in_place_t,std::initializer_list il,Args,...)', '    reset', '    declval', '    operator()(argument_type const & arg)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    swap(optional & rhs)', '    swap(**this,*rhs)', '    swap(optional & x,optional & y)', '    T(std::forward args,...)', '    T(il,std::forward args,...)', '    T(std::move *rhs)', '    value', '    value', '    value_or(V)', '    value_or(V)', '    ~constexpr_optional_base', '    ~optional', '    ~optional_base', '    bad_optional_access(const std::string & what_arg)', '    nullopt_t(init)', '    constexpr_optional_base', '    constexpr_optional_base(const T & v)', '    constexpr_optional_base(T)', '    constexpr_optional_base(in_place_t,Args,...)', '    constexpr_storage_t(trivial_init_t)', '    constexpr_storage_t(Args,...)', '    ~constexpr_storage_t', '    convert', '    static_addressof', '    contained_val', '    dataptr', '    dataptr', '    emplace(T & v)', '    emplace', '    has_value', '    initialized', '    operator bool', '    operator*', '    operator->', '    operator=', '    operator=(U)', '    operator=(nullopt_t)', '    optional', '    optional(nullopt_t)', '    optional(U & u)', '    optional', '    optional(const optional & rhs)', '    optional(in_place_t,T & v)', '    optional', '    reset', '    static_assert(,nullopt_t,)', '    static_assert(,in_place_t,)', '    static_assert(,)', '    swap(optional & rhs)', '    value', '    value_or(V)', '    ~optional', '    optional_base', '    optional_base(const T & v)', '    optional_base(T)', '    optional_base(in_place_t,Args,...)', '    swap', '    storage_t(trivial_init_t)', '    storage_t(Args,...)', '    ~storage_t', '    ~T']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\order_preserving_flat_hash_map.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\order_switch_ops.cc', ['    final', '    final'], ['    IDEEPNCHW2NHWCOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPNHWC2NCHWOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPNCHW2NHWCOp', '    ~IDEEPNHWC2NCHWOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\order_switch_ops.cc', ['    GetNCHW2NHWCGradient', '    GetNHWC2NCHWGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUNCHW2NHWC', '    CAFFE_ANONYMOUS_VARIABLE_CPUNHWC2NCHW', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCHW2NHWC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NHWC2NCHW', '    GetGradientDefs', '    GetGradientDefs', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\order_switch_ops.h', ['    final', '    final'], ['    NCHW2NHWCOp(Args,...)', '    NHWC2NCHWOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~NCHW2NHWCOp', '    ~NHWC2NCHWOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\order_switch_ops_cudnn.cc', ['    CuDNNOrderSwithOpBase', '    final', '    final'], ['    CuDNNOrderSwithOpBase(Args,...)', '    SetTensorDescriptor(const cudnnDataType_t data_type,const StorageOrder order,const std::vector & data_dims,cudnnTensorDescriptor_t data_desc)', '    ~CuDNNOrderSwithOpBase', '    CuDNNNCHW2NHWCOp(Args,...)', '    CuDNNNHWC2NCHWOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\order_switch_ops_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDANCHW2NHWC', '    CAFFE_ANONYMOUS_VARIABLE_CUDANHWC2NCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\ordered_dict.cpp', [], ['    TEST(OrderedDictTest,IsEmptyAfterDefaultConstruction)', '    TEST(OrderedDictTest,InsertAddsElementsWhenTheyAreYetNotPresent)', '    TEST(OrderedDictTest,GetReturnsValuesWhenTheyArePresent)', '    TEST(OrderedDictTest,GetThrowsWhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,CanInitializeFromList)', '    TEST(OrderedDictTest,InsertThrowsWhenPassedElementsThatArePresent)', '    TEST(OrderedDictTest,FrontReturnsTheFirstItem)', '    TEST(OrderedDictTest,FrontThrowsWhenEmpty)', '    TEST(OrderedDictTest,BackReturnsTheLastItem)', '    TEST(OrderedDictTest,BackThrowsWhenEmpty)', '    TEST(OrderedDictTest,FindReturnsPointersToValuesWhenPresent)', '    TEST(OrderedDictTest,FindReturnsNullPointersWhenPasesdKeysThatAreNotPresent)', '    TEST(OrderedDictTest,SubscriptOperatorThrowsWhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,SubscriptOperatorReturnsItemsPositionallyWhenPassedIntegers)', '    TEST(OrderedDictTest,SubscriptOperatorsThrowswhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,UpdateInsertsAllItemsFromAnotherOrderedDict)', '    TEST(OrderedDictTest,UpdateAlsoChecksForDuplicates)', '    TEST(OrderedDictTest,CanIterateItems)', '    TEST(OrderedDictTest,EraseWorks)', '    TEST(OrderedDictTest,ClearMakesTheDictEmpty)', '    TEST(OrderedDictTest,CanCopyConstruct)', '    TEST(OrderedDictTest,CanCopyAssign)', '    TEST(OrderedDictTest,CanMoveConstruct)', '    TEST(OrderedDictTest,CanMoveAssign)', '    TEST(OrderedDictTest,CanInsertWithBraces)', '    TEST(OrderedDictTest,ErrorMessagesIncludeTheKeyDescription)', '    TEST(OrderedDictTest,KeysReturnsAllKeys)', '    TEST(OrderedDictTest,ValuesReturnsAllValues)', '    TEST(OrderedDictTest,ItemsReturnsAllItems)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\ordered_dict.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\ordered_preserving_dict_test.cpp', [], ['    init_dict_size', '    TEST(OrderedPreservingDictTest,InsertAndDeleteBasic)', '    TEST(OrderedPreservingDictTest,InsertExistingDoesntAffectOrder)', '    TEST(OrderedPreservingDictTest,testRefType)', '    TEST(OrderedPreservingDictTest,DictCollisions)', '    TEST(OrderedPreservingDictTest,test_range_insert)', '    TEST(OrderedPreservingDictTest,test_range_erase_all)', '    TEST(OrderedPreservingDictTest,test_range_erase)', '    TEST(OrderedPreservingDictTest,test_move_constructor_empty)', '    TEST(OrderedPreservingDictTest,test_move_operator_empty)', '    TEST(OrderedPreservingDictTest,test_reassign_moved_object_move_constructor)', '    TEST(OrderedPreservingDictTest,test_reassign_moved_object_move_operator)', '    TEST(OrderedPreservingDictTest,test_copy_constructor_and_operator)', '    TEST(OrderedPreservingDictTest,test_copy_constructor_empty)', '    TEST(OrderedPreservingDictTest,test_copy_operator_empty)', '    TEST(OrderedPreservingDictTest,test_at)', '    TEST(OrderedPreservingDictTest,test_equal_range)', '    TEST(OrderedPreservingDictTest,test_access_operator)', '    TEST(OrderedPreservingDictTest,test_swap)', '    TEST(OrderedPreservingDictTest,test_swap_empty)', '    test_dict(dict_int_int & dict)', '    operator()(const int64_t input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\serialize\\output-archive.cpp', [], ['    OutputArchive(std::shared_ptr cu)', '    save_to(const std::string & filename)', '    save_to(std::ostream & stream)', '    save_to(const std::function & func)', '    write(const std::string & key,const c10::IValue & ivalue)', '    write(const std::string & key,const Tensor & tensor,bool is_buffer)', '    write(const std::string & key,OutputArchive & nested_archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\serialize\\output-archive.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\output_formatter.h', ['    OutputFormatter'], ['    format(const std::vector & durations_ms,uint64_t threads,uint64_t iterations)', '    ~OutputFormatter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\override_macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\p99.cc', [], ['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\p99_example.cc', [], ['    main(int argc,const char *[] argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\pack.h', [], ['    pytorch_pack_hgemm_w(size_t nc,size_t kc,size_t nr,size_t kr,const uint16_t *k,const uint16_t *b,uint16_t *packed_w)', '    pytorch_pack_q8conv_wdq(size_t n,size_t ks,size_t kc,uint32_t nr,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8conv_wrq(const size_t n,const size_t ks,const size_t kc,const uint32_t nr,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8deconv_wdq(size_t n,size_t ks,size_t kc,uint32_t nr,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8deconv_wrq(const size_t n,const size_t ks,const size_t kc,const uint32_t nr,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8dw_w_dilation(size_t h,size_t w,size_t c,size_t cr,size_t y_start,size_t y_end,size_t x_start,size_t x_end,const uint8_t *k,const int32_t *b,void *packed_w,bool pytorch_pack_b)', '    pytorch_pack_q8dw_wdq(size_t h,size_t w,size_t c,size_t cr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8dw_wrq(const size_t h,const size_t w,const size_t c,const size_t cr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8gemm_wdq(size_t nc,size_t kc,uint32_t nr,uint32_t np,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8gemm_wrq(const size_t nc,const size_t kc,const uint32_t nr,const uint32_t np,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_sconv_w(size_t n,size_t ks,size_t kc,size_t nr,size_t kr,const float *k,const float *b,float *packed_w)', '    pytorch_pack_sgemm_w(size_t nc,size_t kc,size_t nr,size_t kr,const float *k,const float *b,float *packed_w)', '    pytorch_pack_swizzle_q8gemm_bdq(size_t n,size_t kc,uint32_t nr,uint32_t kr,uint32_t sr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_swizzle_q8gemm_brq(const size_t n,const size_t kc,const uint32_t nr,const uint32_t kr,const uint32_t sr,const uint8_t *const k,const int32_t *const b,void *const packed_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pack_rnn_sequence_op.cc', ['    GetPackRNNSequenceGradient', '    GetUnpackRNNSequenceGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPackRNNSequence', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnpackRNNSequence', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackRNNSequence', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnpackRNNSequence', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pack_rnn_sequence_op.h', ['    PackRNNSequenceOpBase'], ['    DoRunWithType', '    PackRNNSequenceOpBase(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pack_segments.cc', ['    GetPackSegmentsGradient', '    GetUnpackSegmentsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPackSegments', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnpackSegments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackSegments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnpackSegments', '    presence_shape', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pack_segments.h', ['    final', '    final'], ['    dev_buffer_', '    dev_buffer_', '    dev_lengths_prefix_sum_', '    dev_lengths_prefix_sum_', '    dev_max_length_', '    dev_max_length_', '    dev_num_cell_', '    DoRunWithType', '    DoRunWithType2', '    GetSingleArgument', '    host_max_length_', '    host_max_length_', '    host_num_cell_', '    PackSegmentsOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    UnpackSegmentsOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\PackedSequence.cpp', [], ['    _pack_padded_sequence(const Tensor & _input,const Tensor & _lengths,bool batch_first)', '    _pack_padded_sequence_backward(const Tensor & grad,at::IntArrayRef input_size,const Tensor & _batch_sizes,bool batch_first)', '    _pad_packed_sequence(const Tensor & data,const Tensor & _batch_sizes,bool batch_first,Scalar padding_value,int64_t total_length)', '    checkLongTensor(const Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pad_op.cc', ['    GetPadImageGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUPadImage', '    StringToPadMode(const string & mode)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadImage', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadImageGradient', '    vector', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    PadTensorInference(const OperatorDef & def,const vector & in)', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pad_op.h', ['    final', '    final', '    PadMode'], ['    StringToPadMode(const string & mode)', '    PadTensorInference(const OperatorDef & def,const vector & in)', '    PadImageGradientOp(Args,...)', '    PadImageOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~PadImageGradientOp', '    ~PadImageOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\padded_buffer.cpp', [], ['    Index(const std::vector & indices)', '    PaddedBufferBase(const std::vector & dims,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\padded_buffer.h', ['    PaddedBuffer', '    PaddedBufferBase'], ['    CompareErrorMsg(const PaddedBuffer & v1,const PaddedBuffer & v2,int index)', '    ExpectAllEqual(const PaddedBuffer & f1,const PaddedBuffer & f2)', '    ExpectAllNear(const PaddedBuffer & f1,const PaddedBuffer & f2,float abs_error)', '    resize', '    CallArg(const PaddedBuffer & buffer)', '    Backup', '    CheckBackup', '    data', '    data', '    operator()(int i0)', '    operator()(int i0)', '    operator()(int i0,int i1)', '    operator()(int i0,int i1)', '    operator()(int i0,int i1,int i2)', '    operator()(int i0,int i1,int i2)', '    operator()(int i0,int i1,int i2,int i3)', '    operator()(int i0,int i1,int i2,int i3)', '    operator()(const std::vector & indices)', '    operator()(const std::vector & indices)', '    PaddedBuffer(int d0,const std::string & name)', '    PaddedBuffer(int d0,int d1,const std::string & name)', '    PaddedBuffer(int d0,int d1,int d2,const std::string & name)', '    PaddedBuffer(int d0,int d1,int d2,int d3,const std::string & name)', '    PaddedBuffer(const std::vector & dims,const std::string & name)', '    PaddedBuffer(const PaddedBuffer & other,const std::string & name)', '    raw_data', '    raw_data', '    ValidateWatermark', '    Index(const std::vector & indices)', '    name', '    PaddedBufferBase(const std::vector & dims,const std::string & name)', '    raw_size', '    size', '    ~PaddedBufferBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\padding.cpp', [], ['    ConstantPadImpl(const ConstantPadOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    pretty_print(std::ostream & stream)', '    ReflectionPadImpl(const ReflectionPadOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    ReplicationPadImpl(const ReplicationPadOptions & options_)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    ZeroPad2dImpl(const ZeroPad2dOptions & options_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\padding.cpp', [], ['    PadFuncOptions(std::vector pad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\padding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\padding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\padding.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\parallel.cpp', [], ['    TEST_F(ParallelTest,DifferentiableScatter_MultiCUDA)', '    TEST_F(ParallelTest,DifferentiableGather_MultiCUDA)', '    TEST_F(ParallelTest,Replicate_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApply_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApplyWithDifferentOutputDevice_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApplyRethrowsException_MultiCUDA)', '    TEST_F(ParallelTest,DataParallelPlacesTheOutputOnTheRequestedDevice_MultiCUDA)', '    TEST_F(ParallelTest,DataParallelUsesAllAvailableCUDADevices_CUDA)', '    TEST_F(ParallelTest,DataParallelNumericalEquivalence_MultiCUDA)', '    conv', '    fc', '    forward(torch::Tensor x)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    M', '    reset', '    reset', '    reset', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Parallel.h', [], ['    divup(int64_t x,int64_t y)', '    get_num_interop_threads', '    get_num_threads', '    get_parallel_info', '    get_thread_num', '    in_parallel_region', '    init_num_threads', '    intraop_default_num_threads', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)', '    set_num_interop_threads(int)', '    set_num_threads(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\parallel_info.cc', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\parallel_net_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSleep', '    CAFFE_ANONYMOUS_VARIABLE_CUDASleep', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sleep', '    RunNetAndGetDuration(const string & net_def_str,const string & type)', '    TEST(DAGNetTest,TestDAGNetTiming)', '    TEST(SimpleNetTest,TestSimpleNetTiming)', '    TEST(DAGNetTest,TestDAGNetTimingReadAfterRead)', '    TEST(SimpleNetTest,TestSimpleNetTimingReadAfterRead)', '    TEST(DAGNetTest,TestDAGNetTimingWriteAfterWrite)', '    TEST(SimpleNetTest,TestSimpleNetTimingWriteAfterWrite)', '    TEST(DAGNetTest,TestDAGNetTimingWriteAfterRead)', '    TEST(SimpleNetTest,TestSimpleNetTimingWriteAfterRead)', '    TEST(DAGNetTest,TestDAGNetTimingControlDependency)', '    TEST(SimpleNetTest,TestSimpleNetTimingControlDependency)', '    RunOnDevice', '    SleepOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelCommon.cpp', [], ['    get_env_num_threads(const char *var_name,size_t def_value)', '    get_env_var(const char *var_name,const char *def_value)', '    get_parallel_info', '    intraop_default_num_threads']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelNative.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelNative.h', [], ['    calc_num_tasks_and_chunk_size(int64_t begin,int64_t end,int64_t grain_size)', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelNativeTBB.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelNativeTBB.h', [], ['    intraop_invoke(const F0 & f0,const F1 & f1)', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelOpenMP.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelOpenMP.h', [], ['    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ParallelThreadPoolNative.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\params.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\utils\\ParamsHash.h', [], ['    operator()(const Params & a,const Params & b)', '    static_assert(std::is_pod::value,)', '    operator()(const Params & params)', '    static_assert(std::is_pod::value,)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\utils\\ParamUtils.h', [], ['    expand_param_if_needed(IntArrayRef list_param,const char *param_name,int64_t expected_dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\parse_string_literal.h', [], ['    isOctal(char c)', '    isCharCount(char c,const std::string & str,size_t start,int len)', '    parseOctal(const std::string & str,size_t pos)', '    parseStringLiteral(const SourceRange & range,const std::string & str)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\parser.cpp', [], ['    mergeTypesFromTypeComment(const Decl & decl,const Decl & type_annotation_decl,bool is_method)', '    followsTuple(int kind)', '    lexer', '    parseClass', '    parseExp', '    parseFunction(bool is_method)', '    Parser(const std::shared_ptr & src)', '    parseTypeComment', '    create_compound(int kind,const SourceRange & range,TreeList)', '    createApply(const Expr & expr)', '    lexer', '    makeList(const SourceRange & range,TreeList)', '    maybeParseAssignmentOp', '    maybeParseTypeAnnotation', '    parseArguments(TreeList & inputs,TreeList & attributes)', '    parseAssign(const Expr & lhs)', '    parseAttributeValue', '    parseBareTypeAnnotation', '    parseBaseExp', '    parseClass', '    parseConcatenatedStringLiterals', '    parseConst', '    parseDecl', '    parseExp', '    parseExp(int precedence)', '    parseExpOrExpTuple', '    parseFor', '    parseFormalParam(bool kwarg_only)', '    parseFormalParams', '    parseFunction(bool is_method)', '    parseIdent', '    parseIf(bool expect_if)', '    parseLHSExp', '    parseList(int begin,int sep,int end,T (ParserImpl::*) () parse)', '    parseReturnAnnotation', '    ParserImpl(const std::shared_ptr & source)', '    parseSequence(int begin,int sep,int end,const std::function & parse)', '    parseStatements(bool expect_indent,bool in_class)', '    parseStmt(bool in_class)', '    parseSubscript(const TreeRef & value)', '    parseSubscriptExp', '    parseTrinary(TreeRef true_branch,const SourceRange & range,int binary_prec)', '    parseTypeComment', '    parseWhile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\parser.h', [], ['    mergeTypesFromTypeComment(const Decl & decl,const Decl & type_annotation_decl,bool is_method)', '    lexer', '    parseClass', '    parseExp', '    parseFunction(bool is_method)', '    Parser(const std::shared_ptr & src)', '    parseTypeComment', '    ~Parser']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\parser_constants.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\partition_desc.h', [], ['    deprecated_AT_ASSERT', '    str(,,,,,::c10::str __VA_ARGS__)', '    dim', '    isNoop', '    nSubTensors', '    subTensorDesc', '    subTensorDesc', '    dim_', '    PartitionDesc(const TensorDesc & _desc,size_t _nSubTensors,size_t _dim)', '    dim_', '    PartitionDesc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\partition_ops.cc', ['    GetGatherByKeyGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherByKey', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsPartition', '    CAFFE_ANONYMOUS_VARIABLE_CPUPartition', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherByKey', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsPartition', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Partition', '    GetGradientDefs', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\partition_ops.h', ['    GatherByKeyOp', '    LengthsPartitionOp', '    PartitionOp', '    PartitionOpBase'], ['    moduloPartition(Index key,int numPartitions)', '    DoRunWithType', '    GatherByKeyOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    LengthsPartitionOp(Args,...)', '    LengthsPartitionOp', '    operator=', '    RunOnDevice', '    DoRunWithType', '    operator=', '    PartitionOp(Args,...)', '    PartitionOp', '    RunOnDevice', '    ApplyPartition(bool skipFirstArgument)', '    PartitionOpBase(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\pass_manager.cpp', [], ['    getCustomPostFusionPasses', '    getCustomPreFusionPasses', '    RegisterPostFusionPass(GraphPass p)', '    RegisterPreFusionPass(GraphPass p)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\pass_manager.h', [], ['    getCustomPostFusionPasses', '    getCustomPreFusionPasses', '    RegisterPostFusionPass(GraphPass p)', '    RegisterPreFusionPass(GraphPass p)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\passes.cc', [], ['    RegistryName', '    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\passes.h', ['    OptimizationPass', '    WorkspaceOptimizationPass'], ['    RegistryName', '    OptimizationPass(NNModule *nn)', '    run', '    ~OptimizationPass', '    WorkspaceOptimizationPass(NNModule *nn,Workspace *ws)', '    ~WorkspaceOptimizationPass']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\pattern_net_transform.cc', [], ['    compare_ops(const OperatorDef & p_op,const OperatorDef & g_op,bool arg_match)', '    GetPatternTraversalOrder(const transform::Graph & graph)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int g_idx)', '    ReplaceRule(const std::vector & match,transform::Graph *g_ptr)', '    ValidatorRule(const transform::Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\pattern_net_transform.h', ['    PatternNetTransform'], ['    DisableArgumentMatching', '    EnableArgumentMatching', '    GetPatternTraversalOrder(const transform::Graph & graph)', '    PatternNetTransform(const NetDef & pattern_net,const NetDef & replace_net)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int g_idx)', '    ReplaceRule(const std::vector & match,transform::Graph *g_ptr)', '    TransformBlobWrapper(const string & blob_name)', '    ValidatorRule(const transform::Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\pattern_net_transform_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp3', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp1', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp2', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp3', '    TEST(PatternNetTransformTest,TestGenerateTransform)', '    TEST(PatternNetTransformTest,TestRepeatedTransform)', '    TEST(PatternNetTransformTest,TestHardTransform)', '    TEST(PatternNetTransformTest,TestGeneralStringMatching)', '    TEST(PatternNetTransformTest,TestDeviceOptionMatching)', '    TEST(PatternNetTransformTest,TestEngineMatching)', '    TEST(PatternNetTransformTest,TestSingularArgumentMatching)', '    TEST(PatternNetTransformTest,TestNonStrictTopographicTransform)', '    TEST(PatternNetTransformTest,TestMultiInputOutputTransform)', '    Run(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\peephole.cpp', [], ['    mustBeEqual(const c10::optional & a,const c10::optional & b)', '    check_none_index', '    PeepholeOptimize(const std::shared_ptr & graph,bool addmm_fusion_enabled)', '    PeepholeOptimizeImpl(const std::shared_ptr & graph,bool onnx_export)', '    run(Block *block)', '    runAliasingSensitivePeepholeTransformations(Node *node)', '    safeToChangeAliasingRelationship(Node *node)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\peephole.cpp', [], ['    convertDynamicUnbindToSplitToSequence(Block *b,int opset_version)', '    convertSplitToDynamic(Block *b,int opset_version)', '    convertUnbindToSplit(Block *b,int opset_version)', '    fuseListConstructListUnpack(Block *b)', '    fuseSplitToSequenceListUnpack(Block *b)', '    fuseSplitListUnpack(Block *b)', '    fuseUnbindListUnpack(Block *b)', '    eraseListConstruct(Block *block,int opset_version)', '    isSafeToSpeculate(Node *n)', '    replaceInputWithList(Node *node,size_t i,ArrayRef to)', '    speculateOps(Block *block)', '    PeepholeOptimizeONNX(std::shared_ptr & graph,int opset_version,bool fixed_batch_size)', '    removeMaxPoolUnusedOutput(Block *b)', '    i', '    composeTransposes(const std::vector & t1,const std::vector & t2)', '    eliminateNopTranspose(Block *b)', '    fixDefaultLstmCellState(Block *b,int opset_version)', '    fixDefaultRnnHiddenState(Block *b,int opset_version)', '    fixDefaultRNNState(Graph *graph,Node *n,int input_index,int opset_version)', '    fuseBroadcast(Block *b)', '    fuseConsecutiveTransposes(Block *b)', '    fuseTransposeIntoGemm(Block *b)', '    fusibleExpandTo(at::IntArrayRef from,at::IntArrayRef to)', '    getBroadcastPositions(Node *node)', '    hackFixupPadPackedShapes(Block *graph)', '    isNopTranspose(const std::vector & perm)', '    isRNN(const Node *node)', '    pushPackingPastRnn(Block *b)', '    removeNopPacking(Block *graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\peephole.h', [], ['    PeepholeOptimize(const std::shared_ptr & graph,bool addmm_fusion_enabled)', '    PeepholeOptimize(Block *block,bool addmm_fusion_enabled)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\peephole.h', [], ['    PeepholeOptimizeONNX(std::shared_ptr & graph,int opset_version,bool fixed_batch_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\percentile_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPercentile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Percentile', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\percentile_op.h', ['    final'], ['    PercentileOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\perf_observer.cc', ['    C10FlagParser_aiBench_netFollowupSampleCount', '    C10FlagParser_aiBench_netFollowupSampleRate', '    C10FlagParser_aiBench_netInitSampleRate', '    C10FlagParser_aiBench_operatorNetSampleRatio', '    C10FlagParser_aiBench_skipIters'], ['    registerGlobalPerfNetObserverCreator(int *,char ***)', '    getCpuMilliseconds', '    getCpuTimeMilliseconds', '    getTensorShapes', '    getTicksPerMillisecond', '    getWallClockTimeMilliseconds', '    getWallMilliseconds', '    PerfOperatorObserver(OperatorBase *op,PerfNetObserver *netObserver)', '    Start', '    Stop', '    ~PerfOperatorObserver', '    C10FlagParser_aiBench_netFollowupSampleCount(const std::string & content)', '    C10FlagParser_aiBench_netFollowupSampleRate(const std::string & content)', '    C10FlagParser_aiBench_netInitSampleRate(const std::string & content)', '    C10FlagParser_aiBench_operatorNetSampleRatio(const std::string & content)', '    C10FlagParser_aiBench_skipIters(const std::string & content)', '    getObserverName(const OperatorBase *op,int idx)', '    PerfNetObserver(NetBase *subject_)', '    Start', '    Stop', '    ~PerfNetObserver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\observers\\perf_observer.h', ['    PerfNetObserver', '    PerfOperatorObserver'], ['    getClockTimeMilliseconds', '    getObserverName(const OperatorBase *op,int idx)', '    PerfNetObserver(NetBase *subject_)', '    Start', '    Stop', '    ~PerfNetObserver', '    getCpuMilliseconds', '    getTensorShapes', '    getWallMilliseconds', '    PerfOperatorObserver(OperatorBase *op,PerfNetObserver *netObserver)', '    Start', '    Stop', '    ~PerfOperatorObserver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\PerOpRegistration.cpp', [], ['    registerer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\perplexity_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPerplexity', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Perplexity', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\perplexity_op.h', ['    final'], ['    PerplexityOp(Args,...)', '    RunOnDevice', '    ~PerplexityOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\PhiloxRNGEngine.h', ['    philox_engine'], ['    incr', '    incr_n(uint64_t n)', '    mulhilo32(uint32_t a,uint32_t b,uint32_t *result_high)', '    operator()', '    philox_engine(uint64_t seed,uint64_t subsequence,uint64_t offset)', '    single_round(detail::UINT4 ctr,detail::UINT2 in_key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\pickle.cpp', ['    VectorReader'], ['    pickle(const IValue & ivalue,std::vector *tensor_table)', '    pickle(std::function writer,const IValue & ivalue,std::vector *tensor_table)', '    pickle_load(const std::vector & data)', '    pickle_save(const at::IValue & ivalue)', '    unpickle(const char *data,size_t size,TypeResolver type_resolver,const std::vector *tensor_table)', '    unpickle(std::function reader,TypeResolver type_resolver,const std::vector *tensor_table)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    VectorReader(const std::vector & data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\pickle.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\pickler.cpp', [], ['    swapDouble(double value)', '    checkHasValidSetGetState(const std::shared_ptr & cls)', '    getTypeTags', '    getWriteableTensorData(const at::Tensor & tensor)', '    endTuple', '    endTypeTag(const IValue & ivalue)', '    protocol', '    pushBinGet(uint32_t memo_id)', '    pushBool(bool value)', '    pushBytes(const std::string & string)', '    pushDevice(const IValue & ivalue)', '    pushDict(const IValue & ivalue)', '    pushDouble(double value)', '    pushGenericList(const IValue & ivalue)', '    pushGlobal(const std::string & module_name,const std::string & class_name)', '    pushInt(int64_t n)', '    pushIValue(const IValue & ivalue)', '    pushIValueImpl(const IValue & ivalue)', '    pushLiteralTensor(const IValue & ivalue)', '    pushLong(const std::string & data)', '    pushNextBinPut', '    pushSpecializedList(const IValue & ivalue,const char *list_name,const std::function & item_pusher)', '    pushStorageOfTensor(const at::Tensor & tensor)', '    pushString(const std::string & string)', '    pushStringImpl(const std::string & string)', '    pushTensor(const IValue & ivalue)', '    pushTensorReference(const IValue & ivalue)', '    pushTuple(const IValue & ivalue)', '    startTuple', '    startTypeTag', '    stop', '    ~Pickler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\pickler.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\piecewise_linear_transform_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPiecewiseLinearTransform', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PiecewiseLinearTransform']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\piecewise_linear_transform_op.h', ['    final'], ['    schema_PiecewiseLinearTransform', '    bounds_device_', '    CheckBoundsSorted(const T *bounds,const int64_t num_bounds_per_group,const int64_t num_group)', '    CheckTransParamFromArg', '    GetRepeatedArgument', '    GetSingleArgument', '    GetTransParamData(const T **bounds,const T **slopes,const T **intercepts,int64_t *num_func_per_group,int64_t *num_group)', '    InferNumFunctionsPerGroup(const int64_t num_bounds,const int64_t num_slopes,const int64_t num_intercepts,int64_t *num_func_per_group,int64_t *num_group)', '    intercepts_device_', '    PiecewiseLinearTransform(const T x,const T *bounds,const T *slopes,const T *intercepts,const int64_t num_func_per_group)', '    PiecewiseLinearTransformOp(Args,...)', '    RunOnDevice', '    setUpTensors(int64_t & num_func_per_group,int64_t & num_group,int64_t M)', '    slopes_device_', '    TransformBinary', '    TransformGeneral']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\pimpl-inl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\pimpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\PinnedMemoryAllocator.cpp', [], ['    getPinnedMemoryAllocator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cuda\\PinnedMemoryAllocator.h', [], ['    getPinnedMemoryAllocator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\PixelShuffle.cpp', [], ['    pixel_shuffle(const Tensor & self,int64_t upscale_factor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\pixelshuffle.cpp', [], ['    forward(const Tensor & input)', '    PixelShuffleImpl(const PixelShuffleOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\pixelshuffle.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\pixelshuffle.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\pixelshuffle.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\plan_executor.cc', ['    C10FlagParser_caffe2_handle_executor_threads_exceptions', '    CompiledGuard'], ['    getContinuationTest(Workspace *,const ExecutionStep & step)', '    ExecuteStepRecursive(ExecutionStepWrapper & stepWrapper)', '    getShouldStop(const Blob *b)', '    next_substep', '    reportWorker', '    RunPlanOnWorkspace(Workspace *ws,const PlanDef & plan,ShouldContinue shouldContinue)', '    worker', '    C10FlagParser_caffe2_handle_executor_threads_exceptions(const std::string & content)', '    done', '    ReporterInstance(int intervalMillis,bool *done,std::function)', '    start(int64_t intervalMillis,std::function)', '    ~Reporter', '    CompiledExecutionStep(const ExecutionStep *mainStep,Workspace *externalWorkspace,ShouldContinue externalShouldContinue,NetDefMap *netDefs,WorkspaceIdInjector *ws_id_injector)', '    gotFailure', '    shouldStop', '    compiled', '    CompiledGuard', '    operator->', '    reset(std::unique_ptr)', '    reset(CompiledExecutionStep *compiledRef)', '    doCompile', '    ExecutionStepWrapper(const ExecutionStep *step,Workspace *externalWorkspace,ShouldContinue externalShouldContinue,NetDefMap *netDefs,WorkspaceIdInjector *ws_id_injector)', '    step', '    InjectWorkspaceId(Workspace *workspace)', '    seq_', '  Static Member Variables', '    GLOBAL_WORKSPACE_ID', '    NODE_ID']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\plan_executor.h', [], ['    RunPlanOnWorkspace(Workspace *ws,const PlanDef & plan,ShouldContinue)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Support\\Pointer.h', [], ['    make_unique(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\pointwise_elim.cc', ['    FuseCastBatchOneHot'], ['    fuseCastBatchOneHot(NNModule *nn)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\custom\\pointwise_elim.h', [], ['    fuseCastBatchOneHot(NNModule *nn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\PointwiseOps.cpp', [], ['    torch_warn_once_74', '    addcdiv(const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcdiv_(Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcdiv_out(Tensor & result,const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul(const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul_(Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul_out(Tensor & result,const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\PointwiseOps.h', [], ['    addcdiv_stub', '    addcdiv_stub', '    operator=', '    addcmul_stub', '    addcmul_stub', '    operator=', '    mse_backward_stub', '    mse_backward_stub', '    operator=', '    operator=', '    smooth_l1_backward_stub', '    smooth_l1_backward_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\PointwiseOpsKernel.cpp', [], ['    addcdiv_cpu_kernel(TensorIterator & iter,Scalar value)', '    addcmul_cpu_kernel(TensorIterator & iter,Scalar value)', '    mse_backward_cpu_kernel(TensorIterator & iter,Scalar value)', '    smooth_l1_backward_cpu_kernel(TensorIterator & iter,Scalar norm)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Pool.h', [], ['    avg_pool2d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,int64_t nbatch,int kH,int kW,int dH,int dW,int padH,int padW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth)', '    avg_pool3d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth)', '    max_pool2d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,int64_t nbatch,int kH,int kW,int dH,int dW,int padH,int padW,int dilationH,int dilationW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth,bool cuda)', '    max_pool3d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int dilationT,int dilationH,int dilationW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth)', '    pool2d_shape_check(const Tensor & input,int kH,int kW,int dH,int dW,int padH,int padW,int dilationH,int dilationW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth)', '    pool3d_shape_check(const Tensor & input,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int dilationT,int dilationH,int dilationW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth,bool check_input_size)', '    pooling_output_shape(T inputSize,T kernelSize,T pad,T stride,T dilation,bool ceil_mode)', '    pooling_output_shape_pad_lr(T inputSize,T kernelSize,T pad_l,T pad_r,T stride,T dilation,bool ceil_mode)', '    safe_downcast(src_t)', '    ndimension', '    numel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\pool_dnnlowp_op.cc', ['    AveragePool', '    final', '    final', '    MaxPool'], ['    finalize(const int size,T & y_data)', '    initialize', '    process(const int x_col,const int y_col,ConstEigenMatrixMap & x_mat,EigenMatrixMap & y_mat)', '    process(const T & x_data,T & y_data)', '    finalize(const int,T &)', '    initialize', '    process(const int x_col,const int y_col,ConstEigenMatrixMap & x_mat,EigenMatrixMap & y_mat)', '    process(const T & x_data,T & y_data)', '    AveragePoolDnnLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolDnnLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\pool_dnnlowp_op_avx2.cc', [], ['    average_pool_3d_avx2(const uint8_t *Xdata,int n,int height,int width,int depth,int channels,int pooled_height,int pooled_width,int pooled_depth,int kernel_h,int kernel_w,int kernel_d,int stride_h,int stride_w,int stride_d,int pad_t,int pad_l,int pad_d,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    average_pool_avx2(const uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    max_pool_avx2(const uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,uint8_t *Ydata)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\pool_dnnlowp_op_avx2.h', [], ['    average_pool_3d_avx2(const uint8_t *Xdata,int n,int height,int width,int depth,int channels,int pooled_height,int pooled_width,int pooled_depth,int kernel_h,int kernel_w,int kernel_d,int stride_h,int stride_w,int stride_d,int pad_t,int pad_l,int pad_d,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    average_pool_avx2(const std::uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,std::uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    max_pool_avx2(const std::uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,std::uint8_t *Ydata)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_gradient_op.cc', ['    GetPoolGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePoolGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPoolGradient', '    ComputeAveragePoolGradient1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient2D(const int W,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient2D(const int,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient1D(const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient1D(const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient2D(const int W,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient2D(const int,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    RunAveragePoolGradient1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const bool count_include_pad,const T *dY,T *dX)', '    RunAveragePoolGradient2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const bool count_include_pad,const T *dY,T *dX)', '    RunAveragePoolGradient3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const bool count_include_pad,const T *dY,T *dX)', '    RunMaxPoolGradient1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const T *dY,const T *X,const T *Y,T *dX)', '    RunMaxPoolGradient2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const T *dY,const T *X,const T *Y,T *dX)', '    RunMaxPoolGradient3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const T *dY,const T *X,const T *Y,T *dX)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector &,const std::vector & stride,const std::vector & pads,const T *dY,const T *,const T *,T *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *,const float *,float *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *,const float *,float *dX,CPUContext *)', '    GetGradientDefs', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector &,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *X,const float *Y,float *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *X,const float *Y,float *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool3D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool3D', '    AveragePoolDocGenerator(const char *dim)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool3D', '    ComputeAveragePool1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool2D(const int W,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool2D(const int,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool1D(const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool1D(const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool2D(const int W,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool2D(const int,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    MaxPoolDocGenerator(const char *dim)', '    RunAveragePool1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const bool count_include_pad,const T *X,T *Y)', '    RunAveragePool2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const bool count_include_pad,const T *X,T *Y)', '    RunAveragePool3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const bool count_include_pad,const T *X,T *Y)', '    RunMaxPool1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const T *X,T *Y)', '    RunMaxPool2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const T *X,T *Y)', '    RunMaxPool3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const T *X,T *Y)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\pool_op.cc', ['    final', '    final'], ['    IDEEPPoolGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPPoolGradientOp', '    ~IDEEPPoolOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_op.h', ['    final', '    final'], ['    AveragePoolFunctor(const OperatorBase & op)', '    Backward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    Forward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,Context *context)', '    GlobalPoolingBackward(int N,int C,int HxW,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    GlobalPoolingForward(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    ones', '    PoolGradientOp(Args,...)', '    PoolOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC', '    ~PoolGradientOp', '    ~PoolOp', '    Backward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    Forward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,Context *context)', '    GlobalPoolingBackward(int N,int C,int HxW,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    GlobalPoolingForward(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    MaxPoolFunctor(const OperatorBase &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_op_cudnn.cc', ['    final', '    final'], ['    SetTensorDescriptor(const cudnnDataType_t data_type,const StorageOrder order,const std::vector & dims,cudnnTensorDescriptor_t *desc)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    CuDNNAveragePoolFunctor(const OperatorBase & op)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,CUDAContext *context)', '    GetPoolingMode', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const T *X,T *Y,CUDAContext *context)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    CuDNNMaxPoolFunctor(const OperatorBase & op)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,CUDAContext *context)', '    GetPoolingMode', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const T *X,T *Y,CUDAContext *context)', '    CuDNNPoolGradientOp(Args,...)', '    CuDNNPoolOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    ~CuDNNPoolGradientOp', '    ~CuDNNPoolOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\cuda_rtc\\pool_op_rtc_gpu.cc', ['    AveragePool', '    final', '    final', '    MaxPool', '    MaxPoolGradientRTCFunction', '    MaxPoolRTCFunction'], ['    MaxPoolGradientRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC', '    ~MaxPoolGradientRTCOp', '    ~MaxPoolRTCOp', '    GetSource(const int output_size,const int num,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l)', '    KernelName(Args,...)', '    MaxPoolGradientRTCFunction', '    GetSource(const int output_size,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l)', '    KernelName(Args,...)', '    MaxPoolRTCFunction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_op_util.cc', [], ['    IsNeon2x2p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    IsNeon4x4p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    RunNeonAveragePool4x4p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)', '    RunNeonMaxPool2x2p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pool_op_util.h', [], ['    IsNeon2x2p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    IsNeon4x4p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    RunNeonAveragePool4x4p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)', '    RunNeonMaxPool2x2p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\pool_test.cc', [], ['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compareMaxPooling(int N,int C,int H,int W,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    runMaxPool(int kernel,int stride,int pad)', '    TEST(PoolOp,MaxPool2x2s2p0Randomized)', '    TEST(PoolOp,MaxPool4x4s3p2Randomized)', '    TEST(PoolOp,MaxPool2x2s2p0Special)', '    TEST(PoolOp,MaxPoolFullyRandomized)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\pooling.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\pooling.cpp', [], ['    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    AvgPoolImpl(const AvgPoolOptions & options_)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    FractionalMaxPool2dImpl(const FractionalMaxPool2dOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    FractionalMaxPool3dImpl(const FractionalMaxPool3dOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    LPPoolImpl(const LPPoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    MaxPoolImpl(const MaxPoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    MaxUnpoolImpl(const MaxUnpoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Pooling.cpp', [], ['    _mkldnn_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,ideep::algorithm algo)', '    mkldnn_adaptive_avg_pool2d(Tensor const & input,IntArrayRef output_size)', '    mkldnn_adaptive_avg_pool2d_out(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    mkldnn_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    mkldnn_avg_pool2d_out(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    mkldnn_max_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Pooling.cpp', [], ['    check1d(const char *function_name,const char *argument_name,IntArrayRef x)', '    adaptive_avg_pool1d(const Tensor & self,IntArrayRef output_size)', '    adaptive_max_pool1d(const Tensor & self,IntArrayRef output_size)', '    avg_pool1d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad)', '    max_pool1d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool1d_with_indices(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\pooling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\pooling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\pooling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Pow.cpp', [], ['    pow(const Tensor & base,const Tensor & exp)', '    pow(const Tensor & base,Scalar exp)', '    pow(Scalar base,const Tensor & exp)', '    pow_(Tensor & base,const Tensor & other)', '    pow_(Tensor & base,Scalar alpha)', '    pow_out(Tensor & result,const Tensor & base,const Tensor & exp)', '    pow_out(Tensor & result,const Tensor & base,Scalar exp)', '    pow_out(Tensor & result,Scalar base,const Tensor & exp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Pow.h', [], ['    operator=', '    pow_tensor_scalar_stub', '    pow_tensor_scalar_stub', '    operator=', '    pow_tensor_tensor_stub', '    pow_tensor_tensor_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pow_op.cc', ['    GetPowGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPow', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Pow', '    vector', '    vector', '    vector', '    vector', '    Run(size_t n,const T1 *a,const T2 *b,T2 e,R *out,CPUContext *)', '    RunWithBroadcast(const T1 *a,const T2 *b,R *out,size_t pre,size_t n,CPUContext *)', '    RunWithBroadcast2(const T1 *a,const T2 *b,R *out,size_t pre,size_t n,size_t post,CPUContext *)', '    CopyArguments', '    GetGradientDefs', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\pow_op.h', ['    PowOp'], ['    DoRunWithType', '    PowOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\pow_test.cpp', [], ['    assert_eq(T val,T act,T exp)', '    assert_eq(T val,T act,T exp)', '    doubles', '    floats', '    ints', '    longs', '    non_neg_ints', '    non_neg_longs', '    scalar_pow_tensor(const Vals vals,c10::ScalarType vals_dtype,const Pows pows,c10::ScalarType pows_dtype)', '    tensor_pow_scalar(const Vals vals,c10::ScalarType vals_dtype,const Pows pows,c10::ScalarType pows_dtype)', '    tensor_pow_tensor(const Vals vals,c10::ScalarType vals_dtype,Pows pows,c10::ScalarType pows_dtype)', '    TEST(PowTest,IntTensorPowAllScalars)', '    TEST(PowTest,DISABLED_LongTensorPowAllScalars)', '    TEST(PowTest,FloatTensorPowAllScalars)', '    TEST(PowTest,DoubleTensorPowAllScalars)', '    TEST(PowTest,IntScalarPowAllTensors)', '    TEST(PowTest,LongScalarPowAllTensors)', '    TEST(PowTest,FloatScalarPowAllTensors)', '    TEST(PowTest,DoubleScalarPowAllTensors)', '    TEST(PowTest,IntTensorPowIntTensor)', '    TEST(PowTest,LongTensorPowLongTensor)', '    TEST(PowTest,FloatTensorPowFloatTensor)', '    TEST(PowTest,DoubleTensorPowDoubleTensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\PowKernel.cpp', [], ['    pow_tensor_scalar_kernel(TensorIterator & iter,Scalar exp_scalar)', '    pow_tensor_tensor_kernel(TensorIterator & iter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-neon.c', [], ['    pytorch_qnnp_requantize_precise__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-psimd.c', [], ['    pytorch_qnnp_requantize_precise__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-psimd.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-scalar.c', [], ['    pytorch_qnnp_requantize_precise__scalar_signed64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned32(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-sse2.c', [], ['    pytorch_qnnp_requantize_precise__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-sse4.c', [], ['    pytorch_qnnp_requantize_precise__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-sse4.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\precise-ssse3.c', [], ['    pytorch_qnnp_requantize_precise__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\precise-ssse3.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor.cc', [], ['    enforceIsTensor(Workspace *ws,const std::string & name)', '    getBlob(Workspace *ws,const std::string & name)', '    getTensor(Workspace *ws,const std::string & name)', '    initialized', '    operator()(const TensorList & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorMap *outputs)', '    Predictor(PredictorConfig config)', '    Predictor(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)', '    run_map_workspace(const TensorMap & inputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\custom_build\\predictor.cpp', [], ['    loadModel(const std::string & path)', '    main(int argc,const char *[] argv)', '    output', '    no_autograd_guard', '    no_optimizer_guard', '    non_var_guard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor.h', ['    Predictor'], ['    def', '    input_names', '    operator()(const TensorList & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorMap *outputs)', '    output_names', '    Predictor(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)', '    Predictor(PredictorConfig config)', '    run_map_workspace(const TensorMap & inputs)', '    ws', '    ~Predictor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor_config.cc', [], ['    warningEmitted', '    getBlobs(const MetaNetDef & def,const std::string & name)', '    getNet(const MetaNetDef & def,const std::string & name)', '    makePredictorConfig(const MetaNetDef & def,Workspace *parent,bool run_init)', '    makePredictorConfig(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor_config.h', [], ['    makePredictorConfig(const MetaNetDef & net,Workspace *parent,bool run_init)', '    makePredictorConfig(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor_test.cc', ['    PredictorTest'], ['    parseMetaNetDef(const std::string & value)', '    parseNetDef(const std::string & value)', '    randomTensor(const std::vector & dims,CPUContext *ctx)', '    TEST_F(PredictorTest,SimpleBatchSized)', '    TEST_F(PredictorTest,SimpleBatchSizedMapInput)', '    SetUp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor_utils.cc', [], ['    extractMetaNetDef(db::Cursor *cursor,const std::string & key)', '    getNet(const MetaNetDef & def,const std::string & name)', '    runGlobalInitialization(std::unique_ptr db,Workspace *master)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\predictor_utils.h', [], ['    extractMetaNetDef(db::Cursor *cursor,const std::string & key)', '    getBlobs(const MetaNetDef & def,const std::string & name)', '    getNet(const MetaNetDef & def,const std::string & name)', '    runGlobalInitialization(std::unique_ptr db,Workspace *master)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\predictor_verifier.cc', ['    C10FlagParser_init_net', '    C10FlagParser_predict_net'], ['    run', '    main(int argc,char **argv)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_predict_net(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prefetch_op.h', ['    PrefetchOperator'], ['    CopyPrefetched', '    Finalize', '    Prefetch', '    PrefetchOperator(const OperatorDef & operator_def,Workspace *ws)', '    PrefetchWorker', '    Run(int)', '    ~PrefetchOperator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\PrefixStore.cpp', [], ['    add(const std::string & key,int64_t)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    joinKey(const std::string & key)', '    joinKeys(const std::vector & keys)', '    PrefixStore(const std::string & prefix,std::shared_ptr store)', '    set(const std::string & key,const std::vector & value)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\PrefixStore.hpp', ['    PrefixStore'], ['    add(const std::string & key,int64_t)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    joinKey(const std::string & key)', '    joinKeys(const std::vector & keys)', '    PrefixStore(const std::string & prefix,std::shared_ptr store)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~PrefixStore']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prelu_op.cc', ['    GetPReluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUPRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prelu_op.h', ['    final', '    final'], ['    PReluGradientOp(Args,...)', '    PReluOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\prepack_folding.cpp', [], ['    PrePackingOpsFolder(script::Module & m,const PrePackingOpsFilterFn & is_foldable_op,const std::string & attr_prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\prepack_folding.h', [], ['    PrePackingOpsFolder(script::Module & m,const PrePackingOpsFilterFn & is_foldable_op,const std::string & attr_prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\prepare_division_for_onnx.cpp', [], ['    PrepareDivisionForONNXOnBlock(Block *block)', '    PrepareDivisionForONNX(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\prepare_division_for_onnx.h', [], ['    PrepareDivisionForONNX(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\prepare_inplace_ops_for_onnx.cpp', [], ['    PrepareListAppendAndInsertForONNX(Block *b)', '    PrepareListPopForONNX(Block *b)', '    FetchSliceAndSelect(const Node *index_put_node)', '    IsSameSource(const Node *n,const Node *m)', '    MergeSliceAndSelectToIndices(Graph *graph,Node *index_put_node,const std::vector & slice_and_select_nodes,Value *orig_data)', '    PrepareCopyForONNX(Block *block)', '    PrepareIndexPutForONNX(Block *block)', '    PrepareInplaceOpsForONNX(const std::shared_ptr & graph)', '    ReshapeToAdvancedIndexingFormat(Graph *graph,Node *index_put_node,std::unordered_map & dim_index_map)', '    SquashSliceAndSelect(Node *index_put_node)', '    CreateCompleteIndexTensor(Value *size,Node *insertBefore)', '    ConvertSelectToIndex(Value *index,Node *insertBefore)', '    ConvertSliceToIndex(Node *slice,Value *size,Node *insertBefore)', '    CreateSizeOfDim(Value *input,int64_t dim,Node *insertBefore)', '    ConvertedIndex(Value *index,c10::Symbol orig_node_kind)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\prepare_inplace_ops_for_onnx.h', [], ['    PrepareInplaceOpsForONNX(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prepend_dim_op.cc', ['    GetPrependDimGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeDim', '    CAFFE_ANONYMOUS_VARIABLE_CPUPrependDim', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeDim', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PrependDim', '    vector', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prepend_dim_op.h', ['    MergeDimOp', '    PrependDimOp'], ['    MergeDimOp(Args,...)', '    RunOnDevice', '    GetSingleArgument', '    PrependDimOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\prepend_dim_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAMergeDim', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPrependDim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\print_core_object_sizes_gpu.cc', [], ['    main(int,char **)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\print_handler.cpp', [], ['    getPrintHandler', '    setPrintHandler(PrintHandler ph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\print_handler.h', [], ['    getPrintHandler', '    setPrintHandler(PrintHandler ph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\print_registered_core_operators.cc', ['    C10FlagParser_schema'], ['    HasDoc(const std::string & str)', '    HasSchema(const std::string & str)', '    main(int argc,char **argv)', '    C10FlagParser_schema(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\process_group_agent.cpp', [], ['    shouldUpdateMinEndTimePredicate', '    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    enqueueRecv(RecvWork work)', '    enqueueSend(SendWork work)', '    getMetrics', '    handleRecv(RecvWork & work)', '    handleSend(const SendWork & work)', '    hasPendingMessage', '    listenLoop', '    listenLoopInternal', '    markFutureWithError(Message & message)', '    markFutureWithError(int64_t id,std::string errorMsg)', '    pollTimedOutRPCs', '    processTimedOutFutures', '    send(const WorkerInfo & to,Message)', '    shutdown', '    start', '    sync', '    addData(uint64_t dataPoint)', '    AverageMetricsTracker(std::string key,uint64_t currentSum,uint64_t currentCount)', '    computeAverage', '    collectNames', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    join', '    increment(int dst)', '    MessageCounter(int worldSize)', '    snapshot', '    ProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout)', '    ~ProcessGroupAgent', '  Static Member Variables', '    kInfiniteTimeoutTimePoint']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\process_group_agent.h', ['    ProcessGroupAgent', '    MessageCounter'], ['    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    addData(uint64_t dataPoint)', '    AverageMetricsTracker(std::string key,uint64_t currentSum,uint64_t currentCount)', '    computeAverage', '    clientActiveCalls_', '    collectNames', '    enqueueRecv(RecvWork work)', '    enqueueSend(SendWork work)', '    FutureInfo(const std::shared_ptr & future,const steady_clock_time_point & endTime,int dstRank,const std::chrono::milliseconds timeout)', '    FutureInfo', '    getMetrics', '    getRPCRemainingTime(const std::chrono::milliseconds & rpcEndTime)', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    handleRecv(RecvWork & work)', '    handleSend(const SendWork & work)', '    hasPendingMessage', '    join', '    listenLoop', '    listenLoopInternal', '    markFutureWithError(Message & message)', '    markFutureWithError(int64_t id,std::string errorMsg)', '    increment(int dst)', '    MessageCounter(int worldSize)', '    snapshot', '    nextId', '    pollTimedOutRPCs', '    ProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout)', '    processTimedOutFutures', '    rpcRunning_', '    send(const WorkerInfo & to,Message)', '    serverActiveAsyncCalls_', '    serverActiveCalls_', '    shutdown', '    start', '    sync', '    ~ProcessGroupAgent', '    ProcessGroupRpcBackendOptions(int num_send_recv_threads,std::chrono::milliseconds rpc_timeout,std::string init_method)', '    RecvWork(const WorkerInfo & from,MessageType type,int64_t id,torch::Tensor)', '    SendWork(const WorkerInfo & to,Message)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroup.cpp', [], ['    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    ProcessGroup(int rank,int size)', '    abort', '    exception', '    finish(std::exception_ptr exception)', '    isCompleted', '    isSuccess', '    result', '    sourceRank', '    synchronize', '    wait', '    ~Work', '    ~ProcessGroup']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroup.hpp', ['    ProcessGroup', '    Work'], ['    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & data,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & data,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    getRank', '    getSize', '    ProcessGroup(int rank,int size)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    exception', '    finish(std::exception_ptr exception)', '    isCompleted', '    isSuccess', '    result', '    sourceRank', '    synchronize', '    wait', '    ~Work', '    ~ProcessGroup']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupGloo.cpp', ['    AsyncAllgatherCoalescedWork', '    AsyncAllgatherWork', '    AsyncAllreduceCoalescedWork', '    AsyncAllreduceWork', '    AsyncBarrierWork', '    AsyncBroadcastWork', '    AsyncGatherWork', '    AsyncReduceWork', '    AsyncScatterWork', '    AsyncSparseAllreduceWork', '    SparseTensorMetadata', '    GlooStore'], ['    band(void *c,const void *a,const void *b,size_t n)', '    bor(void *c,const void *a,const void *b,size_t n)', '    bxor(void *c,const void *a,const void *b,size_t n)', '    override', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    checkSingleTensor(std::vector & tensors)', '    checkTag(int32_t tag)', '    doesHostnameResolveToUsableAddress(const std::string & hostname)', '    setInput(O & opts,at::Tensor & tensor)', '    setInputs(O & opts,std::vector & tensors)', '    setOutput(O & opts,at::Tensor & tensor)', '    setOutput(O & opts,at::Tensor & tensor,std::vector & counts)', '    setOutputs(O & opts,std::vector & tensors)', '    toFunction(const ReduceOp & r)', '    allgather_coalesced', '    AsyncAllgatherCoalescedWork(const std::shared_ptr & context,std::vector,std::vector & input_list,uint32_t tag)', '    run', '    allgather(std::vector,std::vector & inputs)', '    AsyncAllgatherWork(const std::shared_ptr & context,std::vector,std::vector & inputs,uint32_t tag)', '    run', '    allreduceCoalesced(std::vector & tensors)', '    AsyncAllreduceCoalescedWork(const std::shared_ptr & context,std::vector & inputs,ReduceOp reduceOp,uint32_t tag)', '    run', '    allreduce(std::vector & tensors)', '    AsyncAllreduceWork(const std::shared_ptr & context,std::vector & inputs,ReduceOp reduceOp,uint32_t tag)', '    getFunction(gloo::AllreduceOptions::Func & fn,const ReduceOp op)', '    getFunction(const at::ScalarType & dtype,const ReduceOp op)', '    run', '    AsyncBarrierWork(const std::shared_ptr & context,std::vector,uint32_t tag)', '    run', '    AsyncBroadcastWork(const std::shared_ptr & context,std::vector & inputs,int rootRank,int rootTensor,uint32_t tag)', '    broadcast(at::Tensor & tensor)', '    run', '    AsyncGatherWork(const std::shared_ptr & context,std::vector,std::vector & inputs,int root,uint32_t tag)', '    gather(std::vector,std::vector & inputs)', '    run', '    AsyncReduceWork(const std::shared_ptr & context,std::vector & inputs,int rootRank,int rootTensor,ReduceOp reduceOp,uint32_t tag)', '    getFunction(gloo::ReduceOptions::Func & fn,const ReduceOp op)', '    getFunction(const at::ScalarType & dtype,const ReduceOp op)', '    reduce(std::vector & tensors)', '    run', '    AsyncScatterWork(const std::shared_ptr & context,std::vector & outputs,std::vector,int root,uint32_t tag)', '    run', '    scatter(std::vector & outputs,std::vector)', '    allgather_indices(const at::Tensor & tensor,const std::vector & metadata)', '    allgather_metadata(const at::Tensor & tensor)', '    allgather_values(const at::Tensor & tensor,const std::vector & metadata)', '    allreduce(std::vector & tensors)', '    AsyncSparseAllreduceWork(const std::shared_ptr & context,std::vector & inputs,uint32_t tag)', '    result', '    run', '    nnz', '    populate_from_sparse_tensor(const at::Tensor & tensor)', '    sizes', '    SparseTensorMetadata(at::Tensor metadata)', '    GlooStore(const std::shared_ptr & store)', '    Options', '    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector & input_list,const AllgatherOptions &)', '    allreduce(std::vector & inputs,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & inputs,const BroadcastOptions & opts)', '    enqueue(std::shared_ptr work)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    getContext(uint32_t tag)', '    nextTag', '    ProcessGroupGloo(const std::shared_ptr & store,int rank,int size,Options options)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & inputs,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    runLoop(int workerIndex)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupGloo', '    abort', '    RecvWork(at::Tensor & tensor,std::unique_ptr buffer)', '    sourceRank', '    wait', '    abort', '    SendWork(at::Tensor & tensor,std::unique_ptr buffer)', '    wait']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupGloo.hpp', ['    ProcessGroupGloo', '    AsyncWork', '    RecvWork', '    SendWork'], ['    execute(std::shared_ptr work)', '    createDefaultDevice', '    createDeviceForHostname(const std::string & hostname)', '    createDeviceForInterface(const std::string & interface)', '    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & input_list,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    run', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    enqueue(std::shared_ptr work)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    getContext(uint32_t tag)', '    nextTag', '    Options', '    ProcessGroupGloo(const std::shared_ptr & store,int rank,int size,Options options)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    abort', '    RecvWork(at::Tensor & tensor,std::unique_ptr buffer)', '    sourceRank', '    wait', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    runLoop(int workerIndex)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    SendWork(at::Tensor & tensor,std::unique_ptr buffer)', '    wait', '    ~ProcessGroupGloo']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\ProcessGroupGlooAsyncTest.cpp', ['    AsyncAllreduceTest', '    AsyncBroadcastTest', '    AsyncInputIsOutputTest', '    AsyncTest'], ['    initialize(const std::string & path,int N,Args,...)', '    main(int argc,char **argv)', '    runAsyncAllreduceTest(const std::string & path,size_t numProcesses,size_t numTensors)', '    runAsyncBroadcastTest(const std::string & path,size_t numProcesses,size_t numTensors)', '    AsyncAllreduceTest(const std::string & path,int numTensors)', '    run', '    AsyncBroadcastTest(const std::string & path,int numTensors)', '    run(int rootRank,int rootTensor)', '    AsyncInputIsOutputTest(const std::string & path,int numTensors)', '    getTensors', '    wait(std::shared_ptr & work)', '    AsyncTest(const std::string & path)', '    AsyncTest(AsyncTest)', '    getProcessGroup', '    start(int rank,int size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\ProcessGroupGlooTest.cpp', ['    CollectiveTest', '    SignalTest'], ['    TEST(ProcessGroupGlooTest,testSIGSTOPException)', '    TEST(ProcessGroupGlooTest,testSIGKILLException)', '    TEST(ProcessGroupGlooTest,testAllReduceCPU)', '    TEST(ProcessGroupGlooTest,testBroadcastCPU)', '    TEST(ProcessGroupGlooTest,testBarrier)', '    TEST(ProcessGroupGlooTest,testSend)', '    TEST(ProcessGroupGlooTest,testRecv)', '    testAllreduce(const std::string & path,const at::DeviceType b)', '    testBarrier(const std::string & path)', '    testBroadcast(const std::string & path,const at::DeviceType b)', '    testRecv(const std::string & path)', '    testSend(const std::string & path)', '    testSignal(const std::string & path,int signal)', '    initialize(const std::string & path,int num)', '    CollectiveTest(const std::string & path)', '    CollectiveTest(CollectiveTest)', '    getProcessGroup', '    start(int rank,int size)', '    arm(int pid,int signal)', '    run(int rank,int size)', '    SignalTest(const std::string & path)', '    ~SignalTest']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupMPI.cpp', [], ['    checkSameSizeAndType(const at::Tensor & tensor,const std::vector & tensors)', '    checkSingleTensor(const std::vector & tensors)', '    checkSingleTensorHelper(const at::Tensor & tensor)', '    cudaAwareMpiCheck', '    initMPIOnce', '    mpiExit', '    abort', '    AsyncWork(at::Tensor tensor,MPI_Request request)', '    isCompleted', '    isSuccess', '    populateException', '    sourceRank', '    wait', '    ~AsyncWork', '    abort', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    createProcessGroupMPI(std::vector ranks)', '    destroy', '    enqueue(std::unique_ptr entry)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    ProcessGroupMPI(int rank,int size,MPI_Comm pgComm)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    runLoop', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupMPI', '  Static Member Variables', '    mpiThreadSupport_', '    onceFlagInitMPI', '    pgGlobalMutex_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupMPI.hpp', ['    ProcessGroupMPI', '    AsyncWork', '    WorkMPI'], ['    createProcessGroupMPI(std::vector ranks)', '    initMPIOnce', '    mpiExit', '    abort', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputbuffer,at::Tensor & inputbuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    abort', '    AsyncWork(at::Tensor tensor,MPI_Request request)', '    isCompleted', '    isSuccess', '    populateException', '    sourceRank', '    wait', '    ~AsyncWork', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & data,const BroadcastOptions & opts)', '    destroy', '    enqueue(std::unique_ptr entry)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    ProcessGroupMPI(int rank,int size,MPI_Comm pgComm)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensor,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    runLoop', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupMPI', '    operator=', '    WorkEntry(std::vector *srcPtr,std::vector *dstPtr,std::function run)', '    WorkEntry']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\ProcessGroupMPITest.cpp', [], ['    main(int argc,char **argv)', '    testAllgather(int iter)', '    testAllreduce(int iter)', '    testBroadcast(int iter)', '    testGather(int iter)', '    testReduce(int iter)', '    testScatter(int iter)', '    testSendRecv(bool recvAnysource,int iter)', '    waitWork(std::shared_ptr pg,std::vector)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupNCCL.cpp', [], ['    buildNcclUniqueIdStr(const ncclUniqueId & ncclID)', '    getDeviceList(const std::vector & tensors)', '    getKeyFromDevices(const std::vector & devices)', '    getNcclAbortedCommStoreKey(const std::string ncclIdStr)', '    getNcclDataType(at::ScalarType type)', '    syncStreams(const std::vector & devices,std::vector & ncclEvents,std::vector & ncclStreams)', '    check_gpu_tensors(const std::vector & tensors)', '    flatten_for_scatter_gather(std::vector,std::vector & other,size_t world_size)', '    i', '    AutoNcclGroup', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    broadcastUniqueNCCLID(ncclUniqueId *ncclID)', '    checkForNCCLErrors(const std::vector)', '    checkForNCCLErrorsInternal(const std::vector)', '    collective(std::vector & inputs,std::vector & outputs,Fn fn,PreProcess pre,PostProcess post)', '    collective(std::vector & inputs,std::vector & outputs,Fn fn)', '    gather(std::vector,std::vector &,const GatherOptions &)', '    initWork(std::vector devices)', '    ncclCommWatchdog', '    ncclCommWatchdogInternal', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::chrono::milliseconds & opTimeout)', '    recv(std::vector &,int,int)', '    recvAnysource(std::vector &,int)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector &,std::vector,const ScatterOptions &)', '    send(std::vector &,int,int)', '    abort', '    checkAndSetException', '    checkAndThrowException', '    checkForNCCLErrors(const std::vector)', '    finishedGPUExecution', '    finishedGPUExecutionInternal', '    isCompleted', '    isSuccess', '    synchronize', '    wait', '    WorkNCCL(const std::vector & devices)', '    ~WorkNCCL', '    ~ProcessGroupNCCL']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupNCCL.hpp', ['    ProcessGroupNCCL', '    WorkNCCL'], ['    checkForNCCLErrorsInternal(const std::vector)', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputbuffer,at::Tensor & inputbuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    broadcastUniqueNCCLID(ncclUniqueId *ncclID)', '    checkForNCCLErrors(const std::vector)', '    collective(std::vector & input,std::vector & output,Fn fn)', '    collective(std::vector & input,std::vector & output,Fn fn,PreProcess pre,PostProcess post)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    initWork(std::vector devices)', '    ncclCommCounter_', '    ncclCommWatchdog', '    ncclCommWatchdogInternal', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::chrono::milliseconds & opTimeout)', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::string & groupName,const std::chrono::milliseconds & opTimeout)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    checkAndSetException', '    checkAndThrowException', '    checkForNCCLErrors(const std::vector)', '    finishedGPUExecution', '    finishedGPUExecutionInternal', '    isCompleted', '    isSuccess', '    synchronize', '    wait', '    WorkNCCL(const std::vector & devices)', '    ~WorkNCCL', '    ~ProcessGroupNCCL']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\ProcessGroupNCCLErrorsTest.cpp', ['    ProcessGroupNCCLErrorsTest', '    ProcessGroupNCCLSimulateErrors', '    ProcessGroupNCCLTimedOutErrors', '    WorkNCCLSimulateErrors', '    WorkNCCLTimedoutErrors'], ['    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLErrorsBlocking)', '    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLTimedoutErrorsBlocking)', '    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLErrorsNonBlocking)', '    SetUp', '    skipTest', '    TearDown', '    checkForNCCLErrors(const std::vector)', '    getNCCLCommCacheSize', '    getWatchdogSleepInterval', '    initWork(std::vector devices)', '    ProcessGroupNCCLSimulateErrors(const std::shared_ptr & store,int rank,int size,std::chrono::milliseconds timeout)', '    reset_error', '    simulate_error', '    initWork(std::vector devices)', '    ProcessGroupNCCLTimedOutErrors(const std::shared_ptr & store,int rank,int size,std::chrono::milliseconds timeout)', '    reset_timedout_error', '    set_timedout_error', '    checkForNCCLErrors(const std::vector)', '    WorkNCCLSimulateErrors(const std::vector & devices,bool simulate_error)', '    isCompleted', '    WorkNCCLTimedoutErrors(const std::vector & devices,bool set_timedout_error)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\ProcessGroupNCCLTest.cpp', ['    AllgatherNCCLTest', '    AllreduceNCCLTest', '    BroadcastNCCLTest', '    NCCLTest', '    NCCLTestBase', '    ReduceNCCLTest'], ['    main(int argc,char **argv)', '    numDevices', '    testAllgather(const std::string & path,int rank,int size)', '    testAllreduce(const std::string & path,int rank,int size)', '    testBroadcast(const std::string & path,int rank,int size)', '    testReduce(const std::string & path,int rank,int size)', '    testReduceScatter(const std::string & path,int rank,int size)', '    AllgatherNCCLTest(const std::string & path,int worldSize)', '    run', '    AllreduceNCCLTest(const std::string & path,int worldSize)', '    run', '    BroadcastNCCLTest(const std::string & path,int worldSize)', '    run(int rootRank,int rootTensor)', '    getTensors', '    NCCLTest(const std::string & path,int worldSize)', '    wait(std::shared_ptr & work)', '    getProcessGroup', '    initialize(int rank,int size)', '    NCCLTestBase(const std::string & path)', '    NCCLTestBase(NCCLTestBase)', '    ReduceNCCLTest(const std::string & path,int worldSize)', '    run(int rootRank,int rootTensor)', '    ReduceScatterNCCLTest(const std::string & path,int worldSize)', '    run']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupRoundRobin.cpp', [], ['    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions &)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    next', '    ProcessGroupRoundRobin(int rank,int size,std::vector)', '    recv(std::vector &,int,int)', '    recvAnysource(std::vector &,int)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector &,int,int)', '    ~ProcessGroupRoundRobin']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\ProcessGroupRoundRobin.hpp', ['    final'], ['    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    next', '    ProcessGroupRoundRobin(int rank,int size,std::vector)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupRoundRobin']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\prof_dag_counters.cc', [], ['    AddPerOpAsyncEndTime(size_t op_id)', '    AddPerOpEndTime(size_t op_id)', '    AddPerOpStartTime(size_t op_id)', '    GetReport', '    ProfDAGCounters(const std::shared_ptr & net_def)', '    ReportRunEnd', '    ReportRunStart', '    GetOperatorStats', '    GetPerOperatorCost', '    hasStats', '    operator+=(const ProfDAGReport & rhs)', '    PrintStats', '    statsProto(const std::string & name,const ProfDAGStats & stats,const std::vector & op_extra_info)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\prof_dag_counters.h', ['    ProfDAGCounters', '    ProfDAGReport', '    ProfDAGStats'], ['    AddPerOpAsyncEndTime(size_t op_id)', '    AddPerOpEndTime(size_t op_id)', '    AddPerOpStartTime(size_t op_id)', '    GetReport', '    ProfDAGCounters(const std::shared_ptr & net_def)', '    ReportRunEnd', '    ReportRunStart', '    GetOperatorStats', '    GetPerOperatorCost', '    hasStats', '    operator+=(const ProfDAGReport & rhs)', '    PrintStats', '    statsProto(const std::string & name,const ProfDAGStats & stats,const std::vector & op_extra_info)', '    cnt', '    computeMoments', '    operator+=(const ProfDAGStats & rhs)', '    ProfDAGStats', '    ProfDAGStats(float time_ms)', '    sqrsum', '    sum']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\prof\\prof_dag_stats_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGetProfDagStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetProfDagStats']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\prof\\prof_dag_stats_op.h', ['    final'], ['    GetProfDagStatsOp(const OperatorDef & operator_def,Workspace *ws)', '    getProtos(AsyncNetBase *net)', '    RunOnDevice', '    ~GetProfDagStatsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\profile_observer.cc', [], ['    Dump', '    Start', '    Stop']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\profile_observer.h', ['    final', '    final', '    ProfileCounter'], ['    Dump', '    getId', '    ProfileObserver(NetBase *subject)', '    ProfileOperatorObserver', '    ProfileOperatorObserver(OperatorBase *subject,ProfileObserver *netObserver)', '    ProfileOperatorObserver(OperatorBase *subject,ProfileObserver *netObserver,int net_position,int rnn_order)', '    Start', '    Stop', '    ProfileCounter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\profiler.cpp', [], ['    cuda_elapsed_us(const Event & e)', '    record(bool record_cuda)', '    disableProfiler', '    enableProfiler(ProfilerConfig config)', '    getEventList', '    mark(std::string name,bool include_cuda)', '    popRange', '    profilerEnabled', '    pushRange(const StringView & name,const char *msg,int64_t sequence_nr,std::vector)', '    registerCUDAMethods(CUDAStubs *stubs)', '    init', '    processEvents(const std::vector & events)', '    RecordProfile(std::ostream & out)', '    RecordProfile(const std::string & filename)', '    ~RecordProfile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\profiler.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\profiler.h', ['    Profiler'], ['    profile(std::function runnable)', '    ~Profiler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\profiler_cuda.cpp', [], ['    cudaCheck(cudaError_t result,const char *file,int line)', '    elapsed(CUDAEventStub event,CUDAEventStub event2)', '    enabled', '    nvtxMarkA(const char *name)', '    nvtxRangePop', '    nvtxRangePushA(const char *name)', '    onEachDevice(std::function op)', '    record(int *device,CUDAEventStub *event,int64_t *cpu_ns)', '    synchronize', '    RegisterCUDAMethods']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\profiling_graph_executor_impl.cpp', [], ['    bailout_depth', '    executor_mode', '    needsGradientInProfilingMode(Block *b)', '    num_profiled_runs', '    profiling_mode', '    getBailoutDepth', '    getExecutorMode', '    getNumProfiledRuns', '    getProfilingMode', '    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    ProfilingGraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    runProfilingInsensitiveOptimizations(std::shared_ptr & copy)', '    runProfilingOptimizations(std::shared_ptr & copy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\profiling_graph_executor_impl.h', [], ['    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    ProfilingGraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    runProfilingInsensitiveOptimizations(std::shared_ptr & copy)', '    runProfilingOptimizations(std::shared_ptr & copy)', '    ~ProfilingGraphExecutorImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\profiling_record.cpp', [], ['    unprofileBlock(Block *start_block)', '    unprofileGraphInputs(const std::shared_ptr & graph)', '    instrumentGraph(const std::shared_ptr & graph)', '    createProfileNode(const std::function & fp,at::ArrayRef inputs)', '    insertShapeProfile(Node *n,Value *i)', '    instrumentBlock(Block *block)', '    ProfilingRecord(std::shared_ptr g)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\profiling_record.h', [], ['    instrumentGraph(const std::shared_ptr & graph)', '    createProfileNode(const std::function & fp,at::ArrayRef inputs)', '    graph', '    insertShapeProfile(Node *n,Value *i)', '    instrumentBlock(Block *block)', '    ProfilingRecord', '    ProfilingRecord(std::shared_ptr g)', '    ProfilingRecord', '    ready']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\propagate_gradients_req.cpp', [], ['    fromMessage(const Message & message)', '    getAutogradMetadata', '    getGrads', '    PropagateGradientsReq(const AutogradMetadata & autogradMetadata,std::vector grads,bool retainGraph)', '    retainGraph', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\propagate_gradients_req.h', ['    PropagateGradientsReq'], ['    fromMessage(const rpc::Message & message)', '    getAutogradMetadata', '    getGrads', '    PropagateGradientsReq(const AutogradMetadata & autogradMetadata,std::vector grads,bool retainGraph)', '    retainGraph', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\propagate_gradients_resp.cpp', [], ['    fromMessage(const rpc::Message & message)', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\propagate_gradients_resp.h', ['    PropagateGradientsResp'], ['    fromMessage(const rpc::Message & message)', '    PropagateGradientsResp', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_convert.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_convert.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_utils.cc', [], ['    cpu_types', '    gpu_types', '    ArgumentHelper(const OperatorDef & def)', '    ArgumentHelper(const NetDef & netdef)', '    cleanupExternalInputsAndOutputs(NetDef *net)', '    DeviceId(const DeviceOption & option)', '    DeviceTypeName(const int32_t & d)', '    GetArgument(const OperatorDef & def,const string & name)', '    GetArgument(const NetDef & def,const string & name)', '    GetArgumentIndex(const google::protobuf::RepeatedPtrField & args,const string & name)', '    GetFlagArgument(const google::protobuf::RepeatedPtrField & args,const string & name,bool default_value)', '    GetFlagArgument(const OperatorDef & def,const string & name,bool default_value)', '    GetFlagArgument(const NetDef & def,const string & name,bool default_value)', '    GetMutableArgument(const string & name,const bool create_if_missing,OperatorDef *def)', '    GetMutableArgument(const string & name,const bool create_if_missing,NetDef *def)', '    GetMutableArgumentImpl(const string & name,const bool create_if_missing,Def *def)', '    HasInput(const OperatorDef & op,const std::string & input)', '    HasOutput(const OperatorDef & op,const std::string & output)', '    IsCPUDeviceType(int device_type)', '    IsGPUDeviceType(int device_type)', '    IsSameDevice(const DeviceOption & lhs,const DeviceOption & rhs)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const bool & value)', '    MakeArgument(const string & name,const float & value)', '    MakeArgument(const string & name,const int & value)', '    MakeArgument(const string & name,const int64_t & value)', '    MakeArgument(const string & name,const string & value)', '    MakeArgument(const string & name,const MessageLite & value)', '    operator<<(std::ostream & output,const TensorProto & n)', '    operator<<(std::ostream & output,const QTensorProto & n)', '    operator<<(std::ostream & output,const NetDef & n)', '    operator==(const TensorProto & l,const TensorProto & r)', '    operator==(const QTensorProto & l,const QTensorProto & r)', '    operator==(const NetDef & l,const NetDef & r)', '    ParseProtoFromLargeString(const string & str,Message *proto)', '    ProtoDebugString(const Message & proto)', '    ReadProtoFromBinaryFile(const char *filename,MessageLite *proto)', '    ReadProtoFromTextFile(const char *filename,Message *proto)', '    ReadStringFromFile(const char *filename,string *str)', '    SupportsLosslessConversion(const InputType & value)', '    ParseFromString(const string & spec,Message *proto)', '    WriteProtoToBinaryFile(const MessageLite & proto,const char *filename)', '    WriteProtoToTextFile(const Message & proto,const char *filename)', '    WriteStringToFile(const string & str,const char *filename)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    HasArgument(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_utils.h', [], ['    DeviceId(const DeviceOption & option)', '    DeviceTypeName(const int32_t & d)', '    IsCPUDeviceType(int device_type)', '    IsGPUDeviceType(int device_type)', '    IsSameDevice(const DeviceOption & lhs,const DeviceOption & rhs)', '    ParseProtoFromLargeString(const string & str,Message *proto)', '    ProtoDebugString(const Message & proto)', '    ReadProtoFromBinaryFile(const char *filename,MessageLite *proto)', '    ReadProtoFromBinaryFile(const string filename,MessageLite *proto)', '    ReadProtoFromFile(const char *filename,Message *proto)', '    ReadProtoFromFile(const string & filename,Message *proto)', '    ReadProtoFromTextFile(const char *filename,Message *proto)', '    ReadProtoFromTextFile(const string filename,Message *proto)', '    ReadStringFromFile(const char *filename,string *str)', '    ParseFromString(const string & spec,Message *proto)', '    WriteProtoToBinaryFile(const MessageLite & proto,const char *filename)', '    WriteProtoToBinaryFile(const MessageLite & proto,const string & filename)', '    WriteProtoToTextFile(const Message & proto,const char *filename)', '    WriteProtoToTextFile(const Message & proto,const string & filename)', '    WriteStringToFile(const string & str,const char *filename)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_utils_test.cc', [], ['    TEST(ProtoUtilsTest,IsSameDevice)', '    TEST(ProtoUtilsTest,SimpleReadWrite)', '    TEST(ProtoUtilsTest,CleanupExternalInputsAndOutputs)', '    expectedExternalInputs', '    expectedexternalOutputs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_wrap.cc', [], ['    GetEmptyStringAlreadyInited', '    ShutdownProtobufLibrary', '    GetEmptyStringAlreadyInited', '    GetEmptyStringAlreadyInited', '    ShutdownProtobufLibrary']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\proto_wrap.h', [], ['    ShutdownProtobufLibrary']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\db\\protodb.cc', ['    ProtoDB', '    ProtoDBCursor', '    ProtoDBTransaction'], ['    Close', '    NewCursor', '    NewTransaction', '    ProtoDB(const string & source,Mode mode)', '    ~ProtoDB', '    key', '    Next', '    ProtoDBCursor(const TensorProtos *proto)', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    ~ProtoDBCursor', '    Commit', '    ProtoDBTransaction(TensorProtos *proto)', '    Put(const string & key,const string & value)', '    ~ProtoDBTransaction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\ps_roi_pool_op.cc', ['    GetPSRoIPoolGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPSRoIPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUPSRoIPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PSRoIPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PSRoIPoolGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\ps_roi_pool_op.h', ['    final', '    final'], ['    GetSingleArgument', '    PSRoIPoolGradientOp(const OperatorDef & def,Workspace *ws)', '    PSRoIPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\pthreadpool.cc', [], ['    compute_1d_tiled(void *context_,size_t linear_index)', '    compute_2d(void *context_,size_t linear_index)', '    compute_2d_tiled(void *context_,size_t linear_index)', '    compute_3d_tiled(void *context_,size_t linear_index)', '    compute_4d_tiled(void *context_,size_t linear_index)', '    divide_round_up(size_t dividend,size_t divisor)', '    min(size_t a,size_t b)', '    pthreadpool_compute_1d_tiled(pthreadpool_t threadpool,pthreadpool_function_1d_tiled_t function,void *argument,size_t range,size_t tile)', '    pthreadpool_compute_2d(struct pthreadpool *threadpool,pthreadpool_function_2d_t function,void *argument,size_t range_i,size_t range_j)', '    pthreadpool_compute_2d_tiled(pthreadpool_t threadpool,pthreadpool_function_2d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j)', '    pthreadpool_compute_3d_tiled(pthreadpool_t threadpool,pthreadpool_function_3d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_i,size_t tile_j,size_t tile_k)', '    pthreadpool_compute_4d_tiled(pthreadpool_t threadpool,pthreadpool_function_4d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_i,size_t tile_j,size_t tile_k,size_t tile_l)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\pthreadpool.h', [], ['    pthreadpool_compute_1d(pthreadpool_t threadpool,pthreadpool_function_1d_t function,void *argument,size_t range)', '    pthreadpool_compute_1d_tiled(pthreadpool_t threadpool,pthreadpool_function_1d_tiled_t function,void *argument,size_t range,size_t tile)', '    pthreadpool_compute_2d(struct pthreadpool *threadpool,pthreadpool_function_2d_t function,void *argument,size_t range_i,size_t range_j)', '    pthreadpool_compute_2d_tiled(pthreadpool_t threadpool,pthreadpool_function_2d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j)', '    pthreadpool_compute_3d_tiled(pthreadpool_t threadpool,pthreadpool_function_3d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_i,size_t tile_j,size_t tile_k)', '    pthreadpool_compute_4d_tiled(pthreadpool_t threadpool,pthreadpool_function_4d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_i,size_t tile_j,size_t tile_k,size_t tile_l)', '    pthreadpool_create(size_t threads_count)', '    pthreadpool_create_xnnpack(size_t threads_count)', '    pthreadpool_destroy(pthreadpool_t pthreadpool)', '    pthreadpool_destroy_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_get_threads_count(pthreadpool_t threadpool)', '    pthreadpool_get_threads_count_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_parallelize_1d(struct pthreadpool *threadpool,pthreadpool_task_1d_t task,void *argument,size_t range,uint32_t flags)', '    pthreadpool_parallelize_1d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_1d_tile_1d_t task,void *argument,size_t range,size_t tile,uint32_t flags)', '    pthreadpool_parallelize_2d(struct pthreadpool *threadpool,pthreadpool_task_2d_t task,void *argument,size_t range_i,size_t range_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_1d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_3d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_3d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_j,size_t tile_k,uint32_t flags)', '    pthreadpool_parallelize_4d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_4d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_k,size_t tile_l,uint32_t flags)', '    pthreadpool_parallelize_5d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_5d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t tile_l,size_t tile_m,uint32_t flags)', '    pthreadpool_parallelize_6d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_6d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t range_n,size_t tile_m,size_t tile_n,uint32_t flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\pthreadpool_impl.cc', [], ['    pthreadpool_compute_1d(pthreadpool_t threadpool,pthreadpool_function_1d_t function,void *argument,size_t range)', '    pthreadpool_create(size_t threads_count)', '    pthreadpool_destroy(pthreadpool_t pthreadpool)', '    pthreadpool_get_threads_count(pthreadpool_t threadpool)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\pthreadpool_new_if_impl.c', [], ['    atomic_decrement(atomic_size_t *value)', '    checkin_worker_thread(struct pthreadpool *threadpool)', '    compute_1d_tile_1d(const struct compute_1d_tile_1d_context *context,size_t linear_index)', '    compute_2d(const struct compute_2d_context *context,size_t linear_index)', '    compute_2d_tile_1d(const struct compute_2d_tile_1d_context *context,size_t linear_index)', '    compute_2d_tile_2d(const struct compute_2d_tile_2d_context *context,size_t linear_index)', '    compute_3d_tile_2d(const struct compute_3d_tile_2d_context *context,size_t linear_index)', '    compute_4d_tile_2d(const struct compute_4d_tile_2d_context *context,size_t linear_index)', '    compute_5d_tile_2d(const struct compute_5d_tile_2d_context *context,size_t linear_index)', '    compute_6d_tile_2d(const struct compute_6d_tile_2d_context *context,size_t linear_index)', '    divide_round_up(size_t dividend,size_t divisor)', '    min(size_t a,size_t b)', '    modulo_decrement(uint32_t i,uint32_t n)', '    multiply_divide(size_t a,size_t b,size_t d)', '    pthreadpool_allocate(size_t threads_count)', '    thread_main(void *arg)', '    thread_parallelize_1d(struct pthreadpool *threadpool,struct thread_info *thread)', '    wait_for_new_command(struct pthreadpool *threadpool,uint32_t last_command)', '    wait_worker_threads(struct pthreadpool *threadpool)', '    __aligned__', '    __aligned__', '    pthreadpool_create_xnnpack(size_t threads_count)', '    pthreadpool_destroy_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_get_threads_count_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_parallelize_1d(struct pthreadpool *threadpool,pthreadpool_task_1d_t task,void *argument,size_t range,uint32_t flags)', '    pthreadpool_parallelize_1d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_1d_tile_1d_t task,void *argument,size_t range,size_t tile,uint32_t flags)', '    pthreadpool_parallelize_2d(struct pthreadpool *threadpool,pthreadpool_task_2d_t task,void *argument,size_t range_i,size_t range_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_1d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_3d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_3d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_j,size_t tile_k,uint32_t flags)', '    pthreadpool_parallelize_4d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_4d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_k,size_t tile_l,uint32_t flags)', '    pthreadpool_parallelize_5d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_5d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t tile_l,size_t tile_m,uint32_t flags)', '    pthreadpool_parallelize_6d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_6d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t range_n,size_t tile_m,size_t tile_n,uint32_t flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\pthreadpool_utils_new_if.h', [], ['    disable_fpu_denormals', '    get_fpu_state', '    set_fpu_state(const struct fpu_state state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\PtrWrapper.cpp', [], ['    THPWrapper_dealloc(THPWrapper *self)', '    THPWrapper_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPWrapper_check(PyObject *obj)', '    THPWrapper_get(PyObject *obj)', '    THPWrapper_init(PyObject *module)', '    THPWrapper_New(void *data,void (*) (void *) destructor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\PtrWrapper.h', [], ['    THPWrapper_check(PyObject *obj)', '    THPWrapper_get(PyObject *obj)', '    THPWrapper_init(PyObject *module)', '    THPWrapper_New(void *data,void (*) (void *) destructor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\PTThreadPool.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\py_export.cc', [], ['    PYBIND11_MODULE(python,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\py_export.cc', [], ['    PYBIND11_MODULE(python,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\py_rref.cpp', [], ['    fromPyTuple(const py::tuple & pyTuple)', '    toPyTuple(const RRefForkData & rrefForkData)', '    tryInferTypeWithTypeHint(const py::object & value,const py::object & type_hint)', '    unpickle(const py::tuple & pyTuple)', '    confirmedByOwner', '    isOwner', '    localValue', '    owner', '    ownerName', '    pickle', '    PyRRef(const py::object & value,const py::object & type_hint)', '    PyRRef(c10::intrusive_ptr rref)', '    str', '    toHere', '    toIValue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\py_rref.h', ['    PyRRef'], ['    unpickle(const py::tuple & pyTuple)', '    confirmedByOwner', '    isOwner', '    localValue', '    owner', '    ownerName', '    pickle', '    PyRRef(const py::object & value,const py::object & type_hint)', '    PyRRef(c10::intrusive_ptr rref)', '    str', '    toHere', '    toIValue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\pybind.cc', [], ['    PYBIND11_MODULE(dnnlowp_pybind11,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\pybind.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\pybind.h', [], ['    cast(const std::vector & src,return_value_policy,handle parent)', '    cast(const std::vector *src,return_value_policy pol,handle parent)', '    tuple_tail(const py::tuple & tup)', '    cast(torch::jit::IValue src,return_value_policy,handle)', '    cast(torch::jit::Symbol src,return_value_policy,handle)', '    cast(torch::jit::AttributeKind src,return_value_policy,handle)', '    load(handle src,bool)', '    load(handle src,bool)', '    load(handle src,bool)', '    PYBIND11_TYPE_CASTER(torch::jit::IValue,_)', '    PYBIND11_TYPE_CASTER(torch::jit::Symbol,_)', '    PYBIND11_TYPE_CASTER(torch::jit::AttributeKind,_)', '    fromQualString', '    toTypeInferredIValue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\pybind.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state.cc', ['    BackgroundPlan', '    GetPythonGradient', '    StringFetcher'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPython', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonGradient', '    addGlobalMethods(py::module & m)', '    addObjectMethods(py::module & m)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Python', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonDLPack', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonDLPackGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonGradient', '    CaffeToNumpyType(const TypeMeta & meta)', '    DefinitionGetter(const Registry *registry)', '    GetCurrentWorkspace', '    NumpyTypeToCaffe(int numpy_type)', '    deserializeBlob(const string & content)', '    feedBlob(Blob *blob,const py::object & arg,const py::object device_option)', '    fetchBlob(Workspace *ws,const std::string & name)', '    getGradientFunc(const std::string & token)', '    getOpFunc(const std::string & token)', '    gRegistry', '    RegistryName', '    RegistryName', '    switchWorkspaceInternal(const std::string & name,bool create_if_missing)', '    gRegistry', '    gRegistry', '    initialize', '    arg', '    PYBIND11_MODULE(caffe2_pybind11_state,m)', '    tensors_data', '    value_infos', '    vi', '    weight_names_overwrite', '    BackgroundPlan(Workspace *ws,PlanDef def)', '    isDone', '    isSucceeded', '    run', '    ~BlobFeederBase', '    ~BlobFetcherBase', '    GetGradientDefs', '    Fetch(const Blob & blob)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state.h', ['    BlobFeederBase', '    BlobFetcherBase', '    PythonOpBase', '    TensorFeeder', '    TensorFetcher', '    PythonGradientOp', '    PythonOp'], ['    CaffeToNumpyType(const TypeMeta & meta)', '    CreateFeeder(int device_type)', '    CreateFetcher(TypeIdentifier id)', '    GetCurrentWorkspace', '    NumpyTypeToCaffe(int numpy_type)', '    getGradientFunc(const std::string & token)', '    getOpFunc(const std::string & token)', '    RegistryName', '    static_assert(,)', '    Feed(const DeviceOption & option,PyArrayObject *array,Blob *blob,bool in_place)', '    ~BlobFeederBase', '    Fetch(const Blob & blob)', '    ~BlobFetcherBase', '    getFunc(const std::string & token)', '    PythonOpBase(const OperatorDef & operator_def,Workspace *ws,const std::string & pickled_builder_arg_name)', '    RunOnDevice', '    ~PythonOpBase', '    Feed(const DeviceOption & option,PyArrayObject *original_array,Blob *blob,bool in_place)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array,Tensor *out,bool in_place)', '    Fetch(const Blob & blob)', '    FetchTensor(const Tensor & tensor,bool force_copy)', '    NeedsCopy(const Tensor *tensor,const TypeMeta & dtype)', '    getFunc(const std::string & token)', '    PythonGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    getFunc(const std::string & token)', '    PythonOp(const OperatorDef & operator_def,Workspace *ws)', '    bytes', '    cast', '    len', '    getGradientFunc', '    getOpFunc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_dlpack.cc', [], ['    dl_device_type_map', '    dl_type_map', '    map', '    CaffeToDLDeviceType(int device_type)', '    CaffeToDLType(const TypeMeta & meta)', '    DLTypeToCaffe(const DLDataType & dl_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_dlpack.h', ['    DLPackWrapper'], ['    CaffeToDLDeviceType(int device_type)', '    CaffeToDLType(const TypeMeta & meta)', '    DLTypeToCaffe(const DLDataType & dl_type)', '    data', '    DLPackWrapper(Tensor *tensor,DeviceOption device_option)', '    feed(py::object obj)', '    dim', '    id', '    raw_data', '    ShareExternalPointer', '    reinterpret_steal']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAPython', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonGradient', '    addCUDAObjectMethods(py::module & m)', '    addCUDAGlobalMethods(py::module & m)', '    PYBIND11_MODULE(caffe2_pybind11_state_gpu,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_hip.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_HIPPython', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonGradient', '    addHIPObjectMethods(py::module & m)', '    addHIPGlobalMethods(py::module & m)', '    PYBIND11_MODULE(caffe2_pybind11_state_hip,m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_ideep.cc', ['    IDeepFeeder', '    IDeepFetcher'], ['    Feed(const DeviceOption & option,PyArrayObject *original_array,Blob *blob,bool in_place)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array,itensor *tensor)', '    type_transform(const TypeMeta & meta)', '    ZeroDim(PyArrayObject *array)', '    Fetch(const Blob & blob)', '    FetchTensor(const itensor & atensor,bool force_copy)', '    type_transform(const itensor & atensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_int8.cc', ['    Int8TensorFetcher'], ['    Fetch(const Blob & blob)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_nomni.cc', [], ['    cast(const std::vector *src,return_value_policy pol,handle parent)', '    cast(const std::vector & src,return_value_policy,handle parent)', '    addNomnigraphMethods(pybind11::module & m)', '    GraphPrinter(Graph::NodeRef node)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    addNomnigraphMethodsImpl(py::module & m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_registry.cc', [], ['    RegistryName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\python\\pybind_state_registry.h', [], ['    RegistryName', '    PybindAddition', '    PybindAddition(py::module &)', '    ~PybindAddition']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\pybind_utils.h', [], ['    torch_warn_once_399', '    torch_warn_once_708', '    argumentToIValue(const FunctionSchema & schema,size_t argumentPosition,py::handle object)', '    deprecated_AT_ASSERT', '    deprecated_AT_ERROR', '    if_empty_then(::c10::str __VA_ARGS__,)', '    str(,,,,,::c10::str __VA_ARGS__)', '    createGenericDict(py::dict obj,const TypePtr & key_type,const TypePtr & value_type)', '    createGenericList(py::handle obj,const TypePtr & elem_type)', '    createPyObjectForStack(Stack)', '    createStackForSchema(const FunctionSchema & schema,const tuple_slice & args,const py::kwargs & kwargs,c10::optional self)', '    evilDeprecatedBadCreateStackDoNotUse(const py::tuple & tuple,at::ArrayRef inputs,size_t reserve_extra_space)', '    friendlyTypeName(py::handle obj)', '    guardAgainstNamedTensor(const T & var)', '    invokeOperatorFromPython(const std::vector,py::args args,py::kwargs kwargs)', '    invokeScriptFunctionFromPython(Function & callee,tuple_slice args,py::kwargs kwargs)', '    invokeScriptMethodFromPython(Method & callee,tuple_slice args,py::kwargs kwargs)', '    invokeScriptMethodFromPython(Object & object,const std::string & method_name,tuple_slice args,py::kwargs kwargs)', '    isTraceableType(TypePtr type)', '    setattr(pyObj,attrName,toPyObject)', '    tuple', '    returnToIValue(const TypePtr & type,py::handle object)', '    runAndInsertCall(Function & callee,tuple_slice args,py::kwargs kwargs,c10::optional self,std::function callInserter)', '    toIValue(py::handle obj,const TypePtr & type,c10::optional N)', '    toPyObject(IValue ivalue)', '    get_python_cu', '    toDictKeyIValue(py::handle key)', '    tryToInferContainerType(py::handle input)', '    tryToInferType(py::handle input)', '    unifyOrInitializeType(TypePtr accum,TypePtr unify)', '    toTraceableStack(const py::tuple & inputs)', '    toTypeInferredIValue(py::handle input)', '    create', '    at', '    findErrorInKwargs', '    formatTypeMismatchMsg', '    create', '    import', '    getOperation', '    schema', '    cast_error', '    getattr', '    hasattr', '    repr', '    toBool', '    toDouble', '    toGenericDict', '    toInt', '    toList', '    toObject', '    toStringRef', '    toTensor', '    toTuple', '    emplace_back', '    push_back', '    reserve', '    InferredType(TypePtr type)', '    InferredType(std::string reason)', '    reason', '    success', '    type', '    PythonFutureWrapper(c10::intrusive_ptr fut)', '    wait', '    ivalue', '    type', '    getPythonInterpreterSourceRange', '    getTracingState', '    getValueTrace', '    pauseTracing', '    setValueTrace', '    createNamed', '    begin', '    end', '    operator[](size_t index)', '    size', '    tuple_slice(py::tuple tup_)', '    tuple_slice(py::tuple tup_,int64_t b_)', '    tuple_slice(py::tuple tup_,int64_t b_,int64_t e_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\python.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_anomaly_mode.cpp', [], ['    print_stack(const std::string & current_node_name)', '    store_stack']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_anomaly_mode.h', [], ['    dict', '    print_stack(const std::string & current_node_name)', '    PyAnomalyMetadata', '    store_stack', '    ~PyAnomalyMetadata']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_arg_flatten.cpp', [], ['    sequence', '    sequence', '    cast_dict(std::vector objs)', '    cast_handle_sequence(std::vector objs)', '    cast_sequence(std::vector objs)', '    flatten(py::handle obj)', '    flatten_rec(PyObject *obj,ParsedArgs & args)', '    unflatten(ArrayRef vars,const IODescriptor & desc)', '    unflatten_rec(ArrayRef::iterator & var_it,ArrayRef::iterator & var_it_end,std::string::const_iterator & desc_it,std::vector::const_iterator & str_it,std::vector::const_iterator & str_it_end)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_arg_flatten.h', [], ['    operator<<(std::ostream & out,const IODescriptor::VariableMetadata & meta)', '    operator<<(std::ostream & out,const IODescriptor & desc)', '    unflatten(at::ArrayRef vars,const IODescriptor & structure)', '    hash(const IODescriptor & o)', '    hash(const VariableMetadata & m)', '    extend(const autograd::variable_list & list)', '    operator==(const IODescriptor & o)', '    operator==(const VariableMetadata & o)', '    VariableMetadata(const autograd::Variable & var)', '    extend(const autograd::variable_list & list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_arg_parser.cpp', [], ['    find_param(FunctionSignature & signature,PyObject *name)', '    parse_as_integer(const std::string & s)', '    parse_intlist_args(const std::string & s,int64_t size)', '    should_allow_numbers_as_tensors(const std::string & name)', '    torch_warn_once_750', '    parse(PyObject *args,PyObject *kwargs,PyObject *[] dst,bool raise_exception)', '    append_overloaded_arg(std::vector & overloaded_args,PyObject *obj)', '    handle_torch_function(PythonArgs & r,PyObject *args,PyObject *kwargs,PyObject *torch_api,const char *module_name)', '    check_deprecated(const FunctionSignature & signature)', '    get_signatures', '    print_error(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    PythonArgParser(std::vector fmts,bool traceable)', '    raw_parse(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    scalar_slow(int i)', '    tensor_slow(int i)', '    check(PyObject *obj,std::vector & overloaded_args)', '    FunctionParameter(const std::string & fmt,bool keyword_only)', '    set_default_str(const std::string & str)', '    type_name', '    FunctionSignature(const std::string & fmt,int index)', '    toString']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_arg_parser.h', ['    ParameterType'], ['    _is_basic_python_type(PyTypeObject *tp)', '    check_has_torch_function(PyObject *obj)', '    PyObject_FastGetAttrString(PyObject *obj,char *name)', '    PyTorch_LookupSpecial(PyObject *obj,char *name)', '    handle_torch_function(PythonArgs & r,PyObject *args,PyObject *kwargs,PyObject *torch_api,const char *module_name)', '    parseDimnameList(PyObject *arg)', '    stashValue', '    get', '    dimnamelist(int i)', '    generator(int i)', '    isNone(int i)', '    memoryformat(int i)', '    memoryformatOptional(int i)', '    pyobject(int i)', '    storage(int i)', '    string(int i)', '    toBool(int i)', '    toBoolOptional(int i)', '    toBoolWithDefault(int i,bool default_bool)', '    toComplex(int i)', '    toComplexWithDefault(int i,std::complex default_value)', '    toDouble(int i)', '    toDoubleOptional(int i)', '    toDoubleWithDefault(int i,double default_double)', '    toInt64(int i)', '    toInt64Optional(int i)', '    toInt64WithDefault(int i,int64_t default_int)', '    toQScheme(int i)', '    empty', '    push_back', '    reserve', '    type_name', '    check(PyObject *obj,std::vector & overloaded_args)', '    FunctionParameter(const std::string & fmt,bool keyword_only)', '    set_default_str(const std::string & str)', '    type_name', '    FunctionSignature(const std::string & fmt,int index)', '    parse(PyObject *args,PyObject *kwargs,PyObject *[] dst,bool raise_exception)', '    toString', '    ParsedArgs', '    check_deprecated(const FunctionSignature & signature)', '    get_signatures', '    parse(PyObject *args,PyObject *kwargs,ParsedArgs & dst)', '    PythonArgParser(std::vector fmts,bool traceable)', '    raw_parse(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    device(int i)', '    deviceOptional(int i)', '    deviceWithDefault(int i,const at::Device & default_device)', '    dimname(int i)', '    dimnamelist(int i)', '    generator(int i)', '    get_func_name', '    has_torch_function', '    intlist(int i)', '    intlistWithDefault(int i,std::vector default_intlist)', '    isNone(int i)', '    layout(int i)', '    layoutOptional(int i)', '    layoutWithDefault(int i,at::Layout default_layout)', '    memoryformat(int i)', '    memoryformatOptional(int i)', '    pyobject(int i)', '    PythonArgs(bool traceable,const FunctionSignature & signature,PyObject **args)', '    scalar(int i)', '    scalar_slow(int i)', '    scalarOptional(int i)', '    scalartype(int i)', '    scalartypeOptional(int i)', '    scalartypeWithDefault(int i,at::ScalarType default_scalartype)', '    scalarWithDefault(int i,at::Scalar default_scalar)', '    storage(int i)', '    string(int i)', '    tensor(int i)', '    tensor_slow(int i)', '    tensorlist(int i)', '    tensorlist_n(int i)', '    toBool(int i)', '    toBoolOptional(int i)', '    toBoolWithDefault(int i,bool default_bool)', '    toComplex(int i)', '    toComplexWithDefault(int i,std::complex default_complex)', '    toDouble(int i)', '    toDoubleOptional(int i)', '    toDoubleWithDefault(int i,double default_double)', '    toInt64(int i)', '    toInt64Optional(int i)', '    toInt64WithDefault(int i,int64_t default_int)', '    toQScheme(int i)', '    isTracing']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\utils\\python_arg_parsing.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_autograd.h', [], ['    THPAutograd_initExtension(PyObject *_unused,PyObject *unused)', '    THPAutograd_initFunctions', '    python_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_call.cpp', [], ['    fromMessage(const Message & message)', '    PythonCall(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_call.h', ['    final'], ['    fromMessage(const Message & message)', '    PythonCall(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\python_comm.cpp', [], ['    initCommMethods(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\python_comm.h', [], ['    initCommMethods(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_compat.h', [], ['    __PySlice_Unpack(PyObject *_r,Py_ssize_t *start,Py_ssize_t *stop,Py_ssize_t *step)', '    PyGILState_Check']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_cpp_function.cpp', [], ['    _initFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    functionToPyObject(const std::shared_ptr & cdata)', '    registerCppFunction(const std::type_info & type,PyTypeObject *pytype)', '    registerFunctionHook(Node & fn,PyObject *hook)', '    THPCppFunction_call(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPCppFunction_clear(PyObject *self)', '    THPCppFunction_dealloc(PyObject *self)', '    THPCppFunction_metadata(THPCppFunction *self,void *_unused)', '    THPCppFunction_name(PyObject *self,PyObject *noargs)', '    THPCppFunction_next_functions(THPCppFunction *self,PyObject *hook)', '    THPCppFunction_register_hook(PyObject *self,PyObject *hook)', '    THPCppFunction_register_hook_dict(PyObject *self,PyObject *_var)', '    THPCppFunction_requires_grad(THPCppFunction *self,void *unused)', '    THPCppFunction_traverse(PyObject *self,visitproc visit,void *arg)', '    DefaultFunctionType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_cpp_function.h', [], ['    _initFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    CppFunction_pynew(PyTypeObject *type,PyObject *args,PyObject *kwds)', '    createForwardFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    functionToPyObject(const std::shared_ptr & cdata)', '    registerCppFunction(const std::type_info & type,PyTypeObject *pytype)', '    registerFunctionHook(Node & fn,PyObject *hook)', '    THPCppFunction_metadata(THPCppFunction *self,void *_unused)', '    THPCppFunction_name(PyObject *self,PyObject *noargs)', '    THPCppFunction_next_functions(THPCppFunction *self,PyObject *hook)', '    THPCppFunction_register_hook(PyObject *self,PyObject *hook)', '    THPCppFunction_register_hook_dict(PyObject *self,PyObject *_var)', '    THPCppFunction_requires_grad(THPCppFunction *self,void *unused)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_custom_class.cpp', [], ['    initPythonCustomClassBindings(PyObject *module)', '    __call__(py::args args,py::kwargs kwargs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_custom_class.h', [], ['    initPythonCustomClassBindings(PyObject *module)', '    __call__(py::args args,py::kwargs kwargs)', '    ScriptClass(c10::StrongTypePtr class_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\python_dimname.cpp', [], ['    THPDimname_parse(PyObject *obj)', '    THPUtils_checkDimname(PyObject *obj)', '    THPUtils_checkDimnameList(PyObject *obj)', '    addMapping(PyObject *obj,at::Dimname dimname)', '    lookup(PyObject *obj)', '    ~InternedStringsTable']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\python_dimname.h', [], ['    THPDimname_parse(PyObject *obj)', '    THPUtils_checkDimname(PyObject *obj)', '    THPUtils_checkDimnameList(PyObject *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_dispatch.cpp', [], ['    dispatch_str(const char *key,Func)', '    initDispatchBindings(PyObject *module)', '    parseAliasAnalysisKind(const std::string & k)', '    parseDispatchKey(const std::string & k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_dispatch.h', [], ['    initDispatchBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_engine.cpp', [], ['    child_atfork', '    py_outputs', '    THPEngine_initModule(PyObject *module)', '    THPEngine_is_checkpoint_valid(PyObject *self,PyObject *noargs)', '    THPEngine_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPEngine_queue_callback(PyObject *self,PyObject *_callback)', '    THPEngine_run_backward(THPEngine *self,PyObject *args,PyObject *kwargs)', '    get_python_engine', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    make_anomaly_metadata', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_engine.h', [], ['    THPEngine_initModule(PyObject *module)', '    get_python_engine', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    make_anomaly_metadata', '    PythonEngine', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_function.cpp', [], ['    _assert_not_tracing(const char *name,const variable_list & input_vars)', '    _mark_dirty(THPFunction *self)', '    _parse_non_differentiable(THPFunction *self)', '    _prepare_grads(THPFunction *self,THPObjectPtr & raw_grads,bool is_grad_output)', '    _save_variables(const std::shared_ptr & cdata_ptr,THPFunction *self)', '    _trace_post_record(torch::jit::Node *node,PyObject *op_obj,const variable_list & input_vars,PyObject *output_objects,bool is_inplace,bool unpack_output)', '    _trace_pre_record(PyObject *op_obj,PyObject *input_objects,const variable_list & input_vars)', '    _trim_grad_input(const std::shared_ptr & cdata,THPFunction *self,THPObjectPtr & grad_input)', '    _wrap_outputs(const std::shared_ptr & cdata,THPFunction *self,const variable_list & input_vars,PyObject *raw_output,PyObject *outputs,bool is_executable)', '    THPFunction_clear(THPFunction *self)', '    THPFunction_dealloc(THPFunction *self)', '    THPFunction_traverse(THPFunction *self,visitproc visit,void *arg)', '    unpack_saved_variables(THPFunction *self,const std::function & unpack_fn)', '    as_variable', '    forward_class', '    getImplMember(PyObject *obj,void *_unused)', '    getMember(PyObject *obj,void *_unused)', '    getObject(PyObject *obj,void *_unused)', '    getRequiresGrad(PyObject *obj,void *_unused)', '    process_outputs(PyObject *op_obj,const std::shared_ptr & cdata,THPFunction *grad_fn,const UnpackedInput & unpacked,PyObject *inputs,THPObjectPtr,bool is_executable,torch::jit::Node *node)', '    setObject(PyObject *obj,PyObject *value,void *_unused)', '    THPFunction__register_hook_dict(THPFunction *self,PyObject *_var)', '    THPFunction_apply(PyObject *cls,PyObject *inputs)', '    THPFunction_do_backward(THPFunction *self,PyObject *args)', '    THPFunction_initModule(PyObject *module)', '    THPFunction_metadata(THPFunction *self,void *_unused)', '    THPFunction_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPFunction_next_functions(THPFunction *self,void *_unused)', '    THPFunction_register_hook(THPFunction *self,PyObject *hook)', '    THPFunction_saved_tensors(THPFunction *self,void *_unused)', '    THPFunction_saved_variables(THPFunction *self,void *_unused)', '    traceable_py_bool', '    unpack_input(PyObject *args)', '    apply(variable_list)', '    is_traceable', '    legacy_apply(const variable_list & inputs)', '    name', '    release_variables', '    throw_python_error']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_function.h', [], ['    THPFunction_Check(PyObject *obj)', '    THPFunction_initModule(PyObject *module)', '    ensure_tuple(THPObjectPtr & obj)', '    apply(variable_list)', '    is_traceable', '    legacy_apply(const variable_list & inputs)', '    name', '    PyNode(THPObjectPtr obj)', '    release_variables', '    throw_python_error', '    ~PyNode']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_functions.cpp', [], ['    matchBuiltinOp(const std::string & opName,const py::args & args,const py::kwargs & kwargs,Stack & stack)', '    pyRemoteBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRemotePythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    pyRpcBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRpcPythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    sendPythonRemoteCall(const WorkerInfo & dst,SerializedPyObj serializedPyObj,const IValue & rrefId,const IValue & forkId,const std::shared_ptr & rf)', '    toPyObj(const Message & message)', '    toPyObjInternal(RpcCommandBase & rpc,MessageType messageType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\python_functions.cpp', [], ['    addClass(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    initialize_autogenerated_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_functions.h', [], ['    pyRemoteBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRemotePythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    pyRpcBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRpcPythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    toPyObj(const Message & message)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\python_functions.h', [], ['    initialize_autogenerated_functions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\python_headers.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_hook.cpp', [], ['    check_result(PyObject *prev,PyObject *result,PyObject *hook)', '    check_single_result(PyObject *_original,PyObject *_result,PyObject *hook)', '    hook_name(PyObject *hook)', '    unwrap_variables(PyObject *py_variables)', '    wrap_variables(const variable_list & c_variables)', '    operator()(const variable_list & _outputs,const variable_list & _inputs)', '    PyFunctionPostHook(PyObject *dict)', '    ~PyFunctionPostHook', '    operator()(const variable_list & values)', '    PyFunctionPreHook(PyObject *dict,int value_idx)', '    ~PyFunctionPreHook']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_hook.h', [], ['    operator()(const variable_list & _outputs,const variable_list & _inputs)', '    PyFunctionPostHook(PyObject *dict)', '    ~PyFunctionPostHook', '    operator()(const variable_list & values)', '    PyFunctionPreHook(PyObject *dict,int value_idx)', '    ~PyFunctionPreHook']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_interpreter.cpp', [], ['    aliasAnalysisIsSpecialCase', '    createPythonOperation(const Node *op_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_ir.cpp', [], ['    findAllNodes(c10::ArrayRef blocks,Symbol kind,bool recurse)', '    findAllNodes(Block *block,Symbol kind,bool recurse)', '    findNode(c10::ArrayRef blocks,Symbol kind,bool recurse)', '    findNode(Block *block,Symbol kind,bool recurse)', '    getPythonName(const PyObject *obj_)', '    initPythonIRBindings(PyObject *module_)', '    printPyObject(std::ostream & out,const THPObjectPtr & obj)', '    autogradFunction', '    cloneFrom(Node *other_)', '    lint_python', '    name', '    writeScalars(std::ostream & out)', '    createPythonOp(THPObjectPtr,const std::string & cconv,pyobj_list)', '  Static Member Variables', '    Kind']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_ir.h', [], ['    initPythonIRBindings(PyObject *module_)', '    allocNewInstance(Graph *g)', '    autogradFunction', '    cloneFrom(Node *other_)', '    ConcretePythonOp(Graph *graph)', '    init(THPObjectPtr,const std::string & cconv,pyobj_list)', '    lint_python', '    name', '    writeScalars(std::ostream & out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_ivalue.h', [], ['    create(py::object py_obj)', '    ConcretePyObjectHolder(py::object py_obj)', '    getPyObject', '    ~ConcretePyObjectHolder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_legacy_variable.cpp', [], ['    THPVariable_pynew(PyTypeObject *type,PyObject *args,PyObject *kwds)', '    init_legacy_variable(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_legacy_variable.h', [], ['    init_legacy_variable(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\python_nccl.cpp', [], ['    destroy_nccl_comm(PyObject *capsule)', '    extract_tensors(PyObject *obj)', '    unpack_comms(PyObject *obj,size_t size)', '    unpack_nccl_comm(PyObject *capsule)', '    THCPModule_nccl_all_gather(PyObject *self,PyObject *args)', '    THCPModule_nccl_all_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_broadcast(PyObject *self,PyObject *args)', '    THCPModule_nccl_init_rank(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce_scatter(PyObject *self,PyObject *args)', '    THCPModule_nccl_unique_id(PyObject *self,PyObject *args)', '    THCPModule_nccl_version(PyObject *self,PyObject *args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\python_nccl.h', [], ['    THCPModule_nccl_all_gather(PyObject *self,PyObject *args)', '    THCPModule_nccl_all_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_broadcast(PyObject *self,PyObject *args)', '    THCPModule_nccl_init_rank(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce_scatter(PyObject *self,PyObject *args)', '    THCPModule_nccl_unique_id(PyObject *self,PyObject *args)', '    THCPModule_nccl_version(PyObject *self,PyObject *args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\python_nn_functions.cpp', [], ['    THPVariable__parse_to(PyObject *module,PyObject *args,PyObject *kwargs)', '    $', '    $', '    initNNFunctions(PyObject *module)', '    tuple']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_nn_functions.h', [], ['    initNNFunctions(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_numbers.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\python_print.cpp', ['    TaggedStringStream'], ['    isValidIdentifier(const std::string & name)', '    isValidIdentifierChar(char c,size_t pos)', '    makeValidIdentifier(const std::string & candidate)', '    printFunction(const Function & func)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    PythonPrint(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    ranges', '    str', '    assignValue(Value *v,const std::string & s)', '    assignValue(Value *v,std::shared_ptr s)', '    assignValue(Value *v,Value *w)', '    assignValuesToTheirUniqueNames(at::ArrayRef values)', '    buildConstantList(Node *n,std::vector & constants)', '    buildConstantList(Block *b,std::vector & constants)', '    canInline(Value *v)', '    createBroadList(dtype value,const int64_t & N)', '    genName(const std::string & candidate)', '    genNameImpl(const std::string & candidate,std::unordered_set & used)', '    genUniqueNameFor(Value *v)', '    getOrAddTensorConstant(at::Tensor t)', '    indent', '    isLongInline(Node *node)', '    isLongLine(const std::string & str)', '    isNonConstantInline(Value *input)', '    previousNonConstant(Node *n)', '    printAnnotatedAssignment(at::ArrayRef lhs,at::ArrayRef rhs)', '    printAssignment(at::ArrayRef lhs,at::ArrayRef rhs)', '    printBlock(Block *root,bool block_has_other_statements)', '    printBody(Block *body)', '    printClass(const ClassTypePtr & classType)', '    printConstant(TaggedStringStream & stmt,const IValue & v)', '    printDefaultValue(const Argument & arg,TaggedStringStream & stmt,const IValue & value)', '    printDict(TaggedStringStream & stmt,at::ArrayRef key_value_pairs,const char *begin,const char *end)', '    printFunction(const Function & func,bool print_first_argument_type)', '    printIf(IfView stmt)', '    printLoop(LoopView stmt)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    printNode(Node *node,bool print_const)', '    printOpName(TaggedStringStream & stmt,Symbol kind)', '    printOutputDefinition(Node *node,const T & expr)', '    printRHS(TaggedStringStream & stmt,Node *node)', '    printValueIndex(TaggedStringStream & stmt,at::ArrayRef inputs)', '    printValueList(TaggedStringStream & stmt,at::ArrayRef list,const char *begin,const char *end)', '    PythonPrintImpl(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    registerClassDependencies(const TypePtr & type)', '    registerDependency(const c10::NamedTypePtr & type)', '    requiresAnnotation(Value *lhs,Value *rhs)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanTypeDependencies(Node *node)', '    scanValue(Node *block_point,Value *v)', '    splitLongInlines(at::ArrayRef inputs)', '    operator<<(const std::string & s)', '    operator<<(const TaggedStringStream & rhs)', '    operator<<(const std::shared_ptr & rhs)', '    operator<<(const T & t)', '    ranges', '    str', '    TaggedStringStream(const SourceRangeStack *srs)', '    useOf(Value *v)', '    WithIndented', '    WithSourceRange(SourceRangeStack *stack,Node *n)', '    ~WithSourceRange', '    zipWith(at::ArrayRef list_a,at::ArrayRef list_b,F action)', '    ~PythonPrintImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\python_print.h', [], ['    printFunction(const Function & func)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    PythonPrint(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    ranges', '    str', '    ~PythonPrint']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_remote_call.cpp', [], ['    fromMessage(const Message & message)', '    PythonRemoteCall(SerializedPyObj,at::IValue retRRefId,at::IValue retForkId)', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_remote_call.h', ['    PythonRemoteCall'], ['    fromMessage(const Message & message)', '    PythonRemoteCall(SerializedPyObj,at::IValue retRRefId,at::IValue retForkId)', '    retForkId', '    retRRefId', '    serializedPyObj', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_resp.cpp', [], ['    fromMessage(const Message & message)', '    PythonResp(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_resp.h', ['    final'], ['    fromMessage(const Message & message)', '    PythonResp(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_rpc_handler.cpp', [], ['    getFunction(const py::object & module,const char *name)', '    getInstance', '    cleanup', '    deserialize(const SerializedPyObj & serializedObj)', '    handleException(const py::object & obj)', '    handleExceptionGILHeld(const py::object & obj)', '    jitCompilationUnit', '    parseTypeFromStr(const std::string & type_str)', '    PythonRpcHandler', '    runPythonUdf(py::object)', '    serialize(const py::object & obj)', '    resolveType(const std::string & name,const jit::SourceRange &)', '    resolveValue(const std::string &,torch::jit::Function &,const jit::SourceRange &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\python_rpc_handler.h', ['    PythonRpcHandler'], ['    getInstance', '    cleanup', '    deserialize(const SerializedPyObj & serializedObj)', '    handleException(const py::object & obj)', '    handleExceptionGILHeld(const py::object & obj)', '    jitCompilationUnit', '    operator=', '    operator=', '    parseTypeFromStr(const std::string & type_str)', '    PythonRpcHandler', '    PythonRpcHandler', '    PythonRpcHandler', '    runPythonUdf(py::object)', '    serialize(const py::object & obj)', '    ~PythonRpcHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_scalars.h', [], ['    load_scalar(void *data,at::ScalarType scalarType)', '    store_scalar(void *data,at::ScalarType scalarType,PyObject *obj)', '    convert']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_strings.h', [], ['    THPUtils_checkString(PyObject *obj)', '    THPUtils_internString(const std::string & str)', '    THPUtils_internStringInPlace(PyObject **obj)', '    THPUtils_isInterned(PyObject *obj)', '    THPUtils_packString(const char *str)', '    THPUtils_packString(const std::string & str)', '    THPUtils_unpackString(PyObject *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_stub.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\python_stub.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_sugared_value.cpp', [], ['    checkInterface(const SourceRange & loc,Function & m,std::shared_ptr self,const std::string & field)', '    isNamedTupleClass(const py::object & obj)', '    as_function(const py::object & obj)', '    typeString(py::handle h)', '    recurseThroughNestedModules(const SourceRange & loc,Function & m,std::vector & keys,std::vector & values,std::shared_ptr self,const std::string & prefix,const std::string & field)', '    registerNamedTuple(const py::object & obj,const SourceRange & loc)', '    toSugaredValue(const IValue & v,Function & m,const SourceRange & loc)', '    toSugaredValue(py::object obj,Function & m,SourceRange loc,bool is_constant)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getSugaredModuleDict(const SourceRange & loc,Function & m)', '    iter(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    checkForAddToConstantsError(std::stringstream & ss)', '    getattr(const SourceRange & loc,const std::string & name)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    getSchema(const size_t n_args,const size_t n_binders,const SourceRange & loc)', '    kind']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_sugared_value.h', [], ['    as_function(const py::object & obj)', '    isNamedTupleClass(const py::object & obj)', '    recurseThroughNestedModules(const SourceRange & loc,Function & m,std::vector & keys,std::vector & values,std::shared_ptr self,const std::string & prefix,const std::string & field)', '    registerNamedTuple(const py::object & obj,const SourceRange & loc)', '    toSimple(Value *v)', '    toSugaredValue(py::object obj,Function & m,SourceRange loc,bool is_constant)', '    BooleanDispatchValue(py::dict dispatched_fn)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    ConstantParameterList(Value *the_list)', '    kind', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    ModuleDictMethod(SugaredValuePtr iterable,const std::string & name)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getSugaredModuleDict(const SourceRange & loc,Function & m)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    ModuleValue(Value *self,std::shared_ptr concreteType)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    PythonClassValue(ClassTypePtr type,py::object py_type)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    PythonModuleValue(py::object mod)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    checkForAddToConstantsError(std::stringstream & ss)', '    getattr(const SourceRange & loc,const std::string & name)', '    getSchema(const size_t n_args,const size_t n_binders,const SourceRange & loc)', '    kind', '    PythonValue(py::object the_self,c10::optional rcb,Value *module_self)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    getKeys', '    getModules', '    iter(const SourceRange & loc,Function & m)', '    kind', '    SugaredModuleDict(std::shared_ptr self,std::shared_ptr keys,std::shared_ptr modules)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\tensor\\python_tensor.cpp', [], ['    get_module(Backend backend)', '    get_name(Backend backend,ScalarType scalarType)', '    get_storage_obj(PyTensorType *type)', '    get_tensor_dict', '    initialize_aten_types(std::vector & tensor_types)', '    py_bind_tensor_types(const std::vector & tensor_types)', '    py_initialize_metaclass(PyTypeObject & metaclass)', '    py_initialize_tensor_type(PyTypeObject & type,const char *name,PyObject *tp_dict)', '    PyTensorType_Check(PyObject *obj)', '    set_name(PyTensorType & type_obj,const std::string & name)', '    set_type(PyTensorType & type_obj,Backend backend,ScalarType scalarType)', '    Tensor_instancecheck(PyTensorType *self,PyObject *arg)', '    Tensor_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    unavailable_type(const PyTensorType & type)', '    get_default_dispatch_key', '    get_default_scalar_type', '    initialize_python_bindings', '    py_set_default_dtype(PyObject *obj)', '    py_set_default_tensor_type(PyObject *obj)', '    set_default_tensor_type(PyTensorType *type)', '    Tensor_dtype(PyTensorType *self,void *unused)', '    Tensor_is_cuda(PyTensorType *self,void *unused)', '    Tensor_is_sparse(PyTensorType *self,void *unused)', '    Tensor_layout(PyTensorType *self,void *unused)', '    get_backend', '    get_dispatch_key', '    get_scalar_type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\tensor\\python_tensor.h', [], ['    get_default_dispatch_key', '    get_default_scalar_type', '    initialize_python_bindings', '    py_set_default_dtype(PyObject *obj)', '    py_set_default_tensor_type(PyObject *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\python_torch_functions.cpp', [], ['    check_out_type_matches(Tensor result,ScalarType scalarType,bool scalarType_is_none,c10::optional layout,const Device & device,bool device_is_none)', '    dispatch_nonzero(const Tensor & self)', '    dispatch_nonzero(const Tensor & self,Tensor out)', '    dispatch_nonzero_numpy(const Tensor & self)', '    THPVariable_arange(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_as_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_from_numpy(PyObject *module,PyObject *arg)', '    THPVariable_full(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_get_device(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_nonzero(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_numel(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_randint(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_range(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_sparse_coo_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    TypeError_to_NotImplemented_(PyObject *self,PyObject *args,PyObject *kwargs)', '    options', '    $', '    $', '    dispatch_arange(Scalar end,Tensor result)', '    dispatch_arange(Scalar end,const TensorOptions & options)', '    dispatch_arange(Scalar start,Scalar end,Scalar step,Tensor result)', '    dispatch_arange(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,c10::optional names,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,Generator generator,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    dispatch_randint(int64_t high,IntArrayRef size,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,const TensorOptions & options)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,Tensor result)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Tensor result)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,const TensorOptions & options)', '    dispatch_range(Scalar start,Scalar end,Scalar step,Tensor result)', '    dispatch_range(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    initTorchFunctions(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_tracer.cpp', [], ['    lookup_fn_adapter', '    initPythonTracerBindings(PyObject *module)', '    preRecordPythonTrace(THPObjectPtr pyobj,const std::string & arg_types,at::ArrayRef inputs,pyobj_list scalar_args)', '    pythonRecordSourceLocation(Node *n)', '    pythonWarn(const std::string & reason)', '    createGraphByTracing(const py::function & func,Stack trace_inputs,const py::function & var_name_lookup_fn,bool force_outplace,Module *self)', '    getPythonInterpreterSourceRange']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_tracer.h', [], ['    createGraphByTracing(const py::function & func,Stack inputs,const py::function & var_name_lookup_fn,bool force_outplace,Module *self)', '    getPythonInterpreterSourceRange', '    getPythonInterpreterStackTrace', '    initPythonTracerBindings(PyObject *module)', '    preRecordPythonTrace(THPObjectPtr pyobj,const std::string & arg_types,at::ArrayRef inputs,std::vector scalar_args)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_tree_views.cpp', [], ['    initTreeViewBindings(PyObject *module)', '    maybeConvertToString(const py::object & obj)', '    wrap_list(const SourceRange & fallback_pos,std::vector)', '    wrap_maybe(const SourceRange & fallback_pos,T *val)', '    create(int line,int start_col,int end_col)', '    line_col_to_byte_offs(int line,int start_col,int end_col)', '    SourceRangeFactory(std::string text,py::object filename,size_t file_lineno,size_t leading_whitespace_chars)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\python_tree_views.h', [], ['    initTreeViewBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\python_tuples.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_variable.cpp', [], ['    THPVariable_clear(THPVariable *self)', '    THPVariable_dealloc(THPVariable *self)', '    THPVariable_device(THPVariable *self,void *unused)', '    THPVariable_dtype(THPVariable *self,void *unused)', '    THPVariable_get_data(THPVariable *self,void *unused)', '    THPVariable_is_leaf(THPVariable *self,void *unused)', '    THPVariable_layout(THPVariable *self,void *unused)', '    THPVariable_make_subclass(PyObject *_ignored,PyObject *args,PyObject *kwargs)', '    THPVariable_NewWithVar(PyTypeObject *type,Variable var)', '    THPVariable_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPVariable_set_grad_fn(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_traverse(THPVariable *self,visitproc visit,void *arg)', '    parsed_args', '    THPVariable_get_backwards_hooks(THPVariable *self,void *unused)', '    THPVariable_get_base(THPVariable *self,void *unused)', '    THPVariable_get_cdata(THPVariable *self,void *unused)', '    THPVariable_get_grad(THPVariable *self,void *unused)', '    THPVariable_get_grad_fn(THPVariable *self,void *unused)', '    THPVariable_get_name(THPVariable *self,void *unused)', '    THPVariable_get_names(THPVariable *self,void *unused)', '    THPVariable_get_ndim(THPVariable *self,void *unused)', '    THPVariable_get_output_nr(THPVariable *self,void *unused)', '    THPVariable_get_requires_grad(THPVariable *self,void *unused)', '    THPVariable_get_shape(THPVariable *self,void *unused)', '    THPVariable_get_T(THPVariable *self,void *unused)', '    THPVariable_get_version(THPVariable *self,void *unused)', '    THPVariable_get_volatile(THPVariable *self,void *unused)', '    THPVariable_initModule(PyObject *module)', '    THPVariable_is_complex(THPVariable *self,void *unused)', '    THPVariable_is_cuda(THPVariable *self,void *unused)', '    THPVariable_is_mkldnn(THPVariable *self,void *unused)', '    THPVariable_is_quantized(THPVariable *self,void *unused)', '    THPVariable_is_sparse(THPVariable *self,void *unused)', '    THPVariable_set_backwards_hooks(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_set_data(THPVariable *self,PyObject *data,void *unused)', '    THPVariable_set_grad(THPVariable *self,PyObject *py_grad,void *unused)', '    THPVariable_set_names(THPVariable *self,PyObject *names)', '    THPVariable_set_requires_grad(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_set_volatile(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_Wrap(Variable var)', '    initTensorImplConversion(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_variable.h', [], ['    THPVariable_CheckExact(PyObject *obj)', '    THPVariable_Check(PyObject *obj)', '    THPVariable_initModule(PyObject *module)', '    THPVariable_Unpack(PyObject *obj)', '    THPVariable_Wrap(Variable var)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_variable_indexing.cpp', [], ['    applySlicing(const Variable & self,PyObject *index,variable_list & outIndices,bool is_tracing,const at::Device & self_device,const IntArrayRef & self_sizes)', '    count_specified_dimensions(PyObject *index)', '    checkUnpackSlice(PyObject *index,Py_ssize_t *start_ptr,Py_ssize_t *stop_ptr,Py_ssize_t *step_ptr)', '    recordSelectTrace(const Tensor & index_tensor)', '    recordSliceTrace(PyObject *obj)', '    sequenceToVariable(c10::DispatchKey dispatch_key,PyObject *seq)', '    valueToTensor(c10::TensorOptions options,PyObject *value,const at::Device & device)', '    treatSequenceAsTuple(PyObject *index)', '    wrapTuple(PyObject *index)', '    obj', '    THPVariable_getitem(PyObject *self,PyObject *index)', '    THPVariable_setitem(PyObject *self,PyObject *index,PyObject *py_value)', '    THPVariable_length(PyObject *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\python_variable_indexing.h', [], ['    THPVariable_getitem(PyObject *self,PyObject *index)', '    THPVariable_length(PyObject *self)', '    THPVariable_setitem(PyObject *self,PyObject *index,PyObject *value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\python_variable_methods.cpp', [], ['    dispatch_contiguous(const Tensor & self,at::MemoryFormat memory_format)', '    dispatch_copy_(Tensor & self,const Tensor & other,bool non_blocking)', '    dispatch_invert(const Tensor & self)', '    dispatch_nonzero(const Tensor & self)', '    dispatch_nonzero_numpy(const Tensor & self)', '    dispatch_to(const Tensor & self,Device device,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,Device device,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to_Bool(const Tensor & self)', '    dispatch_to_CComplexDouble(const Tensor & self)', '    dispatch_to_CDouble(const Tensor & self)', '    dispatch_to_CLong(const Tensor & self)', '    THPVariable__is_view(PyObject *self,PyObject *args)', '    THPVariable_apply_(PyObject *self,PyObject *arg)', '    THPVariable_bfloat16(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_bool(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_bool_scalar(PyObject *self,PyObject *args)', '    THPVariable_byte(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_char(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_contiguous(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_copy_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_cpu(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_cuda(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_data_ptr(PyObject *self_,PyObject *args)', '    THPVariable_dim(PyObject *self,PyObject *args)', '    THPVariable_double(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_element_size(PyObject *self,PyObject *args)', '    THPVariable_float(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_float_scalar(PyObject *self,PyObject *args)', '    THPVariable_get_device(PyObject *self_,PyObject *args)', '    THPVariable_half(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_has_names(PyObject *self_,PyObject *args)', '    THPVariable_index_scalar(PyObject *self,PyObject *args)', '    THPVariable_int(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_integral_scalar(PyObject *self,PyObject *args)', '    THPVariable_invert(PyObject *self,PyObject *args)', '    THPVariable_is_contiguous(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_item(PyObject *self,PyObject *args)', '    THPVariable_long(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_map2_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_map_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new_ones(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_nonzero(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_numel(PyObject *self,PyObject *args)', '    THPVariable_numpy(PyObject *self,PyObject *arg)', '    THPVariable_record_stream(PyObject *self,PyObject *arg)', '    THPVariable_requires_grad_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_short(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_size(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_storage(PyObject *self,PyObject *arg)', '    THPVariable_storage_offset(PyObject *self_,PyObject *args)', '    THPVariable_storage_type(PyObject *self,PyObject *arg)', '    THPVariable_stride(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_to(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_to_type(PyObject *self,ScalarType scalarType,c10::optional optional_memory_format)', '    THPVariable_tolist(PyObject *self,PyObject *args)', '    THPVariable_type(PyObject *self,PyObject *args,PyObject *kwargs)', '    TypeError_to_NotImplemented_(PyObject *self,PyObject *args,PyObject *kwargs)', '    $', '    dispatch_is_contiguous(Tensor & self,MemoryFormat memory_format)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\PythonTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\src\\main\\cpp\\pytorch_jni_common.cpp', ['    TensorHybrid'], ['    newAtTensor(facebook::jni::alias_ref jbuffer,facebook::jni::alias_ref jshape,jint jdtype)', '    once', '    _s', '    _s', '    common_registerNatives', '    dict', '    dict', '    list', '    list', '    list', '    list', '    list', '    put(facebook::jni::alias_ref key,facebook::jni::alias_ref value)', '    shapeVec', '    init', '    initHybrid(facebook::jni::alias_ref jTensorThis)', '    newAtTensorFromJTensor(facebook::jni::alias_ref jtensor)', '    newJTensorFromAtTensor(const at::Tensor & input_tensor)', '    JIValueToAtIValue(facebook::jni::alias_ref jivalue)', '    newJIValueFromAtIValue(const at::IValue & ivalue)', '    tensor', '    TensorHybrid(at::Tensor tensor)', '  Static Member Variables', '    is_initialized_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\src\\main\\cpp\\pytorch_jni_common.h', ['    JIValue', '    Trace'], ['    common_registerNatives', '    JIValueToAtIValue(facebook::jni::alias_ref jivalue)', '    newJIValueFromAtIValue(const at::IValue & ivalue)', '    beginSection(const char *name)', '    endSection', '    ensureInit', '    init', '    Trace(const char *name)', '    ~Trace']]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\src\\main\\cpp\\pytorch_jni_jit.cpp', ['    final', '    PytorchJni'], ['    once', '    _s', '    inputs', '    inputs', '    JNI_OnLoad(JavaVM *vm,void *)', '    output', '    output', '    initHybrid(facebook::jni::alias_ref,facebook::jni::alias_ref modelPath)', '    preModuleLoadSetupOnce', '    registerNatives', '    MemoryReadAdapter(const void *data,off_t size)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    ~MemoryReadAdapter', '    no_autograd_guard', '    no_optimizer_guard', '    non_var_guard', '    forward(facebook::jni::alias_ref jinputs)', '    preModuleLoadSetup', '    PytorchJni(facebook::jni::alias_ref modelPath)', '    runMethod(facebook::jni::alias_ref jmethodName,facebook::jni::alias_ref jinputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android\\src\\main\\cpp\\pytorch_jni_lite.cpp', ['    PytorchJni'], ['    inputs', '    inputs', '    JNI_OnLoad(JavaVM *vm,void *)', '    output', '    output', '    initHybrid(facebook::jni::alias_ref,facebook::jni::alias_ref modelPath)', '    registerNatives', '    non_var_guard', '    forward(facebook::jni::alias_ref jinputs)', '    PytorchJni(facebook::jni::alias_ref modelPath)', '    runMethod(facebook::jni::alias_ref jmethodName,facebook::jni::alias_ref jinputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\include\\pytorch_qnnpack.h', [], ['    pytorch_qnnp_create_add_nc_q8(size_t channels,uint8_t a_zero_point,float a_scale,uint8_t b_zero_point,float b_scale,uint8_t sum_zero_point,float sum_scale,uint8_t sum_min,uint8_t sum_max,uint32_t flags,pytorch_qnnp_operator_t *add_out)', '    pytorch_qnnp_create_average_pooling2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *average_pooling_out)', '    pytorch_qnnp_create_channel_shuffle_nc_x8(size_t groups,size_t group_channels,uint32_t flags,pytorch_qnnp_operator_t *channel_shuffle_out)', '    pytorch_qnnp_create_clamp_nc_u8(size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *clamp_out)', '    pytorch_qnnp_create_convolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t kernel_height,uint32_t kernel_width,uint32_t subsampling_height,uint32_t subsampling_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *convolution_out)', '    pytorch_qnnp_create_deconvolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t adjustment_height,uint32_t adjustment_width,uint32_t kernel_height,uint32_t kernel_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *deconvolution_out)', '    pytorch_qnnp_create_fully_connected_nc_q8(size_t input_channels,size_t output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *fully_connected_out)', '    pytorch_qnnp_create_global_average_pooling_nwc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *global_average_pooling_out)', '    pytorch_qnnp_create_leaky_relu_nc_q8(size_t channels,float negative_slope,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *leaky_relu_out)', '    pytorch_qnnp_create_max_pooling2d_nhwc_u8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *max_pooling_out)', '    pytorch_qnnp_create_sigmoid_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *sigmoid_out)', '    pytorch_qnnp_create_softargmax_nc_q8(size_t channels,float input_scale,uint8_t output_zero_point,float output_scale,uint32_t flags,pytorch_qnnp_operator_t *softargmax_out)', '    pytorch_qnnp_create_tanh_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *tanh_out)', '    pytorch_qnnp_deinitialize', '    pytorch_qnnp_delete_operator(pytorch_qnnp_operator_t op)', '    pytorch_qnnp_initialize', '    pytorch_qnnp_run_operator(pytorch_qnnp_operator_t op,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_add_nc_q8(pytorch_qnnp_operator_t add_op,size_t batch_size,const uint8_t *a,size_t a_stride,const uint8_t *b,size_t b_stride,uint8_t *sum,size_t sum_stride)', '    pytorch_qnnp_setup_average_pooling2d_nhwc_q8(pytorch_qnnp_operator_t average_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_channel_shuffle_nc_x8(pytorch_qnnp_operator_t channel_shuffle_op,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_clamp_nc_u8(pytorch_qnnp_operator_t clamp,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_convolution2d_nhwc_q8(pytorch_qnnp_operator_t convolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_deconvolution2d_nhwc_q8(pytorch_qnnp_operator_t deconvolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_fully_connected_nc_q8(pytorch_qnnp_operator_t fully_connected,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_global_average_pooling_nwc_q8(pytorch_qnnp_operator_t global_average_pooling_op,size_t batch_size,size_t width,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_leaky_relu_nc_q8(pytorch_qnnp_operator_t leaky_relu,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_max_pooling2d_nhwc_u8(pytorch_qnnp_operator_t max_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_sigmoid_nc_q8(pytorch_qnnp_operator_t sigmoid,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_softargmax_nc_q8(pytorch_qnnp_operator_t softargmax,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_tanh_nc_q8(pytorch_qnnp_operator_t tanh,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\android\\pytorch_android_torchvision\\src\\main\\cpp\\pytorch_vision_jni.cpp', [], ['    imageYUV420CenterCropToFloatBuffer(JNIEnv *jniEnv,jclass,jobject yBuffer,jint yRowStride,jint yPixelStride,jobject uBuffer,jobject vBuffer,jint uRowStride,jint uvPixelStride,jint imageWidth,jint imageHeight,jint rotateCWDegrees,jint tensorWidth,jint tensorHeight,jfloatArray jnormMeanRGB,jfloatArray jnormStdRGB,jobject outBuffer,jint outOffset)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\q31-neon.c', [], ['    pytorch_qnnp_requantize_q31__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\q31-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\q31-scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\q31-scalar.c', [], ['    pytorch_qnnp_requantize_q31__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\q31-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\q31-sse2.c', [], ['    pytorch_qnnp_requantize_q31__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\q31-sse4.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\q31-sse4.c', [], ['    pytorch_qnnp_requantize_q31__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\q31-ssse3.c', [], ['    pytorch_qnnp_requantize_q31__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\requantization\\q31-ssse3.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8avgpool.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8avgpool.h', [], ['    pytorch_q8avgpool_ukernel_mp8x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_mp8x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8x9__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8x9__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8xm__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8xm__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8conv.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8conv.h', [], ['    pytorch_q8conv_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8conv_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8conv_ukernel_4x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8conv_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8conv_ukernel_8x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8dwconv.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8dwconv.h', [], ['    pytorch_q8dwconv_ukernel_mp8x25__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_mp8x25__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__aarch32_neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8gavgpool.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8gavgpool.h', [], ['    pytorch_q8gavgpool_ukernel_mp8x7p7q__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_mp8x7p7q__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8x7__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8x7__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8xm__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8xm__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\q8gemm.cc', ['    COMPUTE_ROW_SUM_Op', '    Q8GEMM', '    Q8GEMM_L1', '    Q8GEMM_Op', '    Q8GEMM_XZP', '    Q8GEMM_XZP_L1', '    Q8GEMM_XZP_Op'], ['    GemmArguments(benchmark::internal::Benchmark *b)', '    MobileNetV1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8GemmArguments(benchmark::internal::Benchmark *b)', '    SqueezeNetV10GemmArguments(benchmark::internal::Benchmark *b)', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)', '    COMPUTE_ROW_SUM_Op', '    SetUp(const benchmark::State & state)', '    TearDown(benchmark::State & state)', '    a', '    b', '    c', '    k', '    kc', '    kc_', '    kcStride', '    kr', '    kr_', '    mc', '    mc_', '    mr', '    mr_', '    nc', '    nc_', '    ncStride', '    np', '    np_', '    nr', '    nr_', '    Q8GEMM(uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    quantizationParams', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    w', '    w', '    Q8GEMM_L1', '    Q8GEMM_Op', '    SetUp(const benchmark::State & state)', '    aRowSums', '    aRowSums', '    Q8GEMM_XZP(uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    requantizationParams', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    Q8GEMM_XZP_L1', '    Q8GEMM_XZP_Op', '    SetUp(const benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8gemm.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8gemm.h', [], ['    pytorch_q8gemm_dq_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)', '    pytorch_q8gemm_dq_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params *quantization_params)', '    pytorch_q8gemm_dq_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)', '    pytorch_q8gemm_dq_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_2x4c8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_2x4c8__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_3x3c8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_6x4__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_8x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_xzp_ukernel_4x8c2__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params *requantization_params)', '    pytorch_q8gemm_xzp_ukernel_4x8c2__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params [1] requantization_params)', '    pytorch_q8sumrows_ukernel_4x__neon(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *a_sum)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\q8vadd.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\q8vadd.h', [], ['    pytorch_q8vadd_ukernel__neon(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)', '    pytorch_q8vadd_ukernel__sse2(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\q_adaavgpool.cpp', [], ['    adaptive_avg_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeC,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideC,int64_t istrideH,int64_t istrideW)', '    end_index(int out_idx,int out_len,int in_len)', '    get_output_shape(const Tensor & input,IntArrayRef output_size)', '    q_adaptive_avg_pool2d(const Tensor & input,IntArrayRef output_size)', '    quantized_adaptive_avg_pool2d(const at::Tensor & input,IntArrayRef output_size)', '    start_index(int out_idx,int out_len,int in_len)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\q_avgpool.cpp', [], ['    avg_pool2d_out_frame(const Tensor & input,Tensor & output,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    get_kernel(IntArrayRef kernel_size)', '    get_output_shape(const Tensor & input_,int kW,int kH,int dW,int dH,int padW,int padH,bool ceil_mode)', '    get_padding(IntArrayRef padding)', '    get_stride(IntArrayRef stride,int kW,int kH)', '    q_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    quantized_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\q_avgpool3d.cpp', [], ['    get_kernel(IntArrayRef kernel_size)', '    get_output_shape(const Tensor & input_,int kW,int kH,int kD,int dW,int dH,int dD,int padW,int padH,int padD,bool ceil_mode)', '    get_padding(IntArrayRef padding)', '    get_stride(IntArrayRef stride,int kW,int kH,int kD)', '    q_avg_pool3d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    quantized_avg_pool3d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qadd.cpp', ['    final', '    final', '    final', '    final'], ['    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _add_scalar_out(Tensor & out,const Tensor & self,Scalar other)', '    check_inputs(const Tensor & qa,const Tensor & qb)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)', '    operator()(Tensor qa,Scalar b)', '    operator()(Tensor qa,Tensor qb,Tensor out)', '    operator()(Tensor qa,Scalar b,Tensor out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qbatch_norm.cpp', ['    final', '    final'], ['    compute_fused_params(const int64_t channels,const float *weight_data,const float *bias_data,const float *mean_data,const float *var_data,double eps,double input_scale,double output_scale,float *alpha_data,float *beta_data)', '    q_batch_norm3d_impl(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    q_batch_norm_impl(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    quantized_batch_norm(const Tensor & qx,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & var,double eps,double output_scale,int64_t output_zero_point)', '    operator()(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    operator()(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qclamp.cpp', ['    final'], ['    quantized_clamp(const Tensor & qx,optional min,optional max)', '    quantized_clamp_impl(const Tensor & qx,optional min,optional max)', '    quantized_hardtanh(const Tensor & qx,Scalar min,Scalar max)', '    quantized_hardtanh_(Tensor & self,Scalar min,Scalar max)', '    quantized_hardtanh_out(Tensor & result,const Tensor & qx,Scalar min,Scalar max)', '    operator()(Tensor,optional min,optional max)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qconcat.cpp', ['    final', '    final'], ['    is_cat_nhwc_fast_path(const c10::List & qxs,int dim)', '    is_valid_quantization_scheme(const Tensor & t)', '    quantized_cat(TensorList qxs,int64_t dim)', '    quantized_cat_impl(const c10::List & qxs,int64_t dim,double scale,int64_t zero_point)', '    quantized_cat_out(Tensor & out,TensorList qxs,int64_t dim)', '    operator()(const c10::List & qxs,int64_t dim,c10::optional scale,c10::optional zero_point)', '    operator()(const c10::List & qxs,int64_t dim,Tensor out)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qconv.cpp', ['    final'], ['    ConvDimChecks(int64_t act_dims,int64_t stride_dims,int64_t padding_dims,int64_t dilation_dims)', '    operator()(Tensor act,Tensor packed_weight,torch::List stride,torch::List padding,torch::List dilation,int64_t groups,double output_scale,int64_t output_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qconv_prepack.cpp', ['    final'], ['    operator()(Tensor weight,c10::optional bias,torch::List stride,torch::List padding,torch::List dilation,int64_t groups)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qconv_unpack.cpp', ['    final'], ['    Tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qelu.cpp', [], ['    quantized_elu(const Tensor & qx,Scalar alpha,Scalar scale,Scalar input_scale)', '    quantized_elu_(Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    quantized_elu_out(Tensor & result,const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\QEngine.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qhardsigmoid.cpp', [], ['    quantized_hardsigmoid(const Tensor & qx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qhardswish.cpp', [], ['    quantized_hardswish(const Tensor & qx)', '    quantized_hardswish_(Tensor & qx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\qint32.h', [], ['    qint32(int32_t val)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\qint8.h', [], ['    qint8(int8_t val)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear.cpp', ['    final'], ['    operator()(at::Tensor input,at::Tensor packed_weight,double output_scale,int64_t output_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_dynamic.cpp', ['    final', '    final'], ['    operator()(at::Tensor,at::Tensor)', '    operator()(at::Tensor input,at::Tensor packed_weight)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_prepack.cpp', ['    final', '    final'], ['    operator()(at::Tensor weight,c10::optional bias)', '    operator()(at::Tensor weight,c10::optional bias)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_unpack.cpp', ['    final', '    final'], ['    Tensor', '    Tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qmul.cpp', ['    final', '    final', '    final', '    final'], ['    _mul_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _mul_scalar_out(Tensor & out,const Tensor & self,Scalar other)', '    check_inputs(const Tensor & qa,const Tensor & qb)', '    operator()(at::Tensor qa,at::Tensor qb,Tensor out)', '    operator()(Tensor qa,Scalar b)', '    operator()(Tensor qa,Scalar b,Tensor out)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\include\\qnnpack_func.h', ['    final', '    final'], ['    qnnpackConv(const conv_param_t & conv_p,void *packed_weights,const size_t batch_size,const size_t input_height,const size_t input_width,const float input_scale,const uint8_t input_zero_point,const uint8_t *input,const float output_scale,const uint8_t output_zero_point,uint8_t *output,pthreadpool_t threadpool)', '    qnnpackLinear(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t output_zero_point,const float output_scale,const uint8_t output_min,const uint8_t output_max,const uint8_t *input,const size_t input_stride,void *packed_weights,uint8_t *output,const size_t output_stride,pthreadpool_t threadpool)', '    qnnpackLinearDynamic(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *input,const size_t input_stride,void *packed_weights,const float *bias,float *output,const size_t output_stride,pthreadpool_t threadpool)', '    getInputChannels', '    getOutputChannels', '    getOutputChannels', '    getPackedWeights', '    getPackedWeights', '    operator=', '    operator=', '    PackBMatrix(size_t input_channels,size_t output_channels,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias)', '    PackBMatrix', '    PackBMatrix', '    PrePackConvWeights(const conv_param_t & conv_param,const uint8_t *kernel,const int32_t *bias)', '    PrePackConvWeights', '    PrePackConvWeights', '    ~PackBMatrix', '    ~PrePackConvWeights']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack_utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qpool.cpp', ['    final'], ['    check_maxpool2d_params(IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)', '    q_maxpool_2d(Tensor,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,bool ceil_mode)', '    quantized_max_pool2d(const Tensor & qx,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    spatial_dilated_max_pooling(const T *iData,int64_t iC,int64_t iH,int64_t iW,int64_t oH,int64_t oW,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,T *oData)', '    operator()(Tensor,std::vector kernel_size,std::vector stride,std::vector padding,std::vector dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qreduction.cpp', [], ['    quantized_mean_cpu(const Tensor & self,optional dtype)', '    quantized_mean_cpu(const Tensor & self,IntArrayRef dim,bool keepdim,optional dtype)', '    quantized_mean_cpu(const Tensor & self,DimnameList dim,bool keepdim,optional dtype)', '    quantized_mean_out_cpu(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    quantized_mean_out_cpu(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,c10::optional opt_dtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qrelu.cpp', ['    final'], ['    quantized_leaky_relu(const Tensor & self,Scalar negval)', '    quantized_leaky_relu_(Tensor & self,Scalar negval)', '    quantized_leaky_relu_out(Tensor & result,const Tensor & self,Scalar negval)', '    quantized_relu(const Tensor & qx)', '    quantized_relu6(const Tensor & qx)', '    quantized_relu6_(Tensor & qx)', '    quantized_relu_(Tensor & qx)', '    operator()(Tensor,bool inplace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\QScheme.cpp', [], ['    self', '    THPQScheme_init(PyObject *module)', '    THPQScheme_New(at::QScheme qscheme,const std::string & name)', '    THPQScheme_reduce(THPQScheme *self,PyObject *noargs)', '    THPQScheme_repr(THPQScheme *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\QScheme.h', [], ['    THPQScheme_Check(PyObject *obj)', '    THPQScheme_init(PyObject *module)', '    THPQScheme_New(at::QScheme qscheme,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\QScheme.h', ['    QScheme'], ['    toString(QScheme qscheme)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qsigmoid.cpp', [], ['    quantized_sigmoid(const Tensor & qx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qsort.cpp', [], ['    quantized_topk_cpu(const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    quantized_topk_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool largest,bool sorted)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qtanh.cpp', [], ['    quantized_tanh(const Tensor & qx)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\qtensor.cc', [], ['    noexcept']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\QTensor.cpp', [], ['    _choose_qparams_per_tensor(const Tensor & self,bool reduce_range)', '    dequantize_quant(const Tensor & self)', '    dequantize_tensors_quant(TensorList tensors)', '    int_repr_quant(const Tensor & self)', '    make_per_channel_quantized_tensor_cpu(const Tensor & self,const Tensor & scales,const Tensor & zero_points,int64_t axis)', '    make_per_tensor_quantized_tensor_cpu(const Tensor & self,double scale,int64_t zero_point)', '    q_per_channel_axis_quant(const Tensor & self)', '    q_per_channel_scales_quant(const Tensor & self)', '    q_per_channel_zero_points_quant(const Tensor & self)', '    q_scale_quant(const Tensor & self)', '    q_zero_point_quant(const Tensor & self)', '    qscheme_quant(const Tensor & self)', '    quantize_per_channel_cpu(const Tensor & self,const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType dtype)', '    quantize_per_tensor_cpu(const Tensor & self,double scale,int64_t zero_point,ScalarType dtype)', '    quantized_clone(const Tensor & self,c10::optional optional_memory_format)', '    quantized_equal(const Tensor & self,const Tensor & other)', '    set_quantizer_(Tensor & self,ConstQuantizerPtr quantizer)', '    set_storage_quantized_cpu_(Tensor & self,Storage storage,int64_t storage_offset,IntArrayRef sizes,IntArrayRef strides)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\qtensor.h', ['    QTensor'], ['    aligned_size', '    alignment', '    bias', '    canonical_axis_index(int axis_index)', '    data', '    dim32(const int i)', '    dims', '    GetBitAtIndex(const unsigned char bit,const size_t index)', '    is_signed', '    mutable_data', '    nbytes', '    ndim', '    precision', '    QTensor', '    QTensor(at::ArrayRef dims,const unsigned char precision,const bool signbit)', '    Resize(at::ArrayRef dim_source)', '    scale', '    SetBias(const double bias)', '    SetBitAtIndex(const unsigned char bit,const size_t index,const bool value)', '    SetPrecision(const unsigned char precision)', '    SetScale(const double scale)', '    SetSigned(const bool make_signed)', '    size', '    size_from_dim(int k)', '    size_to_dim(int k)', '    sizes', '    ~QTensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\qtensor_serialization.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\qtensor_serialization.h', ['    QTensorDeserializer', '    QTensorSerializer'], ['    context', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const QTensorProto & proto,QTensor *qtensor)', '    QTensorSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    ~QTensorSerializer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\quantized\\QTensorImpl.cpp', [], ['    QTensorImpl(Storage,DispatchKeySet key_set,QuantizerPtr quantizer)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\quantized\\QTensorImpl.h', [], ['    copy_tensor_metadata(const QTensorImpl *src_q_impl,QTensorImpl *dest_q_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    QTensorImpl(Storage,DispatchKeySet key_set,QuantizerPtr quantizer)', '    quantizer', '    set_quantizer_(QuantizerPtr quantizer)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    copy_tensor_metadata']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\qualified_name.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quant_decode_op.cc', ['    GetQuantDecodeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUQuantDecode', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecode', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecodeGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quant_decode_op.h', ['    final', '    final', '    QuantDecodeRunTy'], ['    Decode(const Tensor & codebook,const Tensor & codes,const Tensor *const decoded_grad,Tensor *const output,bool resizeOnly)', '    Decode(codebook_,codes_,gradient_,outDecoded_,resizeOnly_)', '    DecodeGeneral(const Tensor & codebook,const Tensor & codes,const Tensor *gradient,Tensor *outDecoded,bool resizeOnly)', '    Decode(codebook_,codes_,gradient_,outDecoded_,resizeOnly_)', '    ResizeLike', '    hasRun_', '    QuantDecodeGradientOp(Args,...)', '    QuantDecodeOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~QuantDecodeGradientOp', '    ~QuantDecodeOp', '    Id']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\zstd\\quant_decomp_zstd_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUQuantDecompZstd', '    GetMutableData(int type_index,TensorCPU *tensor)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecompZstd', '    Decompress(const TensorProto & compressed,TensorCPU *outDecomp)', '    GetCompressedPtr(const TensorCPU & compressed,size_t *out_size)', '    GetTensorsProto(const TensorCPU & compressed)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\share\\contrib\\zstd\\quant_decomp_zstd_op.h', ['    final'], ['    QuantDecompZstdOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~QuantDecompZstdOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\quant_utils.h', [], ['    ChooseQuantizationParams(float min,float max,int32_t qmin,int32_t qmax,bool preserve_sparsity,bool force_scale_power_of_two,bool reduce_range)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantile_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUQuantile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Quantile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\quantile_op.h', ['    final'], ['    CountLowerEq(const T & thd)', '    DoRunWithType', '    GetRangeFromInputs(T *lo,T *hi)', '    GetSingleArgument', '    QuantileOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\quantization.cpp', ['    FoldConvBatchNorm2dHelper', '    InsertQuantDeQuantHelper', '    ModuleUseDeduper', '    InsertObserversHelper', '    ModuleCloneHelper'], ['    hastensor(Module & m,const char *name)', '    addBiasForConv2dIfNone(Module & module)', '    checkGetQParamsResult(const IValue & qparams)', '    DedupModuleUses(Module & module)', '    extractOptionalBNParams(const script::Module & bn,ConvBNParameters & r)', '    filter_fn', '    Finalize(script::Module & module)', '    findObserverName(Value *v)', '    FoldConvBatchNorm2d(const Module & module)', '    FoldPrepackedWeightIntoModule(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    FoldQuantizeCallIntoBuffer(Module & module,const std::string & method_name)', '    FoldQuantizedPrepackingOps(Module & module)', '    FoldQuantNodesIntoInputsOutputs(std::shared_ptr & graph)', '    insertDeQuantCall(Graph *graph,Value *quantized_val,Value *original_val,const std::vector & uses)', '    InsertObservers(Module & input_module,const std::string & method_name,const QConfigDict & qconfig_dict,bool inplace,bool is_dynamic)', '    InsertPrepackUnpack(std::shared_ptr & graph)', '    InsertPrepackUnpack(Module & module)', '    insertPrepackUnpackForConv(std::shared_ptr & graph)', '    insertPrepackUnpackForLinear(std::shared_ptr & graph)', '    InsertQuantDeQuant(Module & input_module,const std::string & method_name,bool inplace)', '    insertQuantDeQuantCall(Value *self,Node *observer,bool is_per_channel,const std::vector & qparam_names)', '    QuantFusion(std::shared_ptr & graph)', '    replaceConv2dBiasWithGetAttr(Module & module)', '    ReplicateDeQuant(std::shared_ptr & graph)', '    ReplicateQuant(std::shared_ptr & graph)', '    rv', '    swapDeQuant(Block *block)', '    SwapDeQuant(std::shared_ptr & graph)', '    SwapFunctionalLinear(Module & module)', '    SwapFunctionalLinear(std::shared_ptr & graph)', '    toAffine(c10::QScheme qscheme)', '    alwaysRaisesException(Block *block)', '    fillQConfigMap(const Module & module,const QConfigDict & qconfig_dict,ModuleQConfigMap & map,const std::string & key,const c10::optional & parent_qconfig)', '    findChildModule(const Module & module,const std::vector & path)', '    getCallFunctionGraph(Node *n)', '    getGeneralOpTensorInputs(Node *n)', '    getInvokedModule(Module & module,Node *n,Value *self)', '    getModuleAccessPath(Value *instance,Value *self)', '    getObserverModuleFor(Value *v,const QConfig & qconfig)', '    hitGraphInput(Value *value)', '    isAddScalar(Node *n)', '    isAtenFuncNthArg(Value *v,Node *use,const std::string & func_name,int n)', '    isBiasOfConvOrLinear(Value *v)', '    isCallFunctionNthArg(Value *v,Node *use,const std::string & func_name,int n)', '    isFunctionNode(Node *n,const std::vector & call_funcs,const std::vector & aten_funcs)', '    isPerChannel(at::QScheme qscheme)', '    isWeightOfConvOrLinear(Value *v)', '    matchArgPattern(Value *v,const AtenFuncArgs & aten_func_args,const CallFuncArgs & call_func_args)', '    mayRequireObservation(Value *v)', '    nodeQuantizable(Node *n)', '    userDefinedCallFunction(Node *n)', '    toTwoElementIntList(Value *v)', '    type_remap_fn', '    parse_from_str(std::string pattern_string)', '    analyze(Module & module)', '    computeUpdatedConvWeightAndBias(const ConvBNParameters & p)', '    transform', '    tryExtractingConvBNParameters(Module & conv,Module & bn,ConvBNParameters & r)', '    run(Module & module,const std::string & method_name,const Module & linear_params_module,const Module & conv_params_module)', '    run(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    addValuesToDelayObservation(const Module & module,const std::string & method_name)', '    delayObservingValuesInPattern(Graph & graph,const PatternInfo & pattern)', '    fillBoundaryValueMap(Module & module,const std::string & method_name)', '    fillPassThroughValueMap(const std::shared_ptr & graph)', '    fillValueObserverMap(Module & module,const std::string & method_name)', '    getObserverFor(Value *v)', '    preprocess(Module & module,const std::string & method_name)', '    propagateObservedProperty(Value *output,std::unordered_set & block_observed_values)', '    recordObserved(Value *v,Module observer_module,std::unordered_map & values_to_observe,std::unordered_set & block_observed_values)', '    setDynamicFlag(bool is_dynamic_)', '    valueNeedsToBeQuantized(Value *v)', '    checkQScheme(Graph *g,c10::QScheme qscheme)', '    cleanup(Module & module)', '    cleanup(Module & module,Graph *g)', '    collectObserverNodesAndValueToQuantize(Module & module,Value *v)', '    findChildModuleToQuantize(Module & module,Value *child_instance)', '    getInvokedMethods(Module & module,const std::string & method_name)', '    getQSchemeAndQParamVector(script::Module & module,Node *n)', '    InsertQuantDeQuantHelper', '    quantizeTensors(Module & module,Graph *g,Value *self)', '    run(Module & module,const std::string & method_name)', '    addChildModule(Module & module,const Module & child_module,const std::vector & path)', '    dedup', '    dedupModuleUses', '    findModuleUses(Graph *graph)', '    ModuleUseDeduper(Module & module)', '    getInvokedMethods(Module & module,const std::string & method_name)', '    insertObserverFor(Value *v,Module & module,const Module & observer_module,NameModuleVector & observer_name_and_modules)', '    InsertObserversHelper(const ModuleQConfigMap & map)', '    isObserved(Value *v,const std::unordered_set & block_observed_values)', '    clone(const Module & module,const ModuleQConfigMap & module_qconfig_map)', '    clone_impl(const Module & module,const ModuleQConfigMap & module_qconfig_map,std::unordered_map & type_remap)', '    clone_method(const Module & source,Module & target,const Function & method,const ModuleQConfigMap & module_qconfig_map,const std::unordered_map & type_remap)', '    remapTypes(Block *block,Value *self,const Module & source,Module & target,const ModuleQConfigMap & module_qconfig_map,const std::function & type_remap_fn)', '    remapTypes(Graph *graph,const Module & source,Module & target,const ModuleQConfigMap & module_qconfig_map,const std::function & type_remap_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\quantization.h', [], ['    DedupModuleUses(Module & module)', '    FoldConvBatchNorm2d(const Module & module)', '    FoldPrepackedWeightIntoModule(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    FoldQuantizeCallIntoBuffer(Module & module,const std::string & method_name)', '    FoldQuantizedPrepackingOps(Module & module)', '    FoldQuantNodesIntoInputsOutputs(std::shared_ptr & graph)', '    InsertObservers(Module & module,const std::string & method_name,const QConfigDict & qconfig_dict,bool inplace,bool is_dynamic)', '    InsertPrepackUnpack(std::shared_ptr & graph)', '    InsertPrepackUnpack(Module & module)', '    InsertQuantDeQuant(Module & module,const std::string & method_name,bool inplace)', '    QuantFusion(std::shared_ptr & graph)', '    ReplicateDeQuant(std::shared_ptr & graph)', '    ReplicateQuant(std::shared_ptr & graph)', '    SwapDeQuant(std::shared_ptr & graph)', '    SwapFunctionalLinear(std::shared_ptr & graph)', '    SwapFunctionalLinear(Module & module)', '    has_value', '    operator()(const torch::jit::Module & arg)', '    _ivalue', '    operator()(const c10::optional & qconfig_opt)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\quantization_error_minimization.h', ['    L1ErrorMinimization', '    NormMinimization', '    P99', '    QuantizationErrorMinimization'], ['    L1ErrorMinimization', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    NonlinearQuantizationParamsSearch(const Histogram & hist,bool preserve_sparsity,int precision)', '    NormMinimization(Kind kind)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    P99(float p99_threshold)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    ~QuantizationErrorMinimization']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\quantization_patterns.h', [], ['    quant_fusion_pattern_and_replacements']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\quantize_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Quantize', '    QuantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\quantize_dnnlowp_op.h', ['    final'], ['    arguments_parsed_', '    QuantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\quantized_ops.cpp', ['    final'], ['    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    QHelper(Tensor qa)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\quantized_ops.h', [], ['    operator=', '    qadaptive_avg_pool2d_nhwc_stub', '    qadaptive_avg_pool2d_nhwc_stub', '    operator=', '    qadd_relu_stub', '    qadd_relu_stub', '    operator=', '    qadd_scalar_relu_stub', '    qadd_scalar_relu_stub', '    operator=', '    qadd_scalar_stub', '    qadd_scalar_stub', '    operator=', '    qadd_stub', '    qadd_stub', '    operator=', '    qavg_pool2d_nhwc_stub', '    qavg_pool2d_nhwc_stub', '    operator=', '    qavg_pool3d_nhwc_stub', '    qavg_pool3d_nhwc_stub', '    operator=', '    qbatch_norm_relu_stub', '    qbatch_norm_relu_stub', '    operator=', '    qbatch_norm_stub', '    qbatch_norm_stub', '    operator=', '    qcat_nhwc_stub', '    qcat_nhwc_stub', '    operator=', '    qcat_relu_nhwc_stub', '    qcat_relu_nhwc_stub', '    operator=', '    qclamp_stub', '    qclamp_stub', '    operator=', '    qelu_stub', '    qelu_stub', '    operator=', '    qhardsigmoid_stub', '    qhardsigmoid_stub', '    operator=', '    qhardswish_stub', '    qhardswish_stub', '    operator=', '    qmaxpool_2d_nhwc_stub', '    qmaxpool_2d_nhwc_stub', '    operator=', '    qmul_relu_stub', '    qmul_relu_stub', '    operator=', '    qmul_stub', '    qmul_stub', '    operator=', '    qrelu6_stub', '    qrelu6_stub', '    operator=', '    qrelu_leaky_stub', '    qrelu_leaky_stub', '    operator=', '    qrelu_stub', '    qrelu_stub', '    operator=', '    qsigmoid_stub', '    qsigmoid_stub', '    operator=', '    qtanh_stub', '    qtanh_stub', '    operator=', '    qtopk_stub', '    qtopk_stub', '    operator=', '    qupsample_bilinear2d_nhwc_stub', '    qupsample_bilinear2d_nhwc_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\quantized_ops.h', [], ['    callOp(const c10::OperatorHandle & op,Args,...)', '    callOp(const char *func_name,const char *overload_name,Args,...)', '    makeStack(Inputs,...)', '    has_value', '    value', '    singleton']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\quantized_test.cpp', [], ['    qx_expect', '    TEST(TestQTensor,QuantDequantAPIs)', '    TEST(TestQTensor,RoundingMode)', '    TEST(TestQTensor,Item)', '    TEST(TestQTensor,EmptyQuantized)', '    TEST(TestQTensor,EmptyPerchannelQuantized)', '    x_values']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\QuantizedLinear.cpp', [], ['    fbgemm_is_cpu_supported', '    fbgemm_linear_fp16_weight(const Tensor & input,const Tensor & packed_weight,const Tensor & bias)', '    fbgemm_linear_fp16_weight_fp32_activation(const Tensor & input,const Tensor & packed_weight,const Tensor & bias)', '    fbgemm_linear_int8_weight(const Tensor &,const Tensor &,const Tensor &,const Tensor &,Scalar,Scalar,const Tensor &)', '    fbgemm_linear_int8_weight_fp32_activation(const Tensor &,const Tensor &,const Tensor &,const Tensor &,Scalar,Scalar,const Tensor &)', '    fbgemm_linear_quantize_weight(const Tensor &)', '    fbgemm_pack_gemm_matrix_fp16(const Tensor & weight)', '    fbgemm_pack_quantized_matrix(const Tensor &)', '    fbgemm_pack_quantized_matrix(const Tensor &,int64_t,int64_t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\kernels\\QuantizedOpKernels.cpp', [], ['    leaky_qrelu_out_kernel(Tensor & out,const Tensor & qx,Scalar negval_)', '    fake_quant_per_channel_cpu(TensorIterator & iter,int64_t quant_min,int64_t quant_max)', '    do_avg_pool_on_AVX2(T::underlying *i_p,T::underlying *o_p,int64_t & c,int64_t channel_size,int64_t channel_multiplier,int32_t input_zero_point_m_size,int32_t output_zero_point,float multiplier,int64_t dstart,int64_t dend,int64_t hstart,int64_t hend,int64_t wstart,int64_t wend,int64_t stride_C,int64_t stride_D,int64_t stride_H,int64_t stride_W)', '    do_quantized_bilinear_on_AVX2(const T::underlying *& pos1,T::underlying *& pos2,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t channels,int32_t output_zero_point,int32_t input_zero_point,float inverse_scale,const float h0lambda,const float h1lambda,const float w0lambda,const float w1lambda,const int64_t h1p,const int64_t w1p)', '    fake_quantize_grad_tensor_kernel(Tensor & input_grad,const Tensor & input,const Tensor & output_grad,float sc,int64_t z_point,int64_t quant_min,int64_t quant_max)', '    fake_quantize_tensor_kernel(Tensor & output,const Tensor & input,float sc,int64_t z_point,int64_t quant_min,int64_t quant_max)', '    q_batch_norm_kernel(int64_t N,int64_t C,int64_t HxW,int64_t in_zero_point,int64_t out_zero_point,const Tensor & input,const Tensor & a,const Tensor & b,Tensor & output)', '    qadaptive_avg_pool2d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t sizeC,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideC,int64_t istrideH,int64_t istrideW)', '    qadd_kernel(Tensor & out,const Tensor & self,const Tensor & other)', '    qadd_scalar_kernel(Tensor & out,const Tensor & self,Scalar other)', '    qavg_pool2d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    qavg_pool3d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t inputDepth,int64_t outputWidth,int64_t outputHeight,int64_t outputDepth,int kW,int kH,int kD,int dW,int dH,int dD,int padW,int padH,int padD,bool count_include_pad,c10::optional divisor_override)', '    qcat_nhwc_kernel(const c10::List & qxs,int64_t dim,double scale,int64_t zero_point)', '    qclamp_kernel(const Tensor & qx,Scalar min_scalar,Scalar max_scalar,Tensor & qy)', '    qelu_kernel(const Tensor & qx,Scalar alpha,Tensor & qy)', '    qhardsigmoid_kernel(const Tensor & qx,Tensor & qy)', '    qhardswish_kernel(const Tensor & qx,Tensor & qy)', '    qmaxpool_2d_nhwc_kernel(const Tensor & qx,int64_t iC,int64_t iH,int64_t iW,int64_t oH,int64_t oW,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,Tensor & qy)', '    qmul_kernel(Tensor & out,const Tensor & self,const Tensor & other)', '    qrelu6_kernel(const Tensor & qx,Tensor & qy)', '    qrelu_kernel(const Tensor & qx,Tensor & qy)', '    qsigmoid_kernel(const Tensor & qx,Tensor & qy)', '    qtanh_kernel(const Tensor & qx,Tensor & qy)', '    qtopk_kernel(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    qupsample_bilinear2d_nhwc_kernel(Tensor & output,const Tensor & input,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    fake_quant_grad_per_channel_cpu(TensorIterator & iter,int64_t quant_min,int64_t quant_max)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\quantized\\Quantizer.cpp', [], ['    checkFloatCPUTensor(std::string fn_name,Tensor t)', '    checkQuantizedCPUTensor(std::string fn_name,Tensor t)', '    checkZeroPoint(std::string fn_name,int64_t zero_point)', '    checkZeroPoints(std::string fn_name,Tensor zero_points)', '    dequantize_tensor(Tensor qtensor,Tensor rtensor,double scale,int64_t zero_point)', '    dequantize_tensor_per_channel_affine(Tensor qtensor,Tensor rtensor,Tensor scales,Tensor zero_points,int64_t axis)', '    dequantize_val(double scale,int64_t zero_point,T value)', '    get_qtensorimpl(const Tensor & self)', '    make_per_channel_affine_quantizer(const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType scalar_type)', '    make_per_tensor_affine_quantizer(double scale,int64_t zero_point,ScalarType scalar_type)', '    new_qtensor_cpu(IntArrayRef sizes,const TensorOptions & options,QuantizerPtr quantizer)', '    quantize_tensor(Tensor rtensor,Tensor qtensor,double scale,int64_t zero_point)', '    quantize_tensor_per_channel_affine(Tensor rtensor,Tensor qtensor,Tensor scales,Tensor zero_points,int64_t axis)', '    quantize_val(double scale,int64_t zero_point,float value)', '    quantize_val_arm(const float scale,const int32_t zero_point,const float value)', '    quantize_vec(double scale,int64_t zero_point,const float *src,T *dst,size_t count)', '    requantize_from_int(double multiplier,int64_t zero_point,int64_t src)', '    requantize_val(double src_scale,int64_t src_zero_point,double dst_scale,int64_t dst_zero_point,SRC_T src)', '    Round(const T x)', '    dequantize(Tensor qtensor)', '    quantize(Tensor rtensor)', '    dequantize(Tensor qtensor)', '    quantize(Tensor rtensor)', '    ~Quantizer', '    quantizer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\quantized\\Quantizer.h', [], ['    dequantize_tensor(Tensor qtensor,Tensor rtensor,double scale,int64_t zero_point)', '    dequantize_val(double scale,int64_t zero_point,T value)', '    dequantize_vec(double scale,int64_t zero_point,const T *src,float *dst,size_t count)', '    get_qtensorimpl(const Tensor & self)', '    make_per_channel_affine_quantizer(const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType scalar_type)', '    make_per_tensor_affine_quantizer(double scale,int64_t zero_point,ScalarType scalar_type)', '    new_qtensor_cpu(IntArrayRef sizes,const TensorOptions & options,QuantizerPtr quantizer)', '    quantize_tensor(Tensor rtensor,Tensor qtensor,double scale,int64_t zero_point)', '    quantize_val(double scale,int64_t zero_point,float value)', '    quantize_vec(double scale,int64_t zero_point,const float *src,T *dst,size_t count)', '    requantize_from_int(double multiplier,int64_t zero_point,int64_t src)', '    requantize_val(double src_scale,int64_t src_zero_point,double dst_scale,int64_t dst_zero_point,SRC_T src)', '    AffineQuantizer(ScalarType scalar_type)', '    NonUniformQuantizer(ScalarType scalar_type)', '    axis', '    dequantize(Tensor qtensor)', '    equalTo(QuantizerPtr other)', '    PerChannelAffineQuantizer(ScalarType scalar_type,Tensor scales,Tensor zero_points,int64_t axis)', '    qscheme', '    quantize(Tensor rtensor)', '    scales', '    zero_points', '    dequantize(Tensor qtensor)', '    equalTo(QuantizerPtr other)', '    PerTensorAffineQuantizer(ScalarType scalar_type,double scale,int64_t zero_point)', '    qscheme', '    quantize(Tensor rtensor)', '    scale', '    zero_point', '    dequantize(Tensor t)', '    equalTo(QuantizerPtr other)', '    intrusive_from_this', '    qscheme', '    quantize(Tensor t)', '    Quantizer(ScalarType scalar_type)', '    scalar_type', '    ~Quantizer', '    equal', '    UniformQuantizer(ScalarType scalar_type)', '    reclaim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\detail\\queue.h', ['    Queue'], ['    deprecated_AT_ASSERT', '    str(,,,,,::c10::str __VA_ARGS__)', '    clear', '    pop(optional timeout)', '    push(T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\queue_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCloseBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSafeDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSafeEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSampleDequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloseBlobsQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateBlobsQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnqueueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SafeDequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SafeEnqueueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSampleDequeueBlobs', '    noexcept']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\queue_ops.cc', ['    final', '    final'], ['    IDEEPCreateBlobsQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSafeEnqueueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ws_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\queue_ops.h', ['    final', '    final', '    final', '    final', '    final', '    final', '    final'], ['    CreateBlobsQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    DequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    dequeueMany(std::shared_ptr & queue)', '    dequeueOne(std::shared_ptr & queue)', '    Outputs', '    OutputSize', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SafeDequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    WeightedSampleDequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    ws_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\queue_ops_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDACloseBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CUDADequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDAEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDASafeDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDASafeEnqueueBlobs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\quint8.h', [], ['    quint8(uint8_t val)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qupsample_bilinear2d.cpp', [], ['    upsample_bilinear2d_out_frame(Tensor & output,const Tensor & input,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_bilinear2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qupsample_nearest2d.cpp', [], ['    upsample_nearest2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_frame_nhwc(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_nearest2d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qupsample_nearest3d.cpp', [], ['    upsample_nearest3d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_frame_nhwc(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_nearest3d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\data\\samplers\\random.cpp', [], ['    index', '    load(serialize::InputArchive & archive)', '    RandomSampler(int64_t size,Dtype index_dtype)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\random.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Range.cpp', [], ['    operator<<(std::ostream & out,const Range & range)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Range.h', [], ['    operator<<(std::ostream & out,const Range & range)', '    operator/(int64_t divisor)', '    Range(int64_t begin,int64_t end)', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\RangeFactories.cpp', [], ['    arange_cpu_out(Tensor & result,Scalar start,Scalar end,Scalar step)', '    linspace_cpu_out(Tensor & result,Scalar start,Scalar end,int64_t steps)', '    logspace_cpu_out(Tensor & result,Scalar start,Scalar end,int64_t steps,double base)', '    range_cpu_out(Tensor & result,Scalar start,Scalar end,Scalar step)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rank_loss_op.cc', ['    GetPairWiseLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUPairWiseLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUPairWiseLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PairWiseLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PairWiseLossGradient', '    logLogit(T x)', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rank_loss_op.h', ['    final', '    final'], ['    PairWiseLossGradientOp(Args,...)', '    PairWiseLossOp(Args,...)', '    RunOnDevice', '    ~PairWiseLossGradientOp', '    ~PairWiseLossOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\read_adapter_interface.cc', [], ['    ~ReadAdapterInterface']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\serialize\\read_adapter_interface.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\rebatching_queue.cc', [], ['    concat(CPUContext & context,const std::vector,const std::vector & outputs)', '    canRead', '    canWrite', '    capacity', '    close', '    dequeue(CPUContext & context,size_t numElements,const std::vector & outputs)', '    enqueue(std::vector)', '    enqueueMany(CPUContext & context,const std::vector & inputs)', '    enqueueOne(CPUContext &,const std::vector & inputs)', '    isClosed', '    numBlobs', '    RebatchingQueue(size_t capacity,size_t numBlobs)', '    ~RebatchingQueue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\rebatching_queue.h', ['    RebatchingQueue'], ['    canRead', '    canWrite', '    capacity', '    close', '    dequeue(CPUContext & context,size_t numElements,const std::vector & outputs)', '    enqueue(std::vector)', '    enqueueMany(CPUContext & context,const std::vector & inputs)', '    enqueueOne(CPUContext & context,const std::vector & inputs)', '    head_', '    isClosed', '    isClosed_', '    numBlobs', '    RebatchingQueue(size_t capacity,size_t numBlobs)', '    tail_', '    ~RebatchingQueue']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\rebatching_queue_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCloseRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUDequeueRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnqueueRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloseRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DequeueRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnqueueRebatchingQueue', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\queue\\rebatching_queue_ops.h', ['    CloseRebatchingQueueOp', '    CreateRebatchingQueueOp', '    DequeueRebatchingQueueOp', '    EnqueueRebatchingQueueOp'], ['    CloseRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    CreateRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    DequeueRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    EnqueueRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reciprocal_gradient_op.cc', ['    GetReciprocalGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReciprocalGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reciprocal_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReciprocal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reciprocal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReciprocalGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reciprocal_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\record_function.cpp', ['    CallbackManager'], ['    getSamplingProbability', '    hasCallbacks', '    hasNonSampledCallbacks', '    manager', '    needsInputs', '    popCallback', '    pushCallback(RecordFunctionCallback start,RecordFunctionCallback end,bool needs_inputs,bool sampled)', '    runBeforeCallbacks(RecordFunction *rf,const std::string & funcName)', '    setSamplingProbability(double prob)', '    shouldRunSampledCallbacks', '    sample_zero_one', '    _setCurrent', '    before(const char *name,int64_t sequence_nr)', '    before(std::string name,int64_t sequence_nr)', '    before(Node *fn,int64_t sequence_nr)', '    current', '    end', '    getCurrentThreadId', '    processCallbacks', '    ~RecordFunction', '    getSamplingProbability', '    hasCallbacks', '    hasNonSampledCallbacks', '    needsInputs', '    popCallback', '    pushCallback(RecordFunctionCallback start,RecordFunctionCallback end,bool needs_inputs,bool sampled)', '    setSamplingProbability(double prob)', '    shouldRunSampledCallbacks']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\record_function.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\record_function_ops.cpp', [], ['    record_function_enter(const std::string & name)', '    record_function_exit(const at::Tensor & handle)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_blob_fetcher_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetworkBlobFetcher', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetworkBlobFetcher']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_blob_fetcher_op.h', ['    final'], ['    copy(blob_names_vector,blob_names_vector,output)', '    GetSingleArgument', '    RecurrentNetworkBlobFetcherOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike', '    LocalBlobs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_blob_fetcher_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDARecurrentNetworkBlobFetcher']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_executor.cc', [], ['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper rnn_args)', '    _Exec', '    Run(int T)', '    RunBackwards(int T)', '    RunOp(OpTask job,int)', '    WorkerFunction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_executor.h', ['    RecurrentNetworkExecutorBase', '    ThreadedRecurrentNetworkExecutor'], ['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper rnn_args)', '    add_race_conflict_dependencies(int opidx,std::vector & rnn_ops,std::unordered_set *dep_ops)', '    AnalyzeOps', '    CalculateInternalDependencies', '    EnsureTimestepInitialized(int t,Workspace *ws,const std::vector)', '    has_input(std::string x,int opidx)', '    ignoreLinkDependencies', '    infer_dependencies(int start_i,std::unordered_set outputs,std::vector & rnn_ops,std::unordered_set *dep_ops)', '    NumObserversStepNet', '    op_deps(int i)', '    PrintInfo(int t)', '    RecurrentNetworkExecutorBase(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    Run(int T)', '    RunBackwards(int T)', '    SetMaxParallelTimesteps(int p)', '    ~RecurrentNetworkExecutorBase', '    _Exec', '    _ExecRange(int from,int to)', '    ignoreLinkDependencies', '    Run(int T)', '    RunBackwards(int T)', '    RunOp(OpTask job,int)', '    setNumThreads(int n)', '    ThreadedRecurrentNetworkExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    WorkerFunction', '    ~ThreadedRecurrentNetworkExecutor', '    CreateBlob', '    GetBlob']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_executor_gpu.cc', [], ['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper arg_helper)', '    _ExecRange(int from,int to)', '    Run(int T)', '    RunBackwards(int T)', '    ~CUDARecurrentNetworkExecutor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_executor_gpu.h', ['    CUDARecurrentNetworkExecutor'], ['    _ExecRange(int from,int to)', '    AnalyzeOps', '    CUDARecurrentNetworkExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    ignoreLinkDependencies', '    Run(int T)', '    RunBackwards(int T)', '    setMaxStreams(int n)', '    ~CUDARecurrentNetworkExecutor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_executor_incl.h', [], ['    backward', '    forward', '    OpTask', '    OpTask(int _timestep,int _op_idx,int _T,int _direction)', '    RNNNetOperator(const OperatorDef & def,int order)', '    RNNNetOperator(const RNNNetOperator & x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_op.cc', ['    C10FlagParser_caffe2_rnn_executor'], ['    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetwork', '    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetworkGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUrnn_internal_accumulate_gradient_input', '    CAFFE_ANONYMOUS_VARIABLE_CPUrnn_internal_apply_link', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetwork', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetworkGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_rnn_internal_accumulate_gradient_input', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_rnn_internal_apply_link', '    AddApplyLinkOps(const vector & links,std::string timestep,const DeviceOption & device_option,NetDef *netdef)', '    extractLinks(OperatorBase *op,const std::string & internalArg,const std::string & externalArg,const std::string & offsetArg,const std::string & windowArg,std::vector *links)', '    extractNetDef(const OperatorDef & op,const std::string & argName)', '    GetRecurrentMapping(const std::vector & links,bool backward)', '    PrependOps(std::vector ops,NetDef *netdef)', '    C10FlagParser_caffe2_rnn_executor(const std::string & content)', '    GetGradientDefs', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_network_op.h', ['    AccumulateInputGradientOp', '    final', '    final', '    RNNApplyLinkOp'], ['    accumulateFinalInputGradients', '    AddApplyLinkOps(const vector & links,std::string timestep,const DeviceOption & device_option,NetDef *netdef)', '    applyOffsetAlias(const OffsetAlias & oc,Workspace *ws,Context *)', '    extractLinks(OperatorBase *op,const std::string & internalArg,const std::string & externalArg,const std::string & offsetArg,const std::string & windowArg,std::vector *links)', '    extractNetDef(const OperatorDef & op,const std::string & argName)', '    GetRecurrentMapping(const std::vector & links,bool backward)', '    initializeRecurrentInput(const RecurrentInput & rc,int32_t seqLen,int32_t batchSize,Workspace *ws,Context *context)', '    PrependOps(std::vector ops,NetDef *netdef)', '    repeatCopy(size_t repeat_n,size_t n,const T *src,T *dst,Context *context)', '    UpdateTimestepBlob(Workspace *ws,std::string blob_name,int t)', '    AccumulateInputGradientOp(Args,...)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    offset', '    window', '    offset', '    AddGradientInputAccumulationOps(const OperatorDef & operator_def)', '    AddParamGradientAccumulationOps(const OperatorDef & operator_def)', '    constructAliases', '    constructLinks', '    constructLinks', '    constructParams(const OperatorDef & operator_def)', '    constructRecurrentGradients(const OperatorDef & operator_def)', '    constructRecurrentInputs(const OperatorDef & operator_def,Workspace *sharedWs)', '    CreateSharedBlobs(const std::shared_ptr & step0Ws,Workspace *sharedBlobsWs)', '    debug_def', '    DoRunWithType', '    DoRunWithType', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    initializeBlobsToRecomputeOnBackward(Workspace *sharedBlobsWs)', '    InitializeExecutor(const OperatorDef & operator_def)', '    InitializeExecutor(const OperatorDef & operator_def)', '    input', '    NumObservers', '    numSequences_', '    output', '    RecurrentNetworkGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentNetworkOp(const OperatorDef & operator_def,Workspace *ws)', '    remappedLink(const detail::Link & link)', '    remappedName(std::string blob_name)', '    renameOpInputOutput(std::string from_name,std::string to_name)', '    RunOnDevice', '    RunOnDevice', '    DoRunWithType', '    GetSingleArgument', '    RNNApplyLinkOp(Args,...)', '    RunOnDevice', '    Add']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_op_cudnn.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Recurrent', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentParamGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentParamSet', '    dim', '    array', '    stride', '    vector', '    TensorDescriptors(size_t n,const std::vector & dim,const std::vector & stride)', '    ~TensorDescriptors', '    initialize(const Tensor & input,Tensor *dropoutStates,Tensor *output,Tensor *hiddenOutput,Tensor *cellOutput)', '    ~RecurrentBaseOp', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\recurrent_op_cudnn.h', ['    TensorDescriptors', '    RecurrentBaseOp', '    RecurrentGradientOp', '    RecurrentOp', '    RecurrentParamAccessOp'], ['    descs', '    TensorDescriptors(size_t n,const std::vector & dim,const std::vector & stride)', '    ~TensorDescriptors', '    initialize(const Tensor & input,Tensor *dropoutStates,Tensor *output,Tensor *hiddenOutput,Tensor *cellOutput)', '    RecurrentBaseOp(Args,...)', '    ~RecurrentBaseOp', '    RecurrentGradientOp(Args,...)', '    RunOnDevice', '    RecurrentOp(Args,...)', '    RunOnDevice', '    RecurrentParamAccessOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rnn\\hip\\recurrent_op_miopen.h', ['    TensorDescriptors', '    RecurrentBaseOp', '    RecurrentGradientOp', '    RecurrentOp', '    RecurrentParamAccessOp'], ['    descs', '    RecurrentGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentParamAccessOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\functions\\recvrpc_backward.cpp', [], ['    apply(variable_list)', '    RecvRpcBackward(const AutogradMetadata & autogradMetadata,ContextPtr autogradContext,rpc::worker_id_t fromWorkerId)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\functions\\recvrpc_backward.h', ['    RecvRpcBackward'], ['    apply(torch::autograd::variable_list)', '    RecvRpcBackward(const AutogradMetadata & autogradMetadata,std::shared_ptr autogradContext,rpc::worker_id_t fromWorkerId)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\redis_store_handler.cc', [], ['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    compoundKey(const std::string & name)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    RedisStoreHandler(std::string & host,int port,std::string & prefix)', '    set(const std::string & name,const std::string & data)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~RedisStoreHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\redis_store_handler.h', ['    RedisStoreHandler'], ['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    compoundKey(const std::string & name)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    RedisStoreHandler(std::string & host,int port,std::string & prefix)', '    set(const std::string & name,const std::string & data)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~RedisStoreHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\redis_store_handler_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURedisStoreHandlerCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RedisStoreHandlerCreate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\redis_store_handler_op.h', ['    final'], ['    RedisStoreHandlerCreateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\redis_store_handler_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDARedisStoreHandlerCreate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\reduce.cc', [], ['    BothEndsMoments(const int M,const int N,const int K,const T *X,T *mean,T *var)', '    BothEndsReduceL1(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceL2(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *)', '    BothEndsReduceMax(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceMean(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceMin(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceSum(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseMoments(const int rows,const int cols,const T *X,T *mean,T *var)', '    ColwiseReduceL1(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceL2(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    ColwiseReduceMax(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceMean(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceMin(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceSum(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    Moments(const int ndim,const int *X_dims,const int *Y_dims,const float *X,float *mean,float *var,CPUContext *context)', '    Moments(const int ndim,const int *X_dims,const int *Y_dims,const double *X,double *mean,double *var,CPUContext *context)', '    MomentsImpl(const int ndim,const int *X_dims,const int *Y_dims,const T *X,T *mean,T *var,CPUContext *)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceL1Impl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceL2Impl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMax(const int N,const float *X,float *Y,Tensor *,CPUContext *)', '    ReduceMax(const int N,const std::int32_t *X,std::int32_t *Y,Tensor *,CPUContext *)', '    ReduceMax(const int N,const std::int64_t *X,std::int64_t *Y,Tensor *,CPUContext *)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceMaxImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMeanImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMin(const int N,const float *X,float *Y,Tensor *,CPUContext *)', '    ReduceMin(const int N,const std::int32_t *X,std::int32_t *Y,Tensor *,CPUContext *)', '    ReduceMin(const int N,const std::int64_t *X,std::int64_t *Y,Tensor *,CPUContext *)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceMinImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceSumImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceTensorImpl(const int ndim,const int *X_dims,const int *Y_dims,const Reducer & reducer,const T init,const T *X,T *Y,CPUContext *context)', '    RowwiseMoments(const int rows,const int cols,const T *X,T *mean,T *var)', '    RowwiseReduceL1(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceL1(const int rows,const int cols,const float alpha,const float *X,float *Y,CPUContext *)', '    RowwiseReduceL1(const int rows,const int cols,const double alpha,const double *X,double *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const float alpha,const float *X,float *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const double alpha,const double *X,double *Y,CPUContext *)', '    RowwiseReduceMax(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceMean(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceMin(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceSum(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\Reduce.h', [], ['    for_each_in_tuple(const std::tuple & t,const TensorIterator & iter,const int num_outputs)', '    is_contiguous_reduction(const int64_t *strides)', '    is_outer_reduction(const int64_t *strides)', '    reduction128(char **data,int64_t n,int64_t stride,func_t op,vec_func_t vop,bool reduce)', '    set_result(const int index,const res_t result,const TensorIterator & iter,const int num_outputs)', '    set_results(const res_t result,const TensorIterator & iter,const int num_outputs)', '    UNARY_OUTER_LOOP(char *[2] data,const int64_t [2] strides,int64_t n,F f)', '    vectorized_inner_reduction(char **data,int64_t n,func_t op,vec_func_t vop)', '    vectorized_outer_reduction(char **data,int64_t inner_stride,int64_t size0,int64_t size1,func_t op,vec_func_t vop)', '    set_results(const std::tuple & result,const TensorIterator & iter,const int num_outputs)', '    set_result(i,std::get,iter,num_outputs)', '    UNARY_OUTER_LOOP(data,step,remaining,[],[0] data,[1] data,,inner_stride)', '    binary_kernel_reduce(TensorIterator & iter,ops_t ops,init_t init)', '    binary_kernel_reduce_vec(TensorIterator & iter,func_t op,vec_func_t vop,double ident)', '    UNARY_OUTER_LOOP(data,outer_strides,size1,[],data [0],data [1],strides [0],strides [1])', '    foreach_reduced_elt', '    noutputs', '    output', '    parallel_reduce']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\reduce.h', [], ['    Moments(const int ndims,const int *X_dims,const int *Y_dims,const T *X,T *mean,T *var,Context *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMax(const int N,const T *X,T *y,Tensor *scratch_ptr,Context *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMin(const int N,const T *X,T *y,Tensor *scratch_ptr,Context *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_front_back_max_ops.cc', ['    GetReduceBackMaxGradient', '    GetReduceFrontMaxGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMaxGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    Compute(int rows,int cols,const float *data,const int32_t *lengths_data,float *out_data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_front_back_max_ops.h', ['    final', '    final'], ['    Compute(int rows,int cols,const float *data,const int32_t *lengths_data,float *out_data)', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    GetSingleArgument', '    MaxReduceDimsGradientOp(Args,...)', '    MaxReduceDimsOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_front_back_mean_ops.cc', ['    GetReduceBackMeanGradient', '    GetReduceFrontMeanGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMeanGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_front_back_sum_mean_ops.h', ['    final', '    final'], ['    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    shape_', '    SumReduceDimsGradientOp(Args,...)', '    SumReduceDimsOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_front_back_sum_ops.cc', ['    GetReduceBackSumGradient', '    GetReduceFrontSumGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontSumGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_ops.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL1', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL1Gradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL2', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL2Gradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMin', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMinGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL1Gradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL2Gradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceSumGradient', '    ComputeReduceMinMaxGradient(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data)', '    GetGradientDefs', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduce_ops.h', ['    final', '    final'], ['    DoRunWithType', '    DoRunWithType', '    ReduceGradientOp(Args,...)', '    ReduceOp(Args,...)', '    reducer_', '    reducer_', '    RunOnDevice', '    RunOnDevice', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *,const T *,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *,const T *,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\reduce_ops_test.cpp', [], ['    dtype', '    TEST(ReduceOpsTest,MaxValuesAndMinValues)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\reduce_scatter_ops.cc', [], ['    initializeHalvingDoubling']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\reduce_scatter_ops.h', ['    final'], ['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    initialize', '    initializeHalvingDoubling', '    ReduceScatterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    update(GlooParameters & params)', '    ~ReduceScatterOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReduceAllOps.cpp', [], ['    max(const Tensor & self)', '    min(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReduceAllOps.h', [], ['    max_all_stub', '    max_all_stub', '    operator=', '    min_all_stub', '    min_all_stub', '    operator=']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\ReduceAllOpsKernel.cpp', [], ['    min_all_kernel_impl(Tensor & result,const Tensor & input)', '    max_all_kernel_impl(Tensor & result,const Tensor & input)', '    reduce_all_impl(Tensor & output,const Tensor & input,const scalar_t ident_v,func_t op)', '    reduce_all_impl_vec(Tensor & output,const Tensor & input,const scalar_t ident_v,func_t op,vec_func_t vop)', '    result', '    result']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReduceOps.cpp', [], ['    _norm(const Tensor & self,Scalar p)', '    allocate_reduction_result(Tensor & result,const Tensor & self,DimMask mask,bool keepdim,ScalarType dtype)', '    check_scalar_type_device_layout_equal(const Tensor & out,const Tensor & self)', '    get_dtype(Tensor & result,const Tensor & self,optional dtype,bool promote_integers)', '    integer_upcast(const Tensor & self,optional dtype)', '    logsumexp_out_impl(Tensor & result,const Tensor & self,IntArrayRef dims,bool keepdim)', '    make_dim_mask(IntArrayRef dims,int64_t ndim)', '    make_reduction(const char *name,Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType in_dtype,ScalarType out_dtype)', '    make_reduction(const char *name,Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType out_dtype)', '    make_reduction(const char *name,Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    norm_out(Tensor & result,const Tensor & self,optional opt_p,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    prod_out_impl(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    review_reduce_result(const Tensor & result,int ndim,DimMask mask,bool keepdim)', '    squeeze_multiple(const Tensor & self,IntArrayRef dims)', '    std_var_mean_out(const char *fname,Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim,bool take_sqrt)', '    std_var_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim,bool take_sqrt)', '    _all(Tensor & result,TensorIterator & iter)', '    _any(Tensor & result,TensorIterator & iter)', '    _cumprod_cpu(const Tensor & self,int64_t dim)', '    _cumprod_out_cpu(Tensor & result,const Tensor & self,int64_t dim)', '    _cumsum_cpu(const Tensor & self,int64_t dim)', '    _cumsum_out_cpu(Tensor & result,const Tensor & self,int64_t dim)', '    all(const Tensor & self)', '    all(const Tensor & self,int64_t dim,bool keepdim)', '    all(const Tensor & self,Dimname dim,bool keepdim)', '    all_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim)', '    all_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim)', '    any(const Tensor & self)', '    any(const Tensor & self,int64_t dim,bool keepdim)', '    any(const Tensor & self,Dimname dim,bool keepdim)', '    any_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim)', '    any_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim)', '    argmax(const Tensor & self,c10::optional dim,bool keepdims)', '    argmax_out(Tensor & result,const Tensor & self,c10::optional dim,bool keepdim)', '    argmin(const Tensor & self,c10::optional dim,bool keepdims)', '    argmin_out(Tensor & result,const Tensor & self,c10::optional dim,bool keepdim)', '    cummax(const Tensor & self,int64_t dim)', '    cummax(const Tensor & self,Dimname dim)', '    cummax_cummin_helper(const T1 *self_data,T1 *values_data,T2 *indices_data,int self_dim_size,int self_stride,int values_stride,int indices_stride)', '    cummax_helper_cpu(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim)', '    cummax_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim)', '    cummax_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim)', '    cummin(const Tensor & self,int64_t dim)', '    cummin(const Tensor & self,Dimname dim)', '    cummin_helper_cpu(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim)', '    cummin_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim)', '    cummin_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim)', '    cumprod(const Tensor & self,int64_t dim,c10::optional dtype)', '    cumprod(const Tensor & self,Dimname dim,c10::optional dtype)', '    cumprod_out(Tensor & result,const Tensor & self,int64_t dim,c10::optional dtype)', '    cumprod_out(Tensor & result,const Tensor & self,Dimname dim,c10::optional dtype)', '    cumsum(const Tensor & self,int64_t dim,c10::optional dtype)', '    cumsum(const Tensor & self,Dimname dim,c10::optional dtype)', '    cumsum_out(Tensor & result,const Tensor & self,int64_t dim,c10::optional dtype)', '    cumsum_out(Tensor & result,const Tensor & self,Dimname dim,c10::optional dtype)', '    dist(const Tensor & self,const Tensor & other,Scalar p)', '    isnan_(T x)', '    isnan_(T x)', '    logsumexp(const Tensor & self,IntArrayRef dims,bool keepdim)', '    logsumexp(const Tensor & self,DimnameList dims,bool keepdim)', '    logsumexp_out(Tensor & result,const Tensor & self,IntArrayRef dims,bool keepdim)', '    logsumexp_out(Tensor & result,const Tensor & self,DimnameList dims,bool keepdim)', '    max_values(const Tensor & self,IntArrayRef dims,bool keepdim)', '    max_values(const Tensor & self,DimnameList dims,bool keepdim)', '    mean(const Tensor & self,DimnameList dim,bool keepdim,optional dtype)', '    mean_cpu_gpu(const Tensor & self,optional dtype)', '    mean_cpu_gpu(const Tensor & self,IntArrayRef dim,bool keepdim,optional dtype)', '    mean_out(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,c10::optional opt_dtype)', '    mean_out_cpu_gpu(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    min_values(const Tensor & self,IntArrayRef dims,bool keepdim)', '    min_values(const Tensor & self,DimnameList dims,bool keepdim)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,ScalarType dtype)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim)', '    norm(const Tensor & self,Scalar p)', '    norm(const Tensor & self,optional p,DimnameList dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,DimnameList dim,bool keepdim)', '    norm_out(Tensor & result,const Tensor & self,optional p,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm_out(Tensor & result,const Tensor & self,optional p,IntArrayRef dim,bool keepdim)', '    norm_out(Tensor & result,const Tensor & self,optional p,DimnameList dim,bool keepdim,ScalarType dtype)', '    norm_out(Tensor & result,const Tensor & self,optional p,DimnameList dim,bool keepdim)', '    prod(const Tensor & self,int64_t dim,bool keepdim,c10::optional dtype)', '    prod(const Tensor & self,c10::optional dtype)', '    prod(const Tensor & self,Dimname dim,bool keepdim,c10::optional dtype)', '    prod_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim,c10::optional dtype)', '    prod_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim,optional opt_dtype)', '    std(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    std(const Tensor & self,bool unbiased)', '    std_mean(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_mean(const Tensor & self,bool unbiased)', '    std_mean(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    std_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,bool unbiased)', '    std_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_out(Tensor & result,const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    sum(const Tensor & self,c10::optional dtype)', '    sum(const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional dtype)', '    sum(const Tensor & self,DimnameList dim,bool keepdim,c10::optional dtype)', '    sum_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    sum_out(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,optional opt_dtype)', '    var(const Tensor & self,bool unbiased)', '    var(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    var_mean(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_mean(const Tensor & self,bool unbiased)', '    var_mean(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    var_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,bool unbiased)', '    var_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_out(Tensor & result,const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    result', '    result', '    t']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReduceOps.h', [], ['    and_stub', '    and_stub', '    operator=', '    argmax_stub', '    argmax_stub', '    operator=', '    argmin_stub', '    argmin_stub', '    operator=', '    cumprod_stub', '    cumprod_stub', '    operator=', '    cumsum_stub', '    cumsum_stub', '    operator=', '    max_values_stub', '    max_values_stub', '    operator=', '    mean_stub', '    mean_stub', '    operator=', '    min_values_stub', '    min_values_stub', '    operator=', '    norm_kernel', '    norm_kernel', '    operator=', '    norm_stub', '    norm_stub', '    operator=', '    operator=', '    or_stub', '    or_stub', '    operator=', '    prod_stub', '    prod_stub', '    operator=', '    std_var_stub', '    std_var_stub', '    operator=', '    sum_stub', '    sum_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\ReduceOpsKernel.cpp', [], ['    and_kernel_impl(TensorIterator & iter)', '    argmax_kernel_impl(TensorIterator & iter)', '    argmin_kernel_impl(TensorIterator & iter)', '    cpu_cum_base_kernel(Tensor & result,const Tensor & self,int64_t dim,const func_t & f,scalar_t init_val)', '    cumprod_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim)', '    cumsum_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim)', '    max_values_kernel_impl(TensorIterator & iter)', '    mean_kernel_impl(TensorIterator & iter)', '    min_values_kernel_impl(TensorIterator & iter)', '    norm_kernel_tensor_iterator_impl(TensorIterator & iter,Scalar p)', '    or_kernel_impl(TensorIterator & iter)', '    prod_kernel_impl(TensorIterator & iter)', '    std_var_kernel_impl(TensorIterator & iter,bool unbiased,bool take_sqrt)', '    sum_kernel_impl(TensorIterator & iter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReduceOpsUtils.h', [], ['    ensure_nonempty_dim(int64_t dim)', '    ensure_nonempty_size(const Tensor & t,int64_t dim)', '    ensure_nonempty_stride(const Tensor & t,int64_t dim)', '    ensure_nonempty_vec(IdxVec vec)', '    restride_dim(const Tensor & src,int64_t dim,IntArrayRef replacement_shape)', '    _allreduce_return_trivial(const Tensor & self,Scalar ident)', '    _dimreduce_return_trivial(Tensor & result,const Tensor & self,Scalar ident,int64_t dim,bool keepdim)', '    _dimreduce_return_trivial_no_ident(Tensor & result,const Tensor & self,int64_t dim,bool keepdim,const char *fn_name)', '    _dimreduce_setup(Tensor & result,const Tensor & self,int64_t dim)', '    lower_bound', '    upper_bound', '    scalar_tensor', '    infinity', '    lowest', '    max']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\reducer.cpp', ['    LambdaPostHook'], ['    current_time_in_nanos', '    index', '    operator==(const BucketKey & lhs,const BucketKey & rhs)', '    hash(const BucketKey & key)', '    BucketKey(c10::ScalarType type,c10::Device device)', '    LambdaPostHook(std::function fn)', '    operator()(const variable_list & outputs,const variable_list &)', '    Reducer(std::vector,std::vector,std::shared_ptr process_group,std::vector)', '    autograd_hook(VariableIndex index)', '    finalize_backward', '    finalize_bucket_dense(Bucket & bucket)', '    finalize_bucket_sparse(Bucket & bucket)', '    initialize_buckets(std::vector)', '    mark_bucket_ready(size_t bucket_index)', '    mark_variable_ready(VariableIndex index)', '    mark_variable_ready_dense(VariableIndex index)', '    mark_variable_ready_sparse(VariableIndex index)', '    prepare_for_backward(const std::vector & outputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\c10d\\reducer.h', ['    Reducer'], ['    autograd_hook(VariableIndex index)', '    finalize_backward', '    finalize_bucket_dense(Bucket & replica)', '    finalize_bucket_sparse(Bucket & replica)', '    mark_bucket_ready(size_t bucket_index)', '    mark_variable_ready(VariableIndex index)', '    mark_variable_ready_dense(VariableIndex index)', '    mark_variable_ready_sparse(VariableIndex index)', '    initialize_buckets(std::vector)', '    prepare_for_backward(const std::vector & outputs)', '    Reducer(std::vector,std::vector,std::shared_ptr process_group,std::vector)', '    ~Reducer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reducer_functors.h', ['    BaseReducer', '    BaseReducerGradient', '    LogMeanExpRangeReducer', '    LogMeanExpRangeReducerGradient', '    LogSumExpRangeReducer', '    LogSumExpRangeReducerGradient', '    MaxRangeReducer', '    MaxRangeReducerGradient', '    MaxReducer', '    MaxReducerGradient', '    MeanRangeReducer', '    MeanRangeReducerGradient', '    MeanReducer', '    MeanReducerGradient', '    SumRangeReducer', '    SumRangeReducerGradient', '    SumReducer', '    SumReducerGradient', '    WeightedSumReducer', '    WeightedSumReducerGradient'], ['    computeLength', '    numAuxInputsWithGrads(const OperatorDef &)', '    originalInputs', '    requiresDataInput(const OperatorDef &)', '    requiresForwardOutput', '    PopulateSchema(OpSchema &)', '    requiresDataInput(const OperatorDef &)', '    requiresForwardOutput', '    PopulateSchema(OpSchema &)', '    computeLength', '    PopulateSchema(OpSchema &)', '    PopulateSchema(OpSchema & schema)', '    numAuxInputsWithGrads(const OperatorDef & def)', '    originalInputs', '    requiresDataInput(const OperatorDef & def)', '    finish(const Meta &,CPUContext *)', '    appendOutputShape(vector *output_shape)', '    computeMeta(at::IntArrayRef dims,size_t skip_dims)', '    getOutputShape(const TensorShape & in,int skip_dims)', '    Meta(bool first)', '    observeInput(int input,const Tensor & value,int skip_dims)', '    appendGradShape(vector *output_shape)', '    Meta(const Tensor & out_grad,int skip_dims,bool first_dim)', '    observeOriginalInput(int,const Tensor &,Tensor *,int)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    r', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    MaxReducer(const Meta & meta,T *out,CPUContext *)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    fillGradWithMainInputAndForwardOutput(const Meta & meta,const T *data,T *data_grad,const T *forward_output,int64_t,Context *,const int)', '    MaxReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *,const T *,Context *)', '    finish(const Meta & meta,CPUContext *context)', '    MeanReducer(const Meta & meta,T *out,CPUContext *)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int length)', '    MeanReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *,const T *,Context *context)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    SumReducer(const Meta & meta,T *out,CPUContext *)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int length)', '    SumReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    dim', '    ResizeLike', '    size_from_dim', '    Meta(bool first)', '    observeInput(int input,const Tensor & value,int skip_dims)', '    process(const Meta & meta,const T *in,int64_t offset,CPUContext *context)', '    WeightedSumReducer(const Meta & meta,T *out,CPUContext *)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int)', '    fillGradWithMainInput(const Meta & meta,const T *data,T *data_grad,int64_t offset,Context *context,const int)', '    observeOriginalInput(int original_input,const Tensor & value,Tensor *input_grad,int)', '    WeightedSumReducerGradient(const Meta &,const T *s_grad,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Reduction.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\reduction.h', ['    Function'], ['    arg(int index)', '    args', '    bodies', '    body(size_t index)', '    dim(int index)', '    dims', '    func_var(size_t index)', '    func_vars', '    Function(const std::vector & func_names,const std::vector & dims,const std::vector & args,const std::vector & bodies)', '    Function(const std::string & func_name,const std::vector & dims,const std::vector & args,const Expr *body)', '    ndim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduction_ops.cc', ['    GetSumElementsGradient', '    GetColwiseMaxGradient', '    GetRowwiseMaxGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUColwiseMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUColwiseMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwiseMax', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwiseMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElements', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElementsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElementsInt', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumSqrElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElementsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElementsInt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumSqrElements', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColumnMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColwiseMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColwiseMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowwiseMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowwiseMaxGradient', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reduction_ops.h', ['    MaxReductionGradientOp', '    MaxReductionOp', '    SumElementsGradientOp', '    SumElementsIntOp', '    SumElementsOp', '    SumSqrElementsOp'], ['    MaxReductionGradientOp(Args,...)', '    RunOnDevice', '    ~MaxReductionGradientOp', '    MaxReductionOp(Args,...)', '    RunOnDevice', '    ~MaxReductionOp', '    RunOnDevice', '    SumElementsGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    SumElementsGradientOp(const OperatorDef & operator_def,Workspace *ws,bool average)', '    SumElementsGradientOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs)', '    SumElementsGradientOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs,bool average)', '    ~SumElementsGradientOp', '    RunOnDevice', '    scratch_', '    SumElementsIntOp(Args,...)', '    ~SumElementsIntOp', '    RunOnDevice', '    scratch_', '    SumElementsOp(const OperatorDef & operator_def,Workspace *ws)', '    SumElementsOp(const OperatorDef & operator_def,Workspace *ws,bool average)', '    SumElementsOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs)', '    SumElementsOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs,bool average)', '    ~SumElementsOp', '    DoRunWithType', '    RunOnDevice', '    scratch_', '    SumSqrElementsOp(Args,...)', '    ~SumSqrElementsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReflectionPad.cpp', [], ['    reflection_pad1d_backward_out_frame(scalar_t *grad_input,scalar_t *grad_output,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad2d_backward_out_frame(scalar_t *grad_input,scalar_t *grad_output,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad1d_backward_cpu(const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_backward_out_loop(scalar_t *grad_input,scalar_t *grad_output,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_backward_out_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_cpu(const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_out_loop(scalar_t *input_p,scalar_t *output_p,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_out_template(Tensor & output,const Tensor & input_,IntArrayRef padding)', '    reflection_pad2d_backward_cpu(const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_backward_out_loop(scalar_t *grad_input,scalar_t *grad_output,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_backward_out_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_cpu(const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_out_loop(scalar_t *input_p,scalar_t *output_p,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_out_template(Tensor & output,const Tensor & input_,IntArrayRef padding)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\jit\\templates\\register_aten_ops.cpp', [], ['    $', '    as_bool_array(const c10::List & list)', '    atenOperatorOptions', '    DUMMY_OPERATION', '    toListOfOptionalTensor(const IValue & v)', '    toOptionalTensor(const IValue & v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_c10_ops.cpp', ['    final'], ['    createOperatorFromC10(const c10::OperatorHandle & op)', '    ensure_c10_registerer_defined', '    registerer', '    onOperatorDeregistered(const c10::OperatorHandle & op)', '    onOperatorRegistered(const c10::OperatorHandle & op)', '    Registerer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_distributed_ops.cpp', [], ['    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase', '    optional_to_tensor(c10::optional v)', '    toOptionalTensor(const c10::IValue & v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\register_mobile_autograd.cpp', [], ['    conv2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    log_softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    toOptionalTensor(const c10::IValue & v)', '    view_kernel(const c10::OperatorHandle & op,Stack *stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\register_mobile_ops.cpp', [], ['    __is__kernel(const c10::OperatorHandle & op,Stack *stack)', '    __isnot__kernel(const c10::OperatorHandle & op,Stack *stack)', '    _convolution_kernel(const c10::OperatorHandle & op,Stack *stack)', '    cat_kernel(const c10::OperatorHandle & op,Stack *stack)', '    conv2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    format_kernel(const c10::OperatorHandle & op,Stack *stack)', '    listAppend(const c10::OperatorHandle & op,Stack *stack)', '    log_softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    normalizeIndex(int64_t idx,int64_t list_size)', '    optional_to_tensor(c10::optional v)', '    permute_kernel(const c10::OperatorHandle & op,Stack *stack)', '    pop_kernel(const c10::OperatorHandle & op,Stack *stack)', '    softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    to_dtype_kernel(const c10::OperatorHandle & op,Stack *stack)', '    toOptionalTensor(const c10::IValue & v)', '    TupleIndex_kernel(const c10::OperatorHandle & op,Stack *stack)', '    tupleunpack_kernel(const c10::OperatorHandle & op,Stack *stack)', '    upsample_nearest2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    view_kernel(const c10::OperatorHandle & op,Stack *stack)', '    warn_kernel(const c10::OperatorHandle & op,Stack *stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_prim_ops.cpp', [], ['    ceil(double a)', '    floor(double a)', '    floordiv(int64_t a,int64_t b)', '    gcd(int64_t a,int64_t b)', '    to_dispatch(at::Tensor self,c10::optional device,c10::optional scalarType,bool non_blocking,bool copy)', '    _is_floating_value(double v)', '    _output_size(const at::Tensor & input,size_t dim,const IValue & size,const IValue & scale_factors)', '    cat(const c10::List & tensors)', '    checkSortSchema(const c10::TypePtr & list_element_type)', '    convert_scale_factor_to_double(const IValue & int_ivalue)', '    get_first(const c10::List)', '    interpolate(const at::Tensor & input,const IValue & size,const IValue & scale_factors,const std::string & mode,c10::optional align_corners,c10::optional recompute_scale_factor)', '    interpolate_op(Stack & stack)', '    leaky_relu(const at::Tensor & tensor,double scalar)', '    simpleClassTypeArg(const Argument & arg,const ClassTypePtr & type)', '    sort_op(Stack & stack)', '    dictClear(Stack & stack)', '    dictConstructFromList(Stack & stack)', '    dictContains(Stack & stack)', '    dictCopy(Stack & stack)', '    dictDelete(Stack & stack)', '    dictGet(Stack & stack)', '    dictIndex(Stack & stack)', '    dictItems(Stack & stack)', '    dictKeys(Stack & stack)', '    dictLen(Stack & stack)', '    dictPop(Stack & stack)', '    dictPopItem(Stack & stack)', '    dictSetDefault(Stack & stack)', '    dictSetItem(Stack & stack)', '    dictUpdate(Stack & stack)', '    dictValues(Stack & stack)', '    hashValue(Stack & stack)', '    aliasAnalysisConservative', '    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase', '    checkDoubleInRange(double a)', '    checkImplicitTensorToNum(at::Tensor t,bool toInt)', '    degrees(double x)', '    factorial(int n)', '    getItem(const c10::List & list,int64_t idx)', '    listAdd(Stack & stack)', '    listAppend(Stack & stack)', '    listClear(Stack & stack)', '    listContains(Stack & stack)', '    listCopy(Stack & stack)', '    listCount(Stack & stack)', '    listCount(Stack & stack)', '    listDelete(Stack & stack)', '    listEq(Stack & stack)', '    listEq(Stack & stack)', '    listExtend(Stack & stack)', '    listIndex(Stack & stack)', '    listIndex(Stack & stack)', '    listInplaceAdd(Stack & stack)', '    listInsert(Stack & stack)', '    listLen(Stack & stack)', '    listList(Stack & stack)', '    listMax(Stack & stack)', '    listMin(Stack & stack)', '    listMulIntLeft(Stack & stack)', '    listMulIntLeftInPlace(Stack & stack)', '    listMulIntRight(Stack & stack)', '    listNe(Stack & stack)', '    listNe(Stack & stack)', '    listPop(Stack & stack)', '    listPopImpl(Stack & stack,const char *empty_message)', '    listRemove(Stack & stack)', '    listRemove(Stack & stack)', '    listReverse(Stack & stack)', '    listSelect(Stack & stack)', '    listSlice(Stack & stack)', '    listSort(Stack & stack)', '    listSort(Stack & stack)', '    loop(int n,int64_t & p,int64_t & r)', '    make_result_list(const TypePtr & elemType)', '    make_result_list(const TypePtr & elemType)', '    maxList(Stack & stack)', '    minList(Stack & stack)', '    nminussumofbits(int v)', '    noop(Stack & n)', '    normalizeIndex(int64_t idx,int64_t list_size)', '    partProduct(int n,int m)', '    radians(double x)', '    setItem(const c10::List & list,int64_t idx,T)', '    tensor_list_equal(const c10::List & a,const c10::List & b)', '    tensorToListRecursive(char *data,int64_t cur_dim,int64_t num_tensor_dims,TypePtr ty,at::IntArrayRef sizes,at::IntArrayRef strides,size_t element_size)', '    listCopyAndSort(Stack & stack)', '    listCopyAndSort(Stack & stack)', '    listSetItem(Stack & stack)', '    upsample_bilinear_op(Stack & stack)', '    upsample_nearest_op(Stack & stack)', '    upsample_op(Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_prim_ops_c10.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_prim_ops_fulljit.cpp', [], ['    aliasAnalysisConservative', '    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_special_ops.cpp', [], ['    aliasAnalysisFromSchema', '    castTensorTo(at::Tensor self,const IValue & dtype,const IValue & device)', '    checkListInputType(const c10::TypePtr & elem_type,bool empty_list)', '    checkSequenceSize(int64_t n,int64_t dim,int64_t seq_size)', '    compute_sizes(const IValue & seq)', '    createTensorFromList(Stack & stack)', '    recursiveStore(char *data,const std::vector & sizes,const c10::ArrayRef & strides,int64_t dim,int elementSize,const IValue & obj)', '    storeLastDimension(char *data,const std::vector & sizes,const c10::ArrayRef & strides,int64_t dim,int elementSize,at::ArrayRef obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\register_string_ops.cpp', [], ['    aliasAnalysisFromSchema', '    normalizeIndex(int64_t idx,int64_t list_size)', '    stringFindImpl(std::string string,std::string substr,int64_t start,int64_t end,bool reverse)', '    stringSlice(std::string string,int64_t start,int64_t end,int64_t step)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\register_symbols.cpp', [], ['    InternedStrings']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\RegisterOpContextClass.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\RegistrationDeclarations.h', [], ['    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\dispatch\\RegistrationHandleRAII.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Registry.h', ['    Registerer', '    Registry'], ['    KeyStrRepr(const KeyType &)', '    KeyStrRepr(const std::string & key)', '    DefaultCreator(Args,...)', '    Registerer(const SrcType & key,Registry *registry,Registry::Creator creator,const std::string & help_msg)', '    Registerer(const SrcType & key,const RegistryPriority priority,Registry *registry,Registry::Creator creator,const std::string & help_msg)', '    Create(const SrcType & key,Args,...)', '    Has(const SrcType & key)', '    HelpMessage', '    HelpMessage(const SrcType & key)', '    Keys', '    operator=', '    Register(const SrcType & key,Creator creator,const RegistryPriority priority)', '    Register(const SrcType & key,Creator creator,const std::string & help_msg,const RegistryPriority priority)', '    Registry(bool warning)', '    Registry', '    SetTerminate(bool terminate)', '    exit']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\registry_test.cpp', ['    AnotherBar', '    Bar', '    Foo'], ['    RegisterFooBarFallback', '    RegisterFooBarPreferred', '    RegisterFooDefault', '    RegisterFooDefaultAgain', '    RegistryName', '    TEST(RegistryTest,CanRunCreator)', '    TEST(RegistryTest,ReturnNullOnNonExistingCreator)', '    TEST(RegistryTest,RegistryPriorities)', '    AnotherBar(int x)', '    Bar(int x)', '    Foo(int x)', '    ~Foo']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Relu.cpp', [], ['    mkldnn_relu(const Tensor & input)', '    mkldnn_relu_(Tensor & input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\relu_cpu.cc', [], ['    relu_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\relu_dnnlowp_op.cc', [], ['    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\relu_dnnlowp_op.h', ['    final'], ['    ReluAVX2(const int N,const int zero_point,const T *X,T *Y)', '    ReluDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\relu_dnnlowp_op_avx2.cc', [], ['    ReluAVX2(const int N,const int zero_point,const uint8_t *X,uint8_t *Y)', '    ReluAVX2(const int N,const int zero_point,const uint16_t *X,uint16_t *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\relu_n_op.cc', ['    GetReluNGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReluN', '    CAFFE_ANONYMOUS_VARIABLE_CPUReluNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluNGradient', '    CostInferenceForReluN(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\relu_n_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    ReluNFunctor(OperatorBase & op)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)', '    ReluNGradientFunctor(OperatorBase & op)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\relu_op.cc', ['    GetReluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPURelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Relu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluGradient', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\relu_op.cc', ['    final', '    final'], ['    IDEEPReluGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPReluGradientOp', '    ~IDEEPReluOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\relu_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\remove_data_blocks_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURemoveDataBlocks', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RemoveDataBlocks']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\remove_data_blocks_op.h', ['    final'], ['    DoRunWithType', '    RemoveDataBlocksOp(Args,...)', '    RunOnDevice', '    ~RemoveDataBlocksOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\remove_expands.cpp', [], ['    RemoveExpands(Block *block)', '    RemoveExpands(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\remove_expands.h', [], ['    RemoveExpands(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\remove_inplace_ops.cpp', [], ['    isInplaceOp(const Node *node)', '    RemoveInplaceOps(Block *block)', '    RemoveInplaceOps(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\remove_inplace_ops.h', [], ['    RemoveInplaceOps(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Repeat.cpp', [], ['    compute_cpu(int64_t *repeat_ptr,int64_t *cumsum_ptr,int64_t *result_ptr,int64_t size)', '    repeat_interleave(const Tensor & self,const Tensor & repeats,c10::optional dim)', '    repeat_interleave(const Tensor & self,int64_t repeats,c10::optional dim)', '    repeat_interleave_cpu(const Tensor & repeat)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Repeat.h', [], ['    repeat_interleave_common(const Tensor & repeats)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\replace_nan_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReplaceNaN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReplaceNaN', '    ReplaceNaN(const T & value,const int64_t size,const T *X,T *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\replace_nan_op.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    ReplaceNaN(const T & value,const int64_t size,const T *X,T *Y)', '    ReplaceNaNOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ReplicationPadding.cpp', [], ['    replication_pad1d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,long nslices,long iwidth,long owidth,int pad_l,int pad_r,int nbatch)', '    replication_pad1d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,long nslices,long iwidth,long owidth,int pad_l,int pad_r)', '    replication_pad1d_out_batch(scalar_t *input_data,scalar_t *output_data,long nslices,long iwidth,long owidth,int pad_l,int pad_r,int nbatch)', '    replication_pad1d_out_frame(scalar_t *input_p,scalar_t *output_p,long nslices,long iwidth,long owidth,int pad_l,int pad_r)', '    replication_pad2d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b,int nbatch)', '    replication_pad2d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b)', '    replication_pad2d_out_batch(scalar_t *input_data,scalar_t *output_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b,int nbatch)', '    replication_pad2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b)', '    replication_pad3d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback,int nbatch)', '    replication_pad3d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    replication_pad3d_out_batch(scalar_t *input_data,scalar_t *output_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback,int nbatch)', '    replication_pad3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    shapeCheck3d(const Tensor & input,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    replication_pad1d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)', '    replication_pad2d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)', '    replication_pad3d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\requantization-stubs.h', [], ['    pytorch_qnnp_requantize_fp32__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_lrintf(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_magic(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_signed64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned32(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\requantization-tester.h', ['    RequantizationTester'], ['    requantizeApproximate(int32_t value,float scale,uint8_t zeroPoint,uint8_t qmin,uint8_t qmax)', '    shiftLeft(int64_t w,uint32_t n)', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    s(uint32_t s)', '    s', '    s_', '    scale', '    testDivideByPO2WithRoundingAway(pytorch_requantization_function requantize)', '    testDivideByPO2WithRoundingDown(pytorch_requantization_function requantize)', '    testDivideByPO2WithRoundingUp(pytorch_requantization_function requantize)', '    testExactDivideByPO2(pytorch_requantization_function requantize)', '    testRandomCasesAgainstReference(pytorch_requantization_function requantize,pytorch_requantization_function requantizeReference)', '    testRandomCasesApproximate(pytorch_requantization_function requantize)', '    testRandomCasesPrecise(pytorch_requantization_function requantize)', '    testSpecialCases(pytorch_requantization_function requantize)', '    zeroPoint(int32_t zeroPoint)', '    zeroPoint', '    zeroPoint_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\requantization.cc', [], ['    TEST(PRECISE__SCALAR_UNSIGNED32,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_UNSIGNED32,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_UNSIGNED32,special_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED32,random_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED64,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_UNSIGNED64,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_UNSIGNED64,special_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED64,random_cases)', '    TEST(PRECISE__SCALAR_SIGNED64,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_SIGNED64,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_SIGNED64,special_cases)', '    TEST(PRECISE__SCALAR_SIGNED64,random_cases)', '    TEST(FP32__SCALAR_LRINTF,random_cases)', '    TEST(FP32__SCALAR_MAGIC,random_cases)', '    TEST(Q31__SCALAR,exact_divide_by_po2)', '    TEST(Q31__SCALAR,exact_divide_by_po2_with_zero_point)', '    TEST(Q31__SCALAR,divide_by_po2_with_rounding_up)', '    TEST(Q31__SCALAR,divide_by_po2_with_rounding_away)', '    TEST(Q31__SCALAR,special_cases)', '    TEST(Q31__SCALAR,random_cases)', '    TEST(Q31__SCALAR,random_match_gemmlowp)', '    TEST(GEMMLOWP__SCALAR,random_cases)', '    TEST(PRECISE__PSIMD,exact_divide_by_po2)', '    TEST(PRECISE__PSIMD,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__PSIMD,special_cases)', '    TEST(PRECISE__PSIMD,random_cases)', '    TEST(FP32__PSIMD,random_cases)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\requantization.cc', ['    Requantization'], ['    divideRoundUp(uint32_t x,uint32_t q)', '    min(uint32_t a,uint32_t b)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    roundUp(uint32_t x,uint32_t q)', '    input', '    n', '    output', '    Requantization', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\requantization.h', [], ['    pytorch_qnnp_add_quantize(uint8_t a,uint8_t b,union pytorch_qnnp_add_quantization_params params)', '    pytorch_qnnp_avgpool_quantize(int32_t n,union pytorch_qnnp_avgpool_quantization_params params)', '    pytorch_qnnp_compute_add_quantization_params(uint8_t a_zero_point,uint8_t b_zero_point,uint8_t output_zero_point,float a_output_scale,float b_output_scale,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_avgpool_quantization_params(int32_t bias,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_conv_quantization_params(uint8_t input_zero_point,uint8_t kernel_zero_point,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_requantization_params(float scale,uint8_t zero_point,uint8_t min,uint8_t max)', '    pytorch_qnnp_compute_scalar_add_quantization_params(uint8_t a_zero_point,uint8_t b_zero_point,uint8_t output_zero_point,float a_output_scale,float b_output_scale,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_scalar_avgpool_quantization_params(int32_t bias,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_scalar_requantization_params(float scale,uint8_t zero_point,uint8_t min,uint8_t max)', '    pytorch_qnnp_compute_u8_clamping_params(uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_q31_requantize(int32_t n,union pytorch_qnnp_q31_requantization_params params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\requantization_test.cc', [], ['    TEST(Requantization,BatchRequantizationUnitTest)', '    TEST(Requantization,RequantizationUnitTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\request_callback.cpp', [], ['    operator()(Message & request)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\request_callback.h', ['    RequestCallback'], ['    operator()(Message & request)', '    processMessage(Message & request)', '    ~RequestCallback']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\request_callback_impl.cpp', [], ['    deserializePythonRpcCommand(std::unique_ptr,const MessageType & messageType)', '    deserializePythonRpcCommandReference(RpcCommandBase & rpc,const MessageType & messageType)', '    clear', '    ~ClearAutogradContextGuard', '    handleError(const std::exception & e,const MessageType messageType,int64_t messageId)', '    processMessage(Message & request)', '    processRpc(RpcCommandBase & rpc,const MessageType & messageType,const int64_t messageId,const std::shared_ptr & responseFuture)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\request_callback_impl.h', ['    RequestCallbackImpl'], ['    handleError(const std::exception & e,const MessageType messageType,int64_t messageId)', '    processMessage(Message & request)', '    processRpc(RpcCommandBase & rpc,const MessageType & messageType,const int64_t messageId,const std::shared_ptr & responseFuture)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\requires_grad_analysis.cpp', [], ['    bitwiseOr(std::vector a,const std::vector & b)', '    getRequiresGrad(Value *value)', '    PropagateRequiresGrad(std::shared_ptr & graph)', '    PropagateRequiresGrad(Block *block)', '    PropagateRequiresGrad(Node *node)', '    PropagateRequiresGradSimpleNode(Node *node)', '    setRequiresGrad(Value *value,bool req_value)', '    setRequiresGrad(at::ArrayRef outputs,const std::vector & values)', '    setRequiresGrad(Node *node,const std::vector & values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\requires_grad_analysis.h', [], ['    PropagateRequiresGrad(std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reservoir_sampling.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReservoirSampling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReservoirSampling', '    countNewEntries(const std::set & unique_object_ids)', '    ReservoirSamplingOp(const OperatorDef operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reshape_op.cc', ['    GetReshapeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reshape', '    vector', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\reshape_op.cc', ['    final'], ['    IDEEPReshapeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reshape_op.h', ['    ReshapeOp'], ['    DoRunWithType', '    DoRunWithTypeImpl(const Tensor & input,Tensor *output)', '    GetRepeatedArgument', '    InputIsTensorType', '    ReshapeOp(Args,...)', '    RunOnDevice', '    begin', '    dim', '    end', '    raw_data', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reshape_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAReshape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reshape_op_gpu_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(ReshapeOpGPUTest,testReshapeWithScalar)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Resize.cpp', [], ['    resize_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    resize_as_(Tensor & self,const Tensor & the_template,c10::optional optional_memory_format)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Resize.h', [], ['    checkInBoundsForStorage(IntArrayRef size,IntArrayRef stride,int64_t storage_offset,const Storage & new_storage)', '    checkSetStorage(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)', '    maybe_resize_storage_cpu(TensorImpl *self,int64_t new_size)', '    resize_impl_cpu_(TensorImpl *self,IntArrayRef size,c10::optional stride)', '    setStrided(const Tensor & self,IntArrayRef size,IntArrayRef stride,int64_t storage_offset)', '    computeStorageSize', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\resize_3d_op.cc', ['    GetResizeNearest3DGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeNearest3D', '    schema_OperatorName', '    resizeNearest3DNCHW2x(int batch_size,int num_channels,int temporal_scale,int input_frames,int input_height,int input_width,const float *input,float *output)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest3DGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\resize_3d_op.h', ['    final', '    final'], ['    schema_ResizeNearest3D', '    GetSingleArgument', '    ResizeNearest3DGradientOp(Args,...)', '    ResizeNearest3DOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\resize_nearest_3d_dnnlowp_op.cc', [], ['    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\resize_nearest_3d_dnnlowp_op.h', ['    final'], ['    ResizeNearest3DDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\resize_nearest_dnnlowp_op.cc', [], ['    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\resize_nearest_dnnlowp_op.h', ['    final'], ['    ResizeNearestDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\resize_op.cc', ['    GetResizeNearestGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeNearest', '    schema_OperatorName', '    resizeNearestNCHW2x(int batch_size,int num_channels,int input_height,int input_width,const float *input,float *output)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearestGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\resize_op.h', ['    final', '    final'], ['    schema_ResizeNearest', '    GetSingleArgument', '    ResizeNearestGradientOp(Args,...)', '    ResizeNearestOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ios\\resize_test.cc', [], ['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compareResizeNeareast(int N,int C,int H,int W,float wscale,float hscale)', '    randInt(int a,int b)', '    TEST(ResizeNearestOp,ResizeNearest2x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ResizeCommon.h', [], ['    resize_named_tensor_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    has_value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\resolver.h', [], ['    nativeResolver', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    ~Resolver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\resource_guard.h', ['    ResourceGuard'], ['    release', '    ResourceGuard(std::function destructor)', '    ~ResourceGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cpu\\resource_strings.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cuda\\resource_strings.h', [], ['    half_support_literal', '    n']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\restore_macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\reverse_iterator.h', ['    reverse_iterator'], ['    __make_reverse_iterator(_Iterator __i)', '    __niter_base(reverse_iterator __it)', '    operator!=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator!=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator-(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator==(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator==(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>=(const reverse_iterator & __x,const reverse_iterator & __y)', '    make_reverse_iterator(_Iterator __i)', '    operator+(reverse_iterator::difference_type __n,const reverse_iterator & __x)', '    _S_to_pointer(_Tp *__p)', '    _S_to_pointer(_Tp __t)', '    base', '    operator*', '    operator+(difference_type __n)', '    operator++', '    operator++(int)', '    operator+=(difference_type __n)', '    operator-(difference_type __n)', '    operator--', '    operator--(int)', '    operator-=(difference_type __n)', '    operator->', '    operator=(const reverse_iterator & rhs)', '    operator[](difference_type __n)', '    reverse_iterator', '    reverse_iterator(iterator_type __x)', '    reverse_iterator(const reverse_iterator & __x)', '    reverse_iterator(const reverse_iterator & __x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reverse_packed_segs_op.cc', ['    GetReversePackedSegsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReversePackedSegs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReversePackedSegs', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\reverse_packed_segs_op.h', ['    final'], ['    DoRunWithLengthType', '    DoRunWithType', '    ReversePackedSegsOp(Args,...)', '    RunOnDevice', '    ~ReversePackedSegsOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rmac_regions_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURMACRegions', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RMACRegions', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rmac_regions_op.h', ['    final'], ['    RMACRegionsOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\rmax-microkernel-tester.h', ['    RMaxMicrokernelTester'], ['    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_u8rmax_ukernel_function u8rmax)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\rmsprop.cpp', [], ['    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)', '    operator==(const RMSpropOptions & lhs,const RMSpropOptions & rhs)', '    operator==(const RMSpropParamState & lhs,const RMSpropParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    RMSpropOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\rmsprop.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rmsprop_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURmsProp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RmsProp', '    rmsprop_update(int N,const float *g,const float *ms,const float *mom,float *ng,float *nms,float *nmom,float decay,float momentum,float epsilon,const float *lr,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rmsprop_op.h', ['    final'], ['    rmsprop_update(int N,const float *g,const float *ms,const float *mom,float *ng,float *nms,float *nmom,float decay,float momentum,float epsilon,const float *lr,Context *context)', '    decay_', '    epsilon_', '    GetSingleArgument', '    momentum_', '    RmsPropOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp_extensions\\rng_extension.cpp', [], ['    createTestCPUGenerator(uint64_t value)', '    getInstanceCount', '    identity(Generator g)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    random_(Tensor & self,Generator generator)', '    random_from_to(Tensor & self,int64_t from,optional to,Generator generator)', '    random_to(Tensor & self,int64_t to,Generator generator)', '    device_type', '    clone_impl', '    current_seed', '    random', '    random64', '    seed', '    set_current_seed(uint64_t seed)', '    TestCPUGenerator(uint64_t value)', '    ~TestCPUGenerator']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\rng_test.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\rnn.cpp', [], ['    GRUCellOptions(int64_t input_size,int64_t hidden_size)', '    GRUOptions(int64_t input_size,int64_t hidden_size)', '    LSTMCellOptions(int64_t input_size,int64_t hidden_size)', '    LSTMOptions(int64_t input_size,int64_t hidden_size)', '    RNNCellOptions(int64_t input_size,int64_t hidden_size)', '    RNNCellOptionsBase(int64_t input_size,int64_t hidden_size,bool bias,int64_t num_chunks)', '    RNNOptions(int64_t input_size,int64_t hidden_size)', '    RNNOptionsBase(rnn_options_base_mode_t mode,int64_t input_size,int64_t hidden_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\RNN.cpp', [], ['    _quantized_params_dynamic(TensorList params,std::string qengine)', '    gather_params(TensorList params,bool has_biases)', '    gather_quantized_params(TensorList params)', '    gather_quantized_params_dynamic(TensorList params)', '    gather_quantized_params_fp16(TensorList params)', '    unpair_vec(std::vector)', '    _lstm_impl(const io_type & input,const std::vector & params,const Tensor & hx,const Tensor & cx,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _rnn_impl_with_concat(const io_type & input,const std::vector & params,const std::vector & hiddens,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _thnn_differentiable_gru_cell_backward(const Tensor & grad_hy,const Tensor & input_gates,const Tensor & hidden_gates,const Tensor & hx,const Tensor & input_bias,const Tensor & hidden_bias)', '    _thnn_differentiable_lstm_cell_backward(const Tensor & grad_hy,const Tensor & grad_cy,const Tensor & input_gates,const Tensor & hidden_gates,const Tensor & input_bias,const Tensor & hidden_bias,const Tensor & cx,const Tensor & cy)', '    _use_cudnn_rnn_flatten_weight', '    use_miopen(const at::Tensor & input,const double dropout_state)', '    CellParams', '    dropout(const Tensor & input,double p)', '    dropout(const PackedSequence & input,double p)', '    grad_bias', '    grad_hidden_bias', '    grad_input_bias', '    gru(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    gru_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    hidden_as_output(const Tensor & t)', '    hidden_as_output(const tpair_of & t)', '    hidden_concat(at::ArrayRef)', '    hidden_concat(at::ArrayRef hiddens)', '    hidden_slice(const Tensor & t,int64_t start,int64_t end)', '    hidden_slice(const tpair_of & t,int64_t start,int64_t end)', '    input', '    input', '    input', '    input', '    input', '    input', '    lstm(const Tensor & _input,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm(const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_cell(const Tensor & input,TensorList hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    output', '    PackedSequence', '    PackedSequence', '    prepare_quantized_hx(simple_hx_type hx)', '    prepare_quantized_lstm_hx(TensorList hx)', '    project(at::ArrayRef)', '    quantized_gru(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    quantized_gru(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    quantized_gru_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_lstm(const Tensor & _input,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first,c10::optional dtype,bool use_dynamic)', '    quantized_lstm(const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,c10::optional dtype,bool use_dynamic)', '    quantized_lstm_cell(const Tensor & input,TensorList hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_rnn_relu_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_rnn_tanh_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    rnn_relu(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_relu_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    rnn_tanh(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    CellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    linear_hh(Tensor h)', '    linear_ih(Tensor input)', '    matmul_hh(Tensor h)', '    matmul_ih(Tensor input)', '    PackedSequence(Tensor _data,Tensor _batch_sizes)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    matmul_hh(const Tensor & h)', '    matmul_ih(const Tensor & input)', '    QuantizedCellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,const Tensor & _packed_ih,const Tensor & _packed_hh,const Tensor & _col_offsets_ih,const Tensor & _col_offsets_hh,const Scalar & _scale_ih,const Scalar & _scale_hh,const Scalar & _zero_point_ih,const Scalar & _zero_point_hh)', '    linear_hh(const Tensor & input_hh)', '    linear_ih(const Tensor & input_ih)', '    matmul_hh(const Tensor & h)', '    matmul_ih(const Tensor & input)', '    QuantizedCellParamsDynamic(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    matmul_hh(const Tensor &)', '    matmul_ih(const Tensor &)', '    QuantizedCellParamsFP16(const Tensor & _packed_ih,const Tensor & _packed_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    operator()(const Tensor & t)', '    operator()(const Tensor & t)', '    ~Cell', '    FullBidirectionalLayer(Cell & cell)', '    operator()(const Tensor & input,const hidden_type & input_hidden,const param_type & params)', '    reverse(std::vector)', '    FullLayer(Cell & cell)', '    operator()(const std::vector & step_inputs,const hidden_type & input_hidden,const cell_params & params,bool pre_compute_input)', '    operator()(const Tensor & inputs,const hidden_type & input_hidden,const cell_params & params)', '    operator()(const Tensor & input,const hidden_type & hidden,const cell_params & params,bool pre_compute_input)', '    ~Layer', '    operator()(const Tensor & input,const hidden_type & hidden,const cell_params & params,bool pre_compute_input)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const param_type & params)', '    PackedBidirectionalLayer(Cell & cell)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const cell_params & params)', '    PackedLayer(Cell & cell)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const cell_params & params)', '    ReversedPackedLayer(Cell & cell)', '    operator()(const Tensor & input,const Tensor & hidden,const cell_params & params,bool pre_compute_input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\rnn.cpp', ['    CuDNNMode'], ['    compute_rnn_options_base_mode(RNNOptions::nonlinearity_t nonlinearity)', '    apply_permutation(const Tensor & tensor,const Tensor & permutation,int64_t dim)', '    get_cudnn_mode_for_rnn(detail::RNNOptionsBase::rnn_options_base_mode_t mode)', '    forward(const Tensor & input,Tensor hx)', '    GRUCellImpl(const GRUCellOptions & options_)', '    forward(const Tensor & input,Tensor hx)', '    forward_helper(const Tensor & input,const Tensor & batch_sizes,const Tensor & sorted_indices,int64_t max_batch_size,Tensor hx)', '    forward_with_packed_input(const PackedSequence & packed_input,Tensor hx)', '    GRUImpl(const GRUOptions & options_)', '    forward(const Tensor & input,torch::optional,Tensor)', '    LSTMCellImpl(const LSTMCellOptions & options_)', '    check_forward_args(const Tensor & input,std::tuple hidden,const Tensor & batch_sizes)', '    LSTMImpl(const LSTMOptions & options_)', '    permute_hidden(std::tuple hx,const Tensor & permutation)', '    forward(const Tensor & input,Tensor hx)', '    get_nonlinearity_str', '    RNNCellImpl(const RNNCellOptions & options_)', '    check_forward_hidden(const Tensor & input,const Tensor & hx,std::string hidden_label)', '    check_forward_input(const Tensor & input)', '    get_nonlinearity_str', '    pretty_print(std::ostream & stream)', '    reset_parameters', '    RNNCellImplBase(const RNNCellOptionsBase & options_)', '    forward(const Tensor & input,Tensor hx)', '    forward_helper(const Tensor & input,const Tensor & batch_sizes,const Tensor & sorted_indices,int64_t max_batch_size,Tensor hx)', '    forward_with_packed_input(const PackedSequence & packed_input,Tensor hx)', '    RNNImpl(const RNNOptions & options_)', '    all_weights', '    check_forward_args(Tensor input,Tensor hidden,Tensor batch_sizes)', '    check_hidden_size(const Tensor & hx,std::tuple expected_hidden_size,std::string msg)', '    check_input(const Tensor & input,const Tensor & batch_sizes)', '    flatten_parameters', '    get_expected_hidden_size(const Tensor & input,const Tensor & batch_sizes)', '    permute_hidden(Tensor hx,const Tensor & permutation)', '    pretty_print(std::ostream & stream)', '    reset_flat_weights', '    reset_parameters', '    RNNImplBase(const RNNOptionsBase & options_)', '    to(torch::Device device,torch::Dtype dtype,bool non_blocking)', '    to(torch::Dtype dtype,bool non_blocking)', '    to(torch::Device device,bool non_blocking)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\rnn.cpp', [], ['    bi_grus', '    bi_lstm', '    BidirectionalGRUReverseForward(bool cuda)', '    BidirectionalLSTMReverseForwardTest(bool cuda)', '    check_lstm_sizes(std::tuple,std::tuple,torch::Tensor)', '    copyParameters(torch::nn::ModuleHolder & target,std::string t_suffix,const torch::nn::ModuleHolder & source,std::string s_suffix)', '    forward_op', '    gru_cpu', '    gru_cuda', '    gru_output_to_device(std::tuple gru_output,torch::Device device)', '    lstm_cpu', '    lstm_cuda', '    reverse_gru', '    reverse_lstm', '    TEST_F(RNNTest,CheckOutputSizes)', '    TEST_F(RNNTest,CheckOutputValuesMatchPyTorch)', '    TEST_F(RNNTest,EndToEndLSTM)', '    TEST_F(RNNTest,EndToEndGRU)', '    TEST_F(RNNTest,EndToEndRNNRelu)', '    TEST_F(RNNTest,EndToEndRNNTanh)', '    TEST_F(RNNTest,Sizes_CUDA)', '    TEST_F(RNNTest,EndToEndLSTM_CUDA)', '    TEST_F(RNNTest,EndToEndGRU_CUDA)', '    TEST_F(RNNTest,EndToEndRNNRelu_CUDA)', '    TEST_F(RNNTest,EndToEndRNNTanh_CUDA)', '    TEST_F(RNNTest,PrettyPrintRNNs)', '    TEST_F(RNNTest,BidirectionalFlattenParameters)', '    TEST_F(RNNTest,BidirectionalGRUReverseForward)', '    TEST_F(RNNTest,BidirectionalGRUReverseForward_CUDA)', '    TEST_F(RNNTest,BidirectionalLSTMReverseForward)', '    TEST_F(RNNTest,BidirectionalLSTMReverseForward_CUDA)', '    TEST_F(RNNTest,BidirectionalMultilayerGRU_CPU_vs_CUDA)', '    TEST_F(RNNTest,BidirectionalMultilayerLSTM_CPU_vs_CUDA)', '    TEST_F(RNNTest,UsePackedSequenceAsInput)', '    test_RNN_xor(Func,bool cuda)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp', [], ['    dropout_state_cache', '    _copyParams(MatrixRef params_from,MatrixRef params_to)', '    _cudnn_impl(const Tensor & input,const Tensor & _batch_sizes,const hidden_type & hidden,TensorList params,bool has_biases,cudnnRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _cudnn_impl(const Tensor & input,const hidden_type & hidden,TensorList params,bool has_biases,cudnnRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    _cudnn_init_dropout_state(double dropout,bool train,int64_t dropout_seed,const TensorOptions & options)', '    _cudnn_rnn(const Tensor & input_r,TensorList weight,int64_t weight_stride0,const Tensor & weight_buf_r,const Tensor & hx,const Tensor & cx,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state)', '    _cudnn_rnn_backward_input(const Tensor & input_r,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,const Tensor & grad_output_r,const Tensor & grad_hy,const Tensor & grad_cy,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,std::array output_mask)', '    _cudnn_rnn_backward_weight(const Tensor & input_r,TensorList weight_arr,int64_t weight_stride0,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve)', '    _cudnn_rnn_flatten_weight(TensorList weight_arr,int64_t weight_stride0,int64_t input_size,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,bool fn_bidirectional)', '    _hidden_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _input_size(const TensorDescriptorListParams & tensors)', '    _num_linear_layers(cudnnRNNMode_t mode)', '    _output_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _viewOrCopyParams(MatrixRef params_from,MatrixRef params_to,bool copy)', '    _viewParams(MatrixRef params_from,MatrixRef params_to)', '    batch_sizes', '    get_algo(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors,const Tensor input)', '    get_dropout_state(double dropout_p,bool train,TensorOptions options)', '    get_expected_data_ptrs(const Tensor & weight_buf,cudnnHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,cudnnDataType_t datatype)', '    get_num_weights(cudnnHandle_t handle,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,cudnnDataType_t datatype)', '    get_parameters(cudnnHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,const FilterDescriptor & w_desc,const Tensor & weight_buf)', '    gru_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_cudnn(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & input,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm_packed_cudnn(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    promote_rnn_math_type(cudnnDataType_t dtype)', '    rnn_descriptor(const Tensor & tensor,int64_t N)', '    rnn_descriptor_sequence(const Tensor & tensor,IntArrayRef batch_sizes)', '    rnn_relu_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    try_get_weight_buf(const Tensor & input,TensorList parameters,bool has_biases,cudnnRNNMode_t mode,int64_t hidden_size,int64_t num_layers,bool bidirectional)', '    unpack_hidden(const std::tuple & hidden)', '    unpack_hidden(const Tensor & hidden)', '    weight', '    weight', '    DropoutDescriptorParams', '    lock', '    unlock', '    descriptor(cudnnHandle_t handle,DropoutDescriptor)', '    descriptor(cudnnHandle_t handle)', '    int64_t', '    num_directions', '    set_algo(cudnnRNNAlgo_t algo)', '    set_bidirectional(bool fn_bidirectional)', '    set_mode(int64_t fn_mode)', '    get_descs(const std::vector & descs)', '    get_x_descs', '    get_y_descs', '    RNNDescriptors(const RNNParams & fn,cudnnHandle_t handle,Tensor x,Tensor y,Tensor hx,Tensor cx)', '    descriptors(Tensor x)', '    IntArrayRef', '    is_input_packed']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\rnn.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\rnn.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\RNN.h', [], ['    check_device(const Tensor & input,const TensorList & params,const TensorList & hiddens)', '    gru_cudnn_stub', '    gru_cudnn_stub', '    operator=', '    gru_miopen_stub', '    gru_miopen_stub', '    operator=', '    gru_packed_cudnn_stub', '    gru_packed_cudnn_stub', '    operator=', '    gru_packed_miopen_stub', '    gru_packed_miopen_stub', '    operator=', '    lstm_cudnn_stub', '    lstm_cudnn_stub', '    operator=', '    lstm_miopen_stub', '    lstm_miopen_stub', '    operator=', '    lstm_packed_cudnn_stub', '    lstm_packed_cudnn_stub', '    operator=', '    lstm_packed_miopen_stub', '    lstm_packed_miopen_stub', '    operator=', '    operator=', '    rnn_relu_cudnn_stub', '    rnn_relu_cudnn_stub', '    operator=', '    rnn_relu_miopen_stub', '    rnn_relu_miopen_stub', '    operator=', '    rnn_relu_packed_cudnn_stub', '    rnn_relu_packed_cudnn_stub', '    operator=', '    rnn_relu_packed_miopen_stub', '    rnn_relu_packed_miopen_stub', '    operator=', '    rnn_tanh_cudnn_stub', '    rnn_tanh_cudnn_stub', '    operator=', '    rnn_tanh_miopen_stub', '    rnn_tanh_miopen_stub', '    operator=', '    rnn_tanh_packed_cudnn_stub', '    rnn_tanh_packed_cudnn_stub', '    operator=', '    rnn_tanh_packed_miopen_stub', '    rnn_tanh_packed_miopen_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\utils\\rnn.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\miopen\\RNN_miopen.cpp', [], ['    _miopen_impl(const Tensor & input,const Tensor & _batch_sizes,const hidden_type & hidden,TensorList params,bool has_biases,miopenRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _miopen_impl(const Tensor & input,const hidden_type & hidden,TensorList params,bool has_biases,miopenRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    MatrixRef', '    _copyParams(MatrixRef params_from,MatrixRef params_to)', '    _copyParams_and_permute(MatrixRef params_from,MatrixRef params_to,int64_t mode)', '    _hidden_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _input_size(const TensorDescriptorListParams & tensors)', '    _num_linear_layers(miopenRNNMode_t mode)', '    _output_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _viewOrCopyParams(MatrixRef params_from,MatrixRef params_to,bool copy)', '    _viewParams(MatrixRef params_from,MatrixRef params_to)', '    get_num_weights(miopenHandle_t handle,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,miopenDataType_t datatype)', '    get_parameters(miopenHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,const FilterDescriptor & w_desc,const Tensor & weight_buf)', '    MatrixRef', '    miopen_rnn(const Tensor & input_r,TensorList weight,int64_t weight_stride0,const Tensor & hx,const Tensor & cx,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state)', '    permute_wei_for_miopen(Tensor wei,int64_t mode)', '    rnn_descriptor(const Tensor & tensor,int64_t N)', '    rnn_descriptor_sequence(const Tensor & tensor,IntArrayRef batch_sizes)', '    batch_sizes', '    gru_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_miopen(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & input,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm_packed_miopen(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    miopen_rnn_backward_input(const Tensor & input_r,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,const Tensor & grad_output_r,const Tensor & grad_hy,const Tensor & grad_cy,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,std::array output_mask)', '    miopen_rnn_backward_weight(const Tensor & input_r,TensorList weight_arr,int64_t weight_stride0,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,const Tensor & fn_workspace)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    rnn_relu_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    unpack_hidden(const std::tuple & hidden)', '    unpack_hidden(const Tensor & hidden)', '    descriptor', '    int64_t', '    num_directions', '    set_algo(miopenRNNAlgo_t algo)', '    set_bidirectional(bool fn_bidirectional)', '    set_mode(int64_t fn_mode)', '    get_descs(const std::vector & descs)', '    get_x_descs', '    get_y_descs', '    RNNDescriptors(const RNNParams & fn,miopenHandle_t handle,Tensor x,Tensor y,Tensor hx,Tensor cx)', '    descriptors(Tensor x)', '    IntArrayRef', '    is_input_packed']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\rocksdb\\rocksdb.cc', ['    C10FlagParser_caffe2_rocksdb_block_size', '    RocksDB', '    RocksDBCursor', '    RocksDBTransaction'], ['    gCaffe2ModuleSanityCheckcaffe2_rocksdb', '    C10FlagParser_caffe2_rocksdb_block_size(const std::string & content)', '    Close', '    NewCursor', '    NewTransaction', '    RocksDB(const string & source,Mode mode)', '    key', '    Next', '    RocksDBCursor(rocksdb::DB *db)', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~RocksDBCursor', '    Commit', '    Put(const string & key,const string & value)', '    RocksDBTransaction(rocksdb::DB *db)', '    ~RocksDBTransaction']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_gradient_op.cc', ['    GetRoIAlignGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlignGradient', '    schema_OperatorName', '    add(const T & val,T *address)', '    bilinear_interpolate_gradient(const int height,const int width,T y,T x,T & w1,T & w2,T & w3,T & w4,int & x_low,int & x_high,int & y_low,int & y_high,const int)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignGradient', '    ROIAlignBackwardFeature(const int nthreads,const T *top_diff,const int,const T & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,T *bottom_diff,const T *bottom_rois,int rois_cols,bool continuous_coordinate)', '    vector', '    GetGradientDefs', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_gradient_op.h', ['    final'], ['    schema_RoIAlignGradient', '    GetSingleArgument', '    RoIAlignGradientOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlign', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlign', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const float *X,const float *R,float *Y)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const float *X,const float *R,float *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_op.h', ['    final'], ['    schema_RoIAlign', '    Y_sizes', '    RoIAlignOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const T *X,const T *R,T *Y)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const T *X,const T *R,T *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_op_gpu_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Context *context,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    CreateAndRun(TensorCPU *outResult,const string & order,const TestParams & test_params,bool random_test)', '    GetDeviceType', '    randInt(int a,int b)', '    rois', '    TEST(RoiAlignTest,DISABLED_CheckCPUGPUEqual)', '    test_params']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_rotated_gradient_op.cc', ['    GetRoIAlignRotatedGradient'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignRotatedGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_rotated_gradient_op.h', ['    final'], ['    GetSingleArgument', '    RoIAlignRotatedGradientOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_rotated_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlignRotated', '    schema_OperatorName', '    schema_OperatorName', '    pre_calc_for_bilinear_interpolate(const int height,const int width,const int pooled_height,const int pooled_width,const int iy_upper,const int ix_upper,T roi_start_h,T roi_start_w,T bin_size_h,T bin_size_w,int roi_bin_grid_h,int roi_bin_grid_w,T roi_center_h,T roi_center_w,T theta,std::vector)', '    ROIAlignRotatedForward(const int nthreads,const T *bottom_data,const T & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,const T *bottom_rois,int roi_cols,T *top_data,StorageOrder order,bool continuous_coordinate)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignRotated', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_align_rotated_op.h', ['    final'], ['    schema_RoIAlignRotated', '    RoIAlignRotatedOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\roi_pool_f_op.cc', ['    GetRoIPoolFGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolF', '    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolFGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolF', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolFGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\roi_pool_f_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RoIPoolFGradientOp(const OperatorDef & def,Workspace *ws)', '    RoIPoolFOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_pool_op.cc', ['    GetRoIPoolGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPURoIPool', '    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolGradient', '    vector', '    GetGradientDefs', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\roi_pool_op.h', ['    final', '    final'], ['    RoIPoolGradientOp(Args,...)', '    RoIPoolOp(Args,...)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rowmul_op.cc', ['    GetRowMulGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceTailSum', '    CAFFE_ANONYMOUS_VARIABLE_CPURowMul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceTailSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowMul', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rowmul_op.h', ['    ReduceTailSumOp', '    RowMulOp'], ['    ReduceTailSumOp(Args,...)', '    RunOnDevice', '    ~ReduceTailSumOp', '    RowMulOp(Args,...)', '    RunOnDevice', '    ~RowMulOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rowwise_adagrad_fused.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rowwise_adagrad_fused.h', ['    final', '    final', '    final'], ['    compute_square_average_inlined_(const float *a,int len)', '    compute(int64_t block_size,const SIndex *indices,int64_t n,const TLengths *lengths,int64_t numSegments,const T *gradIn,const Tdata *paramIn,int64_t numParams,const T *momentIn,Tdata *paramOut,T *momentOut,float epsilon,T lr,rowWiseAdagradT & kernel)', '    compute(int64_t block_size,const SIndex *indices,int64_t n,const TLengths *lengths,int64_t numSegments,const T *gradIn,const Tdata *paramIn,int64_t numParams,const T *momentIn,const T *auxParamIn,Tdata *paramOut,T *momentOut,T *auxGrad,float epsilon,T lr,rowWiseAdagradT & kernel,CPUContext *context)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RowWiseSparseAdagradFusedWithSparseLengthsSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp(const OperatorDef & operator_def,Workspace *ws)', '    RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    operator()(int N,float *w,float *w_n,const float *g,float g_sq_avg,float *h,float *h_n,float epsilon,float lr)', '    Resize', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rowwise_counter.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseCounter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\rowwise_counter.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    RowWiseCounterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rpc.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rpc_agent.cpp', [], ['    getCurrentRpcAgent', '    isCurrentRpcAgentSet', '    setCurrentRpcAgent(std::shared_ptr rpcAgent)', '    cleanup', '    enableGILProfiling(bool flag)', '    getDebugInfo', '    getTypeResolver', '    getWorkerInfo', '    isGILProfilingEnabled', '    retryExpiredRpcs', '    RpcAgent(WorkerInfo workerId,std::unique_ptr cb,std::chrono::milliseconds rpcTimeout)', '    rpcRetryCallback(const rpc::Message & message,const c10::optional & futErr,steady_clock_time_point newTime,std::shared_ptr earliestRpc)', '    sendWithRetries(const WorkerInfo & to,Message,RpcRetryOptions retryOptions)', '    setTypeResolver(std::shared_ptr typeResolver)', '    ~RpcAgent', '  Static Member Variables', '    currentRpcAgent_', '    MAX_NAME_LEN']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rpc_agent.h', ['    RpcAgent'], ['    getCurrentRpcAgent', '    isCurrentRpcAgentSet', '    setCurrentRpcAgent(std::shared_ptr rpcAgent)', '    time_point_cast', '    operator()(const torch::distributed::rpc::WorkerInfo & worker_info)', '    isalnum', '    now', '    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    cleanup', '    computeNewRpcRetryTime(RpcRetryOptions & options,int retryCount)', '    enableGILProfiling(bool flag)', '    getDebugInfo', '    getMetrics', '    getRpcTimeout', '    getTypeResolver', '    getWorkerInfo', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    isGILProfilingEnabled', '    join', '    retryExpiredRpcs', '    RpcAgent(WorkerInfo workerId,std::unique_ptr cb,std::chrono::milliseconds rpcTimeout)', '    rpcRetryCallback(const rpc::Message & message,const c10::optional & futErr,steady_clock_time_point newTime,std::shared_ptr earliestRpc)', '    send(const WorkerInfo & to,Message)', '    sendWithRetries(const WorkerInfo & to,Message,RpcRetryOptions retryOptions)', '    setRpcTimeout(const std::chrono::milliseconds & rpcTimeout)', '    setTypeResolver(std::shared_ptr typeResolver)', '    shutdown', '    start', '    sync', '    ~RpcAgent', '    RpcBackendOptions', '    RpcBackendOptions(std::chrono::milliseconds rpcTimeout,std::string initMethod)', '    RpcRetryInfo(const WorkerInfo & to,Message,std::shared_ptr originalFuture,int retryCount,RpcRetryOptions options)', '    maxRetries', '    retryBackoff', '    rpcRetryDuration', '    RpcRetryOptions', '    operator==(const WorkerInfo & rhs)', '    WorkerInfo(std::string name,int64_t id)', '    WorkerInfo(std::string name,worker_id_t id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rpc_command_base.h', ['    RpcCommandBase'], ['    toMessageImpl', '    toMessage', '    toMessageImpl', '    ~RpcCommandBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\rpc_with_autograd.cpp', [], ['    ivalues', '    autogradMetadata', '    fromMessage(const Message & message)', '    fromWorkerId', '    moveWrappedRpc', '    RpcWithAutograd(worker_id_t fromWorkerId,MessageType messageType,const AutogradMetadata & autogradMetadata,rpc::Message)', '    RpcWithAutograd(worker_id_t fromWorkerId,MessageType messageType,const AutogradMetadata & autogradMetadata,std::unique_ptr wrappedRpc,MessageType wrappedMessageType,std::vector tensors)', '    setWrappedRpc(std::unique_ptr wrappedRpc)', '    tensors', '    toMessageImpl', '    wrappedMessageType', '    wrappedRpc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\rpc_messages\\rpc_with_autograd.h', ['    final'], ['    fromMessage(const rpc::Message & message)', '    autogradMetadata', '    fromWorkerId', '    moveWrappedRpc', '    RpcWithAutograd(rpc::worker_id_t fromWorkerId,rpc::MessageType messageType,const AutogradMetadata & autogradMetadata,rpc::Message)', '    RpcWithAutograd(rpc::worker_id_t fromWorkerId,rpc::MessageType messageType,const AutogradMetadata & autogradMetadata,std::unique_ptr wrappedRpc,rpc::MessageType wrappedMessageType,std::vector tensors)', '    setWrappedRpc(std::unique_ptr wrappedRpc)', '    tensors', '    toMessageImpl', '    wrappedMessageType', '    wrappedRpc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\metrics\\RpcMetricsHandler.h', ['    RpcMetricsHandler'], ['    ~RpcMetricsHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_context.cpp', [], ['    confirmPendingUser(const rpc::Message & message,const c10::optional & futErr)', '    finishCreatingOwnerRRef(const Message & message,const c10::optional & futErr)', '    getInstance', '    addConfirmedUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    addForkOfOwnerIfNotPresent(const RRefId & rrefId,const ForkId & forkId)', '    addPendingChild(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addPendingUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addSelfAsFork(c10::intrusive_ptr & rref)', '    checkRRefLeaks(bool ignoreRRefLeak)', '    clearRecordedPendingRRefsOnError', '    createOwnerRRef(const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,const TypePtr & type)', '    delAllUsers(std::chrono::milliseconds timeoutMillis)', '    delForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    delPendingChild(const ForkId & forkId)', '    delPendingUser(const ForkId & forkId)', '    delUser(const worker_id_t owner,const RRefId & rrefId,const ForkId & forkId)', '    finishForkRequest(const ForkId & forkId,worker_id_t parent)', '    getDebugInfo', '    getOrCreateOwnerRRef(const RRefId & rrefId,const TypePtr & type)', '    getOrCreateRRef(const RRefForkData & rrefForkData,const TypePtr & type)', '    getOwnerRRef(const RRefId & rrefId)', '    handleException(const c10::optional & futErr)', '    notifyOwnerAndParentOfFork(const ForkId & forkId,worker_id_t parent,const c10::intrusive_ptr & rref)', '    prepareChildFork(const c10::intrusive_ptr & rref)', '    recordThreadLocalPendingRRefs', '    RRefContext(std::shared_ptr agent)', '    ~RRefContext', '  Static Member Variables', '    recording']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_context.h', ['    RRefContext'], ['    confirmPendingUser(const rpc::Message & message,const c10::optional & futErr)', '    finishCreatingOwnerRRef(const Message & message,const c10::optional & futErr)', '    getInstance', '    handleException(const c10::optional & futErr)', '    static_intrusive_pointer_cast', '    addConfirmedUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    addForkOfOwnerIfNotPresent(const RRefId & rrefId,const ForkId & forkId)', '    addPendingChild(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addPendingUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addSelfAsFork(c10::intrusive_ptr & rref)', '    agent', '    checkRRefLeaks(bool ignoreRRefLeak)', '    clearRecordedPendingRRefsOnError', '    createOwnerRRef(const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,const TypePtr & type)', '    delAllUsers(std::chrono::milliseconds timeoutMillis)', '    delForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    delPendingChild(const ForkId & forkId)', '    delPendingUser(const ForkId & forkId)', '    delUser(const worker_id_t owner,const RRefId & rrefId,const ForkId & forkId)', '    finishForkRequest(const ForkId & forkId,worker_id_t parent)', '    genGloballyUniqueId', '    getDebugInfo', '    getOrCreateOwnerRRef(const RRefId & rrefId,const TypePtr & type)', '    getOrCreateRRef(const RRefForkData & rfd,const TypePtr & type)', '    getOwnerRRef(const RRefId & rrefId)', '    getWorkerId', '    getWorkerName', '    notifyOwnerAndParentOfFork(const ForkId & forkId,worker_id_t parent,const c10::intrusive_ptr & rref)', '    operator=', '    operator=', '    confirm', '    PendingUserState(c10::intrusive_ptr rref)', '    prepareChildFork(const c10::intrusive_ptr & rref)', '    recordThreadLocalPendingRRefs', '    RRefContext', '    RRefContext', '    RRefContext(std::shared_ptr)', '    ~RRefContext']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_impl.cpp', [], ['    getFuture', '    getTypeStr(const c10::TypePtr & type)', '    getValue', '    hasValue', '    setValue(IValue)', '    nextLocalId_', '    fork', '    RRef(worker_id_t ownerId,const RRefId & rrefId,TypePtr type)', '    RRefForkData(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,worker_id_t parent,std::string typeStr)', '    fork', '    forkId', '    release_resources', '    toHere', '    tryDel', '    UserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,TypePtr type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_impl.h', ['    final', '    final', '    RRef'], ['    confirm', '    confirmedByOwner', '    confirmedByOwner', '    deletedOnOwner_', '    fork', '    forkId', '    getFuture', '    getValue', '    hasValue', '    isOwner', '    isOwner', '    operator=', '    operator=', '    operator=', '    operator=', '    release_resources', '    setValue(IValue)', '    toHere', '    tryDel', '    UserRRef', '    UserRRef', '    UserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,TypePtr type)', '    worker_id_t', '    worker_id_t', '    ~UserRRef', '    fork', '    isPyObj', '    operator=', '    owner', '    ownerName', '    RRef', '    RRef', '    RRef(worker_id_t ownerId,const RRefId & rrefId,TypePtr type)', '    rrefId', '    tryDel', '    type', '    ~RRef', '    RRefForkData(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,worker_id_t parent,std::string typeStr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\rref_interface.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_proto.cpp', [], ['    fromIValues(std::vector ivalues,MessageType type)', '    toIValues(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    toMessageImpl', '    forkId', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    forkId', '    toMessageImpl', '    toMessageImpl', '    values', '    rrefId', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\rref_proto.h', ['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    ForkMessageBase', '    RRefFetchRet', '    RRefMessageBase'], ['    fromMessage(const Message & message)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    forkId', '    fromWorkerId', '    PythonRRefFetchCall(worker_id_t fromWorkerId,const RRefId & rrefId)', '    PythonRRefFetchRet(std::vector values)', '    RemoteRet(const RRefId & rrefId,const ForkId & forkId)', '    RRefAck', '    RRefChildAccept(const ForkId & forkId)', '    RRefForkRequest(const RRefId & rrefId,const ForkId & forkId)', '    RRefUserDelete(const RRefId & rrefId,const ForkId & forkId)', '    ScriptRRefFetchCall(worker_id_t fromWorkerId,const RRefId & rrefId)', '    ScriptRRefFetchRet(std::vector values)', '    toMessageImpl', '    forkId', '    ForkMessageBase(const RRefId & rrefId,const ForkId & forkId,MessageType type)', '    toMessageImpl', '    ~ForkMessageBase', '    RRefFetchRet(std::vector values,MessageType type)', '    toMessageImpl', '    values', '    rrefId', '    RRefMessageBase(const RRefId & rrefId,MessageType type)', '    toMessageImpl', '    ~RRefMessageBase']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rsqrt_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPURsqrt', '    CAFFE_ANONYMOUS_VARIABLE_CPURsqrtGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Rsqrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RsqrtGradient', '    GetGradientDefs', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *Y,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\rsqrt_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & Y_dims,const T *dY,const T *Y,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\run_plan.cc', ['    C10FlagParser_plan'], ['    main(int argc,char **argv)', '    C10FlagParser_plan(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\run_plan_mpi.cc', ['    C10FlagParser_plan'], ['    main(int argc,char **argv)', '    C10FlagParser_plan(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\runcnt_observer.cc', [], ['    debugInfo', '    Start', '    Stop', '    RunCountOperatorObserver(OperatorBase *op,RunCountNetObserver *netObserver)', '    Start', '    Stop']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\runcnt_observer.h', ['    final', '    final'], ['    debugInfo', '    RunCountNetObserver(NetBase *subject_)', '    RunCountOperatorObserver', '    RunCountOperatorObserver(OperatorBase *op,RunCountNetObserver *netObserver)', '    Start', '    Stop', '    ~RunCountNetObserver', '    ~RunCountOperatorObserver']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\runtime-assembly.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\runtime-neon.h', [], ['    sub_zero_point(const uint8x8_t va,const uint8x8_t vzp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\requantization\\runtime-sse2.h', [], ['    sub_zero_point(const __m128i va,const __m128i vzp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sample_as_op.cc', ['    GetSampleAsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSampleAs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSampleAsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SampleAs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SampleAsGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sample_as_op.h', ['    final', '    final'], ['    RunOnDevice', '    RunOnDevice', '    SampleAsGradientOp(const OperatorDef & def,Workspace *ws)', '    SampleAsOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\saved_variable.cpp', [], ['    SavedVariable(const Variable & variable,bool is_output,bool is_inplace_view)', '    unpack(std::shared_ptr saved_for)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\saved_variable.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\scalar-utils.h', [], ['    asr_s32(int32_t x,uint32_t n)', '    asr_s64(int64_t x,uint32_t n)', '    pytorch_scalar_requantize_precise(int32_t value,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8lut32norm\\scalar.c', [], ['    compute_sum(size_t n,const uint8_t *x,const uint32_t *t)', '    pytorch_u8lut32norm_ukernel__scalar(size_t n,const uint8_t *x,const uint32_t *t,uint8_t *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8lut32norm\\scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8lut\\scalar.c', [], ['    pytorch_x8lut_ukernel__scalar(size_t n,const uint8_t *x,const uint8_t [256] t,uint8_t *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8lut\\scalar.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Scalar.cpp', [], ['    _local_scalar_dense_cpu(const Tensor & self)', '    item(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Scalar.cpp', [], ['    operator-']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Scalar.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Scalar.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Scalar.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\scalar_tensor_test.cpp', [], ['    require_equal_size_dim(const Tensor & lhs,const Tensor & rhs)', '    should_expand(const IntArrayRef & from_size,const IntArrayRef & to_size)', '    TEST(TestScalarTensor,TestScalarTensorCPU)', '    TEST(TestScalarTensor,TestScalarTensorCUDA)', '    test(DeprecatedTypeProperties & T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\scalar_test.cpp', [], ['    TEST(TestScalar,TestScalar)', '    test_overflow', '    apply(Tensor a,Tensor b)', '    apply(Tensor a,Tensor b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\scalar_type_analysis.cpp', ['    ScalarTypeHashFunction'], ['    CreateProfiledTensorTypeWithScalarType(const TensorTypePtr & typePtr,const c10::ScalarType & scalar_type)', '    ImplicitCastForONNX(Block *block)', '    InferExpectedScalarType(const Node *n)', '    IsComparisonOp(const NodeKind & nkind)', '    IsImplicitCastSupported(const NodeKind & nodeKind)', '    IsStandardOp(const NodeKind & nkind)', '    PromoteScalarTypes(const std::vector & types)', '    ScalarTypeToONNXType(const c10::ScalarType & st)', '    UpdateScalarTypeForInputs(Node *n,const c10::ScalarType & scalar_type)', '    UpdateScalarTypeForOutput(Node *n,const c10::ScalarType & scalar_type)', '    ImplicitCastForONNX(const std::shared_ptr & graph)', '    ScalarTypeAnalysisForONNX(const std::shared_ptr & graph)', '    operator()(const c10::ScalarType & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\scalar_type_analysis.h', [], ['    ScalarTypeAnalysisForONNX(const std::shared_ptr & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ScalarOps.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\ScalarType.h', ['    ScalarType'], ['    canCast(const ScalarType from,const ScalarType to)', '    elementSize(ScalarType t)', '    isComplexType(ScalarType t)', '    isFloatingType(ScalarType t)', '    isIntegralType(ScalarType t)', '    isIntegralType(ScalarType t,bool includeBool)', '    isQIntType(ScalarType t)', '    isSignedType(ScalarType t)', '    isUnderlying(ScalarType type,ScalarType qtype)', '    operator==(ScalarType t,caffe2::TypeMeta m)', '    operator==(caffe2::TypeMeta m,ScalarType t)', '    promoteTypes(ScalarType a,ScalarType b)', '    scalarTypeToTypeMeta(ScalarType scalar_type)', '    toQIntType(ScalarType t)', '    toString(ScalarType t)', '    toUnderlying(ScalarType t)', '    toValueType(ScalarType t)', '    tryTypeMetaToScalarType(caffe2::TypeMeta dtype)', '    typeMetaToScalarType(caffe2::TypeMeta dtype)', '    operator<<(std::ostream & stream,at::ScalarType scalar_type)', '    TypeMeta']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\ScalarType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ScalarType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\scale_blobs_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUScaleBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScaleBlobs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\scale_blobs_op.h', ['    final'], ['    DoRunWithType', '    RunOnDevice', '    ScaleBlobsOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\scale_op.cc', ['    GetScaleGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUScale', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Scale', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\scale_op.h', ['    final'], ['    DoRunWithType', '    RunOnDevice', '    ScaleOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\scale_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAScale', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\ScatterGatherKernel.cpp', [], ['    gather_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index)', '    gather_shape_check(const Tensor & self,int64_t dim,const Tensor & index)', '    scatter_add_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_fill_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,Scalar src)', '    scatter_shape_check(const Tensor & self,int64_t dim,const Tensor & index,const c10::optional & src_opt)', '    operator()(scalar_t *self_data,int64_t self_dim_stride,int64_t *index_data,int64_t index_dim_stride,scalar_t *src_data,int64_t src_dim_stride,int64_t dim,int64_t index_dim_size,int64_t index_upper_bound,const func_t & f)', '    operator()(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src,const std::string & method_name,const func_t & f,bool serial_exec)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\ScatterGatherShapeChecks.h', [], ['    gather_shape_check(const Tensor & self,int64_t dim,const Tensor & index)', '    scatter_shape_check(const Tensor & self,int64_t dim,const Tensor & index,const c10::optional & src_opt)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\torch_ops\\schema.cc', ['    PyTorchSchemasRegisterer'], ['    registerer', '    PyTorchSchemasRegisterer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\torch_ops\\schema.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\schema_matching.cpp', [], ['    emitBuiltinNode(const MatchedSchema & matched_schema,const SourceRange & loc,Graph & graph,Symbol name)', '    packOutputs(Graph & g,at::ArrayRef values,c10::OptNameList field_names)', '    prefixLine(const std::string & str,const std::string & prefix)', '    isIntOrFloatUsedAsList(const Value *value,const Argument & arg)', '    tryCreateList(const TypePtr & elem_type,Graph & graph,const SourceRange & loc,at::ArrayRef varargs,std::ostream *failure_messages,const std::function & err,bool convert_tensor_to_num,TypeEnv & type_env)', '    tryMatchArgument(const Argument & arg,Graph & graph,const SourceRange & loc,const NamedValue & named_value,std::ostream *failure_messages,const std::function & err,bool allow_conversions,TypeEnv & type_env)', '    tryMatchSchema(const FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,c10::optional self,std::ostream *failure_messages,bool allow_conversions)', '    unwrapOptional(TypePtr opt_type)', '    varargsCanBeUsedAsList(const FunctionSchema & schema,size_t arg_index,const Argument & arg)', '    allow_conversions', '    emitBuiltinCall(const SourceRange & loc,Graph & graph,Symbol name,at::ArrayRef inputs,at::ArrayRef attributes,const c10::optional & self)', '    err', '    matchSchemas(const std::vector & schemas,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & self,bool render_errors)', '    convertibleToList(const TypePtr & type,const TypePtr & list_type_)', '    findInputWithName(const std::string & name,at::ArrayRef kwargs)', '    tryConvertToType(const SourceRange & loc,Graph & graph,const TypePtr & concrete_type,Value *value,bool allow_conversions)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & self)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\schema_matching.h', [], ['    convertibleToList(const TypePtr & type,const TypePtr & list_type_)', '    emitBuiltinCall(const SourceRange & loc,Graph & graph,Symbol name,at::ArrayRef inputs,at::ArrayRef attributes,const c10::optional & self)', '    findInputWithName(const std::string & name,at::ArrayRef kwargs)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwarg,const c10::optional & self)', '    matchSchemas(const std::vector & schemas,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwarg,const c10::optional & self,bool render_errors)', '    tryConvertToType(const SourceRange & loc,Graph & graph,const TypePtr & concrete_type,Value *value,bool allow_conversions)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\schema_type_parser.cpp', [], ['    parseList(int begin,int sep,int end,const std::function & callback)', '    parseRefinedTensor', '    parseTensorDType(const std::string & dtype)', '    parseAliasAnnotation', '    parseBaseType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\schema_type_parser.h', [], ['    parseAliasAnnotation', '    parseBaseType', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseRefinedTensor', '    parseTensorDType(const std::string & dtype)', '    SchemaTypeParser(Lexer & L,bool parse_complete_tensor_types)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\sconv.cc', [], ['    TEST(SCONV_6x8__PSIMD,k_eq_1)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_strided_c)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_qmin128)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_qmax128)', '    TEST(SCONV_6x8__PSIMD,k_gt_1)', '    TEST(SCONV_6x8__PSIMD,k_gt_1_strided_c)', '    TEST(SCONV_6x8__PSIMD,k_gt_1_subtile)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\sconv.h', [], ['    pytorch_sconv_ukernel_6x8__psimd(size_t mr,size_t nr,size_t kc,size_t ks,const float **a,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\scope.cpp', [], ['    callee', '    InlinedCallStack(Function *fn,SourceRange source_range)', '    InlinedCallStack(InlinedCallStackPtr callee,Function *fn,SourceRange source_range)', '    intrusive_from_this', '    vec', '    getDepth', '    getRoot', '    intrusive_from_this', '    isBlank', '    isRoot', '    name', '    namesFromRoot(const std::string & separator)', '    parent', '    push(Symbol name)', '    Scope', '    Scope(ScopePtr parent,Symbol name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\scope.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\scope_guard.h', ['    ScopeGuardImplBase', '    ScopeGuardImpl'], ['    makeFailsafe(std::true_type,const void *)', '    ScopeGuardImpl(const FunctionType & fn)', '    execute', '    function_(std::forward fn)', '    MakeGuard(F)', '    ScopeGuardImpl(FunctionType)', '    ScopeGuardImpl(ScopeGuardImpl)', '    ScopeGuardImpl(Fn,ScopeGuardImplBase)', '    ref(*fn)', '    ~ScopeGuardImpl', '    asConst(const T & t)', '    makeEmptyScopeGuard', '    dismiss', '    ScopeGuardImplBase', '    ScopeGuardImpl(FunctionType & fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\script.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_call.cpp', [], ['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    matchOperator(const std::string & str_schema)', '    hasOp', '    hasQualifiedName', '    op', '    qualifiedName', '    ScriptCall(std::shared_ptr op,std::vector)', '    ScriptCall(const c10::QualifiedName & qualifiedName,std::vector)', '    stack', '    stackRef', '    toIValues(std::vector & ivalues)', '    toMessageImpl', '  Static Member Variables', '    ATEN_PREFIX_', '    BUILTIN_OP_NAMESPACE_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_call.h', ['    ScriptCall'], ['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    matchOperator(const std::string & str_schema)', '    hasOp', '    hasQualifiedName', '    op', '    qualifiedName', '    ScriptCall(std::shared_ptr op,std::vector)', '    ScriptCall(const c10::QualifiedName & qualifiedName,std::vector)', '    stack', '    stackRef', '    toIValues(std::vector & ivalues)', '    toMessageImpl', '    ~ScriptCall']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\script_init.cpp', [], ['    _jit_debug_module_iterators(Module & module)', '    bind(const py::module & m,const char *name)', '    mergeDefaultsAndExtraParametersToOverloadDecl(const Decl & overload_decl,const Decl & impl_decl,const FunctionDefaults & defaults)', '    script_compile_function(const c10::QualifiedName & name,const Def & def,const FunctionDefaults & defaults,ResolutionCallback rcb)', '    script_compile_overloaded_function(const c10::QualifiedName & name,const Decl & overload_decl,const Def & implementation_def,ResolutionCallback rcb,const FunctionDefaults & implementation_defaults,const py::object & signature)', '    _assign_output_shapes(Graph & graph,std::vector outputs)', '    _propagate_and_assign_input_shapes(Graph & graph,const std::vector & inputs,bool with_grad,bool propagate)', '    _propagate_shapes(Graph & graph,std::vector inputs,bool with_grad)', '    getTensorType(const at::Tensor & t,bool complete)', '    getTupleTensorType(const Stack::const_iterator & s_iter,const Stack::const_iterator & s_iter_end,const TypePtr & tupleType,bool complete)', '    setInputTensorTypes(Graph & g,const Stack & stack,bool complete)', '    debugMakeList(const T & list)', '    debugMakeNamedList(const T & list)', '    getattr(const std::string & name)', '    getSchemaWithNameAndDefaults(const SourceRange & range,const FunctionSchema & schema,const at::optional & new_name,const FunctionDefaults & default_args)', '    initJitScriptBindings(PyObject *module)', '    setattr(const std::string & name,py::object value)', '    addFunctionToModule(Module & module,const StrongFunctionPtr & func)', '    calcOverloadedFunctionDefaults(const FunctionSchema & schema,const FunctionDefaults & defaults)', '    checkMutableFunctionDefault(const py::object & def_arg)', '    checkOverloadDecl(const Decl & new_decl,const Decl & old_decl)', '    ivalue_tags_match(const Module & lhs,const Module & rhs)', '    pythonResolver(ResolutionCallback rcb)', '    pythonResolver(ResolutionCallback rcb,std::string classname,ClassTypePtr classType)', '    tryCalculateDefaultParam(const Argument & arg,const py::object & def_value)', '    isNamedTupleClass(py::object obj)', '    contains(const std::string & name)', '    slot_dict_impl(ModulePtr)', '    getClassType', '    makeSugared(Value *v)', '    ModuleSelf(std::shared_ptr concreteType)', '    PythonResolver(ResolutionCallback rcb)', '    PythonResolver(ResolutionCallback rcb,std::string classname,ClassTypePtr classType)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveTypeFromObject(const py::object & obj,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\script_init.h', [], ['    initJitScriptBindings(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\pytorch\\script_module_op.cc', ['    final', '    final', '    ScriptModuleDeserializer', '    ScriptModuleSerializer'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUScriptModule', '    CAFFE_ANONYMOUS_VARIABLE_CPUScriptModuleLoad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScriptModule', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScriptModuleLoad', '    noexcept', '    castIValueToTensor(IValue)', '    RunOnDevice', '    RunOnDevice', '    ScriptModuleLoadOp(const OperatorDef & operator_def,Workspace *ws)', '    ScriptModuleOp(const OperatorDef & operator_def,Workspace *ws)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_remote_call.cpp', [], ['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    ScriptRemoteCall(std::shared_ptr op,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    ScriptRemoteCall(const c10::QualifiedName & qualifiedName,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_remote_call.h', ['    final'], ['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    retForkId', '    retRRefId', '    ScriptRemoteCall(std::shared_ptr op,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    ScriptRemoteCall(const c10::QualifiedName & qualifiedName,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    toMessageImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_resp.cpp', [], ['    fromMessage(const Message & message)', '    ScriptResp(at::IValue)', '    toMessageImpl', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\script_resp.h', ['    final'], ['    fromMessage(const Message & message)', '    ScriptResp(at::IValue)', '    toMessageImpl', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\script_type_parser.cpp', [], ['    collectQualname(const Select & select)', '    isTorch(const Expr & expr)', '    evaluateDefaults(const SourceRange & r,const std::vector & default_types,const std::vector & default_exprs)', '    parseArgsFromDecl(const Decl & decl,bool skip_self)', '    parseBaseTypeName(const Expr & expr)', '    parseClassConstant(const Assign & assign)', '    parseReturnFromDecl(const Decl & decl)', '    parseSchemaFromDef(const Def & def,bool skip_self)', '    parseType(const std::string & str)', '    parseTypeFromExpr(const Expr & expr)', '    subscriptToType(const std::string & typeName,const Subscript & subscript)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\script_type_parser.h', ['    ScriptTypeParser'], ['    evaluateDefaults(const SourceRange & r,const std::vector & default_types,const std::vector & default_exprs)', '    parseArgsFromDecl(const Decl & decl,bool skip_self)', '    parseBaseTypeName(const Expr & expr)', '    parseClassConstant(const Assign & assign)', '    parseReturnFromDecl(const Decl & decl)', '    parseSchemaFromDef(const Def & def,bool skip_self)', '    parseType(const std::string & str)', '    parseTypeFromExpr(const Expr & expr)', '    ScriptTypeParser', '    ScriptTypeParser(ResolverPtr resolver)', '    subscriptToType(const std::string & typeName,const Subscript & subscript)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\sdwconv.h', [], ['    pytorch_sdwconv_ukernel_up4x9__psimd(size_t channels,size_t output_width,const float **input,const float *weights,float *output,size_t input_stride,size_t output_increment,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\segment_reduction_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsIndicesInGradientMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsIndicesInGradientSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientWeightedSumWithMainInputGradient', '    schema_OperatorName', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_gradient_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsIndicesInGradientMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsIndicesInGradientSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeLogMeanExpGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeLogSumExpGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentWeightedSumGradient', '    CostInferenceForSparseLengths(const OperatorDef & def,const vector & inputs,bool use_weight)', '    equal(char const *lhs,char const *rhs1,char const *rhs2,char const *rhs3)', '    FormatDoc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\segment_reduction_op.h', ['    AbstractSortedSegmentRangeGradientOp', '    BaseInputAccessor'], ['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    schema_LengthsMax', '    schema_LengthsMean', '    schema_LengthsSum', '    RangeReducer', '    PopulateSchema(OpSchema & schema)', '    GetGradientDefs', '    vector', '    AbstractSortedSegmentRangeGradientOp(Args,...)', '    RunOnDevice', '    ~AbstractSortedSegmentRangeGradientOp', '    BaseInputAccessor', '    getBlockPtr(int64_t in_block_size,int64_t idx,int64_t)', '    observeInput(const Tensor & dataInput)', '    raw_data']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\select_smooth_l1_loss_op.cc', ['    GetSelectSmoothL1LossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSelectSmoothL1Loss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSelectSmoothL1LossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SelectSmoothL1Loss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SelectSmoothL1LossGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\select_smooth_l1_loss_op.h', ['    final', '    final'], ['    buff_', '    buff_', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SelectSmoothL1LossGradientOp(const OperatorDef & def,Workspace *ws)', '    SelectSmoothL1LossOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\selu_op.cc', ['    GetSeluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUSeluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Selu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SeluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\selu_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    SeluGradientOp(Args,...)', '    SeluOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\functions\\sendrpc_backward.cpp', [], ['    apply(torch::autograd::variable_list)', '    setGrads(const torch::autograd::variable_list & grads)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\functions\\sendrpc_backward.h', [], ['    apply(torch::autograd::variable_list)', '    setGrads(const torch::autograd::variable_list & grads)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sequence_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAddPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUGatherPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUPadEmptySamples', '    CAFFE_ANONYMOUS_VARIABLE_CPURemovePadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AddPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadEmptySamples', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RemovePadding', '    g_inputs', '    g_inputs', '    padding_grads', '    zero', '    MakePadding(const T *in_ptr,T *out_ptr,const int32_t *lengths_ptr,int32_t lengths_size,int32_t outer_size,const T *padding_start_ptr,const T *padding_end_ptr,int64_t block_size)', '    RunOnDevice', '    GatherPadding(const int outer_size,const int lengths_size,const int block_size,const int pad_width,const T *in_ptr,const int *lengths_ptr,T *padding_start_ptr,T *padding_end_ptr)', '    GetGradientDefs', '    GetGradientDefs', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sequence_ops.h', ['    final', '    final', '    final', '    PadEmptySamplesOp'], ['    AddPaddingOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GatherPadding(const int outer_size,const int lengths_size,const int block_size,const int pad_width,const T *in_ptr,const int *lengths_ptr,T *padding_start_ptr,T *padding_end_ptr)', '    GatherPaddingOp(Args,...)', '    GetSingleArgument', '    lengths_prefix_sum_', '    lengths_prefix_sum_', '    lengths_prefix_sum_', '    lengths_prefix_sum_buffer_', '    lengths_prefix_sum_buffer_', '    lengths_prefix_sum_buffer_', '    MakePadding(const T *in_ptr,T *out_ptr,const int32_t *lengths_ptr,int32_t lengths_size,int32_t outer_size,const T *padding_start_ptr,const T *padding_end_ptr,int64_t block_size)', '    RemovePaddingOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    PadEmptySamplesOp(Args,...)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\detail\\sequencers.h', [], ['    buffer_contains_result(const std::vector)', '    next(ResultProducer next_result)', '    buffer(size_t index)', '    next(ResultProducer next_result)', '    OrderedSequencer(size_t max_jobs)', '    next(ResultProducer next_result)', '    ~Sequencer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\sequential.cpp', [], ['    forward', '    forward', '    forward', '    forward', '    forward', '    M(const M & other)', '    TEST_F(SequentialTest,CanContainThings)', '    TEST_F(SequentialTest,ConstructsFromSharedPointer)', '    TEST_F(SequentialTest,ConstructsFromConcreteType)', '    TEST_F(SequentialTest,ConstructsFromModuleHolder)', '    TEST_F(SequentialTest,PushBackAddsAnElement)', '    TEST_F(SequentialTest,AccessWithAt)', '    TEST_F(SequentialTest,AccessWithPtr)', '    TEST_F(SequentialTest,CallingForwardOnEmptySequentialIsDisallowed)', '    TEST_F(SequentialTest,CallingForwardChainsCorrectly)', '    TEST_F(SequentialTest,CallingForwardWithTheWrongReturnTypeThrows)', '    TEST_F(SequentialTest,TheReturnTypeOfForwardDefaultsToTensor)', '    TEST_F(SequentialTest,ForwardReturnsTheLastValue)', '    TEST_F(SequentialTest,SanityCheckForHoldingStandardModules)', '    TEST_F(SequentialTest,ExtendPushesModulesFromOtherSequential)', '    TEST_F(SequentialTest,HasReferenceSemantics)', '    TEST_F(SequentialTest,IsCloneable)', '    TEST_F(SequentialTest,RegistersElementsAsSubmodules)', '    TEST_F(SequentialTest,CloneToDevice_CUDA)', '    TEST_F(SequentialTest,PrettyPrintSequential)', '    TEST_F(SequentialTest,ModuleForwardMethodOptionalArg)', '    forward(int x)', '    forward(int x)', '    forward(int x)', '    forward(int x)', '    forward(torch::Tensor v)', '    forward', '    forward', '    MImpl(int value_)', '    forward(int value)', '    MockModule(int value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\data\\samplers\\sequential.cpp', [], ['    index', '    load(serialize::InputArchive & archive)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    SequentialSampler(size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\container\\sequential.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\sequential.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\serialization.cpp', [], ['    doRead(file,& size,)', '    doRead(file,data,)', '    doRead(file,le_buffer,)', '    THP(THStorage *self,io fd,bool save_size)', '    THPUtils_setError(__VA_ARGS__)', '    THP_decodeInt16Buffer(int16_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)', '    THP_decodeInt32Buffer(int32_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)', '    THP_decodeInt64Buffer(& size,,torch::utils::THP_nativeByteOrder,)', '    THP_decodeInt64Buffer(int64_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\serialization.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\serialization.cpp', [], ['    doPartialPythonIO(PyObject *fildes,void *buf,size_t nbytes,bool is_read)', '    doPartialPythonReadBuffered(PyObject *fildes,void *buf,size_t raw_nbytes)', '    doPartialPythonReadInto(PyObject *fildes,void *buf,size_t nbytes)', '    doPartialPythonWrite(PyObject *fildes,void *buf,size_t nbytes)', '    isUnsupportedOperation', '    doPartialRead(int fildes,void *buf,size_t nbytes)', '    doPartialRead(PyObject *fildes,void *buf,size_t nbytes)', '    doPartialWrite(int fildes,void *buf,size_t nbytes)', '    doPartialWrite(PyObject *fildes,void *buf,size_t nbytes)', '    doRead(io fildes,void *raw_buf,size_t nbytes)', '    doWrite(io fildes,void *raw_buf,size_t nbytes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\serialization.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\serialization.h', [], ['    doRead(io fildes,void *raw_buf,size_t nbytes)', '    doWrite(io fildes,void *raw_buf,size_t nbytes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\serialization.h', [], ['    THP(THStorage *self,io fd,bool save_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\serialize.cpp', [], ['    pickle_load(const std::vector & data)', '    pickle_save(const at::IValue & ivalue)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\serialize.cpp', [], ['    serialize(serialize::InputArchive & archive,const std::string & key,int64_t & value)', '    serialize(serialize::OutputArchive & archive,const std::string & key,const std::vector & steps)', '    serialize(serialize::InputArchive & archive,const std::string & key,std::vector & steps)', '    serialize(serialize::OutputArchive & archive,const std::string & key,const int64_t & value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\serialize.cpp', [], ['    closure', '    closure', '    is_optimizer_param_group_equal(const OptimizerParamGroup & lhs,const OptimizerParamGroup & rhs)', '    is_optimizer_state_equal(const ska::flat_hash_map,std::unique_ptr,const ska::flat_hash_map,std::unique_ptr)', '    iteration_', '    save_and_load(torch::Tensor input)', '    step', '    step', '    step', '    step', '    step', '    step', '    step', '    TEST(SerializeTest,KeysFunc)', '    TEST(SerializeTest,TryReadFunc)', '    TEST(SerializeTest,Basic)', '    TEST(SerializeTest,BasicToFile)', '    TEST(SerializeTest,BasicViaFunc)', '    TEST(SerializeTest,Resized)', '    TEST(SerializeTest,Sliced)', '    TEST(SerializeTest,NonContiguous)', '    TEST(SerializeTest,ErrorOnMissingKey)', '    TEST(SerializeTest,XOR)', '    TEST(SerializeTest,Optim)', '    TEST(SerializeTest,Optim_Adagrad)', '    TEST(SerializeTest,Optim_SGD)', '    TEST(SerializeTest,Optim_Adam)', '    TEST(SerializeTest,Optim_RMSprop)', '    TEST(SerializeTest,Optim_LBFGS)', '    TEST(SerializeTest,XOR_CUDA)', '    TEST(SerializeTest,CanSerializeModulesWithIntermediateModulesWithoutParametersOrBuffers)', '    TEST(SerializeTest,VectorOfTensors)', '    TEST(SerializeTest,IValue)', '    TEST(SerializeTest,UnserializableSubmoduleIsSkippedWhenSavingModule)', '    TEST(SerializeTest,UnserializableSubmoduleIsIgnoredWhenLoadingModule)', '    test_serialize_optimizer(DerivedOptimizerOptions options,bool only_has_global_state)', '    write_int_value(torch::serialize::OutputArchive & archive,const std::string & key,const int64_t & value)', '    write_step_buffers(torch::serialize::OutputArchive & archive,const std::string & key,const std::vector & steps)', '    write_tensors_to_archive(torch::serialize::OutputArchive & archive,const std::string & key,const BufferContainer & buffers)', '    xor_model', '    A', '    A', '    A', '    A(const std::string & name_b,const std::string & name_c)', '    B(const std::string & name_c)', '    B', '    C', '    M']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\serialize.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\serialize.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\serialize.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\optim\\sgd.cpp', [], ['    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)', '    operator==(const SGDOptions & lhs,const SGDOptions & rhs)', '    operator==(const SGDParamState & lhs,const SGDParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    SGDOptions(double lr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\optim\\sgd.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\sgemm.cc', [], ['    MobileNetV1(benchmark::internal::Benchmark *b)', '    MobileNetV2(benchmark::internal::Benchmark *b)', '    ResNet18(benchmark::internal::Benchmark *b)', '    ResNet50(benchmark::internal::Benchmark *b)', '    sgemm(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    sgemm_6x8__psimd(benchmark::State & state,const char *net)', '    sgemm_in_l1(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    sgemmBenchmark(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mc,uint32_t nc,uint32_t kc,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X05(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X10(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X15(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X20(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)', '    clampingParams', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\sgemm.cc', [], ['    TEST(SGEMM_6x8__PSIMD,k_eq_2)', '    TEST(SGEMM_6x8__PSIMD,k_eq_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_eq_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_eq_8_qmin128)', '    TEST(SGEMM_6x8__PSIMD,k_eq_8_qmax128)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_subtile)', '    TEST(SGEMM_6x8__PSIMD,k_div_2)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_subtile)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\sgemm.h', [], ['    pytorch_sgemm_ukernel_5x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)', '    pytorch_sgemm_ukernel_6x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)', '    pytorch_sgemm_ukernel_6x8__psimd(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\shape_analysis.cpp', ['    ShapePropagator'], ['    all_reduce_ops', '    all_reduce_ops_with_integer_upcast_and_dtype', '    any_tensor_type', '    argminmax', '    binary_ops_strict_match', '    broadcast', '    broadcasting_ops', '    broadcasting_ops_arithmetic', '    broadcasting_tensor_scalar_ops', '    broadcasting_tensor_scalar_ops_arithmetic', '    cast_ops', '    comparison_ops', '    determineListSize(Value *list)', '    dim_reduce_ops', '    dim_reduce_ops_dtype', '    dim_reduce_ops_with_integer_upcast', '    factory_with_ndim', '    fused_accum_binary_ops', '    get_cast_scalar_type', '    like_factories_with_options', '    multidim_reduce_with_keepdim', '    nn_ops_first_input_preserving', '    propagate', '    propagate_complete', '    reduce_op_handler', '    reduce_ops_with_opt_dtype', '    register_softmax', '    reshape_prop', '    resize_ops', '    simple_unary_ops', '    size_factories_with_options', '    where_op', '    broadcastBinary(Node *node,std::vector & types,size_t idx1,size_t idx2)', '    canPropagateShapeByRunningIt(Node *node)', '    dependsOnMutation(Node *node)', '    DoesntRefineOutputs(Node *node)', '    EraseShapeInformation(at::ArrayRef vals)', '    EraseShapeInformation(Block *b)', '    EraseShapeInformation(const std::shared_ptr & graph)', '    getPromotedTypeForArithmeticOp(Node *node)', '    getSingleOutputType', '    mergeTypes(ArrayRef lhs,ArrayRef rhs,ArrayRef outputs)', '    PropagateCatShape(Node *cat_node)', '    PropagateCompleteShapeOnNode(Node *node,bool insert_expands,std::vector tensor_types)', '    PropagateInputShapes(const std::shared_ptr & graph)', '    PropagateShapeOnNode(Node *node,bool insert_expands)', '    PropagateShapeOnNodeByRunningIt(Node *node)', '    PropagateTensorShapeOnNode(Node *node,bool insert_expands)', '    propagateTorchTensorShape(Node *node)', '    setUnshapedTypeIfAliasResizedSet(at::ArrayRef vs)', '    containsTensorType(const TypePtr & t)', '    isValidArgumentForRunning(Value *v)', '    isValidReturnForRunning(Value *v)', '    unionScalarTypes(c10::ScalarType original,c10::ScalarType next)', '    jitDeviceIndexToDevice(int device)', '    register_formula_for(OperatorSet operators,formula_t formula)', '    collectResizeSet(Block *block)', '    PropagateShapeOnBlock(Block *block,bool insert_expands)', '    representativeValue(Value *v)', '    resizesInput(Node *n)', '    setUnshapedType(Value *o)', '    setUnshapedType(Node *node)', '    ShapePropagator(std::shared_ptr graph)', '    wrapDim(int64_t dim,at::IntArrayRef sizes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\shape_analysis.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\shape_info.cc', [], ['    constructShapeInfoWithDefaultDimType(TensorShape shape,TensorBoundShape_DimType defaultFirstDimType)', '    getShapeInfoFromBlob(const Blob *blob)', '    operator==(const ShapeInfo & lhs,const ShapeInfo & rhs)', '    parseShapeInfoMapFromString(const std::string & input,ShapeInfoMap & shape_hints)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\shape_info.h', [], ['    constructShapeInfoWithDefaultDimType(TensorShape shape,TensorBoundShape_DimType defaultFirstDimType)', '    getShapeInfoFromBlob(const Blob *blob)', '    operator==(const ShapeInfo & lhs,const ShapeInfo & rhs)', '    parseShapeInfoMapFromString(const std::string & input,ShapeInfoMap & shape_hints)', '    QShapeInfo(float o,float s,uint32_t a)', '    dimTypeIsSet', '    getDimType', '    getDimType(int idx)', '    setDimType(const std::vector & dim_types)', '    setDimType(int idx,TensorBoundShape_DimType type)', '    ShapeInfo(bool q)', '    ShapeInfo(std::vector,TensorShape,bool q)', '    ShapeInfo(const std::vector & t,TensorShape,bool q)', '    ShapeInfo(const std::vector & t,const TensorShape & s,bool q)', '    ShapeInfo(bool q,const QShapeInfo & info)', '    ShapeInfo(const std::vector & t,TensorShape,bool q,const QShapeInfo & info)', '    ShapeInfo(const std::vector & t,const TensorShape & s,bool q,const QShapeInfo & info)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\shape_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUShape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Shape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\shape_op.cc', ['    IDEEPShapeOp'], ['    IDEEPShapeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\shape_op.h', ['    ShapeOp'], ['    RunOnDevice', '    ShapeOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\shape_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAShape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\shared.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SharedReduceOps.h', [], ['    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    combine(arg_t a,arg_t b)', '    project(arg_t)', '    reduce(arg_t arg,scalar_t val,int64_t idx)', '    translate_idx(arg_t a,int64_t base_idx)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    operator()(scalar_t a,scalar_t b)', '    operator()(scalar_t a,scalar_t b)', '    combine(acc_t a,acc_t b)', '    MeanOps(factor_t factor)', '    project(acc_t a)', '    reduce(acc_t a,acc_t b,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    NormOps(acc_t norm_)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    WelfordData', '    WelfordData(scalar_t mean,scalar_t m2,index_t n,combine_t nf)', '    combine(acc_t a,acc_t b)', '    project(acc_t acc)', '    reduce(acc_t acc,scalar_t data,index_t)', '    WelfordOps(bool unbiased,bool take_sqrt)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\xnnpack\\Shim.cpp', [], ['    available', '    convolution2d(const Tensor &,const Tensor &,const Tensor &,const IntArrayRef,const IntArrayRef,const IntArrayRef,const int64_t,const bool)', '    linear(const Tensor &,const Tensor &,const Tensor &)', '    use_convolution2d(const Tensor &,const Tensor &,const Tensor &,const IntArrayRef,const IntArrayRef,const IntArrayRef,const int64_t,const bool)', '    use_linear(const Tensor &,const Tensor &,const Tensor &)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\shm_mutex\\shm_mutex.cc', [], ['    getInstance', '    addLock(const std::string & name)', '    removeLock(const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\shm_mutex\\shm_mutex.h', ['    ShmProcessMutex', '    ShmProcessMutexCheck', '    ShmTicketMutex', '    ShmTTSetMutex'], ['    getInstance', '    internalDestroy', '    lock', '    operator=(ShmProcessMutex)', '    ShmProcessMutex(ShmProcessMutex)', '    ShmProcessMutex(const char *name)', '    try_lock', '    unlock', '    ~ShmProcessMutex', '    addLock(const std::string & name)', '    operator=', '    removeLock(const std::string & name)', '    ShmProcessMutexCheck', '    ShmProcessMutexCheck', '    ShmTicketMutex(const char *name,int delay)', '    subUnlock', '    waitForLock', '    ShmTTSetMutex(const char *name,int timeout)', '    subUnlock', '    waitForLock']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\sigmoid-operator-tester.h', ['    SigmoidOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sigmoid.c', [], ['    pytorch_qnnp_create_sigmoid_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *sigmoid_out)', '    pytorch_qnnp_setup_sigmoid_nc_q8(pytorch_qnnp_operator_t sigmoid,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\sigmoid.cc', [], ['    Compute(T x)', '    Sigmoid(double max_abs_err)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\sigmoid.cc', [], ['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    sigmoid_q8(benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\sigmoid.cc', [], ['    TEST(SIGMOID_OP,zero_batch)', '    TEST(SIGMOID_OP,unit_batch)', '    TEST(SIGMOID_OP,unit_batch_with_qmin)', '    TEST(SIGMOID_OP,unit_batch_with_qmax)', '    TEST(SIGMOID_OP,unit_batch_with_input_scale)', '    TEST(SIGMOID_OP,unit_batch_with_input_zero_point)', '    TEST(SIGMOID_OP,small_batch)', '    TEST(SIGMOID_OP,small_batch_with_input_stride)', '    TEST(SIGMOID_OP,small_batch_with_output_stride)', '    TEST(SIGMOID_OP,small_batch_with_qmin)', '    TEST(SIGMOID_OP,small_batch_with_qmax)', '    TEST(SIGMOID_OP,small_batch_with_input_scale)', '    TEST(SIGMOID_OP,small_batch_with_input_zero_point)', '    TEST(SIGMOID_OP,strided_batch)', '    TEST(SIGMOID_OP,strided_batch_with_qmin)', '    TEST(SIGMOID_OP,strided_batch_with_qmax)', '    TEST(SIGMOID_OP,strided_batch_with_input_scale)', '    TEST(SIGMOID_OP,strided_batch_with_input_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\sigmoid.h', ['    Sigmoid'], ['    Compute(T x)', '    GetInputQuantizationParams', '    GetOutputQuantizationParams', '    Sigmoid(double max_abs_err)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\sigmoid_cpu.cc', [], ['    sigmoid_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sigmoid_cross_entropy_loss_op.cc', ['    GetSigmoidCrossEntropyLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyLossGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sigmoid_cross_entropy_loss_op.h', ['    final', '    final'], ['    counts_', '    counts_', '    GetSingleArgument', '    losses_', '    RunOnDevice', '    RunOnDevice', '    SigmoidCrossEntropyLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SigmoidCrossEntropyLossOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\sigmoid_cross_entropy_with_logits_cpu.cc', [], ['    sigmoid_cross_entropy_with_logits_op_cpu_impl(const at::Tensor & logits_,const at::Tensor & targets_,const at::Tensor & out_,bool log_D_trick,bool unjoined_lr_loss)', '    sigmoid_partition(float lgt)', '    sigmoid_xent_forward(float lgt,float tgt)', '    sigmoid_xent_forward_with_log_d_trick(float lgt,float tgt)', '    unjoined_sigmoid_xent_forward(float lgt,float tgt)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\sigmoid_dnnlowp_op.cc', ['    SigmoidFunctor'], ['    GetOutputQuantizationParams', '    operator()(const int n,const T *x,T *y)', '    SigmoidFunctor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sigmoid_focal_loss_op.cc', ['    GetSigmoidFocalLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFocalLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFocalLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFocalLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFocalLossGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\sigmoid_focal_loss_op.h', ['    final', '    final'], ['    counts_', '    counts_', '    GetSingleArgument', '    losses_', '    RunOnDevice', '    RunOnDevice', '    SigmoidFocalLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SigmoidFocalLossOp(const OperatorDef & operator_def,Workspace *ws)', '    weights_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sigmoid_gradient_op.cc', ['    GetSigmoidGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sigmoid_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidGradient', '    operator()(const int N,const T *X,T *Y,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\sigmoid_op.cc', ['    final', '    final'], ['    IDEEPSigmoidGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSigmoidOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPSigmoidGradientOp', '    ~IDEEPSigmoidOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sigmoid_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sigmoid_op_cudnn.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\sigmoid_test.cc', [], ['    TEST(Sigmoid,SigmoidUnitTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\signal_handler.cc', [], ['    CheckForSignals', '    GotSIGHUP', '    GotSIGINT', '    SignalHandler(SignalHandler::Action SIGINT_action,SignalHandler::Action SIGHUP_action)', '    ~SignalHandler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\signal_handler.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\vector\\simd.h', [], ['    detectHostSIMDExtensions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\simple_ops.cpp', [], ['    AA_op(const Tensor & self)', '    BB_op(const Tensor & self)', '    CC_op(const Tensor & self)', '    DD_op(const Tensor & self)', '    EE_op(const Tensor & self)', '    FF_op(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\simple_ops.h', [], ['    call_AA_op(const Tensor & self)', '    call_BB_op(const Tensor & self)', '    call_CC_op(const Tensor & self)', '    call_DD_op(const Tensor & self)', '    call_EE_op(const Tensor & self)', '    call_FF_op(const Tensor & self)', '    singleton']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\simple_queue.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\simple_queue_test.cc', [], ['    ConsumerFunction(int thread_idx)', '    ProducerFunction(int thread_idx,int start,int count)', '    TEST(SimpleQueueTest,SingleProducerSingleConsumer)', '    TEST(SimpleQueueTest,SingleProducerDoubleConsumer)', '    TEST(SimpleQueueTest,DoubleProducerDoubleConsumer)', '    TEST(SimpleQueueDeathTest,CannotAddAfterQueueFinished)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sin_op.cc', ['    GetSinGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSin', '    CAFFE_ANONYMOUS_VARIABLE_CPUSinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinGradient', '    GetGradientDefs', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sin_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\single_op_transform.cc', [], ['    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\transforms\\single_op_transform.h', ['    SingleOpTransform'], ['    MatchOperator(const OperatorDef & op)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceOperator(OperatorDef *op)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sinh_op.cc', ['    GetSinhGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSinh', '    CAFFE_ANONYMOUS_VARIABLE_CPUSinhGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sinh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinhGradient', '    GetGradientDefs', '    Forward(const std::vector &,const std::vector & X_dims,const T *dY,const T *X,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sinh_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sinusoid_position_encoding_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSinusoidPositionEncoding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinusoidPositionEncoding']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sinusoid_position_encoding_op.h', ['    SinusoidPositionEncodingOp'], ['    DoRunWithType', '    GetSingleArgument', '    Input', '    RunOnDevice', '    SinusoidPositionEncodingOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\six.h', [], ['    isStructSeq(pybind11::handle input)', '    isStructSeq(PyObject *obj)', '    isTuple(pybind11::handle input)', '    isTuple(PyObject *obj)', '    maybeAsTuple(PyStructSequence *obj)', '    maybeAsTuple(PyObject *obj)', '    handle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Size.cpp', [], ['    isTracedZeroDimVar(PyObject *item)', '    THPSize_numel(THPSize *self,PyObject *noargs)', '    THPSize_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPSize_reduce(THPSize *self,PyObject *noargs)', '    THPSize_repr(THPSize *self)', '    wrap_tuple_fn(Args,...)', '    ret', '    THPSize_init(PyObject *module)', '    THPSize_New(const torch::autograd::Variable & var)', '    THPSize_NewFromSizes(int dim,const int64_t *sizes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Size.h', [], ['    THPSize_init(PyObject *module)', '    THPSize_New(const torch::autograd::Variable & var)', '    THPSize_NewFromSizes(int dim,const int64_t *sizes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\slice_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSlice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Slice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SliceGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\slice_op.h', ['    SliceOp', '    SliceGradientOp'], ['    SliceImpl(Tensor *output,const Tensor & data,const Tensor & starts,const Tensor & ends,Context *context,Tensor *gdata,const Tensor *go)', '    DoRunWithType', '    operator=', '    RunOnDevice', '    SliceOp(Args,...)', '    SliceOp', '    itemsize', '    nbytes', '    ResizeLike', '    DoRunWithType', '    operator=', '    RunOnDevice', '    SliceGradientOp(Args,...)', '    SliceGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\SmallVector.cpp', [], ['    grow_pod(void *FirstEl,size_t MinSizeInBytes,size_t TSize)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\SmallVector.h', ['    SmallVector', '    SmallVectorBase', '    SmallVectorImpl', '    SmallVectorTemplateBase', '    SmallVectorTemplateBase', '    SmallVectorTemplateCommon'], ['    NextPowerOf2(uint64_t A)', '    capacity_in_bytes(const SmallVector & X)', '    operator<<(std::ostream & out,const SmallVector & list)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    destroy_range(T *,T *)', '    destroy_range(T *S,T *E)', '    uninitialized_copy(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_copy(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_copy(T1 *Iit,T1 *Eit,T2 *Dest,std::enable_if::type *)', '    uninitialized_move(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_move(It1 Iit,It1 Eit,It2 Dest)', '    operator=(const SmallVector & RHS)', '    operator=(const Container & RHS)', '    operator=(SmallVector)', '    operator=(SmallVectorImpl)', '    operator=(Container)', '    operator=(std::initializer_list IL)', '    SmallVector', '    SmallVector(size_t Size,const T & Value)', '    SmallVector(ItTy S,ItTy E)', '    SmallVector(Container)', '    SmallVector(std::initializer_list IL)', '    SmallVector(const SmallVector & RHS)', '    SmallVector(SmallVector)', '    SmallVector(SmallVectorImpl)', '    capacity_in_bytes', '    empty', '    grow_pod(void *FirstEl,size_t MinSizeInBytes,size_t TSize)', '    size_in_bytes', '    SmallVectorBase(void *FirstEl,size_t Size)', '    append(in_iter in_start,in_iter in_end)', '    append(size_type NumInputs,const T & Elt)', '    append(std::initializer_list IL)', '    assign(size_type NumElts,const T & Elt)', '    assign(in_iter in_start,in_iter in_end)', '    assign(std::initializer_list IL)', '    clear', '    emplace_back(ArgTypes,...)', '    erase(const_iterator CIit)', '    erase(const_iterator CSit,const_iterator CEit)', '    insert(iterator Iit,T)', '    insert(iterator Iit,const T & Elt)', '    insert(iterator Iit,size_type NumToInsert,const T & Elt)', '    insert(iterator Iit,ItTy From,ItTy To)', '    insert(iterator Iit,std::initializer_list IL)', '    operator!=(const SmallVectorImpl & RHS)', '    operator<(const SmallVectorImpl & RHS)', '    operator=(const SmallVectorImpl & RHS)', '    operator=(SmallVectorImpl)', '    operator==(const SmallVectorImpl & RHS)', '    pop_back_val', '    reserve(size_type N)', '    resize(size_type N)', '    resize(size_type N,const T & NV)', '    set_size(size_type N)', '    SmallVectorImpl(unsigned N)', '    SmallVectorImpl', '    swap(SmallVectorImpl & RHS)', '    ~SmallVectorImpl', '    grow(size_t MinSize)', '    grow(size_t MinSize)', '    pop_back', '    pop_back', '    push_back(const T & Elt)', '    push_back(T)', '    push_back(const T & Elt)', '    SmallVectorTemplateBase(size_t Size)', '    SmallVectorTemplateBase(size_t Size)', '    at(size_type idx)', '    at(size_type idx)', '    back', '    back', '    begin', '    begin', '    capacity', '    capacity_ptr', '    capacity_ptr', '    data', '    data', '    end', '    end', '    front', '    front', '    grow_pod(size_t MinSizeInBytes,size_t TSize)', '    isSmall', '    max_size', '    operator[](size_type idx)', '    operator[](size_type idx)', '    rbegin', '    rbegin', '    rend', '    rend', '    resetToSmall', '    setEnd(T *P)', '    size', '    SmallVectorTemplateCommon(size_t Size)', '    bad_alloc', '    copy', '    distance', '    equal', '    fill_n', '    lexicographical_compare', '    make_move_iterator', '    move_backward', '    move_iterator', '    swap', '    uninitialized_copy', '    uninitialized_fill', '    uninitialized_fill_n']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\SmallVector.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\smart_tensor_printer.cc', [], ['    DefaultTensorPrinter', '    PrintTensor(const Tensor & tensor)', '    DoRunWithType', '    Print', '    Print(const Tensor & tensor)', '    SmartTensorPrinter(const std::string & tensor_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\smart_tensor_printer.h', ['    SmartTensorPrinter'], ['    DefaultTensorPrinter', '    PrintTensor(const Tensor & tensor)', '    Print(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    PrintTensorMeta(const Tensor & tensor)', '    SmartTensorPrinter(const std::string & tensor_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    SmartTensorPrinter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\smart_tensor_printer_test.cc', [], ['    expect_stderr_contains(const std::vector & values)', '    my_to_string(const T & value)', '    my_to_string(const std::string & value)', '    printTensorAndCheck(const std::vector & values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\smooth_l1_loss_op.cc', ['    GetSmoothL1LossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSmoothL1Loss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSmoothL1LossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SmoothL1Loss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SmoothL1LossGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\smooth_l1_loss_op.h', ['    final', '    final'], ['    buff_', '    buff_', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SmoothL1LossGradientOp(const OperatorDef & def,Workspace *ws)', '    SmoothL1LossOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\snpe\\snpe_ffi.cc', [], ['    copyOutputTo(float *outputData)', '    snpe_copy_output_to(void *ctx,float *outputData)', '    snpe_create(const uint8_t *container,size_t size,const char *input_name)', '    snpe_destroy(void *ctx)', '    snpe_get_input_dims(void *ctx,size_t const **dims,size_t *size)', '    snpe_has_gpu', '    snpe_run(void *ctx,const float *inputData,size_t inputSize,size_t const **outputDims,size_t *outputSize)', '    getInputDims', '    SNPEContext(const std::vector & buffer,const char *input_name,bool enable_logging)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\snpe\\snpe_ffi.h', [], ['    gSNPELocation', '    snpe_copy_output_to(void *ctx,float *outputData)', '    snpe_create(const uint8_t *container,size_t size,const char *input_name)', '    snpe_destroy(void *ctx)', '    snpe_get_input_dims(void *ctx,size_t const **dims,size_t *size)', '    snpe_has_gpu', '    snpe_run(void *ctx,const float *inputData,size_t inputSize,size_t const **outputDims,size_t *outputSize)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\snpe\\snpe_globals.cc', [], ['    gSNPELocation']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\snpe\\snpe_op.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSNPE', '    RunOnDevice', '    SNPEOp(const OperatorDef & def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\snpe\\snpe_op_benchmark.cc', [], ['    main']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SobolEngineOps.cpp', [], ['    _sobol_engine_draw(const Tensor & quasi,int64_t n,const Tensor & sobolstate,int64_t dimension,int64_t num_generated,optional dtype)', '    _sobol_engine_ff_(Tensor & quasi,int64_t n,const Tensor & sobolstate,int64_t dimension,int64_t num_generated)', '    _sobol_engine_initialize_state_(Tensor & sobolstate,int64_t dimension)', '    _sobol_engine_scramble_(Tensor & sobolstate,const Tensor & ltm,int64_t dimension)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SobolEngineOpsUtils.h', [], ['    bit_length(const int64_t n)', '    bitsubseq(const int64_t n,const int64_t pos,const int64_t length)', '    cdot_pow2(const at::Tensor & bmat)', '    rightmost_zero(const int64_t n)', '    options', '    size']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\libshm\\socket.h', ['    ClientSocket', '    ManagerServerSocket', '    ManagerSocket', '    Socket'], ['    ClientSocket(const std::string & path)', '    register_allocation(AllocInfo & info)', '    register_deallocation(AllocInfo & info)', '    accept', '    ManagerServerSocket(const std::string & path)', '    ~ManagerServerSocket', '    confirm', '    ManagerSocket(int fd)', '    receive', '    address_length(struct sockaddr_un address)', '    prepare_address(const char *path)', '    recv(void *_buffer,size_t num_bytes)', '    send(const void *_buffer,size_t num_bytes)', '    Socket', '    Socket', '    Socket(Socket)', '    Socket(int fd)', '    ~Socket']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\softargmax-operator-tester.h', ['    SoftArgMaxOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    testQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\softargmax.c', [], ['    pytorch_qnnp_create_softargmax_nc_q8(size_t channels,float input_scale,uint8_t output_zero_point,float output_scale,uint32_t flags,pytorch_qnnp_operator_t *softargmax_out)', '    pytorch_qnnp_setup_softargmax_nc_q8(pytorch_qnnp_operator_t softargmax,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\softargmax.cc', [], ['    TEST(SOFTARGMAX_OP,zero_batch)', '    TEST(SOFTARGMAX_OP,single_class)', '    TEST(SOFTARGMAX_OP,two_classes)', '    TEST(SOFTARGMAX_OP,many_classes)', '    TEST(SOFTARGMAX_OP,cifar_classes)', '    TEST(SOFTARGMAX_OP,imagenet_classes)', '    TEST(SOFTARGMAX_OP,many_channels_with_input_scale)', '    TEST(SOFTARGMAX_OP,many_channels_with_input_zero_point)', '    TEST(SOFTARGMAX_OP,small_batch)', '    TEST(SOFTARGMAX_OP,small_batch_with_input_stride)', '    TEST(SOFTARGMAX_OP,small_batch_with_output_stride)', '    TEST(SOFTARGMAX_OP,strided_batch_with_input_and_output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\softargmax.cc', [], ['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    softargmax_q8(benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SoftMax.cpp', [], ['    host_softmax(Tensor output,const Tensor & input,const int64_t dim)', '    host_softmax_backward(Tensor & gI,const Tensor & grad,const Tensor & output,int64_t dim)', '    log_softmax(const Tensor & input_,const int64_t dim_)', '    log_softmax(const Tensor & input_,const int64_t dim_,c10::optional dtype)', '    log_softmax(const Tensor & self,Dimname dim,optional dtype)', '    log_softmax_backward_cpu(const Tensor & grad_,const Tensor & output_,int64_t dim_,const Tensor & input_)', '    log_softmax_cpu(const Tensor & input_,const int64_t dim_,const bool half_to_float)', '    softmax(const Tensor & input_,const int64_t dim_)', '    softmax(const Tensor & input_,const int64_t dim_,c10::optional dtype)', '    softmax(const Tensor & self,Dimname dim,optional dtype)', '    softmax_backward_cpu(const Tensor & grad_,const Tensor & output_,int64_t dim_,const Tensor & input_)', '    softmax_cpu(const Tensor & input_,const int64_t dim_,const bool half_to_float)', '    grad_arg', '    grad_arg', '    result', '    result', '    result', '    result']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\SoftMax.cpp', [], ['    mkldnn_softmax(const Tensor & self,const int64_t dim,const bool half_to_float)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\softmax_focal_loss_op.cc', ['    GetSoftmaxFocalLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxFocalLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxFocalLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxFocalLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxFocalLossGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\softmax_focal_loss_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SoftmaxFocalLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SoftmaxFocalLossOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_op.cc', ['    GetSoftmaxGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_op.h', ['    final', '    final'], ['    RunOnDevice', '    SoftmaxGradientOp(Args,...)', '    SoftmaxOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_op_cudnn.cc', ['    final', '    final'], ['    CuDNNSoftmaxGradientOp(Args,...)', '    CuDNNSoftmaxOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    ~CuDNNSoftmaxGradientOp', '    ~CuDNNSoftmaxOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_utils.cc', [], ['    SoftmaxCPU(const int N,const int D,const bool logarithmic,const float *X,float *Y,float *scratch,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_utils.h', [], ['    SoftmaxCPU(int N,int D,bool logarithmic,const T *X,T *Y,T *scratch,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_with_loss_op.cc', ['    GetSoftmaxWithLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxWithLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxWithLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxWithLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxWithLossGradient', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softmax_with_loss_op.h', ['    final', '    final'], ['    RunOnDevice', '    scratch_', '    scratch_', '    SoftmaxWithLossGradientOp(Args,...)', '    SoftmaxWithLossOp(Args,...)', '    sum_multiplier_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\SoftMaxKernel.cpp', [], ['    log_softmax_backward_lastdim_kernel_impl(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    log_softmax_lastdim_kernel_impl(Tensor & result,const Tensor & self)', '    softmax_backward_lastdim_kernel_impl(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    softmax_lastdim_kernel_impl(Tensor & result,const Tensor & self)', '    _vec_host_softmax_backward_lastdim(scalar_t *grad_input_data_base,scalar_t *grad_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    _vec_log_softmax_lastdim(scalar_t *input_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    _vec_softmax_lastdim(scalar_t *input_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    apply(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    apply(Tensor & output,const Tensor & input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\SoftmaxKernel.h', [], ['    log_softmax_backward_lastdim_kernel', '    log_softmax_backward_lastdim_kernel', '    operator=', '    log_softmax_lastdim_kernel', '    log_softmax_lastdim_kernel', '    operator=', '    operator=', '    softmax_backward_lastdim_kernel', '    softmax_backward_lastdim_kernel', '    operator=', '    softmax_lastdim_kernel', '    softmax_lastdim_kernel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softplus_op.cc', ['    GetSoftplusGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftplus', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftplusGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softplus', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftplusGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softplus_op.h', ['    final', '    final'], ['    RunOnDevice', '    SoftplusGradientOp(Args,...)', '    SoftplusOp(Args,...)', '    ~SoftplusGradientOp', '    ~SoftplusOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softsign_op.cc', ['    GetSoftsignGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftsign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softsign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftsignGradient', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\softsign_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Sorting.cpp', [], ['    kthvalue_out_impl_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool keepdim)', '    kthvalue(const Tensor & self,int64_t k,int64_t dim,bool keepdim)', '    kthvalue(const Tensor & self,int64_t k,Dimname dim,bool keepdim)', '    kthvalue_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,Dimname dim,bool keepdim)', '    kthvalue_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool keepdim)', '    median(const Tensor & self,int64_t dim,bool keepdim)', '    median(const Tensor & self,Dimname dim,bool keepdim)', '    median_cpu(const Tensor & self)', '    median_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim,bool keepdim)', '    median_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    quick_select_template(TensorAccessor arr,int64_t k,Comp gt_or_nan,Fn swap_fn)', '    topk(const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    topk_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool largest,bool sorted)', '    result']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Sorting.h', [], ['    operator=', '    topk_stub', '    topk_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\SortingKernel.cpp', [], ['    topk_kernel(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SortingUtils.h', [], ['    _allocate_or_resize_output_with_indices(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim_,int64_t k)', '    _reduction_with_indices_allocate_or_resize_output(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim_,bool keepdim)', '    dim_apply(TensorList tensors,int64_t dim,Fn f)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\source_range.cpp', [], ['    highlight(std::ostream & out)', '    print_with_context(std::ostream & out,size_t context,bool highlight,const std::string & funcname)', '    format_stack_trace(std::ostream & out,const std::vector & entries)', '    findSourceRangeThatGenerated(const SourceRange & range)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\source_range.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\source_range_serialization.cpp', ['    SourceRangeDeserializer', '    SourceRangeSerializer'], ['    row_elems', '    ConcreteSourceRangeUnpickler(at::DataPtr,size_t size)', '    findSourceRangeThatGenerated(const SourceRange & range)', '    unpickle', '    deserialize(const c10::IValue & iv)', '    deserialize_source(const c10::IValue & iv)', '    pickle(const SourceRangeRecords & ranges)', '    SourceRangePickler', '    serialize(const SourceRange & sr)', '    serialize_source(const std::shared_ptr & s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\source_range_serialization.h', ['    SourceRangePickler', '    SourceRangeUnpickler'], ['    pickle(const SourceRangeRecords & ranges)', '    SourceRangePickler', '    findSourceRangeThatGenerated(const SourceRange & range)', '    ~SourceRangeUnpickler']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\source_range_serialization_impl.h', ['    ConcreteSourceRangeUnpickler'], ['    ConcreteSourceRangeUnpickler(at::DataPtr,size_t size)', '    findSourceRangeThatGenerated(const SourceRange & range)', '    unpickle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\space_batch_op.cc', ['    GetSpaceToBatchGradient', '    GetBatchToSpaceGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchToSpace', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpaceToBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchToSpace', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpaceToBatch', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\space_batch_op.h', ['    final', '    final', '    SpaceBatchOpBase'], ['    batchToSpace(const Tensor & input,int pad_t,int pad_l,int block_size,Tensor *output,Context *)', '    spaceToBatch(const Tensor & input,int pad_t,int pad_l,int block_size,Tensor *output,Context *)', '    RunOnDevice', '    RunOnDevice', '    GetSingleArgument', '    SpaceBatchOpBase(Args,...)', '    dim', '    dim32']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\sparse_bitset.h', ['    SparseBitVector', '    SparseBitVectorIterator'], ['    begin', '    count', '    find_first', '    find_last', '    find_next(unsigned Curr)', '    intersects(const SparseBitVectorElement & RHS)', '    intersectWith(const SparseBitVectorElement & RHS,bool & BecameZero)', '    intersectWithComplement(const SparseBitVectorElement & RHS,bool & BecameZero)', '    intersectWithComplement(const SparseBitVectorElement & RHS1,const SparseBitVectorElement & RHS2,bool & BecameZero)', '    reset(unsigned Idx)', '    test(unsigned Idx)', '    test_and_set(unsigned Idx)', '    unionWith(const SparseBitVectorElement & RHS)', '    contains(const SparseBitVector & RHS)', '    count', '    empty', '    end', '    find_first', '    find_last', '    intersects(const SparseBitVector *RHS)', '    intersects(const SparseBitVector & RHS)', '    intersectWithComplement(const SparseBitVector & RHS)', '    intersectWithComplement(const SparseBitVector *RHS)', '    intersectWithComplement(const SparseBitVector & RHS1,const SparseBitVector & RHS2)', '    intersectWithComplement(const SparseBitVector *RHS1,const SparseBitVector *RHS2)', '    operator!=(const SparseBitVector & RHS)', '    operator&(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator&=(const SparseBitVector & RHS)', '    operator&=(SparseBitVector *LHS,const SparseBitVector & RHS)', '    operator&=(SparseBitVector & LHS,const SparseBitVector *RHS)', '    operator-(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator-=(const SparseBitVector & RHS)', '    operator<<(std::ostream & stream,const SparseBitVector & vec)', '    operator==(const SparseBitVector & RHS)', '    operator|(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator|=(const SparseBitVector & RHS)', '    operator|=(SparseBitVector & LHS,const SparseBitVector *RHS)', '    operator|=(SparseBitVector *LHS,const SparseBitVector & RHS)', '    test_and_set(unsigned Idx)', '    empty', '    index', '    operator!=(const SparseBitVectorElement & RHS)', '    operator==(const SparseBitVectorElement & RHS)', '    SparseBitVectorElement', '    SparseBitVectorElement(unsigned Idx)', '    word(unsigned Idx)', '    clear', '    FindLowerBound(unsigned ElementIndex)', '    FindLowerBoundConst(unsigned ElementIndex)', '    FindLowerBoundImpl(unsigned ElementIndex)', '    intersectWithComplement', '    operator&=', '    operator=(const SparseBitVector & RHS)', '    operator=(SparseBitVector)', '    operator|=', '    reset(unsigned Idx)', '    SparseBitVector', '    SparseBitVector(const SparseBitVector & RHS)', '    SparseBitVector(SparseBitVector)', '    AdvanceToFirstNonZero', '    AdvanceToNextNonZero', '    operator!=(const SparseBitVectorIterator & RHS)', '    operator*', '    operator++', '    operator++(int)', '    operator==(const SparseBitVectorIterator & RHS)', '    SparseBitVectorIterator', '    SparseBitVectorIterator(const SparseBitVector *RHS,bool end)', '    test(unsigned Idx)', '    find_first', '    find_last', '    index']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_dropout_with_replacement_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseDropoutWithReplacement', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseDropoutWithReplacement', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_dropout_with_replacement_op.h', ['    final'], ['    GetSingleArgument', '    RunOnDevice', '    SparseDropoutWithReplacementOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\sparse_funhash_op.cc', ['    GetSparseFunHashGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFunHash', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFunHashGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFunHash', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFunHashGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\sparse_funhash_op.h', ['    SparseFunHashGradientOp', '    SparseFunHashOp'], ['    RunOnDevice', '    SparseFunHashGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    SparseFunHashOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\sparse_lengths_sum_cpu.cc', [], ['    sparse_lengths_sum_op_cpu(const at::Tensor & dataInput,const at::Tensor & indicesInput,const at::Tensor & lengthsInput,const at::Tensor & output)', '    sparse_lengths_sum_op_cpu_impl(const at::Tensor & dataInput,const at::Tensor & indicesInput,const at::Tensor & lengthsInput,const at::Tensor & output)', '    sparse_lengths_sum_op_cpu_impl_(const at::Tensor & dataInput_,const at::Tensor & indicesInput_,const at::Tensor & lengthsInput_,const at::Tensor & output_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\sparse_matrix_reshape_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseMatrixReshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseMatrixReshape']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\sparse_matrix_reshape_op.h', ['    SparseMatrixReshapeOp'], ['    RunOnDevice', '    SparseMatrixReshapeOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_normalize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseNormalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseNormalize', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_normalize_op.h', ['    final'], ['    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SparseNormalizeOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_to_dense_mask_op.cc', ['    GetSparseToDenseMaskGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDenseMask', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDenseMaskGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDenseMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDenseMaskGradient', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_to_dense_mask_op.h', ['    SparseToDenseMaskBase', '    SparseToDenseMaskGradientOp', '    SparseToDenseMaskOp'], ['    getFeatureIdx(int64_t id)', '    GetRepeatedArgument', '    SparseToDenseMaskBase(Args,...)', '    DoRunWithType', '    RunOnDevice', '    SparseToDenseMaskGradientOp(Args,...)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SparseToDenseMaskOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_to_dense_op.cc', ['    GetSparseToDenseGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDense', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sparse_to_dense_op.h', ['    final'], ['    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType2', '    GetOutputFirstDim(const TInd *sparse_indices_vec,const int32_t sparse_indices_len)', '    GetSingleArgument', '    max_element_host_', '    RunOnDevice', '    scratch_', '    SparseToDenseOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\sparse\\cuda\\SparseCUDATensor.cpp', [], ['    sparse_mask_cuda(const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cuda(SparseTensor & r,const Tensor & t,const SparseTensor & mask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\sparse\\SparseTensor.cpp', [], ['    expand_values_if_needed(const Tensor & values)', '    _coalesced_sparse_(SparseTensor & self,bool coalesced)', '    _indices_sparse(const SparseTensor & self)', '    _is_same_size_as_sparse(const SparseTensor & self,const SparseTensor & src)', '    _nnz_sparse(const SparseTensor & self)', '    _sparse_coo_tensor_unsafe(const Tensor & indices,const Tensor & values_,ArrayRef size,const TensorOptions & options)', '    _values_sparse(const SparseTensor & self)', '    clone_sparse(const SparseTensor & self,c10::optional optional_memory_format)', '    coalesce_sparse_cpu(const SparseTensor & self)', '    copy_sparse_(SparseTensor & self,const SparseTensor & src,bool non_blocking)', '    dense_dim_sparse(const SparseTensor & self)', '    dense_to_sparse(const Tensor & self)', '    dense_to_sparse(const Tensor & self,int64_t sparse_dim)', '    empty_sparse(IntArrayRef size,const TensorOptions & options,c10::optional optional_memory_format)', '    indices_sparse(const Tensor & self)', '    is_coalesced_sparse(const SparseTensor & self)', '    new_sparse(const TensorOptions & options)', '    new_with_dims_and_tensor_sparse(int64_t sparse_dim,int64_t dense_dim,ArrayRef size,const LongTensor & indices,const Tensor & values,const TensorOptions & options)', '    new_with_dims_sparse(int64_t sparse_dim,int64_t dense_dim,ArrayRef size,const TensorOptions & options)', '    resize_as_sparse_(SparseTensor & self,const SparseTensor & src)', '    sparse_coo_tensor(const Tensor & indices,const Tensor & values_,const TensorOptions & options)', '    sparse_coo_tensor(const Tensor & indices,const Tensor & values_,ArrayRef size,const TensorOptions & options)', '    sparse_coo_tensor(ArrayRef size,const TensorOptions & options)', '    sparse_dim_sparse(const SparseTensor & self)', '    sparse_mask_cpu(const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cpu(SparseTensor & r,const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cpu_kernel(Tensor & r_values,const Tensor & t,const int64_t r_nnz,const int64_t sparse_dim,const LongTensor & mask_indices)', '    sparse_resize_(SparseTensor & self,ArrayRef size,int64_t sparse_dim,int64_t dense_dim)', '    sparse_resize_and_clear_(SparseTensor & self,ArrayRef size,int64_t sparse_dim,int64_t dense_dim)', '    sparse_to_dense(const SparseTensor & self)', '    values_sparse(const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\SparseTensorImpl.cpp', [], ['    sparseTensorSetToDeviceType(DispatchKeySet key_set)', '    dim', '    has_storage', '    is_contiguous(at::MemoryFormat memory_format)', '    set_indices_and_values_unsafe(const Tensor & indices,const Tensor & values)', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,at::Tensor indices,at::Tensor values)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\SparseTensorImpl.h', [], ['    copy_tensor_metadata(const SparseTensorImpl *src_sparse_impl,SparseTensorImpl *dest_sparse_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    coalesced', '    dense_dim', '    dim', '    has_storage', '    indices', '    is_contiguous(at::MemoryFormat memory_format)', '    nnz', '    raw_resize_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    resize_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    resize_and_clear_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    set_coalesced(bool coalesced)', '    set_indices_and_values_unsafe(const Tensor & indices,const Tensor & values)', '    set_nnz_and_narrow(int64_t new_nnz)', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    sparse_dim', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,at::Tensor indices,at::Tensor values)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    values', '    narrow', '    options', '    resize_', '    size', '    copy_tensor_metadata']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\sparse\\SparseTensorMath.cpp', [], ['    coalesce_(SparseTensor & tensor)', '    wrapped_scalar_tensor(Scalar s)', '    _sparse_addmm(const Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    _sparse_mm(const SparseTensor & sparse,const Tensor & dense)', '    _sparse_mm_out(SparseTensor & result,const SparseTensor & sparse,const Tensor & dense)', '    _sparse_sum(const SparseTensor & input)', '    _sparse_sum(const SparseTensor & input,ScalarType dtype)', '    _sparse_sum(const SparseTensor & input,IntArrayRef dims_to_sum,ScalarType dtype)', '    _sparse_sum(const SparseTensor & input,IntArrayRef dims_to_sum)', '    _sparse_sum_backward_cpu(const Tensor & grad_,const SparseTensor & input_,IntArrayRef dims_to_sum)', '    _sspaddmm_out_cpu(SparseTensor & r,const SparseTensor & t,const SparseTensor & sparse_,const Tensor & dense,Scalar beta,Scalar alpha)', '    _sspaddmm_out_only_sparse(Tensor & result,const Tensor & self,const Tensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    any_sparse(const Tensor & self)', '    addmm_sparse_dense_cpu(const Tensor & self,const SparseTensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    _to_csr(const int64_t *indices,int64_t dim,int64_t nnz)', '    add_dense_sparse_worker_cpu(Tensor & r,Scalar value,const SparseTensor & sparse,const Tensor & indices,const Tensor & values)', '    add_out_dense_sparse_cpu(Tensor & r,const Tensor & dense,const SparseTensor & sparse_,Scalar value)', '    add_out_sparse_contiguous(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value,ScalarType commonDtype)', '    add_out_sparse_cpu(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value)', '    add_out_sparse_non_contiguous(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value,ScalarType commonDtype)', '    add_sparse(const Tensor & self,const Tensor & other,Scalar alpha)', '    add_sparse_(Tensor & self,const Tensor & other,Scalar alpha)', '    addmm_out_sparse_dense_cpu(Tensor & result,const Tensor & self,const SparseTensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    div_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    div_out_sparse_zerodim(SparseTensor & r,const SparseTensor & t,const Tensor & value)', '    div_sparse(const Tensor & self,const Tensor & value)', '    div_sparse_(Tensor & self,const Tensor & value)', '    floor_divide_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    floor_divide_out_sparse_zerodim(SparseTensor & result,const SparseTensor & dividend,const Tensor & divisor)', '    floor_divide_sparse(const Tensor & self,const Tensor & value)', '    floor_divide_sparse_(Tensor & self,const Tensor & value)', '    log1p_out_sparse(SparseTensor & r,const SparseTensor & t)', '    log1p_sparse_(SparseTensor & t)', '    mul_out_sparse_cpu(SparseTensor & r,const Tensor & t_,const Tensor & src_)', '    mul_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    mul_out_sparse_zerodim(SparseTensor & r,const SparseTensor & t,const Tensor & value)', '    mul_sparse(const Tensor & self,const Tensor & other)', '    mul_sparse_(Tensor & self,const Tensor & other)', '    norm_sparse(const SparseTensor & self,Scalar value)', '    pow_out_sparse_scalar(SparseTensor & r,const SparseTensor & t_,Scalar value)', '    pow_sparse_scalar(const SparseTensor & t,Scalar value)', '    s_addmm_out_sparse_dense_cpu(Tensor & r,const Tensor & t,const SparseTensor & sparse_,const Tensor & dense,Scalar beta,Scalar alpha)', '    s_addmm_out_sparse_dense_worker(int64_t nnz,int64_t dim_i,int64_t dim_j,int64_t dim_k,Tensor & r,Scalar beta,const Tensor & t,Scalar alpha,const Tensor & indices,const Tensor & values,const Tensor & dense)', '    sub_out_sparse(Tensor & r,const Tensor & self,const Tensor & other,Scalar alpha)', '    sub_sparse(const Tensor & self,const Tensor & other,Scalar alpha)', '    sub_sparse_(Tensor & self,const Tensor & other,Scalar alpha)', '    true_divide_out_sparse_scalar(SparseTensor & result,const SparseTensor & dividend,Scalar divisor)', '    true_divide_out_sparse_zerodim(SparseTensor & result,const SparseTensor & dividend,const Tensor & divisor)', '    true_divide_sparse(const Tensor & self,const Tensor & value)', '    true_divide_sparse_(Tensor & self,const Tensor & divisor)', '    zero_sparse_(SparseTensor & self)', '    s_addmm_sparse_dense_cpu(const Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    hspmm_out_sparse_cpu(SparseTensor & r,const SparseTensor & sparse_,const Tensor & dense)', '    hspmm_sparse_cpu(const SparseTensor & sparse,const Tensor & dense)', '    index_preamble', '    isnan_sparse(const Tensor & self)', '    s_addmm_sparse_dense_cpu_(Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    smm(const Tensor & self,const Tensor & mat2)', '    sspaddmm(const Tensor & self,const Tensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\sparse\\SparseTensorMath.h', [], ['    mul_out_sparse_scalar(sparse::SparseTensor & r,const sparse::SparseTensor & t,Scalar value)', '    mul_out_sparse_zerodim(sparse::SparseTensor & r,const sparse::SparseTensor & t,const Tensor & value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\SparseTensorUtils.h', [], ['    alias_into_sparse(const SparseTensor & self,const LongTensor & indices,const Tensor & values)', '    copy_into_sparse(const SparseTensor & self,const LongTensor & indices,const Tensor & values,bool non_blocking)', '    flatten_indices(const Tensor & indices,IntArrayRef full_size,bool force_clone)', '    flatten_indices_by_dims(const LongTensor & indices,const IntArrayRef & sizes,const IntArrayRef & dims_to_flatten)', '    get_sparse_impl(const SparseTensor & self)', '    is_same_density(const SparseTensor & self,const SparseTensor & src)', '    is_same_tensor(const Tensor & lhs,const Tensor & rhs)', '    new_values_with_size_of(const Tensor & values,int64_t nnz)', '    variable_excluded_from_dispatch', '    device', '    mul', '    sizes', '    squeeze', '    to', '    unsafeGetTensorImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\SparseTypeDerived.cpp', [], ['    registerer', '    $extra_cuda_headers', '    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\spatial_batch_norm_dnnlowp_op.cc', [], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SpatialBN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SpatialBNRelu', '    RunOnDevice', '    SpatialBNDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\spatial_batch_norm_dnnlowp_op.h', ['    final'], ['    SpatialBNNHWCAVX2(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const T *X,const float *alpha,const float *beta,T *Y,bool relu_fused)', '    ComputeFusedParam_(const int C,const float *scale,const float *bias,const float *mean,const float *var,float *alpha,float *beta)', '    RunOnDevice', '    SpatialBNDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ~SpatialBNDNNLowPOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\spatial_batch_norm_dnnlowp_op_avx2.cc', [], ['    SpatialBNNHWCAVX2(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const uint8_t *X,const float *alpha,const float *beta,uint8_t *Y,bool relu_fused)', '    SpatialBNNHWCAVX2_uint8(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const uint8_t *X,const float *alpha,const float *beta,uint8_t *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\spatial_batch_norm_fp16_fake_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNFakeFp16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNFakeLoweredFp16NNPI']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\spatial_batch_norm_fp16_fake_op.h', ['    SpatialBNFakeFp16Op', '    SpatialBNFakeLoweredFp16Op'], ['    GetDeviceType', '    AffineChannel_NCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    ComputeFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *alpha,T *beta)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNFakeFp16Op(Args,...)', '    ~SpatialBNFakeFp16Op', '    AffineChannel_NCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,const float *mean,float *Y)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SpatialBNFakeLoweredFp16Op(Args,...)', '    ~SpatialBNFakeLoweredFp16Op']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\spatial_batch_norm_gradient_op.cc', ['    GetSpatialBNGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBNGradient', '    GetGradientDefs', '    ComputeMultiBatchScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *scale,const T *mean,const T *rstd,const T *dscale_sum,const T *dbias_sum,T *dscale,T *dbias,T *alpha,T *beta,T *gamma)', '    ComputeScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *dY,const T *X,const T *scale,const T *mean,const T *rstd,T *dscale,T *dbias,T *alpha,T *beta,T *gamma,T *)', '    ComputeXGradient(const int N,const int C,const int HxW,const T *dY,const T *X,const T *alpha,const T *beta,const T *gamma,T *dX)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\spatial_batch_norm_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBN', '    CostInferenceForSpatialBN(const OperatorDef & def,const vector & in)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\spatial_batch_norm_op.cc', ['    final', '    final'], ['    IDEEPSpatialBNGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSpatialBNOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPSpatialBNGradientOp', '    ~IDEEPSpatialBNOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\spatial_batch_norm_op.h', ['    SpatialBNGradientOp', '    SpatialBNOp'], ['    ComputeMultiBatchScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *scale,const T *mean,const T *rstd,const T *dscale_sum,const T *dbias_sum,T *dscale,T *dbias,T *alpha,T *beta,T *gamma)', '    ComputeScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *dY,const T *X,const T *scale,const T *mean,const T *rstd,T *dscale,T *dbias,T *alpha,T *beta,T *gamma,T *)', '    ComputeXGradient(const int N,const int C,const int HxW,const T *dY,const T *X,const T *alpha,const T *beta,const T *gamma,T *dX)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNGradientOp(Args,...)', '    ~SpatialBNGradientOp', '    ComputeBatchMoments(const int N,const int C,const int HxW,const T *batch_mean_sum,const T *batch_var_sum,T *mean,T *var)', '    ComputeFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *alpha,T *beta)', '    ComputeRunningMomentsAndFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *running_mean,T *running_var,T *rstd,T *alpha,T *beta)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNOp(Args,...)', '    ~SpatialBNOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\spatial_batch_norm_relu_op.cc', ['    SpatialBNReluOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBNRelu', '    RunOnDevice', '    SpatialBNReluOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\spatial_narrow_as_op.cc', ['    SpatialNarrowAsGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialNarrowAs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialNarrowAsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialNarrowAs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialNarrowAsGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\spatial_narrow_as_op.h', ['    final', '    final'], ['    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SpatialNarrowAsGradientOp(const OperatorDef & def,Workspace *ws)', '    SpatialNarrowAsOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\spatial_softmax_with_loss_op.cc', ['    GetSoftmaxWithLossGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialSoftmaxWithLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialSoftmaxWithLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialSoftmaxWithLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialSoftmaxWithLossGradient', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\spatial_softmax_with_loss_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    scratch_', '    scratch_', '    SpatialSoftmaxWithLossGradientOp(Args,...)', '    SpatialSoftmaxWithLossOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\specialize_autogradzero.cpp', ['    State'], ['    specializeAutogradZero(Graph & g)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\specialize_autogradzero.h', [], ['    specializeAutogradZero(Graph & g)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkl\\SpectralOps.cpp', [], ['    _fft_fill_with_conjugate_symmetry_(Tensor & input,int64_t signal_ndim,int64_t size_last_dim,int64_t last_dim_start_slice)', '    _fft_fill_with_conjugate_symmetry_slice(Tensor & output,int64_t signal_ndim,int64_t size_last_dim,int64_t start_last_dim_idx,int64_t i,int64_t num)', '    _fft_mkl(const Tensor & self,int64_t signal_ndim,bool complex_input,bool complex_output,bool inverse,IntArrayRef checked_signal_sizes,bool normalized,bool onesided,IntArrayRef output_sizes)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SpectralOps.cpp', [], ['    _fft(const Tensor & self,const int64_t signal_ndim,const bool complex_input,const bool complex_output,const bool inverse,IntArrayRef signal_sizes,const bool normalized,const bool onesided)', '    _cufft_clear_plan_cache(int64_t device_index)', '    _cufft_get_plan_cache_max_size(int64_t device_index)', '    _cufft_get_plan_cache_size(int64_t device_index)', '    _cufft_set_plan_cache_max_size(int64_t device_index,int64_t max_size)', '    fft(const Tensor & self,const int64_t signal_ndim,const bool normalized)', '    ifft(const Tensor & self,const int64_t signal_ndim,const bool normalized)', '    irfft(const Tensor & self,const int64_t signal_ndim,const bool normalized,const bool onesided,IntArrayRef signal_sizes)', '    rfft(const Tensor & self,const int64_t signal_ndim,const bool normalized,const bool onesided)', '    stft(const Tensor & self,const int64_t n_fft,const optional hop_lengthOpt,const optional win_lengthOpt,const Tensor & window,const bool normalized,const bool onesided)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SpectralOpsUtils.h', [], ['    infer_ft_complex_to_real_onesided_size(int64_t complex_size,int64_t expected_size)', '    infer_ft_real_to_complex_onesided_size(int64_t real_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\speed_benchmark.cc', ['    C10FlagParser_algo', '    C10FlagParser_engine', '    C10FlagParser_force_algo', '    C10FlagParser_force_engine', '    C10FlagParser_init_net', '    C10FlagParser_input', '    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_net', '    C10FlagParser_opt', '    C10FlagParser_output', '    C10FlagParser_output_folder', '    C10FlagParser_run_individual', '    C10FlagParser_warmup'], ['    main(int argc,char **argv)', '    C10FlagParser_algo(const std::string & content)', '    C10FlagParser_engine(const std::string & content)', '    C10FlagParser_force_algo(const std::string & content)', '    C10FlagParser_force_engine(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_net(const std::string & content)', '    C10FlagParser_opt(const std::string & content)', '    C10FlagParser_output(const std::string & content)', '    C10FlagParser_output_folder(const std::string & content)', '    C10FlagParser_run_individual(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\speed_benchmark_torch.cc', ['    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_model', '    C10FlagParser_print_output', '    C10FlagParser_pytext_len', '    C10FlagParser_report_pep', '    C10FlagParser_warmup'], ['    main(int argc,char **argv)', '    split(char separator,const std::string & string,bool ignore_empty)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_model(const std::string & content)', '    C10FlagParser_print_output(const std::string & content)', '    C10FlagParser_pytext_len(const std::string & content)', '    C10FlagParser_report_pep(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\split_db.cc', ['    C10FlagParser_batch_size', '    C10FlagParser_db_type', '    C10FlagParser_input_db', '    C10FlagParser_splits'], ['    Split(int argc,char **argv)', '    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_db_type(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_splits(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqr_op.cc', ['    GetSqrGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSqr', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sqr', '    GetGradientDefs', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqr_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqr_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDASqr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqrt_op.cc', ['    GetSqrtGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSqrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sqrt', '    GetGradientDefs', '    vector', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqrt_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\sqrt_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDASqrt']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\square_root_divide_op.cc', ['    GetSquareRootDivideGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSquareRootDivide', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquareRootDivide', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\square_root_divide_op.h', ['    final'], ['    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    SquareRootDivideOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\onnx\\ssa_test.cc', [], ['    TEST(SsaTest,ConvReluInplace)', '    TEST(SsaTest,FC_FC_FC_InPlace_Output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8rmax\\sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8vadd\\sse2.c', [], ['    pytorch_q8vadd_ukernel__sse2(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8clamp\\sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8clamp\\sse2.c', [], ['    pytorch_u8clamp_ukernel__sse2(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8vadd\\sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8rmax\\sse2.c', [], ['    pytorch_u8rmax_ukernel__sse2(size_t n,const uint8_t *x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\stack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms\\stack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\stateful.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\dataloader\\stateful.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\dataloader\\stateless.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\static.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\detail\\static.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\static_tracepoint.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\static_tracepoint_elfx86.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\stats.cc', [], ['    toMap(const ExportedStatList & stats)', '    get', '    add(const std::string & name)', '    publish(ExportedStatList & exported,bool reset)', '    update(const ExportedStatList & data)', '    ~StatRegistry']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\stats.h', ['    AvgExportedStat', '    DetailedExportedStat', '    ExportedStat', '    StaticStat', '    StatRegistry', '    StatValue', '    StdDevExportedStat'], ['    ScopeGuard(T f)', '    toMap(const ExportedStatList & stats)', '    get', '    AvgExportedStat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    _ScopeGuard(T)', '    operator bool', '    ~_ScopeGuard', '    DetailedExportedStat(const std::string & gn,const std::string & n)', '    increment(T value,size_t detailIndex,Unused,...)', '    setDetails(const std::vector & detailNames)', '    ExportedStat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    increment(Unused,...)', '    Stat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    StaticStat(const std::string & groupName,const std::string & name)', '    add(const std::string & name)', '    publish(ExportedStatList & exported,bool reset)', '    publish(bool reset)', '    update(const ExportedStatList & data)', '    ~StatRegistry', '    exchange', '    get', '    increment(int64_t inc)', '    load', '    reset(int64_t value)', '    v_', '    compare_exchange_strong', '    const_min_', '    first_', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    load', '    StdDevExportedStat(const std::string & gn,const std::string & n)', '    now']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stats_ops.cc', ['    StatRegistryCreateOp', '    StatRegistryExportOp', '    StatRegistryUpdateOp', '    TimerInstance'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryExport', '    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryUpdate', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerBegin', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerEnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerGetAndEnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryExport', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerBegin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerEnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerGetAndEnd', '    noexcept', '    RunOnDevice', '    StatRegistryCreateOp(Args,...)', '    RunOnDevice', '    StatRegistryExportOp(Args,...)', '    RunOnDevice', '    StatRegistryUpdateOp(Args,...)', '    RunOnDevice', '    TimerBeginOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    TimerEndOp(Args,...)', '    RunOnDevice', '    TimerGetAndEndOp(Args,...)', '    RunOnDevice', '    TimerGetOp(Args,...)', '    begin', '    end', '    get_ns', '    TimerInstance(const std::string & name)', '    time_ns', '    TimerStat(std::string name)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stats_put_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePut', '    CAFFE_ANONYMOUS_VARIABLE_CPUIncrementPut', '    CAFFE_ANONYMOUS_VARIABLE_CPUStdDevPut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IncrementPut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StdDevPut', '    AveragePutStat(std::string name)', '    stat_value', '    IncrementPutStat(std::string name)', '    stat_value', '    stat_value', '    StdDevPutStat(std::string name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stats_put_ops.h', [], ['    DoRunWithType', '    isNan(V input)', '    RunOnDevice', '    TemplatePutOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\stats_test.cc', [], ['    filterMap(const ExportedStatMap & map,const ExportedStatMap & keys)', '    TEST(StatsTest,StatsTestClass)', '    TEST(StatsTest,StatsTestDuration)', '    TEST(StatsTest,StatsTestSimple)', '    TEST(StatsTest,StatsTestStatic)', '    MyCaffeClass(const std::string & name)', '    MyStats(std::string name)', '    num_failures', '    num_runs', '    num_successes', '    usdt_only', '    run(int numRuns)', '    tryRun(int)', '    count', '    cpuUsage', '    memUsage', '    s1', '    s2', '    s3', '    TestStats(std::string name)', '    TestStats(std::string name)', '    TestStats(std::string name)', '    time_ns']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\std_output_formatter.h', ['    StdOutputFormatter'], ['    get_mean(const std::vector & values)', '    get_stdev(const std::vector & values)', '    format(const std::vector & durations_ms,uint64_t threads,uint64_t iterations)', '    inner_product']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\stmt.h', ['    Allocate', '    Block', '    Cond', '    For', '    Free', '    LetStmt', '    LoopOptions', '    Stmt', '    StmtNode', '    Store'], ['    make(const VarHandle & buffer_var,Dtype dtype,const std::vector & dims)', '    make(const std::vector & stmts)', '    make(const ExprHandle & condition,Stmt *true_stmt,Stmt *false_stmt)', '    make(const VarHandle & var,const ExprHandle & start,const ExprHandle & stop,Stmt *body)', '    make(const VarHandle & var,const ExprHandle & start,const ExprHandle & stop,Stmt *body,const LoopOptions & loop_options)', '    make(const VarHandle & buffer_var)', '    make(const VarHandle & var,const ExprHandle & value,Stmt *body)', '    clone(Stmt *s)', '    set_parent(Stmt *s,Stmt *new_parent)', '    make(const Buffer & buffer,const ExprHandle & index,const ExprHandle & value,const ExprHandle & mask)', '    make(const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & value,const ExprHandle & mask)', '    make(const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & value)', '    empty', '    node', '    push_back', '    size', '    Allocate(const Var *buffer_var,Dtype dtype,const std::vector & dims)', '    buffer_var', '    dims', '    dtype', '    append_stmt(Stmt *s)', '    Block(const std::vector & stmts)', '    nstmts', '    prepend_stmt(Stmt *s)', '    replace_stmt(Stmt *old_stmt,Stmt *new_stmt)', '    stmts', '    Cond(const Expr *condition,Stmt *true_stmt,Stmt *false_stmt)', '    condition', '    false_stmt', '    true_stmt', '    body', '    For(const Var *var,const Expr *start,const Expr *stop,Stmt *body)', '    For(const Var *var,const Expr *start,const Expr *stop,Stmt *body,const LoopOptions & loop_options)', '    loop_options', '    set_gpu_block_index(int block_index)', '    set_gpu_thread_index(int thread_index)', '    start', '    stop', '    var', '    buffer_var', '    Free(const Var *buffer_var)', '    body', '    LetStmt(const Var *var,const Expr *value,Stmt *body)', '    value', '    var', '    gpu_block_index', '    gpu_block_index_str', '    gpu_thread_index', '    gpu_thread_index_str', '    is_gpu_block_index', '    is_gpu_thread_index', '    set_gpu_block_index(int index)', '    set_gpu_thread_index(int index)', '    ToString', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    get_parent', '    Stmt', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    StmtNode', '    base_handle', '    index', '    mask', '    Store(const Buffer & buffer,const Expr *index,const Expr *value,const Expr *mask)', '    Store(const Var *base_handle,const Expr *index,const Expr *value,const Expr *mask)', '    value', '    dtype']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stop_gradient.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUStopGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StopGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stop_gradient.h', ['    StopGradientOp'], ['    RunOnDevice', '    StopGradientOp(Args,...)', '    ~StopGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\experimental\\c10\\cpu\\stop_gradient_cpu.cc', [], ['    stop_gradient_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stop_gradient_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAStopGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Storage.cpp', [], ['    free']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\Storage.cpp', [], ['    THP(THPStorage *self)', '    THP(THPStorage *self)', '    THP(THPStorage *self,PyObject *index,PyObject *value)', '    deprecated_AT_ASSERT', '    incref(old_storage)', '    str(,,,,,::c10::str __VA_ARGS__)', '    PyDict_DelItemString(kwargs,)', '    PyErr_Format(PyExc_IndexError,,int64_t,int64_t)', '    PyErr_Format(PyExc_TypeError,,Py_TYPE)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    TH(ptr)', '    TH_CONCAT_4(THP,Real,Storage_,New)', '    TH_CONCAT_4(TH,Real,Storage_,copy_functions)', '    THP(PyObject *module)', '    THP', '    THP(PyObject *module)', '    THPUtils_invalidArguments(args,kwargs,TH_CONCAT_STRING_3,,,,,,,)', '    THPUtils_setError(__VA_ARGS__)', '    THPUtils_setError', '    THPUtils_setError(,Py_TYPE,Py_TYPE,THPUtils_typeTraits::python_type_str)', '    THPUtils_setError(,int64_t)', '    data']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Storage.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Storage.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\storage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Storage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Storage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Storage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Storage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\Storage.h', [], ['    TH_CONCAT_3(THP,Real,StorageClass)', '    TH_CONCAT_3(THP,Real,StorageType)', '    TH_CONCAT_4(THP,Real,Storage_,New)', '    THP(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\StorageDefs.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\StorageImpl.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\StorageImpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\StorageMethods.cpp', [], ['    _lseeki64(fd,THPUtils_unpackLong,SEEK_SET)', '    _lseeki64(fd,fd_original_pos,SEEK_SET)', '    Py_DECREF(seek_return)', '    Py_INCREF(self)', '    PyBuffer_Release(& buffer)', '    PyErr_Format(PyExc_ValueError,,byte_order_str)', '    PyErr_Format(PyExc_ValueError,,int64_t,int64_t)', '    PyErr_Format(PyExc_ValueError,,int64_t,int64_t,int64_t)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    TH(ptr)', '    TH(self,newsize)', '    TH(self,TH_CONCAT_4 THP)', '    TH(self)', '    THP(self,file,save_size)', '    THP(self,fd,save_size)', '    THPUtils_setError(__VA_ARGS__)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\StorageSharing.cpp', [], ['    THP', '    deprecated_AT_ASSERT', '    decref(weak_storage)', '    str(,,,,,::c10::str __VA_ARGS__)', '    Py_INCREF(self)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    PyTuple_SET_ITEM(tuple,,manager_handle)', '    PyTuple_SET_ITEM(tuple,,storage_handle)', '    PyTuple_SET_ITEM(tuple,,size)', '    TH_CONCAT_4(THP,Real,Storage_,newFilenameStorage)', '    TH_CONCAT_4(TH,Real,Storage_,newWithDataAndAllocator)', '    TH_CONCAT_4(THP,Real,Storage_,newFdStorage)', '    THPUtils_invalidArguments(args,nullptr,,,)', '    THPUtils_setError(__VA_ARGS__)', '    THPUtils_setError', '    move(sptr)', '    makeDataPtr(,handle,flags,size *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\Store.cpp', [], ['    setTimeout(const std::chrono::milliseconds & timeout)', '    ~Store', '  Static Member Variables', '    kDefaultTimeout', '    kNoTimeout']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\Store.hpp', ['    Store'], ['    add(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    setTimeout(const std::chrono::milliseconds & timeout)', '    Store', '    Store(const std::chrono::milliseconds & timeout)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~Store', '    zero']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\store_handler.cc', [], ['    noexcept', '    ~StoreHandler', '  Static Member Variables', '    kDefaultTimeout', '    kNoTimeout']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\store_handler.cc', [], ['    get(const std::string & key)', '    set(const std::string & key,const std::vector & data)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\gloo\\store_handler.h', ['    StoreHandlerWrapper'], ['    get(const std::string & key)', '    StoreHandlerWrapper(StoreHandler & handler)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~StoreHandlerWrapper']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\store_handler.h', ['    StoreHandler'], ['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~StoreHandler', '    StoreHandlerNotAvailableException(const std::string & msg)', '    StoreHandlerTimeoutException(const std::string & msg)', '    seconds', '    zero']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\store_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUStoreAdd', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreSet', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreWait', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreAdd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreSet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreWait', '    RunOnDevice', '    StoreAddOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreGetOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreSetOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreWaitOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\distributed\\store_ops.h', ['    final', '    final', '    final', '    final'], ['    RunOnDevice', '    StoreAddOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreGetOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreSetOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreWaitOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\StoreTestCommon.hpp', [], ['    check(Store & store,const std::string & key,const std::string & expected)', '    set(Store & store,const std::string & key,const std::string & value)', '    set']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Stream.cpp', [], ['    operator<<(std::ostream & stream,const Stream & s)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Stream.cpp', [], ['    THCPStream_dealloc(THCPStream *self)', '    THCPStream_eq(THCPStream *self,THCPStream *other)', '    THCPStream_get_cuda_stream(THCPStream *self,void *unused)', '    THCPStream_get_device(THCPStream *self,void *unused)', '    THCPStream_get_priority(THCPStream *self,void *unused)', '    THCPStream_priority_range', '    THCPStream_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPStream_query(THCPStream *self,PyObject *noargs)', '    THCPStream_synchronize(THCPStream *self,PyObject *noargs)', '    THCPStream_init(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\data\\samplers\\stream.cpp', [], ['    BatchSize(size_t size)', '    operator size_t', '    size', '    load(serialize::InputArchive & archive)', '    next(size_t batch_size)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    StreamSampler(size_t epoch_size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Stream.h', [], ['    THCPStream_Check(PyObject *obj)', '    THCPStream_init(PyObject *module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\samplers\\stream.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\Stream.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\StreamGuard.h', [], ['    current_stream', '    operator=', '    operator=', '    OptionalStreamGuard', '    OptionalStreamGuard(Stream stream)', '    OptionalStreamGuard(optional stream_opt)', '    OptionalStreamGuard', '    OptionalStreamGuard', '    original_stream', '    reset', '    reset_stream(Stream stream)', '    current_device', '    current_stream', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    StreamGuard', '    StreamGuard(Stream stream)', '    StreamGuard', '    StreamGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\core\\StreamGuard_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\string_ops.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\string_ops.h', [], ['    ForEach(OperatorBase & op)', '    operator()(int n,const In *in,Out *out,Context *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\string_ops_test.cc', ['    StringJoinOpTest'], ['    TEST_F(StringJoinOpTest,testString1DJoin)', '    TEST_F(StringJoinOpTest,testString2DJoin)', '    TEST_F(StringJoinOpTest,testFloat1DJoin)', '    TEST_F(StringJoinOpTest,testFloat2DJoin)', '    TEST_F(StringJoinOpTest,testLong2DJoin)', '    checkAndGetOutput(int outputSize)', '    runOp(const Tensor & input)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\string_to_type.cpp', [], ['    string_to_type_lut']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\string_utils.cc', [], ['    editDistance(const std::string & s1,const std::string & s2,size_t max_distance)', '    editDistanceHelper(const char *s1,size_t s1_len,const char *s2,size_t s2_len,std::vector & current,std::vector & previous,std::vector & previous1,size_t max_distance)', '    split(char separator,const std::string & string,bool ignore_empty)', '    trim(const std::string & str)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\string_utils.h', [], ['    editDistance(const std::string & s1,const std::string & s2,size_t max_distance)', '    editDistanceHelper(const char *s1,size_t s1_len,const char *s2,size_t s2_len,std::vector & current,std::vector & previous,std::vector & previous1,size_t max_distance)', '    EndsWith(const std::string & full,const std::string & ending)', '    split(char separator,const std::string & string,bool ignore_empty)', '    StartsWith(const std::string & str,const std::string & prefix)', '    trim(const std::string & str)', '    mismatch']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\string_utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\string_view.h', ['    final'], ['    begin(basic_string_view sv)', '    end(basic_string_view sv)', '    operator!=(basic_string_view lhs,basic_string_view rhs)', '    operator<(basic_string_view lhs,basic_string_view rhs)', '    operator<<(std::basic_ostream & stream,basic_string_view sv)', '    operator<=(basic_string_view lhs,basic_string_view rhs)', '    operator==(basic_string_view lhs,basic_string_view rhs)', '    operator>(basic_string_view lhs,basic_string_view rhs)', '    operator>=(basic_string_view lhs,basic_string_view rhs)', '    operator()(::c10::basic_string_view x)', '    swap(basic_string_view & lhs,basic_string_view & rhs)', '    strlen_(const_pointer str)', '    swap', '    at(size_type pos)', '    at_(size_type pos)', '    back', '    basic_string_view', '    basic_string_view(const_pointer str,size_type count)', '    basic_string_view(const_pointer str)', '    basic_string_view(const ::std::basic_string & str)', '    basic_string_view', '    begin', '    cbegin', '    cend', '    compare(basic_string_view rhs)', '    compare(size_type pos1,size_type count1,basic_string_view v)', '    compare(size_type pos1,size_type count1,basic_string_view v,size_type pos2,size_type count2)', '    compare(const_pointer s)', '    compare(size_type pos1,size_type count1,const_pointer s)', '    compare(size_type pos1,size_type count1,const_pointer s,size_type count2)', '    copy(pointer dest,size_type count,size_type pos)', '    crbegin', '    crend', '    data', '    empty', '    end', '    ends_with(basic_string_view suffix)', '    ends_with(CharT suffix)', '    ends_with(const_pointer suffix)', '    equals_(basic_string_view rhs)', '    operator()(CharT actual)', '    operator()(CharT ch)', '    operator()(CharT ch)', '    operator()(CharT actual)', '    find(basic_string_view v,size_type pos)', '    find(CharT ch,size_type pos)', '    find(const_pointer s,size_type pos,size_type count)', '    find(const_pointer s,size_type pos)', '    find_first_if_(size_type pos,Condition)', '    find_first_not_of(basic_string_view v,size_type pos)', '    find_first_not_of(CharT ch,size_type pos)', '    find_first_not_of(const_pointer s,size_type pos,size_type count)', '    find_first_not_of(const_pointer s,size_type pos)', '    find_first_of(basic_string_view v,size_type pos)', '    find_first_of(CharT ch,size_type pos)', '    find_first_of(const_pointer s,size_type pos,size_type count)', '    find_first_of(const_pointer s,size_type pos)', '    find_last_if_(size_type pos,Condition)', '    find_last_not_of(basic_string_view v,size_type pos)', '    find_last_not_of(CharT ch,size_type pos)', '    find_last_not_of(const_pointer s,size_type pos,size_type count)', '    find_last_not_of(const_pointer s,size_type pos)', '    find_last_of(basic_string_view v,size_type pos)', '    find_last_of(CharT ch,size_type pos)', '    find_last_of(const_pointer s,size_type pos,size_type count)', '    find_last_of(const_pointer s,size_type pos)', '    front', '    length', '    max_size', '    operator ::std::basic_string', '    operator=(const basic_string_view & rhs)', '    operator[](size_type pos)', '    rbegin', '    remove_prefix(size_type n)', '    remove_suffix(size_type n)', '    rend', '    rfind(basic_string_view v,size_type pos)', '    rfind(CharT ch,size_type pos)', '    rfind(const_pointer s,size_type pos,size_type count)', '    rfind(const_pointer s,size_type pos)', '    size', '    starts_with(basic_string_view prefix)', '    starts_with(CharT prefix)', '    starts_with(const_pointer prefix)', '    substr(size_type pos,size_type count)', '    substr_(size_type pos,size_type count)', '    swap(basic_string_view & sv)', '    min', '    to_string', '    max', '    out_of_range']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\string_view_test.cpp', [], ['    TEST(StringViewTest,testConversionToString)', '    TEST(StringViewTest,whenCopyingFullStringView_thenDestinationHasCorrectData)', '    TEST(StringViewTest,whenCopyingSubstr_thenDestinationHasCorrectData)', '    TEST(StringViewTest,whenCopyingTooMuch_thenJustCopiesLess)', '    TEST(StringViewTest,whenCopyingJustAtRange_thenDoesntCrash)', '    TEST(StringViewTest,whenCopyingOutOfRange_thenThrows)', '    assign(string_view value)', '    TEST(StringViewTest,testCopyAssignment)', '    TEST(StringViewTest,testHash)', '    TEST(StringViewTest,testOutputOperator)', '    testOutputIterator(const std::string & str)', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    TEST(StringViewTest,whenCallingAccessOperatorOutOfRange_thenThrows)', '    remove_prefix(string_view input,size_t len)', '    TEST(StringViewTest,whenRemovingValidPrefix_thenWorks)', '    TEST(StringViewTest,whenRemovingTooLargePrefix_thenThrows)', '    remove_suffix(string_view input,size_t len)', '    TEST(StringViewTest,whenRemovingValidSuffix_thenWorks)', '    TEST(StringViewTest,whenRemovingTooLargeSuffix_thenThrows)', '    TEST(StringViewTest,testStringConstructor)', '    test_conversion_is_implicit(string_view a)', '    TEST(StringViewTest,whenCallingSubstrWithPosOutOfRange_thenThrows)', '    get', '    TEST(StringViewTest,testSwapFunction)', '    get', '    TEST(StringViewTest,testSwapMethod)', '    expectThrows(Functor,const char *expectMessageContains)', '    string_equal(const char *lhs,const char *rhs,size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\StringUtil.cpp', [], ['    StripBasename(const std::string & full_path)', '    operator<<(std::ostream & out,const SourceLocation & loc)', '    ReplaceAll(std::string & s,const char *from,const char *to)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\StringUtil.h', [], ['    isPrint(char s)', '    _str(std::ostream & ss)', '    _str(std::ostream & ss,const T & t)', '    _str(std::ostream & ss,const T & t,const Args &,...)', '    _str_wrapper(const Args &,...)', '    StripBasename(const std::string & full_path)', '    Join(const std::string & delimiter,const Container & v)', '    operator<<(std::ostream & out,const SourceLocation & loc)', '    printQuotedString(std::ostream & stmt,const std::string & str)', '    ReplaceAll(std::string & s,const char *from,const char *to)', '    str(const Args &,...)', '    str(const std::string & str)', '    str(const char *c_str)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\strtod.cpp', [], ['    strtod_c(const char *nptr,char **endptr)', '    strtof_c(const char *nptr,char **endptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\strtod.h', [], ['    strtod_c(const char *nptr,char **endptr)', '    strtof_c(const char *nptr,char **endptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\structseq.cpp', [], ['    returned_structseq_repr(PyStructSequence *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\structseq.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\stub.cpp', [], ['    PyInit__C']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stump_func_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUStumpFunc', '    CAFFE_ANONYMOUS_VARIABLE_CPUStumpFuncIndex', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StumpFunc', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StumpFuncIndex', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stump_func_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    StumpFuncIndexOp(Args,...)', '    StumpFuncOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\stylizer_ops.cc', ['    BRGNCHWCToPackedInt8BGRAStylizerDeprocessOp', '    PackedInt8BGRANHWCToNCHWCStylizerPreprocessOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUBRGNCHWCToPackedInt8BGRAStylizerDeprocess', '    CAFFE_ANONYMOUS_VARIABLE_CPUPackedInt8BGRANHWCToNCHWCStylizerPreprocess', '    clamped_cast(float f)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BRGNCHWCToPackedInt8BGRAStylizerDeprocess', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackedInt8BGRANHWCToNCHWCStylizerPreprocess', '    runBatch(int N,int,int H,int W,const float *input,const float *meanChannel,uint8_t *output)', '    runCPU(int H,int W,const float *input,const float *meanChannel,uint8_t *output)', '    RunOnDevice', '    initNoiseCPU(Tensor *noise,int size)', '    PackedInt8BGRANHWCToNCHWCStylizerPreprocessOp(const OperatorDef & operator_def,Workspace *ws)', '    runBatch(int N,int,int H,int W,int noiseCycle,const uint8_t *input,const float *meanChannel,const float *noise,float *output)', '    runCPU(int H,int W,int noiseCycle,const uint8_t *input,const float *meanChannel,const float *noise,float *output)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8maxpool\\sub16-neon.c', [], ['    pytorch_u8maxpool_ukernel_sub16__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8maxpool\\sub16-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\u8maxpool\\sub16-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\u8maxpool\\sub16-sse2.c', [], ['    pytorch_u8maxpool_ukernel_sub16__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\subgraph_matcher.cpp', ['    SubgraphMatcher'], ['    endsWith(const std::string & str,const std::string & suffix)', '    findPatternMatches(const Graph & pattern,Graph & graph)', '    patternGraphIsValid(const Graph & pattern)', '    matchAttributes(const Node *n1,Node *n2)', '    matchesSubgraphFromAnchorNode(Node *anchor)', '    matchNodes(const Node *n1,Node *n2)', '    matchValues(const Value *v1,Value *v2)', '    nodes_map', '    SubgraphMatcher(const Graph & pattern)', '    values_map']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\subgraph_matcher.h', [], ['    findPatternMatches(const Graph & pattern,Graph & graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\subgraph_rewrite.cpp', [], ['    PatternBasedRewrite(const Module & module)', '    overlapsWithPreviousMatches(const Match *match)', '    RegisterDefaultPatterns', '    RegisterRewritePattern(const std::string & pattern,const std::string & replacement)', '    rewriteSinglePatternOnGraph(std::shared_ptr & graph,const RewritePatternDescr & pattern,const std::function & filter)', '    runOnGraph(std::shared_ptr & graph,const std::function & filter)', '    runOnModule(const Module & module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\subgraph_rewrite.h', ['    SubgraphRewriter'], ['    PatternBasedRewrite(const Module & module)', '    overlapsWithPreviousMatches(const Match *match)', '    RegisterDefaultPatterns', '    RegisterRewritePattern(const std::string & pattern,const std::string & replacement)', '    rewriteSinglePatternOnGraph(std::shared_ptr & graph,const RewritePatternDescr & pattern,const std::function & filter)', '    runOnGraph(std::shared_ptr & graph,const std::function & filter)', '    runOnModule(const Module & module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\subgraph_utils.cpp', [], ['    closedOverValues(Node *toMerge,std::unordered_map & inputsMap)', '    collectNestedUses(std::unordered_set & closed_over_values,std::unordered_set & new_values,std::unordered_map & inputsMap,Node *input_node)', '    createSingletonSubgraph(Node *n,Symbol subgraphKind)', '    getSubgraph(Node *n)', '    hasSubgraph(Node *n)', '    mergeNodeIntoSubgraph(Node *toMerge,Node *subgraphNode)', '    mergeSubgraph(Node *mergeTo,Node *mergeFrom)', '    unmergeSubgraph(Node *subgraphNode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\utils\\subgraph_utils.h', [], ['    createSingletonSubgraph(Node *n,Symbol subgraphKind)', '    getSubgraph(Node *n)', '    mergeNodeIntoSubgraph(Node *toMerge,Node *subgraphNode)', '    unmergeSubgraph(Node *subgraphNode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Transformations\\SubgraphMatcher.h', ['    MatchGraph', '    MatchPredicate', '    SubgraphMatchResult'], ['    matched(bool ownSubgraph)', '    notMatched(const std::string & debugMessage)', '    notMatched', '    debugString(MatchGraph::NodeRef rootCriteriaRef,bool invertGraphTraversal)', '    isNodeMatch(GraphType::NodeRef node,const MatchPredicate & matchPredicate)', '    isSubgraphMatch(GraphType::NodeRef root,const MatchGraph::NodeRef & rootCriteriaRef,bool invertGraphTraversal,bool debug)', '    isSubgraphMatchInternal(std::shared_ptr matchedNodes,std::shared_ptr matchedSubgraph,GraphType::NodeRef root,const MatchGraph::NodeRef & rootCriteriaRef,bool includeInSubgraph,bool invertGraphTraversal,bool debug)', '    replaceSubgraph(GraphType & graph,const MatchGraph::NodeRef & criteria,const ReplaceGraphOperation & replaceFunction,bool invertGraphTraversal)', '    count(int count)', '    excludeFromSubgraph', '    getCount', '    getCriteria', '    getDebugString', '    isNonTerminal', '    MatchPredicate(const Predicate & criteria)', '    MatchPredicate', '    MatchPredicate', '    MatchPredicate', '    nonTerminal', '    operator=', '    setDebugString(const std::string & debugString)', '    shouldIncludeInSubgraph', '    starCount', '    getDebugMessage', '    getMatchedSubgraph', '    getMatchNodeMap', '    isMatch', '    SubgraphMatchResult(bool isMatch,const std::string & debugMessage,bool ownSubgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\SubgraphMatcherTest.cc', [], ['    any', '    getInNode(TestGraph::NodeRef node,int index)', '    isSubgraphMatch(TestGraph::NodeRef nodeRef,const TestMatchGraph::NodeRef & criteria,bool invertGraphTraversal)', '    reset', '    testMatchPredicate(const Criteria & criteria)', '    NonTerminal(const Criteria & root,int count)', '    TestGraphNodePrinter(TestGraph::NodeRef node)', '    Tree(const Criteria & root,const std::vector & children,int count)', '    TEST(SubgraphMatcher,IsNodeMatch)', '    TEST(SubgraphMatcher,IsSubtreeMatch)', '    TEST(SubgraphMatcher,IsSubtreeMatchRepeated)', '    TEST(SubgraphMatcher,DagMatching)', '    TEST(SubgraphMatcher,DagMatchingMultiEdges)', '    TEST(SubgraphMatcher,DagMatchingRandomLargeGraph)', '    TEST(SubgraphMatcher,IsSubtreeMatchRealistic)', '    TEST(SubgraphMatcher,ReplaceGraphRealistic)', '    DataFlowTestGraph', '    DataFlowTestGraphCriteria']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\sugared_value.cpp', [], ['    isRecursive(const TypePtr & classType,const TypePtr & attrType)', '    builtin_cast_methods', '    make_simple_value', '    base_iters', '    tryCreate(Symbol symbol,c10::optional self)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    addChild(const SourceRange & range,Function & m,const SugaredValuePtr iter_value)', '    get_base_iterables', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    len(const SourceRange & loc,Function & m)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    RangeValue(const SourceRange & loc,Function & m,std::vector inputs,c10::optional static_len)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    operator()(T t)', '    kind']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\sugared_value.h', [], ['    toValues(Graph & g,at::ArrayRef nvs)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    shouldEmitUnrolled', '    staticLen', '    ~SugaredValue', '    tryCreate(Symbol symbol,c10::optional self)', '    create(Symbol form)', '    BuiltinFunction(Symbol symbol,c10::optional self)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    BuiltinModule(std::string name,c10::optional version)', '    kind', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    CastValue(TypePtr type,c10::Symbol method)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    ClassValue(ClassTypePtr type)', '    kind', '    asValue(const SourceRange & range,Function & m)', '    ClosureValue(Value *value)', '    kind', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    callees', '    FunctionValue(Function *callee)', '    FunctionValue(const StrongFunctionPtr & p)', '    FunctionValue(const std::vector & callees)', '    kind', '    createTuple', '    insertNode', '    addChild(const SourceRange & range,Function & m,const SugaredValuePtr iter_value)', '    get_base_iterables', '    get_children', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    IterableTree', '    IterableTree(const SourceRange & range,Function & m,at::ArrayRef children)', '    kind', '    len(const SourceRange & loc,Function & m)', '    staticLen', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    MagicMethod(std::string desugared_name,SugaredValuePtr base)', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    MethodValue(Value *self,std::vector method_names)', '    MethodValue(Value *self,std::string method_name)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    NamedTupleConstructor(TupleTypePtr type)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    len(const SourceRange & loc,Function & m)', '    RangeValue(const SourceRange & loc,Function & m,std::vector inputs,c10::optional static_len)', '    staticLen', '    getClassType', '    makeSugared(Value *v)', '    SimpleSelf(ClassTypePtr classType)', '    asValue(const SourceRange & range,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getValue', '    iter(const SourceRange & loc,Function & m)', '    kind', '    len(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    SimpleValue(Value *value)', '    form', '    kind', '    SpecialFormValue(Symbol form)', '    end', '    push_back', '    asValue(const SourceRange & loc,Function & m)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    override', '    staticLen', '    SugaredTupleValue(std::vector)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\summarize_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSummarize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Summarize', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\summarize_op.h', ['    final'], ['    GetSingleArgument', '    RunOnDevice', '    SummarizeOp(const OperatorDef & def,Workspace *ws)', '    ~SummarizeOp', '    RootFolder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\SummaryOps.cpp', [], ['    _bincount_cpu(const Tensor & self,const Tensor & weights,int64_t minlength)', '    _bincount_cpu_template(const Tensor & self,const Tensor & weights,int64_t minlength)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\support.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\common\\support.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\support.h', ['    SimpleContainer'], ['    assert_tensor_equal(at::Tensor a,at::Tensor b,bool allow_inf)', '    assert_tensor_not_equal(at::Tensor x,at::Tensor y)', '    count_substr_occurrences(const std::string & str,const std::string & substr)', '    pointer_equal(at::Tensor first,at::Tensor second)', '    cpu', '    data_ptr', '    device', '    get_device', '    is_cuda', '    is_floating_point', '    numel', '    scalar_type', '    sizes', '    to', '    type', '    type_as', '    equal', '    get_default_dtype', '    isinf', '    isnan', '    manual_seed', '    scalarTypeToTypeMeta', '    set_default_dtype', '    AutoDefaultDtypeMode(c10::ScalarType default_dtype)', '    ~AutoDefaultDtypeMode', '    CerrRedirect(std::streambuf *new_buffer)', '    ~CerrRedirect', '    SeedingFixture', '    add(ModuleHolder module_holder,std::string name)', '    reset', '    typeMetaToScalarType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\swish_op.cc', ['    GetSwishGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSwish', '    CAFFE_ANONYMOUS_VARIABLE_CPUSwishGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Swish', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SwishGradient', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    vector', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\swish_op.h', ['    final'], ['    DoRunWithType', '    RunOnDevice', '    SwishGradientOp(Args,...)', '    ~SwishGradientOp', '    operator()(const int N,const T *X,T *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\symbolic.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\symbolic_script.cpp', [], ['    gradientInfoForSchema(const FunctionSchema & schema)', '    hasGradientInfoForSchema(const FunctionSchema & schema)', '    extractClosure(Value *closure)', '    isHelperFunction(const std::string & method_name)', '    loadModule(const CompilationUnit & module)', '    originalReturnType(const TupleTypePtr & tup)', '    overloadedSchemaString(const FunctionSchema & schema)', '    loadFunctions']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\symbolic_script.h', [], ['    gradientInfoForSchema(const FunctionSchema & schema)', '    hasGradientInfoForSchema(const FunctionSchema & schema)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tan_op.cc', ['    GetTanGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTan', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tan', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanGradient', '    GetGradientDefs', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tan_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\tanh-operator-tester.h', ['    TanHOperatorTester'], ['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\tanh.c', [], ['    pytorch_qnnp_create_tanh_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *tanh_out)', '    pytorch_qnnp_setup_tanh_nc_q8(pytorch_qnnp_operator_t tanh,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\bench\\tanh.cc', [], ['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    tanh_q8(benchmark::State & state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\tanh.cc', [], ['    GetPassRegionEnd_(TensorQuantizationParams in_qparams,TensorQuantizationParams out_qparams,double max_abs_err,int num_in_bits)', '    GetSaturationRegionBegin_(double max_abs_err)', '    sgn(T val)', '    Compute(T x)', '    Tanh(double max_abs_err)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\tanh.cc', [], ['    TEST(TANH_OP,zero_batch)', '    TEST(TANH_OP,unit_batch)', '    TEST(TANH_OP,unit_batch_with_qmin)', '    TEST(TANH_OP,unit_batch_with_qmax)', '    TEST(TANH_OP,unit_batch_with_input_scale)', '    TEST(TANH_OP,unit_batch_with_input_zero_point)', '    TEST(TANH_OP,small_batch)', '    TEST(TANH_OP,small_batch_with_input_stride)', '    TEST(TANH_OP,small_batch_with_output_stride)', '    TEST(TANH_OP,small_batch_with_qmin)', '    TEST(TANH_OP,small_batch_with_qmax)', '    TEST(TANH_OP,small_batch_with_input_scale)', '    TEST(TANH_OP,small_batch_with_input_zero_point)', '    TEST(TANH_OP,strided_batch)', '    TEST(TANH_OP,strided_batch_with_qmin)', '    TEST(TANH_OP,strided_batch_with_qmax)', '    TEST(TANH_OP,strided_batch_with_input_scale)', '    TEST(TANH_OP,strided_batch_with_input_zero_point)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\tanh.h', ['    Tanh'], ['    Compute(T x)', '    GetInputQuantizationParams', '    GetOutputQuantizationParams', '    GetPassRegionEnd', '    GetPassRegionEndDequantized', '    GetSaturationRegionBegin', '    Tanh(double max_abs_err)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\tanh_dnnlowp_op.cc', ['    TanhFunctor'], ['    GetOutputQuantizationParams', '    operator()(const int n,const T *x,T *y)', '    TanhFunctor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tanh_gradient_op.cc', ['    GetTanhGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTanhGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const float *Y,const float *dY,float *dX,CPUContext *)', '    vector']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tanh_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTanh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tanh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanhGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tanh_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tanh_op_cudnn.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\tanh_test.cc', [], ['    TEST(Tanh,TanhUnitTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Graph\\TarjansImpl.h', ['    Tarjans'], ['    NodeWrapper(NodeRef n)', '    NodeWrapper', '    connect(WrappedGraph::NodeRef n)', '    connect(n)', '    Tarjans(Graph *g)', '    unwrapSubgraph(const WrappedSubgraph & wrappedSubgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\TarjansImplTest.cc', [], ['    TEST(Tarjans,Simple)', '    TEST(Tarjans,WithEdgeStorage)', '    TEST(Tarjans,DAG)', '    TEST(Tarjans,Cycle)', '    TEST(Tarjans,Random)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\TCPStore.cpp', ['    CheckResponseType', '    QueryType', '    WaitResponseType'], ['    add(const std::string & key,int64_t value)', '    addHelper_(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    getHelper_(const std::string & key)', '    getPort', '    set(const std::string & key,const std::vector & data)', '    TCPStore(const std::string & masterAddr,PortType masterPort,int numWorkers,bool isServer,const std::chrono::milliseconds & timeout,bool waitWorkers)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    waitForWorkers', '    waitHelper_(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~TCPStore', '    addHandler(int socket)', '    checkHandler(int socket)', '    checkKeys(const std::vector & keys)', '    getHandler(int socket)', '    join', '    query(int socket)', '    run', '    setHandler(int socket)', '    stop', '    TCPStoreDaemon(int storeListenSocket)', '    waitHandler(int socket)', '    wakeupWaitingClients(const std::string & key)', '    ~TCPStoreDaemon']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\TCPStore.hpp', ['    TCPStore', '    TCPStoreDaemon'], ['    add(const std::string & key,int64_t value)', '    addHelper_(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    getHelper_(const std::string & key)', '    getPort', '    TCPStore(const std::string & masterAddr,PortType masterPort,int numWorkers,bool isServer,const std::chrono::milliseconds & timeout,bool waitWorkers)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    waitForWorkers', '    waitHelper_(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~TCPStore', '    addHandler(int socket)', '    checkHandler(int socket)', '    checkKeys(const std::vector & keys)', '    controlPipeFd_', '    getHandler(int socket)', '    join', '    query(int socket)', '    run', '    setHandler(int socket)', '    stop', '    TCPStoreDaemon(int storeListenSocket)', '    waitHandler(int socket)', '    wakeupWaitingClients(const std::string & key)', '    ~TCPStoreDaemon']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\TCPStoreTest.cpp', [], ['    TEST(TCPStoreTest,testHelper)', '    TEST(TCPStoreTest,testHelperPrefix)', '    testHelper(const std::string & prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\cpu\\temp_file.h', [], ['    mkstemps(char *tmpl,int suffix_len)', '    begin', '    end', '    close', '    file', '    name', '    operator=', '    sync', '    TempFile', '    TempFile(const std::string & t,int suffix)', '    write(const std::string & str)', '    ~TempFile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\tempfile.h', [], ['    try_make_tempfile(std::string name_prefix)', '    make_tempfile(std::string name_prefix)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\tempfile_test.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\tensor.cc', [], ['    tensor_info_call_registry_', '    type_call_registry_', '    empty(at::IntArrayRef dims,at::TensorOptions options)', '    GetInt8TensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetInt8TensorType(const void *c)', '    GetTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetTensorInfoFunction(TypeIdentifier id)', '    GetTensorType(const void *c)', '    GetTypeCallFunction(TypeIdentifier id)', '    RegisterTensorInfoFunction(TypeIdentifier id,TensorInfoCall c)', '    RegisterTypeCallFunction(TypeIdentifier id,TypeCall c)', '    ReinitializeAndCopyFrom(Tensor *t,at::TensorOptions options,const Tensor & src,bool async)', '    ReinitializeTensor(Tensor *tensor,at::IntArrayRef dims,at::TensorOptions options)', '    TensorVectorResize(std::vector & tensors,int size,DeviceType type)', '    CopyFrom(const Tensor & src,bool async)', '    enforce_invariants', '    operator at::Tensor', '    operator at::Tensor', '    Tensor(at::Tensor tensor)', '    MetaStr(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    TensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    ~TensorPrinter', '    sizeBytes(const Blob & blob)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\tensor.cpp', [], ['    apply(variable_list)', '    apply(variable_list)', '    CopySlices(const Variable & base_var,at::TensorGeometry view_,std::shared_ptr fn_)', '    release_variables']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\Tensor.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Tensor.cpp', [], ['    _base', '    _register_hook(std::function hook)', '    enforce_invariants', '    grad_fn', '    is_view', '    name', '    print', '    remove_hook(unsigned pos)', '    tensor_data', '    toString', '    variable_data']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\tensor.cpp', [], ['    almost_equal(at::Tensor left,T right,T tolerance)', '    exactly_equal(at::Tensor left,T right)', '    TEST(TensorTest,ToDtype)', '    TEST(TensorTest,ToTensorAndTensorAttributes)', '    TEST(TensorTest,ToOptionsWithRequiresGrad)', '    TEST(TensorTest,ToDoesNotCopyWhenOptionsAreAllTheSame)', '    TEST(TensorTest,AtTensorCtorScalar)', '    TEST(TensorTest,AtTensorCtorSingleDim)', '    TEST(TensorTest,TorchTensorCtorScalarIntegralType)', '    TEST(TensorTest,TorchTensorCtorScalarFloatingType)', '    TEST(TensorTest,TorchTensorCtorScalarBoolType)', '    TEST(TensorTest,TorchTensorCtorSingleDimIntegralType)', '    TEST(TensorTest,TorchTensorCtorSingleDimFloatingType)', '    TEST(TensorTest,TorchTensorCtorSingleDimBoolType)', '    TEST(TensorTest,TorchTensorCtorMultiDimIntegralType)', '    TEST(TensorTest,TorchTensorCtorMultiDimFloatingType)', '    TEST(TensorTest,TorchTensorCtorMultiDimBoolType)', '    TEST(TensorTest,TorchTensorCtorMultiDimWithOptions)', '    TEST(TensorTest,TorchTensorCtorMultiDimErrorChecks)', '    TEST(TensorTest,TorchTensorCtorMultiDim_CUDA)', '    TEST(TensorTest,TorchTensorCtorZeroSizedDim)', '    TEST(TensorTest,TorchTensorCtorWithoutSpecifyingDtype)', '    TEST(TensorTest,TorchTensorCtorWithNonDtypeOptions)', '    TEST(TensorTest,Arange)', '    TEST(TensorTest,PrettyPrintTensorDataContainer)', '    TEST(TensorTest,TensorDataContainerCallingAccessorOfWrongType)', '    TEST(TensorTest,FromBlob)', '    TEST(TensorTest,FromBlobUsesDeleter)', '    TEST(TensorTest,FromBlobWithStrides)', '    TEST(TensorTest,Item)', '    TEST(TensorTest,Item_CUDA)', '    TEST(TensorTest,DataPtr)', '    TEST(TensorTest,Data)', '    TEST(TensorTest,BackwardAndGrad)', '    TEST(TensorTest,BackwardCreatesOnesGrad)', '    TEST(TensorTest,BackwardNonScalarOutputs)', '    TEST(TensorTest,IsLeaf)', '    TEST(TensorTest,OutputNr)', '    TEST(TensorTest,Version)', '    TEST(TensorTest,Detach)', '    TEST(TensorTest,DetachInplace)', '    TEST(TensorTest,SetData)', '    TEST(TensorTest,RequiresGradInplace)', '    test_Arange_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorMultiDim_CUDA_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorMultiDimFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorScalarFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorSingleDimFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorWithNonDtypeOptions_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorWithoutSpecifyingDtype_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorZeroSizedDim_expected_dtype(c10::ScalarType default_dtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\tensor.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\tensor.h', ['    final', '    TensorPrinter'], ['    GetTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetTensorInfoFunction(TypeIdentifier id)', '    GetTypeCallFunction(TypeIdentifier id)', '    RegisterTensorInfoFunction(TypeIdentifier id,TensorInfoCall c)', '    RegisterTypeCallFunction(TypeIdentifier id,TypeCall c)', '    ReinitializeAndCopyFrom(Tensor *t,at::TensorOptions options,const Tensor & src,bool async)', '    ReinitializeTensor(Tensor *tensor,at::IntArrayRef dims,at::TensorOptions options)', '    TensorCPUFromValues(at::IntArrayRef dims,at::ArrayRef values)', '    TensorVectorResize(std::vector & tensors,int size,DeviceType type)', '    device', '    computeDispatchKey', '    CopyItemsFromCPU', '    Alias', '    canonical_axis_index(int axis_index)', '    Clone', '    CopyFrom(const Tensor & src,bool async)', '    data', '    DebugString', '    defined', '    dim', '    dim(const int i)', '    dim32(const int i)', '    dtype', '    dtype_initialized', '    enforce_invariants', '    Extend(int64_t num,float growthPct)', '    ExtendTo(int64_t num,float growthPct)', '    FreeMemory', '    GetDevice', '    GetDeviceType', '    getIntrusivePtr', '    is_contiguous(at::MemoryFormat memory_format)', '    is_same(const Tensor & other)', '    IsType', '    itemsize', '    meta', '    mutable_data', '    nbytes', '    ndim', '    numel', '    operator at::Tensor', '    operator at::Tensor', '    operator bool', '    operator=', '    operator=', '    raw_data', '    raw_mutable_data(const TypeMeta & meta)', '    raw_mutable_data', '    ReserveSpace(const T & outer_dim)', '    Reshape(const vector & dims)', '    Reshape(const vector & dims)', '    Resize(Ts,...)', '    ResizeLike(const Tensor & src_tensor)', '    ShareData(const Tensor & src)', '    ShareExternalPointer(T *src,size_t capacity,MemoryDeleter d)', '    ShareExternalPointer(at::DataPtr,size_t capacity)', '    ShareExternalPointer(void *src,const TypeMeta & data_type,size_t capacity,MemoryDeleter d)', '    ShareExternalPointer(at::DataPtr,const TypeMeta & data_type,size_t capacity)', '    ShrinkTo(int64_t outer_dim)', '    size', '    size(const int i)', '    size_between_dim(int k,int l)', '    size_from_dim(int k)', '    size_to_dim(int k)', '    sizes', '    storage', '    storage', '    storage_initialized', '    stride(int64_t dim)', '    strides', '    Tensor(const Tensor & other,Unsafe _)', '    Tensor', '    Tensor', '    Tensor', '    Tensor(at::Device device)', '    Tensor(at::IntArrayRef dims,DeviceType type)', '    Tensor(at::IntArrayRef dims,at::Device device)', '    Tensor(const vector & dims,DeviceType type)', '    Tensor(const Tensor & src,DeviceType type)', '    Tensor(at::Tensor tensor)', '    unsafeGetTensorImpl', '    UnsafeSharedInstance', '    CopyFrom', '    dtype', '    getIntrusivePtr', '    is_contiguous', '    numel', '    sizes', '    MetaStr(const Tensor & tensor)', '    Print(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    TensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    ~TensorPrinter', '    uninitialized', '    Make']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\tensor.h', ['    DimArg', '    FunctionCall', '    Tensor'], ['    params(,...)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    make(Tensor *tensor,const std::vector & params)', '    dim', '    DimArg(const ExprHandle & dim)', '    DimArg(const ExprHandle & dim,const std::string & name_hint)', '    name_hint', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    FunctionCall(Tensor *tensor,const std::vector & params)', '    tensor', '    tensor', '    arg(int index)', '    args', '    body', '    call(const std::vector & args)', '    call(const Ts &,...)', '    call(const Ts &,...)', '    dim(int index)', '    dims', '    func_var', '    function', '    ndim', '    operator()(const Ts &,...)', '    operator()(const Ts &,...)', '    output_index', '    Tensor(Function *function,int output_index)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Tensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Tensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\tensor.h', [], ['    apply(variable_list)', '    apply(variable_list)', '    CopySlices(const Variable & base_var,at::TensorGeometry view_,std::shared_ptr fn_)', '    release_variables']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\serialize\\tensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms\\tensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\datasets\\tensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_apply.cpp', [], ['    recursive_apply(IntArrayRef sizes,ScalarType scalarType,int64_t dim,PyObject *fn,std::array strided_data)', '    apply_(Tensor & self,PyObject *fn)', '    map2_(Tensor & self,const Tensor & x_,const Tensor & y_,PyObject *fn)', '    map_(Tensor & self,const Tensor & other_,PyObject *fn)', '    step(int dim)', '    StridedData(const Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_apply.h', [], ['    apply_(at::Tensor & self,PyObject *fn)', '    map2_(at::Tensor & self,const at::Tensor & x_,const at::Tensor & y_,PyObject *fn)', '    map_(at::Tensor & self,const at::Tensor & other_,PyObject *fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\tensor_cuda.cpp', [], ['    TEST(TensorTest,AllocatesTensorOnTheCorrectDevice_MultiCUDA)', '    TEST(TensorTest,ToDevice_MultiCUDA)', '    TEST(TensorTest,ToTensorAndTensorAttributes_MultiCUDA)', '    TEST(TensorTest,ToDoesNotCopyWhenOptionsAreAllTheSame_CUDA)', '    TEST(TensorTest,ToDeviceAndDtype_MultiCUDA)', '    TEST(TensorTest,MagmaInitializesCorrectly_CUDA)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\tensor_desc.h', [], ['    findContiguous(const at::IntArrayRef & sizes,const at::IntArrayRef & strides)', '    hash(const TensorDesc & spec)', '    operator<<(std::ostream & out,const TensorDesc & d)', '    lastIsContiguous', '    nDim', '    operator!=(const TensorDesc & desc)', '    operator==(const TensorDesc & desc)', '    TensorDesc(const at::ScalarType & type,const at::IntArrayRef & sizes,const at::IntArrayRef & strides)', '    TensorDesc(const at::Tensor & t)', '    TensorDesc(const c10::TensorTypePtr & type)', '    scalar_type', '    sizes', '    strides', '    findContiguous', '    contiguity', '    TensorDesc(const at::ScalarType & type,const std::vector & contiguity)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_dtypes.cpp', [], ['    getDtypeNames(at::ScalarType scalarType)', '    initializeDtypes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_dtypes.h', [], ['    initializeDtypes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_flatten.cpp', [], ['    flatten_sparse_tensors(at::TensorList tensors)', '    get_indices(const at::Tensor & t)', '    get_values(const at::Tensor & t)', '    reorder_tensors_like(std::vector & tensors,TensorList order)', '    take_tensors(TensorList tensors,size_t size_limit,bool fine_grained)', '    unflatten_sparse_tensors(const at::Tensor & flat_indices,const at::Tensor & flat_values,at::TensorList tensors)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_flatten.h', [], ['    flatten_dense_tensors(at::TensorList tensors)', '    reorder_tensors_like(std::vector & tensors,at::TensorList order)', '    take_tensors(at::TensorList tensors,size_t size_limit,bool fine_grained)', '    unflatten_dense_tensors(const at::Tensor & flat,at::TensorList tensors)', '    unflatten_sparse_tensors(const at::Tensor & flat_indices,const at::Tensor & flat_values,at::TensorList tensors)', '    narrow', '    push_back', '    reserve', '    type', '    type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\tensor_impl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\tensor_indexing.cpp', [], ['    f', '    runner', '    tensor_sizes', '    TEST(TensorIndexingTest,Slice)', '    TEST(TensorIndexingTest,TensorIndex)', '    TEST(TensorIndexingTest,TestNoIndices)', '    TEST(TensorIndexingTest,TestAdvancedIndexingWithArrayRefOfTensor)', '    TEST(TensorIndexingTest,TestSingleInt)', '    TEST(TensorIndexingTest,TestMultipleInt)', '    TEST(TensorIndexingTest,TestNone)', '    TEST(TensorIndexingTest,TestStep)', '    TEST(TensorIndexingTest,TestStepAssignment)', '    TEST(TensorIndexingTest,TestBoolIndices)', '    TEST(TensorIndexingTest,TestBoolIndicesAccumulate)', '    TEST(TensorIndexingTest,TestMultipleBoolIndices)', '    TEST(TensorIndexingTest,TestByteMask)', '    TEST(TensorIndexingTest,TestByteMaskAccumulate)', '    TEST(TensorIndexingTest,TestMultipleByteMask)', '    TEST(TensorIndexingTest,TestByteMask2d)', '    TEST(TensorIndexingTest,TestIntIndices)', '    TEST(TensorIndexingTest,TestIntIndices2d)', '    TEST(TensorIndexingTest,TestIntIndicesBroadcast)', '    TEST(TensorIndexingTest,TestEmptyIndex)', '    TEST(TensorIndexingTest,TestEmptyNdimIndex)', '    TEST(TensorIndexingTest,TestEmptyNdimIndex_CUDA)', '    TEST(TensorIndexingTest,TestEmptyNdimIndexBool)', '    TEST(TensorIndexingTest,TestEmptyNdimIndexBool_CUDA)', '    TEST(TensorIndexingTest,TestEmptySlice)', '    TEST(TensorIndexingTest,TestEmptySlice_CUDA)', '    TEST(TensorIndexingTest,TestIndexGetitemCopyBoolsSlices)', '    TEST(TensorIndexingTest,TestIndexSetitemBoolsSlices)', '    TEST(TensorIndexingTest,TestIndexScalarWithBoolMask)', '    TEST(TensorIndexingTest,TestIndexScalarWithBoolMask_CUDA)', '    TEST(TensorIndexingTest,TestSetitemExpansionError)', '    TEST(TensorIndexingTest,TestGetitemScalars)', '    TEST(TensorIndexingTest,TestSetitemScalars)', '    TEST(TensorIndexingTest,TestBasicAdvancedCombined)', '    TEST(TensorIndexingTest,TestIntAssignment)', '    TEST(TensorIndexingTest,TestByteTensorAssignment)', '    TEST(TensorIndexingTest,TestVariableSlicing)', '    TEST(TensorIndexingTest,TestEllipsisTensor)', '    TEST(TensorIndexingTest,TestOutOfBoundIndex)', '    TEST(TensorIndexingTest,TestZeroDimIndex)', '    TEST(NumpyTests,TestNoneIndex)', '    TEST(NumpyTests,TestEmptyFancyIndex)', '    TEST(NumpyTests,TestEllipsisIndex)', '    TEST(NumpyTests,TestSingleIntIndex)', '    TEST(NumpyTests,TestSingleBoolIndex)', '    TEST(NumpyTests,TestBooleanShapeMismatch)', '    TEST(NumpyTests,TestBooleanIndexingOnedim)', '    TEST(NumpyTests,TestBooleanAssignmentValueMismatch)', '    TEST(NumpyTests,TestBooleanIndexingTwodim)', '    TEST(NumpyTests,TestBooleanIndexingWeirdness)', '    TEST(NumpyTests,TestBooleanIndexingWeirdnessTensors)', '    TEST(NumpyTests,TestBooleanIndexingAlldims)', '    TEST(NumpyTests,TestBooleanListIndexing)', '    TEST(NumpyTests,TestEverythingReturnsViews)', '    TEST(NumpyTests,TestBroaderrorsIndexing)', '    TEST(NumpyTests,TestTrivialFancyOutOfBounds)', '    TEST(NumpyTests,TestIndexIsLarger)', '    TEST(NumpyTests,TestBroadcastSubspace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\codegen\\fuser\\tensor_info.h', [], ['    sizes(size_t nDim)', '    strides(size_t nDim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\tensor_int8.cc', [], ['    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\tensor_int8.h', [], ['    scale', '    Tensor', '    zero_point']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\tensor_interop_test.cpp', [], ['    TEST(Caffe2ToPytorch,SimpleLegacy)', '    TEST(Caffe2ToPytorch,Simple)', '    TEST(Caffe2ToPytorch,ExternalData)', '    TEST(Caffe2ToPytorch,Op)', '    TEST(Caffe2ToPytorch,PartiallyInitialized)', '    TEST(Caffe2ToPytorch,MutualResizes)', '    TEST(PytorchToCaffe2,Op)', '    TEST(PytorchToCaffe2,SharedStorageRead)', '    TEST(PytorchToCaffe2,SharedStorageWrite)', '    TEST(PytorchToCaffe2,MutualResizes)', '    TEST(PytorchToCaffe2,Strided)', '    TEST(PytorchToCaffe2,InplaceStrided)', '    TEST(PytorchToCaffe2,NonRegularTensor)', '    TEST(Caffe2ToPytorch,NonPOD)', '    TEST(Caffe2ToPytorch,Nullptr)', '    TEST(PytorchToCaffe2,Nullptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\tensor_iterator_test.cpp', [], ['    random_tensor_for_type(at::ScalarType scalar_type)', '    TEST(TensorIteratorTest,CPUScalar)', '    TEST(TensorIteratorTest,CPUScalarInputs)', '    TEST(TensorIteratorTest,MixedDevices)', '    TEST(TensorIteratorTest,SerialLoopUnary_Byte)', '    TEST(TensorIteratorTest,SerialLoopUnary_Char)', '    TEST(TensorIteratorTest,SerialLoopUnary_Short)', '    TEST(TensorIteratorTest,SerialLoopUnary_Int)', '    TEST(TensorIteratorTest,SerialLoopUnary_Long)', '    TEST(TensorIteratorTest,SerialLoopUnary_Float)', '    TEST(TensorIteratorTest,SerialLoopUnary_Double)', '    TEST(TensorIteratorTest,SerialLoopBinary_Byte)', '    TEST(TensorIteratorTest,SerialLoopBinary_Char)', '    TEST(TensorIteratorTest,SerialLoopBinary_Short)', '    TEST(TensorIteratorTest,SerialLoopBinary_Int)', '    TEST(TensorIteratorTest,SerialLoopBinary_Long)', '    TEST(TensorIteratorTest,SerialLoopBinary_Float)', '    TEST(TensorIteratorTest,SerialLoopBinary_Double)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Byte)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Char)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Short)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Int)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Long)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Float)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Double)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Double)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Double)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Double)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Byte)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Char)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Short)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Int)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Long)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Float)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Double)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Bool)', '    TEST(TensorIteratorTest,SerialLoopSingleThread)', '    TEST(TensorIteratorTest,InputDType)', '    TEST(TensorIteratorTest,ComputeCommonDTypeInputOnly)', '    TEST(TensorIteratorTest,DoNotComputeCommonDTypeInputOnly)', '    TEST(TensorIteratorTest,DoNotComputeCommonDTypeIfOutputIsUndefined)', '    TEST(TensorIteratorTest,FailNonPromotingBinaryOp)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_layouts.cpp', [], ['    initializeLayouts']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_layouts.h', [], ['    initializeLayouts']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_list.cpp', [], ['    recursive_to_list(char *data,IntArrayRef sizes,IntArrayRef strides,int64_t dim,ScalarType scalarType,int64_t elementSize)', '    tensor_to_list(const Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_list.h', [], ['    tensor_to_list(const at::Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_memoryformats.cpp', [], ['    initializeMemoryFormats']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_memoryformats.h', [], ['    initializeMemoryFormats']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_new.cpp', [], ['    as_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    backendToBackendOfDeviceType(Backend b,DeviceType d)', '    check_base_legacy_new(c10::DispatchKey dispatch_key,at::Layout expected_layout)', '    check_legacy_ctor_device(c10::DispatchKey dispatch_key,c10::optional device)', '    compute_sizes(PyObject *seq)', '    denseTypeIdWithDefault(PythonArgs & r,int64_t device_idx,c10::DispatchKey dispatch_key)', '    dispatch_full(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,Scalar fill_value,const optional & device,IntArrayRef sizes)', '    dispatch_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    dispatch_zeros(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    indexing_tensor_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    infer_scalar_type(PyObject *obj)', '    internal_new_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device_opt,PyObject *data,bool copy_variables,bool copy_numpy,bool type_inference,bool pin_memory)', '    legacy_new_from_sequence(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    legacy_sparse_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_sparse_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    maybe_initialize_cuda(c10::DispatchKey dispatch_key)', '    maybe_initialize_cuda(const Device device)', '    new_from_data_copy(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    new_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_with_sizes(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    new_with_storage(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,Storage storage)', '    new_with_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const Tensor & other)', '    options(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const c10::optional & device)', '    recursive_store(char *data,IntArrayRef sizes,IntArrayRef strides,int64_t dim,ScalarType scalarType,int elementSize,PyObject *obj)', '    sparse_coo_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    typeIdWithDefault(PythonArgs & r,int64_t device_idx,c10::DispatchKey dispatch_key)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_new.h', [], ['    as_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    indexing_tensor_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    legacy_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    sparse_coo_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_numpy.cpp', [], ['    is_numpy_int(PyObject *obj)', '    is_numpy_scalar(PyObject *obj)', '    tensor_from_cuda_array_interface(PyObject *obj)', '    tensor_from_numpy(PyObject *obj)', '    tensor_to_numpy(const at::Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_numpy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\tensor_operators.cpp', [], ['    eq_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    eq_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    eq_quantized_cpu(const Tensor & self,Scalar other)', '    eq_quantized_cpu(const Tensor & self,const Tensor & other)', '    ge_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    ge_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    ge_quantized_cpu(const Tensor & self,Scalar other)', '    ge_quantized_cpu(const Tensor & self,const Tensor & other)', '    gt_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    gt_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    gt_quantized_cpu(const Tensor & self,Scalar other)', '    gt_quantized_cpu(const Tensor & self,const Tensor & other)', '    le_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    le_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    le_quantized_cpu(const Tensor & self,Scalar other)', '    le_quantized_cpu(const Tensor & self,const Tensor & other)', '    lt_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    lt_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    lt_quantized_cpu(const Tensor & self,Scalar other)', '    lt_quantized_cpu(const Tensor & self,const Tensor & other)', '    ne_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar)', '    ne_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    ne_quantized_cpu(const Tensor & self,Scalar other)', '    ne_quantized_cpu(const Tensor & self,const Tensor & other)', '    quantized_resize_cpu_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\tensor_options.cpp', [], ['    TEST(TensorOptionsTest,DefaultsToTheRightValues)', '    TEST(TensorOptionsTest,UtilityFunctionsReturnTheRightTensorOptions)', '    TEST(TensorOptionsTest,ConstructsWellFromCPUTypes)', '    TEST(TensorOptionsTest,ConstructsWellFromCPUTensors)', '    TEST(TensorOptionsTest,ConstructsWellFromVariables)', '    TEST(DeviceTest,ParsesCorrectlyFromString)', '    TEST(DefaultDtypeTest,CanSetAndGetDefaultDtype)', '    TEST(DefaultDtypeTest,NewTensorOptionsHasCorrectDefault)', '    TEST(DefaultDtypeTest,NewTensorsHaveCorrectDefaultDtype)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\tensor_options_cuda.cpp', [], ['    CPUDevice', '    CUDADevice(DeviceIndex index)', '    TEST(TensorOptionsTest,ConstructsWellFromCUDATypes_CUDA)', '    TEST(TensorOptionsTest,ConstructsWellFromCUDATensors_MultiCUDA)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tensor_protos_db_input.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTensorProtosDBInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorProtosDBInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tensor_protos_db_input.h', ['    final'], ['    BlobSetTensor(& [i] prefetched_blobs_,deserializer)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    CopyPrefetched', '    device', '    Prefetch', '    TensorProtosDBInput(const OperatorDef & operator_def,Workspace *ws)', '    ~TensorProtosDBInput', '    CopyPrefetched', '    TensorProtosDBInput(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tensor_protos_db_input_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDATensorProtosDBInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_qschemes.cpp', [], ['    getTHPQScheme(at::QScheme qscheme)', '    initializeQSchemes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_qschemes.h', [], ['    initializeQSchemes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_types.cpp', [], ['    backend_to_string(const at::Backend & backend)', '    options_from_string(const std::string & str)', '    options_to_string(const at::TensorOptions options)', '    type_to_string(const at::DeprecatedTypeProperties & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\tensor_types.h', [], ['    options_from_string(const std::string & str)', '    options_to_string(const at::TensorOptions options)', '    type_to_string(const at::DeprecatedTypeProperties & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorAccessor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\TensorAccessor.h', ['    GenericPackedTensorAccessor', '    GenericPackedTensorAccessor', '    GenericPackedTensorAccessorBase', '    TensorAccessor', '    TensorAccessor', '    TensorAccessorBase'], ['    GenericPackedTensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    data', '    data', '    GenericPackedTensorAccessorBase(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessorBase(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    size(index_t i)', '    stride(index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    TensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    TensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    data', '    data', '    size(index_t i)', '    sizes', '    stride(index_t i)', '    strides', '    TensorAccessorBase(PtrType data_,const index_t *sizes_,const index_t *strides_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp', [], ['    all_strides_match(TensorList tensors)', '    make_index_iterator(const AdvancedIndex & info)', '    make_index_put_iterator(const AdvancedIndex & info,const Tensor & value)', '    make_info(Tensor self,TensorList orig)', '    masked_fill_impl_cpu(Tensor & self,const Tensor & mask,Scalar value)', '    reshape_indexer(const Tensor & index,int64_t dims_before,int64_t dims_after)', '    restride_src(const Tensor & src,int64_t dims_before,int64_t dims_indexed,IntArrayRef replacement_shape)', '    shapes_as_str(TensorList tensors)', '    _gather_sparse_backward(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & grad)', '    _index_put_impl_(Tensor & self,TensorList indices,const Tensor & value,const bool accumulate,const bool unsafe)', '    gather_cpu(const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    gather_out_cpu(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    index(const Tensor & self,TensorList indices)', '    index_add(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_add_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_copy(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_copy_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_fill(const Tensor & self,int64_t dim,const Tensor & index,Scalar source)', '    index_fill(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_fill_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_put(const Tensor & self,TensorList indices,const Tensor & value,bool accumulate)', '    index_put_(Tensor & self,TensorList indices,const Tensor & value,const bool accumulate)', '    index_select_cpu_(const Tensor & self,int64_t dim,const Tensor & index)', '    index_select_out_cpu_(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index)', '    masked_fill(const Tensor & self,const Tensor & mask,Scalar source)', '    masked_fill(const Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_fill__cpu(Tensor & self,const Tensor & mask,Scalar value)', '    masked_fill__cpu(Tensor & self,const Tensor & mask,const Tensor & value)', '    masked_scatter(const Tensor & self,const Tensor & mask,const Tensor & source)', '    nonzero_numpy(const Tensor & self)', '    scatter(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    scatter(const Tensor & self,int64_t dim,const Tensor & index,Scalar source)', '    scatter_add(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    scatter_add_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_fill_cpu_(Tensor & self,int64_t dim,const Tensor & index,Scalar src)', '    AdvancedIndex(const Tensor & src,TensorList indices_list)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.h', [], ['    gather_stub', '    gather_stub', '    operator=', '    index_put_accum_stub', '    index_put_accum_stub', '    operator=', '    index_put_stub', '    index_put_stub', '    operator=', '    index_stub', '    index_stub', '    operator=', '    masked_fill_stub', '    masked_fill_stub', '    operator=', '    operator=', '    scatter_add_stub', '    scatter_add_stub', '    operator=', '    scatter_fill_stub', '    scatter_fill_stub', '    operator=', '    scatter_stub', '    scatter_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TensorBody.h', ['    Tensor'], ['    legacyExtractDispatchKey(const Tensor & t)', '    variable_excluded_from_dispatch', '    make_tensor(Args,...)', '    wrap_tensor_impl(c10::intrusive_ptr tensor_impl)', '    $', '    accessor', '    data', '    data_ptr', '    defined', '    dim', '    element_size', '    generic_packed_accessor', '    getIntrusivePtr', '    grad', '    grad', '    has_storage', '    is_alias_of(const at::Tensor & other)', '    is_contiguous(at::MemoryFormat memory_format)', '    is_non_overlapping_and_dense', '    is_same(const Tensor & other)', '    is_variable', '    itemsize', '    key_set', '    names', '    nbytes', '    ndimension', '    numel', '    operator=(const Tensor & x)', '    operator=(Tensor)', '    opt_names', '    packed_accessor', '    packed_accessor32', '    packed_accessor64', '    requires_grad', '    reset', '    scalar_type', '    set_requires_grad(bool requires_grad)', '    sizes', '    storage', '    storage_offset', '    strides', '    suggest_memory_format(bool channels_last_strides_exact_match)', '    Tensor', '    Tensor(c10::intrusive_ptr tensor_impl)', '    to(caffe2::TypeMeta type_meta,bool non_blocking,bool copy)', '    to(Device device,caffe2::TypeMeta type_meta,bool non_blocking,bool copy)', '    type', '    unsafeGetTensorImpl', '    unsafeReleaseTensorImpl', '    use_count', '    weak_use_count']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorCompare.cpp', [], ['    max_out_impl(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    min_out_impl(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _max_cpu(const Tensor & self,int64_t dim,bool keepdim)', '    _max_out_cpu(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _min_cpu(const Tensor & self,int64_t dim,bool keepdim)', '    _min_out_cpu(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _s_where(const Tensor & condition,const Tensor & self,const Tensor & other)', '    argmax(const Tensor & self,Dimname dim,bool keepdim)', '    argmin(const Tensor & self,Dimname dim,bool keepdim)', '    argsort(const Tensor & self,Dimname dim,bool keepdim)', '    isfinite(const Tensor & self)', '    allclose(const Tensor & self,const Tensor & other,double rtol,double atol,bool equal_nan)', '    isclose(const Tensor & self,const Tensor & other,double rtol,double atol,bool equal_nan)', '    isinf(const Tensor & self)', '    isnan(const Tensor & self)', '    is_nonzero(const Tensor & self)', '    max(const Tensor & self,int64_t dim,bool keepdim)', '    max(const Tensor & self,Dimname dim,bool keepdim)', '    max_out(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    max_out(Tensor & max,Tensor & max_indices,const Tensor & self,Dimname dim,bool keepdim)', '    min(const Tensor & self,int64_t dim,bool keepdim)', '    min(const Tensor & self,Dimname dim,bool keepdim)', '    min_out(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    min_out(Tensor & min,Tensor & min_indices,const Tensor & self,Dimname dim,bool keepdim)', '    mode(const Tensor & self,int64_t dim,bool keepdim)', '    mode(const Tensor & self,Dimname dim,bool keepdim)', '    mode_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim,bool keepdim)', '    mode_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    result', '    result', '    result', '    where(const Tensor & condition,const Tensor & self,const Tensor & other)', '    where(const Tensor & condition)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\TensorCompare.cpp', [], ['    max_quant(const Tensor & self)', '    min_quant(const Tensor & self)', '    sort_quant(const Tensor & self,int64_t dim,bool descending)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorCompare.h', [], ['    max_stub', '    max_stub', '    operator=', '    min_stub', '    min_stub', '    operator=', '    operator=', '    where_kernel', '    where_kernel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\TensorCompareKernel.cpp', [], ['    compare_base_kernel(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim,const func_t & f)', '    max_kernel_impl(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim)', '    min_kernel_impl(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim)', '    where_kernel_impl(TensorIterator & iter,ScalarType condition_type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorConversions.cpp', [], ['    ensure_has_index(Device device)', '    to_impl(const Tensor & self,const TensorOptions & options,bool non_blocking,bool copy)', '    to(const Tensor & self,const TensorOptions & options_,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,Device device,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,const Tensor & other,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to_dense_backward(const Tensor & grad,const Tensor & input_)', '    to_mkldnn_backward(const Tensor & grad,const Tensor & input_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\detail\\TensorDataContainer.h', ['    TensorDataContainerType'], ['    str(,,,,,::c10::str __VA_ARGS__)', '    operator<<(std::ostream & stream,const TensorDataContainer & tensor_data_container)', '    compute_desired_dtype(c10::ScalarType scalar_type)', '    operator<<(std::ostream & stream,const TensorDataContainer & tensor_data_container)', '    operator<<(std::ostream & stream,c10::BFloat16 value)', '    fill_', '    device', '    begin', '    end', '    insert', '    push_back', '    reserve', '    size', '    convert_to_tensor(at::TensorOptions options)', '    fill_tensor(at::Tensor & tensor)', '    init_list', '    is_init_list', '    is_scalar', '    is_tensor', '    pretty_print_recursive(std::ostream & stream)', '    scalar', '    scalar_type', '    sizes', '    tensor', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer', '    TensorDataContainer(uint8_t value)', '    TensorDataContainer(int8_t value)', '    TensorDataContainer(int16_t value)', '    TensorDataContainer(int value)', '    TensorDataContainer(int64_t value)', '    TensorDataContainer(float value)', '    TensorDataContainer(double value)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(std::initializer_list init_list)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorDimApply.h', [], ['    tensor_dim_apply3(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim,Function func)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\tensorexpr_fuser.cpp', [], ['    tensorExprFuserEnabled', '    canHandle(Node *node,AliasDb & aliasDb)', '    canMerge(Node *consumer,Node *producer,AliasDb & aliasDb)', '    createTensorExprOp(const Node *node)', '    fuseTensorExprs(std::shared_ptr & graph)', '    getOrCreateTensorExprSubgraph(Node *n)', '    getTensorExprSymbol', '    isSupported(Node *node)', '    scanNode(Node *consumer,AliasDb & aliasDb)', '    setTensorExprFuserEnabled(bool val)', '    sortReverseTopological(ArrayRef inputs,torch::jit::Block *block)', '    tryMerge(Node *consumer,Node *producer,AliasDb & aliasDb)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\tensorexpr_fuser.h', [], ['    registerTensorExprFuser', '    setTensorExprFuserEnabled(bool val)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\TensorFactories.cpp', [], ['    empty_mkldnn(IntArrayRef sizes,const TensorOptions & options,c10::optional optional_memory_format)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorFactories.cpp', [], ['    allIntegral(std::initializer_list)', '    torch_warn_once_356', '    _cast_BFloat16(const Tensor & self,bool non_blocking)', '    _cast_Bool(const Tensor & self,bool non_blocking)', '    _cast_Byte(const Tensor & self,bool non_blocking)', '    _cast_Char(const Tensor & self,bool non_blocking)', '    _cast_Double(const Tensor & self,bool non_blocking)', '    _cast_Float(const Tensor & self,bool non_blocking)', '    _cast_Half(const Tensor & self,bool non_blocking)', '    _cast_Int(const Tensor & self,bool non_blocking)', '    _cast_Long(const Tensor & self,bool non_blocking)', '    _cast_Short(const Tensor & self,bool non_blocking)', '    _dim_arange(const Tensor & like,int64_t dim)', '    arange(Scalar start,Scalar end,const TensorOptions & options)', '    arange(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    window_function_checks(const char *function_name,const TensorOptions & options,int64_t window_length)', '    bartlett_window(int64_t window_length,const TensorOptions & options)', '    bartlett_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    blackman_window(int64_t window_length,const TensorOptions & options)', '    blackman_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    clone(const Tensor & src,c10::optional optional_memory_format)', '    empty(IntArrayRef size,at::optional names,const TensorOptions & options,optional optional_memory_format)', '    empty_cpu(IntArrayRef size,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_like(const Tensor & self,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_strided_cpu(IntArrayRef size,IntArrayRef stride,const TensorOptions & options)', '    eye(int64_t n,const TensorOptions & options)', '    eye(int64_t n,int64_t m,const TensorOptions & options)', '    from_file(std::string filename,c10::optional shared,c10::optional size,const TensorOptions & options)', '    full(IntArrayRef size,Scalar fill_value,const TensorOptions & options)', '    full(IntArrayRef size,Scalar fill_value,optional names,const TensorOptions & options)', '    full_like(const Tensor & self,Scalar fill_value,const TensorOptions & options,c10::optional optional_memory_format)', '    hamming_window(int64_t window_length,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,double alpha,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,double alpha,double beta,const TensorOptions & options)', '    hann_window(int64_t window_length,const TensorOptions & options)', '    hann_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    infer_full_options(Scalar fill_value,const TensorOptions & options)', '    linspace(Scalar start,Scalar end,int64_t steps,const TensorOptions & options)', '    logspace(Scalar start,Scalar end,int64_t steps,double base,const TensorOptions & options)', '    new_empty(const Tensor & self,IntArrayRef size,const TensorOptions & options)', '    new_full(const Tensor & self,IntArrayRef size,Scalar fill_value,const TensorOptions & options)', '    new_zeros(const Tensor & self,IntArrayRef size,const TensorOptions & options)', '    normal(double mean,double std,IntArrayRef size,Generator generator,const TensorOptions & options)', '    ones(IntArrayRef size,const TensorOptions & options)', '    ones(IntArrayRef size,optional names,const TensorOptions & options)', '    ones_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    rand(IntArrayRef size,const TensorOptions & options)', '    rand(IntArrayRef size,Generator generator,const TensorOptions & options)', '    rand(IntArrayRef size,optional names,const TensorOptions & options)', '    rand(IntArrayRef size,Generator generator,optional names,const TensorOptions & options)', '    rand_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    randint(int64_t high,IntArrayRef size,const TensorOptions & options)', '    randint(int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    randint(int64_t low,int64_t high,IntArrayRef size,const TensorOptions & options)', '    randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    randint_like(const Tensor & self,int64_t high,const TensorOptions & options,c10::optional optional_memory_format)', '    randint_like(const Tensor & self,int64_t low,int64_t high,const TensorOptions & options,c10::optional optional_memory_format)', '    randn(IntArrayRef size,const TensorOptions & options)', '    randn(IntArrayRef size,Generator generator,const TensorOptions & options)', '    randn(IntArrayRef size,optional names,const TensorOptions & options)', '    randn(IntArrayRef size,Generator generator,optional names,const TensorOptions & options)', '    randn_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    randperm(int64_t n,const TensorOptions & options)', '    randperm(int64_t n,Generator generator,const TensorOptions & options)', '    randperm_cpu(Tensor & result,int64_t n,CPUGenerator *generator)', '    range(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    range(Scalar start,Scalar end,const TensorOptions & options)', '    scalar_tensor(Scalar s,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor_backend(ArrayRef values,const TensorOptions & options)', '    tensor_cpu(ArrayRef values,const TensorOptions & options)', '    tril_indices_cpu(int64_t row,int64_t col,int64_t offset,const TensorOptions & options)', '    triu_indices_cpu(int64_t row,int64_t col,int64_t offset,const TensorOptions & options)', '    zeros(IntArrayRef size,const TensorOptions & options)', '    zeros(IntArrayRef size,optional names,const TensorOptions & options)', '    zeros_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\TensorFactories.cpp', [], ['    empty_affine_quantized_cpu(IntArrayRef size,const TensorOptions & options_,double scale,int64_t zero_point,c10::optional optional_memory_format)', '    empty_affine_quantized_other_backends_stub(IntArrayRef,const TensorOptions &,double,int64_t,c10::optional)', '    empty_per_channel_affine_quantized_cpu(IntArrayRef size,const Tensor & scales,const Tensor & zero_points,int64_t axis,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_per_channel_affine_quantized_other_backends_stub(IntArrayRef,const Tensor &,const Tensor &,int64_t,const TensorOptions &,c10::optional)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorFactories.h', [], ['    check_args(int64_t row,int64_t col,const TensorOptions & options)', '    check_size_nonnegative(IntArrayRef size)', '    check_supported_max_int_with_precision(int64_t n,const Tensor & tensor)', '    get_tril_size(int64_t row,int64_t col,int64_t offset)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorGeometry.cpp', [], ['    is_contiguous']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorGeometry.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\TensorImpl.cpp', ['    C10FlagParser_caffe2_keep_on_shrink', '    C10FlagParser_caffe2_max_keep_on_shrink_memory'], ['    deletePlacementDeleteContext(void *ptr)', '    GetAutogradMetaFactory', '    SetAutogradMetaFactory(AutogradMetaFactory *factory)', '    key_set_(key_set)', '    d', '    d', '    makeDataPtr(at::DataPtr,PlacementDtor placement_dtor,size_t size,at::Device device)', '    ~AutogradMetaInterface', '    C10FlagParser_caffe2_keep_on_shrink(const std::string & content)', '    C10FlagParser_caffe2_max_keep_on_shrink_memory(const std::string & content)', '    autograd_meta', '    compute_channels_last_contiguous_2d', '    compute_channels_last_contiguous_3d', '    compute_contiguous', '    compute_non_overlapping_and_dense', '    compute_strides_like_channels_last_2d', '    compute_strides_like_channels_last_3d', '    copy_tensor_metadata(const TensorImpl *src_impl,TensorImpl *dest_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    dim', '    grad', '    grad', '    has_storage', '    is_contiguous(at::MemoryFormat memory_format)', '    release_resources', '    requires_grad', '    set_autograd_meta(std::unique_ptr autograd_meta)', '    set_requires_grad(bool requires_grad)', '    size(int64_t d)', '    sizes', '    storage', '    stride(int64_t d)', '    strides', '    TensorImpl(Storage,DispatchKeySet key_set)', '    TensorImpl(DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::optional device_opt)', '    TensorImpl(Storage,DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::optional device_opt)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\TensorImpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\TensorImpl_test.cpp', [], ['    TEST(TensorImplTest,Caffe2Constructor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorIndexing.cpp', [], ['    set_item(Tensor & self,ArrayRef indices,Scalar)', '    operator<<(std::ostream & stream,const Slice & slice)', '    operator<<(std::ostream & stream,const TensorIndex & tensor_index)', '    operator<<(std::ostream & stream,const std::vector & tensor_indices)', '    index(ArrayRef indices)', '    index(std::initializer_list indices)', '    index_put_(ArrayRef indices,Tensor const & rhs)', '    index_put_(std::initializer_list indices,Tensor const & rhs)', '    index_put_(ArrayRef indices,Scalar v)', '    index_put_(std::initializer_list indices,Scalar v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorIndexing.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorIterator.cpp', [], ['    compute_common_type_(at::ArrayRef operands)', '    maybe_copy_casting_to_common_dtype(OperandInfo & op,ScalarType common_dtype)', '    validate_dtype(OperandInfo & op,ScalarType common_dtype,CommonDTypeStrategy strategy)', '    compute_device(at::ArrayRef operands)', '    binary_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    comparison_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    nullary_op(Tensor & out)', '    reduce_op(Tensor & out,const Tensor & a)', '    reduce_op(Tensor & out1,Tensor & out2,const Tensor & a)', '    unary_op(Tensor & out,const Tensor & a,bool check_mem_overlap)', '    DimCounter(IntArrayRef shape,Range range)', '    increment(const std::array & step)', '    is_done', '    max_2d_step', '    begin', '    end', '    iterator(const TensorIterator & iter)', '    operator*', '    operator++', '    allocate_outputs', '    analyze_memory_format', '    apply_perm_and_mul(IntArrayRef input,int mul)', '    build', '    can_use_32bit_indexing', '    check_mem_overlaps', '    coalesce_dimensions', '    compatible_stride(int element_size)', '    compute_common_type', '    compute_fast_setup_type', '    compute_names', '    compute_shape', '    compute_strides', '    compute_types', '    data_ptr(int arg)', '    fast_set_up', '    for_each(loop_t loop,int64_t grain_size)', '    for_each(loop2d_t loop,int64_t grain_size)', '    get_base_ptrs', '    get_data_ptrs(ArrayRef base,IntArrayRef counter)', '    get_dim_strides(int dim)', '    get_dim_to_split', '    get_strides', '    invert_perm(IntArrayRef input)', '    is_contiguous', '    is_cpu_scalar(int arg)', '    is_dim_reduced(int dim)', '    is_scalar(int arg)', '    is_trivial_1d', '    mark_outputs', '    narrow(int dim,int64_t start,int64_t size)', '    num_output_elements', '    num_reduce_dims', '    numel', '    permute_dimensions(IntArrayRef perm)', '    propagate_names_to_outputs', '    remove_dimension(int dim)', '    remove_operand(int arg)', '    reorder_dimensions', '    select_all_keeping_dim(int start_dim,IntArrayRef indices)', '    serial_for_each(loop_t loop,Range range)', '    serial_for_each(loop2d_t loop,Range range)', '    split(int dim)', '    unsafe_replace_operand(int arg,void *data)', '    with_32bit_indexing']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorIterator.h', ['    CommonDTypeStrategy', '    FastSetupType'], ['    binary_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    comparison_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    nullary_op(Tensor & out)', '    reduce_op(Tensor & out,const Tensor & a)', '    reduce_op(Tensor & out1,Tensor & out2,const Tensor & a)', '    unary_op(Tensor & out,const Tensor & a,bool check_mem_overlap)', '    DimCounter(IntArrayRef shape,Range range)', '    increment(const std::array & step)', '    is_done', '    max_2d_step', '    is_type_defined', '    OperandInfo', '    OperandInfo(const Tensor & t)', '    OperandInfo(const Tensor & t,Device device,ScalarType dtype)', '    options', '    validate', '    begin', '    end', '    iterator', '    iterator(const TensorIterator & iter)', '    iterator', '    operator!=(const iterator & other)', '    operator*', '    operator++', '    operator==(const iterator & other)', '    SplitUntil32Bit(const TensorIterator & iter)', '    defined', '    device', '    layout', '    scalar_type', '    add_input(const Tensor & input)', '    add_input(const Tensor & input,Device device,ScalarType dtype)', '    add_output(const Tensor & output)', '    add_output(const Tensor & input,Device device,ScalarType dtype)', '    allocate_outputs', '    analyze_memory_format', '    apply_perm_and_mul(IntArrayRef input,int mul)', '    build', '    can_use_32bit_indexing', '    cast_outputs', '    check_mem_overlaps', '    coalesce_dimensions', '    common_dtype', '    compatible_stride(int element_size)', '    compute_common_dtype_only_for_inputs', '    compute_common_type', '    compute_fast_setup_type', '    compute_names', '    compute_shape', '    compute_strides', '    compute_types', '    data_ptr(int arg)', '    device(int arg)', '    device_type(int arg)', '    dont_compute_common_dtype', '    dont_resize_outputs', '    dtype(int arg)', '    element_size(int arg)', '    fast_set_up', '    for_each(loop_t loop,int64_t grain_size)', '    for_each(loop2d_t loop,int64_t grain_size)', '    foreach_reduced_elt(loop_subiter_t loop,bool parallelize)', '    get_base_ptrs', '    get_data_ptrs(ArrayRef base,IntArrayRef counter)', '    get_dim_strides(int dim)', '    get_dim_to_split', '    get_inner_strides', '    get_strides', '    has_contiguous_first_dim', '    input(int arg)', '    input_dtype(int arg)', '    invert_perm(IntArrayRef input)', '    is_contiguous', '    is_cpu_scalar(int arg)', '    is_dim_reduced(int dim)', '    is_final_output', '    is_scalar(int arg)', '    is_trivial_1d', '    mark_outputs', '    narrow(int dim,int64_t start,int64_t size)', '    ndim', '    ninputs', '    noutputs', '    ntensors', '    num_output_elements', '    num_reduce_dims', '    numel', '    output(int arg)', '    parallel_reduce(loop2d_t loop)', '    permute_dimensions(IntArrayRef perm)', '    promote_common_dtype', '    propagate_names_to_outputs', '    remove_dimension(int dim)', '    remove_operand(int arg)', '    reorder_dimensions', '    scalar_value(int arg)', '    select_all_keeping_dim(int start_dim,IntArrayRef indices)', '    serial_for_each(loop_t loop,Range range)', '    serial_for_each(loop2d_t loop,Range range)', '    set_check_mem_overlap(bool check_mem_overlap)', '    shape', '    should_accumulate', '    split(int dim)', '    strides(int arg)', '    tensor(int arg)', '    tensor(int arg)', '    TensorIterator', '    unsafe_replace_operand(int arg,void *data)', '    view_offsets', '    with_32bit_indexing', '    fetch_and_cast']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorIteratorReduce.cpp', [], ['    find_split_dim(TensorIterator & iter)', '    parallel_dim_reduction(TensorIterator & iter,loop2d_t loop)', '    round_columns(TensorIterator & iter,int dim,int multiple,int64_t begin,int64_t end)', '    two_pass_reduction(TensorIterator & iter,loop2d_t loop)', '    use_two_pass_reduction(TensorIterator & iter)', '    dims', '    foreach_reduced_elt(loop_subiter_t loop,bool parallelize)', '    parallel_reduce(loop2d_t loop)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TensorMethods.h', [], ['    $', '    get_device(Tensor self)', '    is_cuda(Tensor self)', '    is_hip(Tensor self)', '    is_mkldnn(Tensor self)', '    is_quantized(Tensor self)', '    is_sparse(Tensor self)', '    cpu', '    cuda', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    device', '    dtype', '    get_device', '    get_named_tensor_meta', '    get_named_tensor_meta', '    has_names', '    hip', '    is_cuda', '    is_hip', '    is_mkldnn', '    is_quantized', '    is_sparse', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    layout', '    options', '    register_hook(T)', '    register_hook(T)', '    toBackend(Backend b)', '    toType(ScalarType)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorNames.cpp', [], ['    operator<<(std::ostream & out,const TensorName & tensorname)', '    toDimname', '    unify(const TensorName & other,const char *op_name)', '    append(TensorName)', '    checkUnique(const char *op_name)', '    TensorNames(ArrayRef names)', '    TensorNames(ArrayRef names,int64_t start,int64_t end)', '    toDimnameVec', '    unifyFromRightInplace(const TensorNames & other,const char *op_name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorNames.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorOperators.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\TensorOptions.cpp', [], ['    operator<<(std::ostream & stream,const TensorOptions & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\TensorOptions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorOptions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorProperties.cpp', [], ['    contiguous(const Tensor & self)', '    contiguous(const Tensor & self,MemoryFormat memory_format)', '    cudnn_is_acceptable(const Tensor & self)', '    detach(const Tensor & self)', '    detach_(Tensor & self)', '    is_same_size(const Tensor & self,const Tensor & other)', '    is_set_to(const Tensor & self,const Tensor & src)', '    size(const Tensor & self,int64_t dim)', '    size(const Tensor & self,Dimname dim)', '    stride(const Tensor & self,int64_t dim)', '    stride(const Tensor & self,Dimname dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\tensorrt_op_trt.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDATensorRT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorRT', '    CheckDims(const nvinfer1::Dims & nv_dims,at::ArrayRef c2_dims)', '    MaybeAdjustOutputShape(int output_idx,std::vector *dims)', '    RunOnDevice', '    TensorRTOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\tensorrt_op_trt.h', ['    final'], ['    batch_warning_issued_', '    MaybeAdjustOutputShape(int output_idx,std::vector *dims)', '    RunOnDevice', '    TensorRTOp(const OperatorDef & operator_def,Workspace *ws)', '    trt_engine_', '    trt_executor_', '    ~TensorRTOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\tensorrt_tranformer.cc', [], ['    BlobToTensorProto(const std::string & name,Workspace *ws,CUDAContext *context,::ONNX_NAMESPACE::TensorProto *t)', '    BuildInitializationList(Workspace *ws,::ONNX_NAMESPACE::GraphProto *g,std::unordered_set *initialization_list)', '    ConvertToValueInfo(const std::vector & names,const std::unordered_map & shape_hints)', '    CPUTensorToTensorProto(const TensorCPU & cpu_tensor,::ONNX_NAMESPACE::TensorProto *t)', '    DumpModel(const ::ONNX_NAMESPACE::ModelProto & model,const std::string & fname)', '    FillModelInfo(::ONNX_NAMESPACE::ModelProto *model)', '    InferShapes(Workspace *ws,NetDef *pred_net,CaffeMap *shape_hints_ordered)', '    trt_converter', '    AddTrtOptions(OperatorDef *op,const std::unordered_map,std::vector)', '    BuildTrtOp(const std::string & onnx_model_str,const std::unordered_map,std::vector)', '    BuildTrtOpLazy(const std::string & onnx_model_str,const std::unordered_map,std::vector,const std::unordered_set & initialization_list,const caffe2::NetDef & net)', '    PruneUnusedWeights(Workspace *ws,const NetDef & pred_net)', '    SsaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    SubnetToTrtOp(const caffe2::NetDef & net,Workspace *ws,onnx::OnnxExporter *exporter,std::unordered_map *shape_hints)', '    Transform(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\tensorrt_tranformer.h', ['    TensorRTTransformer'], ['    BuildInitializationList(Workspace *ws,::ONNX_NAMESPACE::GraphProto *g,std::unordered_set *initialization_list)', '    AddTrtOptions(caffe2::OperatorDef *op,const std::unordered_map,std::vector)', '    build_serializable_op_', '    BuildTrtOp(const std::string & onnx_model_str,const std::unordered_map,std::vector)', '    BuildTrtOpLazy(const std::string & onnx_model_str,const std::unordered_map,std::vector,const std::unordered_set & initialization_list,const caffe2::NetDef & net)', '    debug_builder_', '    max_batch_size_', '    max_workspace_size_', '    PruneUnusedWeights(Workspace *ws,const NetDef & pred_net)', '    SsaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    SubnetToTrtOp(const caffe2::NetDef & net,Workspace *ws,onnx::OnnxExporter *exporter,std::unordered_map *shape_hints)', '    TensorRTTransformer(size_t max_batch_size,size_t max_workspace_size,int verbosity,bool debug_builder,bool build_serializable_op)', '    Transform(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    verbosity_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorShape.cpp', [], ['    cat_sparse(TensorList tensors,int64_t dim)', '    check_cat_no_zero_dim(TensorList tensors)', '    check_cat_shape_except_dim(const Tensor & first,const Tensor & second,int64_t dimension)', '    check_cat_sparse_dims(Tensor const & t,int64_t pos,IntArrayRef sizes,int64_t wrapped,int64_t sparse_dim,int64_t dense_dim)', '    check_t(const Tensor & self,const char *fn)', '    get_stack_inputs(TensorList tensors,int64_t dim)', '    propagate_transposed_names(Tensor & result,const Tensor & other,int64_t dim0,int64_t dim1)', '    select_sparse(const Tensor & self,int64_t dim,int64_t index)', '    sizes_match_except(IntArrayRef s1,IntArrayRef s2,int64_t dim_except)', '    sparse_transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    unsqueeze_sparse(Tensor const & self,int64_t dim)', '    _unsafe_view(const Tensor & self,IntArrayRef size)', '    alias(const Tensor & self)', '    apply_diag(Tensor & result,const Tensor & self,int64_t dimension)', '    diag(const Tensor & self,int64_t dimension)', '    diag_out(Tensor & result,const Tensor & self,int64_t dimension)', '    flatten(const Tensor & self,int64_t start_dim,int64_t end_dim)', '    flatten(const Tensor & self,int64_t start_dim,int64_t end_dim,Dimname out_dim)', '    flatten(const Tensor & self,Dimname start_dim,Dimname end_dim,Dimname out_dim)', '    flatten(const Tensor & self,DimnameList dims,Dimname out_dim)', '    inferSqueezeGeometry(const Tensor & tensor)', '    inferSqueezeGeometry(const Tensor & tensor,int64_t dim)', '    inferUnsqueezeGeometry(const Tensor & tensor,int64_t dim)', '    meshgrid(TensorList tensors)', '    _cat_cpu(TensorList tensors,int64_t dim)', '    _cat_out_cpu(Tensor & result,TensorList tensors,int64_t dim)', '    _reshape_from_tensor(const Tensor & self,const Tensor & shape_tensor)', '    _shape_as_tensor(const Tensor & self)', '    alias_with_sizes_and_strides(const Tensor & self,const c10::IntArrayRef sizes,const c10::IntArrayRef strides)', '    as_strided_(Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    as_strided_qtensorimpl(const Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    as_strided_tensorimpl(const Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    broadcast_tensors(TensorList tensors)', '    cat(TensorList tensors,Dimname dim)', '    cat(TensorList tensors,int64_t dim)', '    cat_out(Tensor & result,TensorList tensors,int64_t dim)', '    cat_out(Tensor & result,TensorList tensors,Dimname dim)', '    chunk(const Tensor & self,int64_t chunks,int64_t dim)', '    diag_embed(const Tensor & self,int64_t offset,int64_t dim1_,int64_t dim2_)', '    diagflat(const Tensor & self,int64_t offset)', '    diagonal(const Tensor & self,int64_t offset,int64_t dim1_,int64_t dim2_)', '    diagonal(const Tensor & self,Dimname outdim,Dimname dim1,Dimname dim2,int64_t offset)', '    expand(const Tensor & self,IntArrayRef size,bool implicit)', '    expand_as(const Tensor & self,const Tensor & other)', '    index_select_sparse(const Tensor & self,int64_t dim,const Tensor & index)', '    narrow(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    narrow(const Tensor & self,int64_t dim,const Tensor & start,int64_t length)', '    narrow_copy_dense(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    narrow_copy_sparse(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    permute(const Tensor & self,IntArrayRef dims)', '    repeat(const Tensor & self,IntArrayRef repeats)', '    reshape(const Tensor & self,IntArrayRef proposed_shape)', '    reshape_as(const Tensor & self,const Tensor & other)', '    select(const Tensor & self,int64_t dim,int64_t index)', '    select(const Tensor & self,Dimname dim,int64_t index)', '    set_(Tensor & result,Storage source)', '    set_cpu_(Tensor & result)', '    set_storage_cpu_(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)', '    set_tensor_(Tensor & result,const Tensor & source)', '    slice(const Tensor & self,int64_t dim,int64_t start,int64_t end,int64_t step)', '    split(const Tensor & self,int64_t split_size,int64_t dim)', '    split_with_sizes(const Tensor & self,IntArrayRef split_sizes,int64_t dim)', '    stack(TensorList tensors,int64_t dim)', '    stack_out(Tensor & result,TensorList tensors,int64_t dim)', '    sum_to_size(const Tensor & self,IntArrayRef size)', '    transpose(const Tensor & self,Dimname dim0,Dimname dim1)', '    transpose(const Tensor & self,int64_t dim0,int64_t dim1)', '    transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    numel(const Tensor & self)', '    numpy_T(const Tensor & self)', '    squeeze(const Tensor & self)', '    squeeze(const Tensor & self,int64_t dim)', '    squeeze_(Tensor & self)', '    squeeze_(Tensor & self,int64_t dim)', '    t_(Tensor & self)', '    unbind(const Tensor & self,int64_t dim)', '    unbind(const Tensor & self,Dimname dim)', '    unfold(const Tensor & self,int64_t dimension,int64_t size,int64_t step)', '    unsqueeze(const Tensor & self,int64_t dim)', '    unsqueeze_(Tensor & self,int64_t dim)', '    view(const Tensor & self,IntArrayRef size)', '    view_as(const Tensor & self,const Tensor & other)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\TensorShape.cpp', [], ['    mkldnn_clone(const Tensor & self,c10::optional optional_memory_format)', '    mkldnn_reshape(const Tensor & self,IntArrayRef size)', '    mkldnn_transpose(const Tensor & self,int64_t dim0,int64_t dim1)', '    mkldnn_transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    mkldnn_view(const Tensor & self,IntArrayRef size)', '    y']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\TensorShape.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cuda\\TensorShapeCUDA.cpp', [], ['    set_cuda_(Tensor & result)', '    set_storage_cuda_(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorTransformations.cpp', [], ['    flip_cpu(const Tensor & self,IntArrayRef dims)', '    flip_cpu_kernel(const int64_t total_dims,const std::vector & stride_contiguous_v,const std::bitset & flip_dims_b,const Tensor & in_tensor,Tensor & out_tensor)', '    roll_cpu(const Tensor & self,IntArrayRef shifts,IntArrayRef dims)', '    rot90(const Tensor & self,int64_t k,IntArrayRef dims)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TensorTransformations.h', [], ['    flip_check_errors(int64_t total_dims,int64_t flip_dims_size,IntArrayRef dims)', '    roll_common(const Tensor & self,IntArrayRef shifts,IntArrayRef dims)', '    roll', '    minmax_element', '    unique']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorUtils.cpp', [], ['    check_dim_size(const Tensor & tensor,int64_t dim,int64_t dim_size,int64_t size)', '    checkAllContiguous(CheckedFrom c,at::ArrayRef ts)', '    checkAllDefined(CheckedFrom c,ArrayRef ts)', '    checkAllSame(CheckedFrom c,ArrayRef tensors,void (*) (CheckedFrom, const TensorArg &, const TensorArg &) fn)', '    checkAllSameGPU(CheckedFrom c,ArrayRef tensors)', '    checkAllSameNumel(CheckedFrom c,ArrayRef tensors)', '    checkAllSameSize(CheckedFrom c,ArrayRef tensors)', '    checkAllSameType(CheckedFrom c,ArrayRef tensors)', '    checkBackend(CheckedFrom c,at::ArrayRef tensors,at::Backend backend)', '    checkBackend(CheckedFrom c,const Tensor & t,Backend backend)', '    checkContiguous(CheckedFrom c,const TensorGeometryArg & t)', '    checkDefined(CheckedFrom c,const TensorArg & t)', '    checkDeviceType(CheckedFrom c,at::ArrayRef tensors,at::DeviceType device_type)', '    checkDeviceType(CheckedFrom c,const Tensor & t,DeviceType device_type)', '    checkDim(CheckedFrom,const TensorGeometryArg & t,int64_t dim)', '    checkDimRange(CheckedFrom c,const TensorGeometryArg & t,int64_t dim_start,int64_t dim_end)', '    checkLayout(CheckedFrom c,const Tensor & t,Layout layout)', '    checkLayout(CheckedFrom c,at::ArrayRef tensors,at::Layout layout)', '    checkNumel(CheckedFrom c,const TensorGeometryArg & t,int64_t numel)', '    checkSameDim(CheckedFrom c,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameGPU(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameNumel(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameSize(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameType(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkScalarType(CheckedFrom c,const TensorArg & t,ScalarType ty)', '    checkScalarTypes(CheckedFrom c,const TensorArg & t,at::ArrayRef l)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,IntArrayRef sizes)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,int64_t dim,int64_t size)', '    computeStorageSize(IntArrayRef sizes,IntArrayRef strides)', '    defaultStrides(IntArrayRef sizes)', '    geometry_is_contiguous(IntArrayRef sizes,IntArrayRef strides)', '    maybe_data_ptr(const Tensor & tensor)', '    maybe_data_ptr(const TensorArg & tensor)', '    operator<<(std::ostream & out,TensorGeometryArg t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\TensorUtils.h', [], ['    check_dim_size(const Tensor & tensor,int64_t dim,int64_t dim_size,int64_t size)', '    checkAllContiguous(CheckedFrom c,at::ArrayRef ts)', '    checkAllDefined(CheckedFrom,at::ArrayRef t)', '    checkAllSameGPU(CheckedFrom c,ArrayRef tensors)', '    checkAllSameNumel(CheckedFrom c,ArrayRef tensors)', '    checkAllSameType(CheckedFrom c,ArrayRef tensors)', '    checkBackend(CheckedFrom c,at::ArrayRef tensors,at::Backend backend)', '    checkContiguous(CheckedFrom c,const TensorGeometryArg & t)', '    checkDefined(CheckedFrom c,const TensorArg & t)', '    checkDeviceType(CheckedFrom c,at::ArrayRef tensors,at::DeviceType device_type)', '    checkDim(CheckedFrom,const TensorGeometryArg & t,int64_t dim)', '    checkDimRange(CheckedFrom c,const TensorGeometryArg & t,int64_t dim_start,int64_t dim_end)', '    checkLayout(CheckedFrom c,const Tensor & t,Layout layout)', '    checkLayout(CheckedFrom c,at::ArrayRef tensors,at::Layout layout)', '    checkNumel(CheckedFrom c,const TensorGeometryArg & t,int64_t numel)', '    checkSameDim(CheckedFrom c,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameGPU(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameNumel(CheckedFrom,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameSize(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameType(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkScalarType(CheckedFrom,const TensorArg & t,ScalarType s)', '    checkScalarTypes(CheckedFrom c,const TensorArg & t,at::ArrayRef l)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,IntArrayRef sizes)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,int64_t dim,int64_t size)', '    computeStorageSize(IntArrayRef sizes,IntArrayRef strides)', '    defaultStrides(IntArrayRef sizes)', '    geometry_is_contiguous(IntArrayRef sizes,IntArrayRef strides)', '    maybe_data_ptr(const Tensor & tensor)', '    maybe_data_ptr(const TensorArg & tensor)', '    operator<<(std::ostream & out,TensorGeometryArg t)', '    operator*', '    operator->', '    TensorArg(Tensor tensor,const char *name,int pos)', '    operator*', '    operator->', '    TensorGeometryArg(TensorArg arg)', '    TensorGeometryArg(TensorGeometry tensor,const char *name,int pos)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_alias_analysis.cpp', [], ['    elem', '    testAliasRegistration', '    testContainerAliasing', '    testMemoryDAG', '    testWildcards', '    testWriteTracking', '    aliasAnalysisFromSchema', '    expectThrows(Functor,const char *expectMessageContains)', '    insertIf(Graph & g,Value *condValue,std::function trueInst,std::function falseInst)', '    testAliasAnalysis', '    testTopologicalMove', '    ValueSet', '    checkPostCondition(const std::string & toInsert,const std::string & insertPoint,bool after)', '    createGraph', '    createNode(const std::string & name,const std::vector & inputNames,const std::vector & blockInputNames)', '    moveAfterTopologicallyValid(const std::string & toInsert,const std::string & insertPoint)', '    moveBeforeTopologicallyValid(const std::string & toInsert,const std::string & insertPoint)', '    moveWithChecks(const std::string & toInsert,const std::string & insertPoint,std::function func)', '    TopoMoveTestFixture']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_argument_spec.cpp', [], ['    device(const autograd::Variable & v)', '    hashCode(const TensorTypePtr & ptr)', '    isEqual(at::IntArrayRef lhs,at::IntArrayRef rhs)', '    isEqual(const CompleteArgumentInfo & ti,const autograd::Variable & v)', '    isEqual(const ArgumentInfo & ti,const autograd::Variable & v)', '    testArgumentSpec', '    testCompleteArgumentSpec', '    testProfiledTensorTypeHashing', '    undef', '    var(at::TensorOptions t,at::IntArrayRef sizes,bool requires_grad)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\test_assert.h', [], ['    barf(const char *fmt,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_aten.cpp', [], ['    testATen_cast_Float', '    testATen_sigmoid_backward', '    testATen_tanh_backward', '    testATenaddcmulFloat', '    testATenaddcmulInt', '    testATenaddFloat', '    testATenaddInt', '    testATencosFloat', '    testATendivFloat', '    testATendivInt', '    testATeneqInt', '    testATenerfFloat', '    testATenexpFloat', '    testATenlerp', '    testATenlog10Float', '    testATenlog2Float', '    testATenlogFloat', '    testATenmaxFloat', '    testATenmaxInt', '    testATenminFloat', '    testATenminInt', '    testATenmulFloat', '    testATenmulInt', '    testATennegFloat', '    testATennegInt', '    testATenreciprocal', '    testATenreluFloat', '    testATenreluInt', '    testATensubFloat', '    testATensubInt', '    testATengeInt', '    testATengtInt', '    testATenleInt', '    testATenltInt']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_autodiff.cpp', [], ['    graph', '    testDifferentiate', '    testDifferentiateWithRequiresGrad', '    grad(const variable_list & outputs,const variable_list & inputs,const variable_list & grad_outputs)', '    get_grad_outputs(const variable_list & vars)', '    testADFormulas', '    ADTestSpec(const char *name,var_meta_list input_meta,test_fn_type test_fn,float clampMax)', '    make_vars', '    operator()(const variable_list & inputs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_base.cpp', [], ['    aliasAnalysisFromSchema']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_base.h', [], ['    assertAllEqual(const std::vector & vec,const T & val)', '    ExpectAllNear(const std::vector & v1,const std::vector & v2,V threshold,const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_base.h', [], ['    isSandcastle']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_class_import.cpp', [], ['    import_libs(std::shared_ptr cu,const std::string & class_name,const std::shared_ptr & src,const std::vector & tensor_table)', '    testClassDerive', '    testClassImport', '    testSaveLoadTorchbind', '    testScriptObject']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_class_parser.cpp', [], ['    testClassParser']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_class_type.cpp', [], ['    testClassTypeAddRemoveAttr', '    testClassTypeAddRemoveConstant']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_code_template.cpp', [], ['    testCodeTemplate']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_constant_pooling.cpp', [], ['    testConstantPooling']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_create_autodiff_subgraphs.cpp', [], ['    testCreateAutodiffSubgraphs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_cuda.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_custom_class.cpp', [], ['    testPickle', '    register_take_instance', '    take_an_instance(const c10::intrusive_ptr & instance)', '    test_with_obj', '    testTorchbindIValueAPI', '    add(int64_t z)', '    combine(c10::intrusive_ptr b)', '    Foo', '    Foo(int x_,int y_)', '    increment(int64_t z)', '    info', '    ~Foo', '    clone', '    merge(const c10::intrusive_ptr & c)', '    MyStackClass(std::vector init)', '    pop', '    push(T)', '    return_a_tuple', '    PickleTester(std::vector vals)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_custom_operators.cpp', [], ['    testIValueKWargs', '    testCustomOperatorAliasing', '    testCustomOperators']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\custom_operator\\test_custom_ops.cpp', [], ['    get_autograd_operator_from_registry_and_execute', '    get_autograd_operator_from_registry_and_execute_in_nograd_mode', '    get_operator_from_registry_and_execute', '    check_all_parameters(const torch::jit::Module & module,Predicate predicate)', '    get_operator_from_registry_and_execute(const char *op_name,Args,...)', '    load_serialized_module_with_custom_op_and_execute(const std::string & path_to_exported_script_module)', '    main(int argc,const char *[] argv)', '    test_argument_checking_for_serialized_modules(const std::string & path_to_exported_script_module)', '    test_move_to_device(const std::string & path_to_exported_script_module)', '    test_move_to_dtype(const std::string & path_to_exported_script_module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_dce.cpp', [], ['    testDCE']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\dist_autograd\\test_dist_autograd.cpp', ['    DistAutogradTest'], ['    tensors', '    TEST_F(DistAutogradTest,TestSendFunctionInvalidInputs)', '    TEST_F(DistAutogradTest,TestInitializedContextCleanup)', '    TEST_F(DistAutogradTest,TestInitializedContextCleanupSendFunction)', '    SetUpTestCase', '  Static Member Variables', '    autogradContainer_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_expr.cpp', [], ['    test_01(const ExprHandle & expr)', '    testCond01', '    testExprBinaryMath01', '    testExprBitwiseOps', '    testExprDynamicShapeAdd', '    testExprMath01', '    testExprSubstitute01', '    testExprUnaryMath01', '    testIfThenElse01', '    testIfThenElse02', '    testStmtClone', '    testExprBasicValueTest', '    testExprBasicValueTest02', '    testExprByteTest', '    testExprCharTest', '    testExprCompareSelectEQ', '    testExprDoubleTest', '    testExprFloatTest', '    testExprHalfTest', '    testExprIntTest', '    testExprLetStmtTest01', '    testExprLetTest01', '    testExprLetTest02', '    testExprLongTest', '    testExprShortTest', '    testExprVectorAdd01']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_fuser.cpp', [], ['    graph_strings', '    i', '    testSimple', '    testFusion', '    testRegisterFusionCachesKernel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_graph_executor.cpp', [], ['    testGraphExecutor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\boxing\\test_helpers.h', [], ['    extractDispatchKey(const at::Tensor & t)', '    callOp(const c10::OperatorHandle & op,Args,...)', '    callOpUnboxed(const c10::OperatorHandle & op,Args,...)', '    callOpUnboxedWithDispatchKey(const c10::OperatorHandle & op,c10::DispatchKey dispatchKey,Args,...)', '    dummyTensor(c10::DispatchKeySet ks)', '    dummyTensor(c10::DispatchKey dispatch_key)', '    expectDoesntFindKernel(const char *op_name,c10::DispatchKey dispatch_key)', '    expectDoesntFindOperator(const char *op_name)', '    expectListEquals(c10::ArrayRef expected,c10::List actual)', '    expectListEquals(c10::ArrayRef expected,std::vector actual)', '    expectThrows(Functor,const char *expectMessageContains)', '    makeStack(Inputs,...)', '    make_tensor', '    DispatchKeySet', '    make_intrusive', '    singleton', '    HasSubstr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_inliner.cpp', [], ['    testInliner', '    InlinerGuard(bool shouldInline)', '    ~InlinerGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_interface.cpp', [], ['    import_libs(std::shared_ptr cu,const std::string & class_name,const std::shared_ptr & src,const std::vector & tensor_table)', '    testModuleInterfaceSerialization']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_interpreter.cpp', [], ['    testInterp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_ir.cpp', [], ['    testAttributes', '    testBlocks', '    testCommonAncestor', '    value_names']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_ir_printer.cpp', [], ['    testIRPrinterBasicValueTest', '    testIRPrinterBasicValueTest02', '    testIRPrinterCastTest', '    testIRPrinterLetTest01', '    testIRPrinterLetTest02']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_irparser.cpp', [], ['    checkRoundtrip(const std::string & s)', '    testIRParser']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_jit_type.cpp', [], ['    testUnifyTypes']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_lite_interpreter.cpp', ['    TorchBindLiteInterpreterTestStruct'], ['    reg', '    testLiteInterpreterAdd', '    testLiteInterpreterBuiltinFunction', '    testLiteInterpreterConv', '    testLiteInterpreterInline', '    testLiteInterpreterLoadOrigJit', '    testLiteInterpreterParams', '    testLiteInterpreterPrim', '    testLiteInterpreterPrimOverload', '    testLiteInterpreterSetState', '    testLiteInterpreterTuple', '    testLiteInterpreterUpsampleNearest2d', '    testLiteInterpreterWrongMethodName', '    train_inputs', '    train_inputs', '    vector', '    get(at::Tensor t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_llvm.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_loopnest.cpp', [], ['    remove_space(const std::string & str)', '    b', '    c', '    c', '    c', '    d', '    tensor', '    tensor', '    tensor', '    testScheduleDynamicShape2D', '    e', '    f', '    g', '    InlineFunc01Helper(const std::vector & inline_order)', '    testExprLower01', '    testExprSimple01', '    testExprSimple02', '    testExprSplitWithMask01', '    testExprSplitWithTailNone', '    testScheduleBroadcastAddBuffer', '    testScheduleFunctionCall01', '    testScheduleFuserStyle', '    testScheduleFuserThreeArg', '    testScheduleInlineFunc01', '    x', '    y', '    z', '    z2']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_misc.cpp', ['    TestThreadLocalDebugInfo'], ['    checkShape(Node *n,std::vector expected,bool prev)', '    checkDebugInfo', '    checkTracedInputs(const TracedTestInputs & inputs)', '    eltwise', '    expected', '    expectedAfter', '    expectedBefore', '    fakePass(std::shared_ptr & g)', '    invokeTestRecordFunction(at::Tensor & t)', '    invokeTestRecordFunctionJIT(at::Tensor & t)', '    is', '    is', '    is', '    mm_expected', '    run', '    run_test_function', '    testAutogradProfiler', '    testAutogradSymbols', '    testCallStack', '    testCallStackCaching', '    testInsertAndEliminateRedundantGuards', '    testInsertBailOuts', '    testModuleConversion', '    testModuleDefine', '    testNoneSchemaMatch', '    testPassManagement', '    testProfiler', '    testRecordFunction', '    testThreadLocalDebugInfo', '    testTopologicalIndex', '    aliasAnalysisFromSchema', '    operator<<(std::ostream & out,const std::vector & list)', '    testATenNativeBatchNorm', '    testControlFlow', '    testCustomFusion', '    testCustomFusionNestedBlocks', '    testEvalModeForLoadedModule', '    testFromQualString', '    testInternedStrings', '    testProto', '    testSchemaParser', '    testSerializationInterop', '    testTHNNConv', '    testTorchSaveError', '    getModelId', '    setModelId(int model_id)', '    ~TestThreadLocalDebugInfo']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_mobile_type_parser.cpp', [], ['    testMobileTypeParser']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_module_api.cpp', [], ['    testModuleClone', '    testModuleCloneInstance', '    testModuleConstant', '    testModuleParameter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\test_parallel.cpp', [], ['    TEST(TestParallel,TestParallel)', '    TEST(TestParallel,NestedParallel)', '    TEST(TestParallel,Exceptions)', '    TEST(TestParallel,IntraOpLaunchFuture)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_peephole_optimize.cpp', [], ['    testPeepholeOptimize']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_qualified_name.cpp', [], ['    testQualifiedName']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_save_load.cpp', [], ['    testSaveExtraFilesHook', '    testTypeTags']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_schema_matching.cpp', [], ['    testSchemaMatching']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_simplify.cpp', [], ['    testSimplifyAdd', '    testSimplifyAdds', '    testSimplifyCasts', '    testSimplifyDeeperDifference', '    testSimplifyDeeperTerms', '    testSimplifyEliminatesNoOps', '    testSimplifyEliminatesVar', '    testSimplifyFactorization', '    testSimplifyFactorizeUneven', '    testSimplifyFoldComplexDifference', '    testSimplifyIfComponents', '    testSimplifyManyOps', '    testSimplifyMuls', '    testSimplifyMultiLayer', '    testSimplifyMultiOp', '    testSimplifyMultiTerm', '    testSimplifyMultiVar', '    testSimplifyOpaqueTerms', '    testSimplifyReorderings', '    testSimplifySub', '    testSimplifySubs', '    testSimplifyWontReorderFloat', '    testConstantFoldBitwise', '    testConstantFoldIntrinsics', '    testConstantFoldMinMax', '    testConstantFoldMultiOp', '    testConstantFoldShifts', '    testConstantFoldSimple', '    testConstantFoldTwoLayer', '    testConstantFoldWithVar', '    testHashDifferenceTypes', '    testHashEquivalence', '    testHashEquivalenceAfterFolding', '    testHashLargeExpression', '    testHashSimple', '    testUnFoldableExpr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_subgraph_matcher.cpp', [], ['    testBadPattern', '    testDiamond1', '    testDiamond2', '    testLinear1', '    testLinear2', '    testMatchesAttributes', '    testMatchInBasicBlocks1', '    testMatchInBasicBlocks2', '    testMultipleMatches', '    testOverlappingMatches', '    testSubgraphMatching', '    testTrivial1', '    testTrivial2', '    testTrivial3', '    testTrivial4', '    testXPattern']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_subgraph_rewriter.cpp', [], ['    testFilterMatch', '    testFilterNoMatch', '    testSubgraphRewriter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_subgraph_utils.cpp', [], ['    testSubgraphUtils']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_type.cpp', [], ['    testTypePropagation', '    testTypeTest01']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\test_util.cc', [], ['    BBPrinter(nom::repr::NNCFGraph::NodeRef node)', '    cfgEdgePrinter(nom::repr::NNCFGraph::EdgeRef edge)', '    createGraph', '    createGraphWithCycle', '    createTestNode(nom::Graph & g)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    TestNodePrinter(nom::Graph::NodeRef)', '    to_string(T value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\test_util.h', ['    TestClass', '    TestRandom'], ['    BBPrinter(nom::repr::NNCFGraph::NodeRef node)', '    cfgEdgePrinter(nom::repr::NNCFGraph::EdgeRef edge)', '    createGraph', '    createGraphWithCycle', '    createTestNode(nom::Graph & g)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    TestNodePrinter(nom::Graph::NodeRef)', '    equal(const nom::repr::NNGraph::NodeRef & a,const nom::repr::NNGraph::NodeRef & b)', '    TestClass', '    ~TestClass', '    nextInt', '    TestRandom(unsigned int seed)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\test_utils.cc', [], ['    assertTensorEqualsWithType(const caffe2::TensorCPU & tensor1,const caffe2::TensorCPU & tensor2,float)', '    assertTensorEqualsWithType(const caffe2::TensorCPU & tensor1,const caffe2::TensorCPU & tensor2,float eps)', '    assertNear(float value1,float value2,float epsilon)', '    assertTensorEquals(const TensorCPU & tensor1,const TensorCPU & tensor2,float eps)', '    assertTensorListEquals(const std::vector & tensorNames,const Workspace & workspace1,const Workspace & workspace2)', '    createOperator(const std::string & type,const std::vector & inputs,const std::vector & outputs,caffe2::NetDef *net)', '    createTensor(const std::string & name,caffe2::Workspace *workspace)', '    getTensor(const caffe2::Workspace & workspace,const std::string & name)', '    externalInputs(const std::vector & externalInputs)', '    externalOutputs(const std::vector & externalOutputs)', '    newOp(const std::string & type,const std::vector & inputs,const std::vector & outputs)', '    setDeviceOptionName(const std::string & name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_utils.cpp', [], ['    unpackReturnTuple(Stack & stack)', '    f_code', '    f_interpreter', '    almostEqual(const at::Tensor & a,const at::Tensor & b)', '    assertAllClose(const tensor_list & a,const tensor_list & b)', '    build_lstm', '    checkRtol(const at::Tensor & diff,const std::vector inputs)', '    createStack(std::vector)', '    exactlyEqual(const at::Tensor & a,const at::Tensor & b)', '    lstm(at::Tensor input,at::Tensor hx,at::Tensor cx,at::Tensor w_ih,at::Tensor w_hh)', '    run(InterpreterState & interp,const std::vector & inputs)', '    runGradient(Gradient & grad_spec,tensor_list & tensors_in,tensor_list & tensor_grads_in)', '    t_def(at::Tensor x)', '    t_use(at::Tensor x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\test_utils.h', [], ['    almostEqual(const at::Tensor & a,const at::Tensor & b)', '    assertAllClose(const tensor_list & a,const tensor_list & b)', '    build_lstm', '    checkRtol(const at::Tensor & diff,const std::vector inputs)', '    createStack(std::vector)', '    exactlyEqual(const at::Tensor & a,const at::Tensor & b)', '    lstm(at::Tensor input,at::Tensor hx,at::Tensor cx,at::Tensor w_ih,at::Tensor w_hh)', '    run(InterpreterState & interp,const std::vector & inputs)', '    runGradient(Gradient & grad_spec,tensor_list & tensors_in,tensor_list & tensor_grads_in)', '    t_def(at::Tensor x)', '    t_use(at::Tensor x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\test_utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\test_utils.h', ['    NetMutator', '    WorkspaceMutator'], ['    assertNear(float value1,float value2,float epsilon)', '    assertTensor(const TensorCPU & tensor,const std::vector & sizes,const std::vector & data,float epsilon)', '    assertTensorEquals(const TensorCPU & tensor1,const TensorCPU & tensor2,float eps)', '    assertTensorEquals(const TensorCPU & tensor,const std::vector & data,float epsilon)', '    assertTensorListEquals(const std::vector & tensorNames,const Workspace & workspace1,const Workspace & workspace2)', '    constantFillTensor(const vector & shape,const T & data,TensorCPU *tensor)', '    createOperator(const std::string & type,const std::vector & inputs,const std::vector & outputs,caffe2::NetDef *net)', '    createTensor(const std::string & name,caffe2::Workspace *workspace)', '    createTensorAndConstantFill(const std::string & name,const std::vector & shape,const T & data,Workspace *workspace)', '    createTensorAndFill(const std::string & name,const std::vector & shape,const std::vector & data,Workspace *workspace)', '    createTensorAndFill(const std::vector & shape,const std::vector & data)', '    fillTensor(const std::vector & shape,const std::vector & data,TensorCPU *tensor)', '    getTensor(const caffe2::Workspace & workspace,const std::string & name)', '    randomFill(RealType *data,size_t size,const double min,const double max)', '    addArgument(const std::string & name,const T & value)', '    externalInputs(const std::vector & externalInputs)', '    externalOutputs(const std::vector & externalOutputs)', '    NetMutator(caffe2::NetDef *net)', '    newOp(const std::string & type,const std::vector & inputs,const std::vector & outputs)', '    setDeviceOptionName(const std::string & name)', '    newTensor(const std::string & name,const std::vector & shape,const std::vector & data)', '    newTensorConst(const std::string & name,const std::vector & shape,const T & data)', '    WorkspaceMutator(caffe2::Workspace *workspace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\rpc\\test_wire_serialization.cpp', [], ['    TEST(WireSerialize,Base)', '    TEST(WireSerialize,RecopySparseTensors)', '    TEST(WireSerialize,CloneSparseTensors)', '    TEST(WireSerialize,DISABLED_Sparse)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\testing\\testing.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\tests.h', [], ['    testADFormulas', '    testAliasAnalysis', '    testAliasRegistration', '    testArgumentSpec', '    testATenNativeBatchNorm', '    testAttributes', '    testAutogradSymbols', '    testBlocks', '    testCallStack', '    testCallStackCaching', '    testClassDerive', '    testClassImport', '    testClassParser', '    testClassTypeAddRemoveAttr', '    testCodeTemplate', '    testCommonAncestor', '    testCompleteArgumentSpec', '    testConstantPooling', '    testContainerAliasing', '    testControlFlow', '    testCreateAutodiffSubgraphs', '    testCustomFusion', '    testCustomFusionNestedBlocks', '    testCustomOperatorAliasing', '    testCustomOperators', '    testDCE', '    testDifferentiate', '    testDifferentiateWithRequiresGrad', '    testEvalModeForLoadedModule', '    testFromQualString', '    testFusion', '    testGraphExecutor', '    testInliner', '    testInsertAndEliminateRedundantGuards', '    testInsertBailOuts', '    testInternedStrings', '    testInterp', '    testIRParser', '    testIValueKWargs', '    testLiteInterpreterAdd', '    testLiteInterpreterBuiltinFunction', '    testLiteInterpreterConv', '    testLiteInterpreterInline', '    testLiteInterpreterLoadOrigJit', '    testLiteInterpreterParams', '    testLiteInterpreterPrim', '    testLiteInterpreterSetState', '    testLiteInterpreterTuple', '    testLiteInterpreterUpsampleNearest2d', '    testLiteInterpreterWrongMethodName', '    testMemoryDAG', '    testMobileTypeParser', '    testModuleClone', '    testModuleCloneInstance', '    testModuleConstant', '    testModuleConversion', '    testModuleDefine', '    testModuleInterfaceSerialization', '    testModuleParameter', '    testNoneSchemaMatch', '    testPassManagement', '    testPeepholeOptimize', '    testProfiledTensorTypeHashing', '    testProfiler', '    testProto', '    testQualifiedName', '    testRecordFunction', '    testRegisterFusionCachesKernel', '    testSaveExtraFilesHook', '    testSaveLoadTorchbind', '    testSchemaMatching', '    testSchemaParser', '    testScriptObject', '    testSerializationInterop', '    testSubgraphMatching', '    testSubgraphRewriter', '    testSubgraphUtils', '    testTHNNConv', '    testThreadLocalDebugInfo', '    testTopologicalIndex', '    testTopologicalMove', '    testTorchbindIValueAPI', '    testTorchSaveError', '    testTypeTags', '    testUnifyTypes', '    testWildcards', '    testWriteTracking']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\tensorexpr\\tests.h', [], ['    testATen_cast_Float', '    testATen_sigmoid_backward', '    testATen_tanh_backward', '    testATenaddcmulFloat', '    testATenaddcmulInt', '    testATenaddFloat', '    testATenaddInt', '    testATencosFloat', '    testATendivFloat', '    testATendivInt', '    testATeneqInt', '    testATenerfFloat', '    testATenexpFloat', '    testATengeInt', '    testATengtInt', '    testATenleInt', '    testATenlerp', '    testATenlog10Float', '    testATenlog2Float', '    testATenlogFloat', '    testATenltInt', '    testATenmaxFloat', '    testATenmaxInt', '    testATenminFloat', '    testATenminInt', '    testATenmulFloat', '    testATenmulInt', '    testATennegFloat', '    testATennegInt', '    testATenreciprocal', '    testATenreluFloat', '    testATenreluInt', '    testATensubFloat', '    testATensubInt', '    testCond01', '    testConstantFoldBitwise', '    testConstantFoldIntrinsics', '    testConstantFoldMinMax', '    testConstantFoldMultiOp', '    testConstantFoldShifts', '    testConstantFoldSimple', '    testConstantFoldTwoLayer', '    testConstantFoldWithVar', '    testExprBasicValueTest', '    testExprBasicValueTest02', '    testExprBinaryMath01', '    testExprBitwiseOps', '    testExprByteTest', '    testExprCharTest', '    testExprCompareSelectEQ', '    testExprDoubleTest', '    testExprDynamicShapeAdd', '    testExprFloatTest', '    testExprHalfTest', '    testExprIntTest', '    testExprLetStmtTest01', '    testExprLetTest01', '    testExprLetTest02', '    testExprLongTest', '    testExprLower01', '    testExprMath01', '    testExprShortTest', '    testExprSimple01', '    testExprSimple02', '    testExprSplitWithMask01', '    testExprSplitWithTailNone', '    testExprSubstitute01', '    testExprUnaryMath01', '    testExprVectorAdd01', '    testHashDifferenceTypes', '    testHashEquivalence', '    testHashEquivalenceAfterFolding', '    testHashLargeExpression', '    testHashSimple', '    testIfThenElse01', '    testIfThenElse02', '    testIRPrinterBasicValueTest', '    testIRPrinterBasicValueTest02', '    testIRPrinterCastTest', '    testIRPrinterLetTest01', '    testIRPrinterLetTest02', '    testScheduleBroadcastAddBuffer', '    testScheduleDynamicShape2D', '    testScheduleFunctionCall01', '    testScheduleFuserStyle', '    testScheduleFuserThreeArg', '    testScheduleInlineFunc01', '    testSimplifyAdd', '    testSimplifyAdds', '    testSimplifyCasts', '    testSimplifyDeeperDifference', '    testSimplifyDeeperTerms', '    testSimplifyEliminatesNoOps', '    testSimplifyEliminatesVar', '    testSimplifyFactorization', '    testSimplifyFactorizeUneven', '    testSimplifyFoldComplexDifference', '    testSimplifyIfComponents', '    testSimplifyManyOps', '    testSimplifyMuls', '    testSimplifyMultiLayer', '    testSimplifyMultiOp', '    testSimplifyMultiTerm', '    testSimplifyMultiVar', '    testSimplifyOpaqueTerms', '    testSimplifySub', '    testSimplifySubs', '    testSimplifyWontReorderFloat', '    testStmtClone', '    testTypePropagation', '    testTypeTest01', '    testUnFoldableExpr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\test\\TestUtils.hpp', ['    Semaphore'], ['    isTSANEnabled', '    tmppath', '    Fork', '    isChild', '    ~Fork', '    post(int n)', '    wait(int n)', '    TemporaryFile', '    ~TemporaryFile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\text_file_reader.cc', ['    CreateTextFileReaderOp', '    TextFileReaderReadOp'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTextFileReader', '    CAFFE_ANONYMOUS_VARIABLE_CPUTextFileReaderRead', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTextFileReader', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TextFileReaderRead', '    convert(TensorProto_DataType dst_type,const char *src_start,const char *src_end,void *dst)', '    noexcept', '    CreateTextFileReaderOp(Args,...)', '    RunOnDevice', '    rowsRead', '    TextFileReaderInstance(const std::vector & delims,char escape,const std::string & filename,int numPasses,const std::vector & types)', '    RunOnDevice', '    TextFileReaderReadOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\text_file_reader_utils.cc', [], ['    FileReader(const std::string & path,size_t bufferSize)', '    operator()(CharRange & range)', '    reset', '    ~FileReader', '    next(char *start,char *end,TokenizedString & tokenized)', '    reset', '    Tokenizer(const std::vector & delims,char escape)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\text_file_reader_utils.h', ['    BufferedTokenizer', '    FileReader', '    TokenizedString', '    Tokenizer'], ['    BufferedTokenizer(const Tokenizer & t,StringProvider *p,int numPasses)', '    endDelim', '    next(Token & token)', '    pass_', '    FileReader(const std::string & path,size_t bufferSize)', '    operator()(CharRange & range)', '    reset', '    ~FileReader', '    operator()(CharRange &)', '    reset', '    ~StringProvider', '    lastDelim', '    tokens', '    next(char *start,char *end,TokenizedString & tokenized)', '    reset', '    Tokenizer(const std::vector & delims,char escape)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\text_file_reader_utils_test.cc', [], ['    TEST(TextFileReaderUtilsTest,TokenizeTest)', '    charIdx', '    ChunkProvider(const std::string & str)', '    operator()(CharRange & range)', '    reset']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\TH.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THAllocator.cpp', [], ['    deleteTHMapAllocator(void *ptr)', '    deleteTHRefcountedMapAllocator(void *ptr)', '    WaitForReleaseHandle(PVOID lpParam,BOOLEAN TimerOrWaitFired)', '    getTHDefaultAllocator', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    close', '    THMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THMapAllocator(const char *filename,int flags,size_t size)', '    close', '    data', '    initializeAlloc', '    THRefcountedMapAllocator(const char *filename,int flags,size_t size)', '    THRefcountedMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THRefcountedMapAllocatorArgCheck(int flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THAllocator.h', ['    THMapAllocator', '    THRefcountedMapAllocator'], ['    getTHDefaultAllocator', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    close', '    data', '    fd', '    filename', '    operator=', '    operator=', '    size', '    THMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THMapAllocator(const char *filename,int flags,size_t size)', '    THMapAllocator', '    THMapAllocator', '    ~THMapAllocator', '    checkFlags', '    close', '    data', '    decref', '    incref', '    initializeAlloc', '    THRefcountedMapAllocator(const char *filename,int flags,size_t size)', '    THRefcountedMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    ~THRefcountedMapAllocator', '    THRefcountedMapAllocatorArgCheck(int flags)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THBlas.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THBlas.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THBlas.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THBlas.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THBlasUtils.h', [], ['    THBlas_axpy(int64_t n,T a,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_axpy(int64_t n,uint8_t a,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int8_t a,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int16_t a,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int a,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_axpy(int64_t n,int64_t a,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,float a,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_axpy(int64_t n,double a,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_copy(int64_t n,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_copy(int64_t n,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_copy(int64_t n,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_copy(int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_copy(int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_dot(int64_t n,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_dot(int64_t n,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_dot(int64_t n,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_dot(int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_dot(int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,T alpha,T *a,int64_t lda,T *b,int64_t ldb,T beta,T *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,uint8_t alpha,uint8_t *a,int64_t lda,uint8_t *b,int64_t ldb,uint8_t beta,uint8_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int8_t alpha,int8_t *a,int64_t lda,int8_t *b,int64_t ldb,int8_t beta,int8_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int16_t alpha,int16_t *a,int64_t lda,int16_t *b,int64_t ldb,int16_t beta,int16_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int alpha,int *a,int64_t lda,int *b,int64_t ldb,int beta,int *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int64_t alpha,int64_t *a,int64_t lda,int64_t *b,int64_t ldb,int64_t beta,int64_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,float *a,int64_t lda,float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,double *a,int64_t lda,double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    THBlas_gemv(char transa,int64_t m,int64_t n,T alpha,T *a,int64_t lda,T *x,int64_t incx,T beta,T *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,uint8_t alpha,uint8_t *a,int64_t lda,uint8_t *x,int64_t incx,uint8_t beta,uint8_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int8_t alpha,int8_t *a,int64_t lda,int8_t *x,int64_t incx,int8_t beta,int8_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int16_t alpha,int16_t *a,int64_t lda,int16_t *x,int64_t incx,int16_t beta,int16_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int alpha,int *a,int64_t lda,int *x,int64_t incx,int beta,int *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int64_t alpha,int64_t *a,int64_t lda,int64_t *x,int64_t incx,int64_t beta,int64_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,float alpha,float *a,int64_t lda,float *x,int64_t incx,float beta,float *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,double alpha,double *a,int64_t lda,double *x,int64_t incx,double beta,double *y,int64_t incy)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THC.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCAllocator.cpp', [], ['    deleteTHCIpcDeleter(void *ptr)', '    makeDataPtr(std::shared_ptr basePtr,void *data)', '    THCIpcDeleter(std::shared_ptr basePtr)', '    ~THCIpcDeleter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCAllocator.h', ['    THCIpcDeleter'], ['    makeDataPtr(std::shared_ptr basePtr,void *data)', '    THCIpcDeleter(std::shared_ptr basePtr)', '    ~THCIpcDeleter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCBlas.h', [], ['    THCudaBlas_Ddot(THCState *state,int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THCudaBlas_Dgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,double *a,int64_t lda,double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    THCudaBlas_DgemmBatched(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *[] a,int64_t lda,const double *[] b,int64_t ldb,double beta,double *[] c,int64_t ldc,int64_t batchCount)', '    THCudaBlas_Dgemv(THCState *state,char trans,int64_t m,int64_t n,double alpha,double *a,int64_t lda,double *x,int64_t incx,double beta,double *y,int64_t incy)', '    THCudaBlas_Dger(THCState *state,int64_t m,int64_t n,double alpha,double *x,int64_t incx,double *y,int64_t incy,double *a,int64_t lda)', '    THCudaBlas_Hdot(THCState *state,int64_t n,at::Half *x,int64_t incx,at::Half *y,int64_t incy)', '    THCudaBlas_Hgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,at::Half *a,int64_t lda,at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    THCudaBlas_Sdot(THCState *state,int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THCudaBlas_Sgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,float *a,int64_t lda,float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    THCudaBlas_SgemmBatched(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *[] a,int64_t lda,const float *[] b,int64_t ldb,float beta,float *[] c,int64_t ldc,int64_t batchCount)', '    THCudaBlas_Sgemv(THCState *state,char trans,int64_t m,int64_t n,float alpha,float *a,int64_t lda,float *x,int64_t incx,float beta,float *y,int64_t incy)', '    THCudaBlas_Sger(THCState *state,int64_t m,int64_t n,float alpha,float *x,int64_t incx,float *y,int64_t incy,float *a,int64_t lda)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCCachingHostAllocator.cpp', [], ['    BlockComparator(const BlockSize & a,const BlockSize & b)', '    THCCachingHostDeleter(void *ptr)', '    getTHCCachingHostAllocator', '    THCCachingHostAllocator_emptyCache', '    THCCachingHostAllocator_recordEvent(void *ptr,at::cuda::CUDAStream stream)', '    Block(size_t size,void *ptr,bool allocated)', '    BlockSize(size_t size,void *ptr)', '    allocate(size_t size)', '    raw_deleter', '    emptyCache', '    free(void *ptr)', '    HostAllocator', '    insertEvents(Block & block)', '    malloc(void **ptr,size_t size)', '    processEvents', '    recordEvent(void *ptr,at::cuda::CUDAStream stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCCachingHostAllocator.h', [], ['    getTHCCachingHostAllocator', '    THCCachingHostAllocator_emptyCache', '    THCCachingHostAllocator_recordEvent(void *ptr,at::cuda::CUDAStream stream)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGeneral.cpp', [], ['    __THCublasCheck(cublasStatus_t status,const char *file,const int line)', '    __THCudaCheck(cudaError_t err,const char *file,const int line)', '    __THCudaCheckWarn(cudaError_t err,const char *file,const int line)', '    __THCusparseCheck(cusparseStatus_t status,const char *file,const int line)', '    THCState_alloc', '    THCState_free(THCState *state)', '    THCState_getCudaHostAllocator(THCState *state)', '    THCState_getCurrentDeviceScratchSpaceSize(THCState *state)', '    THCState_getDeviceResourcePtr(THCState *state,int device)', '    THCState_getPeerToPeerAccess(THCState *state,int dev,int devToAccess)', '    THCudaFree(THCState *state,void *ptr)', '    THCudaHostAlloc(THCState *state,size_t size)', '    THCudaHostRecord(THCState *state,void *ptr)', '    THCudaInit(THCState *state)', '    THCudaMalloc(THCState *state,size_t size)', '    THCudaMemGetInfo(THCState *state,size_t *freeBytes,size_t *totalBytes,size_t *largestBlock)', '    THCudaShutdown(THCState *state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGeneral.hpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateAllTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateBFloat16Type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateBoolType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateByteType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateCharType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateDoubleType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateFloatType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateFloatTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateHalfType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateIntType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateLongType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCGenerateShortType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\THCP.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCSleep.h', [], ['    THC_sleep(THCState *state,int64_t cycles)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCStorage.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStorage.cpp', [], ['    THCStorage_getDevice(THCState *state,const THCStorage *storage)', '    THCStorage_new(THCState *state,caffe2::TypeMeta data_type)', '    THCStorage_resize(THCState *state,THCStorage *self,ptrdiff_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCStorage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStorage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStorage.hpp', [], ['    THCStorage_getDevice(THCState *state,const THCStorage *storage)', '    THCStorage_new(THCState *state,caffe2::TypeMeta data_type)', '    THCStorage_newWithDataAndAllocator(THCState *state,at::ScalarType scalar_type,at::DataPtr,ptrdiff_t size,at::Allocator *allocator)', '    THCStorage_resize(THCState *state,THCStorage *self,ptrdiff_t size)', '    THCStorage_retain(THCState *state,THCStorage *storage)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStorageCopy.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCStorageCopy.cpp', [], ['    TH(THCState *state,THCStorage *self,struct THStorage *src)', '    TH(THCState *state,THCStorage *self,struct THByteStorage *src)', '    TH(THCState *state,THCStorage *self,struct THCharStorage *src)', '    TH(THCState *state,THCStorage *self,struct THShortStorage *src)', '    TH(THCState *state,THCStorage *self,struct THIntStorage *src)', '    TH(THCState *state,THCStorage *self,struct THLongStorage *src)', '    TH(THCState *state,THCStorage *self,struct THFloatStorage *src)', '    TH(THCState *state,THCStorage *self,struct THHalfStorage *src)', '    TH(THCState *state,THCStorage *self,struct THDoubleStorage *src)', '    TH(THCState *state,THCStorage *self,struct THBoolStorage *src)', '    TH(THCState *state,THCStorage *self,struct THBFloat16Storage *src)', '    TH(THCState *state,THStorage *self,struct THCStorage *src)', '    TH(THCState *state,THByteStorage *self,struct THCStorage *src)', '    TH(THCState *state,THCharStorage *self,struct THCStorage *src)', '    TH(THCState *state,THShortStorage *self,struct THCStorage *src)', '    TH(THCState *state,THIntStorage *self,struct THCStorage *src)', '    TH(THCState *state,THLongStorage *self,struct THCStorage *src)', '    TH(THCState *state,THFloatStorage *self,struct THCStorage *src)', '    TH(THCState *state,THHalfStorage *self,struct THCStorage *src)', '    TH(THCState *state,THDoubleStorage *self,struct THCStorage *src)', '    TH(THCState *state,THBoolStorage *self,struct THCStorage *src)', '    TH(THCState *state,THBFloat16Storage *self,struct THCStorage *src)', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStorageCopy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCStorageCopy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCStream.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensor.cpp', [], ['    compareSizeAndStride(const void *a,const void *b)', '    THCTensor_all32BitIndexable(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allContiguous(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allSameDevice(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_canUse32BitIndexMath(THCState *state,const at::TensorImpl *t,ptrdiff_t max_elem)', '    THCTensor_free(THCState *state,at::TensorImpl *self)', '    THCTensor_getDevice(THCState *state,const at::TensorImpl *tensor)', '    THCTensor_maybeOverlappingIndices(THCState *state,const at::TensorImpl *t)', '    THCTensor_nDimension(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyAll(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyNoScalars(THCState *state,const at::TensorImpl *self)', '    THCTensor_nElement(THCState *state,const at::TensorImpl *self)', '    THCTensor_new(THCState *state,caffe2::TypeMeta type_meta)', '    THCTensor_preserveReduceDimSemantics(THCState *state,at::TensorImpl *tensor,int in_dims,int64_t dimension,int keepdim)', '    THCTensor_resize(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THCTensor_resizeAs(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_resizeNd(THCState *state,at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THCTensor_retain(THCState *state,at::TensorImpl *self)', '    THCTensor_set(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_setStorage(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THCTensor_size(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_sizeLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_squeeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    THCTensor_stride(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_strideLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_unsqueeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensor.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensor.h', [], ['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim)', '    TH(THCState *state,at::TensorImpl *self,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim,int keepdim)', '    TH(THCState *state,const at::TensorImpl *self)', '    TH(THCState *state,const at::TensorImpl *self,int dim)', '    TH(THCState *state,at::TensorImpl *self,const char flag)', '    TH(THCState *state,at::TensorImpl *tensor,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_,int64_t size3_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_,int64_t size3_,int64_t size4_)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension_,int64_t firstIndex_,int64_t size_)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension_,int64_t sliceIndex_)', '    TH(THCState *state,const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(THCState *state,unsigned int nTensors,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensor.hpp', [], ['    THCTensor_all32BitIndexable(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allContiguous(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allSameDevice(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_canUse32BitIndexMath(THCState *state,const at::TensorImpl *t,ptrdiff_t max_elem)', '    THCTensor_free(THCState *state,at::TensorImpl *self)', '    THCTensor_getDevice(THCState *state,const at::TensorImpl *tensor)', '    THCTensor_maybeOverlappingIndices(THCState *state,const at::TensorImpl *t)', '    THCTensor_nDimension(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyAll(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyNoScalars(THCState *state,const at::TensorImpl *self)', '    THCTensor_nElement(THCState *state,const at::TensorImpl *self)', '    THCTensor_new(THCState *state,caffe2::TypeMeta type_meta)', '    THCTensor_preserveReduceDimSemantics(THCState *state,at::TensorImpl *tensor,int in_dims,int64_t dimension,int keepdim)', '    THCTensor_resize(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THCTensor_resizeAs(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_resizeNd(THCState *state,at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THCTensor_retain(THCState *state,at::TensorImpl *self)', '    THCTensor_set(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_setStorage(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THCTensor_size(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_sizeLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_squeeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    THCTensor_stride(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_strideLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_unsqueeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensor.hpp', [], ['    TH(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    TH(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensorCopy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorCopy.h', [], ['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensorCopy.hpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorIndex.h', [], ['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *res_,int dim,at::TensorImpl *indices,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *src,int dim,at::TensorImpl *index)', '    TH(THCState *state,at::TensorImpl *res_,at::TensorImpl *indices,at::TensorImpl *src,int accumulate)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMasked.h', [], ['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensorMath.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMath.h', [], ['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int64_t k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathBlas.h', [], ['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathMagma.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathPairwise.h', [], ['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathPointwise.h', [], ['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *res_,at::TensorImpl *indices,at::TensorImpl *src,int accumulate)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,scalar_t min_value,scalar_t max_value)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src1,scalar_t value,at::TensorImpl *src2)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathReduce.h', [], ['    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim,int keepdim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMathScan.h', [], ['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorMode.h', [], ['    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\THCTensorRandom.h', [], ['    THCRandom_getRNGState(at::Generator gen_,at::TensorImpl *rng_state)', '    THCRandom_setRNGState(at::Generator gen_,at::TensorImpl *rng_state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorRandom.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorScatterGather.h', [], ['    TH(THCState *state,at::TensorImpl *res_,int dim,at::TensorImpl *indices,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *src,int dim,at::TensorImpl *index)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorSort.h', [], ['    TH(THCState *state,at::TensorImpl *keys,at::TensorImpl *values,int dim,bool dir)', '    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THC\\generic\\THCTensorTopK.h', [], ['    TH(THCState *state,at::TensorImpl *topK,at::TensorImpl *indices,at::TensorImpl *input,int64_t k,int dim,int dir,int sorted)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THCUNN\\generic\\THCUNN.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\THCUNN\\THCUNN.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THDiskFile.cpp', [], ['    THDiskFile_close(THFile *self)', '    THDiskFile_free(THFile *self)', '    THDiskFile_isOpened(THFile *self)', '    THDiskFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THDiskFile_position(THFile *self)', '    THDiskFile_readByte(THFile *self,uint8_t *data,ssize_t n)', '    THDiskFile_readChar(THFile *self,int8_t *data,ssize_t n)', '    THDiskFile_readDouble(THFile *self,double *data,ssize_t n)', '    THDiskFile_readFloat(THFile *self,float *data,ssize_t n)', '    THDiskFile_readHalf(THFile *self,at::Half *data,ssize_t n)', '    THDiskFile_readInt(THFile *self,int32_t *data,ssize_t n)', '    THDiskFile_readLong(THFile *self,int64_t *data,ssize_t n)', '    THDiskFile_readShort(THFile *self,int16_t *data,ssize_t n)', '    THDiskFile_readString(THFile *self,const char *format,char **str_)', '    THDiskFile_reverseMemory(void *dst,const void *src,ssize_t blockSize,ssize_t numBlocks)', '    THDiskFile_seek(THFile *self,ssize_t position)', '    THDiskFile_seekEnd(THFile *self)', '    THDiskFile_synchronize(THFile *self)', '    THDiskFile_writeByte(THFile *self,uint8_t *data,ssize_t n)', '    THDiskFile_writeChar(THFile *self,int8_t *data,ssize_t n)', '    THDiskFile_writeDouble(THFile *self,double *data,ssize_t n)', '    THDiskFile_writeFloat(THFile *self,float *data,ssize_t n)', '    THDiskFile_writeHalf(THFile *self,at::Half *data,ssize_t n)', '    THDiskFile_writeInt(THFile *self,int32_t *data,ssize_t n)', '    THDiskFile_writeLong(THFile *self,int64_t *data,ssize_t n)', '    THDiskFile_writeShort(THFile *self,int16_t *data,ssize_t n)', '    THDiskFile_writeString(THFile *self,const char *str,ssize_t size)', '    THPipeFile_free(THFile *self)', '    THPipeFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THDiskFile_bigEndianEncoding(THFile *self)', '    THDiskFile_isBigEndianCPU', '    THDiskFile_isLittleEndianCPU', '    THDiskFile_littleEndianEncoding(THFile *self)', '    THDiskFile_longSize(THFile *self,int size)', '    THDiskFile_name(THFile *self)', '    THDiskFile_nativeEndianEncoding(THFile *self)', '    THDiskFile_new(const char *name,const char *mode,int isQuiet)', '    THDiskFile_noBuffer(THFile *self)', '    THPipeFile_new(const char *name,const char *mode,int isQuiet)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THDiskFile.h', [], ['    THDiskFile_bigEndianEncoding(THFile *self)', '    THDiskFile_isBigEndianCPU', '    THDiskFile_isLittleEndianCPU', '    THDiskFile_littleEndianEncoding(THFile *self)', '    THDiskFile_longSize(THFile *self,int size)', '    THDiskFile_name(THFile *self)', '    THDiskFile_nativeEndianEncoding(THFile *self)', '    THDiskFile_new(const char *name,const char *mode,int isQuiet)', '    THDiskFile_noBuffer(THFile *self)', '    THPipeFile_new(const char *name,const char *mode,int isQuiet)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THFile.cpp', [], ['    THFile_ascii(THFile *self)', '    THFile_autoSpacing(THFile *self)', '    THFile_binary(THFile *self)', '    THFile_clearError(THFile *self)', '    THFile_close(THFile *self)', '    THFile_free(THFile *self)', '    THFile_hasError(THFile *self)', '    THFile_isAutoSpacing(THFile *self)', '    THFile_isBinary(THFile *self)', '    THFile_isOpened(THFile *self)', '    THFile_isQuiet(THFile *self)', '    THFile_isReadable(THFile *self)', '    THFile_isWritable(THFile *self)', '    THFile_noAutoSpacing(THFile *self)', '    THFile_pedantic(THFile *self)', '    THFile_position(THFile *self)', '    THFile_quiet(THFile *self)', '    THFile_readByte(THFile *self,THByteStorage *storage)', '    THFile_readByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_readByteScalar(THFile *self)', '    THFile_readChar(THFile *self,THCharStorage *storage)', '    THFile_readCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_readCharScalar(THFile *self)', '    THFile_readDouble(THFile *self,THDoubleStorage *storage)', '    THFile_readDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_readDoubleScalar(THFile *self)', '    THFile_readFloat(THFile *self,THFloatStorage *storage)', '    THFile_readFloatRaw(THFile *self,float *data,size_t n)', '    THFile_readFloatScalar(THFile *self)', '    THFile_readHalf(THFile *self,THHalfStorage *storage)', '    THFile_readHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_readHalfScalar(THFile *self)', '    THFile_readInt(THFile *self,THIntStorage *storage)', '    THFile_readIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_readIntScalar(THFile *self)', '    THFile_readLong(THFile *self,THLongStorage *storage)', '    THFile_readLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_readLongScalar(THFile *self)', '    THFile_readShort(THFile *self,THShortStorage *storage)', '    THFile_readShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_readShortScalar(THFile *self)', '    THFile_readStringRaw(THFile *self,const char *format,char **str_)', '    THFile_seek(THFile *self,size_t position)', '    THFile_seekEnd(THFile *self)', '    THFile_synchronize(THFile *self)', '    THFile_writeByte(THFile *self,THByteStorage *storage)', '    THFile_writeByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_writeByteScalar(THFile *self,uint8_t scalar)', '    THFile_writeChar(THFile *self,THCharStorage *storage)', '    THFile_writeCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_writeCharScalar(THFile *self,int8_t scalar)', '    THFile_writeDouble(THFile *self,THDoubleStorage *storage)', '    THFile_writeDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_writeDoubleScalar(THFile *self,double scalar)', '    THFile_writeFloat(THFile *self,THFloatStorage *storage)', '    THFile_writeFloatRaw(THFile *self,float *data,size_t n)', '    THFile_writeFloatScalar(THFile *self,float scalar)', '    THFile_writeHalf(THFile *self,THHalfStorage *storage)', '    THFile_writeHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_writeHalfScalar(THFile *self,at::Half scalar)', '    THFile_writeInt(THFile *self,THIntStorage *storage)', '    THFile_writeIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_writeIntScalar(THFile *self,int32_t scalar)', '    THFile_writeLong(THFile *self,THLongStorage *storage)', '    THFile_writeLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_writeLongScalar(THFile *self,int64_t scalar)', '    THFile_writeShort(THFile *self,THShortStorage *storage)', '    THFile_writeShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_writeShortScalar(THFile *self,int16_t scalar)', '    THFile_writeStringRaw(THFile *self,const char *str,size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THFile.h', [], ['    THFile_ascii(THFile *self)', '    THFile_autoSpacing(THFile *self)', '    THFile_binary(THFile *self)', '    THFile_clearError(THFile *self)', '    THFile_close(THFile *self)', '    THFile_free(THFile *self)', '    THFile_hasError(THFile *self)', '    THFile_isAutoSpacing(THFile *self)', '    THFile_isBinary(THFile *self)', '    THFile_isOpened(THFile *self)', '    THFile_isQuiet(THFile *self)', '    THFile_isReadable(THFile *self)', '    THFile_isWritable(THFile *self)', '    THFile_noAutoSpacing(THFile *self)', '    THFile_pedantic(THFile *self)', '    THFile_position(THFile *self)', '    THFile_quiet(THFile *self)', '    THFile_readBool(THFile *self,THBoolStorage *storage)', '    THFile_readByte(THFile *self,THByteStorage *storage)', '    THFile_readByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_readByteScalar(THFile *self)', '    THFile_readChar(THFile *self,THCharStorage *storage)', '    THFile_readCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_readCharScalar(THFile *self)', '    THFile_readDouble(THFile *self,THDoubleStorage *storage)', '    THFile_readDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_readDoubleScalar(THFile *self)', '    THFile_readFloat(THFile *self,THFloatStorage *storage)', '    THFile_readFloatRaw(THFile *self,float *data,size_t n)', '    THFile_readFloatScalar(THFile *self)', '    THFile_readHalf(THFile *self,THHalfStorage *storage)', '    THFile_readHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_readHalfScalar(THFile *self)', '    THFile_readInt(THFile *self,THIntStorage *storage)', '    THFile_readIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_readIntScalar(THFile *self)', '    THFile_readLong(THFile *self,THLongStorage *storage)', '    THFile_readLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_readLongScalar(THFile *self)', '    THFile_readShort(THFile *self,THShortStorage *storage)', '    THFile_readShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_readShortScalar(THFile *self)', '    THFile_readStringRaw(THFile *self,const char *format,char **str_)', '    THFile_seek(THFile *self,size_t position)', '    THFile_seekEnd(THFile *self)', '    THFile_synchronize(THFile *self)', '    THFile_writeBool(THFile *self,THBoolStorage *storage)', '    THFile_writeByte(THFile *self,THByteStorage *storage)', '    THFile_writeByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_writeByteScalar(THFile *self,uint8_t scalar)', '    THFile_writeChar(THFile *self,THCharStorage *storage)', '    THFile_writeCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_writeCharScalar(THFile *self,int8_t scalar)', '    THFile_writeDouble(THFile *self,THDoubleStorage *storage)', '    THFile_writeDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_writeDoubleScalar(THFile *self,double scalar)', '    THFile_writeFloat(THFile *self,THFloatStorage *storage)', '    THFile_writeFloatRaw(THFile *self,float *data,size_t n)', '    THFile_writeFloatScalar(THFile *self,float scalar)', '    THFile_writeHalf(THFile *self,THHalfStorage *storage)', '    THFile_writeHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_writeHalfScalar(THFile *self,at::Half scalar)', '    THFile_writeInt(THFile *self,THIntStorage *storage)', '    THFile_writeIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_writeIntScalar(THFile *self,int32_t scalar)', '    THFile_writeLong(THFile *self,THLongStorage *storage)', '    THFile_writeLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_writeLongScalar(THFile *self,int64_t scalar)', '    THFile_writeShort(THFile *self,THShortStorage *storage)', '    THFile_writeShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_writeShortScalar(THFile *self,int16_t scalar)', '    THFile_writeStringRaw(THFile *self,const char *str,size_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THFilePrivate.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGeneral.cpp', [], ['    defaultArgErrorHandlerFunction(int argNumber,const char *msg,void *data)', '    defaultErrorHandlerFunction(const char *msg,void *data)', '    _THArgCheck(const char *file,int line,int condition,int argNumber,const char *fmt,...)', '    _THAssertionFailed(const char *file,const int line,const char *exp,const char *fmt,...)', '    _THError(const char *file,const int line,const char *fmt,...)', '    _THSizeDesc(const int64_t *size,const int64_t ndim)', '    THAlloc(ptrdiff_t size)', '    THFree(void *ptr)', '    THRealloc(void *ptr,ptrdiff_t size)', '    THSetArgErrorHandler(THArgErrorHandlerFunction new_handler,void *data)', '    THSetDefaultArgErrorHandler(THArgErrorHandlerFunction new_handler,void *data)', '    THSetDefaultErrorHandler(THErrorHandlerFunction new_handler,void *data)', '    THSetErrorHandler(THErrorHandlerFunction new_handler,void *data)', '    THSetGCHandler(void (*) (void *) torchGCFunction_,void *data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateAllTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateBFloat16Type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateBoolType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateByteType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateCharType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateDoubleType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateFloatType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateFloatTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateHalfType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateIntType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateIntTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateLongType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateQInt32Type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateQInt8Type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateQTypes.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateQUInt8Type.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerateShortType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THGenerator.hpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THHalf.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THLapack.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THLapack.cpp', [], ['    dgeev_(char *jobvl,char *jobvr,int *n,double *a,int *lda,double *wr,double *wi,double *vl,int *ldvl,double *vr,int *ldvr,double *work,int *lwork,int *info)', '    dgels_(char *trans,int *m,int *n,int *nrhs,double *a,int *lda,double *b,int *ldb,double *work,int *lwork,int *info)', '    dgeqrf_(int *m,int *n,double *a,int *lda,double *tau,double *work,int *lwork,int *info)', '    dorgqr_(int *m,int *n,int *k,double *a,int *lda,double *tau,double *work,int *lwork,int *info)', '    dormqr_(char *side,char *trans,int *m,int *n,int *k,double *a,int *lda,double *tau,double *c,int *ldc,double *work,int *lwork,int *info)', '    dpotri_(char *uplo,int *n,double *a,int *lda,int *info)', '    sgeev_(char *jobvl,char *jobvr,int *n,float *a,int *lda,float *wr,float *wi,float *vl,int *ldvl,float *vr,int *ldvr,float *work,int *lwork,int *info)', '    sgels_(char *trans,int *m,int *n,int *nrhs,float *a,int *lda,float *b,int *ldb,float *work,int *lwork,int *info)', '    sgeqrf_(int *m,int *n,float *a,int *lda,float *tau,float *work,int *lwork,int *info)', '    sorgqr_(int *m,int *n,int *k,float *a,int *lda,float *tau,float *work,int *lwork,int *info)', '    sormqr_(char *side,char *trans,int *m,int *n,int *k,float *a,int *lda,float *tau,float *c,int *ldc,float *work,int *lwork,int *info)', '    spotri_(char *uplo,int *n,float *a,int *lda,int *info)', '    TH(char trans,int m,int n,int nrhs,scalar_t *a,int lda,scalar_t *b,int ldb,scalar_t *work,int lwork,int *info)', '    TH(char jobvl,char jobvr,int n,scalar_t *a,int lda,scalar_t *wr,scalar_t *wi,scalar_t *vl,int ldvl,scalar_t *vr,int ldvr,scalar_t *work,int lwork,int *info)', '    TH(char uplo,int n,scalar_t *a,int lda,int *info)', '    TH(int m,int n,scalar_t *a,int lda,scalar_t *tau,scalar_t *work,int lwork,int *info)', '    TH(int m,int n,int k,scalar_t *a,int lda,scalar_t *tau,scalar_t *work,int lwork,int *info)', '    TH(char side,char trans,int m,int n,int k,scalar_t *a,int lda,scalar_t *tau,scalar_t *c,int ldc,scalar_t *work,int lwork,int *info)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THLapack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THLapack.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THMemoryFile.cpp', [], ['    THMemoryFile_cloneString(const int8_t *str,ssize_t size)', '    THMemoryFile_close(THFile *self)', '    THMemoryFile_free(THFile *self)', '    THMemoryFile_grow(THMemoryFile *self,ssize_t size)', '    THMemoryFile_isOpened(THFile *self)', '    THMemoryFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THMemoryFile_position(THFile *self)', '    THMemoryFile_readByte(THFile *self,uint8_t *data,ssize_t n)', '    THMemoryFile_readChar(THFile *self,int8_t *data,ssize_t n)', '    THMemoryFile_readDouble(THFile *self,double *data,ssize_t n)', '    THMemoryFile_readFloat(THFile *self,float *data,ssize_t n)', '    THMemoryFile_readHalf(THFile *self,at::Half *data,ssize_t n)', '    THMemoryFile_readInt(THFile *self,int32_t *data,ssize_t n)', '    THMemoryFile_readLong(THFile *self,int64_t *data,ssize_t n)', '    THMemoryFile_readShort(THFile *self,int16_t *data,ssize_t n)', '    THMemoryFile_readString(THFile *self,const char *format,char **str_)', '    THMemoryFile_seek(THFile *self,ssize_t position)', '    THMemoryFile_seekEnd(THFile *self)', '    THMemoryFile_strnextspace(int8_t *str_,int8_t *c_)', '    THMemoryFile_synchronize(THFile *self)', '    THMemoryFile_writeByte(THFile *self,uint8_t *data,ssize_t n)', '    THMemoryFile_writeChar(THFile *self,int8_t *data,ssize_t n)', '    THMemoryFile_writeDouble(THFile *self,double *data,ssize_t n)', '    THMemoryFile_writeFloat(THFile *self,float *data,ssize_t n)', '    THMemoryFile_writeHalf(THFile *self,at::Half *data,ssize_t n)', '    THMemoryFile_writeInt(THFile *self,int32_t *data,ssize_t n)', '    THMemoryFile_writeLong(THFile *self,int64_t *data,ssize_t n)', '    THMemoryFile_writeShort(THFile *self,int16_t *data,ssize_t n)', '    THMemoryFile_writeString(THFile *self,const char *str,ssize_t size)', '    THMemoryFile_longSize(THFile *self,int size)', '    THMemoryFile_new(const char *mode)', '    THMemoryFile_newWithStorage(THCharStorage *storage,const char *mode)', '    THMemoryFile_storage(THFile *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THMemoryFile.h', [], ['    THMemoryFile_longSize(THFile *self,int size)', '    THMemoryFile_new(const char *mode)', '    THMemoryFile_newWithStorage(THCharStorage *storage,const char *mode)', '    THMemoryFile_storage(THFile *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\THP.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\THP_export.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\thread_init_test.cpp', [], ['    main', '    test(int given_num_threads)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\thread_name.cpp', [], ['    setThreadName(std::string name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\thread_name.h', [], ['    setThreadName(std::string name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\thread_pool.cpp', [], ['    RegistryName', '    ThreadPool(int pool_size,int numa_node_id,std::function init_thread)', '    inThreadPool', '    main_loop(std::size_t index)', '    numAvailable', '    run(const std::function & func)', '    size', '    waitWorkComplete', '    ~ThreadPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\thread_pool.h', ['    TaskThreadPoolBase', '    ThreadPool'], ['    defaultNumThreads', '    inThreadPool', '    numAvailable', '    run(const std::function & func)', '    size', '    ~TaskThreadPoolBase', '    inThreadPool', '    main_loop(std::size_t index)', '    numAvailable', '    run(const std::function & func)', '    runTaskWithID(Task task)', '    size', '    task_element_t(const std::function & f)', '    task_element_t(const std::function & f)', '    ThreadPool(int pool_size,int numa_node_id,std::function init_thread)', '    ThreadPool', '    waitWorkComplete', '    ~ThreadPool', '    hardware_concurrency']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ThreadLocalDebugInfo.cpp', [], ['    getThreadLocalDebugInfo', '    setThreadLocalDebugInfo(std::shared_ptr info)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\ThreadLocalDebugInfo.h', ['    DebugInfoGuard', '    ThreadLocalDebugInfoBase'], ['    getThreadLocalDebugInfo', '    DebugInfoGuard(std::shared_ptr info)', '    ~DebugInfoGuard', '    ThreadLocalDebugInfoBase', '    ~ThreadLocalDebugInfoBase', '    move']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\ThreadLocalPtr.cc', [], ['    getAllThreadLocalHelperVector', '    getThreadLocalHelper', '    erase(ThreadLocalHelper *helper)', '    erase_tlp(ThreadLocalPtrImpl *ptr)', '    push_back(ThreadLocalHelper *helper)', '    erase(ThreadLocalPtrImpl *key)', '    get(ThreadLocalPtrImpl *key)', '    insert(ThreadLocalPtrImpl *tl_ptr,std::shared_ptr ptr)', '    ThreadLocalHelper', '    ~ThreadLocalHelper', '    ~ThreadLocalPtrImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\ThreadLocalPtr.h', ['    AllThreadLocalHelperVector', '    ThreadLocalHelper', '    ThreadLocalPtr', '    ThreadLocalPtrImpl'], ['    getThreadLocalHelper', '    AllThreadLocalHelperVector', '    erase(ThreadLocalHelper *helper)', '    erase_tlp(ThreadLocalPtrImpl *ptr)', '    push_back(ThreadLocalHelper *helper)', '    erase(ThreadLocalPtrImpl *key)', '    get(ThreadLocalPtrImpl *key)', '    insert(ThreadLocalPtrImpl *tl_ptr,std::shared_ptr ptr)', '    ThreadLocalHelper', '    ~ThreadLocalHelper', '    get', '    get', '    operator*', '    operator*', '    operator->', '    operator->', '    reset(unique_ptr ptr)', '    get', '    operator=', '    operator=', '    reset(T *newPtr)', '    ThreadLocalPtrImpl', '    ThreadLocalPtrImpl', '    ThreadLocalPtrImpl', '    ~ThreadLocalPtrImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\ThreadLocalState.cpp', [], ['    getThreadLocalState', '    setThreadLocalState(const ThreadLocalState & state)', '    ThreadLocalState(bool grad_mode_enabled,int64_t dist_autograd_context_id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\ThreadLocalState.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPool.cc', ['    C10FlagParser_caffe2_threadpool_android_cap', '    C10FlagParser_caffe2_threadpool_force_inline', '    C10FlagParser_caffe2_threadpool_ios_cap'], ['    getDefaultNumThreads', '    C10FlagParser_caffe2_threadpool_android_cap(const std::string & content)', '    C10FlagParser_caffe2_threadpool_force_inline(const std::string & content)', '    C10FlagParser_caffe2_threadpool_ios_cap(const std::string & content)', '    defaultThreadPool', '    getNumThreads', '    run(const std::function & fn,size_t range)', '    setMinWorkSize(size_t size)', '    setNumThreads(size_t numThreads)', '    ThreadPool(int numThreads)', '    withPool(const std::function & f)', '    ~ThreadPool', '    FnTask', '    Run', '    ~FnTask']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPool.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPoolCommon.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPoolMobile.cc', [], ['    mobile_pthreadpool', '    mobile_threadpool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPoolMobile.h', [], ['    getDefaultNumThreads', '    mobile_pthreadpool', '    mobile_threadpool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPoolXNNPACK.cc', [], ['    xnnpack_threadpool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\ThreadPoolXNNPACK.h', [], ['    xnnpack_threadpool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\thresholded_relu_op.cc', ['    GetThresholdedReluGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUThresholdedRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUThresholdedReluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThresholdedRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThresholdedReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\thresholded_relu_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    ThresholdedReluGradientOp(Args,...)', '    ThresholdedReluOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\throughput_benchmark-inl.h', [], ['    MessageLogger(,,INFO)', '    finished', '    initialized', '    start', '    lock(m)', '    lock(m)', '    now', '    now', '    empty', '    size', '    benchmark(const BenchmarkConfig & config)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\throughput_benchmark.cpp', [], ['    cloneInput(const ModuleInput & input)', '    cloneInput(const ScriptModuleInput & input)', '    addInput(py::args,py::kwargs)', '    runOnce(ModuleInput)', '    runOnce(py::args,py::kwargs)', '    addInput(py::args,py::kwargs)', '    runOnce(ScriptModuleInput)', '    runOnce(py::args,py::kwargs)', '    addInput(py::args args,py::kwargs kwargs)', '    benchmark(const BenchmarkConfig & config)', '    runOnce(py::args,py::kwargs)', '    ThroughputBenchmark(jit::Module script_module)', '    ThroughputBenchmark(py::object module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\throughput_benchmark.h', ['    BenchmarkHelper', '    ThroughputBenchmark'], ['    cloneInput(const Input & input)', '    num_calling_threads', '    num_iters', '    num_warmup_iters', '    num_worker_threads', '    latency_avg_ms', '    num_iters', '    addInput(py::args,py::kwargs)', '    benchmark(const BenchmarkConfig & config)', '    BenchmarkHelper', '    BenchmarkHelper', '    BenchmarkHelper(Model model)', '    initialized', '    initialized_', '    runOnce(Input)', '    runOnce(py::args,py::kwargs)', '    runOnce(ModuleInput)', '    ModuleInput', '    ModuleInput', '    ModuleInput(py::args,py::kwargs)', '    operator=', '    operator=', '    runOnce(ScriptModuleInput)', '    addInput(py::args args,py::kwargs kwargs)', '    benchmark(const BenchmarkConfig & config)', '    runOnce(py::args,py::kwargs)', '    ThroughputBenchmark(jit::Module script_module)', '    ThroughputBenchmark(py::object module)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THStorage.cpp', [], ['    TH(THStorage *storage1,THStorage *storage2)', '    TH(THStorage *storage)', '    TH(const THStorage *self)', '    TH', '    TH(THStorage *storage,ptrdiff_t size)', '    TH(THStorage *storage,scalar_t value)', '    TH(THStorage *self,ptrdiff_t idx,scalar_t value)', '    TH(const THStorage *self,ptrdiff_t idx)', '    TH(THStorage *storage)', '    Make']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THStorage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THStorage.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THStorageCopy.cpp', [], ['    TH(THStorage *storage,THByteStorage *src)', '    TH(THStorage *storage,THCharStorage *src)', '    TH(THStorage *storage,THShortStorage *src)', '    TH(THStorage *storage,THIntStorage *src)', '    TH(THStorage *storage,THLongStorage *src)', '    TH(THStorage *storage,THFloatStorage *src)', '    TH(THStorage *storage,THDoubleStorage *src)', '    TH(THStorage *storage,THHalfStorage *src)', '    TH(THStorage *storage,THBoolStorage *src)', '    TH(THStorage *storage,THBFloat16Storage *src)', '    TH(THStorage *storage,THStorage *src)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THStorageCopy.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THStorageFunctions.cpp', [], ['    THStorage_free(THStorage *storage)', '    THStorage_new(caffe2::TypeMeta data_type)', '    THStorage_resize(THStorage *storage,ptrdiff_t size)', '    THStorage_retain(THStorage *storage)', '    THStorage_size(const THStorage *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THStorageFunctions.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THStorageFunctions.hpp', [], ['    THStorage_resize(THStorage *storage,ptrdiff_t size)', '    THStorage_retain(THStorage *storage)', '    THStorage_size(const THStorage *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensor.cpp', [], ['    copy_(tensor_wrap,self_wrap,)', '    incref(storage)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(const at::TensorImpl *self,int dim)', '    TH(const at::TensorImpl *self,int dim)', '    TH(at::TensorImpl *self,at::TensorImpl *dst)', '    TH(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    TH(at::TensorImpl *self,at::TensorImpl *src)', '    TH(at::TensorImpl *self,at::TensorImpl *src)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,scalar_t value)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *tensor)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    TH(at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(at::TensorImpl *tensor,int64_t size0)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1,int64_t size2)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3,int64_t size4)', '    TH(at::TensorImpl *self)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t firstIndex,int64_t size)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t sliceIndex)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension1,int dimension2)', '    TH(const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    reclaim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensor.cpp', [], ['    THTensor_free(at::TensorImpl *self)', '    THTensor_resize(at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THTensor_resizeNd(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THTensor_setStorage(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THTensor_stealAndSetStoragePtr(at::TensorImpl *tensor,THStorage *storage)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensor.h', [], ['    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(const at::TensorImpl *self,int dim)', '    TH(at::TensorImpl *tensor,scalar_t value)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,int64_t size0)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1,int64_t size2)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3,int64_t size4)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t firstIndex,int64_t size)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t sliceIndex)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension1,int dimension2)', '    TH(const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensor.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensor.hpp', [], ['    THTensor_getSizePtr(at::TensorImpl *tensor)', '    THTensor_getStoragePtr(const at::TensorImpl *tensor)', '    THTensor_getStridePtr(at::TensorImpl *tensor)', '    THTensor_nDimension(const at::TensorImpl *tensor)', '    THTensor_nDimensionLegacyAll(const at::TensorImpl *tensor)', '    THTensor_nDimensionLegacyNoScalars(const at::TensorImpl *tensor)', '    THTensor_resizeNd(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THTensor_setStorage(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THTensor_sizeLegacyNoScalars(const at::TensorImpl *self,int dim)', '    THTensor_sizesLegacyNoScalars(const at::TensorImpl *self)', '    THTensor_stealAndSetStoragePtr(at::TensorImpl *tensor,THStorage *storage)', '    THTensor_strideLegacyNoScalars(const at::TensorImpl *self,int dim)', '    THTensor_stridesLegacyNoScalars(const at::TensorImpl *self)', '    THTensor_wrap(at::TensorImpl *tensor)', '    reclaim']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensor.hpp', [], ['    TH(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorApply.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorApply.hpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorDimApply.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorEvenMoreMath.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorEvenMoreMath.cpp', [], ['    TH(at::TensorImpl *tensor,ptrdiff_t linearIndex)', '    TH(int64_t linearIndex,int64_t numel)', '    TH(int64_t linearIndex,int64_t numel)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,scalar_t value)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *index,at::TensorImpl *src,int accumulate)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src,at::TensorImpl *mask)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src)', '    TH(at::TensorImpl *subscript,at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *r_,at::TensorImpl *src,at::TensorImpl *index)', '    TH(at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src,at::TensorImpl *mask)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorFastGetSet.hpp', [], ['    TH(at::TensorImpl *self,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,int64_t x4)', '    TH(at::TensorImpl *self,int64_t x0,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,int64_t x4,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0)', '    TH(at::TensorImpl *self,int64_t x0)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorFill.cpp', [], ['    TH(at::TensorImpl *r_,scalar_t value)', '    TH(at::TensorImpl *r_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorFill.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorFill.h', [], ['    TH(at::TensorImpl *r_,scalar_t value)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorLapack.cpp', [], ['    TH(at::TensorImpl *self)', '    TH(at::TensorImpl *self)', '    copy_(result_wrap,src_wrap)', '    copy_(view_wrap,src_wrap)', '    decref(view)', '    TH(at::TensorImpl *rb_,at::TensorImpl *ra_,at::TensorImpl *b,at::TensorImpl *a)', '    TH(at::TensorImpl *re_,at::TensorImpl *rv_,at::TensorImpl *a_,bool eigenvectors)', '    TH(at::TensorImpl *a,char uplo)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,bool upper)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau,at::TensorImpl *c,bool left,bool transpose)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau)', '    TH(at::TensorImpl *ra_,at::TensorImpl *rtau_,at::TensorImpl *a)', '    unsqueeze']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorLapack.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorLapack.h', [], ['    TH(at::TensorImpl *re_,at::TensorImpl *rv_,at::TensorImpl *a_,bool eigenvectors)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,bool upper)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau,at::TensorImpl *c,bool left,bool transpose)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorMath.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorMath.cpp', [], ['    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *m1,at::TensorImpl *m2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *result,at::TensorImpl *t,at::TensorImpl *batch1,at::TensorImpl *batch2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *m1,at::TensorImpl *m2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *vec1,at::TensorImpl *vec2,scalar_t beta,scalar_t alpha)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorMath.h', [], ['    TH(at::TensorImpl *r_,at::TensorImpl *t,scalar_t value)', '    TH(at::TensorImpl *r_,int in_dims,int reduce_dimension,int keepdim)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *index,at::TensorImpl *src,int accumulate)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int64_t k,int dimension,int keepdim)', '    TH(at::TensorImpl *result,at::TensorImpl *t,at::TensorImpl *batch1,at::TensorImpl *batch2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int dimension,int keepdim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorMoreMath.cpp', [], ['    TH(scalar_t *arr,int64_t *idx,int64_t elements,int64_t stride)', '    TH(scalar_t *arr,int64_t *idx,int64_t elements,int64_t stride)', '    TH(at::TensorImpl *result,at::TensorImpl *src)', '    TH(at::TensorImpl *ta,at::TensorImpl *tb)', '    TH(scalar_t *arr,int64_t *idx,int64_t k,int64_t elements,int64_t stride)', '    TH(at::TensorImpl *ta,at::TensorImpl *tb)', '    TH(at::TensorImpl *r_,int in_dims,int reduce_dimension,int keepdim)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int64_t k,int dimension,int keepdim)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int dimension,int keepdim)', '    TH(at::TensorImpl *rt_,at::TensorImpl *ri_,at::TensorImpl *t,int dimension,int descendingOrder)', '    TH(at::TensorImpl *t)', '    TH(at::TensorImpl *result,scalar_t beta,at::TensorImpl *t,scalar_t alpha,at::TensorImpl *batch1,at::TensorImpl *batch2)', '    TH(at::TensorImpl *t)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorMoreMath.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorRandom.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THTensorRandom.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THTensorRandom.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THVector.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\THVector.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THVector.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THVectorDefault.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\generic\\THVectorDispatch.cpp', [], ['    TH_CONCAT_4(TH,Real,Vector_,startup)', '    TH', '    TH(scalar_t *x,const scalar_t,const ptrdiff_t n)', '    TH(scalar_t *y,const scalar_t *x,const scalar_t c,const ptrdiff_t n)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tile_op.cc', ['    GetTileGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTile', '    CAFFE_ANONYMOUS_VARIABLE_CPUTileGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TileGradient', '    GetGradientDefs', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tile_op.h', ['    final', '    final'], ['    DoRunWithType', '    DoRunWithType', '    DoTile(const int outer_size,const int inner_size,const T *X,T *Y)', '    DoTileGradient(const int outer_size,const int inner_size,const T *dY,T *dX)', '    GetArgFromTensor(const Tensor & tensor)', '    GetArgFromTensor(const Tensor & tensor)', '    RunOnDevice', '    RunOnDevice', '    TileGradientOp(Args,...)', '    TileOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\time_observer.cc', [], ['    Start', '    Stop', '    Start', '    Stop']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\time_observer.h', ['    final', '    final', '    TimeCounter'], ['    average_time_children', '    Start', '    Stop', '    TimeObserver(NetBase *subject)', '    TimeOperatorObserver', '    TimeOperatorObserver(OperatorBase *subject,TimeObserver *)', '    average_time', '    TimeCounter', '    GetOperators']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\observers\\time_observer_test.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSleepOp', '    CAFFE_ANONYMOUS_VARIABLE_CUDASleepOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SleepOp', '    CreateNetTestHelper(Workspace *ws)', '    TEST(TimeObserverTest,Test3Seconds)', '    Run(int)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\time_profiler.h', ['    TimeProfiler'], ['    profile(std::function runnable)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\timer.h', ['    Timer'], ['    MicroSeconds', '    MilliSeconds', '    NanoSeconds', '    operator=', '    Seconds', '    Start', '    Timer', '    Timer', '    duration_cast']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\timer_test.cc', [], ['    TEST(TimerTest,Test)', '    TEST(TimerTest,TestLatency)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\top_k.cc', ['    GetTopKGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPUTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TopKGradient', '    GetTopK(const T *input,const int64_t n,const int64_t k,const int64_t src_offset,const int64_t dst_offset,const int64_t stride,T *values,int64_t *indices,int64_t *flatten_indices)', '    SetTopKGradient(const T *values,const int64_t *indices,const int k,const int64_t src_offset,const int64_t dst_offset,const int64_t stride,T *gradient)', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    operator()(const std::pair & lhs,const std::pair & rhs)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\top_k.h', ['    TopKGradientOp', '    TopKOp'], ['    RunOnDevice', '    TopKGradientOp(Args,...)', '    ~TopKGradientOp', '    RunOnDevice', '    TopKOp(Args,...)', '    ~TopKOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\include\\nomnigraph\\Graph\\TopoSort.h', ['    TopoSort'], ['    topoSort(GraphT *g)', '    dfs(NodeRefT node,std::unordered_map & status,std::vector & nodes)', '    run', '    TopoSort(GraphT *graph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\nomnigraph\\tests\\TopoSortTest.cc', [], ['    TEST(TopoSort,Simple)', '    TEST(TopoSort,DAG)', '    TEST(TopoSort,Cycle1)', '    TEST(TopoSort,Cycle2)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\torch.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\api\\torch_include.cpp', [], ['    TEST(TorchIncludeTest,GetSetNumThreads)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\proto\\torch_pb.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\cpp\\jit\\torch_python_test.cpp', [], ['    runJITCPPTests(bool runCuda)', '    runTENSOREXPRCPPTests(bool runCuda)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\torchscript_functions.cpp', [], ['    remoteTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)', '    rpcTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\torchscript_functions.h', [], ['    remoteTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)', '    rpcTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\tracer.cpp', [], ['    addInput(const std::shared_ptr & state,const IValue & input,const TypePtr & type,Value *value)', '    gatherParametersAndBuffers(const std::shared_ptr & state,Value *self_value,const Module & self,const std::string & prefix)', '    kind', '    reason', '    _do_warn(const char *_reason,const char *_kind)', '    defaultRecordSourceLocation(Node *n)', '    defaultWarn(const std::string & str)', '    ensureUniqueIfOutOfPlaced(const char *name,const at::Tensor & tensor)', '    getSizeOf(const autograd::Variable & var,int64_t dim)', '    abandon', '    addInputs(Node *n,const char *name,int64_t value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,bool value)', '    addInputs(Node *n,const char *name,double value)', '    addInputs(Node *n,const char *name,const at::Scalar & value)', '    addInputs(Node *n,const char *name,const std::string & value)', '    addInputs(Node *n,const char *name,const at::Tensor & value)', '    addInputs(Node *n,const char *name,const at::Generator & value)', '    addInputs(Node *n,const char *name,at::Device value)', '    addInputs(Node *n,const char *name,at::Layout value)', '    addInputs(Node *n,const char *name,at::ScalarType value)', '    addInputs(Node *n,const char *name,at::MemoryFormat value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,at::TensorList value,bool allow_undefined)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,const at::TensorOptions & options)', '    addInputs(Node *n,const char *name,at::IntArrayRef value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,const c10::intrusive_ptr & obj)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,c10::optional opt_dtype)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addOutput(Node *node,const at::Tensor & output)', '    addOutput(Node *node,const std::vector & outputs)', '    addOutput(Node *node,const c10::List & outputs)', '    delValueTrace(const IValue & var)', '    getTracingState', '    getValueTrace(const IValue & var)', '    setOutput(Value *value,const at::Tensor & output)', '    setTracingState(std::shared_ptr state)', '    setValueTrace(const IValue & v,Value *value)', '    trace(Stack inputs,const std::function & traced_fn,std::function var_name_lookup_fn,bool force_outplace,Module *self)', '    badArgType(const T & v)', '    genericAddInput(Node *n,T value)', '    pauseTracing', '    recordSourceLocation(Node *n)', '    setRecordSourceLocation(void (*) (Node *) v)', '    setWarn(warn_fn_type fn)', '    warn_callback', '    stashIntArrayRefElem(const std::string & arg_name,size_t size,size_t idx,const Variable & var)', '    stashValue(const std::string & arg_name,size_t idx,const Variable & var,const TypePtr & type)', '    delValue(const IValue & var)', '    getOutput(const IValue & iv,size_t i)', '    getValue(const IValue & var)', '    hasValue(const IValue & var)', '    setValue(const IValue & v,Value *value)', '    TracingState']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\tracer.h', [], ['    _do_warn(const char *_reason,const char *_kind)', '    abandon', '    addInputs(Node *n,const char *name,int64_t value)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,bool value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,double value)', '    addInputs(Node *n,const char *name,const at::Scalar & value)', '    addInputs(Node *n,const char *name,const at::Tensor & value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,ArrayRef value,bool allow_undefined)', '    addInputs(Node *n,const char *name,const std::string & value)', '    addInputs(Node *n,const char *name,const at::TensorOptions & value)', '    addInputs(Node *n,const char *name,at::Device value)', '    addInputs(Node *n,const char *name,at::Layout value)', '    addInputs(Node *n,const char *name,at::ScalarType value)', '    addInputs(Node *n,const char *name,at::MemoryFormat value)', '    addInputs(Node *n,const char *name,const at::Generator & value)', '    addInputs(Node *n,const char *name,const std::vector & value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,const std::unordered_map & value)', '    addInputs(Node *n,const char *name,std::array value)', '    addInputs(Node *n,const char *name,const c10::intrusive_ptr & obj)', '    delValueTrace(const IValue & var)', '    ensureUniqueIfOutOfPlaced(const char *name,const at::Tensor & tensor)', '    getTracingState', '    getValueTrace(const IValue & var)', '    isTracing', '    pauseTracing', '    recordSourceLocation(Node *n)', '    setTracingState(std::shared_ptr state)', '    setValueTrace(const IValue & v,Value *value)', '    setWarn(warn_fn_type fn)', '    trace(Stack inputs,const std::function & traced_fn,std::function var_name_lookup_fn,bool force_outplace,Module *self)', '    warn(const char *_reason,const char *_kind)', '    empty', '    hasIntArrayRef(const std::string & arg_name)', '    hasValue(const std::string & arg_name)', '    popIntArrayRef(const std::string & arg_name)', '    popValue(const std::string & arg_name)', '    stashIntArrayRefElem(const std::string & arg_name,size_t size,size_t idx,const Variable & var)', '    stashValue(const std::string & arg_name,size_t idx,const Variable & var,const c10::TypePtr & type)', '    ArrayRef', '    IValue', '    IntArrayRefTrace(int size)', '    NoWarn', '    ~NoWarn', '    delValue(const IValue & var)', '    enterFrame', '    getOutput(const IValue & var,size_t i)', '    getValue(const IValue & var)', '    hasValue(const IValue & var)', '    leaveFrame', '    setValue(const IValue & v,Value *value)', '    TracingState', '    operator()(const WeakIValue & t1,const WeakIValue & t2)', '    operator()(const WeakIValue & t)', '    ~TracingState', '    WithNestedTracingFrame', '    ~WithNestedTracingFrame']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\transform.cc', [], ['    ApplyTransform(const string & key,const NetDef & netdef)', '    ApplyTransformIfFaster(const string & key,const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs,const double improvement_threshold)', '    average_net_run_duration(const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs)', '    RegistryName', '    CreateTransform(string)', '    ApplyTo(const NetDef & orig_net)', '    PatternMatchHelper(const Graph & graph,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    ReplacePattern(const std::vector,Graph *graph)', '    TryNeighbors(const Graph & graph,const std::map,std::vector,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\transform.h', ['    Transform'], ['    ApplyTransform(const string & key,const NetDef & netdef)', '    ApplyTransformIfFaster(const string & key,const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs,const double improvement_threshold)', '    CreateTransform(string key)', '    RegistryName', '    ApplyTo(const NetDef & orig_net_def)', '    PatternMatchHelper(const transform::Graph & graph,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int)', '    ReplacePattern(const std::vector,transform::Graph *graph)', '    ReplaceRule(const std::vector & subgraph,transform::Graph *g_ptr)', '    SetPatternMatchType(PatternMatchType type)', '    Transform', '    TryNeighbors(const transform::Graph & graph,const std::map,std::vector,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    ValidatorRule(const transform::Graph & g,const std::vector & subgraph)', '    ~Transform']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\image\\transform_gpu.h', [], ['    TransformOnGPU(Tensor & X,Tensor *Y,Tensor & mean,Tensor & std,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\transform_test.cc', ['    DummyTransform', '    FastToSlowTransform', '    final', '    final', '    final', '    GeneralDummyTransform', '    SlowToFastTransform', '    SortedDummyTransform', '    TypeSwapTransform'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp3', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformSleepFastOp', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformSleepSlowOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformSleepFastOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformSleepSlowOp', '    TEST(TransformTest,TestPatternMatch)', '    TEST(TransformTest,TestReplacePattern)', '    TEST(TransformTest,TestTransformApply)', '    TEST(TransformTest,TestPatternMatchTypeSortedOrder)', '    TEST(TransformTest,TestPatternMatchTypeGeneral)', '    TEST(TransformTest,TestApplyTransformIfFasterIsFaster)', '    TEST(TransformTest,TestApplyTransformIfFasterButSlower)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    FastToSlowTransform', '    Run(int)', '    Run(int)', '    Run(int)', '    GeneralDummyTransform', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    SlowToFastTransform', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    SortedDummyTransform', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    TypeSwapTransform(string old_type,string new_type)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\transforms.cc', [], ['    CanRenameBackwards(const string & from,const string & to,const std::shared_ptr & net,const std::set & netInputs,const std::set & netOutputs,const std::set & ignoreTypes,int end)', '    CanRenameForwards(const string & from,const string & to,const std::shared_ptr & net,const std::set & netOutputs,const std::set & ignoreTypes,int start)', '    HasInput(const string & blob,const OperatorDef & op)', '    HasOutput(const string & blob,const OperatorDef & op)', '    InPlaceOps(const InferenceGraph & graph,const std::string & op_type)', '    NextBlob(const Workspace & ws,const string & prefix,int max_tries)', '    RemoveOpsByType(const InferenceGraph & graph,const std::string & op_type)', '    RenameInputs(const string & from,const string & to,OperatorDef *def)', '    RenameInputsInChildren(const string & from,const string & to,std::shared_ptr net,int pidx)', '    RenameOutputs(const string & from,const string & to,OperatorDef *def)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\transforms.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\transforms.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\transpose.cc', [], ['    transpose_4rows(int N,const std::uint8_t *src,std::uint8_t *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\transpose.cc', [], ['    NCHW2NHWC(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *)', '    NHWC2NCHW(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const double *X,double *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const double *X,double *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::uint8_t *X,std::uint8_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::uint8_t *X,std::uint8_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::uint16_t *X,std::uint16_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::uint16_t *X,std::uint16_t *Y,CPUContext *)', '    Transpose2D(const TIndex rows,const TIndex cols,const TData *X,TData *Y)', '    TransposeImpl(const int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y)', '    TransposeND(const int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\transpose.h', [], ['    transpose_4rows(int N,const std::uint8_t *src,std::uint8_t *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\transpose.h', [], ['    NCHW2NHWC(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    NHWC2NCHW(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    Transpose(int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y,Context *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\transpose_op.cc', ['    final'], ['    IDEEPTransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPTransposeOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\transpose_op.cc', ['    GetTransposeGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Transpose', '    vector', '    CopyArguments', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\transpose_op.h', ['    TransposeOp'], ['    dim', '    vec', '    DoRunWithType', '    GetRepeatedArgument', '    RunOnDevice', '    TransposeImpl(const Tensor & X,Tensor *Y)', '    TransposeOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\transpose_op_cudnn.cc', ['    final'], ['    CuDNNTransposeOp(Args,...)', '    DoRunWithType', '    IsCuDNNValidTensor(const Tensor & X)', '    IsFloatType', '    RunOnDevice', '    SetTensorDescriptor(const cudnnDataType_t data_type,const std::vector & X_dims,const std::vector & Y_dims)', '    ~CuDNNTransposeOp', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\tree.h', [], ['    mergeRanges(SourceRange c,const TreeList & others)', '    operator<<(std::ostream & out,pretty_tree t_)', '    operator<<(std::ostream & out,const TreeRef & t)', '    incref(this)', '    matchD(k,,,args,...)', '    matchD(int k,const char *filename,int lineno,Args &,...)', '    matchNumSubtrees(int k,size_t expected_subtrees)', '    matchNumSubtreesD(int k,const char *filename,int lineno,size_t expected_subtrees,bool allow_more)', '    ~Tree', '    create(int kind,const SourceRange & range_,TreeList)', '    create(Args,...)', '    Compound(int kind,SourceRange range)', '    Compound(int kind,const SourceRange & range_,TreeList)', '    isAtom', '    override', '    range', '    trees', '    get_flat(const TreeRef & t)', '    pretty_tree(const TreeRef & tree,size_t col)', '    print(std::ostream & out,const TreeRef & t,int indent)', '    String(std::string value)', '    stringValue', '    isAtom', '    kind', '    range', '    stringValue', '    Tree(int kind_)', '    tree(size_t i)', '    trees']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\frontend\\tree_views.h', [], ['    create(const SourceRange & range)', '    create(const SourceRange & range,const T & value)', '    create(const Expr & value)', '    create(const SourceRange & range,const std::vector & subtrees)', '    unsafeCreate(const SourceRange & range,TreeList)', '    size', '    type_erased_sub', '    create(const SourceRange & range,const Expr & callee,const List & inputs,const List & attributes)', '    create(const SourceRange & range,const Expr & test,const Maybe & msg)', '    create(const SourceRange & range,const List & lhs,const Maybe & rhs,const Maybe & type)', '    create(const SourceRange & range,const Ident & name,const TreeRef & value)', '    create(const SourceRange & range,const Expr & lhs,const AugAssignKind & aug_op,const Expr & rhs)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Ident & name,const Maybe & superclass,const List & body)', '    create(const SourceRange & range,const std::string & value)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Ident & name,const Decl & decl,const List & stmts)', '    create(const SourceRange & range,const List & keys,const List & values)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Expr & list)', '    create(const SourceRange & range,const List & targets,const List & itrs,const List & body)', '    create(const SourceRange & range,const List & names)', '    create(const SourceRange & range,const std::string & name)', '    create(const SourceRange & range,const Expr & cond,const List & true_branch,const List & false_branch)', '    create(const SourceRange & range,const Expr & elt,const Expr & target,const Expr & iter)', '    create(const SourceRange & range,const List & inputs)', '    create(const SourceRange & range,const Ident & ident,const Maybe & type,const Maybe & def,bool kwarg_only)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Maybe & expr)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Expr & value)', '    create(const SourceRange & range,const Expr & value,const Ident & selector)', '    create(const SourceRange & range,const Maybe & start,const Maybe & end,const Maybe & step)', '    create(const SourceRange & range,const Expr & expr)', '    create(const SourceRange & range,const std::string & value)', '    create(const SourceRange & range,const Expr & value,const List & subscript_exprs)', '    create(const SourceRange & range,const Expr & cond,const Expr & true_expr,const Expr & false_expr)', '    create(const SourceRange & range,const List & inputs)', '    create(const SourceRange & range,int kind,const Expr & expr)', '    create(const SourceRange & range,const Ident & name)', '    create(const SourceRange & range,const Expr & cond,const List & body)', '    Apply(const TreeRef & tree)', '    attributes', '    callee', '    inputs', '    Assert(const TreeRef & tree)', '    msg', '    test', '    Assign(const TreeRef & tree)', '    lhs', '    lhs_list', '    Attribute(const TreeRef & tree)', '    name', '    value', '    aug_op', '    AugAssign(const TreeRef & tree)', '    lhs', '    AugAssignKind(const TreeRef & tree)', '    BinOp(const TreeRef & tree)', '    lhs', '    Break(const TreeRef & tree)', '    stoll', '    body', '    ClassDef(const TreeRef & tree)', '    name', '    superclass', '    withName(std::string new_name)', '    asFloatingPoint', '    asIntegral', '    Const(const TreeRef & tree)', '    isFloatingPoint', '    isIntegral', '    text', '    Continue(const TreeRef & tree)', '    Decl(const TreeRef & tree)', '    params', '    decl', '    Def(const TreeRef & tree)', '    name', '    statements', '    withDecl(Decl decl)', '    withName(std::string new_name)', '    DictLiteral(const TreeRef & tree)', '    key_inputs', '    value_inputs', '    Dots(const TreeRef & tree)', '    Expr(const TreeRef & tree)', '    range', '    expr', '    ExprStmt(const TreeRef & tree)', '    body', '    For(const TreeRef & tree)', '    itrs', '    targets', '    Global(const TreeRef & tree)', '    names', '    Ident(const TreeRef & tree)', '    name', '    range', '    cond', '    falseBranch', '    If(const TreeRef & tree)', '    trueBranch', '    withNewBranches(const List & true_branch,const List & false_branch)', '    elt', '    iter', '    ListComp(const TreeRef & tree)', '    target', '    inputs', '    ListLiteral(const TreeRef & tree)', '    get', '    Maybe(const TreeRef & tree)', '    Maybe(const T & tree)', '    present', '    defaultValue', '    ident', '    kwarg_only', '    Param(const TreeRef & tree)', '    type', '    withType(const Maybe & typ)', '    Pass(const TreeRef & tree)', '    expr', '    Raise(const TreeRef & tree)', '    expr', '    Return(const TreeRef & tree)', '    Select(const TreeRef & tree)', '    selector', '    value', '    createInt(int value)', '    end', '    endOr(int alternative)', '    SliceExpr(const TreeRef & tree)', '    start', '    startOr(int alternative)', '    step', '    stepOr(int alternative)', '    expr', '    Starred(const TreeRef & tree)', '    Stmt(const TreeRef & tree)', '    StringLiteral(const TreeRef & tree)', '    text', '    Subscript(const TreeRef & tree)', '    subscript_exprs', '    value', '    cond', '    false_expr', '    TernaryIf(const TreeRef & tree)', '    true_expr', '    begin', '    empty', '    end', '    List(const TreeRef & tree)', '    operator[](size_t i)', '    ListIterator(TreeList::const_iterator it)', '    operator!=(const ListIterator & rhs)', '    operator*', '    operator++', '    operator+=(std::ptrdiff_t n)', '    operator--', '    operator==(const ListIterator & rhs)', '    dump', '    get', '    kind', '    operator TreeRef', '    range', '    subtree(size_t i)', '    tree', '    TreeView(TreeRef tree)', '    inputs', '    TupleLiteral(const TreeRef & tree)', '    UnaryOp(const TreeRef & tree)', '    name', '    Var(const TreeRef & tree)', '    body', '    cond', '    While(const TreeRef & tree)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TriangularOps.cpp', [], ['    apply_triu_tril_single(scalar_t *result,scalar_t *self,bool inplace,int64_t k,int64_t n,int64_t m,int64_t res_row_stride,int64_t res_col_stride,int64_t self_row_stride,int64_t self_col_stride)', '    apply_triu_tril(Tensor & result,const Tensor & self,bool inplace,int64_t k)', '    tril(const Tensor & self,int64_t k)', '    tril_cpu_(Tensor & self,int64_t k)', '    tril_cpu_out(Tensor & result,const Tensor & self,int64_t k)', '    triu(const Tensor & self,int64_t k)', '    triu_cpu_(Tensor & self,int64_t k)', '    triu_cpu_out(Tensor & result,const Tensor & self,int64_t k)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TriangularOpsUtils.h', [], ['    batchCountTrilTriu(const Tensor & batched_matrices)', '    checkTrilTriuBatchContiguous(const Tensor & tensor,bool allow_zero_stride)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\trt_utils.cc', [], ['    BuildTrtEngine(const std::string & onnx_model_str,TrtLogger *logger,size_t max_batch_size,size_t max_workspace_size,bool debug_builder)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\tensorrt\\trt_utils.h', ['    TrtLogger'], ['    BuildTrtEngine(const std::string & onnx_model_str,TrtLogger *logger,size_t max_batch_size,size_t max_workspace_size,bool debug_builder)', '    TrtObject(T *obj)', '    operator()(T *obj)', '    log(Severity severity,const char *msg)', '    TrtLogger(Severity verbosity)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\tsv_2_proto.cc', ['    C10FlagParser_f_in', '    C10FlagParser_f_out'], ['    main(int argc,char **argv)', '    C10FlagParser_f_in(const std::string & content)', '    C10FlagParser_f_out(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\tt_contraction_op.cc', ['    GetTTContractionGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTTContraction', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTContractionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTContraction', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTContractionGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\tt_contraction_op.h', ['    final', '    final'], ['    RunOnDevice', '    RunOnDevice', '    TTContractionGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    TTContractionOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\tt_contraction_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDATTContraction', '    CAFFE_ANONYMOUS_VARIABLE_CUDATTContractionGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tt_linear_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTT', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTLinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTLinearGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\tt_linear_op.h', ['    final', '    TTLinearGradientOp'], ['    dtype', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    ReinitializeTensor(& bias_multiplier_,,at::dtype)', '    GetRepeatedArgument', '    RunOnDevice', '    TTLinearOp(Args,...)', '    ~TTLinearOp', '    dim32', '    Gemm(CblasNoTrans,CblasNoTrans,Y,Y,,,bias_multiplier_,b,,Y,& context_)', '    Set(batch_size,,bias_multiplier_,& context_)', '    RunOnDevice', '    Tensor', '    TTLinearGradientOp(Args,...)', '    ~TTLinearGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\tt_pad_op.cc', ['    GetTTPadGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUTTPad', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTPadGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTPad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTPadGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\experiments\\operators\\tt_pad_op.h', ['    final', '    final'], ['    RunOnDevice', '    RunOnDevice', '    TTPadGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    TTPadOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\tutorial_blob.cc', [], ['    main(int argc,char **argv)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\tvm_transformer.cc', ['    C10FlagParser_caffe2_tvm_min_ops', '    C10FlagParser_caffe2_tvm_profiling_based_jit'], ['    supported_ops', '    cleanUpPredictNet(NetDef *net,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names)', '    tvmTransform(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,size_t max_batch_size,size_t max_seq_size,bool debug)', '    C10FlagParser_caffe2_tvm_min_ops(const std::string & content)', '    C10FlagParser_caffe2_tvm_profiling_based_jit(const std::string & content)', '    applyTvmTransform(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    buildTvmOp(const caffe2::NetDef & net,const std::unordered_set & weights,const ShapeInfoMap & shape_hints)', '    canConvertFullGraph(const caffe2::NetDef & net,const std::unordered_set & blacklisted_ops)', '    getSupportedOps', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & input_shape_hints,const std::unordered_set & blacklisted_ops)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\opt\\tvm_transformer.h', ['    final'], ['    cleanUpPredictNet(NetDef *net,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names)', '    tvmTransform(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,size_t max_batch_size,size_t max_seq_size,bool debug)', '    canConvertFullGraph(const caffe2::NetDef & net,const std::unordered_set & blacklisted_ops)', '    getSupportedOps', '    applyTvmTransform(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    buildTvmOp(const caffe2::NetDef & net,const std::unordered_set & weights,const ShapeInfoMap & shape_hints)', '    profiling_based_jit', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    tvm_op_id_', '    TvmTransformer(const TvmTransformOptions & opts)', '    TvmTransformOptions', '    ~TvmTransformer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Type.cpp', [], ['    demangle(const char *name)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\type.cpp', [], ['    compatible_optional(c10::optional e,T a)', '    compatible_varying_shape(const VaryingShape & e,at::IntArrayRef a)', '    containsAny(const TypePtr & type)', '    operator<<(std::ostream & out,const Type & t)', '    VaryingShape', '    checkNoAny(const Type & base,const char *what,const std::string & attrname,const TypePtr & attrtype)', '    elementTypeCanBeInferredFromMembers(const TypePtr & elem_type)', '    is_module', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    matchTypeVariables(TypePtr formal,TypePtr actual,TypeEnv & type_env)', '    merge(const VaryingShape & other)', '    operator<<(std::ostream & out,const VaryingShape & vs)', '    tryEvalTypeVariables(TypePtr type,std::unordered_map & type_env)', '    typeKindToString(TypeKind kind)', '    unifyTypeList(at::ArrayRef elements,std::ostream & why_not)', '    unifyTypes(const TypePtr & t1,const TypePtr & t2)', '    get', '    get', '    get', '    get', '    get', '    get', '    addAttribute(const std::string & name,const TypePtr & type,bool is_parameter)', '    addConstant(const std::string & name,const IValue & value)', '    addMethod(torch::jit::Function *method)', '    checkNotExist(const std::string & name,const std::string & what)', '    ClassType(c10::optional name,std::weak_ptr cu,bool is_module)', '    compilation_unit', '    compilation_unit', '    create(c10::optional qualifiedName,std::weak_ptr cu,bool is_module)', '    findConstant(const std::string & name)', '    getConstant(const std::string & name)', '    getConstant(size_t slot)', '    getMethod(const std::string & name)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    methods', '    refine(at::ArrayRef refined_slots)', '    unsafeRemoveAttribute(const std::string & name)', '    unsafeRemoveConstant(const std::string & name)', '    unsafeRemoveMethod(const std::string & name)', '    get', '    get', '    FunctionType(torch::jit::Function *function)', '    get', '    addMethod(FunctionSchema schema)', '    create(QualifiedName qualifiedName,bool is_module)', '    getMethod(const std::string & name)', '    InterfaceType(QualifiedName name,bool is_module)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    get', '    get', '    isSubtypeOfExt(const TypePtr rhs_,std::ostream *why_not)', '    ofBools', '    ofFloats', '    ofInts', '    ofStrings', '    ofTensors', '    get', '    get', '    ofTensor', '    get', '    get', '    get', '    get', '    get', '    isCompatibleWithInCurrentExecutionContext(at::Tensor & t)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    merge(TensorTypePtr other)', '    str', '    createNamed(const c10::optional & qualName,const std::vector & field_names,const std::vector & field_types)', '    isSubtypeOfExt(const TypePtr rhs_,std::ostream *why_not)', '    operator==(const Type & rhs)', '    python_str', '    str', '    TupleType(std::vector elements,c10::optional name,std::shared_ptr schema)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\Type.h', [], ['    demangle(const char *name)', '    demangle_type']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\type_hashing.cpp', [], ['    operator()(const TypePtr & a,const TypePtr & b)', '    operator()(const TypePtr & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\ir\\type_hashing.h', [], ['    operator()(const TypePtr & a,const TypePtr & b)', '    operator()(const TypePtr & type)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\type_parser.cpp', ['    TypeParser'], ['    isSpecialChar(char a)', '    parseType(const std::string & pythonStr)', '    CreateSingleElementType', '    cur', '    expect(const std::string & s)', '    lex', '    next', '    parse', '    TypeParser(std::string pythonStr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\mobile\\type_parser.h', [], ['    parseType(const std::string & pythonStr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeCast.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\typed_axpy.cc', [], ['    TypedAxpy(int N,const float a,const float *x,float *y)', '    TypedAxpy(int N,const float a,const at::Half *x,float *y)', '    TypedAxpy(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpy__base(int N,const float a,const float *x,float *y)', '    TypedAxpy_uint8_float__base(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpyHalffloat__base(int N,const float a,const at::Half *x,float *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\typed_axpy.h', [], ['    TypedAxpy(int N,const OUT a,const IN *x,OUT *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\typed_axpy_avx.cc', [], ['    TypedAxpy__avx_f16c(int N,const float a,const float *x,float *y)', '    TypedAxpyHalffloat__avx_f16c(int N,const float a,const at::Half *x,float *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\perfkernels\\typed_axpy_avx2.cc', [], ['    TypedAxpy__avx2_fma(int N,const float a,const float *x,float *y)', '    TypedAxpy_uint8_float__avx2_fma(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpyHalffloat__avx2_fma(int N,const float a,const at::Half *x,float *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TypeDefault.cpp', [], ['    registerer', '    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TypeDefault.h', [], ['    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TypeDerived.cpp', [], ['    $legacy_th_headers', '    $', '    registerer']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\templates\\TypeDerived.h', [], ['    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\typeid.cpp', ['    final'], ['    _ThrowRuntimeTypeLogicError(const string & msg)', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\typeid.h', ['    final', '    final', '    final'], ['    _typeMetaDataInstance', '    Id', '    ItemSize', '    Make', '    TypeName', '    _typeMetaDataInstance', '    copy', '    deleteFn', '    _Copy(const void *src,void *dst,size_t n)', '    _CopyNotAllowed(const void *,void *,size_t)', '    _Delete(void *ptr)', '    _makeTypeMetaDataInstance', '    _New', '    _NewNotDefault', '    _PickCopy', '    _PickCopy', '    _PickDelete', '    _PickNew', '    _PickNew', '    _PickPlacementDelete', '    _PickPlacementNew', '    _PickPlacementNew', '    _PlacementDelete(void *ptr,size_t n)', '    _PlacementNew(void *ptr,size_t n)', '    _PlacementNewNotDefault(void *,size_t)', '    id', '    itemsize', '    Match', '    name', '    newFn', '    placementDelete', '    placementNew', '    operator!=(const TypeMeta & lhs,const TypeMeta & rhs)', '    operator<(TypeIdentifier lhs,TypeIdentifier rhs)', '    operator<<(std::ostream & stream,caffe2::TypeIdentifier typeId)', '    operator<<(std::ostream & stream,caffe2::TypeMeta typeMeta)', '    operator==(const TypeMeta & lhs,const TypeMeta & rhs)', '    TypeMeta', '    Get', '    uninitialized', '    get_fully_qualified_type_name', '    TypeMetaData', '    TypeMetaData(size_t itemsize,New *newFn,PlacementNew *placementNew,Copy *copy,PlacementDelete *placementDelete,Delete *deleteFn,TypeIdentifier id,c10::string_view name)', '    operator=', '    TypeMeta', '    operator()(caffe2::TypeIdentifier x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\typeid.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\typeid_test.cpp', ['    ClassAllowAssignment', '    ClassNoAssignment', '    TypeMetaTestBar', '    TypeMetaTestFoo'], ['    TEST(TypeMetaTest,TypeMetaStatic)', '    TEST(TypeMetaTest,Names)', '    TEST(TypeMetaTest,TypeMeta)', '    TEST(TypeMetaTest,CtorDtorAndCopy)', '    TEST(TypeMetaTest,Float16IsNotUint16)', '    ClassAllowAssignment', '    ClassAllowAssignment(const ClassAllowAssignment & src)', '    ClassNoAssignment', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeIndex.h', [], ['    get_fully_qualified_type_name', '    extract(string_view prefix,string_view suffix,string_view str)', '    fully_qualified_type_name_impl', '    type_index_impl', '    get_type_index', '    operator<(type_index lhs,type_index rhs)', '    operator<<(std::ostream & stream,type_index typeId)', '    fully_qualified_type_name_impl', '    type_index(uint64_t checksum)', '    operator()(c10::util::type_index x)', '    logic_error']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\TypeIndex_test.cpp', ['    final'], ['    TEST(TypeIndex,FunctionArgumentsAndReturns)', '    TEST(TypeIndex,NestedName)', '    TEST(TypeIndex,NonTypeTemplateParameter)', '    TEST(TypeIndex,TopLevelName)', '    TEST(TypeIndex,TypeComputationsAreResolved)', '    TEST(TypeIndex,FunctionTypeComputationsAreResolved)', '    TEST(TypeIndex,TypeTemplateParameter)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\TypeInfo.cpp', [], ['    THPDTypeInfo_bits(THPDTypeInfo *self,void *)', '    THPFInfo_eps(THPFInfo *self,void *)', '    THPFInfo_max(THPFInfo *self,void *)', '    THPFInfo_min(THPFInfo *self,void *)', '    THPFInfo_tiny(THPFInfo *self,void *)', '    THPIInfo_max(THPFInfo *self,void *)', '    THPIInfo_min(THPFInfo *self,void *)', '    self', '    self', '    THPDTypeInfo_compare(THPDTypeInfo *a,THPDTypeInfo *b,int op)', '    THPDTypeInfo_init(PyObject *module)', '    THPFInfo_New(const at::ScalarType & type)', '    THPFInfo_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPFInfo_str(THPFInfo *self)', '    THPIInfo_New(const at::ScalarType & type)', '    THPIInfo_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPIInfo_str(THPIInfo *self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\TypeInfo.h', [], ['    THPDTypeInfo_init(PyObject *module)', '    THPFInfo_Check(PyObject *obj)', '    THPIInfo_Check(PyObject *obj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeList.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeList.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\TypeList_test.cpp', ['    MyClass', '    final', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass'], ['    TEST(TypeListTest,MapTypesToValues_members)', '    TEST(TypeListTest,MapTypesToValues_empty)', '    TEST(TypeListTest,MapTypesToValues_sametype)', '    TEST(TypeListTest,MapTypesToValues_differenttypes)', '    func', '    func', '    operator()(T)', '    operator()(T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TypeProperties.cpp', [], ['    combine_categories(ScalarType higher,ScalarType lower)', '    promote_skip_undefined(ScalarType a,ScalarType b)', '    _has_compatible_shallow_copy_type(const Tensor & self,const Tensor & from)', '    is_complex(const Tensor & self)', '    is_cuda(const Tensor & self)', '    is_distributed(const Tensor & self)', '    is_floating_point(const Tensor & self)', '    is_quantized(const Tensor & self)', '    is_signed(const Tensor & self)', '    is_sparse(const Tensor & self)', '    type_as(const Tensor & self,const Tensor & other)', '    update_result_type_state(const Tensor & tensor,const ResultTypeState & in_state)', '    can_cast(const at::ScalarType from,const at::ScalarType to)', '    promote_types(ScalarType type1,ScalarType type2)', '    tensors', '    tensors']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\TypeProperties.h', [], ['    update_result_type_state(const Tensor & tensor,const ResultTypeState & in_state)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\types.cc', [], ['    data_type_map', '    type_meta_map', '    DataTypeToTypeMeta(const TensorProto::DataType & dt)', '    TypeMetaToDataType(const TypeMeta & meta)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\types.cpp', [], ['    fromIValue(const at::IValue & ivalue)', '    fromIValues(std::vector values)', '    GloballyUniqueId(worker_id_t createdOn,local_id_t localId)', '    toIValue', '    toIValues', '    getAllowJitRRefPickle', '    operator!=(const GloballyUniqueId & other)', '    operator<<(std::ostream & os,GloballyUniqueId const & globalId)', '    operator==(const GloballyUniqueId & other)', '    JitRRefPickleGuard', '    ~JitRRefPickleGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Types.cpp', [], ['    getMiopenDataType(const at::Tensor & tensor)', '    miopen_version']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Types.cpp', [], ['    cudnn_version', '    getCudnnDataType(const at::Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\types.cpp', [], ['    to_string(const Dtype & dtype)', '    to_string(const ScalarType & type)', '    is_floating_point(const ScalarType & type)', '    is_integral(const ScalarType & type)', '    operator<<(std::ostream & stream,const Dtype & dtype)', '    operator<<(std::ostream & stream,const ScalarType & type)', '    ToDtype(ScalarType type)', '    byte_size', '    scalar_dtype', '    ToCppString']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\types.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\types.h', [], ['    DataTypeToTypeMeta(const TensorProto::DataType & dt)', '    fp16_type', '    fp16_type', '    GetDimFromOrderString(const std::string & str)', '    NameScopeSeparator', '    StringToStorageOrder(const string & str)', '    TypeMetaToDataType(const TypeMeta & meta)', '    static_assert(,)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Types.h', [], ['    cudnn_version', '    getCudnnDataType(const at::Tensor & tensor)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\Types.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\types.h', [], ['    getAllowJitRRefPickle', '    operator<<(std::ostream & os,GloballyUniqueId const & globalId)', '    fromIValue(const at::IValue &)', '    fromIValues(std::vector)', '    GloballyUniqueId(worker_id_t createdOn,local_id_t localId)', '    GloballyUniqueId', '    operator()(const GloballyUniqueId & key)', '    operator!=(const GloballyUniqueId & other)', '    operator=', '    operator==(const GloballyUniqueId & other)', '    SerializedPyObj(std::string,std::vector)', '    toIValue', '    toIValues', '    JitRRefPickleGuard', '    ~JitRRefPickleGuard']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\types.h', ['    Dtype', '    ScalarType'], ['    to_string(const Dtype & dtype)', '    to_string(const ScalarType & type)', '    BinaryOpDtype(Dtype op1_dtype,Dtype op2_dtype,ScalarType ret_type)', '    is_floating_point(const ScalarType & type)', '    is_integral(const ScalarType & type)', '    operator<<(std::ostream & stream,const Dtype & dtype)', '    operator<<(std::ostream & stream,const ScalarType & type)', '    promoteTypes(ScalarType a,ScalarType b)', '    promoteTypes(Dtype a,Dtype b)', '    ToDtype', '    ToDtype(ScalarType type)', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    promoteTypes', '    byte_size', '    Dtype(int8_t type)', '    Dtype(ScalarType type)', '    Dtype(int8_t type,int lanes)', '    Dtype(ScalarType type,int lanes)', '    Dtype(Dtype type,int lanes)', '    is_floating_point', '    is_integral', '    lanes', '    operator!=(const Dtype & other)', '    operator==(const Dtype & other)', '    scalar_dtype', '    scalar_type', '    ToCppString']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Types.h', [], ['    getMiopenDataType(const at::Tensor & tensor)', '    miopen_version']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\Types.hpp', ['    ReduceOp'], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeTraits.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\TypeTraits.h', [], ['    declval', '    static_assert(,LambdaType,)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\test\\util\\TypeTraits_test.cpp', ['    final', '    EqualityComparable', '    NotEqualityComparable', '    MyClass', '    Hashable', '    NotHashable', '    Double', '    Multiple', '    MyClass', '    Single', '    NotATypeCondition'], ['    final', '    operator==(const EqualityComparable &,const EqualityComparable &)', '    func', '    lambda', '    func', '    operator()', '    operator()(Args,...)', '    operator()(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\u8clamp.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\u8clamp.h', [], ['    pytorch_u8clamp_ukernel__neon(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8clamp_ukernel__sse2(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\u8lut32norm.cc', [], ['    TEST(U8LUT32NORM__SCALAR,n_eq_1)', '    TEST(U8LUT32NORM__SCALAR,small_n)', '    TEST(U8LUT32NORM__SCALAR,large_n)', '    TEST(U8LUT32NORM__SCALAR,n_eq_1_inplace)', '    TEST(U8LUT32NORM__SCALAR,small_n_inplace)', '    TEST(U8LUT32NORM__SCALAR,large_n_inplace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\u8lut32norm.h', [], ['    pytorch_u8lut32norm_ukernel__scalar(size_t n,const uint8_t *x,const uint32_t *t,uint8_t *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\u8maxpool.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\u8maxpool.h', [], ['    pytorch_u8maxpool_ukernel_16x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_16x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_sub16__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_sub16__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\u8rmax.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\u8rmax.h', [], ['    pytorch_u8rmax_ukernel__neon(size_t n,const uint8_t *x)', '    pytorch_u8rmax_ukernel__sse2(size_t n,const uint8_t *x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ulp2\\ulp.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUQConv', '    create2b1bConvState(Workspace *ws,const TensorCPU & W,const TensorCPU *b)', '    filterNormalization11(const TensorCPU & WQ,TensorCPU *WQN)', '    filterNormalizationL1(const TensorCPU & W,TensorCPU *WL1)', '    qconv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    qim2col(const ConvArgs & args,const TensorCPU & XQ,const TensorCPU & WQ,TensorCPU *XQcol)', '    qpad_zero(const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bConvGeneric(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bUnification(QConvState *state,size_t N,size_t C,const float *WQNVdata,const float *YQs0Vdata,const float *YQs1Vdata,size_t YQstride,float *Ydata,size_t Ystride,const float *bias)', '    signQuantize(const TensorCPU & X,TensorCPU *XQ)', '    uniformQuantize2b1b(const TensorCPU & X,const std::vector,float offset,float inter_center_distance)', '    QConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNHWC']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ulp2\\ulp.h', [], ['    create2b1bConvState(Workspace *ws,const TensorCPU & W,const TensorCPU *b)', '    divRoundUp(size_t x,size_t d)', '    filterNormalization11(const TensorCPU & WQ,TensorCPU *WQN)', '    filterNormalizationL1(const TensorCPU & W,TensorCPU *WL1)', '    qconv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    qim2col(const ConvArgs & args,const TensorCPU & XQ,const TensorCPU & WQ,TensorCPU *XQcol)', '    qpad_zero(const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bConvGeneric(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bUnification(QConvState *state,size_t N,size_t C,const float *WQNVdata,const float *YQs0Vdata,const float *YQs1Vdata,size_t YQstride,float *Ydata,size_t Ystride,const float *bias)', '    signQuantize(const TensorCPU & X,TensorCPU *XQ)', '    uniformQuantize2b1b(const TensorCPU & X,const std::vector,float offset,float inter_center_distance)', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    stride_h', '    stride_w', '    parallelFor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ulp2\\ulp_neon.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ulp2\\ulp_neon.h', [], ['    run2b1bConvNeon(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\ulp2\\ulp_test.cc', [], ['    ca(size_t pad,size_t stride)', '    conv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    ConvTest2b1b(int IC,int KH,int KW,int H,int W,int OC,int N,ConvArgs args)', '    gemmNT(int M,int N,int K,const float *A,const float *B,float *C)', '    gemmTest(int64_t M,int64_t N,int64_t)', '    genTensor0123(std::vector shape)', '    genTensor11(std::vector shape)', '    genTensorUniform11(std::vector shape)', '    qgemmNT(int M,int N,int K,const uint8_t *A,const uint8_t *B,float *C)', '    randInt(int a,int b)', '    TEST(QConv)', '    TEST(QConv)', '    TEST(QConv)', '    TEST(ULP,QPadZero)', '    TEST(QConv,GemmTest)', '    TEST(QConv,ConvTest)', '    rca']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\unary_fp16_fake_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUReluFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFakeFp16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSqrFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanhFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanhFakeFp16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SqrFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanhFakeFp16', '    CalcSigmoidByLUT(at::Half x)', '    CalcTanhByLUT(at::Half input)', '    CalcTanhByPolynomial(at::Half input)', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)', '    sig_lut', '    operator()(const int N,const float *X,float *Y,CPUContext *)', '    operator()(const int N,const float *X,float *Y,CPUContext *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\contrib\\fakelowp\\unary_fp16_fake_op.h', [], ['    operator()(const int N,const T *X,T *Y,Context *)', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    operator()(const int N,const T *X,T *Y,CPUContext *context)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\UnaryOps.cpp', [], ['    mkldnn_sigmoid(const Tensor & self)', '    mkldnn_sigmoid_(Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UnaryOps.cpp', [], ['    mvlgamma_check(const Tensor & self,int64_t p)', '    unary_op_impl(const Tensor & self,OutImpl & out_impl)', '    unary_op_impl_(Tensor & self,OutImpl & out_impl)', '    unary_op_impl_out(Tensor & result,const Tensor & self,Stub & stub)', '    _atan__cpu(Tensor & self)', '    _atan_out_cpu(Tensor & result,const Tensor & self)', '    _clamp__cpu(Tensor & self,optional min,optional max)', '    _clamp_max__cpu(Tensor & self,Scalar max)', '    _clamp_max_out_cpu(Tensor & result,const Tensor & self,Scalar max)', '    _clamp_min__cpu(Tensor & self,Scalar min)', '    _clamp_min_out_cpu(Tensor & result,const Tensor & self,Scalar min)', '    _clamp_out_cpu(Tensor & result,const Tensor & self,optional min,optional max)', '    _cos__cpu(Tensor & self)', '    _cos_out_cpu(Tensor & result,const Tensor & self)', '    _cosh__cpu(Tensor & self)', '    _cosh_out_cpu(Tensor & result,const Tensor & self)', '    _erf__cpu(Tensor & self)', '    _erf_out_cpu(Tensor & result,const Tensor & self)', '    _erfc__cpu(Tensor & self)', '    _erfc_out_cpu(Tensor & result,const Tensor & self)', '    _erfinv__cpu(Tensor & self)', '    _erfinv__cuda(Tensor & self)', '    _erfinv_out_cpu(Tensor & result,const Tensor & self)', '    _erfinv_out_cuda(Tensor & result,const Tensor & self)', '    _exp__cpu(Tensor & self)', '    _exp_out_cpu(Tensor & result,const Tensor & self)', '    _lgamma__cpu(Tensor & self)', '    _lgamma__cuda(Tensor & self)', '    _lgamma_out_cpu(Tensor & result,const Tensor & self)', '    _lgamma_out_cuda(Tensor & result,const Tensor & self)', '    _tan__cpu(Tensor & self)', '    _tan_out_cpu(Tensor & result,const Tensor & self)', '    _tanh__cpu(Tensor & self)', '    _tanh_out_cpu(Tensor & result,const Tensor & self)', '    abs(const Tensor & self)', '    abs_(Tensor & self)', '    abs_out(Tensor & result,const Tensor & self)', '    acos(const Tensor & self)', '    acos_(Tensor & self)', '    acos_out(Tensor & result,const Tensor & self)', '    angle(const Tensor & self)', '    angle_out(Tensor & result,const Tensor & self)', '    asin(const Tensor & self)', '    asin_(Tensor & self)', '    asin_out(Tensor & result,const Tensor & self)', '    atan(const Tensor & self)', '    bitwise_not(const Tensor & self)', '    bitwise_not_(Tensor & self)', '    bitwise_not_out(Tensor & result,const Tensor & self)', '    ceil(const Tensor & self)', '    ceil_(Tensor & self)', '    ceil_out(Tensor & result,const Tensor & self)', '    clamp(const Tensor & self,optional min,optional max)', '    clamp_max(const Tensor & self,Scalar max)', '    clamp_min(const Tensor & self,Scalar min)', '    conj(const Tensor & self)', '    conj_out(Tensor & result,const Tensor & self)', '    cos(const Tensor & self)', '    cosh(const Tensor & self)', '    digamma(const Tensor & self)', '    digamma_(Tensor & self)', '    digamma_out(Tensor & result,const Tensor & self)', '    erf(const Tensor & self)', '    erfc(const Tensor & self)', '    erfinv(const Tensor & self)', '    exp(const Tensor & self)', '    expm1(const Tensor & self)', '    expm1_(Tensor & self)', '    expm1_out(Tensor & result,const Tensor & self)', '    floor(const Tensor & self)', '    floor_(Tensor & self)', '    floor_out(Tensor & result,const Tensor & self)', '    frac(const Tensor & self)', '    frac_(Tensor & self)', '    frac_out(Tensor & result,const Tensor & self)', '    imag(const Tensor & self)', '    lgamma(const Tensor & self)', '    log(const Tensor & self)', '    log10(const Tensor & self)', '    log10_(Tensor & self)', '    log10_out(Tensor & result,const Tensor & self)', '    log1p(const Tensor & self)', '    log1p_(Tensor & self)', '    log1p_out(Tensor & result,const Tensor & self)', '    log2(const Tensor & self)', '    log2_(Tensor & self)', '    log2_out(Tensor & result,const Tensor & self)', '    log_(Tensor & self)', '    log_out(Tensor & result,const Tensor & self)', '    logical_not(const Tensor & self)', '    logical_not_(Tensor & self)', '    logical_not_out(Tensor & result,const Tensor & self)', '    mvlgamma(const Tensor & self,int64_t p)', '    mvlgamma_(Tensor & self,int64_t p)', '    neg(const Tensor & self)', '    neg_(Tensor & self)', '    neg_out(Tensor & result,const Tensor & self)', '    polygamma(int64_t n,const Tensor & self)', '    polygamma_(Tensor & self,int64_t n)', '    polygamma_out(Tensor & result,int64_t n,const Tensor & self)', '    real(const Tensor & self)', '    reciprocal(const Tensor & self)', '    reciprocal_(Tensor & self)', '    reciprocal_out(Tensor & result,const Tensor & self)', '    round(const Tensor & self)', '    round_(Tensor & self)', '    round_out(Tensor & result,const Tensor & self)', '    rsqrt(const Tensor & self)', '    rsqrt_(Tensor & self)', '    rsqrt_out(Tensor & result,const Tensor & self)', '    sigmoid(const Tensor & self)', '    sigmoid_(Tensor & self)', '    sigmoid_out(Tensor & result,const Tensor & self)', '    sign(const Tensor & self)', '    sign_(Tensor & self)', '    sign_out(Tensor & result,const Tensor & self)', '    sin(const Tensor & self)', '    sin_(Tensor & self)', '    sin_out(Tensor & result,const Tensor & self)', '    sinh(const Tensor & self)', '    sinh_(Tensor & self)', '    sinh_out(Tensor & result,const Tensor & self)', '    sqrt(const Tensor & self)', '    sqrt_(Tensor & self)', '    sqrt_out(Tensor & result,const Tensor & self)', '    square(const Tensor & self)', '    square_(Tensor & self)', '    tan(const Tensor & self)', '    tanh(const Tensor & self)', '    trunc(const Tensor & self)', '    trunc_(Tensor & self)', '    trunc_out(Tensor & result,const Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UnaryOps.h', [], ['    abs_stub', '    abs_stub', '    operator=', '    acos_stub', '    acos_stub', '    operator=', '    angle_stub', '    angle_stub', '    operator=', '    asin_stub', '    asin_stub', '    operator=', '    atan_stub', '    atan_stub', '    operator=', '    bernoulli_mkl_stub', '    bernoulli_mkl_stub', '    operator=', '    bitwise_not_stub', '    bitwise_not_stub', '    operator=', '    cauchy_stub', '    cauchy_stub', '    operator=', '    ceil_stub', '    ceil_stub', '    operator=', '    clamp_max_stub', '    clamp_max_stub', '    operator=', '    clamp_min_stub', '    clamp_min_stub', '    operator=', '    clamp_stub', '    clamp_stub', '    operator=', '    conj_stub', '    conj_stub', '    operator=', '    cos_stub', '    cos_stub', '    operator=', '    cosh_stub', '    cosh_stub', '    operator=', '    digamma_stub', '    digamma_stub', '    operator=', '    erf_stub', '    erf_stub', '    operator=', '    erfc_stub', '    erfc_stub', '    operator=', '    erfinv_stub', '    erfinv_stub', '    operator=', '    exp_stub', '    exp_stub', '    operator=', '    expm1_stub', '    expm1_stub', '    operator=', '    exponential_stub', '    exponential_stub', '    operator=', '    floor_stub', '    floor_stub', '    operator=', '    frac_stub', '    frac_stub', '    operator=', '    geometric_stub', '    geometric_stub', '    operator=', '    imag_stub', '    imag_stub', '    operator=', '    lgamma_stub', '    lgamma_stub', '    operator=', '    log10_stub', '    log10_stub', '    operator=', '    log1p_stub', '    log1p_stub', '    operator=', '    log2_stub', '    log2_stub', '    operator=', '    log_normal_stub', '    log_normal_stub', '    operator=', '    log_stub', '    log_stub', '    operator=', '    logical_not_stub', '    logical_not_stub', '    operator=', '    multinomial_stub', '    multinomial_stub', '    operator=', '    neg_stub', '    neg_stub', '    operator=', '    normal_stub', '    normal_stub', '    operator=', '    operator=', '    polygamma_stub', '    polygamma_stub', '    operator=', '    random_from_to_stub', '    random_from_to_stub', '    operator=', '    random_full_64_bits_range_stub', '    random_full_64_bits_range_stub', '    operator=', '    random_stub', '    random_stub', '    operator=', '    real_stub', '    real_stub', '    operator=', '    reciprocal_stub', '    reciprocal_stub', '    operator=', '    round_stub', '    round_stub', '    operator=', '    rsqrt_stub', '    rsqrt_stub', '    operator=', '    sigmoid_stub', '    sigmoid_stub', '    operator=', '    sign_stub', '    sign_stub', '    operator=', '    sin_stub', '    sin_stub', '    operator=', '    sinh_stub', '    sinh_stub', '    operator=', '    sqrt_stub', '    sqrt_stub', '    operator=', '    tan_stub', '    tan_stub', '    operator=', '    tanh_stub', '    tanh_stub', '    operator=', '    trigamma_stub', '    trigamma_stub', '    operator=', '    trunc_stub', '    trunc_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\UnaryOpsKernel.cpp', [], ['    abs_kernel(TensorIterator & iter)', '    acos_kernel(TensorIterator & iter)', '    angle_kernel(TensorIterator & iter)', '    bitwise_not_kernel(TensorIterator & iter)', '    cauchy_kernel(TensorIterator & iter,double median,double sigma,Generator gen)', '    clamp_kernel(TensorIterator & iter,Scalar min_scalar,Scalar max_scalar)', '    clamp_max_kernel(TensorIterator & iter,Scalar max_scalar)', '    clamp_min_kernel(TensorIterator & iter,Scalar min_scalar)', '    conj_kernel(TensorIterator & iter)', '    cosh_kernel(TensorIterator & iter)', '    digamma_kernel(TensorIterator & iter)', '    exponential_kernel(TensorIterator & iter,double lambda,Generator gen)', '    frac_kernel(TensorIterator & iter)', '    geometric_kernel(TensorIterator & iter,double p,Generator gen)', '    imag_kernel(TensorIterator & iter)', '    log_normal_kernel(TensorIterator & iter,double mean,double std,Generator gen)', '    logical_not_kernel(TensorIterator & iter)', '    neg_kernel(TensorIterator & iter)', '    polygamma_kernel(TensorIterator & iter,int64_t n)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,Generator gen)', '    random_full_64_bits_range_kernel(TensorIterator & iter,Generator gen)', '    random_kernel(TensorIterator & iter,Generator gen)', '    real_kernel(TensorIterator & iter)', '    reciprocal_kernel(TensorIterator & iter)', '    rsqrt_kernel(TensorIterator & iter)', '    sigmoid_kernel(TensorIterator & iter)', '    sign_kernel(TensorIterator & iter)', '    sinh_kernel(TensorIterator & iter)', '    trigamma_kernel(TensorIterator & iter)', '    abs_impl(T v)', '    abs_impl(uint8_t v)', '    bernoulli_mkl_kernel(Tensor & self,const double p,Generator gen)', '    normal_kernel(Tensor & self,double mean,double std,Generator gen)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\undef_macros.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\undefined_tensor_test.cpp', [], ['    TEST(TestUndefined,UndefinedTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\UndefinedTensorImpl.cpp', [], ['    dim', '    has_storage', '    size(int64_t d)', '    sizes', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    UndefinedTensorImpl']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\UndefinedTensorImpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\UndefinedTensorImpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Unfold2d.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\Unfold2d.cpp', [], ['    cadd(scalar_t *z,const scalar_t *x,const scalar_t *y,int64_t n)', '    unfolded2d_acc(scalar_t *finput_data,scalar_t *input_data,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_copy(scalar_t *input_data,scalar_t *finput_data,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_acc_kernel(Tensor & finput,Tensor & input,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_copy_kernel(Tensor & finput,Tensor & input,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Unfold2d.h', [], ['    operator=', '    unfolded2d_acc_stub', '    unfolded2d_acc_stub', '    operator=', '    unfolded2d_copy_stub', '    unfolded2d_copy_stub']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Unfold3d.cpp', [], ['    IsAGeZeroAndALtB(int64_t a,int64_t b)', '    MatAdd(int64_t M,int64_t N,int64_t ldx,int64_t ldy,const T *X,T *Y)', '    MatAdd(int64_t M,int64_t N,int64_t ldx,int64_t stridex,int64_t ldy,int64_t stridey,const T *X,T *Y)', '    MatCopy(int64_t M,int64_t N,int64_t lda,int64_t ldb,const T *A,T *B)', '    MatCopy(int64_t M,int64_t N,int64_t lda,int64_t stridea,int64_t ldb,int64_t strideb,const T *A,T *B)', '    Unfold3dAccCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dAccKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,const T *src,T *dst)', '    Unfold3dCopyCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dCopyKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,const T *src,T *dst)', '    Unfold3dZeroPaddingAccKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,const T *src,T *dst)', '    Unfold3dZeroPaddingCopyKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,const T *src,T *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Unfold3d.h', [], ['    Unfold3dAccCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dCopyCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\Unique.cpp', [], ['    _unique2_cpu(const Tensor & self,const bool sorted,const bool return_inverse,const bool return_counts)', '    _unique_cpu(const Tensor & self,const bool sorted,const bool return_inverse)', '    _unique_dim_cpu_impl(ForwardIt first,ForwardIt last,std::vector & indices,Tensor inverse_indices_vec,Tensor counts)', '    _unique_dim_cpu_template(const Tensor & self,const int64_t dim,const bool consecutive,const bool return_inverse,const bool return_counts)', '    unique_consecutive_cpu_template(const Tensor & self,const bool return_inverse,const bool return_counts)', '    unique_cpu_template(const Tensor & self,const bool sorted,const bool return_inverse,const bool return_counts)', '    unique_consecutive_cpu(const Tensor & self,const bool return_inverse,const bool return_counts,c10::optional dim)', '    unique_dim_consecutive_cpu(const Tensor & self,const int64_t dim,const bool return_inverse,const bool return_counts)', '    unique_dim_cpu(const Tensor & self,const int64_t dim,const bool sorted,const bool return_inverse,const bool return_counts)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\unique_name_manager.cpp', [], ['    get_unique_name(const VarHandle & v)', '    get_unique_name(const Var *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\tensorexpr\\unique_name_manager.h', ['    UniqueNameManager'], ['    get_unique_name(const VarHandle & v)', '    get_unique_name(const Var *v)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\unique_ops.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUUnique', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Unique', '    DoRunWithType']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\unique_ops.h', ['    UniqueOp'], ['    cuda_order_buffer_', '    DoRunWithType', '    RunOnDevice', '    second_order_buffer_', '    UniqueOp(Args,...)', '    ~UniqueOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\UniqueVoidPtr.cpp', [], ['    deleteNothing(void *)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\UniqueVoidPtr.h', ['    UniqueVoidPtr'], ['    cast_context(DeleterFnPtr expected_deleter)', '    compare_exchange_deleter(DeleterFnPtr expected_deleter,DeleterFnPtr new_deleter)', '    deleteNothing(void *)', '    get_deleter', '    operator bool', '    operator!=(const UniqueVoidPtr & sp,std::nullptr_t)', '    operator!=(std::nullptr_t,const UniqueVoidPtr & sp)', '    operator==(const UniqueVoidPtr & sp,std::nullptr_t)', '    operator==(std::nullptr_t,const UniqueVoidPtr & sp)', '    clear', '    get', '    get_context', '    operator->', '    release_context', '    UniqueVoidPtr', '    UniqueVoidPtr(void *data)', '    UniqueVoidPtr(void *data,void *ctx,DeleterFnPtr ctx_deleter)', '    unique_ptr']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\unpack_quantized_weights.cpp', [], ['    insertPermutes(std::shared_ptr & graph,std::map & paramsDict)', '    callOpUnboxed(const c10::OperatorHandle & op,Args,...)', '    CreateQuantizedBias(std::vector data,std::shared_ptr & graph,std::vector shapes,double scale,int64_t zero_point)', '    CreateQuantizedWeights(std::string data,std::shared_ptr & graph,std::vector shapes,double scale,int64_t zero_point)', '    getScaleFromInput(Node *input_node)', '    insertPermutesHelper(std::shared_ptr & graph,std::map & paramsDict,const std::string & pattern)', '    UnpackQuantizedWeights(std::shared_ptr & graph,std::map & paramsDict)', '    unpackQuantizedWeightsHelper(std::shared_ptr & graph,std::map & paramsDict,const std::string & pattern,const std::string & unpack_fn)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\onnx\\unpack_quantized_weights.h', [], ['    insertPermutes(std::shared_ptr & graph,std::map & paramsDict)', '    UnpackQuantizedWeights(std::shared_ptr & graph,std::map & paramsDict)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\unpickled_python_call.cpp', [], ['    movePythonUdf', '    toMessageImpl', '    UnpickledPythonCall(const SerializedPyObj & serializedPyObj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\unpickled_python_call.h', ['    UnpickledPythonCall'], ['    movePythonUdf', '    toMessageImpl', '    UnpickledPythonCall(const SerializedPyObj & serializedPyObj)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\unpickled_python_remote_call.cpp', [], ['    forkId', '    rrefId', '    UnpickledPythonRemoteCall(const SerializedPyObj & serializedPyObj,const at::IValue & rrefId,const at::IValue & forkId)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\unpickled_python_remote_call.h', ['    final'], ['    forkId', '    rrefId', '    UnpickledPythonRemoteCall(const SerializedPyObj & serializedPyObj,const at::IValue & retRRefId,const at::IValue & retForkId)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\unpickler.cpp', [], ['    convertList(const IValue & v)', '    restoreAccurateTypeTagsIfPossible(const IValue & root)', '    tupleToIntList(const IValue & v)', '    is_valid_python_id_char(char c)', '    append(std::vector & a,T)', '    append(std::vector & a,bool)', '    restoreAccurateTypeTags(const IValue & root,const TypePtr & type_tag)', '    restoreContainerTypeTags(IValue & ivalue,TypePtr type)', '    parse_ivalue', '    readBytes(size_t length)', '    readFloat', '    readGlobal(const std::string & module_name,const std::string & class_name)', '    readInstruction', '    readList(IValue list_ivalue)', '    readSlowWithBuffer(char *dest,size_t sz)', '    readString', '    rebuildTensor(bool quantized)', '    run', '    setInput(size_t memo_id)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\serialization\\unpickler.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\UnsafeFromTH.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\sdwconv\\up4x9-psimd.c', [], ['    pytorch_sdwconv_ukernel_up4x9__psimd(size_t channels,size_t output_width,const float **input,const float *weights,float *output,size_t input_stride,size_t output_increment,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\up8x7-neon.c', [], ['    pytorch_q8gavgpool_ukernel_up8x7__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\up8x7-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\up8x7-sse2.c', [], ['    pytorch_q8gavgpool_ukernel_up8x7__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\up8x7-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\up8x9-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8dwconv\\up8x9-neon.c', [], ['    pytorch_q8dwconv_ukernel_up8x9__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\up8x9-neon.c', [], ['    pytorch_q8avgpool_ukernel_up8x9__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8dwconv\\up8x9-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8dwconv\\up8x9-sse2.c', [], ['    pytorch_q8dwconv_ukernel_up8x9__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\up8x9-sse2.c', [], ['    pytorch_q8avgpool_ukernel_up8x9__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8dwconv\\up8x9-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\up8x9-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\up8xm-neon.c', [], ['    pytorch_q8gavgpool_ukernel_up8xm__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\up8xm-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\up8xm-neon.c', [], ['    pytorch_q8avgpool_ukernel_up8xm__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\up8xm-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8avgpool\\up8xm-sse2.c', [], ['    pytorch_q8avgpool_ukernel_up8xm__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8avgpool\\up8xm-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\q8gavgpool\\up8xm-sse2.c', [], ['    pytorch_q8gavgpool_ukernel_up8xm__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\q8gavgpool\\up8xm-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\update_graph_executor_opt.cpp', [], ['    getGraphExecutorOptimize', '    setGraphExecutorOptimize(bool o)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\python\\update_graph_executor_opt.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSample.h', [], ['    area_pixel_compute_scale(int64_t input_size,int64_t output_size,bool align_corners,const c10::optional scale)', '    area_pixel_compute_source_index(scalar_t scale,int64_t dst_index,bool align_corners,bool cubic)', '    compute_scales_value(const c10::optional scale,int64_t input_size,int64_t output_size)', '    cubic_convolution1(scalar_t x,scalar_t A)', '    cubic_convolution2(scalar_t x,scalar_t A)', '    cubic_interp1d(scalar_t x0,scalar_t x1,scalar_t x2,scalar_t x3,scalar_t)', '    get_cubic_upsample_coefficients(scalar_t [4] coeffs,scalar_t)', '    nearest_neighbor_compute_source_index(const float scale,int64_t dst_index,int64_t input_size)', '    upsample_1d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_width,int64_t output_width)', '    upsample_2d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    upsample_3d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width)', '    upsample_get_value_bounded(scalar_t *data,int64_t width,int64_t height,int64_t x,int64_t y)', '    upsample_increment_value_bounded(scalar_t *data,int64_t width,int64_t height,int64_t x,int64_t y,scalar_t value)', '    operator=', '    upsample_nearest1d_backward_kernel', '    upsample_nearest1d_backward_kernel', '    operator=', '    upsample_nearest1d_kernel', '    upsample_nearest1d_kernel', '    operator=', '    upsample_nearest2d_backward_kernel', '    upsample_nearest2d_backward_kernel', '    operator=', '    upsample_nearest2d_kernel', '    upsample_nearest2d_kernel', '    operator=', '    upsample_nearest3d_backward_kernel', '    upsample_nearest3d_backward_kernel', '    operator=', '    upsample_nearest3d_kernel', '    upsample_nearest3d_kernel', '    has_value', '    value']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\upsample_nearest_op.cc', ['    GetUpsampleNearestGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleNearest', '    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleNearestGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleNearestGradient', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\modules\\detectron\\upsample_nearest_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    UpsampleNearestGradientOp(const OperatorDef & def,Workspace *ws)', '    UpsampleNearestOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\upsample_op.cc', ['    GetUpsampleBilinearGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleBilinear', '    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleBilinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleBilinear', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleBilinearGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\upsample_op.h', ['    final', '    final'], ['    GetSingleArgument', '    RunOnDevice', '    UpsampleBilinearGradientOp(Args,...)', '    UpsampleBilinearOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleBicubic2d.cpp', [], ['    upsample_bicubic2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleBilinear2d.cpp', [], ['    upsample_bilinear2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\UpSampleKernel.cpp', [], ['    nearest_idx(int64_t output_index,int64_t input_size,int64_t output_size,c10::optional scales)', '    cpu_upsample_nearest(Tensor & output_,const Tensor & input_,const scale_type & scales)', '    cpu_upsample_nearest_backward(Tensor & grad_input_,const Tensor & grad_output_,const scale_type & scales)', '    cpu_upsample_nearest_channels_last(Tensor & output_,const Tensor & input_,const scale_type & scales)', '    data_index_init(T offset)', '    data_index_init(T offset,T & x,const T & X,Args,...)', '    data_index_step', '    data_index_step(T & x,const T & X,Args,...)', '    upsample_nearest1d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_w)', '    upsample_nearest1d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_w)', '    upsample_nearest2d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleLinear1d.cpp', [], ['    upsample_linear1d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_width,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_width,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleNearest1d.cpp', [], ['    upsample_nearest1d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales)', '    upsample_nearest1d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales)', '    upsample_nearest1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleNearest2d.cpp', [], ['    upsample_nearest2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleNearest3d.cpp', [], ['    upsample_nearest3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\UpSampleTrilinear3d.cpp', [], ['    upsample_trilinear3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\modules\\upsampling.cpp', [], ['    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    UpsampleImpl(const UpsampleOptions & options_)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\upsampling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\upsampling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\upsampling.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\utility_dnnlowp_ops.cc', [], ['    GatherDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\quantization\\server\\utility_dnnlowp_ops.h', ['    final', '    final'], ['    ElementWiseSumAVX2(const T *input0,const T *input1,T *output,int len,float a_scale,int32_t a_zero_point,float b_scale,int32_t b_zero_point,float c_scale,int32_t c_zero_point)', '    arguments_parsed_', '    dequantize_output_', '    DoRunWithType', '    Fp32Op_', '    GatherDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    measure_quantization_error_', '    RunOnDevice', '    static_assert(std::is_integral,)', '    SumDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ~GatherDNNLowPOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\ideep\\operators\\utility_ops.cc', ['    final', '    final', '    final', '    IDEEPWeightedSumOp'], ['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyCPUToIDEEP', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyIDEEPToCPU', '    CopyCPUToIDEEPOp(const OperatorDef & operator_def,Workspace *ws)', '    CopyIDEEPToCPUOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPCopyOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~CopyCPUToIDEEPOp', '    ~CopyIDEEPToCPUOp', '    ~IDEEPCopyOp', '    IDEEPWeightedSumOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\utility_ops.cc', ['    GetEnsureDenseGradient', '    GetAliasGradient', '    GetSumGradient', '    GetWeightedSumGradient'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUAccumulateHistogram', '    CAFFE_ANONYMOUS_VARIABLE_CPUAlias', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureDense', '    CAFFE_ANONYMOUS_VARIABLE_CPUFlattenToVec', '    CAFFE_ANONYMOUS_VARIABLE_CPUGatherRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPUHasElements', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsGather', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToSegmentIds', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToShape', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToWeights', '    CAFFE_ANONYMOUS_VARIABLE_CPUPrint', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeLike', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatter', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatterAssign', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatterWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentIdsToLengths', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentIdsToRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumInt', '    CAFFE_ANONYMOUS_VARIABLE_CPUWallClockTime', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUFail', '    CAFFE_ANONYMOUS_VARIABLE_CPUIsNaN', '    CAFFE_ANONYMOUS_VARIABLE_CPULogFatal', '    CAFFE_ANONYMOUS_VARIABLE_CPUNanCheck', '    CAFFE_ANONYMOUS_VARIABLE_CPURange', '    CAFFE_ANONYMOUS_VARIABLE_CPUSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUThrowChildThreadException', '    CAFFE_ANONYMOUS_VARIABLE_CPUThrowException', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AccumulateHistogram', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Alias', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlattenToVec', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HasElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToSegmentIds', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToShape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToWeights', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Print', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeLike', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Scatter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScatterAssign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScatterWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentIdsToLengths', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentIdsToRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumInt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WallClockTime', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSumGradient', '    CostInferenceForWeightedSum(const OperatorDef &,const vector & in)', '    WeightedSumShapeInference(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fail', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsNaN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LogFatal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NanCheck', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Range', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Size', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThrowChildThreadException', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThrowException', '    inputs', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    DoRunOnDevice(const T & start,const T & step,Tensor *output)', '    RunOnDevice', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\utility_ops.h', ['    AccumulateHistogramOp', '    final', '    FailOp', '    final', '    final', '    final', '    final', '    final', '    FlattenToVecOp', '    GatherRangesOp', '    HasElementsOp', '    LengthsGatherOp', '    LengthsToRangesOp', '    LengthsToSegmentIdsOp', '    LengthsToShapeOp', '    LengthsToWeightsOp', '    LogFatalOp', '    RangeOp', '    ResizeLikeOp', '    ScatterAssignOp', '    ScatterOp', '    ScatterWeightedSumOp', '    SegmentIdsToLengthsOp', '    SegmentIdsToRangesOp', '    SizeOp', '    SumOp', '    ThrowChildThreadExceptionOp', '    ThrowExceptionOp', '    WeightedSumGradientOp', '    WeightedSumOp'], ['    CostInferenceForSum(const OperatorDef & def,const std::vector & in)', '    check_indexarray_range(const IndexType *indices,int64_t n,IndexType indexing_axis_dim)', '    AccumulateHistogramOp(Args,...)', '    RunOnDevice', '    NanCheckOp(Args,...)', '    RunOnDevice', '    GetGradientDefs', '    duration_cast', '    FailOp(Args,...)', '    RunOnDevice', '    AliasOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    EnsureDenseOp(Args,...)', '    InputIsTensorType', '    IsNanOp(const OperatorDef & operator_def,Workspace *ws)', '    occurrences_mod_n_', '    PrintOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    WallClockTimeOp(Args,...)', '    ~AliasOp', '    ~EnsureDenseOp', '    FlattenToVecOp(Args,...)', '    RunOnDevice', '    ~FlattenToVecOp', '    accumulate(Index *ranges,size_t start,size_t end)', '    DoRunWithType', '    GatherRangesOp(Args,...)', '    RunOnDevice', '    ~GatherRangesOp', '    HasElementsOp(Args,...)', '    RunOnDevice', '    ~HasElementsOp', '    now', '    DoRunWithType', '    LengthsGatherOp(Args,...)', '    RunOnDevice', '    ~LengthsGatherOp', '    LengthsToRangesOp(Args,...)', '    RunOnDevice', '    ~LengthsToRangesOp', '    LengthsToSegmentIdsOp(Args,...)', '    RunOnDevice', '    ~LengthsToSegmentIdsOp', '    LengthsToShapeOp(Args,...)', '    RunOnDevice', '    ~LengthsToShapeOp', '    DoRunWithType', '    LengthsToWeightsOp(Args,...)', '    RunOnDevice', '    LogFatalOp(Args,...)', '    RunOnDevice', '    Add', '    Axpby', '    Axpy', '    AxpyFixedSize', '    Dot', '    Scale', '    ScaleFixedSize', '    Set', '    dim', '    numel', '    size', '    size_from_dim', '    sizes', '    DoRunOnDevice(const T & start,const T & step,Tensor *output)', '    DoRunWithType', '    local_', '    RangeOp(Args,...)', '    readScalarInput(const int index)', '    RunOnDevice', '    ~RangeOp', '    ResizeLikeOp(Args,...)', '    RunOnDevice', '    ~ResizeLikeOp', '    DoRun', '    DoScatterAssign(T *data,const Index *idxs,const T *slicesData,int64_t N,int64_t K,int64_t block_size)', '    GetRunner(const TensorProto_DataType dataType,const TensorProto_DataType slicesType,const TensorProto_DataType indicesType)', '    RunOnDevice', '    ScatterAssignOp(Args,...)', '    ~ScatterAssignOp', '    DoRunWithType', '    RunOnDevice', '    ScatterOp(Args,...)', '    ~ScatterOp', '    DoRunWithType', '    DoRunWithValue', '    RunOnDevice', '    ScatterWeightedSumOp(Args,...)', '    ~ScatterWeightedSumOp', '    DoRunWithType', '    RunOnDevice', '    SegmentIdsToLengthsOp(Args,...)', '    ~SegmentIdsToLengthsOp', '    DoRunWithType', '    RunOnDevice', '    SegmentIdsToRangesOp(Args,...)', '    ~SegmentIdsToRangesOp', '    RunOnDevice', '    SizeOp(Args,...)', '    ~SizeOp', '    DoRunWithType', '    RunOnDevice', '    SumOp(Args,...)', '    ~SumOp', '    RunOnDevice', '    ThrowChildThreadExceptionOp(Args,...)', '    RunOnDevice', '    ThrowExceptionOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    WeightedSumGradientOp(Args,...)', '    DoRunWithType', '    InputSize', '    RunOnDevice', '    WeightedSumOp(Args,...)', '    ~WeightedSumOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\utility_ops_gpu_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(UtilityOpGPUTest,testReshapeWithScalar)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\utility_ops_test.cc', [], ['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(UtilityOpTest,testReshapeWithScalar)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\utils.cc', [], ['    CheckReduceDims(const int ndim,const int *X_dims,const int *Y_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const std::int32_t *A_dims,const int B_ndim,const std::int32_t *B_dims,std::int32_t *A_broadcast_dims,std::int32_t *B_broadcast_dims,std::int32_t *C_broadcast_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const std::int64_t *A_dims,const int B_ndim,const std::int64_t *B_dims,std::int64_t *A_broadcast_dims,std::int64_t *B_broadcast_dims,std::int64_t *C_broadcast_dims)', '    ComputeTransposeAxesForReduceOp(const int num_dims,const int num_reduce_axes,const int *reduce_axes,int *transpose_axes)', '    ComputeTransposeAxesForReduceOp(const int ndim,const int *dims,int *axes)', '    ComputeTransposedStrides(const int ndim,const std::int32_t *dims,const int *axes,std::int32_t *strides)', '    ComputeTransposedStrides(const int ndim,const std::int64_t *dims,const int *axes,std::int64_t *strides)', '    GetIndexFromDims(const int n,const std::int32_t *dims,const std::int32_t *index)', '    GetIndexFromDims(const int n,const std::int64_t *dims,const std::int64_t *index)', '    IncreaseIndexInDims(const int ndim,const std::int32_t *dims,std::int32_t *index)', '    IncreaseIndexInDims(const int ndim,const std::int64_t *dims,std::int64_t *index)', '    IsBatchTranspose2D(const int ndim,const int *axes)', '    IsBothEndsBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt,bool *broadcast_1st)', '    IsBothEndsReduce(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt)', '    IsColwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsColwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    IsIdentityPermutation(const int n,const int *perm)', '    IsRowwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsRowwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\utils.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\utils.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\utils.cpp', [], ['    check_input_variables(const char *name,const variable_list & inputs,int args,int required_args)', '    wrap_outputs(const variable_list & inputs,tensor_list,const function_constructor & ctr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Utils.cpp', [], ['    pool_output_sizes(IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding_l,IntArrayRef padding_r,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils.cpp', [], ['    classOrTypename(PyObject *obj)', '    getBackCompatBroadcastWarn', '    getBackCompatKeepdimWarn', '    maybeThrowBackCompatKeepdimWarn(char *func)', '    setBackCompatBroadcastWarn(bool warn)', '    setBackCompatKeepdimWarn(bool warn)', '    THPUtils_addPyMethodDefs(std::vector & vector,PyMethodDef *methods)', '    THPUtils_checkIntTuple(PyObject *arg)', '    THPUtils_dispatchStateless(PyObject *tensor,const char *name,PyObject *args,PyObject *kwargs)', '    THPUtils_getCallable(PyObject *arg,PyObject **result)', '    THPUtils_invalidArguments(PyObject *given_args,PyObject *given_kwargs,const char *function_name,size_t num_options,...)', '    THPUtils_setError(const char *format,...)', '    THPUtils_tryUnpackLongs(PyObject *arg,THLongStoragePtr & result)', '    THPUtils_tryUnpackLongVarArgs(PyObject *args,int ignore_first,THLongStoragePtr & result)', '    THPUtils_unpackIntTuple(PyObject *arg)', '    THPUtils_unpackLongs(PyObject *arg)', '    THPUtils_unpackSize(PyObject *arg)', '    free', '    free', '    free']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\utils.cpp', [], ['    cloneSparseTensors(const std::vector & tensors)', '    metaDataReadFunc', '    sectionReadFunc', '    deserializeRequest(const Message & request)', '    deserializeResponse(const Message & response,MessageType & wrappedMsgType)', '    deserializeRespToIValue(const Message & message)', '    deserializeResptoIValueInternal(RpcCommandBase & rpc,MessageType messageType)', '    wireSerialize(const std::vector & payload,const std::vector & tensors)', '    worthRecopying']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\utils.cpp', [], ['    addRecvRpcBackward(const AutogradMetadata & autogradMetadata,std::vector & tensors,rpc::worker_id_t fromWorkerId)', '    addSendRpcBackward(const ContextPtr & autogradContext,const AutogradMetadata & autogradMetadata,std::vector & tensors)', '    getMessageWithAutograd(const rpc::worker_id_t dstId,torch::distributed::rpc::Message,MessageType msgType,bool forceGradRecording)', '    sendMessageWithAutograd(RpcAgent & agent,const WorkerInfo & dst,torch::distributed::rpc::Message,bool forceGradRecording,const std::shared_ptr & rf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\utils.cpp', [], ['    helper(const Tensor & self)', '    global_helper_call_AA_op_1(const Tensor & self)', '    global_helper_call_AA_op_2(const Tensor & self)', '    global_helper_call_AA_op_3(const Tensor & self)', '    lambda', '    lambda']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\Utils.cpp', [], ['    accept(int listenSocket,const std::chrono::milliseconds & timeout)', '    connect(const std::string & address,PortType port,bool wait,const std::chrono::milliseconds & timeout)', '    getSocketPort(int fd)', '    handleConnectException(struct ::addrinfo **nextAddr,int error_code,bool *anyRefused,bool *anyReset,bool wait,std::chrono::time_point start,std::shared_ptr addresses,std::chrono::milliseconds timeout)', '    handleConnectSystemError(struct ::addrinfo **nextAddr,std::system_error & e,bool *anyRefused,bool *anyReset,bool wait,std::chrono::time_point start,std::shared_ptr addresses,std::chrono::milliseconds timeout)', '    listen(PortType port)', '    setSocketNoDelay(int socket)', '    sockaddrToString(struct ::sockaddr *addr)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Utils.cpp', [], ['    _crash_if_asan(int arg)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\math\\utils.h', [], ['    DivUp(const T a,const T b)', '    IntegerLog2(T n,int p)', '    IntegerNextHighestPowerOf2(T v)', '    RoundUp(const T a,const T b)', '    CheckReduceDims(const int ndim,const int *X_dims,const int *Y_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const TIndex *A_dims,const int B_ndim,const TIndex *B_dims,TIndex *A_broadcast_dims,TIndex *B_broadcast_dims,TIndex *C_broadcast_dims)', '    ComputeTransposeAxesForReduceOp(const int num_dims,const int num_reduce_axes,const int *reduce_axes,int *transpose_axes)', '    ComputeTransposeAxesForReduceOp(const int ndim,const int *dims,int *axes)', '    ComputeTransposedStrides(int ndim,const TIndex *dims,const int *axes,TIndex *strides)', '    Cube(const T x)', '    GetIndexFromDims(const int n,const TIndex *dims,const TIndex *index)', '    IncreaseIndexInDims(int ndim,const TIndex *dims,TIndex *index)', '    Inv(const T x)', '    IsAGeZeroAndALtB(const int a,const int b)', '    IsBatchTranspose2D(const int ndim,const int *axes)', '    IsBothEndsBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt,bool *broadcast_1st)', '    IsBothEndsReduce(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt)', '    IsColwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsColwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    IsIdentityPermutation(const int n,const int *perm)', '    IsRowwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsRowwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    Negate(const T x)', '    Not(const T x)', '    Sign(const T x)', '    Square(const T x)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\miopen\\Utils.h', [], ['    contiguousIfZeroInStrides(const Tensor & t)', '    setMIOpenStreamToCurrent', '    getCurrentHIPStream']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cudnn\\Utils.h', [], ['    contiguousIfZeroInStrides(const Tensor & t)', '    contiguous']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils.h', [], ['    getBackCompatBroadcastWarn', '    getBackCompatKeepdimWarn', '    maybeThrowBackCompatKeepdimWarn(char *func)', '    setBackCompatBroadcastWarn(bool warn)', '    setBackCompatKeepdimWarn(bool warn)', '    THPUtils_addPyMethodDefs(std::vector & vector,PyMethodDef *methods)', '    THPUtils_checkIntTuple(PyObject *arg)', '    THPUtils_dispatchStateless(PyObject *tensor,const char *name,PyObject *args,PyObject *kwargs)', '    THPUtils_getCallable(PyObject *arg,PyObject **result)', '    THPUtils_invalidArguments(PyObject *given_args,PyObject *given_kwargs,const char *function_name,size_t num_options,...)', '    THPUtils_setError(const char *format,...)', '    THPUtils_tryUnpackLongs(PyObject *arg,THLongStoragePtr & result)', '    THPUtils_tryUnpackLongVarArgs(PyObject *args,int ignore_first,THLongStoragePtr & result)', '    THPUtils_unpackIntTuple(PyObject *arg)', '    THPUtils_unpackLongs(PyObject *arg)', '    THPUtils_unpackSize(PyObject *arg)', '    mod(_real a,_real b)', '    mod(_real a,_real b)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\predictor\\emulator\\utils.h', [], ['    check_path_valid(std::string path,bool remove)', '    replace(std::string line,const std::string & substring,const std::string & target)', '    split(const string & str,const string & delim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\functions\\utils.h', [], ['    check_input_variables(const char *name,const variable_list & inputs,int args,int required_args)', '    compute_requires_grad(Args,...)', '    set_history(at::Tensor & variable,const std::shared_ptr & grad_fn)', '    set_history(std::vector,const std::shared_ptr & grad_fn)', '    set_history(std::vector & variables,const std::shared_ptr & grad_fn)', '    wrap_outputs(const variable_list & inputs,tensor_list,const function_constructor & ctr)', '    defined', '    set_gradient_edge', '    operator()(const at::Tensor & tensor)', '    short_circuit', '    undefined_input']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\autograd\\utils.h', [], ['    addRecvRpcBackward(const AutogradMetadata & autogradMetadata,std::vector & tensors,rpc::worker_id_t fromWorkerId)', '    addSendRpcBackward(const ContextPtr & autogradContext,const AutogradMetadata & autogradMetadata,std::vector & tensors)', '    getMessageWithAutograd(const rpc::worker_id_t dstId,rpc::Message,rpc::MessageType msgType,bool forceGradRecording)', '    sendMessageWithAutograd(rpc::RpcAgent & agent,const rpc::WorkerInfo & dst,rpc::Message,bool forceGradRecording,const std::shared_ptr & rf)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\distributed\\rpc\\utils.h', [], ['    cloneSparseTensors(const std::vector & tensors)', '    deserializeRequest(const Message & request)', '    deserializeResponse(const Message & response,MessageType & wrappedMsgType)', '    deserializeRespToIValue(const Message & message)', '    deserializeResptoIValueInternal(RpcCommandBase & rpc,MessageType messageType)', '    wireSerialize(const std::vector & payload,const std::vector & tensors)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\generic\\utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\modules\\utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\cuda\\utils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\test\\mobile\\op_deps\\utils.h', [], ['    global_helper_call_AA_op_1(const at::Tensor & self)', '    global_helper_call_AA_op_2(const at::Tensor & self)', '    global_helper_call_AA_op_3(const at::Tensor & self)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\mkldnn\\Utils.h', [], ['    pool_output_sizes(IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding_l,IntArrayRef padding_r,IntArrayRef dilation,bool ceil_mode)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\lib\\c10d\\Utils.hpp', ['    ResourceGuard'], ['    assertCPU(std::function fn,const at::ArrayRef tensors)', '    assertDense(std::function fn,const at::ArrayRef tensors)', '    assertLayoutMatch(std::function fn,const c10::Layout & expected,const at::ArrayRef tensors,size_t index)', '    assertLayoutMatch(std::function fn,const at::ArrayRef tensors)', '    assertNonEmpty(std::function fn,const at::ArrayRef tensors)', '    assertRootRank(std::function fn,int rank,int size)', '    assertRootTensor(std::function fn,int rank,int size)', '    assertSameDevice(std::function fn,const at::ArrayRef tensors)', '    assertSameSizeAndType(const std::vector & tensors)', '    assertSameSizes(const at::IntArrayRef & sizes,const std::vector & tensors)', '    assertSameType(const at::DeprecatedTypeProperties & type,const std::vector & tensors)', '    assertSingleElement(std::function fn,const at::ArrayRef tensors)', '    assertSingleElementInput(std::function fn,const at::ArrayRef tensors)', '    assertSingleElementOutput(std::function fn,const at::ArrayRef tensors)', '    assertSizesMatch(std::function fn,const at::IntArrayRef & sizes,const at::ArrayRef tensors,size_t index)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors,const at::DeprecatedTypeProperties & type,const at::IntArrayRef & sizes)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors,const at::TensorOptions & options,const at::IntArrayRef & sizes)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors)', '    assertTypeMatch(std::function fn,const at::DeprecatedTypeProperties & type,const at::ArrayRef tensors,size_t index)', '    assertTypeMatch(std::function fn,const at::TensorOptions & options,const at::ArrayRef tensors,size_t index)', '    fmap(T & inputs,const F & fn)', '    toString(at::IntArrayRef l)', '    toString(const c10::Layout & layout)', '    flattenDenseTensors(at::TensorList tensors)', '    getDataPointer(const at::Tensor & tensor)', '    getDataPointers(const std::vector & tensors)', '    getDevices(const std::vector & tensors)', '    newLikeFlat(std::vector,size_t deviceIdx)', '    newLikeFlat(std::vector & tensors)', '    sizes', '    sizes', '    accept(int listenSocket,const std::chrono::milliseconds & timeout)', '    connect(const std::string & address,PortType port,bool wait,const std::chrono::milliseconds & timeout)', '    listen(PortType port)', '    recvBytes(int socket,T *buffer,size_t length)', '    recvString(int socket)', '    recvValue(int socket)', '    recvVector(int socket)', '    sendBytes(int socket,const T *buffer,size_t length,bool moreData)', '    sendString(int socket,const std::string & str,bool moreData)', '    sendValue(int socket,const T & value,bool moreData)', '    sendVector(int socket,const std::vector & vec,bool moreData)', '    sockaddrToString(struct sockaddr *addr)', '    data_ptr', '    release', '    ResourceGuard(std::function destructor)', '    ~ResourceGuard', '    system_category', '    system_error', '    data', '    device', '    end', '    equals', '    insert', '    options', '    size', '    sizes', '    storage', '    toString', '    type_equal']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\vadd-microkernel-tester.h', ['    VAddMicrokernelTester'], ['    aScale(float aScale)', '    aScale', '    aScale_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    bScale(float bScale)', '    bScale', '    bScale_', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    inplaceA(bool inplaceA)', '    inplaceA', '    inplaceA_', '    inplaceB(bool inplaceB)', '    inplaceB', '    inplaceB_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_q8vadd_ukernel_function q8vadd)', '    yScale(float yScale)', '    yScale', '    yScale_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\vararg_functions.cpp', [], ['    elems', '    elems', '    createObject(Stack & stack,at::ClassTypePtr type)', '    dictConstruct(Stack & stack,at::DictTypePtr type,size_t num_inputs)', '    format(Stack & stack,size_t num_inputs)', '    isinstance(Stack & stack,at::ArrayRef types)', '    listConstruct(Stack & stack,at::ListTypePtr type,size_t num_inputs)', '    listUnpack(Stack & stack,size_t num_outputs)', '    namedTupleConstruct(Stack & stack,at::TupleTypePtr type,size_t num_inputs)', '    tupleConstruct(Stack & stack,size_t num_inputs)', '    tupleSlice(Stack & stack,size_t begin,size_t end)', '    tupleUnpack(Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\vararg_functions.h', [], ['    createObject(Stack & stack,at::ClassTypePtr type)', '    dictConstruct(Stack & stack,at::DictTypePtr type,size_t num_inputs)', '    format(Stack & stack,size_t num_inputs)', '    isinstance(Stack & stack,at::ArrayRef types)', '    listConstruct(Stack & stack,at::ListTypePtr type,size_t num_inputs)', '    listUnpack(Stack & stack,size_t num_outputs)', '    namedTupleConstruct(Stack & stack,at::TupleTypePtr type,size_t num_inputs)', '    tupleConstruct(Stack & stack,size_t num_inputs)', '    tupleSlice(Stack & stack,size_t begin,size_t end)', '    tupleUnpack(Stack & stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\variable.cpp', [], ['    _register_hook(const Tensor & self,std::function hook)', '    base(const Tensor & self)', '    clear_hooks(const Variable & self)', '    DifferentiableViewMeta(at::TensorImpl *self_impl,Variable base,CreationMeta creation_meta)', '    get_autograd_meta(const Variable & self)', '    grad_fn(const Tensor & self)', '    handle_view_on_rebase(DifferentiableViewMeta *diff_view_meta,bool indirect)', '    is_view(const Tensor & self)', '    name(const Tensor & self)', '    pyobj(const Variable & self)', '    remove_hook(const Tensor & self,unsigned pos)', '    set_name(const Variable & self,const std::string & name)', '    set_pyobj(const Variable & self,PyObject *pyobj)', '    tensor_data(const Tensor & self)', '    add_hook(const Variable & self,std::shared_ptr hook)', '    materialize_autograd_meta(const Variable & self)', '    rebase_history(const Variable & self,Edge gradient_edge)', '    bump_version(const Variable & self)', '    create_cpp_hook(const Variable & self)', '    grad_accumulator(const Variable & self)', '    grad_fn_unsafe(const Variable & self)', '    gradient_edge(const Variable & self)', '    set_grad_accumulator(const Variable & self,std::weak_ptr grad_accumulator)', '    set_gradient_edge(const Variable & self,Edge edge)', '    set_version_counter(const Variable & self,const c10::VariableVersion & version_counter)', '    try_get_grad_accumulator(const Variable & self)', '    version_counter(const Variable & self)', '    variable_data(const Tensor & self)', '    ~DifferentiableViewMeta', '    make', '    undefined_tensor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\variable.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\variable_factories.h', [], ['    $', '    from_blob(void *data,at::IntArrayRef sizes,at::IntArrayRef strides,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,const Deleter & deleter,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,at::IntArrayRef strides,const Deleter & deleter,const at::TensorOptions & options)', '    tensor(detail::TensorDataContainer tensor_data_container,const at::TensorOptions & options)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\variable_length_sequence_padding.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUVariableLengthSequencePadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_VariableLengthSequencePadding']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\variable_length_sequence_padding.h', ['    VariableLengthSequencePaddingOp'], ['    VariableLengthSequencePadding(int N,int B,int M,T *X,const int32_t *seqLengths,const T padValue,Context *)', '    RunOnDevice', '    VariableLengthSequencePaddingOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\runtime\\variable_tensor_list.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp', [], ['    variable_fallback_kernel(const OperatorHandle & op,Stack *stack)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\VariableHooksInterface.cpp', [], ['    GetVariableHooks', '    SetVariableHooks(VariableHooksInterface *h)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\VariableHooksInterface.h', [], ['    GetVariableHooks', '    SetVariableHooks(VariableHooksInterface *h)', '    _register_hook(const Tensor &,std::function hook)', '    base(const Tensor &)', '    grad_fn(const Tensor &)', '    is_view(const Tensor &)', '    name(const Tensor &)', '    remove_hook(const Tensor &,unsigned pos)', '    tensor_data(const Tensor &)', '    variable_data(const Tensor &)', '    ~VariableHooksInterface', '    VariableHooksRegisterer(VariableHooksInterface *hooks)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\VariableMethodStubs.cpp', [], ['    _version(const Tensor & self)', '    backward(const Tensor & self,const Tensor & gradient,bool keep_graph,bool create_graph)', '    data(const Tensor & self)', '    is_leaf(const Tensor & self)', '    output_nr(const Tensor & self)', '    requires_grad_(Tensor & self,bool _requires_grad)', '    retain_grad(const Tensor & self)', '    set_data(const Tensor & self,const Tensor & new_data)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\VariableType.cpp', [], ['    registerer', '    $']]
['RELATIVE:\\pytorch-master\\pytorch-master\\tools\\autograd\\templates\\VariableType.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\VariableTypeManual.cpp', [], ['    detach(const Tensor & self)', '    detach_(Tensor & self)', '    resize_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    resize_as_(Tensor & self,const Tensor & the_template,c10::optional optional_memory_format)', '    _version(const Tensor & self)', '    allCPUTypes', '    allCUDATypes', '    allTypesForBackends(at::ArrayRef backends)', '    backward(const Tensor & self,const Tensor & gradient,bool keep_graph,bool create_graph)', '    checked_cast_variable(const Tensor & t,const char *name,int pos)', '    checked_cast_variable(Tensor & t,const char *name,int pos)', '    copy_(Tensor & self,const Tensor & src,bool non_blocking)', '    data(const Tensor & self)', '    is_leaf(const Tensor & self)', '    output_nr(const Tensor & self)', '    requires_grad_(Tensor & self,bool _requires_grad)', '    retain_grad(const Tensor & self)', '    set_data(const Tensor & self,const Tensor & new_data)', '    unpack(const Tensor & t,const char *name,int pos)', '    unpack(Tensor & t,const char *name,int pos)', '    unpack(at::TensorList tl,const char *name,int pos)', '    unpack_opt(const Tensor & t,const char *name,int pos)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\VariableTypeUtils.h', [], ['    as_view(const Tensor & base,Tensor tensor,bool is_differentiable,CreationMeta creation_meta)', '    as_view(const Tensor & base,std::vector tensors,bool is_differentiable,CreationMeta creation_meta)', '    check_no_requires_grad(const Tensor & tensor,const char *name)', '    check_no_requires_grad(TensorList tensors,const char *name)', '    flatten_tensor_args(Args,...)', '    increment_version(Tensor & t)', '    make_saved_variable_list(TensorList tensors)', '    check_inplace(const Tensor & tensor)', '    rebase_history(Variable & var,std::shared_ptr grad_fn)', '    throw_error_out_requires_grad(const char *name)', '    rebase_history(std::vector,std::shared_ptr grad_fn)', '    bump_version', '    get_autograd_meta', '    rebase_history', '    apply', '    Flatten(variable_list & out)', '    operator()(const at::Tensor & x)', '    operator()(at::ArrayRef xs)', '    undefined_input']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\variadic.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\utils\\variadic.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\core\\Variadic.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\util\\variant.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\variant_test.cpp', [], ['    func(c10::variant v)', '    TEST(VariantTest,Basic)', '    operator()(enumtype::Enum1 & v)', '    operator()(enumtype::Enum2 & v)', '    operator()(enumtype::Enum3 & v)', '    Enum1', '    Enum2', '    Enum3']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_base.h', [], ['    Vec256(T val)', '    size', '    Vec256']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_complex_double.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_complex_float.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_double.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_float.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_int.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vec256\\vec256_qint.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\verify_api_visibility.cpp', [], ['    main']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Version.cpp', [], ['    get_mkl_version', '    get_mkldnn_version', '    get_openmp_version', '    show_config', '    used_cpu_capability']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\Version.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_decoder.cc', [], ['    DecodeMultipleClipsFromVideo(const char *video_buffer,const std::string & video_filename,const int encoded_size,const Params & params,const int start_frm,const int clip_per_video,const std::vector & clip_start_positions,const bool use_local_file,int & height,int & width,std::vector & buffer_rgb)', '    FreeDecodedData(std::vector,std::vector)', '    decodeFile(const string & file,const Params & params,const int start_frm,Callback & callback)', '    decodeLoop(const string & videoName,VideoIOContext & ioctx,const Params & params,const int start_frm,Callback & callback)', '    decodeMemory(const string & videoName,const char *buffer,const int size,const Params & params,const int start_frm,Callback & callback)', '    ffmpegErrorStr(int result)', '    getAudioSample(AVPacket & packet,AVCodecContext *audioCodecContext_,AVFrame *audioStreamFrame_,SwrContext *convertCtx_,Callback & callback,const Params & params)', '    ResizeAndKeepAspectRatio(const int origWidth,const int origHeight,const int short_edge,const int long_edge,int & outWidth,int & outHeight)', '    VideoDecoder']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_decoder.h', ['    Callback', '    CallbackImpl', '    DecodedFrame', '    Params', '    VideoDecoder', '    VideoIOContext'], ['    DecodeMultipleClipsFromVideo(const char *video_buffer,const std::string & video_filename,const int encoded_size,const Params & params,const int start_frm,const int clip_per_video,const std::vector & clip_start_positions,const bool use_local_file,int & height,int & width,std::vector & buffer_rgb)', '    FreeDecodedData(std::vector,std::vector)', '    readFile(void *opaque,unsigned char *buf,int buf_size)', '    readMemory(void *opaque,unsigned char *buf,int buf_size)', '    seekFile(void *opaque,int64_t offset,int whence)', '    seekMemory(void *opaque,int64_t offset,int whence)', '    audioDecoded(std::unique_ptr)', '    frameDecoded(std::unique_ptr img)', '    videoDecodingEnded(double)', '    videoDecodingStarted(const VideoMeta &)', '    ~Callback', '    audioDecoded(std::unique_ptr audio_sample)', '    CallbackImpl', '    clear', '    frameDecoded(std::unique_ptr frame)', '    videoDecodingStarted(const VideoMeta &)', '    DecodedAudio(int dataSize,int outSampleSize,std::unique_ptr audio_data)', '    operator()(unsigned char *p)', '    fps(float v)', '    keyFrames(bool keyFrames)', '    maxOutputDimension(int size)', '    maxOutputFrames(int count)', '    outputHeight(int height)', '    outputWidth(int width)', '    Params', '    pixelFormat(AVPixelFormat pixelFormat)', '    setSampleTimestamps(const std::vector & timestamps)', '    streamIndex(int index)', '    operator<(const SampleInterval & itvl)', '    SampleInterval', '    SampleInterval(double ts,double f)', '    decodeFile(const string & file,const Params & params,const int start_frm,Callback & callback)', '    decodeLoop(const string & videoName,VideoIOContext & ioctx,const Params & params,const int start_frm,Callback & callback)', '    decodeMemory(const string & videoName,const char *buffer,const int size,const Params & params,const int start_frm,Callback & callback)', '    ffmpegErrorStr(int result)', '    getAudioSample(AVPacket & packet,AVCodecContext *audioCodecContext_,AVFrame *audioStreamFrame_,SwrContext *convertCtx_,Callback & callback,const Params & params)', '    ResizeAndKeepAspectRatio(const int origWidth,const int origHeight,const int short_edge,const int long_edge,int & outWidth,int & outHeight)', '    VideoDecoder', '    get_avio', '    read(unsigned char *buf,int buf_size)', '    seek(int64_t offset,int whence)', '    VideoIOContext(const std::string & fname)', '    VideoIOContext(const char *buffer,int size)', '    ~VideoIOContext', '    VideoMeta']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_input_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUVideoInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_VideoInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_input_op.h', ['    final'], ['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    thread_pool_(std::make_shared num_decode_threads_)', '    memset(label_data,,)', '    CheckParamsAndPrint', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *clip_rgb_data,float *clip_of_data,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_clip)', '    GetClipsAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen)', '    GetImageAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data)', '    GetLabelsFromProto(const TensorProto & label_proto,int *label_data)', '    Prefetch', '    prefetched_clip_of_on_device_', '    prefetched_clip_rgb_on_device_', '    prefetched_label_on_device_', '    prefetched_start_frame_on_device_', '    prefetched_video_id_on_device_', '    VideoInputOp(const OperatorDef & operator_def,Workspace *ws)', '    ~VideoInputOp', '    cvtColor', '    clear', '    emplace_back', '    push_back', '    size', '    byte_data', '    data', '    data_type', '    dims', '    dims_size', '    int32_data', '    int64_data', '    size', '    string_data', '    string_data_size', '    CheckParamsAndPrint', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *clip_rgb_data,float *clip_of_data,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_clip)', '    GetClipsAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen)', '    GetImageAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data)', '    Prefetch']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_input_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAVideoInput']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_io.cc', [], ['    ClipTransformOpticalFlow(const unsigned char *buffer_rgb,const int crop_size,const int length_of,const int channels_of,const int sampling_rate_of,const int height,const int width,const cv::Rect & rect,const int channels_rgb,const bool mirror_me,const int flow_alg_type,const int flow_data_type,const int frame_gap_of,const bool do_flow_aggregation,const std::vector & mean_of,const std::vector & inv_std_of,float *transformed_clip)', '    ClipTransformRGB(const unsigned char *buffer_rgb,const int crop_size,const int length_rgb,const int channels_rgb,const int sampling_rate_rgb,const int height,const int width,const int h_off,const int w_off,const bool mirror_me,const std::vector & mean_rgb,const std::vector & inv_std_rgb,float *transformed_clip)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\video\\video_io.h', [], ['    ClipTransformOpticalFlow(const unsigned char *buffer_rgb,const int crop_size,const int length_of,const int channels_of,const int sampling_rate_of,const int height,const int width,const cv::Rect & rect,const int channels_rgb,const bool mirror_me,const int flow_alg_type,const int flow_data_type,const int frame_gap_of,const bool do_flow_aggregation,const std::vector & mean_of,const std::vector & inv_std_of,float *transformed_clip)', '    ClipTransformRGB(const unsigned char *buffer_rgb,const int crop_size,const int length_rgb,const int channels_rgb,const int sampling_rate_rgb,const int height,const int width,const int h_off,const int w_off,const bool mirror_me,const std::vector & mean_rgb,const std::vector & inv_std_rgb,float *transformed_clip)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\ios\\TestApp\\TestApp\\ViewController.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\impl\\VirtualGuardImpl.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\src\\nn\\options\\vision.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\functional\\vision.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\nn\\options\\vision.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libvulkan-stub\\include\\vulkan\\vk_platform.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\cpu\\vml.h', [], ['    vabs(scalar_t *out,const scalar_t *in,int64_t size)', '    vacos(scalar_t *out,const scalar_t *in,int64_t size)', '    vasin(scalar_t *out,const scalar_t *in,int64_t size)', '    vatan(scalar_t *out,const scalar_t *in,int64_t size)', '    vceil(scalar_t *out,const scalar_t *in,int64_t size)', '    vcos(scalar_t *out,const scalar_t *in,int64_t size)', '    verf(scalar_t *out,const scalar_t *in,int64_t size)', '    verfc(scalar_t *out,const scalar_t *in,int64_t size)', '    verfinv(scalar_t *out,const scalar_t *in,int64_t size)', '    vexp(scalar_t *out,const scalar_t *in,int64_t size)', '    vexpm1(scalar_t *out,const scalar_t *in,int64_t size)', '    vfloor(scalar_t *out,const scalar_t *in,int64_t size)', '    vlgamma(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog10(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog1p(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog2(scalar_t *out,const scalar_t *in,int64_t size)', '    vneg(scalar_t *out,const scalar_t *in,int64_t size)', '    vreciprocal(scalar_t *out,const scalar_t *in,int64_t size)', '    vround(scalar_t *out,const scalar_t *in,int64_t size)', '    vrsqrt(scalar_t *out,scalar_t *in,int64_t size)', '    vrsqrt(scalar_t *out,const scalar_t *in,int64_t size)', '    vsin(scalar_t *out,const scalar_t *in,int64_t size)', '    vsqrt(scalar_t *out,const scalar_t *in,int64_t size)', '    vtan(scalar_t *out,const scalar_t *in,int64_t size)', '    vtanh(scalar_t *out,const scalar_t *in,int64_t size)', '    vtrunc(scalar_t *out,const scalar_t *in,int64_t size)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\vol2col.h', [], ['    col2vol(const T *data_col,const int64_t channels,const int64_t depth,const int64_t height,const int64_t width,const int64_t out_depth,const int64_t out_height,const int64_t out_width,const int64_t kT,const int64_t kernel_height,const int64_t kernel_width,const int64_t pT,const int64_t pH,const int64_t pW,const int64_t dT,const int64_t dH,const int64_t dW,const int64_t dilationT,const int64_t dilationH,const int64_t dilationW,T *data_vol)', '    vol2col(const T *data_vol,const int64_t channels,const int64_t depth,const int64_t height,const int64_t width,const int64_t depth_col,const int64_t height_col,const int64_t width_col,const int64_t kT,const int64_t kernel_height,const int64_t kernel_width,const int64_t pT,const int64_t pH,const int64_t pW,const int64_t dT,const int64_t dH,const int64_t dW,const int64_t dilationT,const int64_t dilationH,const int64_t dilationW,T *data_col)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\TH\\vector\\VSX.cpp', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\mobile\\contrib\\libvulkan-stub\\include\\vulkan\\vulkan.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\weakref_test.cpp', [], ['    TEST(TestWeakPointer,WeakPointerGetsInvalidated)', '    TEST(TestWeakPointer,WeakPointerLock)', '    TEST(TestWeakPointer,WeakUpdatesRefcountsTest)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\weight_scale_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightScale', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightScale']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\weight_scale_op.h', ['    final'], ['    weight_scale_update(int N,const T *w,const T scale,int64_t iter,int64_t stepsize,int64_t update_upper_bound,T *nw,Context *context)', '    GetSingleArgument', '    RunOnDevice', '    WeightScaleOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\weighted_multi_sampling_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedMultiSampling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedMultiSampling', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\weighted_multi_sampling_op.h', ['    WeightedMultiSamplingOp'], ['    GetSingleArgument', '    RunOnDevice', '    WeightedMultiSamplingOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\weighted_sample_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSample', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSample', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\weighted_sample_op.h', ['    final'], ['    RunOnDevice', '    WeightedSampleOp(Args,...)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\WeightNorm.cpp', [], ['    _weight_norm(const Tensor & v_in,const Tensor & g_in,int64_t dim)', '    _weight_norm_differentiable_backward(const Tensor & grad_w,const Tensor & saved_v,const Tensor & saved_g,const Tensor & saved_norms,int64_t dim)', '    norm_except_dim(const Tensor & v,int64_t pow,int64_t dim)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\while_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUWhile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_While']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\while_op.h', ['    final'], ['    GetSingleArgument', '    HasSingleArgumentOfType', '    InputIsTensorType', '    RunOnDevice', '    WhileOp(const OperatorDef & operator_def,Workspace *ws)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\while_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAWhile']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\WindowsTorchApiMacro.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\wngrad_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseWngrad', '    CAFFE_ANONYMOUS_VARIABLE_CPUWngrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseWngrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Wngrad']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\wngrad_op.h', ['    final', '    final'], ['    wngrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,const float *lr,Context *)', '    wngrad_update_output_effective_lr(int N,const float *paramIn,const float *gradIn,const float *seqBIn,float *paramOut,float *seqBOut,float *effectiveLROut,float epsilon,const float *lr,Context *)', '    wngrad_update_output_effective_lr_and_update(int N,const float *paramIn,const float *gradIn,const float *seqBIn,float *paramOut,float *seqBOut,float *effectiveLROut,float *updateOut,float epsilon,const float *lr,Context *)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SparseWngradOp(const OperatorDef & operator_def,Workspace *ws)', '    WngradOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\api\\include\\torch\\data\\worker_exception.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\threadpool\\WorkersPool.h', ['    BlockingCounter', '    WorkersPool'], ['    ThreadFunc(void *arg)', '    ChangeState(State new_state)', '    Do256NOPs', '    kGEMMLOWPCacheLineSize', '    StartWork(Task *task)', '    ThreadFunc', '    WaitForVariableChange(std::atomic *var,T initial_value,std::condition_variable *cond,std::mutex *mutex)', '    Worker(BlockingCounter *counter_to_decrement_when_ready)', '    ~Worker', '    alloc(Args,...)', '    release(T *p)', '    count_', '    DecrementCount', '    fetch_sub', '    load', '    Reset(std::size_t initial_count)', '    Wait', '    operator()(T *p)', '    make', '    atomic_thread_fence', '    Run', '    Task', '    ~Task', '    CreateWorkers(std::size_t workers_count)', '    Execute(const std::vector)', '    operator=', '    WorkersPool', '    WorkersPool']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\workspace.cc', ['    C10FlagParser_caffe2_print_blob_sizes_at_exit'], ['    C10FlagParser_caffe2_print_blob_sizes_at_exit(const std::string & content)', '    AddBlobMapping(const Workspace *parent,const std::unordered_map & forwarded_blobs,bool skip_defined_blobs)', '    Blobs', '    bookkeeper', '    CreateBlob(const string & name)', '    CreateLocalBlob(const string & name)', '    CreateNet(const NetDef & net_def,bool overwrite)', '    CreateNet(const std::shared_ptr & net_def,bool overwrite)', '    DeleteNet(const string & name)', '    GetBlob(const string & name)', '    GetBlob(const string & name)', '    GetNet(const string & name)', '    GetThreadPool', '    LocalBlobs', '    PrintBlobSizes', '    RemoveBlob(const string & name)', '    RenameBlob(const string & old_name,const string & new_name)', '    RunNet(const string & name)', '    RunNetOnce(const NetDef & net_def)', '    RunOperatorOnce(const OperatorDef & op_def)', '    RunPlan(const PlanDef & plan,ShouldContinue shouldContinue)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\workspace.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\workspace_ops.cc', ['    final'], ['    CAFFE_ANONYMOUS_VARIABLE_CPUGetAllBlobNames', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetAllBlobNames', '    GetAllBlobNamesOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\core\\workspace_test.cc', ['    WorkspaceTestFoo'], ['    forEachCheck(std::initializer_list workspaces)', '    TEST(WorkspaceTest,BlobAccess)', '    TEST(WorkspaceTest,RunEmptyPlan)', '    TEST(WorkspaceTest,Sharing)', '    TEST(WorkspaceTest,BlobMapping)', '    TEST(WorkspaceTest,ForEach)', '    _typeMetaDataInstance']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\autograd\\utils\\wrap_outputs.h', [], ['    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    wrap(bool value)', '    wrap(std::tuple tensors)', '    wrap(int64_t value)', '    wrap(double value)', '    wrap(std::complex value)', '    wrap(void *value)', '    wrap(THPDtype *dtype)', '    wrap(at::ScalarType scalarType)', '    wrap(THPLayout *layout)', '    wrap(at::Tensor tensor)', '    wrap(at::Scalar scalar)', '    wrap(at::QScheme qscheme)', '    wrap(PyTypeObject *type,std::tuple tensors)', '    wrap(PyTypeObject *type,std::tuple tensors)', '    wrap(at::TensorList tl)', '    wrap(at::IntArrayRef list)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\wrapdim_test.cpp', [], ['    TEST(TestWrapdim,TestWrapdim)', '    TestEmptyTensor(DeprecatedTypeProperties & T)', '    TestExpressionSpecification(DeprecatedTypeProperties & T)', '    TestScalarVs1Dim1Size(DeprecatedTypeProperties & T)', '    TestSimpleCase(DeprecatedTypeProperties & T)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\c10\\core\\WrapDimMinimal.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\WrapDimUtils.h', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\WrapDimUtilsMulti.h', [], ['    dim_list_to_bitset(IntArrayRef dims,int64_t ndims)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x2-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x2-neon.c', [], ['    pytorch_qnnp_x8zip_x2__neon(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x2-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x2-sse2.c', [], ['    pytorch_qnnp_x8zip_x2__sse2(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x3-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x3-neon.c', [], ['    pytorch_qnnp_x8zip_x3__neon(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x3-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x3-sse2.c', [], ['    pytorch_qnnp_x8zip_x3__sse2(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x4-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x4-neon.c', [], ['    pytorch_qnnp_x8zip_x4__neon(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\x4-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\x4-sse2.c', [], ['    pytorch_qnnp_x8zip_x4__sse2(size_t n,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\x8lut.cc', [], ['    TEST(X8LUT__SCALAR,n_eq_1)', '    TEST(X8LUT__SCALAR,small_n)', '    TEST(X8LUT__SCALAR,large_n)', '    TEST(X8LUT__SCALAR,n_eq_1_inplace)', '    TEST(X8LUT__SCALAR,small_n_inplace)', '    TEST(X8LUT__SCALAR,large_n_inplace)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\x8lut.h', [], ['    pytorch_x8lut_ukernel__scalar(size_t n,const uint8_t *x,const uint8_t [256] t,uint8_t *y)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\x8zip.cc', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\qnnpack\\x8zip.h', [], ['    pytorch_qnnp_x8zip_x2__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x2__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x3__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x3__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x4__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x4__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_xm__neon(size_t n,size_t m,const void *input,void *output)', '    pytorch_qnnp_x8zip_xm__sse2(size_t n,size_t m,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\test\\xla_tensor_test.cpp', [], ['    TEST(XlaTensorTest,TestNoStorage)', '    XLAFree(void *ptr)', '    XLAMalloc(ptrdiff_t size)', '    allocate(size_t size)', '    raw_deleter']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\xm-neon.c', [], ['    pytorch_qnnp_x8zip_xm__neon(size_t n,size_t m,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\xm-neon.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\src\\x8zip\\xm-sse2.c', [], ['    pytorch_qnnp_x8zip_xm__sse2(size_t n,size_t m,const void *input,void *output)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\wrappers\\x8zip\\xm-sse2.c', [], []]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\xnnpack_rewrite.cpp', [], ['    FoldPrePackingOps(script::Module & m)', '    insertPrePackedOps(std::shared_ptr & graph)', '    insertPrePackedOps(script::Module & module)', '    optimizeForMobile(script::Module & m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\torch\\csrc\\jit\\passes\\xnnpack_rewrite.h', [], ['    FoldPrePackingOps(script::Module & m)', '    insertPrePackedOps(std::shared_ptr & graph)', '    insertPrePackedOps(script::Module & module)', '    optimizeForMobile(script::Module & m)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\yellowfin_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUYellowFin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_YellowFin', '    GetLrMu']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\sgd\\yellowfin_op.h', ['    final'], ['    AfterApply', '    GetLrMu', '    GetSingleArgument', '    MomentumSgdUpdate', '    MovingAverage(const int N,const T *elt,const T *avg,T *new_avg,T *debias_avg)', '    RunOnDevice', '    scratch_tensor_', '    YellowFinOp(const OperatorDef & operator_def,Workspace *ws)', '    ZeroDebiasFactor']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\zero_gradient_op.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CPUZeroGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ZeroGradient', '    vector', '    vector', '    GetGradientDefs']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\zero_gradient_op.h', ['    final'], ['    RunOnDevice', '    ZeroGradientOp(Args,...)', '    ~ZeroGradientOp']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\operators\\zero_gradient_op_gpu.cc', [], ['    CAFFE_ANONYMOUS_VARIABLE_CUDAZeroGradient']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\quantized\\cpu\\qnnpack\\test\\zip-microkernel-tester.h', ['    ZipMicrokernelTester'], ['    g(size_t g)', '    g', '    g_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_xzipc_ukernel_function xzip)', '    test(pytorch_xzipv_ukernel_function xzip)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\aten\\src\\ATen\\native\\cpu\\zmath.h', [], ['    angle_impl(SCALAR_TYPE z)', '    angle_impl(std::complex z)', '    angle_impl(std::complex z)', '    zabs(SCALAR_TYPE z)', '    ceil_impl(std::complex z)', '    ceil_impl(std::complex z)', '    ceil_impl(TYPE z)', '    conj_impl(TYPE z)', '    floor_impl(std::complex z)', '    floor_impl(std::complex z)', '    floor_impl(TYPE z)', '    imag_impl(std::complex z)', '    imag_impl(SCALAR_TYPE z)', '    imag_impl(std::complex z)', '    max_impl(TYPE a,TYPE b)', '    max_impl(TYPE a,TYPE b)', '    min_impl(TYPE a,TYPE b)', '    min_impl(TYPE a,TYPE b)', '    real_impl(std::complex z)', '    real_impl(SCALAR_TYPE z)', '    real_impl(std::complex z)', '    round_impl(std::complex z)', '    round_impl(std::complex z)', '    round_impl(TYPE z)', '    trunc_impl(std::complex z)', '    trunc_impl(std::complex z)', '    trunc_impl(TYPE z)', '    zabs(std::complex z)', '    zabs(std::complex z)', '    abs', '    arg', '    nearbyint', '    trunc']]
['RELATIVE:\\pytorch-master\\pytorch-master\\binaries\\zmq_feeder.cc', ['    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_server'], ['    main(int argc,char **argv)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_server(const std::string & content)']]
['RELATIVE:\\pytorch-master\\pytorch-master\\caffe2\\utils\\zmq_helper.h', ['    ZmqContext', '    ZmqMessage', '    ZmqSocket'], ['    operator=', '    ptr', '    ZmqContext(int io_threads)', '    ZmqContext', '    ~ZmqContext', '    data', '    msg', '    operator=', '    size', '    ZmqMessage', '    ZmqMessage', '    ~ZmqMessage', '    Bind(const string & addr)', '    Connect(const string & addr)', '    Disconnect(const string & addr)', '    Recv(ZmqMessage *msg)', '    RecvTillSuccess(ZmqMessage *msg)', '    Send(const string & msg,int flags)', '    SendTillSuccess(const string & msg,int flags)', '    Unbind(const string & addr)', '    ZmqSocket(int type)', '    ~ZmqSocket']]
