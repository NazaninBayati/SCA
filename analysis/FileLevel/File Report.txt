jni.h;C++;pytorch-master/pytorch-master/.circleci/docker/java; 1143;  93; 158;112;  787; 24;190;612;323;623;0.12;234;[];['    pytorch_u8maxpool_ukernel_16x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)'];
generate_test_asset.cpp;C++;pytorch-master/pytorch-master/android/pytorch_android; 20;  0; 4;6;  10; 0;0;0;0;1;0.00;0;[];[];
cmake_macros.h;C++;pytorch-master/pytorch-master/android/pytorch_android/src/main/cpp; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];[];
pytorch_jni_common.h;C++;pytorch-master/pytorch-master/android/pytorch_android/src/main/cpp; 95;  1; 19;20;  49; 14;22;31;7;28;0.02;5;[];['    pytorch_u8maxpool_ukernel_16x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)'];
pytorch_jni_jit.cpp;C++;pytorch-master/pytorch-master/android/pytorch_android/src/main/cpp; 237;  10; 31;28;  114; 59;56;54;34;42;0.09;21;[];[];
pytorch_jni_lite.cpp;C++;pytorch-master/pytorch-master/android/pytorch_android/src/main/cpp; 114;  9; 19;10;  78; 0;36;38;23;28;0.12;11;[];['    pytorch_sse_reduce4_i32(__m128i x,__m128i y,__m128i z,__m128i w)', '    pytorch_q8gemm_ukernel_2x4c8__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
AccumulateType.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 50;  4; 7;13;  25; 6;19;25;19;60;0.16;0;[];['    pytorch_q8sumrows_ukernel_4x__neon(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *a_sum)'];
ArrayRef.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];[];
ATen.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 28;  0; 1;27;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_q8gemm_dq_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)'];
autocast_mode.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 13;  2; 3;1;  9; 0;0;9;0;7;0.22;0;[];[];
autocast_VS2017_helper.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 152;  15; 10;23;  105; 0;101;103;101;102;0.14;101;[];[];
Backend.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_q8conv_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
Context.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 174;  16; 30;38;  86; 14;31;34;29;32;0.19;25;[];[];
Context.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 238;  17; 27;16;  179; 0;0;0;0;0;0.09;0;[];['    pytorch_q8gemm_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
alias_info.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 119;  18; 14;5;  83; 0;0;0;0;0;0.22;0;[];['    pytorch_q8gemm_dq_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)'];
aten_interned_strings.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1027;  8; 3;1017;  0; 0;0;0;0;0;0.00;0;[];[];
ATenGeneral.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
ATenGeneral.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 3;  0; 1;2;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_q8conv_ukernel_4x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
Backtrace.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_q8gemm_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
blob.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
blob.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 208;  62; 25;9;  113; 0;0;0;0;0;0.55;0;[];['    pytorch_q8gemm_xzp_ukernel_4x8c2__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params [1] requantization_params)'];
kernel_function.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 29;  3; 3;2;  21; 0;0;0;0;0;0.14;0;[];[];
kernel_function_legacy_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 1111;  37; 225;8;  842; 0;530;364;355;328;0.04;90;[];[];
kernel_function_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 854;  32; 173;5;  645; 0;377;302;239;283;0.05;72;[];['    pytorch_sgemm_ukernel_5x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
kernel_functor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 1024;  34; 199;5;  787; 0;439;359;275;315;0.04;86;[];['    pytorch_q8gemm_ukernel_6x4__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
kernel_lambda.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 37;  5; 6;3;  23; 0;0;0;0;0;0.22;0;[];[];
kernel_lambda_legacy_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 1031;  36; 184;8;  805; 0;516;471;241;395;0.04;50;[];['    pytorch_sgemm_ukernel_6x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
kernel_stackbased_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 162;  15; 33;5;  112; 0;65;49;40;51;0.13;17;[];[];
KernelFunction.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 44;  7; 6;2;  30; 0;13;5;13;4;0.23;3;[];['    pytorch_sconv_ukernel_6x8__psimd(size_t mr,size_t nr,size_t kc,size_t ks,const float **a,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
KernelFunction.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 244;  164; 28;7;  45; 0;0;0;0;0;3.64;0;[];[];
KernelFunction_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 314;  9; 65;4;  238; 0;122;100;95;108;0.04;51;[];['    pytorch_sgemm_ukernel_6x8__psimd(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
test_helpers.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 96;  3; 14;7;  73; 0;39;33;22;20;0.04;12;[];[];
builtin_function.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 105;  4; 23;3;  77; 0;0;0;0;0;0.05;0;[];[];
DeprecatedTypeProperties.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 24;  3; 6;4;  14; 0;5;5;5;4;0.21;3;[];['    pytorch_q8gemm_ukernel_8x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
DeprecatedTypeProperties.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 131;  8; 27;8;  89; 0;0;0;0;0;0.09;0;[];['    pytorch_q8conv_ukernel_8x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
DeprecatedTypePropertiesRegistry.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 33;  2; 7;2;  22; 0;8;10;8;8;0.09;4;[];['    pytorch_hgemm_ukernel_8x8__neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params [1] clamping_params)'];
Dict.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 392;  130; 67;9;  186; 0;0;0;0;0;0.70;0;[];['    backward(AutogradContext *ctx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,const Variable & input,const CrossMapLRN2dOptions & options)'];
Dict_inl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 253;  5; 38;2;  208; 0;0;0;0;0;0.02;0;[];[];
Dimname.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 69;  1; 10;3;  56; 0;28;12;29;11;0.02;7;[];['    main'];
DimVector.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 13;  2; 5;3;  4; 0;0;0;0;0;0.50;0;['    GetAbsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAbs', '    CAFFE_ANONYMOUS_VARIABLE_CPUAbsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Abs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AbsGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
Dispatcher.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 285;  22; 49;3;  211; 0;107;63;93;97;0.10;21;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
Dispatcher.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 305;  107; 55;7;  139; 0;0;0;0;0;0.77;0;[];['    AccumulateGrad(Variable variable_)', '    apply(variable_list)'];
DispatchKeyExtractor.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 182;  68; 21;7;  86; 0;0;0;0;0;0.79;0;[];['    accumulateGrad(const Variable & variable,at::Tensor & variable_grad,const at::Tensor & new_grad,size_t num_expected_refs,const T & update_grad)', '    callHooks(const Variable & variable,at::Tensor new_grad)', '    _indices', '    _values', '    clone', '    defined', '    detach', '    is_contiguous', '    is_sparse', '    options', '    sizes', '    use_count', '    AccumulateGrad(Variable variable_)', '    apply(variable_list)'];
DispatchTable.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 27;  1; 5;2;  20; 0;11;7;13;5;0.05;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAccumulate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Accumulate'];
DispatchTable.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 222;  38; 31;17;  137; 0;0;0;0;0;0.28;0;['    final'];['    AccumulateOp(Args,...)', '    GetSingleArgument', '    RunOnDevice'];
OperatorEntry.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 142;  60; 21;5;  57; 0;0;0;0;0;1.05;0;[];[];
OperatorOptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 30;  3; 5;4;  19; 1;0;0;0;0;0.16;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAccuracy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Accuracy', '    RunOnDevice'];
RegistrationHandleRAII.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 36;  0; 9;2;  25; 0;0;0;0;0;0.00;0;['    final'];['    AccuracyOp(Args,...)', '    RunOnDevice'];
Formatting.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 289;  2; 11;7;  269; 0;176;56;154;53;0.01;11;['    GetAcosGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAcos', '    CAFFE_ANONYMOUS_VARIABLE_CPUAcosGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Acos', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AcosGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
Formatting.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 29;  0; 6;4;  19; 0;0;0;0;0;0.00;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
function.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 64;  7; 21;5;  33; 0;0;0;0;0;0.21;0;[];['    threshold_out(optional opt_result,const Tensor & self,Scalar threshold,Scalar value,const Tensor & other)', '    softshrink_check(Scalar lambd)', '    _rrelu_with_noise_train(Tensor & output,const Tensor & input,const Tensor & noise,Scalar lower_,Scalar upper_,Generator generator)', '    celu(const Tensor & self,Scalar alpha)', '    celu_(Tensor & self,Scalar alpha)', '    elu(const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    elu_(Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    elu_backward(const Tensor & grad_output,Scalar alpha,Scalar scale,Scalar input_scale,const Tensor & output)', '    elu_backward_out(Tensor & grad_input,const Tensor & grad_output,Scalar alpha,Scalar scale,Scalar input_scale,const Tensor & output)', '    elu_out(Tensor & result,const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    hardsigmoid(const Tensor & self)', '    hardsigmoid_(Tensor & self)', '    hardsigmoid_backward(const Tensor & grad_output,const Tensor & self)', '    hardsigmoid_out(Tensor & result,const Tensor & self)', '    hardswish(const Tensor & self)', '    hardswish_(Tensor & self)', '    hardswish_backward(const Tensor & grad_output,const Tensor & self)', '    hardswish_out(Tensor & result,const Tensor & self)', '    hardtanh(const Tensor & self,Scalar min,Scalar max)', '    hardtanh_(Tensor & self,Scalar min,Scalar max)', '    hardtanh_backward(const Tensor & grad_output,const Tensor & self,Scalar min,Scalar max)', '    hardtanh_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,Scalar min,Scalar max)', '    hardtanh_out(Tensor & result,const Tensor & self,Scalar min,Scalar max)', '    prelu_cpu(const Tensor & self,const Tensor & weight_)', '    prelu_cpu_backward_kernel_share_weights(const Tensor & input,const Tensor & weight,const Tensor & grad_out,Tensor & input_grad,Tensor & weight_grad)', '    prelu_cpu_kernel_multi_weights(Tensor & result,const Tensor & input,const Tensor & weight,int64_t input_dim0_size,int64_t channel_size,int64_t input_stride0,int64_t input_stride1)', '    prelu_cpu_kernel_share_weights(Tensor & result,const Tensor & input,const Tensor & weight)', '    relu(const Tensor & self)', '    relu_(Tensor & self)', '    rrelu(const Tensor & self,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_(Tensor & self,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_backward(const Tensor & grad_output,const Tensor & self_or_result,const Tensor & noise,Scalar lower,Scalar upper,bool training,bool is_result)', '    rrelu_with_noise_cpu(const Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_cpu_(Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    rrelu_with_noise_out_cpu(Tensor & output,const Tensor & self,const Tensor & noise,Scalar lower,Scalar upper,bool training,Generator generator)', '    selu(const Tensor & self)', '    selu_(Tensor & self)', '    softplus(const Tensor & self,Scalar beta,Scalar threshold)', '    softplus_backward(const Tensor & grad_output,const Tensor & self,Scalar beta,Scalar threshold,const Tensor & output)', '    softplus_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,Scalar beta,Scalar threshold,const Tensor & output)', '    softplus_out(Tensor & result,const Tensor & self,Scalar beta,Scalar threshold)', '    threshold(const Tensor & self,Scalar threshold,Scalar value)', '    threshold_(Tensor & self,Scalar threshold,Scalar value)', '    threshold_backward(const Tensor & grad,const Tensor & self,Scalar threshold)', '    threshold_out(Tensor & result,const Tensor & self,Scalar threshold,Scalar value)', '    prelu_backward_cpu(const Tensor & grad_out_,const Tensor & self,const Tensor & weight_)', '    prelu_cpu_backward_kernel_multi_weights(const Tensor & input,const Tensor & weight,const Tensor & grad_out,Tensor & input_grad,Tensor & weight_grad_collector,int64_t input_dim0_size,int64_t channel_size,int64_t input_stride0,int64_t input_stride1)', '    gelu_backward_cpu(const Tensor & grad,const Tensor & self)', '    gelu_cpu(const Tensor & self)', '    hardshrink(const Tensor & self,Scalar lambd)', '    hardshrink_backward(const Tensor & grad,const Tensor & self,Scalar lambd)', '    leaky_relu(const Tensor & self,Scalar negval)', '    leaky_relu_(Tensor & self,Scalar neg_val)', '    leaky_relu_backward(const Tensor & grad_output,const Tensor & self_or_result,Scalar negval,bool is_result)', '    leaky_relu_out(Tensor & result,const Tensor & self,Scalar negval)', '    log_sigmoid_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & buffer)', '    log_sigmoid_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & buffer)', '    log_sigmoid_forward_cpu(const Tensor & input)', '    log_sigmoid_forward_out_cpu(Tensor & result,Tensor & buffer,const Tensor & input)', '    softshrink(const Tensor & self,Scalar lambd)', '    softshrink_backward(const Tensor & grad,const Tensor & self,Scalar lambd)', '    softshrink_backward_out(Tensor & grad_input,const Tensor & grad,const Tensor & self,Scalar lambd)', '    softshrink_out(Tensor & result,const Tensor & self,Scalar lambd)', '    sum'];
function_schema.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 412;  50; 41;10;  313; 0;0;0;0;0;0.16;0;[];['    CELUImpl(const CELUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    ELUImpl(const ELUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    GLUImpl(const GLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    HardshrinkImpl(const HardshrinkOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    HardtanhImpl(const HardtanhOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    LeakyReLUImpl(const LeakyReLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    LogSoftmaxImpl(const LogSoftmaxOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    _reset_parameters', '    forward(const Tensor & query,const Tensor & key,const Tensor & value,const Tensor & key_padding_mask,bool need_weights,const Tensor & attn_mask)', '    MultiheadAttentionImpl(const MultiheadAttentionOptions & options_)', '    reset', '    forward(const Tensor & input)', '    PReLUImpl(const PReLUOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    ReLU6Impl(const ReLU6Options & options_)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    ReLUImpl(const ReLUOptions & options_)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    RReLUImpl(const RReLUOptions & options_)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    SELUImpl(const SELUOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftmaxImpl(const SoftmaxOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftminImpl(const SoftminOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftplusImpl(const SoftplusOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftshrinkImpl(const SoftshrinkOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset', '    ThresholdImpl(const ThresholdOptions & options_)'];
function_schema_inl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 335;  24; 20;1;  291; 0;0;0;0;0;0.08;0;[];['    GLUOptions(int64_t dim)', '    HardshrinkOptions(double lambda)', '    LogSoftmaxFuncOptions(int64_t dim)', '    LogSoftmaxOptions(int64_t dim)', '    MultiheadAttentionForwardFuncOptions(int64_t embed_dim_to_check,int64_t num_heads,Tensor in_proj_weight,Tensor in_proj_bias,Tensor bias_k,Tensor bias_v,bool add_zero_attn,double dropout_p,Tensor out_proj_weight,Tensor out_proj_bias)', '    MultiheadAttentionOptions(int64_t embed_dim,int64_t num_heads)', '    ReLU6Options(bool inplace)', '    ReLUOptions(bool inplace)', '    SELUOptions(bool inplace)', '    SoftmaxFuncOptions(int64_t dim)', '    SoftmaxOptions(int64_t dim)', '    SoftminFuncOptions(int64_t dim)', '    SoftminOptions(int64_t dim)', '    SoftshrinkOptions(double lambda)'];
functional.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 54;  11; 8;3;  33; 0;0;0;0;0;0.33;0;[];[];
grad_mode.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 35;  5; 8;5;  9; 10;3;5;2;4;0.56;2;[];[];
grad_mode.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 30;  5; 6;2;  18; 0;0;0;0;0;0.28;0;[];[];
interned_strings.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 125;  9; 18;20;  79; 0;42;24;5035;23;0.11;14;[];['    elu_backward_stub', '    elu_backward_stub', '    operator=', '    elu_stub', '    elu_stub', '    operator=', '    GeluBackwardKernel', '    GeluBackwardKernel', '    operator=', '    GeluKernel', '    GeluKernel', '    operator=', '    glu_backward_stub', '    glu_backward_stub', '    operator=', '    glu_stub', '    glu_stub', '    operator=', '    hardshrink_stub', '    hardshrink_stub', '    operator=', '    hardsigmoid_backward_stub', '    hardsigmoid_backward_stub', '    operator=', '    hardsigmoid_stub', '    hardsigmoid_stub', '    operator=', '    hardswish_backward_stub', '    hardswish_backward_stub', '    operator=', '    hardswish_stub', '    hardswish_stub', '    operator=', '    hardtanh_backward_stub', '    hardtanh_backward_stub', '    operator=', '    leaky_relu_backward_stub', '    leaky_relu_backward_stub', '    operator=', '    leaky_relu_stub', '    leaky_relu_stub', '    operator=', '    log_sigmoid_backward_cpu_stub', '    log_sigmoid_backward_cpu_stub', '    operator=', '    log_sigmoid_cpu_stub', '    log_sigmoid_cpu_stub', '    operator=', '    operator=', '    shrink_backward_stub', '    shrink_backward_stub', '    operator=', '    softplus_backward_stub', '    softplus_backward_stub', '    operator=', '    softplus_stub', '    softplus_stub', '    operator=', '    softshrink_stub', '    softshrink_stub', '    operator=', '    threshold_stub', '    threshold_stub'];
interned_strings_class.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 36;  2; 6;10;  19; 0;0;16;0;16;0.11;0;[];[];
ivalue.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 423;  17; 34;7;  367; 0;238;100;209;92;0.05;22;[];['    HasDNNLowPEngine_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorBase & op)', '    FindMinMax(const T *data,float *min,float *max,int len)', '    FindMinMax(const float *data,float *min,float *max,int len)', '    GetFloatTensorData(TensorCPU *tensor)', '    DumpAndReset_(const string & out_file_name,bool print_total_min_max)', '    HistogramNetObserver(NetBase *subject,const string & out_file_name,int nbins,int dump_freq,bool mul_nets,string op_filter,string delimiter)', '    Stop', '    ~HistogramNetObserver', '    HistogramObserver(OperatorBase *op,shared_ptr info)', '    Stop', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    OutputColumnMaxHistogramNetObserver(NetBase *subject,const std::string & out_file_name,const std::vector & observe_column_max_for_blobs,int nbins,int dump_freq,bool mul_nets,string delimiter)', '    Stop', '    ~OutputColumnMaxHistogramNetObserver', '    OutputColumnMaxHistogramObserver(OperatorBase *op,const std::string & col_max_blob_name,int nbins,std::shared_ptr info)', '    Stop', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    OutputMinMaxNetObserver(NetBase *subject,const string & out_file_name,int dump_freq,string delimiter)', '    Stop', '    ~OutputMinMaxNetObserver', '    OutputMinMaxObserver(OperatorBase *op)', '    Stop', '    ~OutputMinMaxObserver', '    RegisterQuantizationParamsNetObserver(NetBase *subject,const string & min_max_file_name,bool is_weight,const string & qparams_output_file_name)', '    RegisterQuantizationParamsWithHistogramNetObserver(NetBase *subject,const string & histogram_file_name,bool is_weight,const string & qparams_output_file_name)'];
ivalue.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 742;  136; 95;30;  485; 0;0;0;0;0;0.28;0;['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final'];['    localtime_r(time_t *_clock,struct tm *_result)', '    DumpAndReset_(const std::string & out_file_name,bool print_total_min_max)', '    DumpHistogramFile', '    GetInfo', '    HistogramNetObserver(NetBase *subject,const std::string & out_file_name,int nbins,int dump_freq,bool mul_nets,string op_filter,string delimiter)', '    HistogramObserver(OperatorBase *op,std::shared_ptr info)', '    OutputColumnMaxHistogramNetObserver(NetBase *subject,const std::string & out_file_name,const std::vector & observe_column_max_for_blobs,int nbins,int dump_freq,bool mul_nets,string delimiter)', '    OutputColumnMaxHistogramObserver(OperatorBase *op,const std::string & col_max_blob_name,int nbins,std::shared_ptr info)', '    OutputMinMaxNetObserver(NetBase *subject,const std::string & out_file_name,int dump_freq,string delimiter)', '    OutputMinMaxObserver(OperatorBase *op)', '    RegisterQuantizationParamsNetObserver(NetBase *subject,const std::string & min_max_file_name,bool is_weight,const std::string & qparams_output_file_name)', '    RegisterQuantizationParamsWithHistogramNetObserver(NetBase *subject,const std::string & histogram_file_name,bool is_weight,const std::string & qparams_output_file_name)', '    Stop', '    TensorInfo(const std::string & name)', '    Update(float cur_min,float cur_max)', '    ~HistogramNetObserver', '    ~OutputColumnMaxHistogramNetObserver', '    ~OutputMinMaxNetObserver', '    ~OutputMinMaxObserver'];
jit_type.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1997;  226; 237;43;  1521; 0;0;0;0;0;0.15;0;['    CuDNNActivationOpBase', '    final', '    final'];['    CuDNNActivationOpBase(Args,...)', '    SetTensorDescriptor(const cudnnDataType_t data_type,const int data_size)', '    ~CuDNNActivationOpBase', '    CuDNNActivationGradientOp(Args,...)', '    CuDNNActivationOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice'];
LegacyDeviceTypeInit.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 23;  0; 4;1;  18; 0;6;6;4;9;0.00;2;['    final', '    final', '    MIOPENActivationOpBase'];['    DoRunWithType', '    DoRunWithType', '    MIOPENActivationGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    MIOPENActivationOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    MIOPENActivationOpBase(const OperatorDef & operator_def,Workspace *ws)', '    ~MIOPENActivationOpBase'];
LegacyDeviceTypeInit.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 37;  3; 8;7;  20; 0;0;0;0;0;0.15;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAdadelta', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdadelta', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adadelta', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdadelta'];
LegacyTypeDispatch.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 92;  44; 9;8;  32; 0;0;0;0;0;1.38;0;['    final', '    final'];['    AdadeltaUpdate(int N,const float *w,const float *g,const float *h,const float *d,const float epsilon,const float decay,const float *lr,float *nw,float *nh,float *nd,Context *)', '    AdadeltaOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SparseAdadeltaOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
List.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 453;  159; 89;9;  196; 0;0;0;0;0;0.81;0;[];['    adagrad_fp16_update_prefetch(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_fp16_update_prefetch__base(int N,const at::Half *w,const at::Half *,const float *g,const at::Half *h,const at::Half *,at::Half *nw,at::Half *,at::Half *nh,at::Half *,float epsilon,float lr)', '    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update__base(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,const float lr)', '    adagrad_update_prefetch(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)', '    adagrad_update_prefetch__base(int N,const float *w,const float *,const float *g,const float *h,const float *,float *nw,float *,float *nh,float *,float epsilon,float lr)'];
List_inl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 309;  5; 51;3;  251; 0;0;0;0;0;0.02;0;[];['    make_sparse', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    operator==(const AdagradOptions & lhs,const AdagradOptions & rhs)', '    operator==(const AdagradParamState & lhs,const AdagradParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    AdagradOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)'];
Macros.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    adagrad_update_base_inlined(int N,const T *w,const float *g,const T *h,T *nw,T *nh,float decay,float epsilon,float lr)', '    adagrad_fp16_update_prefetch(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update_prefetch(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)', '    adagrad_update_prefetch_inlined(int N,const float *w,const float *,const float *g,const float *h,const float *,float *nw,float *,float *nh,float *,float epsilon,float lr)'];
MT19937RNGEngine.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 194;  78; 26;10;  81; 0;0;0;0;0;0.96;0;[];[];
NamedTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 145;  5; 23;3;  117; 0;57;30;50;31;0.04;17;[];['    adagrad_fp16_update_prefetch__avx_f16c(int N,const at::Half *w,const at::Half *w_n,const float *g,const at::Half *h,const at::Half *h_n,at::Half *nw,at::Half *nw_n,at::Half *nh,at::Half *nh_n,float epsilon,float lr)', '    adagrad_update__avx_f16c(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,float lr)', '    adagrad_update_prefetch__avx_f16c(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)'];
infer_schema.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/op_registration; 34;  1; 6;2;  25; 0;15;5;13;4;0.04;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    operator()(int N,const float *w,const float *w_n,const float *g,const float *h,const float *h_n,float *nw,float *nw_n,float *nh,float *nh_n,float epsilon,float lr)'];
infer_schema.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/op_registration; 170;  29; 29;4;  108; 0;0;0;0;0;0.27;0;['    final', '    final', '    final'];['    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdagradFusedWithSparseLengthsSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    SparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp(const OperatorDef & operator_def,Workspace *ws)', '    SparseAdagradFusedWithSparseLengthsWeightedSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    Resize'];
op_registration.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/op_registration; 181;  11; 33;4;  133; 0;86;44;60;35;0.08;12;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAdagrad', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagrad', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdagrad', '    CostInferenceForSparseAdagrad(const OperatorDef &,const vector & inputs)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adagrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdagrad'];
op_registration_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/op_registration; 1501;  131; 232;8;  1168; 0;667;598;314;1017;0.11;105;['    final', '    final', '    final'];['    adagrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,float decay,const float *lr,Context *)', '    adagrad_update_output_effective_lr(int N,const float *paramIn,const float *gradIn,const float *momentIn,float *paramOut,float *momentOut,float *effectiveLROut,float epsilon,float decay,const float *lr,Context *)', '    adagrad_update_output_effective_lr_and_update(int N,const float *paramIn,const float *gradIn,const float *momentIn,float *paramOut,float *momentOut,float *effectiveLROut,float *updateOut,float epsilon,float decay,const float *lr,Context *)', '    q_none(float *,size_t)', '    q_none_stoc(float *,size_t,CPUContext::rand_gen_type &)', '    AdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RowWiseSparseAdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdagradOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
operator_name.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 21;  0; 5;2;  14; 0;7;4;7;3;0.00;2;[];['    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    operator==(const AdamOptions & lhs,const AdamOptions & rhs)', '    operator==(const AdamParamState & lhs,const AdamParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    AdamOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)'];
operator_name.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 48;  4; 9;5;  31; 0;0;0;0;0;0.13;0;[];[];
PhiloxRNGEngine.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 203;  54; 21;17;  111; 3;73;38;66;33;0.49;6;['    final'];['    adam_ideep_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    adam_ideep_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    adam_ideep_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr)', '    beta1_', '    beta2_', '    epsilon_', '    IDEEPAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
qualified_name.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 160;  20; 25;5;  114; 0;0;0;0;0;0.18;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAdam', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdam', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseAdam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Adam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdam', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseAdam'];
Range.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 12;  1; 4;2;  6; 0;2;3;2;2;0.17;1;['    final', '    final', '    final'];['    adam_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    adam_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    adam_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float correction,const float *lr,Context *)', '    radam_compute(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    radam_compute_output_grad(int N,const float *w,const float *g,const float *m,const float *v,float *nw,float *nm,float *nv,float *ng,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    radam_update(int N,const float *g,const float *m,const float *v,float *ng,float *nm,float *nv,float beta1,float beta2,float eps_hat,float beta1_correction,float correction,float rho_t,float r_correction,const float *lr,Context *)', '    AdamOp(const OperatorDef & operator_def,Workspace *ws)', '    beta1_', '    beta2_', '    DoRunWithType', '    DoRunWithType', '    epsilon_', '    GetSingleArgument', '    RowWiseSparseAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseAdamOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
Reduction.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 16;  8; 2;1;  10; 0;0;0;0;0;0.80;0;[];['    _get_full_log_prob(const Tensor & input,const Tensor & head_output)', '    AdaptiveLogSoftmaxWithLossImpl(AdaptiveLogSoftmaxWithLossOptions options_)', '    forward(const Tensor & input,const Tensor & target)', '    log_prob(const Tensor & input)', '    predict(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    ASMoutput(Tensor output_,double loss_)'];
register_symbols.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 38;  8; 8;3;  21; 0;7;15;2;10;0.38;1;[];['    AdaptiveLogSoftmaxWithLossOptions(int64_t in_features,int64_t n_classes,std::vector cutoffs)'];
rref_interface.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 40;  9; 11;2;  18; 0;0;0;0;0;0.50;0;[];[];
ScalarType.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
stack.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 135;  32; 15;2;  88; 0;0;0;0;0;0.36;0;[];['    adaptive_avg_pool2d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_avg_pool2d(at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_backward_cpu(const Tensor & gradOutput,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool2d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool2d_cpu(at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_cpu_template(at::Tensor & output,at::Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)'];
Tensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 82;  5; 15;4;  59; 0;24;14;25;13;0.08;11;[];['    adaptive_avg_pool3d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_avg_pool3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_avg_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input)', '    adaptive_avg_pool3d_cpu(Tensor const & input,IntArrayRef output_size)', '    adaptive_avg_pool3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    adaptive_avg_pool3d_out_cpu_template(Tensor & output,Tensor const & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)'];
TensorAccessor.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 232;  25; 31;9;  164; 4;27;106;24;56;0.15;27;[];['    adaptive_max_pool2d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool2d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *indices,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool2d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t sizeD,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool2d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool2d_cpu(const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool2d_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool2d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)'];
TensorImpl_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 7;  0; 1;2;  4; 0;1;2;1;2;0.00;1;[];['    adaptive_max_pool3d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool3d_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW)', '    adaptive_max_pool3d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t sizeB,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool3d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t sizeD,int64_t isizeT,int64_t isizeH,int64_t isizeW,int64_t osizeT,int64_t osizeH,int64_t osizeW,int64_t istrideD,int64_t istrideT,int64_t istrideH,int64_t istrideW)', '    adaptive_max_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices)', '    adaptive_max_pool3d_cpu(const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool3d_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    adaptive_max_pool3d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef output_size)', '    end_index(int a,int b,int c)', '    start_index(int a,int b,int c)'];
type.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1040;  54; 82;10;  905; 0;535;276;469;191;0.06;75;['    AddOperatorTester'];['    aScale(float aScale)', '    aScale', '    aScale_', '    aStride(size_t aStride)', '    aStride', '    aStride_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    bScale(float bScale)', '    bScale', '    bScale_', '    bStride(size_t bStride)', '    bStride', '    bStride_', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    channels(size_t channels)', '    channels', '    channels_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8', '    yScale(float yScale)', '    yScale', '    yScale_', '    yStride(size_t yStride)', '    yStride', '    yStride_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_', '    min_element'];
UndefinedTensorImpl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_qnnp_create_add_nc_q8(size_t channels,uint8_t a_zero_point,float a_scale,uint8_t b_zero_point,float b_scale,uint8_t sum_zero_point,float sum_scale,uint8_t sum_min,uint8_t sum_max,uint32_t flags,pytorch_qnnp_operator_t *add_out)', '    pytorch_qnnp_setup_add_nc_q8(pytorch_qnnp_operator_t add_op,size_t batch_size,const uint8_t *a,size_t a_stride,const uint8_t *b,size_t b_stride,uint8_t *sum,size_t sum_stride)'];
UnsafeFromTH.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 20;  0; 4;1;  15; 0;0;0;0;0;0.00;0;[];['    add_nc_q8(benchmark::State & state)', '    add_nc_q8_inplace(benchmark::State & state)', '    CharacteristicArguments(benchmark::internal::Benchmark *b)'];
VariableFallbackKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 74;  15; 7;5;  16; 31;7;8;8;9;0.94;1;[];['    TEST(ADD_OP,zero_batch)', '    TEST(ADD_OP,unit_batch)', '    TEST(ADD_OP,unit_batch_with_qmin)', '    TEST(ADD_OP,unit_batch_with_qmax)', '    TEST(ADD_OP,unit_batch_with_a_scale)', '    TEST(ADD_OP,unit_batch_with_b_scale)', '    TEST(ADD_OP,unit_batch_with_y_scale)', '    TEST(ADD_OP,unit_batch_with_a_zero_point)', '    TEST(ADD_OP,unit_batch_with_b_zero_point)', '    TEST(ADD_OP,unit_batch_with_y_zero_point)', '    TEST(ADD_OP,small_batch)', '    TEST(ADD_OP,small_batch_with_a_stride)', '    TEST(ADD_OP,small_batch_with_b_stride)', '    TEST(ADD_OP,small_batch_with_y_stride)', '    TEST(ADD_OP,small_batch_with_qmin)', '    TEST(ADD_OP,small_batch_with_qmax)', '    TEST(ADD_OP,small_batch_with_a_scale)', '    TEST(ADD_OP,small_batch_with_b_scale)', '    TEST(ADD_OP,small_batch_with_y_scale)', '    TEST(ADD_OP,small_batch_with_a_zero_point)', '    TEST(ADD_OP,small_batch_with_b_zero_point)', '    TEST(ADD_OP,small_batch_with_y_zero_point)', '    TEST(ADD_OP,strided_batch)', '    TEST(ADD_OP,strided_batch_with_qmin)', '    TEST(ADD_OP,strided_batch_with_qmax)', '    TEST(ADD_OP,strided_batch_with_a_scale)', '    TEST(ADD_OP,strided_batch_with_b_scale)', '    TEST(ADD_OP,strided_batch_with_y_scale)', '    TEST(ADD_OP,strided_batch_with_a_zero_point)', '    TEST(ADD_OP,strided_batch_with_b_zero_point)', '    TEST(ADD_OP,strided_batch_with_y_zero_point)'];
VariableHooksInterface.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 62;  27; 10;3;  24; 0;2;20;1;19;1.13;1;[];['    add_op_cpu_impl(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & C_,bool legacy_broadcast,int64_t axis)'];
Variadic.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 76;  23; 11;6;  37; 0;0;0;0;0;0.62;0;['    GetAffineChannelGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAffineChannel', '    CAFFE_ANONYMOUS_VARIABLE_CPUAffineChannelGradient', '    AffineChannelScaleBiasBackwardNCHW(const int N,const int C,const int HxW,const T *dY,const T *X,T *dscale,T *dbias)', '    AffineChannelScaleBiasBackwardNHWC(const int N,const int C,const int HxW,const T *dY,const T *X,T *dscale,T *dbias)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AffineChannel', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AffineChannelGradient', '    RunOnDeviceWithOrderNCHW', '    GetGradientDefs', '    vector'];
cpp_custom_type_hack.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 54;  16; 8;1;  31; 0;13;12;10;7;0.52;3;['    final', '    final'];['    AffineChannelGradientOp(Args,...)', '    AffineChannelOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC'];
FlushDenormal.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu; 14;  9; 3;0;  3; 0;0;3;0;3;3.00;0;[];['    cudnn_affine_grid_generator_backward(const Tensor & grad_grid_t,int64_t N,int64_t C,int64_t H,int64_t W)', '    cudnn_affine_grid_generator_forward(const Tensor & theta_t,int64_t N,int64_t C,int64_t H,int64_t W)', '    setSamplerDescriptor(SpatialTransformerDescriptor & desc,cudnnDataType_t dataType,int N,int C,int H,int W)', '    grad_grid', '    theta'];
functional.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 139;  2; 8;2;  128; 0;69;63;52;62;0.02;5;[];['    affine_grid_generator(const Tensor & theta,IntArrayRef size,bool align_corners)', '    affine_grid_generator_4D(const Tensor & theta,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_4D_backward(const Tensor & grad_grid,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_5D(const Tensor & theta,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_5D_backward(const Tensor & grad_grid,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)', '    affine_grid_generator_backward(const Tensor & grad,IntArrayRef size,bool align_corners)', '    linspace_from_neg_one(const Tensor & grid,int64_t num_steps,bool align_corners)', '    make_base_grid_4D(const Tensor & theta,int64_t N,int64_t C,int64_t H,int64_t W,bool align_corners)', '    make_base_grid_5D(const Tensor & theta,int64_t N,int64_t C,int64_t D,int64_t H,int64_t W,bool align_corners)'];
intrinsics.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 30;  1; 0;23;  0; 18;0;0;0;0;0.00;0;[];['    createSubgraph(GraphType *g)', '    induceEdges(SubgraphType *sg)', '    dominatorTree(G *g,G::NodeRef source)', '    immediateDominatorMap(G *g,G::NodeRef source)', '    reachable(G::NodeRef root,G::NodeRef ignored,std::unordered_set *seen)'];
vec256_base.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 816;  94; 44;33;  621; 32;9;22;9;22;0.15;3;[];['    TEST(DominatorTree,Test1)', '    TEST(DominatorTree,Test2)', '    TEST(Subgraph,InduceEdges)', '    TEST(Subgraph,InduceEdgesCycle)'];
vec256_complex_double.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 432;  1; 4;10;  4; 416;0;0;0;0;0.25;0;['    WorkingSet'];['    ss', '    getMutableTypePtr(const TypePtr & type)', '    mutableType(const Value *v)', '    findSameBlock(Node *target,Node *n)', '    addContainedTypesToFreshElement(Element *container_elem,const TypePtr & mut_type)', '    addToContainedElements(const Value *elem,const Value *container)', '    AliasDb(std::shared_ptr graph,bool isFrozen)', '    analyze(const std::shared_ptr & graph)', '    analyze(Block *block)', '    analyze(Node *node)', '    analyzeBroadcastingChunk(Node *node)', '    analyzeChunk(Node *node)', '    analyzeConservative(Node *node)', '    analyzeContainerConstruct(Node *node)', '    analyzeCreator(Node *node)', '    analyzeExtractor(Node *node)', '    analyzeFork(Node *node)', '    analyzeGradOf(Node *node)', '    analyzeIf(Node *node)', '    analyzeImpl(Node *node)', '    analyzeLoop(Node *node)', '    analyzeRpcAsync(Node *node)', '    analyzeSetAttr(Node *node)', '    analyzeSubgraph(Node *node)', '    analyzeWait(Node *node)', '    couldMoveAfterTopologically(Node *n,Node *movePoint)', '    couldMoveBeforeTopologically(Node *n,Node *movePoint)', '    dump', '    escapesScope(const at::ArrayRef & vs)', '    getElementName(const Element *e)', '    getElements(at::ArrayRef vs)', '    getOrCreateElement(const Value *value)', '    getReads(Node *n)', '    getReadsImpl(Node *n,MemoryLocations & ret)', '    getWildcard(const TypePtr & type)', '    getWrites(Node *n)', '    getWritesImpl(Node *n,MemoryLocations & ret)', '    giveFreshAlias(const Value *value)', '    hasInputWriters(const Node *n)', '    hasOutputWriters(const Node *n)', '    hasWriters(const Node *n)', '    hasWriters(const Value *v)', '    hasWriters(const at::ArrayRef & values)', '    isContainerType(const TypePtr & type)', '    isMutable(Node *n)', '    makePointerTo(const Value *from,const Value *to)', '    mapAliases(at::ArrayRef from,at::ArrayRef to)', '    mayAlias(const Value *a,const Value *b)', '    mayAlias(const ValueSet & a,const ValueSet & b)', '    mayAliasWildcard(const Value *v)', '    mayAliasWildcard(const at::ArrayRef vs)', '    mayContainAlias(Value *a,Value *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    move(Node *toMove,Node *movePoint,MoveSide moveSide)', '    moveAfterTopologicallyValid(Node *n,Node *movePoint)', '    moveBeforeTopologicallyValid(Node *n,Node *movePoint)', '    mutableType(const TypePtr & type)', '    nonAliasingValue(const Value *elem)', '    rebuildWriteCache', '    registerWrite(const Value *v,Node *n)', '    registerWrite(const Element *e,Node *n)', '    safeToChangeAliasingRelationship(const at::ArrayRef & a,const at::ArrayRef & b)', '    setWildcard(const Value *v)', '    toString', '    tryGetOrCreateWildcard(const TypePtr & type)', '    tryMove(Node *toMove,Node *movePoint,MoveSide moveSide,bool dryRun)', '    tryRegisteredAnalysis(Node *node)', '    add(Node *n)', '    consumesFrom(Node *n)', '    dependentNodes', '    dependsOn(Node *n)', '    eraseMover', '    getUsersSameBlock(Node *n)', '    hasDataDependency(Node *n)', '    hasMutabilityDependency(Node *n)', '    producesFor(Node *n)', '    WorkingSet(Node *mover,const AliasDb & aliasDb)', '    writesToAlias(Node *n,const ValueSet & vs)', '    writesToWildcard(Node *n)'];
vec256_complex_float.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 472;  1; 4;10;  4; 456;0;0;0;0;0.25;0;['    AliasDb', '    MoveSide'];['    getMutableTypeKind(const TypePtr & type)', '    isContainerType(const TypePtr & type)', '    mutableType(const Value *v)', '    mutableType(const TypePtr & type)', '    addContainedTypesToFreshElement(Element *container_elem,const TypePtr & mut_type)', '    addToContainedElements(const Value *elem,const Value *container)', '    AliasDb(std::shared_ptr graph,bool isFrozen)', '    analyze(const std::shared_ptr & graph)', '    analyze(Node *node)', '    analyze(Block *block)', '    analyzeBroadcastingChunk(Node *node)', '    analyzeChunk(Node *node)', '    analyzeConservative(Node *node)', '    analyzeContainerConstruct(Node *node)', '    analyzeCreator(Node *node)', '    analyzeExtractor(Node *node)', '    analyzeFork(Node *node)', '    analyzeGradOf(Node *node)', '    analyzeIf(Node *node)', '    analyzeImpl(Node *node)', '    analyzeLoop(Node *node)', '    analyzeRpcAsync(Node *node)', '    analyzeSetAttr(Node *node)', '    analyzeSubgraph(Node *node)', '    analyzeWait(Node *node)', '    couldMoveAfterTopologically(Node *n,Node *movePoint)', '    couldMoveBeforeTopologically(Node *n,Node *movePoint)', '    dump', '    escapesScope(const at::ArrayRef & vs)', '    getElementName(const Element *e)', '    getElements(at::ArrayRef vs)', '    getOrCreateElement(const Value *value)', '    getReads(Node *n)', '    getReadsImpl(Node *n,MemoryLocations & ret)', '    getWildcard(const TypePtr & type)', '    getWrites(Node *n)', '    getWritesImpl(Node *n,MemoryLocations & ret)', '    giveFreshAlias(const Value *value)', '    hasInputWriters(const Node *n)', '    hasOutputWriters(const Node *n)', '    hasWriters(const Node *n)', '    hasWriters(const Value *v)', '    hasWriters(const at::ArrayRef & values)', '    isBeforeOrAfter(const Node *n,MoveSide moveSide)', '    isMutable(Node *n)', '    makeAllAlias(const std::vector & values)', '    makePointerTo(const Value *from,const Value *to)', '    mapAliases(at::ArrayRef from,at::ArrayRef to)', '    mayAlias(const Value *a,const Value *b)', '    mayAlias(const ValueSet & a,const ValueSet & b)', '    mayAliasWildcard(const Value *v)', '    mayAliasWildcard(const at::ArrayRef vs)', '    mayContainAlias(Value *a,Value *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    move(Node *toMove,Node *movePoint,MoveSide moveSide)', '    moveAfterTopologicallyValid(Node *n,Node *movePoint)', '    moveBeforeTopologicallyValid(Node *n,Node *movePoint)', '    nonAliasingValue(const Value *elem)', '    rebuildWriteCache', '    registerWrite(const Value *v,Node *n)', '    registerWrite(const Element *e,Node *n)', '    safeToChangeAliasingRelationship(const at::ArrayRef & a,const at::ArrayRef & b)', '    setWildcard(const Value *v)', '    toString', '    tryGetOrCreateWildcard(const TypePtr & type)', '    tryMove(Node *toMove,Node *movePoint,MoveSide moveSide,bool dryRun)', '    tryRegisteredAnalysis(Node *node)', '    writesToAlias(Node *n,const ValueSet & vs)', '    writesToWildcard(Node *n)', '    ~AliasDb'];
vec256_float.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 342;  1; 4;12;  4; 326;0;0;0;0;0.25;0;[];[];
vec256_int.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 712;  2; 7;20;  5; 692;0;0;0;0;0.40;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAliasWithName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AliasWithName'];
vec256_qint.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 1426;  31; 61;84;  388; 937;0;0;0;0;0.08;0;['    final'];['    schema_AliasWithName', '    AliasWithNameOp(Args,...)', '    GetSingleArgument', '    RunOnDevice'];
CPUApplyUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 439;  64; 45;6;  325; 0;203;102;134;65;0.20;26;['    AlignedAllocator', '    AlignedAllocator'];['    address(reference x)', '    address(const_reference x)', '    AlignedAllocator', '    AlignedAllocator(const AlignedAllocator & other)', '    allocate(size_type n,AlignedAllocator::const_pointer hint)', '    construct(U *p,Args,...)', '    deallocate(pointer p,size_type n)', '    destroy(U *p)', '    max_size'];
CPUFixedAllocator.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 31;  4; 9;3;  15; 0;7;8;10;6;0.27;3;['    AlignerImpl'];['    AlignerImpl'];
CPUGenerator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 176;  82; 22;3;  71; 0;31;30;23;31;1.15;21;[];[];
ATenCUDAGeneral.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 9;  1; 3;5;  0; 0;0;0;0;0;0.00;0;[];['    initializeAlgorithm'];
CublasHandlePool.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 47;  13; 9;5;  22; 0;9;15;14;15;0.59;3;['    final'];['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    AllgatherOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeAlgorithm', '    RunOnDevice', '    update(GlooParameters & params)', '    ~AllgatherOp'];
CUDABlas.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 349;  20; 27;44;  188; 74;88;58;143;40;0.11;10;[];[];
CUDAContext.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 60;  8; 13;6;  36; 0;15;18;20;17;0.22;6;[];[];
CUDAContext.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 69;  31; 14;10;  16; 0;2;12;2;10;1.94;2;[];['    deleteInefficientStdFunctionContext(void *ptr)', '    GetAllocator(const at::DeviceType & t)', '    SetAllocator(at::DeviceType t,at::Allocator *alloc)', '    makeDataPtr(void *ptr,const std::function & deleter,Device device)'];
CUDADevice.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 17;  1; 5;4;  8; 0;2;6;5;6;0.13;1;['    DataPtr'];['    cast_context(DeleterFnPtr expected_deleter)', '    compare_exchange_deleter(DeleterFnPtr expected_deleter,DeleterFnPtr new_deleter)', '    device', '    get_deleter', '    operator bool', '    unsafe_set_device(Device device)', '    GetAllocator(const DeviceType & t)', '    operator!=(const DataPtr & dp,std::nullptr_t)', '    operator!=(std::nullptr_t,const DataPtr & dp)', '    operator==(const DataPtr & dp,std::nullptr_t)', '    operator==(std::nullptr_t,const DataPtr & dp)', '    SetAllocator(DeviceType t,Allocator *alloc)', '    makeDataPtr(void *ptr,const std::function & deleter,Device device)', '    allocate(size_t n)', '    raw_allocate(size_t n)', '    raw_deallocate(void *ptr)', '    raw_deleter', '    ~Allocator', '    AllocatorRegisterer(Allocator *alloc)', '    clear', '    DataPtr', '    DataPtr(void *data,Device device)', '    DataPtr(void *data,void *ctx,DeleterFnPtr ctx_deleter,Device device)', '    get', '    get_context', '    operator->', '    release_context', '    InefficientStdFunctionContext(std::unique_ptr,std::function)'];
CUDAGenerator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 181;  81; 21;3;  79; 0;39;31;32;33;1.03;13;[];[];
CUDAMultiStreamGuard.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 59;  11; 12;6;  31; 0;13;16;9;17;0.35;4;['    final'];['    memory', '    memory', '    deleter(void *pointer)', '    allocate(size_t nbytes)', '    GuardingAllocator', '    raw_deleter', '    ~GuardingAllocator'];
CUDAUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 20;  3; 4;2;  12; 0;6;5;6;5;0.25;1;[];['    main(int argc,char **argv)'];
CUDAHooks.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/detail; 348;  14; 44;83;  152; 70;77;55;81;53;0.09;25;[];['    getAllrduceBcubeBase(int nodes)', '    base', '    baseCheck', '    getExponent', '    initializeBcube', '    initializeRingChunked', '    initializeRingFull'];
CUDAHooks.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/detail; 40;  4; 5;3;  29; 0;1;28;0;29;0.14;1;['    final'];['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    AllreduceOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeBcube', '    initializeHalvingDoubling', '    initializeRingChunked', '    initializeRingFull', '    RunOnDevice', '    update(GlooParameters & params)', '    ~AllreduceOp'];
DeviceThreadHandles.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/detail; 141;  62; 17;7;  57; 0;22;24;22;23;1.09;9;[];['    getAllrduceBcubeBase(int nodes)', '    base', '    baseCheck', '    initializeAlgorithm(bool gpu_direct_,std::shared_ptr context,std::vector ptrs,size_t size)', '    getExponent', '    initializeHalvingDoubling', '    initializeRingChunked', '    initializeRingFull'];
Exceptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 111;  17; 14;71;  9; 10;0;7;1;8;1.89;0;['    HasRand'];['    has_rand', '    HasRand(Stmt *stmt)', '    visit(const Intrinsics *v)', '    op_type'];
ATenNVRTC.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/nvrtc_stub; 13;  1; 3;3;  7; 0;3;4;18;4;0.14;1;[];['    main(int argc,char **argv)'];
ATenNVRTC.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/nvrtc_stub; 94;  20; 10;44;  6; 33;0;6;0;23;3.33;0;[];['    classof(const Annotation *A)', '    getComponentLevels', '    getDevice', '    getDeviceOption', '    getDeviceType', '    getKeyNode', '    getLengthNode', '    getMutableDeviceOption', '    getMutableOperatorDef', '    getOperatorDef', '    getParallelization', '    getParallelizationScheme', '    hasDeviceOption', '    hasOperatorDef', '    setComponentLevels(std::vector components)', '    setDevice(std::string device)', '    setDeviceOption(const caffe2::DeviceOption & devOpt)', '    setDeviceType(int device)', '    setKeyNode(NNGraph::NodeRef n)', '    setLengthNode(NNGraph::NodeRef n)', '    setOperatorDef(const caffe2::OperatorDef & opDef)', '    setParallelization(Caffe2Annotation::ParallelizationScheme s,int num)'];
PinnedMemoryAllocator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 9;  1; 4;2;  3; 0;0;3;0;3;0.33;0;['    Caffe2Annotation', '    ParallelizationScheme'];['    classof(const Annotation *A)', '    Caffe2Annotation', '    Caffe2Annotation(std::string device)', '    getComponentLevels', '    getDevice', '    getDeviceOption', '    getDeviceType', '    getKeyNode', '    getLengthNode', '    getMutableDeviceOption', '    getMutableOperatorDef', '    getOperatorDef', '    getParallelization', '    getParallelizationScheme', '    hasDeviceOption', '    hasOperatorDef', '    setComponentLevels(std::vector components)', '    setDevice(std::string device)', '    setDeviceOption(const caffe2::DeviceOption & devOpt)', '    setDeviceType(int device)', '    setKeyNode(nom::repr::NNGraph::NodeRef)', '    setLengthNode(nom::repr::NNGraph::NodeRef)', '    setOperatorDef(const caffe2::OperatorDef & opDef)', '    setParallelization(Caffe2Annotation::ParallelizationScheme s,int num)', '    ~Caffe2Annotation'];
CUDAGenerator.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 40;  6; 10;3;  24; 0;6;22;0;19;0.25;0;[];[];
cudnn-wrapper.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 16;  0; 5;11;  0; 0;0;0;0;0;0.00;0;[];[];
Descriptors.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 296;  57; 31;11;  194; 7;63;71;160;69;0.29;19;[];['    TEST_F(AnyModuleTest,SimpleReturnType)', '    TEST_F(AnyModuleTest,SimpleReturnTypeAndSingleArgument)', '    TEST_F(AnyModuleTest,StringLiteralReturnTypeAndArgument)', '    TEST_F(AnyModuleTest,StringReturnTypeWithConstArgument)', '    TEST_F(AnyModuleTest,TensorReturnTypeAndStringArgumentsWithFunkyQualifications)', '    TEST_F(AnyModuleTest,WrongArgumentType)', '    TEST_F(AnyModuleTest,WrongNumberOfArguments)', '    TEST_F(AnyModuleTest,PassingArgumentsToModuleWithDefaultArgumentsInForwardMethod)', '    TEST_F(AnyModuleTest,GetWithCorrectTypeSucceeds)', '    TEST_F(AnyModuleTest,GetWithIncorrectTypeThrows)', '    TEST_F(AnyModuleTest,PtrWithBaseClassSucceeds)', '    TEST_F(AnyModuleTest,PtrWithGoodDowncastSuccceeds)', '    TEST_F(AnyModuleTest,PtrWithBadDowncastThrows)', '    TEST_F(AnyModuleTest,DefaultStateIsEmpty)', '    TEST_F(AnyModuleTest,AllMethodsThrowForEmptyAnyModule)', '    TEST_F(AnyModuleTest,CanMoveAssignDifferentModules)', '    TEST_F(AnyModuleTest,ConstructsFromModuleHolder)', '    TEST_F(AnyModuleTest,ConvertsVariableToTensorCorrectly)', '    TEST_F(AnyValueTest,CorrectlyAccessesIntWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesStringLiteralWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesStringWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesPointersWhenCorrectType)', '    TEST_F(AnyValueTest,CorrectlyAccessesReferencesWhenCorrectType)', '    TEST_F(AnyValueTest,TryGetReturnsNullptrForTheWrongType)', '    TEST_F(AnyValueTest,GetThrowsForTheWrongType)', '    TEST_F(AnyValueTest,MoveConstructionIsAllowed)', '    TEST_F(AnyValueTest,MoveAssignmentIsAllowed)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForInt)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForStringLiteral)', '    TEST_F(AnyValueTest,TypeInfoIsCorrectForString)', '    make_value(T)', '    forward(int x)', '    forward(int x)', '    forward(torch::Tensor input)', '    forward(int x)', '    forward(float x)', '    forward(const char *x)', '    forward(int x,const double f)', '    forward(std::string a,const std::string & b,std::string)', '    forward', '    forward(float x)', '    forward(float x)', '    M(int value_)', '    M(int value_)', '    _forward_has_default_args', '    _forward_num_required_args', '    _forward_populate_default_args(std::vector)', '    forward(int a,int b,double c)', '    forward(int a,int b,double c)', '    forward(int a,int b)', '    forward(float x)', '    MImpl(int value_)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(float x)', '    operator()', '    TestAnyValue(T)'];
Exceptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 1;  0; 1;0;  0; 0;0;0;0;0;0.00;0;[];[];
Handle.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 49;  13; 10;6;  22; 0;8;14;22;14;0.59;3;[];[];
Handles.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];[];
Types.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 24;  1; 5;2;  17; 0;9;5;9;5;0.06;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAPMeter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_APMeter', '    BufferPredictions(const float *XData,const int *labelData,int N,int D)'];
Types.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 12;  1; 5;3;  4; 0;0;4;0;4;0.25;0;['    final'];['    APMeterOp(Args,...)', '    BufferPredictions(const float *Xdata,const int *labelData,int N,int D)', '    GetSingleArgument', '    RunOnDevice'];
CPUGuardImpl.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 8;  1; 3;1;  4; 0;0;4;0;4;0.25;0;[];[];
CPUGuardImpl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 61;  8; 6;3;  45; 0;9;24;12;16;0.18;13;[];['    fill_tensor(int64_t scalar,Tensor & t_)', '    test(DeprecatedTypeProperties & type,IntArrayRef shape,int64_t a,int64_t b)', '    TEST(ApplyUtilsTest,Contiguous2D)', '    TEST(ApplyUtilsTest,Small2D)', '    TEST(ApplyUtilsTest,_2D)', '    TEST(ApplyUtilsTest,_3D)', '    TEST(ApplyUtilsTest,Medium3D)', '    TEST(ApplyUtilsTest,_10D)'];
CUDAHooksInterface.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 50;  24; 7;5;  16; 0;6;8;4;10;1.50;2;[];[];
FunctionTraits.h;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 78;  22; 12;2;  42; 0;0;0;0;0;0.52;0;[];[];
HIPHooksInterface.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 29;  3; 6;5;  17; 0;6;8;4;10;0.18;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUArgMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUArgMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ArgMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ArgMin', '    ComputeArgImpl(const int prev_size,const int next_size,const int n,const Compare & comp,const T *X,int64_t *Y,Context *context)', '    InferTensor(const OperatorDef & def,const std::vector & in)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,CPUContext *context)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,CPUContext *context)'];
HIPHooksInterface.h;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 74;  13; 18;10;  35; 0;0;0;0;0;0.37;0;['    final'];['    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,Context *context)', '    operator()(const int prev_size,const int next_size,const int n,const T *X,int64_t *Y,Context *context)', '    ArgOp(Args,...)', '    DoRunWithType', '    reducer_', '    RunOnDevice'];
DeviceGuard.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 36;  12; 6;4;  16; 0;0;0;0;0;0.75;0;[];['    descs', '    device', '    hashCode', '    operator!=(const ArgSpec & spec)', '    operator==(const ArgSpec & other)', '    ArgSpec(at::TensorList inputs,const int _device)', '    device_', '    hash_code_'];
Dimname.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    scanWrittenSlots(Block *block,ArgumentSpecCreator::WrittenSlots & written_slots)', '    ArgumentSpecCreator(Graph & graph)', '    create(bool with_grad,const Stack & input)', '    dump', '    scan(const TypePtr & typ,size_t depth,const WrittenSlots & written_slots)', '    specializeTypes(Graph & graph,const ArgumentSpec & spec)'];
DimVector.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];[];
div_rtn.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 11;  1; 2;1;  7; 0;4;4;3;2;0.14;1;[];[];
DLConvertor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 203;  3; 11;4;  186; 0;152;22;127;20;0.02;7;[];[];
DLConvertor.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 19;  4; 5;4;  7; 0;0;7;0;7;0.57;0;[];['    Array', '    Array(const Array &)', '    operator=(const Array &)', '    operator[](int i)', '    operator[](int i)', '    T'];
DynamicLibrary.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 74;  3; 10;12;  24; 28;13;7;19;6;0.13;3;[];[];
DynamicLibrary.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 21;  1; 8;3;  10; 0;0;0;0;0;0.10;0;['    final'];['    operator!=(c10::ArrayRef a1,const std::vector & a2)', '    operator!=(const std::vector & a1,c10::ArrayRef a2)', '    operator!=(c10::ArrayRef a1,c10::ArrayRef a2)', '    operator<<(std::ostream & out,ArrayRef list)', '    operator==(c10::ArrayRef a1,const std::vector & a2)', '    operator==(const std::vector & a1,c10::ArrayRef a2)', '    operator==(c10::ArrayRef a1,c10::ArrayRef a2)', '    ArrayRef', '    ArrayRef(const std::initializer_list & Vec)', '    ArrayRef(const (*) () T)', '    ArrayRef(const std::array & Arr)', '    ArrayRef(const std::vector & Vec)', '    ArrayRef(const SmallVectorTemplateCommon & Vec)', '    ArrayRef(const T *begin,const T *end)', '    ArrayRef(const T *data,size_t length)', '    ArrayRef(const T & OneElt)', '    ArrayRef', '    at(size_t Index)', '    back', '    begin', '    cbegin', '    cend', '    data', '    empty', '    end', '    equals(ArrayRef RHS)', '    front', '    operator[](size_t Index)', '    rbegin', '    rend', '    size', '    slice(size_t N)', '    slice(size_t N,size_t M)', '    vec', '    begin', '    end'];
ExpandUtils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 88;  5; 10;1;  73; 0;25;37;6;81;0.07;1;[];[];
Formatting.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
Generator.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;['    GetAsinGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAsin', '    CAFFE_ANONYMOUS_VARIABLE_CPUAsinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Asin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AsinGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
HIPAllocatorMasqueradingAsCUDA.h;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 28;  6; 4;3;  16; 0;4;9;3;8;0.38;3;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
HIPCachingAllocatorMasqueradingAsCUDA.h;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 18;  4; 4;4;  9; 0;0;9;0;7;0.44;0;[];[];
HIPGuardImplMasqueradingAsCUDA.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 14;  11; 1;1;  1; 0;0;1;0;2;11.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAssert', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Assert'];
HIPGuardImplMasqueradingAsCUDA.h;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 298;  51; 40;10;  199; 0;109;102;80;93;0.26;47;['    final'];['    AssertOp(Args,...)', '    cmp_tensor_', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice'];
InferSize.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 52;  10; 6;5;  31; 0;20;7;21;6;0.32;1;[];['    allocString', '    allocVector', '    parseFile(const char *,ASTGraph *)', '    parseString(const char *,ASTGraph *)', '    dump(int level)', '    isCall', '    starInputs', '    ~ASTExpr', '    dump', '    ~ASTGraph', '    dump(int level)', '    ~ASTStmt'];
InitialTensorOptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 15;  3; 4;2;  6; 0;2;3;1;2;0.50;1;['    C10FlagParser_benchmark_iter', '    C10FlagParser_inter_op_threads', '    C10FlagParser_iter', '    C10FlagParser_warmup_iter'];['    counter', '    launch_tasks', '    launch_tasks_and_wait(int tasks_num)', '    main(int argc,char **argv)', '    C10FlagParser_benchmark_iter(const std::string & content)', '    C10FlagParser_inter_op_threads(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_warmup_iter(const std::string & content)'];
Layout.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;['    GetAtanGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAtan', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Atan', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtanGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
MemoryOverlap.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 78;  0; 14;2;  62; 0;30;17;31;16;0.00;8;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
MemoryOverlap.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 30;  7; 9;2;  12; 0;0;12;0;13;0.58;0;[];[];
Descriptors.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 117;  2; 13;10;  93; 0;60;33;58;32;0.02;9;[];[];
Exceptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 43;  1; 7;5;  31; 0;9;13;8;9;0.03;4;[];[];
Handle.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 39;  2; 11;4;  24; 0;6;12;6;11;0.08;3;[];['    Set(const std::int64_t,const at::Half h,at::Half *v,CPUContext *c)', '    Set(const std::int64_t,const at::BFloat16 b,at::BFloat16 *v,CPUContext *c)', '    backend'];
Handle.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 9;  1; 4;2;  3; 0;0;3;0;3;0.33;0;[];[];
Types.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 25;  1; 5;3;  17; 0;9;5;9;5;0.06;2;[];[];
Types.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 12;  1; 5;3;  4; 0;0;4;0;4;0.25;0;['    ATenOp'];['    assignListStartingAt(size_t offset,const std::vector & tensors)', '    assignTo(Tensor *dst,const at::Tensor & src_)', '    assignTo(Tensor *dst,at::ScalarType scalar_type,at::Scalar scalar)', '    assignToValue(Tensor *dst,T v)', '    ATenOp(const OperatorDef & operator_def,Workspace *ws)', '    extract(const at::Scalar & s)', '    extract(const at::Scalar & s)', '    findImplementation(const OperatorDef & operator_def)', '    optionsFor(const Tensor & ten)', '    peek(size_t i,size_t N)', '    peekSlice(size_t i,size_t len,size_t N)', '    readAttribute(const std::string & name)', '    readBoolMask(const std::string & name)', '    readIntArrayRef(const std::string & name)', '    readScalarAttribute(const std::string & name)', '    RunOnDevice', '    tensorWrapping(const Tensor & ten_)', '    typeMetaFor(const at::Tensor & t)', '    typeMetaFor(at::ScalarType st)'];
Utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 25;  4; 5;5;  11; 0;4;5;5;5;0.36;2;[];[];
Exceptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/mkl; 19;  1; 4;5;  10; 0;4;3;4;3;0.10;1;[];[];
Limits.h;C++;pytorch-master/pytorch-master/aten/src/ATen/mkl; 11;  3; 4;2;  3; 0;1;3;0;3;1.00;0;[];[];
NamedTensor.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
NamedTensorUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 167;  56; 34;6;  77; 0;0;0;0;0;0.73;0;[];['    load_nvrtc'];
Activation.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 772;  33; 92;8;  646; 0;321;385;227;248;0.05;64;[];['    load_nvrtc', '    decltype(& nvrtcVersion)'];
Activation.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 54;  2; 8;4;  42; 0;37;26;16;140;0.05;0;[];['    f2', '    f2', '    f2', '    TEST(atest,atest)', '    trace'];
AdaptiveAveragePooling3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 312;  17; 31;6;  261; 0;160;118;149;84;0.07;10;['    final', '    final', '    final', '    final', '    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicFetchAdd', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicFetchAdd64', '    CAFFE_ANONYMOUS_VARIABLE_CPUCheckAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUConditionalSetAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateAtomicBool', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateMutex', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicFetchAdd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicFetchAdd64', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConditionalSetAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateAtomicBool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateMutex', '    AtomicFetchAddOp(Args,...)', '    CreateMutexOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
AdaptiveMaxPooling2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 407;  24; 46;4;  336; 0;208;113;115;52;0.07;12;[];['    cpu_atomic_add_float(float *dst,float fvalue)', '    atomic_compare_exchange_strong'];
AdaptiveMaxPooling3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 453;  25; 48;4;  379; 0;239;132;119;61;0.07;12;[];['    clone', '    clone'];
AveragePool2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 426;  13; 48;5;  364; 0;240;130;80;48;0.04;8;[];[];
AveragePool3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 523;  25; 53;5;  448; 0;310;158;115;72;0.06;8;[];['    with_no_gil(F f)', '    AutoGIL', '    ~AutoGIL', '    AutoNoGIL', '    ~AutoNoGIL'];
batch_norm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 18;  2; 8;3;  7; 0;3;5;1;9;0.29;0;['    CastPolicy'];['    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    call(Args,...)', '    cached_cast(at::ScalarType to_type,const Tensor & arg)', '    clear_cache', '    decrement_nesting', '    increment_nesting', '    is_eligible(const Tensor & arg)', '    is_enabled', '    prioritize(at::ScalarType current,const Tensor & nextArg)', '    prioritize(at::ScalarType current,const TensorList & list)', '    prioritize(at::ScalarType current,T nextArg)', '    promote_type(at::ScalarType current)', '    promote_type(at::ScalarType current,Arg0 arg0,Args,...)', '    set_enabled(bool new_enabled)', '    binary_cross_entropy_banned(const Tensor &,const Tensor &,const Tensor &,int64_t)', '    cached_cast(at::ScalarType to_type,const TensorList & arg)', '    cached_cast(at::ScalarType to_type,T arg)', '    firstarg_is_eligible(const Tensor & arg,Args,...)', '    set_opt_dtype(at::ScalarType to_type,const c10::optional & dtype)', '    set_opt_dtype(at::ScalarType to_type,T arg)', '    type_from_firstarg(at::ScalarType to_type,const Tensor & arg,Args,...)'];
BinaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 745;  59; 127;7;  578; 0;276;315;259;309;0.10;160;[];['    clear_cache', '    decrement_nesting', '    increment_nesting', '    is_enabled', '    set_enabled(bool new_enabled)'];
BinaryOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 59;  2; 8;3;  47; 0;34;33;10;150;0.04;2;[];['    _cat(TensorList A,int64_t B)', '    _convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H,int64_t I,bool J,bool K,bool L)', '    _convolution_nogroup(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H)', '    acos(const Tensor & A)', '    addbmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addcdiv(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D)', '    addcmul(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D)', '    addmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addmv(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    addr(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    asin(const Tensor & A)', '    atan2(const Tensor & A,const Tensor & B)', '    baddbmm(const Tensor & A,const Tensor & B,const Tensor & C,Scalar D,Scalar E)', '    bilinear(const Tensor & A,const Tensor & B,const Tensor & C,const Tensor & D)', '    binary_cross_entropy_with_logits(const Tensor & A,const Tensor & B,const Tensor & C,const Tensor & D,int64_t E)', '    bmm(const Tensor & A,const Tensor & B)', '    cat(TensorList A,int64_t B)', '    cat(TensorList A,Dimname B)', '    cdist(const Tensor & A,const Tensor & B,double C,c10::optional D)', '    chain_matmul(TensorList A)', '    conv1d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv2d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv3d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G)', '    conv_tbc(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D)', '    conv_transpose1d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    conv_transpose2d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    conv_transpose3d(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,IntArrayRef H)', '    convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,bool G,IntArrayRef H,int64_t I)', '    cosh(const Tensor & A)', '    cosine_embedding_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,int64_t E)', '    cosine_similarity(const Tensor & A,const Tensor & B,int64_t C,double D)', '    cross(const Tensor & A,const Tensor & B,c10::optional C)', '    cudnn_convolution(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,bool H,bool I)', '    cudnn_convolution(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D,IntArrayRef E,int64_t F,bool G,bool H)', '    cudnn_convolution_transpose(const Tensor & A,const Tensor & B,const Tensor & C,IntArrayRef D,IntArrayRef E,IntArrayRef F,IntArrayRef G,int64_t H,bool I,bool J)', '    cudnn_convolution_transpose(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D,IntArrayRef E,IntArrayRef F,int64_t G,bool H,bool I)', '    cumprod(const Tensor & A,int64_t B,c10::optional C)', '    cumprod(const Tensor & A,Dimname B,c10::optional C)', '    cumsum(const Tensor & A,int64_t B,c10::optional C)', '    cumsum(const Tensor & A,Dimname B,c10::optional C)', '    dist(const Tensor & A,const Tensor & B,Scalar C)', '    dot(const Tensor & A,const Tensor & B)', '    equal(const Tensor & A,const Tensor & B)', '    erfinv(const Tensor & A)', '    exp(const Tensor & A)', '    expm1(const Tensor & A)', '    frobenius_norm(const Tensor & A)', '    frobenius_norm(const Tensor & A,IntArrayRef B,bool C)', '    gelu(const Tensor & A)', '    group_norm(const Tensor & A,int64_t B,const Tensor & C,const Tensor & D,double E,bool F)', '    hinge_embedding_loss(const Tensor & A,const Tensor & B,double C,int64_t D)', '    kl_div(const Tensor & A,const Tensor & B,int64_t C)', '    l1_loss(const Tensor & A,const Tensor & B,int64_t C)', '    layer_norm(const Tensor & A,IntArrayRef B,const Tensor & C,const Tensor & D,double E,bool F)', '    linear(const Tensor & A,const Tensor & B,const Tensor & C)', '    log(const Tensor & A)', '    log10(const Tensor & A)', '    log1p(const Tensor & A)', '    log2(const Tensor & A)', '    log_softmax(const Tensor & A,int64_t B,c10::optional C)', '    log_softmax(const Tensor & A,Dimname B,c10::optional C)', '    margin_ranking_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,int64_t E)', '    matmul(const Tensor & A,const Tensor & B)', '    mm(const Tensor & A,const Tensor & B)', '    mse_loss(const Tensor & A,const Tensor & B,int64_t C)', '    multi_margin_loss(const Tensor & A,const Tensor & B,Scalar C,Scalar D,const Tensor & E,int64_t F)', '    multilabel_margin_loss(const Tensor & A,const Tensor & B,int64_t C)', '    mv(const Tensor & A,const Tensor & B)', '    native_layer_norm(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E,double F)', '    nll_loss(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E)', '    nll_loss2d(const Tensor & A,const Tensor & B,const Tensor & C,int64_t D,int64_t E)', '    norm(const Tensor & A,c10::optional B,ScalarType C)', '    norm(const Tensor & A,c10::optional B,IntArrayRef C,bool D,ScalarType E)', '    norm(const Tensor & A,c10::optional B,DimnameList C,bool D,ScalarType E)', '    nuclear_norm(const Tensor & A,bool B)', '    nuclear_norm(const Tensor & A,IntArrayRef B,bool C)', '    pdist(const Tensor & A,double B)', '    poisson_nll_loss(const Tensor & A,const Tensor & B,bool C,bool D,double E,int64_t F)', '    pow(const Tensor & A,Scalar B)', '    pow(const Tensor & A,const Tensor & B)', '    pow(Scalar A,const Tensor & B)', '    prelu(const Tensor & A,const Tensor & B)', '    prod(const Tensor & A,c10::optional B)', '    prod(const Tensor & A,int64_t B,bool C,c10::optional D)', '    prod(const Tensor & A,Dimname B,bool C,c10::optional D)', '    reciprocal(const Tensor & A)', '    renorm(const Tensor & A,Scalar B,int64_t C,Scalar D)', '    rsqrt(const Tensor & A)', '    sinh(const Tensor & A)', '    smooth_l1_loss(const Tensor & A,const Tensor & B,int64_t C)', '    soft_margin_loss(const Tensor & A,const Tensor & B,int64_t C)', '    softmax(const Tensor & A,int64_t B,c10::optional C)', '    softmax(const Tensor & A,Dimname B,c10::optional C)', '    softplus(const Tensor & A,Scalar B,Scalar C)', '    stack(TensorList A,int64_t B)', '    sum(const Tensor & A,c10::optional B)', '    sum(const Tensor & A,IntArrayRef B,bool C,c10::optional D)', '    sum(const Tensor & A,DimnameList B,bool C,c10::optional D)', '    tan(const Tensor & A)', '    tensordot(const Tensor & A,const Tensor & B,IntArrayRef C,IntArrayRef D)', '    triplet_margin_loss(const Tensor & A,const Tensor & B,const Tensor & C,double D,double E,double F,bool G,int64_t H)', '    _cat', '    _convolution', '    _convolution_nogroup', '    acos', '    addbmm', '    addcdiv', '    addcmul', '    addmm', '    addmv', '    addr', '    asin', '    atan2', '    baddbmm', '    bilinear', '    binary_cross_entropy_with_logits', '    bmm', '    cat', '    cdist', '    chain_matmul', '    conv1d', '    conv2d', '    conv3d', '    conv_tbc', '    conv_transpose1d', '    conv_transpose2d', '    conv_transpose3d', '    convolution', '    cosh', '    cosine_embedding_loss', '    cosine_similarity', '    cross', '    cudnn_convolution', '    cudnn_convolution_transpose', '    cumprod', '    cumsum', '    dist', '    dot', '    equal', '    erfinv', '    exp', '    expm1', '    frobenius_norm', '    gelu', '    group_norm', '    hinge_embedding_loss', '    kl_div', '    l1_loss', '    layer_norm', '    linear', '    log', '    log10', '    log1p', '    log2', '    log_softmax', '    margin_ranking_loss', '    matmul', '    mm', '    mse_loss', '    multi_margin_loss', '    multilabel_margin_loss', '    mv', '    native_layer_norm', '    nll_loss', '    nll_loss2d', '    norm', '    nuclear_norm', '    pdist', '    poisson_nll_loss', '    pow', '    prelu', '    prod', '    reciprocal', '    renorm', '    rsqrt', '    sinh', '    smooth_l1_loss', '    soft_margin_loss', '    softmax', '    softplus', '    stack', '    sum', '    tan', '    tensordot', '    triplet_margin_loss'];
BlasWrappersCPU.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 31;  3; 7;3;  20; 0;8;10;6;8;0.15;4;['    GradientHelper'];['    addReverseInline(Gradient & grad_desc)', '    createAutogradAdd(Value *a,Value *b)', '    deduplicateSizeCaptures(Gradient & grad_desc,ReverseDetails & rev_info)', '    eliminateDeadCode(ReverseDetails & rev_info)', '    err', '    foldSizeIfNotEqual(Block *reverse_block)', '    foldSizeIfNotEqual(Node *node)', '    getReverseCaptures(Gradient & grad_desc)', '    inBlock(Node *node,Block *container)', '    lambdaLiftReverse(Gradient & grad_desc,ReverseDetails & rev_info)', '    liftConstants(Block *block,Block *move_to_this_block)', '    liftConstants(Node *node,Block *move_to_this_block)', '    linearGradientForNode(Node *node,ArrayRef grad_values)', '    Optimize(Gradient & grad_desc,ReverseDetails & rev_info)', '    differentiate(std::shared_ptr & graph)', '    get_grad', '    graph', '    insert_guard', '    ival', '    packReturnValuesIntoTuple(const std::shared_ptr & graph)', '    isDifferentiable(Node *n)', '    isDifferentiable(Graph & g)', '    needTrimGrad(Node *n)', '    wrapDim(int64_t & dim,const std::vector & sizes)', '    buildSymbolicGradient(const ArrayRef & grad_values)', '    gradient(ArrayRef grad_values)', '    GradientHelper(Node *n)', '    ReverseDetails(value_map,Block *reverse_block)'];
Col2Im.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 249;  56; 28;7;  161; 0;90;67;44;30;0.35;6;[];['    differentiate(std::shared_ptr & graph)', '    isDifferentiable(Node *n)', '    isDifferentiable(Graph & g)', '    isZero(Value *v)', '    operator bool'];
ComplexHelper.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 33;  4; 5;2;  23; 0;15;10;11;10;0.17;2;[];['    graph_desc(std::shared_ptr node)', '    simple_fn(const Variable & x,const Variable & y)', '    TEST(AutogradAPITests,BackwardSimpleTest)', '    TEST(AutogradAPITests,BackwardTest)', '    TEST(AutogradAPITests,GradSimpleTest)', '    TEST(AutogradAPITests,GradTest)', '    TEST(AutogradAPITests,GradNonLeafTest)', '    TEST(AutogradAPITests,GradUnreachableTest)', '    TEST(AutogradAPITests,RetainGrad)', '    TEST(CustomAutogradTest,CustomFunction)', '    TEST(CustomAutogradTest,FunctionReturnsInput)', '    TEST(CustomAutogradTest,NoGradCustomFunction)', '    TEST(CustomAutogradTest,MarkDirty)', '    TEST(CustomAutogradTest,MarkNonDifferentiable)', '    TEST(CustomAutogradTest,MarkNonDifferentiableMixed)', '    TEST(CustomAutogradTest,MarkNonDifferentiableNone)', '    TEST(CustomAutogradTest,ReturnLeafInplace)', '    TEST(CustomAutogradTest,ReturnDuplicateInplace)', '    TEST(CustomAutogradTest,ReturnDuplicate)', '    TEST(CustomAutogradTest,SaveEmptyForBackward)', '    TEST(CustomAutogradTest,InvalidGradients)', '    TEST(CustomAutogradTest,NoGradInput)', '    TEST(CustomAutogradTest,TooManyGrads)', '    TEST(CustomAutogradTest,DepNoGrad)', '    TEST(CustomAutogradTest,Reentrant)', '    TEST(CustomAutogradTest,DeepReentrant)', '    TEST(CustomAutogradTest,ReentrantPriority)', '    TEST(CustomAutogradTest,Hooks)', '    TEST(CustomAutogradTest,HookNone)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctsx,variable_list grad_outputs)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable input)', '    backward(AutogradContext *,variable_list grad_output)', '    forward(AutogradContext *,Variable input,Variable ignore)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable a,Variable b)', '    backward(AutogradContext *,variable_list grad)', '    backward(AutogradContext *,variable_list grad_output)', '    backward(AutogradContext *,variable_list grad_outputs)', '    backward(AutogradContext *ctsx,variable_list grad_outputs)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_outputs)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable var1,int mul,Variable var2)', '    forward(AutogradContext *,Variable x)', '    forward(AutogradContext *ctx,Variable x)', '    forward(AutogradContext *,Variable x)', '    forward(AutogradContext *,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable input)', '    forward(AutogradContext *ctx,Variable v)', '    forward(AutogradContext *ctx,Variable v)', '    forward(AutogradContext *ctx,Variable var1)', '    backward(AutogradContext *ctx,variable_list dy)', '    forward(AutogradContext *ctx,Variable x)', '    backward(AutogradContext *ctx,variable_list grad)', '    forward(AutogradContext *ctx,Variable x,Variable y)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    backward(AutogradContext *ctx,variable_list grad_output)', '    forward(AutogradContext *ctx,Variable x)', '    forward(AutogradContext *ctx,Variable input)'];
ConstantPadNd.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 74;  3; 14;1;  57; 0;38;20;33;20;0.05;1;[];['    _make_grads(const variable_list & outputs,const variable_list & grad_outputs)', '    backward(const variable_list & tensors,const variable_list & grad_tensors,c10::optional retain_graph,bool create_graph)', '    grad(const variable_list & outputs,const variable_list & inputs,const variable_list & grad_outputs,c10::optional retain_graph,bool create_graph,bool allow_unused)', '    run_backward(const variable_list & outputs,const variable_list & grad_outputs,bool keep_graph,bool create_graph,const variable_list & inputs,bool allow_unused)'];
ConvolutionMM2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 575;  5; 56;8;  510; 0;288;228;104;100;0.01;11;[];[];
ConvolutionMM3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 678;  5; 54;7;  616; 0;383;245;113;112;0.01;13;[];[];
ConvolutionTBC.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 107;  11; 13;3;  80; 0;62;53;26;53;0.14;2;[];[];
Copy.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 173;  15; 30;10;  121; 0;86;24;98;30;0.12;5;[];['    AutogradMetadata(int64_t autogradContextId_,int64_t autogradMessageId_)'];
Copy.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 17;  2; 7;3;  7; 0;2;6;1;10;0.29;0;[];['    AutogradMetadata(int64_t autogradContextId_,int64_t autogradMessageId_)'];
Activation.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 615;  13; 35;17;  480; 81;0;0;0;3;0.03;0;['    AveragePoolingOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputHeight(size_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputSize(size_t inputHeight,size_t inputWidth)', '    inputWidth(size_t inputWidth)', '    inputWidth', '    inputWidth_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    nextBatchSize(size_t nextBatchSize)', '    nextBatchSize', '    nextBatchSize_', '    nextInputHeight(uint32_t nextInputHeight)', '    nextInputHeight', '    nextInputHeight_', '    nextInputSize(uint32_t nextInputHeight,uint32_t nextInputWidth)', '    nextInputWidth(uint32_t nextInputWidth)', '    nextInputWidth', '    nextInputWidth_', '    nextOutputHeight', '    nextOutputWidth', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputWidth', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    poolingHeight(uint32_t poolingHeight)', '    poolingHeight', '    poolingHeight_', '    poolingSize(uint32_t poolingSize)', '    poolingSize(uint32_t poolingHeight,uint32_t poolingWidth)', '    poolingWidth(uint32_t poolingWidth)', '    poolingWidth', '    poolingWidth_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testQ8', '    testSetupQ8'];
avx_mathfun.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 715;  118; 129;73;  353; 56;324;128;288;214;0.33;12;[];['    compute_output_dimension(size_t padded_input_dimension,size_t pooling_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_average_pooling2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *average_pooling_out)', '    pytorch_qnnp_setup_average_pooling2d_nhwc_q8(pytorch_qnnp_operator_t average_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)'];
batch_norm_kernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 114;  20; 16;6;  75; 0;45;49;38;44;0.27;3;[];['    TEST(AVERAGE_POOLING_OP,zero_batch)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_small_pool_with_qmax)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_many_channels_large_pool_with_qmax)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_1xM_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_padding)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_scale)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_zero_point)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_qmin)', '    TEST(AVERAGE_POOLING_OP,unit_batch_few_channels_with_qmax)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_small_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_many_channels_large_pool_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(AVERAGE_POOLING_OP,small_batch_few_channels_with_output_stride)', '    TEST(AVERAGE_POOLING_OP,setup_increasing_batch)', '    TEST(AVERAGE_POOLING_OP,setup_decreasing_batch)', '    TEST(AVERAGE_POOLING_OP,setup_changing_height)', '    TEST(AVERAGE_POOLING_OP,setup_changing_width)', '    TEST(AVERAGE_POOLING_OP,setup_swap_height_and_width)'];
BinaryOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 631;  18; 46;10;  565; 0;431;99;1445;375;0.03;39;[];['    average_pooling_q8(benchmark::State & state,const char *net)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)'];
CatKernel.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 11;  1; 4;3;  4; 0;2;3;1;9;0.25;0;['    final'];['    operator()(const at::Tensor & X_,const at::Tensor & sum_)'];
CopyKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 71;  17; 6;6;  45; 0;34;11;138;39;0.38;1;[];['    avg_pool2d_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)'];
CrossKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 78;  2; 12;8;  58; 0;49;15;44;23;0.03;2;[];['    avg_pool3d_backward_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int padT,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int padT,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    avg_pool3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)'];
DepthwiseConvKernel.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 19;  5; 6;3;  7; 0;3;5;1;9;0.71;0;['    AvgPoolMicrokernelTester'];['    iterations(size_t iterations)', '    iterations', '    iterations_', '    kc(size_t kc)', '    kc', '    kc_', '    kh(size_t kh)', '    kh', '    kh_', '    kr(size_t kr)', '    kr', '    kr_', '    ks', '    kw(size_t kw)', '    kw', '    kw_', '    mr(size_t mr)', '    mr', '    mr_', '    n(size_t n)', '    n', '    n_', '    packedKs', '    packedN', '    qr(size_t qr)', '    qr', '    qr_', '    s(size_t s)', '    s', '    s_', '    test(pytorch_q8avgpool_up_ukernel_function q8avgpool)', '    test(pytorch_q8avgpool_mp_ukernel_function q8avgpool)', '    xScale(float xScale)', '    xScale', '    xScale_', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    xZeroPoint(uint8_t xZeroPoint)', '    xZeroPoint', '    xZeroPoint_', '    yMax(uint8_t yMax)', '    yMax', '    yMax_', '    yMin(uint8_t yMin)', '    yMin', '    yMin_', '    yScale(float yScale)', '    yScale', '    yScale_', '    yStride(size_t yStride)', '    yStride', '    yStride_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_'];
DistanceOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 443;  51; 68;7;  320; 0;217;151;148;171;0.16;34;[];[];
DistributionTemplates.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 252;  11; 20;15;  159; 50;107;45;195;66;0.07;11;[];[];
GridSamplerKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 1034;  254; 121;95;  578; 7;342;364;162;328;0.44;29;[];['    _mm256_add_epi32(v8si x,v8si y)', '    _mm256_and_si128(v8si x,v8si y)', '    _mm256_andnot_si128(v8si x,v8si y)', '    _mm256_cmpeq_epi32(v8si x,v8si y)', '    _mm256_slli_epi32(v8si x,int a)', '    _mm256_srli_epi32(v8si x,int a)', '    _mm256_sub_epi32(v8si x,v8si y)', '    cos256_ps(v8sf x)', '    exp256_ps(v8sf x)', '    log256_ps(v8sf x)', '    sin256_ps(v8sf x)', '    sincos256_ps(v8sf x,v8sf *s,v8sf *c)'];
GridSamplerKernel.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 18;  1; 5;7;  6; 0;4;5;2;18;0.17;0;[];['    kBrokenOperators', '    kRenamedAttrs', '    kRenamedOperators', '    kRNNOperators', '    AlmostEqual(double a,double b)', '    BuildOperator(caffe2::OperatorDef *c2_op,const std::string & op_type,const std::vector & inputs,const std::vector & outputs,const std::vector & args)', '    BuildOperator(caffe2::OperatorDef *c2_op,const std::string & op_type,const std::vector & inputs,const std::vector & outputs)', '    CopyOnnxAttrValueToCaffe2Arg(caffe2::Argument *arg,const AttributeProto & attr)', '    GetDeviceOption(const Device & onnx_device)', '    IsOperator(const std::string & op_type)', '    LookUpWithDefault(const std::unordered_map & map,const T & key,const U & default_value)', '    OptimizeOnnx(const ModelProto & input,bool init)', '    TryConvertingTensorRawValues(const TensorProto & onnx_tensor,::google::protobuf::RepeatedField *field)', '    UpdateNames(std::shared_ptr dummy,const caffe2::OperatorDef & op)', '    check_fc', '    converter', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    ConvertIntegralValueToCaffe2(caffe2::OperatorDef *c2_op,caffe2::Argument *c2_values,const TensorProto & onnx_tensor)', '    graph_value_infos', '    passes', '    value_infos', '    get_broken_operators', '    get_renamed_attrs', '    get_renamed_operators', '    get_rnn_operators', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key)', '    OnnxAttributes(const NodeProto & node)', '    OnnxAttrToCaffe2Arg(std::function mapper)', '    AllNamesInGraph(const GraphProto & graph)', '    BuildTensorFillingOp(caffe2::OperatorDef *c2_op,const TensorProto & onnx_tensor,const std::string & output_name,const std::string & shape_name)', '    CheckOpSchemaArguments(const caffe2::OpSchema & schema,const caffe2::OperatorDef & op)', '    CommonOnnxNodeToCaffe2Ops(OnnxNode *onnx_node,const ConversionContext & ctx)', '    ConvertNode(const std::string & node_str,const ConversionContext & ctx)', '    CreateArgMaxMin(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateBatchNormalization(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateCast(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConcat(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstant(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstantOfShape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConvPoolOpBase(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDropout(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDynamicSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGather(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGemm(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLogSoftmax(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLRN(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMatMul(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMultinomialOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateNonZeroOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePad(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateRandomNormal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReciprocal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReshape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSplit(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateUpsample(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateWhereOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    get_special_operators', '    OnnxNodeToCaffe2Ops(const ModelProto & init_model,const ModelProto & pred_model,const ConversionContext & ctx,OnnxNode *onnx_node)', '    OnnxToCaffe2(caffe2::NetDef *init_net,caffe2::NetDef *pred_net,const ModelProto & onnx_model,const std::string & device,int opset_version,bool include_initializers,const std::vector & extras)', '    Prepare(const std::string & onnx_model_str,const std::string & device,const std::vector & extras)', '    PreprocessSliceIndexTensor(OnnxNode *onnx_node,Caffe2Ops & ret,std::string indices_tensor,std::string axes_tensor,std::string rank_tensor,std::string zero_tensor,std::string one_tensor,int default_value)', '    SupportOp(const std::string type)'];
IndexKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 173;  10; 16;8;  142; 0;94;74;180;71;0.07;8;[];[];
IsContiguous.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 62;  8; 9;1;  44; 0;0;0;0;0;0.18;0;[];[];
layer_norm_kernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 178;  3; 11;7;  160; 0;92;91;63;52;0.02;4;['    Caffe2Backend', '    ConversionContext', '    OnnxAttributes'];['    AllNamesInGraph(const GraphProto & graph)', '    BuildTensorFillingOp(caffe2::OperatorDef *c2_op,const TensorProto & onnx_tensor,const std::string & output_name,const std::string & shape_name)', '    Caffe2Backend(DummyName *dummy)', '    CheckOpSchemaArguments(const caffe2::OpSchema & schema,const caffe2::OperatorDef & op)', '    CommonOnnxNodeToCaffe2Ops(OnnxNode *onnx_node,const ConversionContext & ctx)', '    ConvertNode(const std::string & node_str,const ConversionContext & ctx)', '    CreateArgMaxMin(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateBatchNormalization(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateCast(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConcat(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstant(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConstantOfShape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateConvPoolOpBase(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDropout(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateDynamicSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGather(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateGemm(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLogSoftmax(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateLRN(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMatMul(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateMultinomialOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateNonZeroOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePad(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreatePadPool(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateRandomNormal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReciprocal(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateReshape(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSlice(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateSplit(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateUpsample(OnnxNode *onnx_node,const ConversionContext & ctx)', '    CreateWhereOp(OnnxNode *onnx_node,const ConversionContext & ctx)', '    get_broken_operators', '    get_renamed_attrs', '    get_renamed_operators', '    get_rnn_operators', '    get_special_operators', '    OnnxNodeToCaffe2Ops(const ModelProto & init_model,const ModelProto & pred_model,const ConversionContext & ctx,OnnxNode *onnx_node)', '    OnnxToCaffe2(caffe2::NetDef *init_net,caffe2::NetDef *pred_net,const ModelProto & onnx_model,const std::string & device,int opset_version,bool include_initializers,const std::vector & extras)', '    Prepare(const std::string & onnx_model_str,const std::string & device,const std::vector & extras)', '    PreprocessSliceIndexTensor(OnnxNode *onnx_node,Caffe2Ops & ret,std::string indices_tensor,std::string axes_tensor,std::string rank_tensor,std::string zero_tensor,std::string one_tensor,int default_value)', '    SupportOp(const std::string tyep)', '    ConversionContext(const ValueInfoMap & value_infos,int opset_version)', '    opset_version', '    value_infos', '    AddRewrittenAttribute(const std::string & key)', '    get(const std::string & key)', '    get(const std::string & key,const T & default_value)', '    get(const std::string & key)', '    HasAttribute(const std::string & key)', '    OnnxAttributes(const NodeProto & node)', '    OnnxAttrToCaffe2Arg(std::function mapper)', '    remove(const std::string & key)', '    OnnxNode(const NodeProto & node_in)'];
LerpKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 71;  10; 7;5;  53; 0;33;23;58;19;0.19;2;[];['    ConvertToC2Net(const TransformSubgraph & sub,const std::unordered_map & infos)', '    DetectBoundaryReferences(TransformSubgraph *subgraph,const std::unordered_map & infos,const std::unordered_set & original_external_output)', '    DumpGraph(NNGraph *g,const std::string & fname)', '    Explore(const std::vector & current_frontier,VisitorContext *context)', '    GetInfo(std::unordered_map & infos,NodeRef node)', '    GetInfo(const std::unordered_map & infos,NodeRef node)', '    OptimizeForBackend(caffe2::NetDef & net,std::function supports,std::function transform_func,bool debug)', '    PruneUnrefereredNodes(NNModule *nn)', '    ReplaceSubgraph(const TransformSubgraph & subgraph,caffe2::NetDef & net_opt,NNGraph *g)', '    ShowNode(NodeRef node)', '    GroupAnnotation(int i,int g)', '    needs_transform', '    group_id', '    needed', '    operator=(TransformSubgraph)', '    Print', '    TransformSubgraph(std::vector,std::vector,int id,bool need)', '    TransformSubgraph(TransformSubgraph)', '    find_supported', '    group', '    VisitorContext(std::function func)'];
MultinomialKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 144;  18; 22;10;  92; 2;58;41;64;40;0.20;2;[];['    DumpGraph(NNGraph *g,const std::string & fname)', '    OptimizeForBackend(caffe2::NetDef & net,std::function supports,std::function transform_func,bool debug)'];
PointwiseOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 102;  4; 9;5;  87; 0;69;22;156;51;0.05;4;[];['    AddConv(caffe2::NetDef *net,int tick)', '    Supports(const caffe2::OperatorDef & op)', '    TEST(BackendCuttingTest,unit)', '    TEST(BackendCuttingTest,line)', '    TEST(BackendCuttingTest,convergedPaths)', '    TEST(BackendCuttingTest,skipPath)', '    Transform(const caffe2::NetDef & net)'];
PowKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 242;  12; 9;7;  217; 0;204;18;138;40;0.06;2;[];['    callBoxedWorkaround(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    generic_mode_fallback(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    generic_wrapper_fallback(const c10::OperatorHandle & op,torch::jit::Stack *stack)', '    TEST(BackendFallbackTest,TestBackendFallbackWithMode)', '    TEST(BackendFallbackTest,TestBackendFallbackWithWrapper)', '    TEST(BackendFallbackTest,TestFallthroughBackendFallback)', '    GenericWrapperTensorImpl(at::Tensor rep)'];
ReduceAllOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 116;  7; 11;10;  89; 0;44;41;42;223;0.08;6;[];['    CheckInit', '    Run(const caffe2::Predictor::TensorList & inputs,caffe2::Predictor::TensorList *outputs)', '    RunMap(const caffe2::Predictor::TensorMap & inputs,caffe2::Predictor::TensorList *outputs)'];
ReduceOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 302;  17; 32;13;  247; 0;185;82;555;171;0.07;14;['    Caffe2BackendRep'];['    CheckInit', '    init_net', '    init_net', '    pred_net', '    pred_net', '    predictor_', '    Run(const caffe2::Predictor::TensorList & inputs,caffe2::Predictor::TensorList *outputs)', '    RunMap(const caffe2::Predictor::TensorMap & inputs,caffe2::Predictor::TensorList *outputs)', '    uninitialized_inputs', '    uninitialized_inputs'];
ScatterGatherKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 295;  36; 38;4;  225; 0;146;63;90;51;0.16;8;[];['    seq_id', '    wrapShapeInfoIntoQTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    wrapShapeInfoIntoTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    annotateOpIndex(NetDef *net)', '    getModelId(const NetDef & net)', '    addShapeToNet(NetDef & shape_net,const ShapeInfoMap & shape_hints)', '    dumpNet(const NetDef & pred_net,const ShapeInfoMap & shape_hints,const std::string & fname)', '    inferShapes(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & shape_hints_mapped,const BoundShapeSpec & spec)', '    ssaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & input_shape_hints)'];
SoftmaxKernel.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 18;  0; 5;3;  10; 0;6;8;2;26;0.00;0;['    BackendTransformerBase'];['    wrapShapeInfoIntoQTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    wrapShapeInfoIntoTensorProto(const std::string & name,const ShapeInfo & shape_info)', '    annotateOpIndex(NetDef *net)', '    getModelId(const NetDef & net)', '    addShapeToNet(NetDef & shape_net,const ShapeInfoMap & shape_hints)', '    BackendTransformerBase', '    dumpNet(const NetDef & pred_net,const ShapeInfoMap & shape_hints,const std::string & fname)', '    inferShapes(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & shape_hints_mapped,const BoundShapeSpec & spec)', '    input_mapping', '    reverse_input_mapping', '    ssaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const ShapeInfoMap & input_shape_hints)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    ~BackendTransformerBase', '    BackendTransformOptions', '    debug', '    min_ops'];
SortingKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 90;  3; 10;6;  73; 0;59;14;35;13;0.04;1;[];[];
TensorCompareKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 166;  5; 17;12;  135; 0;103;49;152;50;0.04;4;[];['    registry', '    $'];
Unfold2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 306;  13; 14;5;  277; 0;200;76;63;24;0.05;5;[];['    get_backtrace(size_t frames_to_skip,size_t maximum_number_of_frames,bool skip_python_frames)'];
UpSampleKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 411;  23; 48;4;  339; 0;243;247;202;114;0.07;14;[];[];
zmath.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 242;  5; 45;4;  192; 0;48;89;44;125;0.03;29;[];['    get_backtrace(size_t frames_to_skip,size_t maximum_number_of_frames,bool skip_python_frames)'];
Cross.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 13;  1; 6;3;  4; 0;2;3;1;9;0.25;0;[];[];
CUDAUnaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 69;  1; 12;10;  46; 0;27;20;37;24;0.02;22;[];['    locateBailOutNodeInUnoptimizedGraph(Block *b,int64_t index)', '    removeBailouts(Block *b)', '    shouldBeCapturedInByBailOut(Node *n)', '    BuildBailOutGraphFrom(int64_t bailout_index,const std::shared_ptr & orig,const std::shared_ptr & target)', '    InsertBailOuts(std::shared_ptr graph)', '    addNewInputForValue(Value *old_value)', '    BailOutGraphBuilderForNode(std::shared_ptr graph,std::shared_ptr target)', '    buildBailOutBlockFrom(Node *n)', '    buildBailOutGraphFrom(Node *n)', '    buildBailOutIf(const at::ArrayRef block_outputs,Node *outer_node)', '    buildBailOutLoop(Node *outer_node)', '    cloneNode(Node *node)', '    getInputForValue(Value *v)', '    getOrAddInputForValue(Value *v)', '    mapValueAndCopyMetadata(Value *old_value,Value *new_value)', '    mapValues(const at::ArrayRef block_outputs,const at::ArrayRef carried_deps)', '    addUnoptimizedFuncToBailouts', '    BailOutInserter(std::shared_ptr graph)', '    insertBailOuts(Block *b)', '    removeGuards(Block *b)', '    replaceGuardsWithBailouts', '    run'];
CuFFTPlanCache.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 480;  102; 52;34;  251; 53;144;89;120;82;0.41;17;[];['    BuildBailOutGraphFrom(int64_t bailout_index,const std::shared_ptr & orig,const std::shared_ptr & target)', '    InsertBailOuts(std::shared_ptr graph)'];
DistributionTemplates.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 379;  44; 23;19;  295; 0;203;91;193;115;0.15;10;[];[];
LaunchUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 18;  3; 3;2;  12; 0;6;5;6;3;0.25;1;['    final'];['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    signalFailure(ws_,ioe)', '    BarrierOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~BarrierOp'];
LegacyDefinitions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 92;  8; 11;5;  69; 0;44;15;33;15;0.12;7;[];[];
TensorShapeCUDA.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 30;  4; 6;4;  16; 0;7;9;5;6;0.25;2;[];[];
AffineGridGenerator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 95;  4; 15;14;  47; 19;20;26;25;19;0.09;5;[];[];
BatchNorm.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 344;  36; 31;24;  156; 111;85;51;72;43;0.23;14;[];[];
GridSampler.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 146;  20; 24;12;  82; 18;44;38;37;34;0.24;11;[];['    SendContext', '    test(DeprecatedTypeProperties & type)', '    TEST(BasicTest,BasicTestCPU)', '    TEST(BasicTest,BasicTestCUDA)', '    TEST(BasicTest,FactoryMethodsTest)', '    TestAbsValue(DeprecatedTypeProperties & type)', '    TestAdd(DeprecatedTypeProperties & type)', '    TestAddingAValueWithScalar(DeprecatedTypeProperties & type)', '    TestCopy(DeprecatedTypeProperties & type)', '    TestCopyBroadcasting(DeprecatedTypeProperties & type)', '    TestDispatch', '    TestIndexingByScalar', '    TestIndexingByZerodimTensor', '    TestIndexingMixedDevice(DeprecatedTypeProperties & type)', '    TestIntArrayRefExpansion(DeprecatedTypeProperties & type)', '    TestIsContiguous(DeprecatedTypeProperties & type)', '    TestLoadOfAddsWithCopy(DeprecatedTypeProperties & type)', '    TestLoadsOfAdds(DeprecatedTypeProperties & type)', '    TestMm(DeprecatedTypeProperties & type)', '    TestNegativeDim(DeprecatedTypeProperties & type)', '    TestOnesAndDot(DeprecatedTypeProperties & type)', '    TestPermute(DeprecatedTypeProperties & type)', '    TestRandperm(DeprecatedTypeProperties & type)', '    TestResize(DeprecatedTypeProperties & type)', '    TestSelect(DeprecatedTypeProperties & type)', '    TestSort(DeprecatedTypeProperties & type)', '    TestSqueeze(DeprecatedTypeProperties & type)', '    TestTensorFromTH', '    TestToCFloat', '    TestToString', '    TestView(DeprecatedTypeProperties & type)', '    TestZeroDim(DeprecatedTypeProperties & type)'];
LossCTC.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 143;  13; 20;14;  80; 21;39;34;38;26;0.16;6;[];['    apply(variable_list)', '    apply(variable_list)'];
RNN.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 1337;  197; 152;42;  897; 65;431;393;382;576;0.22;56;[];['    apply(variable_list)', '    DelayedError(std::string msg,int num_inputs)', '    apply(variable_list)', '    Error(std::string msg,edge_list)', '    Error(std::string msg)', '    apply(variable_list)', '    GraphRoot(edge_list functions,variable_list inputs)', '    undefined_input', '    NotImplemented(const std::string & forward_fn,edge_list)', '    NotImplemented(const std::string & forward_fn)'];
DilatedMaxPool2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 513;  30; 49;6;  431; 0;269;165;106;61;0.07;10;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBoxCox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBoxCox', '    DoRunWithType'];
DilatedMaxPool3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 573;  26; 56;6;  492; 0;323;190;106;75;0.05;10;['    final'];['    BatchBoxCoxOp(Args,...)', '    BoxCoxNaive(int64_t N,int64_t D,const T *data_ptr,const T *lambda1_ptr,const T *lambda2_ptr,T k_eps,T *output_ptr)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice'];
DispatchStub.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 44;  1; 7;7;  30; 0;17;6;15;6;0.03;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBucketize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBucketize', '    RunOnDevice'];
Distance.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 193;  12; 19;6;  157; 0;114;76;91;75;0.08;14;['    final'];['    BatchBucketizeOp(Args,...)', '    RunOnDevice'];
Distance.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 18;  1; 5;3;  10; 0;8;6;4;30;0.10;0;[];['    batch_gather_op_cpu(const at::Tensor & data,const at::Tensor & indices,const at::Tensor & output)', '    batch_gather_op_cpu_impl(const at::Tensor & data_,const at::Tensor & indices_,const at::Tensor & output_)'];
Distributions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 438;  50; 52;25;  309; 4;197;87;234;108;0.16;31;['    GetBatchGatherGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchGather', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchGatherGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchGatherGradient', '    vector', '    GetGradientDefs'];
DistributionTemplates.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 265;  40; 21;14;  192; 0;131;53;207;65;0.21;14;['    final', '    final'];['    BatchGatherGradientOp(Args,...)', '    BatchGatherOp(Args,...)', '    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    RunOnDevice', '    ~BatchGatherGradientOp'];
Dropout.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 125;  5; 23;8;  92; 0;49;34;46;29;0.05;18;['    final'];['    operator()(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & Y_,int64_t trans_a,int64_t trans_b,int64_t broadcast)'];
Embedding.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 165;  10; 29;8;  119; 0;85;59;45;38;0.08;6;[];['    noBroadcastErrorMsg', '    doNothingObj', '    doNothingObj', '    doNothingObj', '    BatchMatMulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
Fill.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 102;  11; 21;4;  69; 0;39;35;75;41;0.16;6;['    final'];['    BatchMatMulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    broadcast_', '    first_invocation_', '    is_B_constant_', '    RunOnDevice'];
Fill.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 13;  2; 5;4;  3; 0;1;3;0;7;0.67;0;['    GetBatchMatMulGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMatMul', '    TensorInferenceForBatchMatMul(const OperatorDef & def,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMatMul', '    CostInferenceForBatchMatMul(const OperatorDef & def,const vector & in)', '    output_dims', '    trans_a_arg', '    trans_b_arg', '    trans_both_arg', '    CopyArguments', '    GetGradientDefs'];
FractionalMaxPool2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 391;  16; 45;5;  329; 0;212;120;82;50;0.05;11;['    final'];['    BatchMatMulOp(Args,...)', '    DoRunWithType', '    RunOnDevice'];
GatedLinearUnit.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 75;  8; 10;4;  55; 0;36;30;23;27;0.15;4;['    BatchMatMulOpGPUTest'];['    TEST_F(BatchMatMulOpGPUTest,BatchMatMulOpGPUNormalTest)', '    TEST_F(BatchMatMulOpGPUTest,BatchMatMulOpGPUBroadcastTest)', '    AddConstInput(const std::vector & dims,const float value,const string & name)', '    SetUp', '    VerifyOutput(const std::vector & dims,const float value)'];
GridSampler.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 486;  35; 42;9;  403; 0;323;101;63;89;0.09;7;['    BatchMatMulOpTest'];['    TEST_F(BatchMatMulOpTest,BatchMatMulOpNormalTest)', '    TEST_F(BatchMatMulOpTest,BatchMatMulOpBroadcastTest)', '    AddConstInput(const std::vector & dims,const float value,const string & name)', '    SetUp', '    VerifyOutput(const std::vector & dims,const float value)'];
GridSampler.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 224;  46; 19;3;  158; 0;80;58;64;32;0.29;12;['    Side'];['    batch_side', '    BatchMM(std::shared_ptr & graph)', '    BatchMMSide(Block *block,AliasDb & alias_db)', '    hasMutableOperators(Block *block)', '    insert_guard', '    insert_guard', '    insert_guard', '    queue', '    aliasAnalysisIsSpecialCase', '    BatchMMTreeReduce(Block *block)', '    have_same_shape(at::TensorList inputs)', '    postprocess', '    shape_is_fast_for_reduce(const at::Tensor & lhs,const at::Tensor & rhs)', '    shape_is_fast_for_side(const at::Tensor & other_side_input)', '    should_be_transposed(at::TensorList inputs)', '    transpose_inputs(at::TensorList inputs)', '    add(Node *add,TreeToken & l,TreeToken & r)', '    mm(Node *mm)', '    transpose(Node *t,TreeToken & inp_token)', '    operator bool', '    removeTransposesAndGatherMatmuls'];
im2col.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 94;  2; 13;5;  76; 0;30;60;16;26;0.03;2;[];['    BatchMM(std::shared_ptr & graph)'];
im2col_shape_check.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 209;  2; 19;2;  188; 0;48;57;40;16;0.01;2;['    GetBatchMomentsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMoments', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchMomentsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMoments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchMomentsGradient', '    ComputeBatchMomentsGradientNCHW(const int N,const int C,const int HxW,const float *dmu,const float *dvar,const float *X,float *dX)', '    ComputeBatchMomentsGradientNHWC(const int N,const int C,const int HxW,const float *dmu,const float *dvar,const float *X,float *dX)', '    ComputeBatchMomentsNCHW(const int N,const int C,const int HxW,const float *X,float *mu,float *var)', '    GetGradientDefs', '    vector'];
IndexingUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 128;  11; 14;2;  101; 0;27;43;19;159;0.11;3;['    final', '    final'];['    BatchMomentsGradientOp(Args,...)', '    BatchMomentsOp(Args,...)', '    ComputeBatchMomentsGradientNCHW(const int N,const int C,const int HxW,const T *dmu,const T *dvar,const T *X,T *dX)', '    ComputeBatchMomentsGradientNHWC(const int N,const int C,const int HxW,const T *dmu,const T *dvar,const T *X,T *dX)', '    ComputeBatchMomentsNCHW(const int N,const int C,const int HxW,const T *X,T *mu,T *var)', '    ComputeBatchMomentsNHWC(const int N,const int C,const int HxW,const T *X,T *mu,T *var)', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice'];
Itertools.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 60;  5; 9;3;  46; 0;26;19;22;17;0.11;3;[];['    batch_norm_cpu_inference_contiguous_stub', '    batch_norm_cpu_inference_contiguous_stub', '    operator='];
layer_norm.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 129;  7; 12;12;  105; 0;43;57;26;26;0.07;3;[];['    batch_norm_cpu_inference_collect_linear_and_constant_terms(TensorAccessor alpha,TensorAccessor beta,int64_t n_channel,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_contiguous_impl(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_contiguous_kernel(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)'];
layer_norm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 36;  21; 6;3;  27; 0;23;6;2;16;0.78;0;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8BatchPermutation', '    RunOnDevice'];
LegacyDefinitions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 49;  4; 7;5;  34; 0;20;7;15;7;0.12;4;['    final'];['    BatchPermutationDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
LegacyNNDefinitions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 61;  1; 14;3;  44; 0;18;20;12;20;0.02;12;['    GetBatchPermutationGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchPermutation', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchPermutationGradient', '    schema_OperatorName', '    batch_permutation_loop(const int N,const int K,const float *src,const int *indices,float *dst)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchPermutation', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchPermutationGradient', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs'];
Lerp.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 56;  2; 10;6;  40; 0;11;22;12;18;0.05;6;['    final', '    final'];['    schema_BatchPermutation', '    BatchPermutationGradientOp(const OperatorDef & def,Workspace *ws)', '    BatchPermutationOp(Args,...)', '    RunOnDevice'];
Linear.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 531;  114; 31;9;  422; 0;302;134;282;129;0.27;6;[];['    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInputCPU(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInputGPU(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    CheckCPUGPUEqual(vector shape,vector indices)', '    CreateAndRun(TensorCPU *outResult,int N,vector & shape,vector & features,vector indices)', '    CreateAndRunGradient(TensorCPU *outResult,int N,vector & shape,vector & features,vector indices)', '    GetDeviceType', '    TEST(BatchPermutationTest,CHECKCPUGPUEqualGenericDimension)', '    y_cpu', '    y_cpu_grad', '    y_gpu', '    y_gpu_grad'];
LinearAlgebra.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 689;  109; 87;14;  499; 0;323;167;285;175;0.22;36;['    GetBatchDenseToSparseGradient', '    GetBatchSparseToDenseGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchDenseToSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchSparseToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchDenseToSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchSparseToDense', '    vector', '    vector', '    FillInSparseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const float *dense_data,float *output_data,CPUContext *)', '    FillInDenseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const float *values_data,float *output_data,CPUContext *)', '    GetGradientDefs', '    GetGradientDefs'];
LinearAlgebraUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 281;  63; 32;7;  180; 0;111;58;120;65;0.35;15;['    BatchDenseToSparseOp', '    BatchSparseToDenseOp'];['    BatchDenseToSparseOp(Args,...)', '    FillInSparseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const T *dense_data,T *output_data,Context *context)', '    len_prefix_sum_', '    len_prefix_tmp_', '    RunOnDevice', '    BatchSparseToDenseOp(Args,...)', '    FillInDenseValues(const int64_t batch_size,const int64_t indice_lengths,const int64_t *lengths_data,const int64_t *indices_data,const T *values_data,T *output_data,Context *context)', '    len_prefix_sum_', '    len_prefix_tmp_', '    RunOnDevice'];
LossCTC.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 388;  71; 36;6;  289; 0;227;71;103;69;0.25;7;[];['    apply_cholesky(Tensor & self,bool upper,std::vector & infos)', '    apply_cholesky_solve(Tensor & b,Tensor & A,bool upper,std::vector & infos)', '    apply_geqrf(Tensor & self,Tensor & tau,int64_t m,int64_t n,std::vector & infos)', '    apply_inverse(Tensor & self,std::vector & infos)', '    apply_lu(Tensor & self,Tensor & pivots,Tensor & infos)', '    apply_lu_solve(Tensor & b,const Tensor & lu,const Tensor & pivots,std::vector & infos)', '    apply_orgqr(Tensor & self,const Tensor & tau,int64_t m,int64_t n_columns,int64_t k,std::vector & infos)', '    apply_solve(Tensor & b,Tensor & A,std::vector & infos)', '    apply_svd(Tensor & self,Tensor & U,Tensor & S,Tensor & VT,char jobz,std::vector & infos)', '    apply_symeig(Tensor & self,Tensor & eigvals,bool eigenvectors,bool upper,std::vector & infos)', '    apply_triangular_solve(Tensor & b,Tensor & A,bool upper,bool transpose,bool unitriangular)', '    _cholesky_helper_cpu(const Tensor & self,bool upper)', '    _cholesky_solve_helper_cpu(const Tensor & self,const Tensor & A,bool upper)', '    _inverse_helper_cpu(const Tensor & self)', '    _lu_solve_helper_cpu(const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    _lu_with_info_cpu(const Tensor & self,bool pivot,bool check_errors)', '    _qr_helper_cpu(const Tensor & self,bool some)', '    _solve_helper_cpu(const Tensor & self,const Tensor & A)', '    _svd_helper_cpu(const Tensor & self,bool some,bool compute_uv)', '    _symeig_helper_cpu(const Tensor & self,bool eigenvectors,bool upper)', '    _triangular_solve_helper_cpu(const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)', '    cholesky(const Tensor & self,bool upper)', '    cholesky_out(Tensor & result,const Tensor & self,bool upper)', '    cholesky_solve(const Tensor & self,const Tensor & A,bool upper)', '    cholesky_solve_out(Tensor & result,const Tensor & self,const Tensor & A,bool upper)', '    inverse(const Tensor & self)', '    inverse_out(Tensor & result,const Tensor & self)', '    lu_solve(const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    lu_solve_out(Tensor & result,const Tensor & self,const Tensor & LU_data,const Tensor & LU_pivots)', '    qr(const Tensor & self,bool some)', '    qr_out(Tensor & Q,Tensor & R,const Tensor & self,bool some)', '    solve(const Tensor & self,const Tensor & A)', '    solve_out(Tensor & solution,Tensor & lu,const Tensor & self,const Tensor & A)', '    svd(const Tensor & self,bool some,bool compute_uv)', '    svd_out(Tensor & U,Tensor & S,Tensor & VT,const Tensor & self,bool some,bool compute_uv)', '    symeig(const Tensor & self,bool eigenvectors,bool upper)', '    symeig_out(Tensor & vals,Tensor & vecs,const Tensor & self,bool eigenvectors,bool upper)', '    triangular_solve(const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)', '    triangular_solve_out(Tensor & result,Tensor & clone_A,const Tensor & self,const Tensor & A,bool upper,bool transpose,bool unitriangular)'];
LossMultiLabelMargin.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 345;  6; 43;4;  296; 0;158;123;148;72;0.02;9;[];['    cudnn_batch_norm_backward(const Tensor & input_t,const Tensor & grad_output_t,const Tensor & weight_t,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean_t,const Tensor & save_var_t,double epsilon,const Tensor & reserveSpace)', '    cudnn_batch_norm(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,const Tensor & running_mean_t,const Tensor & running_var_t,bool training,double exponential_average_factor,double epsilon)', '    expandScale(const Tensor & t,int64_t dim)', '    idesc', '    idesc', '    input', '    input', '    odesc', '    output', '    size', '    t', '    t', '    wdesc', '    wdesc'];
LossMultiMargin.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 340;  7; 31;3;  303; 0;168;132;118;58;0.02;10;[];['    BatchNormOptions(int64_t num_features)'];
LossNLL2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 416;  11; 55;5;  348; 0;209;144;98;79;0.03;12;[];['    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    pretty_print(std::ostream & stream)'];
Math.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 267;  79; 22;18;  148; 4;0;0;0;0;0.53;0;[];[];
MaxUnpooling.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 609;  14; 50;11;  540; 0;288;220;254;141;0.03;13;[];[];
BatchNorm_miopen.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/miopen; 210;  16; 27;11;  143; 22;105;45;43;38;0.11;13;[];[];
Conv_miopen.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/miopen; 1163;  87; 169;22;  797; 96;446;355;225;253;0.11;79;[];['    miopen_batch_norm_backward(const Tensor & input_t,const Tensor & grad_output_t,const Tensor & weight_t,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean_t,const Tensor & save_var_t,double epsilon)', '    expandScale(const Tensor & t,int64_t dim)', '    miopen_batch_norm(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,const Tensor & running_mean_t,const Tensor & running_var_t,bool training,double exponential_average_factor,double epsilon)', '    idesc', '    idesc', '    input', '    input', '    output', '    size', '    t', '    t', '    wdesc', '    wdesc'];
RNN_miopen.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/miopen; 897;  19; 128;45;  690; 25;397;301;285;324;0.03;46;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBBoxTransform', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BBoxTransform', '    RunOnDevice'];
SpectralOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkl; 278;  59; 22;21;  167; 13;117;52;92;43;0.35;3;['    final'];['    schema_BBoxTransform', '    angle_bound_hi_', '    angle_bound_lo_', '    angle_bound_on_', '    apply_scale_', '    BBoxTransformOp(Args,...)', '    clip_angle_thresh_', '    legacy_plus_one_', '    rotated_', '    RunOnDevice'];
BinaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 113;  6; 18;7;  52; 35;29;17;29;11;0.12;8;[];['    wipe_cache'];
Conv.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 217;  7; 22;9;  152; 29;90;65;21;31;0.05;7;[];['    wipe_cache'];
Linear.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 64;  5; 10;7;  32; 14;16;15;13;10;0.16;1;['    C10FlagParser_data_net', '    C10FlagParser_init_net', '    C10FlagParser_input_dims', '    C10FlagParser_input_types', '    C10FlagParser_iter', '    C10FlagParser_num_loading_threads', '    C10FlagParser_run_net', '    C10FlagParser_runs', '    C10FlagParser_threads', '    C10FlagParser_warmup'];['    C10FlagParser_data_net(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_types(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_num_loading_threads(const std::string & content)', '    C10FlagParser_run_net(const std::string & content)', '    C10FlagParser_runs(const std::string & content)', '    C10FlagParser_threads(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)', '    benchmark(const BenchmarkParam & param)'];
MKLDNNCommon.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 78;  1; 1;6;  0; 72;0;0;0;0;0.00;0;['    BenchmarkRunner'];['    benchmark(const BenchmarkParam & param)', '    post_benchmark_cleanup', '    pre_benchmark_setup', '    ~BenchmarkRunner'];
MKLDNNCommon.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 22;  1; 2;6;  0; 15;0;0;0;0;0.00;0;[];[];
MkldnnTensorMath.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 48;  5; 9;10;  18; 11;12;8;4;7;0.28;1;['    C10FlagParser_backend', '    C10FlagParser_init_net', '    C10FlagParser_input', '    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_measure_memory', '    C10FlagParser_net', '    C10FlagParser_output', '    C10FlagParser_output_folder', '    C10FlagParser_run_individual', '    C10FlagParser_sleep_before_run', '    C10FlagParser_sleep_between_iteration', '    C10FlagParser_sleep_between_net_and_operator', '    C10FlagParser_text_output', '    C10FlagParser_warmup', '    C10FlagParser_wipe_cache'];['    C10FlagParser_backend(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_measure_memory(const std::string & content)', '    C10FlagParser_net(const std::string & content)', '    C10FlagParser_output(const std::string & content)', '    C10FlagParser_output_folder(const std::string & content)', '    C10FlagParser_run_individual(const std::string & content)', '    C10FlagParser_sleep_before_run(const std::string & content)', '    C10FlagParser_sleep_between_iteration(const std::string & content)', '    C10FlagParser_sleep_between_net_and_operator(const std::string & content)', '    C10FlagParser_text_output(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)', '    C10FlagParser_wipe_cache(const std::string & content)'];
Normalization.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 77;  13; 9;8;  32; 19;15;19;11;9;0.41;1;[];['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input,const string & FLAGS_input_dims,const string & FLAGS_input_file,const string & FLAGS_input_type,int FLAGS_iter,bool FLAGS_measure_memory,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    getVirtualMemoryIfOptionEnabled(bool FLAGS_measure_memory)', '    loadInput(shared_ptr workspace,const bool run_on_gpu,map & tensor_protos_map,const string & input,const string & input_file,const string & input_dims,const string & input_type)', '    logBenchmarkResult(const std::string & type,const std::string & metric,const std::string & unit,const int value)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetBase *net,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setDeviceType(caffe2::NetDef *net_def,caffe2::DeviceType & run_dev)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)'];
Pooling.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 237;  17; 20;10;  150; 53;80;73;38;61;0.11;6;[];['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input,const string & FLAGS_input_dims,const string & FLAGS_input_file,const string & FLAGS_input_type,int FLAGS_iter,bool FLAGS_measure_memory,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    getVirtualMemoryIfOptionEnabled(bool FLAGS_measure_memory)', '    loadInput(shared_ptr workspace,const bool run_on_gpu,map & tensor_protos_map,const string & input,const string & input_file,const string & input_dims,const string & input_type)', '    logBenchmarkResult(const std::string & type,const std::string & metric,const std::string & unit,const int value)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetBase *net,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)', '    writeTextOutput(TensorType *tensor,const string & output_prefix,const string & name,int index,int num_blobs)', '    replace', '    shared_ptr'];
SoftMax.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 44;  4; 6;7;  17; 14;5;11;6;6;0.24;1;[];['    denorm_min', '    epsilon', '    infinity', '    lowest', '    max', '    min', '    quiet_NaN', '    round_error', '    signaling_NaN', '    operator&(BFloat16 & a,const BFloat16 & b)', '    operator*(const BFloat16 & a,const BFloat16 & b)', '    operator*(BFloat16 a,float b)', '    operator*(float a,BFloat16 b)', '    operator*(BFloat16 a,double b)', '    operator*(double a,BFloat16 b)', '    operator*(BFloat16 a,int b)', '    operator*(int a,BFloat16 b)', '    operator*(BFloat16 a,int64_t b)', '    operator*(int64_t a,BFloat16 b)', '    operator*=(BFloat16 & a,const BFloat16 & b)', '    operator*=(float & a,const BFloat16 & b)', '    operator+(const BFloat16 & a,const BFloat16 & b)', '    operator+(BFloat16 a,float b)', '    operator+(float a,BFloat16 b)', '    operator+(BFloat16 a,double b)', '    operator+(double a,BFloat16 b)', '    operator+(BFloat16 a,int b)', '    operator+(int a,BFloat16 b)', '    operator+(BFloat16 a,int64_t b)', '    operator+(int64_t a,BFloat16 b)', '    operator+=(BFloat16 & a,const BFloat16 & b)', '    operator+=(float & a,const BFloat16 & b)', '    operator-(const BFloat16 & a,const BFloat16 & b)', '    operator-(const BFloat16 & a)', '    operator-(BFloat16 a,float b)', '    operator-(float a,BFloat16 b)', '    operator-(BFloat16 a,double b)', '    operator-(double a,BFloat16 b)', '    operator-(BFloat16 a,int b)', '    operator-(int a,BFloat16 b)', '    operator-(BFloat16 a,int64_t b)', '    operator-(int64_t a,BFloat16 b)', '    operator-=(BFloat16 & a,const BFloat16 & b)', '    operator-=(float & a,const BFloat16 & b)', '    operator/(const BFloat16 & a,const BFloat16 & b)', '    operator/(BFloat16 a,float b)', '    operator/(float a,BFloat16 b)', '    operator/(BFloat16 a,double b)', '    operator/(double a,BFloat16 b)', '    operator/(BFloat16 a,int b)', '    operator/(int a,BFloat16 b)', '    operator/(BFloat16 a,int64_t b)', '    operator/(int64_t a,BFloat16 b)', '    operator/=(BFloat16 & a,const BFloat16 & b)', '    operator/=(float & a,const BFloat16 & b)', '    operator^(BFloat16 & a,const BFloat16 & b)', '    operator|(BFloat16 & a,const BFloat16 & b)', '    exp(c10::BFloat16 a)', '    log(c10::BFloat16 a)', '    BFloat16(float value)', '    from_bits', '    operator float', '    f32_from_bits', '    round_to_nearest_even', '    exp', '    log'];
TensorFactories.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 29;  1; 5;4;  5; 15;1;3;4;3;0.20;1;[];['    from_bits', '    BFloat16', '    BFloat16(unsigned short bits,from_bits_t)', '    BFloat16(float value)', '    bits_from_f32(float src)', '    f32_from_bits(uint16_t src)', '    round_to_nearest_even(float src)', '    operator float', '    isnan'];
TensorShape.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 85;  4; 10;8;  40; 27;18;17;20;15;0.10;6;['    BFloat16Test'];['    BinaryToFloat(uint32_t bytes)', '    float_from_bytes(uint32_t sign,uint32_t exponent,uint32_t fraction)', '    TEST(BFloat16Conversion,FloatToBFloat16AndBack)', '    TEST(BFloat16Conversion,FloatToBFloat16RNEAndBack)', '    TEST(BFloat16Conversion,NaN)', '    TEST(BFloat16Conversion,Inf)', '    TEST(BFloat16Conversion,SmallestDenormal)', '    TEST(BFloat16Math,Addition)', '    TEST(BFloat16Math,Substraction)', '    TEST_P(BFloat16Test,BFloat16RNETest)'];
UnaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 46;  4; 7;7;  17; 15;8;9;4;7;0.24;2;[];['    assert'];
Utils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 34;  1; 5;2;  26; 0;13;12;6;5;0.04;1;[];['    exp', '    exp1', '    exp2', '    TEST(BinaryMatch,NoMatch)', '    TEST(BinaryMatch,AllMatch)', '    TEST(BinaryMatch,EmptyGraph)', '    TEST(BinaryMatch,Basic)', '    TEST(BinaryMatch,RemovedMiddleNode)'];
Utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 16;  0; 3;3;  10; 0;0;10;0;3;0.00;0;[];['    mkldnn_add(const Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_add_(Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_add_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    mkldnn_mul(const Tensor & self,const Tensor & other)', '    mkldnn_mul_(Tensor & self,const Tensor & other)', '    mkldnn_mul_out(Tensor & result,const Tensor & self,const Tensor & other)', '    scales', '    scales'];
NaiveConvolutionTranspose3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1037;  74; 107;5;  859; 0;606;249;194;131;0.09;8;[];['    check_convert(Scalar scalar,ScalarType scalarType)', '    wrapped_scalar_tensor(Scalar scalar)', '    wrapped_scalar_tensor_and_check_convert(Scalar scalar,Tensor tensor)', '    torch_warn_once_63', '    torch_warn_once_78', '    __and__(const Tensor & self,const Tensor & other)', '    __and__(const Tensor & self,Scalar other)', '    __iand__(Tensor & self,const Tensor & other)', '    __iand__(Tensor & self,Scalar other)', '    __ilshift__(Tensor & self,const Tensor & other)', '    __ilshift__(Tensor & self,Scalar other)', '    __ior__(Tensor & self,const Tensor & other)', '    __ior__(Tensor & self,Scalar other)', '    __irshift__(Tensor & self,const Tensor & other)', '    __irshift__(Tensor & self,Scalar other)', '    __ixor__(Tensor & self,const Tensor & other)', '    __ixor__(Tensor & self,Scalar other)', '    __lshift__(const Tensor & self,const Tensor & other)', '    __lshift__(const Tensor & self,Scalar other)', '    __or__(const Tensor & self,const Tensor & other)', '    __or__(const Tensor & self,Scalar other)', '    __rshift__(const Tensor & self,const Tensor & other)', '    __rshift__(const Tensor & self,Scalar other)', '    __xor__(const Tensor & self,const Tensor & other)', '    __xor__(const Tensor & self,Scalar other)', '    add(const Tensor & self,const Tensor & other,Scalar alpha)', '    add(const Tensor & self,Scalar other,Scalar alpha)', '    add_(Tensor & self,const Tensor & other,Scalar alpha)', '    add_(Tensor & self,Scalar other,Scalar alpha)', '    add_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    atan2(const Tensor & self,const Tensor & other)', '    atan2_(Tensor & self,const Tensor & other)', '    atan2_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_and(const Tensor & self,const Tensor & other)', '    bitwise_and(const Tensor & self,Scalar other)', '    bitwise_and_(Tensor & self,const Tensor & other)', '    bitwise_and_(Tensor & self,Scalar other)', '    bitwise_and_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_and_out(Tensor & result,const Tensor & self,Scalar other)', '    bitwise_or(const Tensor & self,const Tensor & other)', '    bitwise_or(const Tensor & self,Scalar other)', '    bitwise_or_(Tensor & self,const Tensor & other)', '    bitwise_or_(Tensor & self,Scalar other)', '    bitwise_or_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_or_out(Tensor & result,const Tensor & self,Scalar other)', '    bitwise_xor(const Tensor & self,const Tensor & other)', '    bitwise_xor(const Tensor & self,Scalar other)', '    bitwise_xor_(Tensor & self,const Tensor & other)', '    bitwise_xor_(Tensor & self,Scalar other)', '    bitwise_xor_out(Tensor & result,const Tensor & self,const Tensor & other)', '    bitwise_xor_out(Tensor & result,const Tensor & self,Scalar other)', '    comparison_op(const Tensor & self,const Tensor & other,OutImpl & out_impl)', '    comparison_op(const Tensor & self,Scalar other,OutImpl & out_impl)', '    comparison_op_(Tensor & self,const Tensor & other,OutImpl & out_impl)', '    comparison_op_(Tensor & self,Scalar other,OutImpl & out_impl)', '    comparison_op_out(Tensor & result,const Tensor & self,const Tensor & other,Stub & stub)', '    comparison_op_out(Tensor & result,const Tensor & self,Scalar other,OutImpl & out_impl)', '    div(const Tensor & self,const Tensor & other)', '    div(const Tensor & self,Scalar other)', '    div_(Tensor & self,const Tensor & other)', '    div_(Tensor & self,Scalar other)', '    div_out(Tensor & result,const Tensor & self,const Tensor & other)', '    eq(const Tensor & self,const Tensor & other)', '    eq(const Tensor & self,Scalar other)', '    eq_(Tensor & self,const Tensor & other)', '    eq_(Tensor & self,Scalar other)', '    eq_out(Tensor & result,const Tensor & self,const Tensor & other)', '    eq_out(Tensor & result,const Tensor & self,Scalar other)', '    floor_divide(const Tensor & self,const Tensor & other)', '    floor_divide(const Tensor & self,Scalar other)', '    floor_divide_(Tensor & self,const Tensor & other)', '    floor_divide_(Tensor & self,Scalar other)', '    floor_divide_out(Tensor & result,const Tensor & self,const Tensor & other)', '    fmod(const Tensor & self,const Tensor & other)', '    fmod(const Tensor & self,Scalar other)', '    fmod_(Tensor & self,const Tensor & other)', '    fmod_(Tensor & self,Scalar other)', '    fmod_out(Tensor & result,const Tensor & self,const Tensor & other)', '    fmod_out(Tensor & result,const Tensor & self,Scalar other)', '    ge(const Tensor & self,const Tensor & other)', '    ge(const Tensor & self,Scalar other)', '    ge_(Tensor & self,const Tensor & other)', '    ge_(Tensor & self,Scalar other)', '    ge_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ge_out(Tensor & result,const Tensor & self,Scalar other)', '    gt(const Tensor & self,const Tensor & other)', '    gt(const Tensor & self,Scalar other)', '    gt_(Tensor & self,const Tensor & other)', '    gt_(Tensor & self,Scalar other)', '    gt_out(Tensor & result,const Tensor & self,const Tensor & other)', '    gt_out(Tensor & result,const Tensor & self,Scalar other)', '    le(const Tensor & self,const Tensor & other)', '    le(const Tensor & self,Scalar other)', '    le_(Tensor & self,const Tensor & other)', '    le_(Tensor & self,Scalar other)', '    le_out(Tensor & result,const Tensor & self,const Tensor & other)', '    le_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_and(const Tensor & self,const Tensor & other)', '    logical_and(const Tensor & self,Scalar other)', '    logical_and_(Tensor & self,const Tensor & other)', '    logical_and_(Tensor & self,Scalar other)', '    logical_and_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_and_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_or(const Tensor & self,const Tensor & other)', '    logical_or(const Tensor & self,Scalar other)', '    logical_or_(Tensor & self,const Tensor & other)', '    logical_or_(Tensor & self,Scalar other)', '    logical_or_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_or_out(Tensor & result,const Tensor & self,Scalar other)', '    logical_xor(const Tensor & self,const Tensor & other)', '    logical_xor(const Tensor & self,Scalar other)', '    logical_xor_(Tensor & self,const Tensor & other)', '    logical_xor_(Tensor & self,Scalar other)', '    logical_xor_out(Tensor & result,const Tensor & self,const Tensor & other)', '    logical_xor_out(Tensor & result,const Tensor & self,Scalar other)', '    lt(const Tensor & self,const Tensor & other)', '    lt(const Tensor & self,Scalar other)', '    lt_(Tensor & self,const Tensor & other)', '    lt_(Tensor & self,Scalar other)', '    lt_out(Tensor & result,const Tensor & self,const Tensor & other)', '    lt_out(Tensor & result,const Tensor & self,Scalar other)', '    max(const Tensor & self,const Tensor & other)', '    max_(Tensor & self,const Tensor & other)', '    max_out(Tensor & result,const Tensor & self,const Tensor & other)', '    min(const Tensor & self,const Tensor & other)', '    min_(Tensor & self,const Tensor & other)', '    min_out(Tensor & result,const Tensor & self,const Tensor & other)', '    mul(const Tensor & self,const Tensor & other)', '    mul(const Tensor & self,Scalar other)', '    mul_(Tensor & self,const Tensor & other)', '    mul_(Tensor & self,Scalar other)', '    mul_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ne(const Tensor & self,const Tensor & other)', '    ne(const Tensor & self,Scalar other)', '    ne_(Tensor & self,const Tensor & other)', '    ne_(Tensor & self,Scalar other)', '    ne_out(Tensor & result,const Tensor & self,const Tensor & other)', '    ne_out(Tensor & result,const Tensor & self,Scalar other)', '    remainder(const Tensor & self,const Tensor & other)', '    remainder(const Tensor & self,Scalar other)', '    remainder_(Tensor & self,const Tensor & other)', '    remainder_(Tensor & self,Scalar other)', '    remainder_out(Tensor & result,const Tensor & self,const Tensor & other)', '    remainder_out(Tensor & result,const Tensor & self,Scalar other)', '    rsub(const Tensor & self,const Tensor & other,Scalar alpha)', '    rsub(const Tensor & self,Scalar other,Scalar alpha)', '    sigmoid_backward(const Tensor & grad_output,const Tensor & output)', '    sigmoid_backward_out(Tensor & result,const Tensor & grad_output,const Tensor & output)', '    sub(const Tensor & self,const Tensor & other,Scalar alpha)', '    sub(const Tensor & self,Scalar other,Scalar alpha)', '    sub_(Tensor & self,const Tensor & other,Scalar alpha)', '    sub_(Tensor & self,Scalar other,Scalar alpha)', '    sub_out(Tensor & result,const Tensor & self,const Tensor & other,Scalar alpha)', '    tanh_backward(const Tensor & grad_output,const Tensor & output)', '    tanh_backward_out(Tensor & result,const Tensor & grad_output,const Tensor & output)', '    true_divide(const Tensor & self,const Tensor & divisor)', '    true_divide(const Tensor & self,Scalar divisor)', '    true_divide_(Tensor & self,const Tensor & divisor)', '    true_divide_(Tensor & self,Scalar divisor)', '    true_divide_out(Tensor & result,const Tensor & self,const Tensor & divisor)'];
NaiveDilatedConvolution.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 642;  200; 26;6;  454; 0;349;155;54;65;0.44;8;[];['    alpha_check(const ScalarType dtype,Scalar alpha)', '    sub_check(const Tensor & self,const Tensor & other)', '    add_stub', '    add_stub', '    operator=', '    atan2_stub', '    atan2_stub', '    operator=', '    bitwise_and_stub', '    bitwise_and_stub', '    operator=', '    bitwise_or_stub', '    bitwise_or_stub', '    operator=', '    bitwise_xor_stub', '    bitwise_xor_stub', '    operator=', '    div_stub', '    div_stub', '    operator=', '    eq_stub', '    eq_stub', '    operator=', '    fmod_scalar_stub', '    fmod_scalar_stub', '    operator=', '    fmod_stub', '    fmod_stub', '    operator=', '    ge_stub', '    ge_stub', '    operator=', '    gt_stub', '    gt_stub', '    operator=', '    le_stub', '    le_stub', '    operator=', '    logical_and_stub', '    logical_and_stub', '    operator=', '    logical_or_stub', '    logical_or_stub', '    operator=', '    logical_xor_stub', '    logical_xor_stub', '    operator=', '    lshift_stub', '    lshift_stub', '    operator=', '    lt_stub', '    lt_stub', '    operator=', '    max_elementwise_stub', '    max_elementwise_stub', '    operator=', '    min_elementwise_stub', '    min_elementwise_stub', '    operator=', '    mse_stub', '    mse_stub', '    operator=', '    mul_stub', '    mul_stub', '    operator=', '    ne_stub', '    ne_stub', '    operator=', '    operator=', '    remainder_stub', '    remainder_stub', '    operator=', '    rshift_stub', '    rshift_stub', '    operator=', '    sigmoid_backward_stub', '    sigmoid_backward_stub', '    operator=', '    smooth_l1_stub', '    smooth_l1_stub', '    operator=', '    sub_stub', '    sub_stub', '    operator=', '    tanh_backward_stub', '    tanh_backward_stub', '    scalar_type'];
NamedTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 417;  64; 41;4;  314; 0;161;116;130;98;0.20;38;[];['    lshift_wrapper(scalar_t a,scalar_t b)', '    lshift_wrapper(int8_t a,int8_t b)', '    lshift_wrapper(int16_t a,int16_t b)', '    lshift_wrapper(int32_t a,int32_t b)', '    lshift_wrapper(int64_t a,int64_t b)', '    rshift_wrapper(scalar_t a,scalar_t b)', '    rshift_wrapper(int8_t a,int8_t b)', '    rshift_wrapper(int16_t a,int16_t b)', '    rshift_wrapper(int32_t a,int32_t b)', '    rshift_wrapper(int64_t a,int64_t b)', '    torch_warn_once_536', '    add_kernel(TensorIterator & iter,Scalar alpha_scalar)', '    atan2_kernel(TensorIterator & iter)', '    bitwise_and_kernel(TensorIterator & iter)', '    bitwise_or_kernel(TensorIterator & iter)', '    bitwise_xor_kernel(TensorIterator & iter)', '    div_kernel(TensorIterator & iter)', '    eq_kernel(TensorIterator & iter)', '    fmod_kernel(TensorIterator & iter)', '    fmod_scalar_kernel(TensorIterator & iter,Scalar divisor)', '    ge_kernel(TensorIterator & iter)', '    gt_kernel(TensorIterator & iter)', '    le_kernel(TensorIterator & iter)', '    logical_and_kernel(TensorIterator & iter)', '    logical_or_kernel(TensorIterator & iter)', '    logical_xor_kernel(TensorIterator & iter)', '    lshift_kernel(TensorIterator & iter)', '    lt_kernel(TensorIterator & iter)', '    max_elementwise_kernel(TensorIterator & iter)', '    min_elementwise_kernel(TensorIterator & iter)', '    mse_kernel(TensorIterator & iter)', '    mul_kernel(TensorIterator & iter)', '    ne_kernel(TensorIterator & iter)', '    remainder_kernel(TensorIterator & iter)', '    rshift_kernel(TensorIterator & iter)', '    sigmoid_backward_kernel(TensorIterator & iter)', '    smooth_l1_kernel(TensorIterator & iter)', '    sub_kernel(TensorIterator & iter,Scalar alpha_scalar)', '    tanh_backward_kernel(TensorIterator & iter)'];
Normalization.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 608;  71; 87;11;  458; 0;307;158;162;130;0.16;18;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBisectPercentile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BisectPercentile'];
Onehot.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 35;  5; 6;1;  25; 0;17;6;19;5;0.20;1;['    final'];['    binary_search(const std::vector::iterator & data,int lo,int hi,float val)', '    BisectPercentileOp(Args,...)', '    compute_percentile(const std::vector::iterator & pct_raw_it,const std::vector::iterator & pct_mapping_it,const std::vector::iterator & pct_lower_it,const std::vector::iterator & pct_upper_it,const int size,const float val)', '    RunOnDevice'];
PackedSequence.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 184;  38; 20;2;  128; 0;86;49;68;49;0.30;4;[];['    mm_cpu(const Tensor & self,const Tensor & mat2)', '    mm_cpu_out(Tensor & result,const Tensor & self,const Tensor & mat2)', '    mv_cpu(const Tensor & self,const Tensor & vec)', '    mv_cpu_out(Tensor & result,const Tensor & self,const Tensor & vec)'];
PointwiseOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 99;  5; 11;6;  81; 0;34;45;24;17;0.06;7;[];[];
PointwiseOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 21;  3; 7;3;  10; 0;5;9;1;25;0.30;0;[];['    BlobGetMutableTensor(Blob *blob,at::IntArrayRef dims,at::TensorOptions options)', '    BlobGetMutableTensor(Blob *blob,DeviceType device_type)', '    BlobGetTensor(const Blob & blob,DeviceType device_type)', '    BlobGetTensorOrUndefined(const Blob & blob)', '    BlobIsInt8TensorCPUType(const Blob & blob)', '    BlobIsTensorType(const Blob & blob,DeviceType device_type)', '    BlobSetTensor(Blob *blob,Tensor)', '    GetSizedTensorWithOptions(Tensor,at::IntArrayRef dims,at::TensorOptions options)', '    XBlobGetMutableTensor(Blob *blob,at::IntArrayRef dims,at::TensorOptions options)', '    defined', '    GetDevice', '    GetDeviceType', '    has_index', '    raw_mutable_data', '    Resize', '    UnsafeSharedInstance', '    TypeName'];
Pool.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 262;  11; 34;6;  215; 0;90;88;65;23;0.05;9;[];[];
Pow.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 71;  5; 13;5;  52; 0;25;22;17;19;0.10;8;['    TensorGPUDeathTest', '    TensorGPUTest'];['    TEST(TensorGPUTest,TensorSerialization_bool)', '    TEST(TensorGPUTest,TensorSerialization_double)', '    TEST(TensorGPUTest,TensorSerialization_float)', '    TEST(TensorGPUTest,TensorSerialization_int)', '    TEST(TensorGPUTest,TensorSerialization_int8_t)', '    TEST(TensorGPUTest,TensorSerialization_int16_t)', '    TEST(TensorGPUTest,TensorSerialization_uint8_t)', '    TEST(TensorGPUTest,TensorSerialization_uint16_t)', '    TEST(TensorGPUTest,TensorSerialization_int64_t)', '    TEST(TensorConstruction,ReinitializeTensorTest)', '    TEST(TensorTest,TensorSerializationMultiDevices)', '    TYPED_TEST(TensorGPUTest,TensorInitializedEmpty)', '    TYPED_TEST(TensorGPUTest,TensorInitializedNonEmpty)', '    TYPED_TEST(TensorGPUTest,TensorAlias)', '    TYPED_TEST(TensorGPUTest,TensorAliasCanUseDifferentShapes)', '    TYPED_TEST(TensorGPUTest,NoLongerAliasAfterNumelChanges)', '    TYPED_TEST(TensorGPUDeathTest,CannotAccessDataWhenEmpty)'];
Pow.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 20;  2; 8;3;  9; 0;4;7;2;17;0.22;0;['    C10FlagParser_caffe2_max_tensor_serializer_threads', '    C10FlagParser_caffe2_serialize_fp16_as_bytes', '    C10FlagParser_caffe2_serialize_using_bytes_as_holder', '    C10FlagParser_caffe2_tensor_chunk_size', '    StringDeserializer', '    StringSerializer'];['    ContextFromProto(const TensorProto & tensor_proto)', '    DimsFromTensorProto(const TensorProto & proto)', '    EnableByteEncoding(const TensorProto::DataType & dataType,const size_t & typeSize)', '    GetDataType(const TensorProto & tensor_proto)', '    NumelFromTensorProto(const TensorProto & tensor_proto)', '    SerializeUsingBytesOrInt32(const Tensor & input,const TensorProto::DataType & dataType,size_t chunkBegin,int32_t chunkSize,BaseContext *context,TensorProto & proto)', '    TensorOptionsFromProto(const TensorProto & tensor_proto)', '    DeserializeBlob(const string & content,Blob *result)', '    DeserializeBlob(const BlobProto & blob_proto,Blob *result)', '    DeserializeFromBytesOrInt32(const TensorProto & tensor_proto,size_t chunkBegin,int32_t chunkSize,BaseContext *context,Tensor *tensor)', '    EmptyTensorFromProto(const TensorProto & tensor_proto)', '    RegistryName', '    RegistryName', '    SerializeAsString_EnforceCheck(const google::protobuf::MessageLite & msg,const char *error_location)', '    SerializeBlob(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const void *pointer,TypeMeta typeMeta,const string & name)', '    SerializeBlob(const Blob & blob,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const Blob & blob,const string & name)', '    processChunk', '    task', '    C10FlagParser_caffe2_max_tensor_serializer_threads(const std::string & content)', '    C10FlagParser_caffe2_serialize_fp16_as_bytes(const std::string & content)', '    C10FlagParser_caffe2_serialize_using_bytes_as_holder(const std::string & content)', '    C10FlagParser_caffe2_tensor_chunk_size(const std::string & content)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    StringSerializer', '    ~StringSerializer', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const TensorProto & tensor_proto)', '    DeserializeToTensor(const TensorProto & tensor_proto,Tensor *tensor)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Serialize(const Tensor & input,const string & name,TensorProto *proto_ptr,size_t chunkBegin,int32_t chunkSize)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    StoreDeviceDetail(const Tensor & input,TensorProto *proto)'];
Copy.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 31;  3; 3;3;  24; 0;12;6;31;13;0.13;1;['    TensorDeserializer', '    TensorSerializer'];['    DeserializeBlob(const string & content,Blob *result)', '    DeserializeBlob(const BlobProto & blob_proto,Blob *result)', '    CopyFromProtoAsIs(const size_t size,const google::protobuf::RepeatedField & field,DstType *dst,BaseContext *context)', '    CopyFromProtoWithCast(const size_t size,const google::protobuf::RepeatedField & field,DstType *dst,BaseContext *context)', '    CopyToProtoAsIs(const size_t size,const SrcType *src,google::protobuf::RepeatedField *field,BaseContext *context)', '    CopyToProtoWithCast(const size_t size,const SrcType *src,google::protobuf::RepeatedField *field,BaseContext *context)', '    EmptyTensorFromProto(const TensorProto & tensor_proto)', '    SerializeAsString_EnforceCheck(const google::protobuf::MessageLite & msg,const char *error_location)', '    SerializeBlob(const Blob & blob,const string & name,BlobSerializerBase::SerializationAcceptor acceptor,int chunk_size)', '    SerializeBlob(const Blob & blob,const string & name)', '    SerializeBlobProtoAsString_EnforceCheck(const BlobProto & blob)', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const TensorProto & tensor_proto)', '    DeserializeToTensor(const TensorProto & tensor_proto,Tensor *tensor)', '    Serialize(const Tensor & input,const string & name,TensorProto *proto_ptr,size_t chunkBegin,int32_t chunkSize)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor,int chunk_size)', '    StoreDeviceDetail(const Tensor & input,TensorProto *proto)', '    TensorSerializer', '    ~TensorSerializer'];
fbgemm_utils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 199;  1; 0;9;  0; 197;0;0;0;0;0.00;0;[];[];
fbgemm_utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 115;  1; 1;8;  0; 111;0;0;0;0;0.00;0;['    BlobDeserializerBase', '    BlobSerializerBase'];['    CreateDeserializer(const string & type)', '    CreateSerializer(TypeIdentifier id)', '    RegistryName', '    Deserialize(const BlobProto & proto,Blob *blob)', '    ~BlobDeserializerBase', '    Serialize(const void *pointer,TypeMeta typeMeta,const std::string & name,SerializationAcceptor acceptor)', '    SerializeWithChunkSize(const void *pointer,TypeMeta typeMeta,const std::string & name,SerializationAcceptor acceptor,int)', '    ~BlobSerializerBase'];
init_qnnpack.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 24;  0; 0;6;  0; 22;0;0;0;0;0.00;0;[];['    sizeBytes(const Blob & blob)', '    doRegister(TypeIdentifier id,std::unique_ptr)', '    get(TypeIdentifier id)', '    instance'];
QuantizedOpKernels.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/kernels; 1577;  147; 118;26;  1270; 70;993;330;507;354;0.12;26;[];['    sizeBytes(const Blob & blob)', '    sizeBytes(const Blob & blob)', '    ~BlobStatGetter', '    doRegister(TypeIdentifier id,std::unique_ptr)', '    get(TypeIdentifier id)', '    instance', '    instance', '    Registrar', '    Id'];
q_adaavgpool.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 244;  25; 22;9;  191; 0;125;75;45;46;0.13;6;['    C10FlagParser_caffe2_test_big_tensor_size', '    BlobTestBar', '    BlobTestFoo', '    BlobTestFooDeserializer', '    BlobTestFooSerializer', '    BlobTestNonDefaultConstructible', '    DummyTypeDeserializer', '    DummyTypeSerializer', '    TensorCPUDeathTest', '    TensorCPUTest', '    TypedTensorTest', '    VectorCursor', '    VectorDB'];['    CreateProtoWithInt32Data(const caffe2::TensorProto::DataType & dataType,size_t numEl,bool useCached)', '    blob3', '    TEST(BlobTest,Blob)', '    TEST(BlobTest,BlobUninitialized)', '    TEST(BlobTest,BlobWrongType)', '    TEST(BlobTest,BlobReset)', '    TEST(BlobTest,BlobMove)', '    TEST(BlobTest,BlobNonConstructible)', '    TEST(BlobTest,BlobShareExternalPointer)', '    TEST(BlobTest,BlobShareExternalObject)', '    TEST(BlobTest,StringSerialization)', '    TEST(TensorNonTypedTest,TensorChangeType)', '    TEST(TensorNonTypedTest,NonDefaultConstructible)', '    TEST(TensorTest,TensorNonFundamentalType)', '    TEST(TensorTest,TensorNonFundamentalTypeClone)', '    TEST(TensorTest,Tensor64BitDimension)', '    TEST(TensorTest,UndefinedTensor)', '    TEST(TensorDeathTest,CannotCastDownLargeDims)', '    TEST(TensorTest,TensorSerialization_bool)', '    TEST(EmptyTensorTest,TensorSerialization_bool)', '    TEST(TensorTest,TensorSerialization_double)', '    TEST(EmptyTensorTest,TensorSerialization_double)', '    TEST(TensorTest,TensorSerialization_float)', '    TEST(EmptyTensorTest,TensorSerialization_float)', '    TEST(TensorTest,TensorSerialization_int)', '    TEST(EmptyTensorTest,TensorSerialization_int)', '    TEST(TensorTest,TensorSerialization_int8_t)', '    TEST(EmptyTensorTest,TensorSerialization_int8_t)', '    TEST(TensorTest,TensorSerialization_int16_t)', '    TEST(EmptyTensorTest,TensorSerialization_int16_t)', '    TEST(TensorTest,TensorSerialization_uint8_t)', '    TEST(EmptyTensorTest,TensorSerialization_uint8_t)', '    TEST(TensorTest,TensorSerialization_uint16_t)', '    TEST(EmptyTensorTest,TensorSerialization_uint16_t)', '    TEST(TensorTest,TensorSerialization_int64_t)', '    TEST(EmptyTensorTest,TensorSerialization_int64_t)', '    TEST(TensorTest,TensorSerialization_CustomType)', '    TEST(TensorTest,Half)', '    TEST(TensorTest,TensorFactory)', '    TEST(QTensorTest,QTensorSerialization)', '    TEST(ContentChunks,Serialization)', '    TEST(CustomChunkSize,BigTensorSerialization)', '    TEST(QTensor,QTensorSizingTest)', '    TEST(BlobTest,CastingMessage)', '    TEST(TensorConstruction,UninitializedCopyTest)', '    TEST(TensorConstruction,CopyConstructorTest)', '    TEST(TensorConstruction,MoveAssignmentOpTest)', '    TEST(TensorSerialization,MistakenlySerializingDtypeUninitializedTensor)', '    TEST(TensorSerialization,TestCorrectness)', '    TestDataType(const caffe2::TensorProto::DataType & dataType,std::string dataTypeName)', '    TYPED_TEST(TensorCPUTest,TensorInitializedEmpty)', '    TYPED_TEST(TensorCPUTest,TensorInitializedNonEmpty)', '    TYPED_TEST(TensorCPUTest,TensorInitializedZeroDim)', '    TYPED_TEST(TensorCPUTest,TensorResizeZeroDim)', '    TYPED_TEST(TensorCPUTest,TensorInitializedScalar)', '    TYPED_TEST(TensorCPUTest,TensorAlias)', '    TYPED_TEST(TensorCPUTest,TensorShareDataRawPointer)', '    TYPED_TEST(TensorCPUTest,TensorShareDataRawPointerWithMeta)', '    TYPED_TEST(TensorCPUTest,TensorAliasCanUseDifferentShapes)', '    TYPED_TEST(TensorCPUTest,NoLongerAliassAfterNumelChanges)', '    TYPED_TEST(TensorCPUTest,NoLongerAliasAfterFreeMemory)', '    TYPED_TEST(TensorCPUTest,KeepOnShrink)', '    TYPED_TEST(TensorCPUTest,MaxKeepOnShrink)', '    TYPED_TEST(TensorCPUDeathTest,CannotAccessRawDataWhenEmpty)', '    TYPED_TEST(TensorCPUDeathTest,CannotAccessDataWhenEmpty)', '    TYPED_TEST(TypedTensorTest,BigTensorSerialization)', '    dims', '    dims', '    registerData(const string & name,StringMap)', '    C10FlagParser_caffe2_test_big_tensor_size(const std::string & content)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    BlobTestFooSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~BlobTestFooSerializer', '    BlobTestNonDefaultConstructible(int x)', '    deserialize(const BlobProto &)', '    DummyType(int n_chunks_init)', '    serialize(const std::string & name,const int32_t chunk_id)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    DummyTypeSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~DummyTypeSerializer', '    key', '    Next', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    VectorCursor(StringMap *data)', '    ~VectorCursor', '    Close', '    getData', '    NewCursor', '    NewTransaction', '    VectorDB(const string & source,db::Mode mode)', '    ~VectorDB', '    vector', '    vector', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '  Static Member Variables', '    data_', '    dataRegistryMutex_'];
q_avgpool.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 422;  7; 20;17;  277; 104;184;110;51;45;0.03;7;[];['    canRead', '    blockingWrite(const std::vector & inputs)', '    canWrite', '    close', '    doWrite(const std::vector & inputs)', '    tryWrite(const std::vector & inputs)', '    BlobsQueue(Workspace *ws,const std::string & queueName,size_t capacity,size_t numBlobs,bool enforceUniqueName,const std::vector & fieldNames)', '    blockingRead(const std::vector & inputs,float timeout_secs)'];
qadd.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 298;  34; 18;15;  165; 77;111;82;47;33;0.21;7;['    BlobsQueue'];['    BlobsQueue(Workspace *ws,const std::string & queueName,size_t capacity,size_t numBlobs,bool enforceUniqueName,const std::vector & fieldNames)', '    blockingRead(const std::vector & inputs,float timeout_secs)', '    blockingWrite(const std::vector & inputs)', '    canWrite', '    close', '    closing_', '    doWrite(const std::vector & inputs)', '    getNumBlobs', '    queue_balance', '    queue_dequeued_bytes', '    queue_dequeued_records', '    QueueStats(std::string name)', '    read_time_ns', '    write_time_ns', '    reader_', '    tryWrite(const std::vector & inputs)', '    writer_', '    ~BlobsQueue'];
qbatch_norm.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 323;  14; 30;7;  280; 0;132;216;37;60;0.05;6;['    CreateBlobsQueueDBOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateBlobsQueueDB', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateBlobsQueueDB', '    CreateBlobsQueueDBOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
qclamp.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 91;  8; 11;8;  68; 0;21;45;35;30;0.12;6;['    BlobsQueueDB', '    BlobsQueueDBCursor'];['    blob_vector', '    GetStringFromBlob(Blob *blob)', '    BlobsQueueDB(const string & source,Mode mode,std::shared_ptr queue,int key_blob_index,int value_blob_index,float timeout_secs)', '    Close', '    NewCursor', '    NewTransaction', '    ~BlobsQueueDB', '    BlobsQueueDBCursor(std::shared_ptr queue,int key_blob_index,int value_blob_index,float timeout_secs)', '    key', '    Next', '    Seek(const string &)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~BlobsQueueDBCursor'];
qconv.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 669;  35; 13;23;  82; 522;27;44;11;8;0.43;2;['    final', '    GetBooleanMaskGradient', '    GetSequenceMaskGradient', '    LowerDiagFunctor', '    LowerFunctor', '    SequenceFunctor', '    UpperDiagFunctor', '    UpperFunctor', '    WindowFunctor'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanMask', '    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanMaskLengths', '    CAFFE_ANONYMOUS_VARIABLE_CPUSequenceMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMaskGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanMaskLengths', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SequenceMask', '    MaskWithFunctor(int N,int M,int B,const float *in,Functor fn,float fill_val,float *out)', '    RepeatedMaskWithFunctor(int N,int M,int D,const float *in,Functor fn,float fill_val,float *out)', '    vector', '    RunOnDevice', '    DoRunWithType', '    BooleanMaskLengthsOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    GetGradientDefs', '    CopyArguments', '    GetGradientDefs', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    SequenceFunctor(const int *sl,const size_t len)', '    DoRunWithType', '    RunOnDevice', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    operator()(int i,int j,float)', '    WindowFunctor(const int *c,int r)'];
qconv_prepack.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 328;  13; 13;21;  44; 247;20;36;2;8;0.30;1;['    final', '    final', '    final'];['    BooleanMaskOp(Args,...)', '    BooleanMaskOpGradient(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SequenceMaskOp(const OperatorDef & operator_def,Workspace *ws)'];
qconv_unpack.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 161;  13; 11;15;  32; 95;15;24;2;9;0.41;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBooleanUnmask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BooleanUnmask', '    RunOnDevice'];
qhardsigmoid.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 20;  1; 5;6;  9; 0;1;7;1;6;0.11;1;['    final'];['    BooleanUnmaskOp(Args,...)', '    RunOnDevice', '    ~BooleanUnmaskOp'];
qhardswish.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 26;  1; 6;6;  14; 0;2;10;2;8;0.07;2;[];['    AddScalarInput(const DataT & value,const string & name,Workspace *ws,bool isEmpty)', '    TEST(BooleanUnmaskTest,Test)'];
qlinear.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 368;  3; 5;17;  32; 314;13;25;2;7;0.09;1;[];['    makeTensorInfo(const std::vector & t,const std::vector & dims,TensorProto::DataType dtype,bool quantized)', '    new_shape', '    new_shape2', '    TEST(BoundShapeInference,SparseLengthsSum)', '    TEST(BoundShapeInference,SparseLengthsSumFused8BitRowwise)', '    TEST(BoundShapeInference,SparseLengthsSumFused4BitRowwise)', '    TEST(BoundShapeInference,LengthsRangeFill)', '    TEST(BoundShapeInference,Reshape)', '    TEST(BoundShapeInference,ConcatMissingInput)', '    TEST(BoundShapeInference,DISABLED_Int8QuantizeInferInputBackwards)', '    TEST(BoundShapeInference,ConcatInferInputBackwards)', '    TEST(BoundShapeInference,Bucketize)', '    TEST(BoundShapeInference,Split)', '    TEST(BoundShapeInference,FC)', '    TEST(BoundShapeInference,FC3D)', '    TEST(BoundShapeInference,Quantization)', '    TEST(BoundShapeInference,Combo0)', '    verifyShapeInfo(const ShapeInfoMap & info,const std::string & name,const std::vector & t,const std::vector & dims,TensorProto::DataType dtype,bool quantized)'];
qlinear_prepack.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 319;  10; 8;31;  47; 233;22;32;4;11;0.21;2;[];['    unsupported', '    ConvertToVec(const ::google::protobuf::RepeatedField & in)', '    InferOutput(const OperatorDef & op,const std::vector & input_shapes)', '    setDimTypeWithFirst(TensorBoundShape::DimType firstDimType,uint32_t n)', '    SizeFromDim(const TensorShape & shape,int axis)', '    SizeToDim(const TensorShape & shape,int axis)', '    getBoundShapeInferencer(const BoundShapeSpec & spec)', '    input_shapes', '    RegistryName', '    InferCommonOp(const OperatorDef & op)', '    InferConcat(const OperatorDef & op)', '    InferConcatInputs(const OperatorDef & op)', '    InferFC(const OperatorDef & op)', '    InferInt8QuantizeInput(const OperatorDef & op)', '    InferQuantizationTransformation(const OperatorDef & op)', '    InferReshape(const OperatorDef & op)', '    InferShape(const OperatorDef & op)', '    CheckAndSetTensorBoundShape(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized,bool allow_existing_shape)', '    EnsureShapeNames(std::unordered_map *info)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    InferGivenTensorFill(const OperatorDef & op)', '    InferLengthsRangeFill(const OperatorDef & op)', '    InferOps(const OperatorDef & op,caffe2::Workspace *)', '    InferSparseLengthsSum(const OperatorDef & op)', '    Initialize(const ShapeInfoMap & info,bool extract_feature_len)', '    SetTensorBoundShapeIfNotExist(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized)'];
qlinear_unpack.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 152;  7; 7;21;  36; 88;12;22;4;14;0.19;2;['    BoundShapeInferencer', '    BoundShapeInferencerBase'];['    getBoundShapeInferencer(const BoundShapeSpec & spec)', '    RegistryName', '    BoundShapeInferencer(const BoundShapeSpec & spec)', '    CheckAndSetTensorBoundShape(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized,bool allow_existing_shape)', '    current_dim_type_', '    current_max_batch_size_', '    EnsureShapeNames(ShapeInfoMap *info)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    InferCommonOp(const OperatorDef & op)', '    InferConcat(const OperatorDef & op)', '    InferConcatInputs(const OperatorDef & op)', '    InferFC(const OperatorDef & op)', '    InferGivenTensorFill(const OperatorDef & op)', '    InferInt8QuantizeInput(const OperatorDef & op)', '    InferLengthsRangeFill(const OperatorDef & op)', '    InferOps(const OperatorDef & op,caffe2::Workspace *)', '    InferQuantizationTransformation(const OperatorDef & op)', '    InferReshape(const OperatorDef & op)', '    InferShape(const OperatorDef & op)', '    InferSparseLengthsSum(const OperatorDef & op)', '    Initialize(const ShapeInfoMap & info,bool extract_feature_len)', '    SetTensorBoundShapeIfNotExist(const std::string & name,const std::vector & t,std::vector bound_dims,TensorProto::DataType type,bool is_quantized)', '    ~BoundShapeInferencer', '    BoundShapeInferencerBase(const BoundShapeSpec & spec)', '    InferBoundShapeAndType(const NetDef & net,const ShapeInfoMap & info,caffe2::Workspace *ws,bool extract_feature_len)', '    PrintShapeInfo', '    shape_info', '    ~BoundShapeInferencerBase', '    BoundShapeSpec(int64_t b,int64_t q)'];
qmul.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 200;  17; 21;7;  166; 0;117;89;42;36;0.10;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBoxWithNMSLimit', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BoxWithNMSLimit', '    get_all_scores_sorted', '    RunOnDevice'];
average-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 194;  24; 25;12;  140; 0;96;50;47;33;0.17;6;['    final'];['    schema_BoxWithNMSLimit', '    BoxWithNMSLimitOp(Args,...)', '    cls_agnostic_bbox_reg_', '    get_box_cls_index(int bg_fg_cls_id)', '    get_score_cls_index(int bg_fg_cls_id)', '    input_boxes_include_bg_cls_', '    input_scores_fg_cls_starting_id_', '    legacy_plus_one_', '    output_classes_include_bg_cls_', '    rotated_', '    RunOnDevice', '    ~BoxWithNMSLimitOp'];
channel-shuffle.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 249;  59; 47;9;  138; 0;85;48;65;36;0.43;9;[];[];
convolution.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 1013;  313; 65;12;  626; 0;542;92;469;85;0.50;20;[];['    AffineChannel(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y,CPUContext *)', '    AffineChannel(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y,CPUContext *)'];
hgemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 378;  23; 46;20;  238; 52;156;60;141;55;0.10;38;[];['    AffineChannel(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y,Context *context)'];
max-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 168;  29; 23;12;  109; 0;85;31;38;30;0.27;5;[];['    initializeAlgorithm'];
q8gemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 1043;  23; 73;40;  362; 547;234;91;187;81;0.06;51;['    final'];['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    BroadcastOp(const OperatorDef & operator_def,Workspace *ws)', '    initialize', '    initializeAlgorithm', '    RunOnDevice', '    update(GlooParameters & params)', '    ~BroadcastOp'];
sgemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 624;  84; 53;20;  399; 69;279;111;255;73;0.21;23;[];[];
sigmoid.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 99;  17; 17;9;  66; 0;53;16;27;17;0.26;2;[];['    TEST(BroadcastTest,Broadcast)', '    TestEmptyTensor(DeprecatedTypeProperties & T)', '    TestExplicitDimBasic(DeprecatedTypeProperties & T)', '    TestExplicitDimWithMismatchedSizes(DeprecatedTypeProperties & T)', '    TestExplicitDimWithScalar(DeprecatedTypeProperties & T)', '    TestIn2Basic(DeprecatedTypeProperties & T)', '    TestIn2ExpandError(DeprecatedTypeProperties & T)', '    TestIn2WithScalar(DeprecatedTypeProperties & T)', '    TestIn3Basic(DeprecatedTypeProperties & T)', '    TestIn3ExpandError(DeprecatedTypeProperties & T)', '    TestIn3WithScalar(DeprecatedTypeProperties & T)', '    TestOut2Basic(DeprecatedTypeProperties & T)', '    TestOut2MismatchedSizes(DeprecatedTypeProperties & T)', '    TestOut2OldFallback(DeprecatedTypeProperties & T)', '    TestOut2WithScalar(DeprecatedTypeProperties & T)', '    TestOut3Basic(DeprecatedTypeProperties & T)', '    TestOut3MismatchedSizes(DeprecatedTypeProperties & T)', '    TestOut3OldFallback(DeprecatedTypeProperties & T)', '    TestOut3WithScalar(DeprecatedTypeProperties & T)'];
softargmax.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 101;  19; 17;9;  63; 0;51;13;28;14;0.30;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUBucketize', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Bucketize', '    RunOnDevice'];
clog.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/deps/clog/include; 123;  7; 13;81;  20; 5;0;20;0;5;0.35;0;['    final'];['    schema_BucketizeOp', '    boundaries_device_', '    BucketizeOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    is_sorted'];
clog.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/deps/clog/src; 524;  84; 35;67;  318; 34;248;40;120;40;0.26;5;[];[];
clog.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/deps/clog/test; 53;  7; 9;2;  35; 0;27;19;75;34;0.20;19;['    Buffer'];['    begin', '    end', '    Buffer(const VarHandle & data,const Dtype & dtype,const std::vector & dims)', '    Buffer(const std::string & name,const Dtype & dtype,const std::vector & dims)', '    call(const std::vector & args)', '    data', '    dim(int index)', '    dtype', '    Index(const ExprHandle & x)', '    Index(const ExprHandle & x,const ExprHandle & y)', '    Index(const ExprHandle & x,const ExprHandle & y,const ExprHandle & z)', '    Index(const ExprHandle & x,const ExprHandle & y,const ExprHandle & z,const ExprHandle & w)', '    Index(const std::vector & indices)', '    LoadValue(const ExprHandle & index)', '    ndim', '    operator()(Args,...)', '    make'];
pytorch_qnnpack.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/include; 355;  12; 37;9;  298; 0;0;298;0;32;0.04;0;[];[];
qnnpack_func.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/include; 126;  1; 17;2;  107; 0;17;76;9;26;0.01;7;[];['    rhs', '    scalar', '    scalar', '    getAllBuiltinFunctionsFor(Symbol name)', '    getAllBuiltinFunctionsFor(Symbol name)', '    loadBuiltinFunctions', '    loadSource(const std::string & source,const std::string & the_namespace)'];
add.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 160;  7; 23;10;  120; 0;85;27;53;7;0.06;2;[];['    getAllBuiltinFunctionsFor(Symbol name)'];
channel-shuffle.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 101;  7; 17;9;  68; 0;47;16;35;4;0.10;2;[];['    decodeUInt16BE(const uint8_t *data)', '    decodeUInt16LE(const uint8_t *data)', '    decodeUInt32BE(const uint8_t *data)', '    decodeUInt32LE(const uint8_t *data)', '    decodeUInt64BE(const uint8_t *data)', '    decodeUInt64LE(const uint8_t *data)', '    swapBytes16(void *ptr)', '    swapBytes32(void *ptr)', '    swapBytes64(void *ptr)', '    THP_decodeBFloat16Buffer(at::BFloat16 *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeBoolBuffer(bool *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeDoubleBuffer(double *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeFloatBuffer(float *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeHalfBuffer(at::Half *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt16Buffer(int16_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt32Buffer(int32_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt64Buffer(int64_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_encodeDoubleBuffer(uint8_t *dst,const double *src,THPByteOrder order,size_t len)', '    THP_encodeFloatBuffer(uint8_t *dst,const float *src,THPByteOrder order,size_t len)', '    THP_encodeInt16Buffer(uint8_t *dst,const int16_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt32Buffer(uint8_t *dst,const int32_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt64Buffer(uint8_t *dst,const int64_t *src,THPByteOrder order,size_t len)', '    THP_nativeByteOrder'];
clamp.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 102;  7; 17;8;  70; 0;48;17;35;4;0.10;2;[];['    THP_decodeBFloat16Buffer(at::BFloat16 *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeBoolBuffer(bool *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeDoubleBuffer(double *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeFloatBuffer(float *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeHalfBuffer(at::Half *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt16Buffer(int16_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt32Buffer(int32_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_decodeInt64Buffer(int64_t *dst,const uint8_t *src,THPByteOrder order,size_t len)', '    THP_encodeDoubleBuffer(uint8_t *dst,const double *src,THPByteOrder order,size_t len)', '    THP_encodeFloatBuffer(uint8_t *dst,const float *src,THPByteOrder order,size_t len)', '    THP_encodeInt16Buffer(uint8_t *dst,const int16_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt32Buffer(uint8_t *dst,const int32_t *src,THPByteOrder order,size_t len)', '    THP_encodeInt64Buffer(uint8_t *dst,const int64_t *src,THPByteOrder order,size_t len)', '    THP_nativeByteOrder'];
conv-prepack.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 190;  4; 8;4;  176; 0;157;33;49;24;0.02;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUByteWeightDequant', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ByteWeightDequant'];
convolution.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 625;  10; 51;24;  540; 0;452;107;180;51;0.02;3;['    ByteWeightDequantOp'];['    ByteWeightDequantOp(const OperatorDef & operator_def,Workspace *ws)', '    GetRepeatedArgument', '    GetSingleArgument', '    RunOnDevice'];
deconvolution.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 326;  7; 37;16;  266; 0;200;94;94;30;0.03;3;[];[];
fc-dynamic-run.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 117;  2; 9;3;  105; 0;58;74;3;38;0.02;2;['    final'];['    call(T value)', '    apply_impl(F,Tuple,std::index_sequence)', '    max(const T & a,const T & b)', '    min(const T & a,const T & b)', '    to_string(T value)', '    invoke(Functor,Args,...)', '    invoke(Functor,Args,...)', '    make_index_sequence', '    make_index_sequence', '    to_string(c10::guts::detail::DummyClassForToString)', '    call(T)', '    forward', '    mem_fn', '    call'];
fc-run.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 126;  2; 8;3;  115; 0;67;76;6;36;0.02;2;[];[];
fully-connected.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 184;  7; 27;15;  135; 0;101;31;55;9;0.05;2;[];['    callOp(const c10::OperatorHandle & op,Args,...)', '    callOp(const char *func_name,const char *overload_name,Args,...)', '    makeStack(Inputs,...)', '    has_value', '    value', '    singleton'];
global-average-pooling.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 158;  7; 23;10;  118; 0;87;24;57;6;0.06;2;[];[];
indirection.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 277;  7; 12;5;  253; 0;201;181;64;132;0.03;4;[];['    main(int argc,char **argv)'];
init.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 280;  7; 10;41;  25; 204;13;7;11;7;0.28;4;[];['    GetQuantizationFactoryOf_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorDef & op_def)', '    HasDNNLowPEngine_(const OperatorBase & op)', '    OutputArgumentIdxString_(int idx)', '    OutputScaleArgumentName(int idx)', '    OutputZeroPointArgumentName(int idx)', '    SetStaticQuantizationParams_(OperatorDef *op_def,int output_index,const TensorQuantizationParams & qparams)', '    AddScaleZeroOffsetArgumentsWithHistogram(NetDef net_def,const string & histogram_file_name)', '    AdjustOutputTensorQuantizationParamsWithFollowedBy(OperatorBase *op,const string & followed_by)', '    GetInputTensorQuantizationParamsOf(OperatorBase *op,int idx,const QuantizationFactory *qfactory,bool is_weight)', '    GetQuantizationFactoryOf(const OperatorBase *op)', '    GetStaticQuantizationParamsOf(const caffe2::OperatorBase *op,int idx)', '    HasStaticQuantization(const caffe2::OperatorBase *op,int output_index)', '    MeasureQuantizationError(const float *actual,const float *ref,size_t len,QuantizationErrorStats *stat)', '    ParseDNNLowPOperatorArguments(OperatorBase *op,bool *dequantize_output,bool *measure_quantization_error,string *followed_by)', '    PropagateOutputTensorQuantizationParams(OperatorBase *op,int idx,const TensorQuantizationParams & qparams)', '    QuantizeInputIfNeeded(OperatorBase *op,int input_index,const TensorQuantizationParams & qparams,vector & temp)', '    ReportQuantizationError(const OperatorBase *op,const QuantizationErrorStats & stat)', '    RowWiseQuantizeInputIfNeeded(OperatorBase *op,int input_index,const std::vector & qparams,vector & temp)', '    SetStaticQuantizationParams(OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)'];
leaky-relu.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 169;  7; 25;8;  129; 0;93;32;61;11;0.05;2;[];['    AddScaleZeroOffsetArgumentsWithHistogram(caffe2::NetDef net_def,const std::string & histogram_file_name)', '    AdjustOutputTensorQuantizationParamsWithFollowedBy(caffe2::OperatorBase *op,const std::string & followed_by)', '    GetInputTensorQuantizationParamsOf(caffe2::OperatorBase *op,int input_index,const QuantizationFactory *qfactory,bool is_weight)', '    GetQuantizationFactoryOf(const caffe2::OperatorBase *op)', '    GetStaticQuantizationParamsOf(const caffe2::OperatorBase *op,int idx)', '    HasStaticQuantization(const caffe2::OperatorBase *op,int output_index)', '    MeasureQuantizationError(const float *actual,const float *ref,size_t len,QuantizationErrorStats *stat)', '    ParseDNNLowPOperatorArguments(caffe2::OperatorBase *op,bool *dequantize_output,bool *measure_quantization_error,std::string *followed_by)', '    PropagateOutputTensorQuantizationParams(caffe2::OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)', '    QuantizeInputIfNeeded(caffe2::OperatorBase *op,int input_index,const TensorQuantizationParams & qparams,std::vector & temp)', '    ReportQuantizationError(const caffe2::OperatorBase *op,const QuantizationErrorStats & stat)', '    RowWiseQuantizeInputIfNeeded(caffe2::OperatorBase *op,int input_index,const std::vector & qparams,std::vector & temp)', '    SetStaticQuantizationParams(caffe2::OperatorBase *op,int output_index,const TensorQuantizationParams & qparams)', '    max_abs_err', '    max_err_actual', '    max_err_ref', '    measure_cnt', '    sum_err_sq', '    sum_sq'];
operator-delete.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 27;  7; 4;3;  13; 0;9;2;9;1;0.54;1;['    C10FlagParser_caffe_test_root'];['    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)'];
operator-run.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 1237;  16; 78;28;  1119; 6;770;701;118;394;0.01;21;[];['    DeviceToOption(const at::Device & device)', '    ExtractDeviceOption(DeviceOption *device_option,const at::Device & device)', '    OptionToDevice(const caffe2::DeviceOption option)', '    ProtoToType(const caffe2::DeviceTypeProto p)', '    ProtoToType(int p)', '    TypeToProto(const DeviceType & t)', '    Device'];
mp8x9p8q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 547;  7; 55;18;  417; 50;383;258;128;181;0.02;1;[];['    CanonicalizeIfOutputs(Node *n)', '    CanonicalizeLoopOutputs(Node *n)', '    CanonicalizeOutputs(Block *block)', '    CanonicalizeOutputs(std::shared_ptr & graph)', '    sort_indexes(at::ArrayRef values)', '    blockIndex(const Block *b)', '    Canonicalize(const std::shared_ptr & graph,bool keep_unique_names)', '    isBefore(Node *n1,Node *n2)', '    isBefore(const Use & a,const Use & b)'];
up8x9-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 338;  7; 31;18;  232; 50;207;147;64;87;0.03;1;[];['    Canonicalize(const std::shared_ptr & graph,bool keep_unique_names)', '    CanonicalizeOutputs(std::shared_ptr & graph)'];
up8x9-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 327;  7; 39;3;  278; 0;253;181;64;114;0.03;1;[];['    canonicalizeModifiedLoops(Block *block)', '    CanonicalizeModifiedLoops(std::shared_ptr & graph)', '    canonicalizeModifiedLoop(Node *n)'];
up8xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 169;  7; 17;12;  107; 26;89;58;36;30;0.07;1;[];[];
4x4c2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv; 465;  7; 39;3;  416; 0;393;212;82;117;0.02;1;[];['    CanonicalizeOps(Block *block)', '    CanonicalizeOps(const std::shared_ptr & graph)', '    insert_guard', '    ChunkOutput(Value *v,size_t o)'];
4x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv; 686;  7; 43;6;  617; 13;572;135;219;81;0.01;1;[];['    CanonicalizeOps(const std::shared_ptr & graph)'];
8x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv; 1178;  7; 43;6;  1097; 25;1048;195;407;118;0.01;1;[];['    GetCastDataType(const ArgumentHelper & helper,std::string arg)'];
mp8x25-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv; 1138;  7; 102;2;  1027; 0;1000;699;206;426;0.01;1;[];['    CastAllConstantToFloating(Block *block)', '    CastAllConstantToFloating(const std::shared_ptr & graph)'];
up8x9-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv; 966;  7; 39;11;  308; 601;292;178;106;111;0.02;1;[];['    CastAllConstantToFloating(const std::shared_ptr & graph)'];
up8x9-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv; 548;  7; 67;3;  471; 0;455;341;80;203;0.01;1;[];['    cast_op_cpu(const at::Tensor & input,const at::Tensor & output,int64_t to)', '    cast_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_,int64_t to_)', '    do_cast_(const Tensor & input,const Tensor & output)'];
mp8x7p7q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 410;  9; 44;3;  354; 0;330;182;149;126;0.03;1;['    GetCastGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cast', '    vector', '    call(SrcType data)', '    call(SrcType data)', '    DoRunWithDstType', '    DoRunWithType', '    SetBody(TensorProto_DataType to)', '    CopyArguments', '    GetGradientDefs'];
up8x7-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 295;  7; 28;18;  192; 50;172;118;60;72;0.04;1;['    CastOp'];['    CastOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithDstType', '    DoRunWithType', '    RunOnDevice', '    SetBody(TensorProto_DataType to)'];
up8x7-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 291;  7; 35;3;  246; 0;226;144;76;89;0.03;1;[];['    TEST(CastTest,GetCastDataType)'];
up8xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 145;  7; 19;3;  116; 0;98;63;36;33;0.06;1;[];['    doit(const std::unique_ptr & Val)', '    assert(isa)', '    cast(const Y & Val)', '    cast(Y & Val)', '    cast(Y *Val)', '    cast_or_null(const Y & Val)', '    cast_or_null(Y & Val)', '    cast_or_null(Y *Val)', '    dyn_cast(const Y & Val)', '    dyn_cast(Y & Val)', '    dyn_cast(Y *Val)', '    dyn_cast_or_null(const Y & Val)', '    dyn_cast_or_null(Y & Val)', '    dyn_cast_or_null(Y *Val)', '    isa(const Y & Val)', '    doit(From & Val)', '    doit(const FromTy & Val)', '    doit(const From &)', '    doit(const From & Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From *Val)', '    doit(const From & Val)', '    doit(const From & Val)', '    doit(const From & Val)', '    doit(const FromTy & Val)', '    getSimplifiedValue(From & Val)', '    getSimplifiedValue(const From & Val)'];
2x4c8-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 291;  11; 34;6;  233; 7;205;158;54;89;0.05;2;[];[];
4x-sumrows-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 154;  15; 13;2;  128; 0;109;42;58;27;0.12;1;[];['    cat_serial_kernel(Tensor & result,TensorList tensors,int64_t dim)', '    cat_serial_kernel_impl(Tensor & result,TensorList tensors,int64_t dim)', '    InputMeta(const Tensor & t,int64_t dim,int64_t inner)'];
4x4c2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 452;  7; 42;3;  400; 0;374;213;83;115;0.02;1;[];['    cat_serial_stub', '    cat_serial_stub', '    operator='];
4x8-dq-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 586;  7; 46;3;  530; 0;500;132;190;77;0.01;1;[];['    catlas_caxpby(const int N,const void *alpha,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    catlas_cset(const int N,const void *alpha,void *X,const int incX)', '    catlas_daxpby(const int N,const double alpha,const double *X,const int incX,const double beta,double *Y,const int incY)', '    catlas_dset(const int N,const double alpha,double *X,const int incX)', '    catlas_saxpby(const int N,const float alpha,const float *X,const int incX,const float beta,float *Y,const int incY)', '    catlas_sset(const int N,const float alpha,float *X,const int incX)', '    catlas_zaxpby(const int N,const void *alpha,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    catlas_zset(const int N,const void *alpha,void *X,const int incX)', '    cblas_caxpy(const int N,const void *alpha,const void *X,const int incX,void *Y,const int incY)', '    cblas_ccopy(const int N,const void *X,const int incX,void *Y,const int incY)', '    cblas_cdotc_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotc)', '    cblas_cdotu_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotu)', '    cblas_cgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_cgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cgerc(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_cgeru(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_chbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_chemm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_chemv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_cher(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const void *X,const int incX,void *A,const int lda)', '    cblas_cher2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_cher2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const float beta,void *C,const int ldc)', '    cblas_cherk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const void *A,const int lda,const float beta,void *C,const int ldc)', '    cblas_chpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *Ap,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_chpr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const void *X,const int incX,void *A)', '    cblas_chpr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *Ap)', '    cblas_crotg(void *a,void *b,void *c,void *s)', '    cblas_cscal(const int N,const void *alpha,void *X,const int incX)', '    cblas_csrot(const int N,void *X,const int incX,void *Y,const int incY,const float c,const float s)', '    cblas_csscal(const int N,const float alpha,void *X,const int incX)', '    cblas_cswap(const int N,void *X,const int incX,void *Y,const int incY)', '    cblas_csymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_csyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_csyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *beta,void *C,const int ldc)', '    cblas_ctbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ctbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ctpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ctpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ctrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ctrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_ctrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ctrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_dasum(const int N,const double *X,const int incX)', '    cblas_daxpy(const int N,const double alpha,const double *X,const int incX,double *Y,const int incY)', '    cblas_dcopy(const int N,const double *X,const int incX,double *Y,const int incY)', '    cblas_ddot(const int N,const double *X,const int incX,const double *Y,const int incY)', '    cblas_dgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dger(const enum CBLAS_ORDER Order,const int M,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A,const int lda)', '    cblas_dnrm2(const int N,const double *X,const int incX)', '    cblas_drot(const int N,double *X,const int incX,double *Y,const int incY,const double c,const double s)', '    cblas_drotg(double *a,double *b,double *c,double *s)', '    cblas_drotm(const int N,double *X,const int incX,double *Y,const int incY,const double *P)', '    cblas_drotmg(double *d1,double *d2,double *b1,const double b2,double *P)', '    cblas_dsbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dscal(const int N,const double alpha,double *X,const int incX)', '    cblas_dsdot(const int N,const float *X,const int incX,const float *Y,const int incY)', '    cblas_dspmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *Ap,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dspr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,double *Ap)', '    cblas_dspr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A)', '    cblas_dswap(const int N,double *X,const int incX,double *Y,const int incY)', '    cblas_dsymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dsymv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *A,const int lda,const double *X,const int incX,const double beta,double *Y,const int incY)', '    cblas_dsyr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,double *A,const int lda)', '    cblas_dsyr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const double *X,const int incX,const double *Y,const int incY,double *A,const int lda)', '    cblas_dsyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const double *A,const int lda,const double *B,const int ldb,const double beta,double *C,const int ldc)', '    cblas_dsyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const double *A,const int lda,const double beta,double *C,const int ldc)', '    cblas_dtbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const double *A,const int lda,double *X,const int incX)', '    cblas_dtbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const double *A,const int lda,double *X,const int incX)', '    cblas_dtpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *Ap,double *X,const int incX)', '    cblas_dtpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *Ap,double *X,const int incX)', '    cblas_dtrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const double alpha,const double *A,const int lda,double *B,const int ldb)', '    cblas_dtrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *A,const int lda,double *X,const int incX)', '    cblas_dtrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const double alpha,const double *A,const int lda,double *B,const int ldb)', '    cblas_dtrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const double *A,const int lda,double *X,const int incX)', '    cblas_dzasum(const int N,const void *X,const int incX)', '    cblas_dznrm2(const int N,const void *X,const int incX)', '    cblas_errprn(int ierr,int info,char *form,...)', '    cblas_icamax(const int N,const void *X,const int incX)', '    cblas_idamax(const int N,const double *X,const int incX)', '    cblas_isamax(const int N,const float *X,const int incX)', '    cblas_izamax(const int N,const void *X,const int incX)', '    cblas_sasum(const int N,const float *X,const int incX)', '    cblas_saxpy(const int N,const float alpha,const float *X,const int incX,float *Y,const int incY)', '    cblas_scasum(const int N,const void *X,const int incX)', '    cblas_scnrm2(const int N,const void *X,const int incX)', '    cblas_scopy(const int N,const float *X,const int incX,float *Y,const int incY)', '    cblas_sdot(const int N,const float *X,const int incX,const float *Y,const int incY)', '    cblas_sdsdot(const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY)', '    cblas_sgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_sgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sger(const enum CBLAS_ORDER Order,const int M,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A,const int lda)', '    cblas_snrm2(const int N,const float *X,const int incX)', '    cblas_srot(const int N,float *X,const int incX,float *Y,const int incY,const float c,const float s)', '    cblas_srotg(float *a,float *b,float *c,float *s)', '    cblas_srotm(const int N,float *X,const int incX,float *Y,const int incY,const float *P)', '    cblas_srotmg(float *d1,float *d2,float *b1,const float b2,float *P)', '    cblas_ssbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sscal(const int N,const float alpha,float *X,const int incX)', '    cblas_sspmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *Ap,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_sspr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,float *Ap)', '    cblas_sspr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A)', '    cblas_sswap(const int N,float *X,const int incX,float *Y,const int incY)', '    cblas_ssymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_ssymv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *A,const int lda,const float *X,const int incX,const float beta,float *Y,const int incY)', '    cblas_ssyr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,float *A,const int lda)', '    cblas_ssyr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const float alpha,const float *X,const int incX,const float *Y,const int incY,float *A,const int lda)', '    cblas_ssyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc)', '    cblas_ssyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const float alpha,const float *A,const int lda,const float beta,float *C,const int ldc)', '    cblas_stbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const float *A,const int lda,float *X,const int incX)', '    cblas_stbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const float *A,const int lda,float *X,const int incX)', '    cblas_stpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *Ap,float *X,const int incX)', '    cblas_stpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *Ap,float *X,const int incX)', '    cblas_strmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const float alpha,const float *A,const int lda,float *B,const int ldb)', '    cblas_strmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *A,const int lda,float *X,const int incX)', '    cblas_strsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const float alpha,const float *A,const int lda,float *B,const int ldb)', '    cblas_strsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const float *A,const int lda,float *X,const int incX)', '    cblas_xerbla(int p,const char *rout,const char *form,...)', '    cblas_zaxpy(const int N,const void *alpha,const void *X,const int incX,void *Y,const int incY)', '    cblas_zcopy(const int N,const void *X,const int incX,void *Y,const int incY)', '    cblas_zdotc_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotc)', '    cblas_zdotu_sub(const int N,const void *X,const int incX,const void *Y,const int incY,void *dotu)', '    cblas_zdrot(const int N,void *X,const int incX,void *Y,const int incY,const double c,const double s)', '    cblas_zdscal(const int N,const double alpha,void *X,const int incX)', '    cblas_zgbmv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const int KL,const int KU,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zgemm(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_TRANSPOSE TransB,const int M,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zgemv(const enum CBLAS_ORDER Order,const enum CBLAS_TRANSPOSE TransA,const int M,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zgerc(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zgeru(const enum CBLAS_ORDER Order,const int M,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zhbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const int K,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zhemm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zhemv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *A,const int lda,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zher(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const void *X,const int incX,void *A,const int lda)', '    cblas_zher2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *A,const int lda)', '    cblas_zher2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const double beta,void *C,const int ldc)', '    cblas_zherk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const double alpha,const void *A,const int lda,const double beta,void *C,const int ldc)', '    cblas_zhpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *Ap,const void *X,const int incX,const void *beta,void *Y,const int incY)', '    cblas_zhpr(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const double alpha,const void *X,const int incX,void *A)', '    cblas_zhpr2(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const int N,const void *alpha,const void *X,const int incX,const void *Y,const int incY,void *Ap)', '    cblas_zrotg(void *a,void *b,void *c,void *s)', '    cblas_zscal(const int N,const void *alpha,void *X,const int incX)', '    cblas_zswap(const int N,void *X,const int incX,void *Y,const int incY)', '    cblas_zsymm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const int M,const int N,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zsyr2k(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *B,const int ldb,const void *beta,void *C,const int ldc)', '    cblas_zsyrk(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE Trans,const int N,const int K,const void *alpha,const void *A,const int lda,const void *beta,void *C,const int ldc)', '    cblas_ztbmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ztbsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const int K,const void *A,const int lda,void *X,const int incX)', '    cblas_ztpmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ztpsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *Ap,void *X,const int incX)', '    cblas_ztrmm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ztrmv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)', '    cblas_ztrsm(const enum CBLAS_ORDER Order,const enum CBLAS_SIDE Side,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int M,const int N,const void *alpha,const void *A,const int lda,void *B,const int ldb)', '    cblas_ztrsv(const enum CBLAS_ORDER Order,const enum CBLAS_UPLO Uplo,const enum CBLAS_TRANSPOSE TransA,const enum CBLAS_DIAG Diag,const int N,const void *A,const int lda,void *X,const int incX)'];
4x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 673;  7; 42;6;  605; 13;575;134;224;79;0.01;1;['    GetCbrtGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCbrt', '    CAFFE_ANONYMOUS_VARIABLE_CPUCbrtGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cbrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CbrtGradient', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *Y,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
6x4-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 547;  7; 38;6;  486; 10;453;134;188;80;0.01;1;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & Y_dims,const T *dY,const T *Y,T *dX,Context *context)'];
8x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 1177;  7; 42;6;  1097; 25;1059;194;420;117;0.01;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConcatAddMulReplaceNaNClip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatAddMulReplaceNaNClip'];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8vadd; 382;  23; 35;24;  187; 113;170;91;67;48;0.12;1;['    final'];['    ConcatAddMulReplaceNaNClipOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice'];
AlignedAllocator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 104;  7; 17;12;  63; 7;12;38;9;27;0.11;9;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConcatBatchMatMulBatchGatherOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatBatchMatMulBatchGatherOp'];
assembly.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 33;  8; 1;3;  0; 21;0;0;0;0;0.00;0;['    final'];['    ConcatBatchMatMulBatchGatherOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    Gemm'];
common.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 82;  7; 10;65;  0; 26;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCeil', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Ceil'];
indirection.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 45;  7; 9;9;  18; 2;0;18;0;4;0.39;0;['    final'];['    CeilOp(Args,...)', '    RunOnDevice', '    ~CeilOp'];
isa-checks.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 32;  7; 5;20;  0; 0;0;0;0;0;0.00;0;['    ChannelShuffleOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels', '    groupChannels(size_t groupChannels)', '    groupChannels', '    groupChannels_', '    groups(size_t groups)', '    groups', '    groups_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    testX8'];
log.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 35;  7; 5;6;  17; 0;5;5;21;10;0.41;5;[];['    pytorch_qnnp_create_channel_shuffle_nc_x8(size_t groups,size_t group_channels,uint32_t flags,pytorch_qnnp_operator_t *channel_shuffle_out)', '    pytorch_qnnp_setup_channel_shuffle_nc_x8(pytorch_qnnp_operator_t channel_shuffle_op,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
operator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 121;  7; 17;4;  93; 0;4;83;4;60;0.08;4;[];['    TEST(CHANNEL_SHUFFLE_OP,zero_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_unit_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_input_stride)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,two_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,three_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,four_groups_small_batch_with_input_and_output_stride)', '    TEST(CHANNEL_SHUFFLE_OP,many_groups_small_batch_with_input_and_output_stride)'];
pack.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 640;  10; 29;15;  584; 7;332;318;256;165;0.02;14;[];['    channel_shuffle_x8(benchmark::State & state,const char *net)', '    ShuffleNetV1G2Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x0_5Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x1_0Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x1_5Arguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV2x2_0Arguments(benchmark::internal::Benchmark *b)'];
params.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 567;  33; 49;26;  378; 88;0;357;0;196;0.09;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUChannelBackpropStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelBackpropStats', '    RunOnDevice'];
q8conv.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 41;  7; 7;20;  5; 2;0;5;0;5;1.40;0;['    ChannelBackpropStatsOp'];['    ChannelBackpropStatsOp(Args,...)', '    RunOnDevice', '    ~ChannelBackpropStatsOp'];
q8dwconv.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 53;  7; 9;30;  5; 2;0;5;0;5;1.40;0;[];['    ChannelShuffleDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
q8gavgpool.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 54;  7; 9;30;  6; 2;0;6;0;6;1.17;0;['    final'];['    ChannelShuffleDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
q8vadd.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 34;  7; 7;16;  2; 2;0;2;0;2;3.50;0;['    final', '    final'];['    ChannelShuffleGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    ChannelShuffleOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW'];
requantization-stubs.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 74;  8; 12;18;  37; 0;0;37;0;25;0.22;0;['    GetChannelShuffleGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUChannelShuffle', '    RunChannelShuffleNCHW(const int N,const int G,const int K,const int HxW,const T *X,T *Y,CPUContext *context)', '    RunChannelShuffleNHWC(const int N,const int G,const int K,const int HxW,const T *X,T *Y,CPUContext *context)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelShuffleGradient', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW', '    GetGradientDefs', '    vector'];
requantization.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 549;  33; 43;28;  310; 135;219;140;132;69;0.11;11;['    final', '    final'];['    ChannelShuffleGradientOp(Args,...)', '    ChannelShuffleOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
sconv.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 37;  7; 7;20;  1; 2;0;1;0;1;7.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUChannelStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ChannelStats', '    ComputeChannelStatsNCHW(const int N,const int C,const int HxW,const float *X,float *sum,float *sumsq)'];
sdwconv.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 48;  7; 8;30;  1; 2;0;1;0;1;7.00;0;['    final'];['    ChannelStatsOp(Args,...)', '    ComputeChannelStatsNCHW(int N,int C,int HxW,const T *X,T *sum,T *sumsq)', '    ComputeChannelStatsNHWC(int N,int C,int HxW,const T *X,T *sum,T *sumsq)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice'];
sgemm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 38;  8; 7;19;  5; 0;0;5;0;3;1.60;0;[];['    checkAliasAnnotation(const std::shared_ptr & graph,std::vector pythonInputs,const std::string & unqualifiedOpName)', '    checkAliases(const std::vector & inputs,const std::vector & outputs)', '    checkInputPreconditions(const Stack & inputs)', '    checkWrites(const std::vector & inputs,const std::vector & deepCopiedInputs)', '    deepCopy(const IValue & self)', '    deepCopy(const Stack & stack)', '    deepEquals(const IValue & lhs,const IValue & rhs)', '    findNodeForOp(const Graph & g,const std::string & unqualifiedOpName)', '    toIValueProp(const Value *v)', '    AliasAndIValue(c10::optional aliasInfo,IValue iValue)'];
u8lut32norm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 29;  7; 7;12;  1; 2;0;1;0;1;7.00;0;[];['    checkAliasAnnotation(const std::shared_ptr & graph,std::vector pythonInputs,const std::string & unqualifiedOpName)'];
u8maxpool.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 39;  7; 7;19;  4; 2;0;4;0;4;1.75;0;[];[];
u8rmax.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 29;  7; 7;11;  2; 2;0;2;0;2;3.50;0;[];['    clBuildProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCompileProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_headers,const cl_program *input_headers,const char **header_include_names,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCreateBuffer(cl_context context,cl_mem_flags flags,size_t size,void *host_ptr,cl_int *errcode_ret)', '    clCreateCommandQueue(cl_context context,cl_device_id device,cl_command_queue_properties properties,cl_int *errcode_ret)', '    clCreateContext(const cl_context_properties *properties,cl_uint num_devices,const cl_device_id *devices,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateContextFromType(const cl_context_properties *properties,cl_device_type device_type,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateImage(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,const cl_image_desc *image_desc,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage2D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_row_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage3D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_depth,size_t image_row_pitch,size_t image_slice_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateKernel(cl_program program,const char *kernel_name,cl_int *errcode_ret)', '    clCreateKernelsInProgram(cl_program program,cl_uint num_kernels,cl_kernel *kernels,cl_uint *num_kernels_ret)', '    clCreateProgramWithBinary(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const size_t *lengths,const unsigned char **binaries,cl_int *binary_status,cl_int *errcode_ret)', '    clCreateProgramWithBuiltInKernels(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *kernel_names,cl_int *errcode_ret)', '    clCreateProgramWithSource(cl_context context,cl_uint count,const char **strings,const size_t *lengths,cl_int *errcode_ret)', '    clCreateSampler(cl_context context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *errcode_ret)', '    clCreateSubBuffer(cl_mem buffer,cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *errcode_ret)', '    clCreateSubDevices(cl_device_id in_device,const cl_device_partition_property *properties,cl_uint num_devices,cl_device_id *out_devices,cl_uint *num_devices_ret)', '    clCreateUserEvent(cl_context context,cl_int *errcode_ret)', '    clEnqueueBarrier(cl_command_queue command_queue)', '    clEnqueueBarrierWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBuffer(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,size_t src_offset,size_t dst_offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferRect(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,const size_t *src_origin,const size_t *dst_origin,const size_t *region,size_t src_row_pitch,size_t src_slice_pitch,size_t dst_row_pitch,size_t dst_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferToImage(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_image,size_t src_offset,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImage(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_image,const size_t *src_origin,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImageToBuffer(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_buffer,const size_t *src_origin,const size_t *region,size_t dst_offset,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillBuffer(cl_command_queue command_queue,cl_mem buffer,const void *pattern,size_t pattern_size,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillImage(cl_command_queue command_queue,cl_mem image,const void *fill_color,const size_t *origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMapBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_map,cl_map_flags map_flags,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMapImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_map,cl_map_flags map_flags,const size_t *origin,const size_t *region,size_t *image_row_pitch,size_t *image_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMarker(cl_command_queue command_queue,cl_event *event)', '    clEnqueueMarkerWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMigrateMemObjects(cl_command_queue command_queue,cl_uint num_mem_objects,const cl_mem *mem_objects,cl_mem_migration_flags flags,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNativeKernel(cl_command_queue command_queue,void (*) (void *) user_func,void *args,size_t cb_args,cl_uint num_mem_objects,const cl_mem *mem_list,const void **args_mem_loc,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNDRangeKernel(cl_command_queue command_queue,cl_kernel kernel,cl_uint work_dim,const size_t *global_work_offset,const size_t *global_work_size,const size_t *local_work_size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,size_t offset,size_t size,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_read,const size_t *origin,const size_t *region,size_t row_pitch,size_t slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueTask(cl_command_queue command_queue,cl_kernel kernel,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueUnmapMemObject(cl_command_queue command_queue,cl_mem memobj,void *mapped_ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWaitForEvents(cl_command_queue command_queue,cl_uint num_events,const cl_event *event_list)', '    clEnqueueWriteBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,size_t offset,size_t size,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_write,const size_t *origin,const size_t *region,size_t input_row_pitch,size_t input_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clFinish(cl_command_queue command_queue)', '    clFlush(cl_command_queue command_queue)', '    clGetCommandQueueInfo(cl_command_queue command_queue,cl_command_queue_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetContextInfo(cl_context context,cl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetDeviceIDs(cl_platform_id platform,cl_device_type device_type,cl_uint num_entries,cl_device_id *devices,cl_uint *num_devices)', '    clGetDeviceInfo(cl_device_id device,cl_device_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventInfo(cl_event event,cl_event_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventProfilingInfo(cl_event event,cl_profiling_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetExtensionFunctionAddress(const char *func_name)', '    clGetExtensionFunctionAddressForPlatform(cl_platform_id platform,const char *func_name)', '    clGetImageInfo(cl_mem image,cl_image_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelArgInfo(cl_kernel kernel,cl_uint arg_indx,cl_kernel_arg_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelInfo(cl_kernel kernel,cl_kernel_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelWorkGroupInfo(cl_kernel kernel,cl_device_id device,cl_kernel_work_group_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetMemObjectInfo(cl_mem memobj,cl_mem_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetPlatformIDs(cl_uint num_entries,cl_platform_id *platforms,cl_uint *num_platforms)', '    clGetPlatformInfo(cl_platform_id platform,cl_platform_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramBuildInfo(cl_program program,cl_device_id device,cl_program_build_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramInfo(cl_program program,cl_program_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSamplerInfo(cl_sampler sampler,cl_sampler_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSupportedImageFormats(cl_context context,cl_mem_flags flags,cl_mem_object_type image_type,cl_uint num_entries,cl_image_format *image_formats,cl_uint *num_image_formats)', '    clLinkProgram(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_programs,const cl_program *input_programs,void (*) (cl_program, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clReleaseCommandQueue(cl_command_queue command_queue)', '    clReleaseContext(cl_context context)', '    clReleaseDevice(cl_device_id device)', '    clReleaseEvent(cl_event event)', '    clReleaseKernel(cl_kernel kernel)', '    clReleaseMemObject(cl_mem memobj)', '    clReleaseProgram(cl_program program)', '    clReleaseSampler(cl_sampler sampler)', '    clRetainCommandQueue(cl_command_queue command_queue)', '    clRetainContext(cl_context context)', '    clRetainDevice(cl_device_id device)', '    clRetainEvent(cl_event event)', '    clRetainKernel(cl_kernel kernel)', '    clRetainMemObject(cl_mem memobj)', '    clRetainProgram(cl_program program)', '    clRetainSampler(cl_sampler sampler)', '    clSetEventCallback(cl_event event,cl_int command_exec_callback_type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    clSetKernelArg(cl_kernel kernel,cl_uint arg_index,size_t arg_size,const void *arg_value)', '    clSetMemObjectDestructorCallback(cl_mem memobj,void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    clSetUserEventStatus(cl_event event,cl_int execution_status)', '    clUnloadCompiler', '    clUnloadPlatformCompiler(cl_platform_id platform)', '    clWaitForEvents(cl_uint num_events,const cl_event *event_list)'];
x8zip.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 40;  7; 9;14;  8; 2;0;8;0;8;0.88;0;['    Buffer', '    BufferGL', '    BufferRenderGL', '    CommandQueue', '    Context', '    KernelFunctorGlobal', '    NullType', '    Wrapper', '    Wrapper', '    Device', '    Event', '    Image', '    Image1D', '    Image1DArray', '    Image1DBuffer', '    Image2D', '    Image2DArray', '    Image3D', '    ImageGL', '    Kernel', '    Memory', '    NDRange', '    Platform', '    Program', '    Sampler', '    size_t', '    UserEvent'];['    errHandler(cl_int err,const char *errStr)', '    getDevicePlatformVersion(cl_device_id device)', '    getPlatformVersion(cl_platform_id platform)', '    getVersion(const char *versionInfo)', '    WaitForEvents(const std::vector & events)', '    __local(::size_t size)', '    copy(const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    copy(const CommandQueue & queue,const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    compare_exchange(volatile int *dest,int exchange,int comparand)', '    fence', '    getInfo(Func f,const Arg0 & arg0,cl_uint name,T *param)', '    getInfo(Func f,const Arg0 & arg0,const Arg1 & arg1,cl_uint name,T *param)', '    getInfo(Func f,cl_uint name,T *param)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,long)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,int,T::cl_type)', '    getInfoHelper(Func f,cl_uint name,T *param,int,T::cl_type)', '    getInfoHelper(Func f,cl_uint name,STRING_CLASS *param,long)', '    getInfoHelper(Func f,cl_uint name,size_t *param,long)', '    getInfoHelper(Func f,cl_uint name,std::vector *param,int)', '    getInfoHelper(Functor f,cl_uint name,T *param,long)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    linkProgram(Program input1,Program input2,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    linkProgram(std::vector inputPrograms,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    Local(::size_t size)', '    getDefault(cl_int *err)', '    getDefault(cl_int *err)', '    ptr(const T & value)', '    ptr(const LocalSpaceArg &)', '    size(const LocalSpaceArg & value)', '    size(const T &)', '    release(cl_context context)', '    release(cl_mem memory)', '    release(cl_command_queue queue)', '    release(cl_sampler sampler)', '    release(cl_kernel kernel)', '    release(cl_program program)', '    release(cl_platform_id)', '    release(cl_event event)', '    release(cl_device_id device)', '    retain(cl_context context)', '    retain(cl_mem memory)', '    retain(cl_command_queue queue)', '    retain(cl_kernel kernel)', '    retain(cl_program program)', '    retain(cl_platform_id)', '    retain(cl_event event)', '    retain(cl_device_id device)', '    retain(cl_sampler sampler)', '    set(Kernel kernel,T0 arg)', '    set(Kernel,NullType)', '    isReferenceCountable(cl_device_id device)', '    getDefault(cl_int *err)', '    waitForEvents(const std::vector & events)', '    get(std::vector *platforms)', '    get(Platform *platform)', '    get(cl_int *errResult)', '    getDefault(cl_int *errResult)', '    Buffer(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const Context & context,cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const Buffer & buf)', '    Buffer', '    Buffer(IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const cl_mem & buffer)', '    Buffer(cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const Context & context,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    createSubBuffer(cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Buffer & buf)', '    BufferGL(const Context & context,cl_mem_flags flags,cl_GLuint bufobj,cl_int *err)', '    BufferGL(const cl_mem & buffer)', '    BufferGL', '    BufferGL(const BufferGL & buf)', '    getObjectInfo(cl_gl_object_type *type,cl_GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferGL & buf)', '    BufferRenderGL(const Context & context,cl_mem_flags flags,cl_GLuint bufobj,cl_int *err)', '    BufferRenderGL(const BufferRenderGL & buf)', '    BufferRenderGL', '    BufferRenderGL(const cl_mem & buffer)', '    getObjectInfo(cl_gl_object_type *type,cl_GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferRenderGL & rhs)', '    CommandQueue(cl_command_queue_properties properties,cl_int *err)', '    CommandQueue', '    CommandQueue(const CommandQueue & queue)', '    CommandQueue(const Context & context,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(const cl_command_queue & commandQueue)', '    CommandQueue(const Context & context,const Device & device,cl_command_queue_properties properties,cl_int *err)', '    enqueueAcquireGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueBarrierWithWaitList(const std::vector *events,Event *event)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueFillBuffer(const Buffer & buffer,PatternType pattern,::size_t offset,::size_t size,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_float4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_int4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_uint4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueMapImage(const Image & buffer,cl_bool blocking,cl_map_flags flags,const size_t & origin,const size_t & region,::size_t *row_pitch,::size_t *slice_pitch,const std::vector *events,Event *event,cl_int *err)', '    enqueueMarkerWithWaitList(const std::vector *events,Event *event)', '    enqueueMigrateMemObjects(const std::vector & memObjects,cl_mem_migration_flags flags,const std::vector *events,Event *event)', '    enqueueNativeKernel(void (*) (void *) userFptr,std::pair args,const std::vector *mem_objects,const std::vector *mem_locs,const std::vector *events,Event *event)', '    enqueueNDRangeKernel(const Kernel & kernel,const NDRange & offset,const NDRange & global,const NDRange & local,const std::vector *events,Event *event)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReleaseGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueTask(const Kernel & kernel,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    getInfo(cl_command_queue_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const CommandQueue & queue)', '    operator=(const cl_command_queue & rhs)', '    Context(const std::vector & devices,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Device & device,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Context & ctx)', '    Context', '    Context(const cl_context & context)', '    Context(cl_device_type type,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_context_info name,T *param)', '    getSupportedImageFormats(cl_mem_flags flags,cl_mem_object_type type,std::vector *formats)', '    operator=(const Context & ctx)', '    operator=(const cl_context & rhs)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30,T31 arg31)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    KernelFunctorGlobal(Kernel kernel)', '    KernelFunctorGlobal(const Program & program,const STRING_CLASS name,cl_int *err)', '    operator()(const EnqueueArgs & args,T0 t0,T1 t1,T2 t2,T3 t3,T4 t4,T5 t5,T6 t6,T7 t7,T8 t8,T9 t9,T10 t10,T11 t11,T12 t12,T13 t13,T14 t14,T15 t15,T16 t16,T17 t17,T18 t18,T19 t19,T20 t20,T21 t21,T22 t22,T23 t23,T24 t24,T25 t25,T26 t26,T27 t27,T28 t28,T29 t29,T30 t30,T31 t31)', '    operator()', '    operator()', '    operator()', '    operator()', '    operator=(const cl_type & rhs)', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    operator=(const Wrapper & rhs)', '    release', '    release', '    retain', '    retain', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    ~Wrapper', '    ~Wrapper', '    createSubDevices(const cl_device_partition_property *properties,std::vector *devices)', '    Device', '    Device(const cl_device_id & device)', '    Device(const Device & dev)', '    getInfo(cl_device_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const cl_device_id & rhs)', '    operator=(const Device & dev)', '    EnqueueArgs(const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(NDRange global)', '    EnqueueArgs(NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange global)', '    EnqueueArgs(Event e,NDRange global,NDRange local)', '    EnqueueArgs(NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(const std::vector & events,NDRange global)', '    EnqueueArgs(const std::vector & events,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange global)', '    EnqueueArgs(CommandQueue & queue,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global,NDRange local)', '    Event', '    Event(const cl_event & event)', '    getInfo(cl_int *err)', '    getInfo(cl_event_info name,T *param)', '    getProfilingInfo(cl_profiling_info name,T *param)', '    getProfilingInfo(cl_int *err)', '    operator=(const cl_event & rhs)', '    setCallback(cl_int type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    wait', '    Image1D(const cl_mem & image1D)', '    Image1D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,void *host_ptr,cl_int *err)', '    Image1D', '    Image1D(const Image1D & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1D & img)', '    Image1DArray(const cl_mem & imageArray)', '    Image1DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t rowPitch,void *host_ptr,cl_int *err)', '    Image1DArray', '    Image1DArray(const Image1DArray & img)', '    operator=(const Image1DArray & img)', '    operator=(const cl_mem & rhs)', '    Image1DBuffer(const cl_mem & image1D)', '    Image1DBuffer(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,const Buffer & buffer,cl_int *err)', '    Image1DBuffer', '    Image1DBuffer(const Image1DBuffer & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1DBuffer & img)', '    Image2D(const cl_mem & image2D)', '    Image2D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t row_pitch,void *host_ptr,cl_int *err)', '    Image2D', '    Image2D(const Image2D & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2D & img)', '    Image2DArray(const cl_mem & imageArray)', '    Image2DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t height,::size_t rowPitch,::size_t slicePitch,void *host_ptr,cl_int *err)', '    Image2DArray', '    Image2DArray(const Image2DArray & img)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2DArray & img)', '    Image3D(const cl_mem & image3D)', '    Image3D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t depth,::size_t row_pitch,::size_t slice_pitch,void *host_ptr,cl_int *err)', '    Image3D', '    Image3D(const Image3D & img)', '    operator=(const Image3D & img)', '    operator=(const cl_mem & rhs)', '    getImageInfo(cl_image_info name,T *param)', '    getImageInfo(cl_int *err)', '    Image(const cl_mem & image)', '    Image', '    Image(const Image & img)', '    operator=(const Image & img)', '    operator=(const cl_mem & rhs)', '    ImageFormat', '    ImageFormat(cl_channel_order order,cl_channel_type type)', '    operator=(const ImageFormat & rhs)', '    ImageGL(const Context & context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texobj,cl_int *err)', '    ImageGL(const cl_mem & image)', '    ImageGL', '    ImageGL(const ImageGL & img)', '    operator=(const cl_mem & rhs)', '    operator=(const ImageGL & img)', '    getArgInfo(cl_uint argIndex,cl_kernel_arg_info name,T *param)', '    getArgInfo(cl_uint argIndex,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_kernel_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_kernel_work_group_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_int *err)', '    Kernel(const Program & program,const char *name,cl_int *err)', '    Kernel(const Kernel & kernel)', '    Kernel(const cl_kernel & kernel)', '    Kernel', '    operator=(const Kernel & kernel)', '    operator=(const cl_kernel & rhs)', '    setArg(cl_uint index,const T & value)', '    setArg(cl_uint index,::size_t size,const void *argPtr)', '    make_kernel(const Program & program,const STRING_CLASS name,cl_int *err)', '    make_kernel(const Kernel kernel)', '    getInfo(cl_mem_info name,T *param)', '    getInfo(cl_int *err)', '    Memory(const cl_mem & memory)', '    Memory', '    Memory(const Memory & mem)', '    operator=(const cl_mem & rhs)', '    operator=(const Memory & mem)', '    setDestructorCallback(void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    dimensions', '    NDRange', '    NDRange(::size_t size0)', '    NDRange(::size_t size0,::size_t size1)', '    NDRange(::size_t size0,::size_t size1,::size_t size2)', '    operator const size_t *', '    getDevices(cl_device_type type,std::vector *devices)', '    getInfo(cl_int *err)', '    getInfo(cl_platform_info name,STRING_CLASS *param)', '    operator=(const cl_platform_id & rhs)', '    Platform', '    Platform(const cl_platform_id & platform)', '    unloadCompiler', '    build(const std::vector & devices,const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    build(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    compile(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    createKernels(std::vector *kernels)', '    getBuildInfo(const Device & device,cl_program_build_info name,T *param)', '    getBuildInfo(const Device & device,cl_int *err)', '    getInfo(cl_program_info name,T *param)', '    getInfo(cl_int *err)', '    getInfo(cl_int *err)', '    operator=(const Program & program)', '    operator=(const cl_program & rhs)', '    Program(const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Program & program)', '    Program(const cl_program & program)', '    Program(const Context & context,const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const STRING_CLASS & kernelNames,cl_int *err)', '    Program(const Context & context,const Sources & sources,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const Binaries & binaries,std::vector *binaryStatus,cl_int *err)', '    Program', '    getInfo(cl_sampler_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const Sampler & sam)', '    operator=(const cl_sampler & rhs)', '    Sampler(const cl_sampler & sampler)', '    Sampler(const Context & context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *err)', '    Sampler', '    Sampler(const Sampler & sam)', '    operator const size_t *', '    operator size_t *', '    operator[](int index)', '    operator[](int index)', '    size_t', '    setStatus(cl_int status)', '    UserEvent', '    UserEvent(const Context & context,cl_int *err)', '  Static Member Variables', '    default_', '    default_error_', '    default_initialized_', '    default_', '    default_error_', '    default_initialized_'];
fp32-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 171;  66; 11;10;  51; 33;41;42;8;25;1.29;1;['    Buffer', '    BufferGL', '    BufferRenderGL', '    CommandQueue', '    Context', '    KernelFunctorGlobal', '    NullType', '    Wrapper', '    Wrapper', '    Device', '    Event', '    Image', '    Image1D', '    Image1DArray', '    Image1DBuffer', '    Image2D', '    Image2DArray', '    Image3D', '    ImageGL', '    Kernel', '    Memory', '    NDRange', '    Platform', '    Program', '    Sampler', '    size_t', '    UserEvent'];['    errHandler(cl_int err,const char *errStr)', '    getDevicePlatformVersion(cl_device_id device)', '    getPlatformVersion(cl_platform_id platform)', '    getVersion(const char *versionInfo)', '    WaitForEvents(const std::vector & events)', '    __local(::size_t size)', '    copy(const CommandQueue & queue,const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    copy(const cl::Buffer & buffer,IteratorType startIterator,IteratorType endIterator)', '    copy(const CommandQueue & queue,IteratorType startIterator,IteratorType endIterator,cl::Buffer & buffer)', '    compare_exchange(volatile int *dest,int exchange,int comparand)', '    fence', '    getInfo(Func,const Arg0 & arg0,cl_uint name,T *param)', '    getInfo(Func,const Arg0 & arg0,const Arg1 & arg1,cl_uint name,T *param)', '    getInfo(Func,cl_uint name,T *param)', '    getInfoHelper(Func,cl_uint name,std::vector *param,long)', '    getInfoHelper(Func,cl_uint name,std::vector *param,int,T::cl_type)', '    getInfoHelper(Func,cl_uint name,T *param,int,T::cl_type)', '    getInfoHelper(Func,cl_uint name,STRING_CLASS *param,long)', '    getInfoHelper(Func,cl_uint name,size_t *param,long)', '    getInfoHelper(Func,cl_uint name,std::vector *param,int)', '    getInfoHelper(Functor,cl_uint name,T *param,long)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    linkProgram(Program input1,Program input2,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    linkProgram(std::vector inputPrograms,const char *options,void (*) (cl_program, void *) notifyFptr,void *data,cl_int *err)', '    Local(::size_t size)', '    getDefault(cl_int *err)', '    getDefault(cl_int *err)', '    ptr(T & value)', '    ptr(LocalSpaceArg &)', '    size(const LocalSpaceArg & value)', '    size(const T &)', '    release(cl_context context)', '    release(cl_mem memory)', '    release(cl_command_queue queue)', '    release(cl_sampler sampler)', '    release(cl_kernel kernel)', '    release(cl_program program)', '    release(cl_platform_id)', '    release(cl_event event)', '    release(cl_device_id device)', '    retain(cl_context context)', '    retain(cl_mem memory)', '    retain(cl_command_queue queue)', '    retain(cl_kernel kernel)', '    retain(cl_program program)', '    retain(cl_platform_id)', '    retain(cl_event event)', '    retain(cl_device_id device)', '    retain(cl_sampler sampler)', '    Kernel', '    Kernel', '    isReferenceCountable(cl_device_id device)', '    getDefault(cl_int *err)', '    waitForEvents(const std::vector & events)', '    get(Platform *platform)', '    get(cl_int *errResult)', '    get(std::vector *platforms)', '    getDefault(cl_int *errResult)', '    Buffer(const Buffer & buffer)', '    Buffer', '    Buffer(IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    Buffer(const cl_mem & buffer)', '    Buffer(const Context & context,IteratorType startIterator,IteratorType endIterator,bool readOnly,bool useHostPtr,cl_int *err)', '    Buffer(const Context & context,cl_mem_flags flags,::size_t size,void *host_ptr,cl_int *err)', '    createSubBuffer(cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Buffer & rhs)', '    BufferGL', '    BufferGL(const BufferGL & buffer)', '    BufferGL(const cl_mem & buffer)', '    BufferGL(const Context & context,cl_mem_flags flags,GLuint bufobj,cl_int *err)', '    getObjectInfo(cl_gl_object_type *type,GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferGL & rhs)', '    BufferRenderGL', '    BufferRenderGL(const cl_mem & buffer)', '    BufferRenderGL(const Context & context,cl_mem_flags flags,GLuint bufobj,cl_int *err)', '    BufferRenderGL(const BufferGL & buffer)', '    getObjectInfo(cl_gl_object_type *type,GLuint *gl_object_name)', '    operator=(const cl_mem & rhs)', '    operator=(const BufferRenderGL & rhs)', '    CommandQueue', '    CommandQueue(const CommandQueue & commandQueue)', '    CommandQueue(const Context & context,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(const cl_command_queue & commandQueue)', '    CommandQueue(const Context & context,const Device & device,cl_command_queue_properties properties,cl_int *err)', '    CommandQueue(cl_command_queue_properties properties,cl_int *err)', '    enqueueAcquireGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueBarrierWithWaitList(const std::vector *events,Event *event)', '    enqueueCopyBuffer(const Buffer & src,const Buffer & dst,::size_t src_offset,::size_t dst_offset,::size_t size,const std::vector *events,Event *event)', '    enqueueCopyBufferRect(const Buffer & src,const Buffer & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,::size_t src_row_pitch,::size_t src_slice_pitch,::size_t dst_row_pitch,::size_t dst_slice_pitch,const std::vector *events,Event *event)', '    enqueueCopyBufferToImage(const Buffer & src,const Image & dst,::size_t src_offset,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImage(const Image & src,const Image & dst,const size_t & src_origin,const size_t & dst_origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueCopyImageToBuffer(const Image & src,const Buffer & dst,const size_t & src_origin,const size_t & region,::size_t dst_offset,const std::vector *events,Event *event)', '    enqueueFillBuffer(const Buffer & buffer,PatternType pattern,::size_t offset,::size_t size,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_float4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_int4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueFillImage(const Image & image,cl_uint4 fillColor,const size_t & origin,const size_t & region,const std::vector *events,Event *event)', '    enqueueMapBuffer(const Buffer & buffer,cl_bool blocking,cl_map_flags flags,::size_t offset,::size_t size,const std::vector *events,Event *event,cl_int *err)', '    enqueueMapImage(const Image & buffer,cl_bool blocking,cl_map_flags flags,const size_t & origin,const size_t & region,::size_t *row_pitch,::size_t *slice_pitch,const std::vector *events,Event *event,cl_int *err)', '    enqueueMarkerWithWaitList(const std::vector *events,Event *event)', '    enqueueMigrateMemObjects(const std::vector & memObjects,cl_mem_migration_flags flags,const std::vector *events,Event *event)', '    enqueueNativeKernel(void (*) (void *) userFptr,std::pair args,const std::vector *mem_objects,const std::vector *mem_locs,const std::vector *events,Event *event)', '    enqueueNDRangeKernel(const Kernel & kernel,const NDRange & offset,const NDRange & global,const NDRange & local,const std::vector *events,Event *event)', '    enqueueReadBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,void *ptr,const std::vector *events,Event *event)', '    enqueueReadBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReadImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueReleaseGLObjects(const std::vector *mem_objects,const std::vector *events,Event *event)', '    enqueueTask(const Kernel & kernel,const std::vector *events,Event *event)', '    enqueueUnmapMemObject(const Memory & memory,void *mapped_ptr,const std::vector *events,Event *event)', '    enqueueWriteBuffer(const Buffer & buffer,cl_bool blocking,::size_t offset,::size_t size,const void *ptr,const std::vector *events,Event *event)', '    enqueueWriteBufferRect(const Buffer & buffer,cl_bool blocking,const size_t & buffer_offset,const size_t & host_offset,const size_t & region,::size_t buffer_row_pitch,::size_t buffer_slice_pitch,::size_t host_row_pitch,::size_t host_slice_pitch,void *ptr,const std::vector *events,Event *event)', '    enqueueWriteImage(const Image & image,cl_bool blocking,const size_t & origin,const size_t & region,::size_t row_pitch,::size_t slice_pitch,void *ptr,const std::vector *events,Event *event)', '    finish', '    flush', '    getInfo(cl_command_queue_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const CommandQueue & rhs)', '    operator=(const cl_command_queue & rhs)', '    Context(const Device & device,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const Context & context)', '    Context', '    Context(const cl_context & context)', '    Context(cl_device_type type,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    Context(const std::vector & devices,cl_context_properties *properties,void (*) (const char *, const void *, ::size_t, void *) notifyFptr,void *data,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_context_info name,T *param)', '    getSupportedImageFormats(cl_mem_flags flags,cl_mem_object_type type,std::vector *formats)', '    operator=(const Context & rhs)', '    operator=(const cl_context & rhs)', '    ~Context', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    functionImplementation_(const FunctorType & functor)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30,T31 arg31)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29,T30 arg30)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28,T29 arg29)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27,T28 arg28)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26,T27 arg27)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25,T26 arg26)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24,T25 arg25)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23,T24 arg24)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22,T23 arg23)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21,T22 arg22)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20,T21 arg21)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19,T20 arg20)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18,T19 arg19)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17,T18 arg18)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16,T17 arg17)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15,T16 arg16)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14,T15 arg15)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13,T14 arg14)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12,T13 arg13)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11,T12 arg12)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10,T11 arg11)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9,T10 arg10)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8,T9 arg9)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7,T8 arg8)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6,T7 arg7)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5,T6 arg6)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4,T5 arg5)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3,T4 arg4)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2,T3 arg3)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1,T2 arg2)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0,T1 arg1)', '    operator()(const EnqueueArgs & enqueueArgs,T0 arg0)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    operator()(cl_uint param,::size_t size,void *value,::size_t *size_ret)', '    KernelFunctorGlobal(Kernel kernel)', '    KernelFunctorGlobal(const Program & program,const STRING_CLASS name,cl_int *err)', '    operator()(const EnqueueArgs & args,T0 t0,T1 t1,T2 t2,T3 t3,T4 t4,T5 t5,T6 t6,T7 t7,T8 t8,T9 t9,T10 t10,T11 t11,T12 t12,T13 t13,T14 t14,T15 t15,T16 t16,T17 t17,T18 t18,T19 t19,T20 t20,T21 t21,T22 t22,T23 t23,T24 t24,T25 t25,T26 t26,T27 t27,T28 t28,T29 t29,T30 t30,T31 t31)', '    set', '    operator()', '    operator()', '    operator()', '    operator()', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    operator=(const cl_type & rhs)', '    operator=(const Wrapper & rhs)', '    release', '    release', '    retain', '    retain', '    Wrapper(const Wrapper & rhs)', '    Wrapper(const cl_type & obj)', '    Wrapper(const cl_type & obj)', '    Wrapper', '    Wrapper(const Wrapper & rhs)', '    Wrapper', '    ~Wrapper', '    ~Wrapper', '    createSubDevices(const cl_device_partition_property *properties,std::vector *devices)', '    Device(const cl_device_id & device)', '    Device(const Device & device)', '    Device', '    getInfo(cl_device_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const cl_device_id & rhs)', '    operator=(const Device & rhs)', '    EnqueueArgs(const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(NDRange global)', '    EnqueueArgs(NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(Event e,NDRange global)', '    EnqueueArgs(Event e,NDRange global,NDRange local)', '    EnqueueArgs(NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(const std::vector & events,NDRange global)', '    EnqueueArgs(const std::vector & events,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange global)', '    EnqueueArgs(CommandQueue & queue,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global)', '    EnqueueArgs(CommandQueue & queue,Event e,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,NDRange offset,NDRange global,NDRange local)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global)', '    EnqueueArgs(CommandQueue & queue,const std::vector & events,NDRange global,NDRange local)', '    Event', '    Event(const cl_event & event)', '    Event(const Event & event)', '    getInfo(cl_int *err)', '    getInfo(cl_event_info name,T *param)', '    getProfilingInfo(cl_profiling_info name,T *param)', '    getProfilingInfo(cl_int *err)', '    operator=(const cl_event & rhs)', '    operator=(const Event & rhs)', '    setCallback(cl_int type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    wait', '    ~Event', '    Image1D(const cl_mem & image1D)', '    Image1D', '    Image1D(const Image1D & image1D)', '    Image1D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1D & rhs)', '    Image1DArray(const cl_mem & imageArray)', '    Image1DArray', '    Image1DArray(const Image1DArray & imageArray)', '    Image1DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t rowPitch,void *host_ptr,cl_int *err)', '    operator=(const Image1DArray & rhs)', '    operator=(const cl_mem & rhs)', '    Image1DBuffer(const cl_mem & image1D)', '    Image1DBuffer', '    Image1DBuffer(const Image1DBuffer & image1D)', '    Image1DBuffer(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,const Buffer & buffer,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image1DBuffer & rhs)', '    Image2D(const cl_mem & image2D)', '    Image2D', '    Image2D(const Image2D & image2D)', '    Image2D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t row_pitch,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2D & rhs)', '    Image2DArray(const cl_mem & imageArray)', '    Image2DArray', '    Image2DArray(const Image2DArray & imageArray)', '    Image2DArray(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t arraySize,::size_t width,::size_t height,::size_t rowPitch,::size_t slicePitch,void *host_ptr,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const Image2DArray & rhs)', '    Image3D(const cl_mem & image3D)', '    Image3D', '    Image3D(const Image3D & image3D)', '    Image3D(const Context & context,cl_mem_flags flags,ImageFormat format,::size_t width,::size_t height,::size_t depth,::size_t row_pitch,::size_t slice_pitch,void *host_ptr,cl_int *err)', '    operator=(const Image3D & rhs)', '    operator=(const cl_mem & rhs)', '    getImageInfo(cl_image_info name,T *param)', '    getImageInfo(cl_int *err)', '    Image', '    Image(const cl_mem & image)', '    Image(const Image & image)', '    operator=(const Image & rhs)', '    operator=(const cl_mem & rhs)', '    ImageFormat', '    ImageFormat(cl_channel_order order,cl_channel_type type)', '    operator=(const ImageFormat & rhs)', '    ImageGL', '    ImageGL(const ImageGL & image)', '    ImageGL(const cl_mem & image)', '    ImageGL(const Context & context,cl_mem_flags flags,GLenum target,GLint miplevel,GLuint texobj,cl_int *err)', '    operator=(const cl_mem & rhs)', '    operator=(const ImageGL & rhs)', '    getArgInfo(cl_uint argIndex,cl_kernel_arg_info name,T *param)', '    getArgInfo(cl_uint argIndex,cl_int *err)', '    getInfo(cl_int *err)', '    getInfo(cl_kernel_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_kernel_work_group_info name,T *param)', '    getWorkGroupInfo(const Device & device,cl_int *err)', '    Kernel(const Kernel & kernel)', '    Kernel', '    Kernel(const cl_kernel & kernel)', '    Kernel(const Program & program,const char *name,cl_int *err)', '    operator=(const Kernel & rhs)', '    operator=(const cl_kernel & rhs)', '    setArg(cl_uint index,T value)', '    setArg(cl_uint index,::size_t size,void *argPtr)', '    ~Kernel', '    make_kernel(const Program & program,const STRING_CLASS name,cl_int *err)', '    make_kernel(const Kernel kernel)', '    getInfo(cl_mem_info name,T *param)', '    getInfo(cl_int *err)', '    Memory', '    Memory(const cl_mem & memory)', '    Memory(const Memory & memory)', '    operator=(const cl_mem & rhs)', '    operator=(const Memory & rhs)', '    setDestructorCallback(void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    ~Memory', '    dimensions', '    NDRange', '    NDRange(::size_t size0)', '    NDRange(::size_t size0,::size_t size1)', '    NDRange(::size_t size0,::size_t size1,::size_t size2)', '    operator const size_t *', '    getDevices(cl_device_type type,std::vector *devices)', '    getInfo(cl_int *err)', '    getInfo(cl_platform_info name,STRING_CLASS *param)', '    operator=(const cl_platform_id & rhs)', '    operator=(const Platform & rhs)', '    Platform(const cl_platform_id & platform)', '    Platform(const Platform & platform)', '    Platform', '    unloadCompiler', '    build(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    build(const std::vector & devices,const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    compile(const char *options,void (*) (cl_program, void *) notifyFptr,void *data)', '    createKernels(std::vector *kernels)', '    getBuildInfo(const Device & device,cl_int *err)', '    getBuildInfo(const Device & device,cl_program_build_info name,T *param)', '    getInfo(cl_program_info name,T *param)', '    getInfo(cl_int *err)', '    getInfo(cl_int *err)', '    operator=(const Program & rhs)', '    operator=(const cl_program & rhs)', '    Program(const Program & program)', '    Program(const cl_program & program)', '    Program(const Context & context,const STRING_CLASS & source,bool build,cl_int *err)', '    Program(const Context & context,const std::vector & devices,const STRING_CLASS & kernelNames,cl_int *err)', '    Program(const Context & context,const Sources & sources,cl_int *err)', '    Program', '    Program(const Context & context,const std::vector & devices,const Binaries & binaries,std::vector *binaryStatus,cl_int *err)', '    Program(const STRING_CLASS & source,bool build,cl_int *err)', '    getInfo(cl_sampler_info name,T *param)', '    getInfo(cl_int *err)', '    operator=(const Sampler & rhs)', '    operator=(const cl_sampler & rhs)', '    Sampler(const cl_sampler & sampler)', '    Sampler', '    Sampler(const Context & context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *err)', '    Sampler(const Sampler & sampler)', '    ~Sampler', '    operator const size_t *', '    operator size_t *', '    operator[](int index)', '    operator[](int index)', '    size_t', '    operator=(const UserEvent & rhs)', '    setStatus(cl_int status)', '    UserEvent', '    UserEvent(const Context & context,cl_int *err)', '    UserEvent(const UserEvent & event)', '    checked_array_iterator'];
fp32-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 107;  41; 11;4;  51; 0;41;42;8;25;0.80;1;[];['    clCreateSubDevicesEXT(cl_device_id,const cl_device_partition_property_ext *,cl_uint,cl_device_id *,cl_uint *)', '    clIcdGetPlatformIDsKHR(cl_uint,cl_platform_id *,cl_uint *)', '    clLogMessagesToStderrAPPLE(const char *,const void *,size_t,void *)', '    clLogMessagesToStdoutAPPLE(const char *,const void *,size_t,void *)', '    clLogMessagesToSystemLogAPPLE(const char *,const void *,size_t,void *)', '    clReleaseDeviceEXT(cl_device_id)', '    clRetainDeviceEXT(cl_device_id)', '    clSetMemObjectDestructorAPPLE(cl_mem,void (*) (cl_mem, void *),void *)', '    clTerminateContextKHR(cl_context)'];
fp32-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 109;  55; 10;4;  40; 0;30;31;8;21;1.38;1;[];['    clCreateFromGLBuffer(cl_context context,cl_mem_flags flags,cl_GLuint bufobj,int *errcode_ret)', '    clCreateFromGLRenderbuffer(cl_context context,cl_mem_flags flags,cl_GLuint renderbuffer,cl_int *errcode_ret)', '    clCreateFromGLTexture(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture2D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture3D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clEnqueueAcquireGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReleaseGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clGetGLContextInfoKHR(const cl_context_properties *properties,cl_gl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetGLObjectInfo(cl_mem memobj,cl_gl_object_type *gl_object_type,cl_GLuint *gl_object_name)', '    clGetGLTextureInfo(cl_mem memobj,cl_gl_texture_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)'];
gemmlowp-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 113;  27; 16;8;  57; 6;47;48;8;34;0.47;1;[];['    clCreateEventFromGLsyncKHR(cl_context,cl_GLsync,cl_int *)'];
gemmlowp-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 81;  11; 12;6;  53; 0;43;41;11;28;0.21;1;[];[];
gemmlowp-sse.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 123;  39; 14;15;  53; 7;46;33;13;24;0.74;3;['    ClampMicrokernelTester'];['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_u8clamp_ukernel_function u8clamp)'];
gemmlowp-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 73;  9; 12;6;  47; 0;37;38;8;26;0.19;1;['    ClampOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testU8'];
gemmlowp-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 73;  9; 12;6;  47; 0;37;38;8;25;0.19;1;[];['    pytorch_qnnp_create_clamp_nc_u8(size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *clamp_out)', '    pytorch_qnnp_setup_clamp_nc_u8(pytorch_qnnp_operator_t clamp,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
precise-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 200;  40; 15;17;  84; 44;74;73;10;49;0.48;1;[];['    TEST(CLAMP_OP,zero_batch)', '    TEST(CLAMP_OP,unit_batch)', '    TEST(CLAMP_OP,unit_batch_with_qmin)', '    TEST(CLAMP_OP,unit_batch_with_qmax)', '    TEST(CLAMP_OP,small_batch)', '    TEST(CLAMP_OP,small_batch_with_input_stride)', '    TEST(CLAMP_OP,small_batch_with_output_stride)', '    TEST(CLAMP_OP,small_batch_with_input_and_output_stride)', '    TEST(CLAMP_OP,qmin_and_qmax_equal_uint8_max)'];
precise-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 165;  7; 21;5;  132; 0;122;121;10;72;0.05;1;[];['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextReq(int64_t context_id)', '    getContextId', '    toMessageImpl'];
precise-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 365;  126; 33;5;  201; 0;171;159;39;112;0.63;3;['    CleanupAutogradContextReq'];['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextReq(int64_t context_id)', '    getContextId', '    toMessageImpl'];
precise-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 134;  24; 16;5;  89; 0;79;78;10;52;0.27;1;[];['    fromMessage(const rpc::Message & message)', '    toMessageImpl'];
precise-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 150;  23; 17;5;  105; 0;95;94;10;55;0.22;1;['    CleanupAutogradContextResp'];['    fromMessage(const rpc::Message & message)', '    CleanupAutogradContextResp', '    toMessageImpl'];
q31-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 144;  55; 15;8;  60; 6;50;47;12;30;0.92;1;[];['    clearUndefinedness(Value *o)', '    clearUndefinedness(Block *block)', '    ClearUndefinedness(const std::shared_ptr & graph)'];
q31-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 241;  32; 27;5;  177; 0;167;164;12;89;0.18;1;[];['    ClearUndefinedness(const std::shared_ptr & graph)'];
q31-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 162;  30; 18;5;  109; 0;99;96;12;53;0.28;1;[];[];
q31-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 238;  33; 27;5;  173; 0;163;160;12;89;0.19;1;['    GetClipGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUClip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Clip', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ClipGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
runtime-neon.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 22;  8; 3;5;  4; 2;1;2;1;0;2.00;1;['    final', '    final'];['    ClipGradientOp(Args,...)', '    ClipOp(Args,...)', '    RunOnDevice'];
runtime-sse2.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 22;  8; 3;5;  4; 2;1;2;1;0;2.00;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUClipTensorByScaling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ClipTensorByScaling'];
6x8-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/sconv; 203;  7; 11;2;  183; 0;162;46;124;36;0.04;1;['    final'];['    ClipTensorByScalingOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice'];
5x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm; 268;  7; 14;11;  206; 30;176;49;138;39;0.03;1;[];['    clog_vlog_debug(const char *module,const char *format,va_list args)', '    clog_vlog_error(const char *module,const char *format,va_list args)', '    clog_vlog_fatal(const char *module,const char *format,va_list args)', '    clog_vlog_info(const char *module,const char *format,va_list args)', '    clog_vlog_warning(const char *module,const char *format,va_list args)'];
6x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm; 307;  7; 14;11;  239; 36;207;55;163;45;0.03;1;[];['    named_log_debug(const char *format,...)', '    named_log_error(const char *format,...)', '    named_log_fatal(const char *format,...)', '    named_log_info(const char *format,...)', '    named_log_warning(const char *format,...)', '    nameless_log_debug(const char *format,...)', '    nameless_log_error(const char *format,...)', '    nameless_log_fatal(const char *format,...)', '    nameless_log_info(const char *format,...)', '    nameless_log_warning(const char *format,...)', '    suppressed_log_debug(const char *format,...)', '    suppressed_log_error(const char *format,...)', '    suppressed_log_fatal(const char *format,...)', '    suppressed_log_info(const char *format,...)', '    suppressed_log_warning(const char *format,...)', '    TEST(CLOG,debug)', '    TEST(CLOG,info)', '    TEST(CLOG,warning)', '    TEST(CLOG,error)'];
6x8-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm; 215;  7; 11;2;  195; 0;169;45;133;35;0.04;1;[];['    clog_vlog_debug(const char *module,const char *format,va_list args)', '    clog_vlog_error(const char *module,const char *format,va_list args)', '    clog_vlog_fatal(const char *module,const char *format,va_list args)', '    clog_vlog_info(const char *module,const char *format,va_list args)', '    clog_vlog_warning(const char *module,const char *format,va_list args)'];
softargmax.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 139;  7; 23;8;  101; 0;73;24;51;8;0.07;2;[];[];
tanh.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 161;  11; 24;8;  119; 0;85;28;58;10;0.09;2;[];[];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8clamp; 86;  7; 10;3;  66; 0;55;23;36;15;0.11;1;[];['    format(const std::string & fmt,TemplateEnv & env)', '    keyIsString(const std::string & k)', '    s(const std::string & k)', '    v(const std::string & k)', '    charAt(size_t p)', '    CodeTemplate(std::string t)', '    emitCommaSeparatedList(std::ostream & out,const string_list & strings,bool comma_before,bool comma_after)', '    emitIndent(std::ostream & out,size_t indent)', '    emitLinesIndented(std::stringstream & out,size_t indent,const string_list & strings)', '    emitStringWithIndents(std::ostream & out,size_t indent,const std::string & str)', '    format(const TemplateEnv & env)', '    parseIdent(size_t pos,std::ostream & k)', '    parseKey(size_t pos,std::ostream & k,bool & comma_before,bool & comma_after)', '    TemplateEnv', '    TemplateEnv(TemplateEnv & parent)'];
scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8lut32norm; 49;  7; 8;3;  31; 0;20;19;8;11;0.23;2;[];['    calcScalarTypeName(const at::ScalarType type)', '    emitIndexingFor(std::ostream & out,const std::string & tensor,const int ndim,const bool last_is_cont)', '    encodeRHS(const Node *n)', '    encodeSpecialRHS(const Node *n,TemplateEnv & env)', '    scalarTypeName(const at::ScalarType type)', '    scalarValue(const int64_t v)', '    scalarValue(const bool v)', '    scalarValue(const double v)', '    typeCastedValueName(const std::shared_ptr & t,const at::ScalarType outtype,const std::string & vn)', '    valueName(const Value *n)', '    variableType(const std::shared_ptr & t)', '    generateKernel(const std::string & name,const Graph & graph,const std::vector,const c10::optional & inputs,const std::vector,const TensorDesc,const bool use_cuda)', '    RHSTemplate(const char *for_float)', '    RHSTemplate(const char *for_float,const char *for_double)'];
16x9p8q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool; 251;  7; 24;3;  217; 0;185;106;89;94;0.03;1;[];['    CreateCodeGen(const std::string & name,Stmt *stmt,const std::vector & params,at::Device device)', '    AddStmtFactoryMethod(const std::string & name,const StmtFactoryMethod & stmt_factory_method)', '    FindStmtFactoryMethod(const std::string & name)'];
16x9p8q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool; 254;  7; 25;3;  219; 0;187;108;89;94;0.03;1;['    RegisterCodeGen', '    RegisterCodeGenList', '    CodeGen', '    BufferArg', '    CallArg'];['    CreateCodeGen(const std::string & name,Stmt *stmt,const std::vector & params,at::Device device)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    BytePtr', '    CharPtr', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    DoublePtr', '    FloatPtr', '    IntPtr', '    LongPtr', '    ShortPtr', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    GetInstance', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    RegisterCodeGen(const std::string & name)', '    AddStmtFactoryMethod(const std::string & name,const StmtFactoryMethod & stmt_factory_method)', '    FindStmtFactoryMethod(const std::string & name)', '    operator=', '    RegisterCodeGenList', '    RegisterCodeGenList', '    data', '    buffer_args', '    buffer_args', '    BufferArg(const Buffer & buffer)', '    BufferArg(Tensor *tensor)', '    BufferArg(const Function & func)', '    BufferArg(const VarHandle & var)', '    dtype', '    isVar', '    isVar_', '    var', '    call(const std::vector & args)', '    ByteData', '    CallArg(const PaddedBuffer & buffer)', '    CallArg(const std::vector & buffer)', '    CallArg(void *ptr)', '    CallArg(uint8_t v)', '    CallArg(int8_t v)', '    CallArg(int16_t v)', '    CallArg(int v)', '    CallArg(int64_t v)', '    CallArg(float v)', '    CallArg(double v)', '    CallArg((*) () decltype)', '    CallArg((*) () decltype)', '    CharData', '    data', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    DoubleData', '    FloatData', '    IntData', '    LongData', '    ShortData', '    CodeGen(Stmt *stmt,Ts,...)', '    CodeGen(Stmt *stmt,const std::vector & buffer_args,at::Device device)', '    device', '    stmt', '    ~CodeGen'];
sub16-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool; 86;  7; 8;3;  68; 0;50;18;38;8;0.10;1;[];['    generateKernel(const std::string & name,const Graph & graph,const std::vector,const c10::optional & inputs,const std::vector,const TensorDesc,const bool use_cuda)'];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8rmax; 48;  7; 5;3;  33; 0;28;11;14;11;0.21;1;[];['    col2im_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_cpu(const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_cpu(const Tensor & input,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    col2im_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)'];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8rmax; 47;  7; 5;3;  32; 0;27;7;17;7;0.22;1;[];[];
x2-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 46;  7; 4;2;  33; 0;26;9;17;9;0.21;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCollectAndDistributeFpnRpnProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUCollectRpnProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUDistributeFpnProposals', '    schema_OperatorName', '    schema_OperatorName', '    schema_OperatorName', '    ArgSort(EArrXi & arr)', '    BoxesArea(const ERArrXXf & boxes,const bool legacy_plus_one)', '    MapRoIsToFpnLevels(Eigen::Ref rois,const float k_min,const float k_max,const float s0,const float lvl0,const bool legacy_plus_one)', '    RowsWhereRoILevelEquals(Eigen::Ref rois,const ERArrXXf & lvls,const int lvl,ERArrXXf *out_filtered,EArrXi *out_indices)', '    SortAndLimitRoIsByScores(Eigen::Ref scores,int n,ERArrXXf & rois)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectAndDistributeFpnRpnProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectRpnProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DistributeFpnProposals', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
x2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 52;  7; 4;2;  39; 0;35;17;16;15;0.18;1;['    final', '    final', '    final'];['    schema_CollectAndDistributeFpnRpnProposals', '    schema_CollectRpnProposals', '    schema_DistributeFpnProposals', '    BoxesArea(const ERArrXXf & boxes,const bool legacy_plus_one)', '    MapRoIsToFpnLevels(Eigen::Ref rois,const float k_min,const float k_max,const float s0,const float lvl0,const bool legacy_plus_one)', '    RowsWhereRoILevelEquals(Eigen::Ref rois,const ERArrXXf & lvls,const int lvl,ERArrXXf *out_filtered,EArrXi *out_indices)', '    SortAndLimitRoIsByScores(Eigen::Ref scores,int n,ERArrXXf & rois)', '    CollectAndDistributeFpnRpnProposalsOp(Args,...)', '    CollectRpnProposalsOp(Args,...)', '    DistributeFpnProposalsOp(Args,...)', '    legacy_plus_one_', '    legacy_plus_one_', '    roi_canonical_level_', '    roi_canonical_level_', '    roi_canonical_scale_', '    roi_canonical_scale_', '    roi_max_level_', '    roi_max_level_', '    roi_min_level_', '    roi_min_level_', '    rpn_max_level_', '    rpn_max_level_', '    rpn_min_level_', '    rpn_min_level_', '    rpn_post_nms_topN_', '    rpn_post_nms_topN_', '    RunOnDevice', '    ~CollectAndDistributeFpnRpnProposalsOp', '    ~CollectRpnProposalsOp', '    ~DistributeFpnProposalsOp'];
x3-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 51;  7; 4;2;  38; 0;32;11;21;11;0.18;1;[];['    apply(variable_list)', '    Gather(const at::Device & destination_device,int64_t dim)', '    ~Gather', '    apply(variable_list)', '    Scatter(std::vector devices,const c10::optional,int64_t dim,const c10::optional,bool unsqueeze_scalars)', '    ~Scatter'];
x4-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 57;  7; 4;2;  44; 0;38;13;25;13;0.16;1;[];['    broadcast(const Tensor & tensor,IntArrayRef devices)', '    broadcast_coalesced(TensorList tensors,IntArrayRef devices,size_t buffer_size)', '    gather(at::TensorList tensors,int64_t dim,c10::optional destination_index)', '    scatter(const at::Tensor & tensor,at::IntArrayRef devices,const c10::optional,int64_t dim,const c10::optional)', '    show(const at::DeprecatedTypeProperties & t)'];
x4-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 82;  7; 4;2;  69; 0;65;39;24;35;0.10;1;['    BroadcastWork'];['    broadcast_coalesced(std::shared_ptr process_group,at::TensorList tensors,size_t buffer_size)', '    BroadcastWork(const std::shared_ptr & process_group,std::vector bucket_tensors)', '    finish'];
xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 177;  7; 24;2;  144; 0;129;48;61;38;0.05;1;[];['    apply(variable_list)', '    Gather(const at::Device & destination_device,int64_t dim)', '    ~Gather', '    apply(variable_list)', '    Scatter(std::vector devices,const c10::optional,int64_t dim,const c10::optional,bool unsqueeze_scalars)', '    ~Scatter'];
add-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 281;  11; 42;9;  220; 0;149;52;95;52;0.05;43;[];['    broadcast_coalesced(std::shared_ptr process_group,at::TensorList tensors,size_t buffer_size)'];
add.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 397;  7; 33;2;  355; 0;245;79;127;79;0.02;31;[];['    broadcast(const at::Tensor & tensor,at::IntArrayRef devices)', '    broadcast_coalesced(at::TensorList tensors,at::IntArrayRef devices,size_t buffer_size)', '    gather(at::TensorList tensors,int64_t dim,c10::optional destination_index)', '    scatter(const at::Tensor & tensor,at::IntArrayRef devices,const c10::optional,int64_t dim,const c10::optional)'];
average-pooling-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 874;  24; 89;10;  757; 0;567;162;275;142;0.03;88;[];['    createDevice(const createDeviceAttr attr)', '    signalFailure(Blob *status_blob,std::exception &)'];
avgpool-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 429;  15; 57;12;  345; 0;244;107;153;81;0.04;56;[];['    g_caffe2_has_cuda_linked', '    g_caffe2_has_hip_linked', '    GetBuildOptions', '    HasCudaRuntime', '    HasHipRuntime', '    SetCudaRuntimeFlag', '    SetHipRuntimeFlag'];
channel-shuffle-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 157;  10; 25;9;  114; 0;76;28;50;28;0.09;20;['    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp', '    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp_denorms'];['    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp(const std::string & content)', '    C10FlagParser_caffe2_fbgemm_fake_fp16_clamp_denorms(const std::string & content)'];
channel-shuffle.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 268;  7; 23;2;  236; 0;167;48;71;46;0.03;21;[];[];
clamp-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 177;  11; 27;9;  131; 0;90;33;57;33;0.08;22;['    SkipIndices', '    SkipIndices'];['    dynamic_cast_if_rtti(Src ptr)', '    GetBuildOptions', '    HasCudaRuntime', '    HasHipRuntime', '    SetCudaRuntimeFlag', '    SetHipRuntimeFlag', '    Contains(const int)', '    Contains(const int i)', '    ContainsInternal(const int i)', '    ContainsInternal(const int i)', '    unique_ptr'];
clamp.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 107;  7; 11;2;  87; 0;59;19;29;19;0.08;9;[];['    createDevice(const createDeviceAttr attr)', '    signalFailure(Blob *status_blob,std::exception &)', '    getInputs', '    getOutput', '    getOutputs', '    IsType', '    operator==(GlooParameters const & other)'];
convolution-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 647;  15; 77;12;  547; 0;368;190;205;121;0.03;79;['    Notifier', '    StorageType', '    StorageType'];['    deleteCallback(std::list & callbackList,Callback *toDelete)', '    deleteDestructorCallback(Callback *c)', '    deleteNotificationCallback(Callback *c)', '    Notifier', '    notify', '    registerDestructorCallback(Callback fn)', '    registerNotificationCallback(Callback fn)', '    ~Notifier', '    data', '    mutableData', '    resetData(T)', '    StorageType(T)', '    StorageType', '    StorageType'];
deconvolution-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 635;  14; 79;10;  536; 0;365;164;204;124;0.03;87;[];[];
deconvolution.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 275;  7; 25;2;  241; 0;195;23;23;23;0.03;23;[];[];
dwconv-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 499;  7; 58;15;  419; 0;335;146;142;92;0.02;43;[];[];
fully-connected.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 360;  44; 38;2;  276; 0;212;32;32;32;0.16;32;[];['    GET_BLOCKS(const int N)'];
gavgpool-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 301;  15; 40;12;  234; 0;169;81;102;55;0.06;36;[];[];
gemm-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1107;  19; 137;22;  933; 0;744;265;431;198;0.02;59;[];[];
global-average-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 651;  7; 37;3;  604; 0;420;150;224;112;0.01;34;[];[];
hgemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 183;  7; 4;7;  0; 165;0;0;0;0;0.00;0;[];['    PrintCuDNNInfo(int *,char ***)', '    cudnn_states'];
leaky-relu-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 240;  11; 37;10;  183; 0;122;50;78;48;0.06;37;['    cudnnFilterDescWrapper', '    cudnnTensorDescWrapper', '    cudnnTypeWrapper', '    cudnnTypeWrapper', '    cudnnTypeWrapper'];['    CheckCuDNNVersions', '    cudnnCompiledVersion', '    cudnnRuntimeVersion', '    GetCudnnTensorFormat(const StorageOrder & order)', '    cudnnGetErrorString(cudnnStatus_t status)', '    static_assert(CUDNN_VERSION,)', '    kOne', '    kOne', '    kOne', '    kZero', '    kZero', '    kZero', '    cudnnFilterDescWrapper', '    cudnnFilterDescWrapper', '    Descriptor(const StorageOrder & order,const cudnnDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    operator=', '    ~cudnnFilterDescWrapper', '    cudnnTensorDescWrapper', '    cudnnTensorDescWrapper', '    Descriptor(const cudnnTensorFormat_t format,const cudnnDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    operator=', '    ~cudnnTensorDescWrapper'];
lut-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 90;  10; 15;9;  56; 0;34;17;29;17;0.18;10;['    CudaRuntimeFlagFlipper'];['    CaffeCudaGetDevice', '    CaffeCudaSetDevice(const int id)', '    cublasGetErrorString(cublasStatus_t error)', '    curandGetErrorString(curandStatus_t error)', '    DeviceQuery(const int device)', '    GetCudaPeerAccessPattern(vector *pattern)', '    GetDefaultGPUID', '    GetDeviceProperty(const int deviceid)', '    GetGPUIDForPointer(const void *ptr)', '    NumCudaDevices', '    SetDefaultGPUID(const int deviceid)', '    TensorCoreAvailable', '    CudaDevicePropWrapper', '    CudaRuntimeFlagFlipper'];
lut-norm-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 99;  10; 15;9;  65; 0;42;23;33;20;0.15;10;[];[];
max-pooling-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 800;  24; 89;9;  684; 0;496;160;278;138;0.04;86;['    miopenTensorDescWrapper', '    miopenTypeWrapper', '    miopenTypeWrapper'];['    CheckMIOPENVersions', '    miopenGetErrorString(miopenStatus_t status)', '    miopenCompiledVersion', '    miopenRuntimeVersion', '    kOne', '    kOne', '    kZero', '    kZero', '    Descriptor(const miopenDataType_t type,const vector & dims,bool *changed)', '    Descriptor(const StorageOrder & order,const vector & dims)', '    miopenTensorDescWrapper', '    miopenTensorDescWrapper', '    operator=', '    ~miopenTensorDescWrapper'];
maxpool-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 256;  11; 41;10;  194; 0;120;56;92;55;0.06;43;[];[];
q8avgpool.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1965;  9; 5;9;  0; 1944;0;0;0;0;0.00;0;['    CudaRTCFunction'];['    GetUniqueName', '    Compile(Args,...)', '    CudaRTCFunction', '    Launch(unsigned int gx,unsigned int gy,unsigned int gz,unsigned int bx,unsigned int by,unsigned int bz,unsigned int shared_mem,cudaStream_t stream,Args,...)', '    LaunchEx(unsigned int gx,unsigned int gy,unsigned int gz,unsigned int bx,unsigned int by,unsigned int bz,unsigned int shared_mem,cudaStream_t stream,void **extra)', '    ~CudaRTCFunction'];
q8conv.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1084;  7; 7;13;  0; 1057;0;0;0;0;0.00;0;[];['    are_nodes_common(const Graph & g,int model_idx,int candidate_idx)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)'];
q8gavgpool.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1155;  9; 5;9;  0; 1134;0;0;0;0;0.00;0;[];['    EliminateCommonSubexpression(const std::shared_ptr & graph)', '    EliminateCommonSubexpression(Block *block,const AliasDb & aliasDb,std::function parent_lookup_fn)'];
q8gemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 3820;  7; 7;15;  0; 3793;0;0;0;0;0.00;0;[];['    EliminateCommonSubexpression(const std::shared_ptr & graph)'];
q8vadd.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 297;  9; 5;9;  0; 276;0;0;0;0;0.00;0;['    CommonSubexpressionEliminationTransform'];['    CommonSubexpressionEliminationTransform', '    IsWhitelisted(string op_type)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)'];
requantization.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1077;  38; 54;11;  282; 694;161;82;125;82;0.13;39;[];['    TEST(CommonSubexpressionEliminationTest,TestSimple)', '    TEST(CommonSubexpressionEliminationTest,TestFromExternal)'];
rmax-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 68;  10; 13;9;  36; 0;20;14;16;14;0.28;7;[];['    TEST(CommonTest,TestStoi)', '    TEST(CommonTest,TestStod)'];
sconv.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 103;  7; 10;5;  81; 0;62;12;17;12;0.09;7;[];['    initializeForContext'];
sigmoid-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 214;  11; 33;10;  161; 0;108;45;67;43;0.07;30;['    final', '    final', '    final'];['    initializeForContext', '    CloneCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    DestroyCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    handleException(std::exception & ex)', '    RunOnDevice', '    RunOnDevice', '    ~CloneCommonWorld', '    CreateCommonWorld(const OperatorDef & operator_def,Workspace *ws)', '    handleException(std::exception & ex)', '    initialize', '    initializeForContext', '    rendezvousWithMPI', '    rendezvousWithStore(const std::unique_ptr & handler)', '    RunOnDevice', '    ~CreateCommonWorld', '    what', '    milliseconds'];
sigmoid.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 229;  7; 21;3;  198; 0;139;41;64;41;0.04;18;[];[];
softargmax-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 198;  11; 29;10;  149; 0;103;38;63;36;0.07;24;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CPUAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUBarrier', '    CAFFE_ANONYMOUS_VARIABLE_CPUBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CPUCloneCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUDestroyCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceScatter', '    CAFFE_ANONYMOUS_VARIABLE_CPUSendTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Allgather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Allreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Barrier', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Broadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloneCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DestroyCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReceiveTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceScatter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SendTensor'];
tanh-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 214;  11; 33;10;  161; 0;108;45;67;43;0.07;30;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CUDAAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDABroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDACloneCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDAReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CUDAReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDASendTensor'];
tanh.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 229;  7; 21;3;  198; 0;139;41;64;41;0.04;18;[];[];
u8clamp.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 127;  9; 5;9;  0; 106;0;0;0;0;0.00;0;[];['    fusion_backends_lock_', '    debug_fusion', '    getFusionBackends', '    getInputDependencies(const Value *output)', '    next_kernel_id', '    setInputBroadcastGroups(KernelSpec & spec)', '    setInputChunkDescriptors(KernelSpec & spec)', '    upfrontCompilation(KernelSpec & spec)', '    usedInFusedChunk(const Value *input)', '    fusionBackendLock', '    queue', '    compileKernel(const KernelSpec & spec,const ArgSpec & arg_spec,const std::vector & map_size,const at::Device device)', '    debugFuser', '    getConstructor(at::Device::Type backend_type)', '    hasFusionBackend(at::Device::Type backend_type)', '    nCompiledKernels', '    registerFusion(const Node *fusion_group)', '    registerFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)'];
u8maxpool.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1539;  8; 5;9;  0; 1518;0;0;0;0;0.00;0;[];['    compileKernel(const KernelSpec & spec,const ArgSpec & arg_spec,const std::vector & map_size,const at::Device device)', '    debugFuser', '    hasFusionBackend(at::Device::Type backend_type)', '    nCompiledKernels', '    registerFusion(const Node *fusion_group)', '    registerFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)', '    RegisterFusionBackend(at::Device::Type backend_type,FusedKernelConstructor ctor)'];
u8rmax.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 71;  9; 5;9;  0; 50;0;0;0;0;0.00;0;['    Branch', '    Data', '    Instruction', '    Opcode', '    Phi', '    Return', '    Terminator', '    Value', '    ValueKind'];['    classof(const Value *V)', '    classof(const Value *V)', '    classof(const Value *V)', '    isTerminator(const Opcode & op)', '    Branch', '    Data', '    getVersion', '    setVersion(size_t version)', '    ~Data', '    getOpcode', '    Instruction', '    Instruction(Opcode op)', '    ~Instruction', '    Phi', '    Return', '    Terminator(Instruction::Opcode op)', '    getKind', '    Value(ValueKind K)', '    Value', '    ~Value'];
vadd-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 224;  11; 34;10;  169; 0;110;64;69;47;0.07;37;['    numeric_limits'];['    operator*(const std::complex & a,const iT & b)', '    operator*(const iT & a,const std::complex & b)', '    operator+(const std::complex & a,const iT & b)', '    operator+(const iT & a,const std::complex & b)', '    operator-(const std::complex & a,const iT & b)', '    operator-(const iT & a,const std::complex & b)', '    operator/(const std::complex & a,const iT & b)', '    operator/(const iT & a,const std::complex & b)'];
x8zip.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 350;  7; 5;9;  0; 329;0;0;0;0;0.00;0;[];['    TestBinaryOpsForAllIntTypes(T real,T img,int8_t i)', '    TestBinaryOpsForIntType(T real,T img,int_t num)', '    TEST(ComplexTest,Integer)'];
zip-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 108;  11; 21;10;  66; 0;40;22;37;22;0.17;11;[];['    computeStrideForComplex(IntArrayRef oldstride)', '    view_complex_as_float(const Tensor & self)'];
dummy.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers; 1;  0; 1;0;  0; 0;0;0;0;0;0.00;0;[];['    concat_op_cpu_impl(c10::List inputs,const at::Tensor & output_,const at::Tensor & split_,int64_t axis,int64_t add_axis)'];
mp8x9p8q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConcatDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_'];
up8x9-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    final'];['    ConcatDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice'];
up8x9-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    ConcatAddMulNaNClipElim', '    ConcatElim', '    GatherFuse8BitRowwiseQuantFloatMulLengthsSumElim'];['    concatAddMulNaNClipElim(NNModule *nn)', '    concatElim(NNModule *nn)', '    gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim(NNModule *nn)', '    run', '    run', '    run'];
up8xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    concatAddMulNaNClipElim(NNModule *nn)', '    concatElim(NNModule *nn)', '    gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim(NNModule *nn)'];
4x4c2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    lut_dims', '    TEST(gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim,Basic)', '    TEST(gatherFuse8BitRowwiseQuantFloatMulLengthsSumElim,NoFuse)', '    TEST(ConcatElim,BasicNet)', '    TEST(ConcatElim,ProdNet)', '    TEST(ConcatAddMulNaNClipElim,BasicNet)', '    TEST(ConcatAddMulNaNClipElim,ProdNet)'];
4x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    GetConcatGradient', '    GetSplitGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUConcat', '    CAFFE_ANONYMOUS_VARIABLE_CPUDepthConcat', '    CAFFE_ANONYMOUS_VARIABLE_CPUDepthSplit', '    CAFFE_ANONYMOUS_VARIABLE_CPUSplit', '    CAFFE_ANONYMOUS_VARIABLE_CPUSplitByLengths', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Concat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DepthConcat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DepthSplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Split', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SplitByLengths', '    CostInferenceForConcat(const OperatorDef & def,const vector & in)', '    ret_invalid_shape', '    TensorInferenceForConcat(const OperatorDef & def,const vector & in)', '    TensorInferenceForSplit(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    GetGradientDefs'];
mp8x25-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
mp8x25-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
up8x9-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAConcat', '    CAFFE_ANONYMOUS_VARIABLE_CUDADepthConcat', '    CAFFE_ANONYMOUS_VARIABLE_CUDADepthSplit', '    CAFFE_ANONYMOUS_VARIABLE_CUDASplit', '    CAFFE_ANONYMOUS_VARIABLE_CUDASplitByLengths'];
mp8x7p7q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    operator==(const ConcreteModuleTypeBuilder::ModuleInfo & lhs,const ConcreteModuleTypeBuilder::ModuleInfo & rhs)', '    fromJitType(TypePtr type)', '    dump', '    findBuiltinFunction(const std::string & name)', '    findFailedAttribute(const std::string & name)', '    findFunctionAttribute(const std::string & name)', '    findSubmoduleConcreteType(const std::string & name)', '    getConstantsPy', '    getIterableModuleKind', '    addAttribute(std::string name,TypePtr type,bool isParameter)', '    addBuiltinFunction(std::string name,std::string symbol_name)', '    addConstant(std::string name,py::object value)', '    addFailedAttribute(std::string name,std::string failureReason)', '    addFunctionAttribute(std::string name,const TypePtr & type,py::object pyFunction)', '    addModule(std::string name,std::shared_ptr meta)', '    addOverload(std::string methodName,std::vector overloadedMethodNames)', '    setIterableModuleKind(IterableModuleKind kind)', '    setPoisoned', '    ConcreteModuleType(ConcreteModuleTypeBuilder data)', '    getJitType', '    getPyClass', '    createTypeFromThis', '    equals(const ConcreteModuleTypeBuilder & other)'];
mp8x7p7q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    ConcreteModuleType', '    ConcreteModuleTypeBuilder', '    IterableModuleKind'];['    operator==(const Constant & lhs,const Constant & rhs)', '    operator==(const FunctionAttribute & lhs,const FunctionAttribute & rhs)', '    operator==(const Attribute & lhs,const Attribute & rhs)', '    fromJitType(TypePtr type)', '    ConcreteModuleType(ConcreteModuleTypeBuilder data)', '    ConcreteModuleType', '    dump', '    equals(const ConcreteModuleType & other)', '    equals(const ConcreteModuleTypeBuilder & other)', '    findBuiltinFunction(const std::string & name)', '    findFailedAttribute(const std::string & name)', '    findFunctionAttribute(const std::string & name)', '    findSubmoduleConcreteType(const std::string & name)', '    getConstantsPy', '    getIterableModuleKind', '    getJitType', '    getPyClass', '    addAttribute(std::string name,TypePtr type,bool isParameter)', '    addBuiltinFunction(std::string name,std::string symbol_name)', '    addConstant(std::string name,py::object value)', '    addFailedAttribute(std::string name,std::string failureReason)', '    addFunctionAttribute(std::string name,const TypePtr & type,py::object pyFunction)', '    addModule(std::string name,std::shared_ptr meta)', '    addOverload(std::string methodName,std::vector overloadedMethodNames)', '    Attribute(TypePtr type,bool isParam)', '    build', '    ConcreteModuleTypeBuilder(py::object pyClass)', '    ConcreteModuleTypeBuilder', '    Constant(py::object v)', '    createTypeFromThis', '    equals(const ConcreteModuleTypeBuilder & other)', '    ModuleInfo(std::string name,std::shared_ptr meta)', '    setIterableModuleKind(IterableModuleKind kind)', '    setPoisoned'];
up8x7-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConditional', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conditional', '    RunOnDevice'];
up8xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    final'];['    ConditionalOp(Args,...)', '    RunOnDevice'];
up8xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    areNodeInputsConstant(Node *node,const ValueToParamPairMap & valsToParamsMap)', '    buildParamsMapFromValueToParamsMap(const ValueToParamPairMap & valsToParamsMap,ParamMap & paramsDict)', '    ConstantFoldONNX(Block *b,ParamMap & paramsDict,int opset_version)', '    eraseUnusedBlockInputs(Block *b)', '    getOnnxConstParentsToRemove(Node *node)', '    getValues(Node *node,const ValueToParamPairMap & valsToParamsMap)', '    handleNegativeStartEndIndex(int64_t & start,int64_t & end,int64_t & axis,c10::IntArrayRef tensorSizes)', '    isConstant(Value *val,const ValueToParamPairMap & valsToParamsMap)', '    runTorchBackendForOnnx(const Node *node,std::vector & inputTensorValues,int opset_version)', '    runTorchSlice_opset10(const Node *node,std::vector & inputTensorValues)', '    runTorchSlice_opset9(const Node *node,std::vector & inputTensorValues)'];
2x4c8-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConstantFoldONNX(Block *b,std::map & paramDict,int opset_version)'];
4x4c2-dq-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConstantPooling(const std::shared_ptr & graph)', '    ConstantPooling(Block *block,std::unordered_set & constants,const AliasDb & aliasDb)'];
4x4c2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConstantPooling(const std::shared_ptr & graph)'];
4x8-dq-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConstantPropagation(std::shared_ptr & graph)', '    ConstantPropagationImmutableTypes(std::shared_ptr & graph)', '    NoAliasDb(std::shared_ptr graph)', '    WithAliasDb(std::shared_ptr graph)', '    ConstantPropagation(at::ArrayRef blocks)', '    ConstantPropagation(Node *n)', '    ConstantPropagation(Block *block)', '    ConstantPropagator(std::shared_ptr graph,bool aliasing_types)', '    inlineIf(Node *n)', '    inlineIfBody(Block *body)', '    loopWillNotRun(Node *node)', '    noMutableValues(at::ArrayRef values)', '    propagateNode(Node *n)', '    removeExtraIfOutputs(Node *n)', '    removeExtraLoopOutputs(Node *node)', '    removeLoopNode(Node *n)', '    replaceAndRemoveIfOutput(Node *n,size_t i,Value *replacement)', '    run', '    runnableInputs(Node *n)', '    supportedNode(Node *n)'];
4x8c2-xzp-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    ConstantPropagation(std::shared_ptr & graph)', '    ConstantPropagationImmutableTypes(std::shared_ptr & graph)', '    runNodeIfInputsAreConstant(const Node *node)'];
6x4-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    constant_pad_nd(const Tensor & self,IntArrayRef pad,Scalar value)'];
8x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    aliasAnalysisInternalSpecialCase', '    insertableIValue(const IValue & ivalue)', '    insertableTensor(const at::Tensor & ten)', '    insertConstant(Graph & g,const IValue & val,c10::optional loc,c10::optional scope)', '    toIValue(const Value *v)', '    tryInsertConstant(Graph & g,const IValue & val,c10::optional loc,c10::optional scope)'];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8vadd; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
fp32-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
fp32-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    crc64(c10::string_view str)', '    crc64(const char *str,size_t size)', '    crc64impl(uint64_t accumulator,const char *data,size_t size)', '    checksum', '    crc64_t(uint64_t checksum)', '    underlyingId', '    operator()(c10::util::crc64_t x)'];
fp32-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
gemmlowp-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    currentContextId', '    forceCurrentContextId(int64_t contextId)', '    getInstance', '    getInstanceInternal', '    init(int64_t worker_id)', '    setCurrentContextId(int64_t contextId)', '    clearCurrentContext', '    currentContext', '    DistAutogradContainer', '    eraseContextIdAndReset(int64_t context_id)', '    getMaxId', '    getOrCreateContext(int64_t context_id)', '    getWorkerId', '    hasValidContext', '    isValidContext(int64_t context_id)', '    newAutogradMessageId', '    newContext', '    numAutogradContexts', '    releaseContext(int64_t context_id)', '    releaseContextIfPresent(int64_t context_id)', '    retrieveContext(int64_t context_id)', '    sendReleaseContextRpc(int64_t context_id)'];
gemmlowp-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;['    DistAutogradContainer'];['    currentContextId', '    forceCurrentContextId(int64_t contextId)', '    getInstance', '    getInstanceInternal', '    init(int64_t worker_id)', '    setCurrentContextId(int64_t contextId)', '    clearCurrentContext', '    currentContext', '    DistAutogradContainer', '    DistAutogradContainer', '    DistAutogradContainer', '    eraseContextIdAndReset(int64_t context_id)', '    getMaxId', '    getOrCreateContext(int64_t context_id)', '    getWorkerId', '    hasValidContext', '    isValidContext(int64_t context_id)', '    newAutogradMessageId', '    newContext', '    numAutogradContexts', '    operator=', '    operator=', '    releaseContext(int64_t context_id)', '    releaseContextIfPresent(int64_t context_id)', '    retrieveContext(int64_t context_id)', '    sendReleaseContextRpc(int64_t context_id)', '    ~DistAutogradContainer'];
gemmlowp-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    noexcept', '    _typeMetaDataInstance'];
gemmlowp-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    CopyBytesImpl(size_t nbytes,const void *src,void *dst)', '    CopyBytesWrapper(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device)', '    RandomNumberSeed', '    CopyBytesSameDevice(size_t nbytes,const void *src,void *dst)'];
precise-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    EventCreateOPENCL(const DeviceOption &,Event *)', '    EventFinishOPENCL(const Event *)', '    EventRecordOPENCL(Event *,const void *,const char *)', '    EventResetOPENCL(Event *)', '    EventWaitOPENCL(const Event *,void *)', '    noexcept', '    getInstance', '    OpenCLContextSingleton', '    BuildArgumentList(std::vector,std::string)', '    BuildKernel(const char *src,std::string additional_options,const char *fn_name)', '    Delete(void *ptr)', '    GetSingleton', '    New(size_t nbytes)'];
precise-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    supported_qengines', '    getCPUAllocator', '    globalContext', '    benchmarkCuDNN', '    Context', '    deterministicCuDNN', '    hasLAPACK', '    hasMKL', '    hasMKLDNN', '    hasOpenMP', '    isXNNPACKAvailable', '    qEngine', '    setBenchmarkCuDNN(bool b)', '    setDeterministicCuDNN(bool b)', '    setFlushDenormal(bool on)', '    setQEngine(at::QEngine e)', '    setUserEnabledCuDNN(bool e)', '    setUserEnabledMkldnn(bool e)', '    supportedQEngines', '    userEnabledCuDNN', '    userEnabledMkldnn', '    initCPU', '    initCUDA', '    initHIP', '    LegacyDeviceTypeInit(LegacyDeviceTypeInitArgs)'];
precise-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    accumulateGrad(const torch::autograd::Variable & variable,const torch::Tensor & grad,size_t num_expected_refs)', '    addOutstandingRpc(const std::shared_ptr & futureMessage)', '    clearAndWaitForOutstandingRpcsAsync', '    clearOutstandingRpcs', '    getGradients', '    resetGraphTask', '    retrieveGraphTask', '    retrieveSendFunction(int64_t autograd_message_id)', '    setGraphTask(std::shared_ptr graphTask)', '    alreadySentError', '    State(int32_t count)', '    addKnownWorkerId(const rpc::worker_id_t workerId)', '    addRecvFunction(std::shared_ptr & func,int64_t autograd_message_id)', '    addSendFunction(const std::shared_ptr & func,int64_t autograd_message_id)', '    contextId', '    DistAutogradContext(int64_t contextId)', '    getKnownWorkerIds'];
precise-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    final'];['    GetDeviceType', '    HasAsyncPartDefault', '    IsStreamFree(const DeviceOption &,int)', '    SupportsAsyncScheduling', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyItems(const TypeMeta & meta,size_t n,const void *src,void *dst)', '    device', '    device_type', '    random_seed_', '    random_seed_set_', '    RandomNumberSeed', '    size_t', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    CPUContext', '    CPUContext(const DeviceOption & option)', '    CPUContext(const at::Device & device)', '    FinishDeviceComputation', '    RandGenerator', '    Record(Event *ev,const char *err_msg)', '    SwitchToDevice(int)', '    WaitEvent(const Event & ev)', '    ~CPUContext', '    CopyBytes(size_t nbytes,const void *src,void *dst)'];
q31-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
q31-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];[];
q31-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    DistAutogradContext'];['    accumulateGrad(const torch::autograd::Variable & variable,const torch::Tensor & grad,size_t num_expected_refs)', '    addKnownWorkerId(const rpc::worker_id_t workerId)', '    addOutstandingRpc(const std::shared_ptr & futureMessage)', '    addRecvFunction(std::shared_ptr & func,int64_t autograd_message_id)', '    addSendFunction(const std::shared_ptr & func,int64_t autograd_message_id)', '    clearAndWaitForOutstandingRpcsAsync', '    clearOutstandingRpcs', '    contextId', '    DistAutogradContext(int64_t contextId)', '    DistAutogradContext', '    DistAutogradContext', '    getGradients', '    getKnownWorkerIds', '    operator=', '    operator=', '    resetGraphTask', '    retrieveGraphTask', '    retrieveSendFunction(int64_t autograd_message_id)', '    setGraphTask(std::shared_ptr graphTask)'];
q31-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    final'];['    BuildArgumentList(std::vector,std::string)', '    GetSingleton', '    IsStreamFree(const DeviceOption &,int)', '    BuildKernel(const char *src,std::string additional_options,const char *fn_name)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    CopyBytes(n *meta,src,dst)', '    FinishDeviceComputation', '    HasAsyncPartDefault', '    Record(Event *ev,const char *&)', '    SupportsAsyncScheduling', '    SwitchToDevice(int a,...)', '    SwitchToDevice', '    WaitEvent(const Event & ev)', '    getInstance', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(n *,,)', '    OpenCLContext', '    OpenCLContext(const DeviceOption & option)', '    ~OpenCLContext', '    OpenCLContextSingleton', '    OpenCLContextSingleton', '    OpenCLContextSingleton'];
5x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    RegistryName'];
6x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    BaseContext'];['    CreateContext(const at::Device & device)', '    RegistryName', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesSameDevice(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyFromCPU(size_t n,const T *src,T *dst)', '    CopyItemsFromCPU(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopyItemsSameDevice(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopyItemsToCPU(const caffe2::TypeMeta & meta,size_t n,const void *src,void *dst)', '    CopySameDevice(size_t n,const T *src,T *dst)', '    CopyToCPU(size_t n,const T *src,T *dst)', '    device', '    device_type', '    EnforceMetaCopyOK', '    FinishDeviceComputation', '    Record(caffe2::Event *ev,const char *err_msg)', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    WaitEvent(const caffe2::Event & ev)', '    ~BaseContext', '    ContextRegistry'];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8clamp; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8clamp; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    getStreamForHandle(cublasHandle_t handle)', '    TEST(CUDATest,HasCudaRuntime)', '    TEST(CUDAContextTest,TestAllocDealloc)', '    TEST(CUDAContextTest,TestSetGetDeviceWithoutCaffeMode)', '    TEST(CUDAContextTest,MemoryPoolAllocateDealloc)', '    TEST(CUDAContextTest,TestSameThreadSameObject)', '    TEST(CUDAContextTest,TestSameThreadTempObject)', '    TEST(CUDAContextTest,TestSameThreadDifferntObjectIfDifferentDevices)', '    TEST(CUDAContextTest,TestDifferntThreadDifferentobject)', '    TEST_GetStreamAddress(cudaStream_t *ptr)'];
scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8lut32norm; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    TEST(ContextTest,BasicInit)'];
16x9p8q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    TEST(CPUContextTest,TestAllocAlignment)', '    TEST(CPUContextTest,TestAllocDealloc)'];
sub16-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    ControlFlowGraph', '    BasicBlock'];['    deleteNode(ControlFlowGraph *cfg,G::NodeRef node)', '    ControlFlowGraph', '    ControlFlowGraph', '    ControlFlowGraph', '    createAnonymousFunction', '    createNamedFunction(std::string name)', '    createNode', '    operator=', '    ~ControlFlowGraph', '    BasicBlock', '    BasicBlock', '    BasicBlock', '    deleteInstruction(NodeRef instr)', '    getInstructions', '    getMutableInstructions', '    hasInstruction(NodeRef instr)', '    insertInstructionBefore(NodeRef newInstr,NodeRef instr)', '    moveInstructionBefore(NodeRef instr1,NodeRef instr2)', '    operator=', '    pushInstructionNode(NodeRef node)', '    trackNode(NodeRef node)', '    untrackNode(NodeRef node)', '    ~BasicBlock', '    static_assert(,)', '    remove'];
sub16-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    PrePackConvWeights(const conv_param_t & conv_p,const uint8_t *kernel,const int32_t *bias)'];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8rmax; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    compute_dwconv_multiipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_dwconv_unipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_output_dimension(size_t padded_input_dim,size_t kernel_dimension,size_t dilation_dimension,size_t subsampling_dimension)', '    compute_q8conv(const struct q8conv_context [1] context,size_t group_index,size_t image_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t image_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm_xzp(const struct q8gemm_xzp_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_sum_rows(const struct q8sum_rows_context [1] context,size_t group_index,size_t batch_index,size_t block_start,size_t group_range,size_t batch_range,size_t block_size)', '    convolution', '    qnnpackConv(const conv_param_t & conv_p,void *packed_weights,const size_t batch_size,const size_t input_height,const size_t input_width,const float input_scale,const uint8_t input_zero_point,const uint8_t *input,const float output_scale,const uint8_t output_zero_point,uint8_t *output,pthreadpool_t threadpool)', '    operator()(pytorch_qnnp_operator_t op)'];
scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8lut; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    _get_pad_mode_from_conv_padding_mode(torch::nn::detail::conv_padding_mode_t conv_padding_mode)', '    Conv1dImpl(Conv1dOptions options_)', '    forward(const Tensor & input)', '    _conv_forward(const Tensor & input,const Tensor & weight)', '    Conv2dImpl(Conv2dOptions options_)', '    forward(const Tensor & input)', '    Conv3dImpl(Conv3dOptions options_)', '    forward(const Tensor & input)', '    ConvTranspose1dImpl(ConvTranspose1dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    ConvTranspose2dImpl(ConvTranspose2dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    ConvTranspose3dImpl(ConvTranspose3dOptions options_)', '    forward(const Tensor & input,const c10::optional & output_size)', '    _output_padding(const Tensor & input,const c10::optional & output_size,const ExpandingArray & stride,const ExpandingArray & padding,const ExpandingArray & kernel_size)'];
x2-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    AlgoIterator'];['    check_args(CheckedFrom,IntArrayRef args,size_t expected_size,const char *arg_name)', '    convolution_shape_check(CheckedFrom c,const TensorGeometryArg & input,const TensorGeometryArg & weight,const TensorGeometryArg & output,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    split_batch_dim_to_32bit_out(const at::Tensor & output,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,int64_t max_worksize,func_t func_32bit)', '    args', '    args', '    args', '    cudnn_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    cudnn_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_forward(CheckedFrom c,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    allocate_workspace(size_t size,const Tensor & other)', '    cudnn_convolution(const Tensor & input_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_deprecated(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    cudnn_convolution_transpose_backward_input(const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_deprecated(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    getMaxWorkspaceSize(const ConvolutionArgs & args,const algo_t *algo,int n_algo)', '    getValidAlgorithms(perf_t *perfResults,const ConvolutionArgs & args,int n_algo)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdDataAlgo_t algo,size_t *sz)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdFilterAlgo_t algo,size_t *sz)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionFwdAlgo_t algo,size_t *sz)', '    narrowGroup(const Tensor & t,int dim,int group_idx,int64_t groups)', '    raw_cudnn_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_forward_out_32bit(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    setConvolutionParams(ConvolutionParams *params,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool deterministic)', '    raw_cudnn_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_backward_input_out_32bit(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose(const Tensor & input_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cudnn_convolution_transpose_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    grad_input', '    grad_output', '    grad_output', '    grad_output_contig', '    grad_weight', '    input', '    input', '    input', '    output', '    raw_cudnn_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_cudnn_convolution_backward_weight_out_32bit(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    onlyDefaultAlgorithm(const ConvolutionArgs & args)', '    cache', '    cache', '    cache', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    findAlgorithms(const ConvolutionArgs & args,bool benchmark)', '    getWorkspaceSize(const ConvolutionArgs & args,cudnnConvolutionBwdDataAlgo_t algo,size_t *workspaceSize)', '    getWorkspaceSize(const ConvolutionArgs & args,algo_t algo,size_t *workspaceSize)', '    getWorkspaceSize(const ConvolutionArgs & args,algo_t algo,size_t *workspaceSize)', '    AlgoIterator(const ConvolutionArgs & args,bool benchmark)', '    try_all(std::function f)', '    find(const ConvolutionParams & params,T *results)', '    insert(const ConvolutionParams & params,const T & results)', '    ConvolutionArgs(const Tensor & input,const Tensor & output,const Tensor & weight)', '    Workspace(size_t size)', '    ~Workspace'];
x3-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
x3-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    _mkldnn_conv2d(const ideep::tensor & x,const ideep::tensor & w,const c10::optional & b,at::IntArrayRef padding,at::IntArrayRef stride,at::IntArrayRef dilation,int64_t groups)', '    get_mkldnn_tensor(const at::Tensor & tensor)', '    mkldnn_bias', '    mkldnn_convolution(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    mkldnn_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,std::array output_mask)', '    mkldnn_convolution_backward_input(IntArrayRef input_size,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool bias_defined)', '    mkldnn_convolution_backward_weights(IntArrayRef weight_size,const at::Tensor & grad_output,const at::Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool bias_defined)'];
x4-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
qnnpack_utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 86;  0; 1;11;  0; 82;0;0;0;0;0.00;0;['    C10FlagParser_caffe2_dnnlowp_acc16_density_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_k_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_m_threshold', '    C10FlagParser_caffe2_dnnlowp_acc16_n_threshold'];['    conv_nhwc_acc16_ref_(int num_groups,int N,int output_image_size,int M,int kernel_dim,const uint8_t *col_buffer,const int8_t *W,int32_t *Y)', '    C10FlagParser_caffe2_dnnlowp_acc16_density_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_k_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_m_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_acc16_n_threshold(const std::string & content)', '    ConvDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    ConvOutlier_(const uint8_t *col_buffer,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,const uint8_t *col_buffer_data,vector *Y_int32,uint8_t *Y_uint8_data)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
qreduction.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 141;  2; 6;10;  51; 74;17;32;8;11;0.04;5;['    final'];['    Acc16', '    ConvDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    ConvOutlier_(const std::uint8_t *col_buffer,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,const std::uint8_t *col_buffer_data,vector *Y_int32,uint8_t *Y_uint8_data)', '    fallback_to_32_bit_accumulation_', '    first_invocation_', '    GetQuantizationParameters_', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
qrelu.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 176;  3; 13;15;  82; 66;46;35;58;47;0.04;8;['    C10FlagParser_caffe2_dnnlowp_dump_tensors', '    C10FlagParser_caffe2_dnnlowp_shared_int32_buffer'];['    conv_nhwc_ref_(int group_id,int num_groups,int i_begin,int i_end,int M,int kernel_dim,const T *col_buffer,const T_signed *W,int32_t *Y)', '    C10FlagParser_caffe2_dnnlowp_dump_tensors(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_shared_int32_buffer(const std::string & content)', '    ConvDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    FilterQuantizationParams(int group_id)', '    GetConvParam_', '    RequantizationParams(int group_id)', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    ~ConvDNNLowPOp', '    ConvNHWCCore_(const T *col_buffer_data,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,vector *Y_int32,uint8_t *Y_uint8_data)', '    GetConv3DParam_', '    GetQuantizationParameters_', '    Im2ColNHWC_(Tensor *col_buffer)', '    IsConvGEMM_', '    KernelDim_', '    NoIm2ColNHWC_', '    PartitionGroupedNHWCConv_(int *group_begin,int *group_end,int *i_begin,int *i_end,int num_groups,int m,int nthreads,int thread_id)', '    PreComputeRowColumnOffsets_', '    QuantizeBias_', '    QuantizeWeight_', '    RunOnDeviceEpilogueNCHW_(const T *col_buffer_data,int32_t *Y_int32,T *Y_data,size_t i_offset,int group_id)', '    RunOnDeviceEpilogueNHWC_(const T *col_buffer_data,int32_t *Y_int32)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    TakeGConvFastPath_'];
qsigmoid.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 89;  3; 5;15;  9; 60;1;7;1;6;0.33;1;['    ConvDNNLowPOp'];['    PartitionGroupedNHWCConv_(int *group_begin,int *group_end,int *i_begin,int *i_end,int num_groups,int m,int nthreads,int thread_id)', '    Acc16', '    b_quantized_data_', '    col_buffer_', '    col_buffer_shape_device_', '    ConvDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ConvNHWCCore_(const T *col_buffer_data,vector *Y_int32)', '    DispatchFBGEMM_(PackAMatrix & packA,vector *Y_int32,uint8_t *Y_uint8_data)', '    FilterQuantizationParams(int group_id)', '    GetConv3DParam_', '    GetConvParam_', '    GetQuantizationParameters_', '    Im2ColNHWC_(Tensor *col_buffer)', '    img_shape_device_', '    in_qparams_scale_old_', '    in_qparams_zero_point_old_', '    IsConvGEMM_', '    KernelDim_', '    NoIm2ColNHWC_', '    PreComputeRowColumnOffsets_', '    QuantizeBias_', '    QuantizeWeight_', '    RequantizationParams(int group_id)', '    RunOnDeviceEpilogueNCHW_(const T *col_buffer_data,std::int32_t *Y_int32,T *Y_data,std::size_t i_offset,int group_id)', '    RunOnDeviceEpilogueNHWC_(const T *col_buffer_data,std::int32_t *Y_int32)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    ~ConvDNNLowPOp'];
qtanh.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 88;  3; 5;15;  9; 59;1;7;1;6;0.33;1;['    GetConvGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUConv1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUConvGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvGradient', '    CostInferenceForConvGradient(const OperatorDef & def,const vector & inputs)', '    TensorInferenceForConvGradient(const OperatorDef & def,const std::vector & in)', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs'];
quant_utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 124;  34; 13;4;  74; 0;48;31;31;18;0.46;1;[];['    check_args(CheckedFrom,IntArrayRef args,size_t expected_size,const char *arg_name)', '    convolution_shape_check(CheckedFrom c,const TensorGeometryArg & input,const TensorGeometryArg & weight,const TensorGeometryArg & output,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    args', '    args', '    args', '    args', '    args', '    args', '    miopen_convolution(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_convolution_transpose_backward_input(const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_forward(CheckedFrom c,const TensorArg & input,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    bdesc', '    chooseAlgorithm(const ConvolutionArgs & args,bool benchmark,algo_t *algo)', '    findAlgorithm(const ConvolutionArgs & args,bool benchmark,algo_t *algo)', '    getBestAlgorithm(perf_t *perfResults,bool deterministic,int n_algo)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvBwdWeightsAlgorithm_t)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvBwdDataAlgorithm_t)', '    getWorkspaceSize(const ConvolutionArgs & args,const miopenConvFwdAlgorithm_t)', '    miopen_convolution_add_bias_(CheckedFrom c,const TensorArg & output,const TensorArg & bias)', '    narrowGroup(const Tensor & t,int dim,int group_idx,int64_t groups)', '    setConvolutionParams(ConvolutionParams *params,miopenHandle_t handle,const at::Tensor & input,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool deterministic)', '    raw_miopen_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_forward_out(const Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    bdesc', '    grad_bias', '    grad_input', '    grad_input', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_output', '    grad_weight', '    grad_weight', '    input', '    input', '    input', '    miopen_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_convolution_backward_bias(const Tensor & grad_output_t)', '    miopen_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const TensorArg & grad_output,const TensorArg & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose(const Tensor & input_t,const Tensor & weight_t,const Tensor & bias_t,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_convolution_transpose_forward(CheckedFrom c,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output_t,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic,std::array output_mask)', '    miopen_depthwise_convolution_backward_input(CheckedFrom c,IntArrayRef input_size,const TensorArg & grad_output,const TensorArg & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_input(IntArrayRef input_size,const Tensor & grad_output_t,const Tensor & weight_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_weight(CheckedFrom c,IntArrayRef weight_size,const TensorArg & grad_output,const TensorArg & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    miopen_depthwise_convolution_backward_weight(IntArrayRef weight_size,const Tensor & grad_output_t,const Tensor & input_t,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    odesc', '    output', '    output', '    raw_miopen_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_backward_input_out(const at::Tensor & grad_input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    raw_miopen_depthwise_convolution_backward_weight_out(const Tensor & grad_weight,const Tensor & grad_output,const Tensor & input,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups,bool benchmark,bool deterministic)', '    cache', '    cache', '    cache', '    findAlgorithm(const ConvolutionArgs & args)', '    findAlgorithm(const ConvolutionArgs & args)', '    findAlgorithm(const ConvolutionArgs & args)', '    wsscache', '    wsscache', '    wsscache', '    find(const ConvolutionParams & params,T *results)', '    insert(const ConvolutionParams & params,const T & results)', '    ConvolutionArgs(const Tensor & input,const Tensor & output,const Tensor & weight)', '    operator()(const ConvolutionParams & a,const ConvolutionParams & b)', '    operator()(const ConvolutionParams & params)', '    Workspace(size_t size)', '    ~Workspace'];
quantized_ops.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 149;  24; 9;3;  136; 0;132;29;18;163;0.18;0;['    final', '    final', '    IDEEPConvOp'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvFusion', '    ConvFusionDocGenerator(const char *dim)', '    IDEEPConvFusionOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvFusionOp', '    ~IDEEPConvGradientOp', '    IDEEPConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvOp'];
qupsample_nearest2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 174;  5; 22;6;  143; 0;92;79;82;56;0.03;3;['    C10FlagParser_caffe2_profile_nnpack', '    final'];['    initNNPACK', '    C10FlagParser_caffe2_profile_nnpack(const std::string & content)', '    NNPACKConvOp(const OperatorDef & operator_def,Workspace *ws)', '    getActivationType', '    getConvolutionAlgorithm', '    getConvolutionTransformStrategy', '    RunOnDeviceWithOrderNCHW'];
qupsample_nearest3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 200;  5; 23;6;  168; 0;108;96;86;64;0.03;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConv', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUConv3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Conv3D', '    ConvDocGenerator(const char *dim)'];
tensor_operators.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 88;  12; 7;46;  28; 0;12;17;66;67;0.43;25;['    final', '    final'];['    bias_multiplier_', '    col_buffer_', '    col_buffer_shape_device_', '    col_buffer_shape_device_', '    ConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    img_shape_device_', '    img_shape_device_', '    Run1x1ConvOnDeviceWithOrderNCHW(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    Run1x1ConvOnDeviceWithOrderNHWC(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~ConvGradientOp', '    ~ConvOp'];
fake_quant_per_channel_affine.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 156;  32; 23;6;  97; 0;40;29;57;27;0.33;2;[];[];
fake_quant_per_tensor_affine.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 98;  36; 8;6;  50; 0;14;25;20;10;0.72;2;['    AlgorithmsCache'];['    getAlgorithm(at::IntArrayRef tensorDimensions1,at::IntArrayRef tensorDimensions2,int algorithmFlags,std::function generatingFunc)'];
QTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 242;  23; 31;7;  190; 0;118;98;120;79;0.12;18;[];['    TEST(AlgorithmsCacheTest,CachesCorrectly)', '    TEST(AlgorithmsCacheTest,KeysDifferIfOneVectorIsEmpty)', '    TEST(AlgorithmsCacheTest,KeysDifferIfFlagsAreDifferent)', '    res2', '    res3', '    result'];
TensorFactories.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 83;  7; 6;4;  68; 0;22;32;16;8;0.10;4;['    CudnnConvOpBase', '    final', '    final'];['    CudnnConvOpBase(const OperatorDef & operator_def,Workspace *ws)', '    DetermineComputeTypeFromInput(const T & X)', '    DuplicateConvDesc(cudnnConvolutionDescriptor_t input,size_t kernelDims,size_t dilationDims,cudnnConvolutionDescriptor_t copy)', '    SetConvDescComputeType(cudnnConvolutionDescriptor_t conv_desc,cudnnDataType_t math)', '    SetConvDescFromArguments', '    SetTensorNdDescriptorWithGroup(int size,cudnnTensorDescriptor_t tensorDesc,int N,int C,int H,int W,int D)', '    ~CudnnConvOpBase', '    CudnnConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    CudnnConvOp(const OperatorDef & operator_def,Workspace *ws)', '    ~CudnnConvGradientOp', '    ~CudnnConvOp', '    DoRunWithType', '    RunOnDevice', '    DoRunWithType', '    RunOnDevice'];
QuantizedLinear.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 531;  61; 19;23;  63; 393;9;37;17;11;0.97;9;[];[];
RangeFactories.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 220;  13; 24;6;  181; 0;165;14;194;46;0.07;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAConv', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv1D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv2D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv3D', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConv3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConvGradient'];
ReduceAllOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 12;  0; 4;3;  5; 0;3;4;1;14;0.00;0;[];['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    runWithSharedBuffer(ws_,f)', '    copy(Y_dims,Y_dims,buffer_shape)', '    GetDims', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    Run1x1ConvOnDeviceWithOrderNCHW(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    Run1x1ConvOnDeviceWithOrderNHWC(const int N,const int C,const int HxW,const int M,const T *X,const T *filter,const T *bias,T *Y)', '    RunOnDeviceWithOrderNCHW', '    SetOutputSize', '    SetOutputSize(X,Y,M)', '    Col2Im', '    Col2ImNd', '    Gemm', '    GemmBatched', '    GemmEx', '    GemmStridedBatched', '    Gemv', '    Im2Col', '    Im2ColNd', '    Set', '    cend', '    data', '    dim', '    dim32', '    mutable_data', '    numel', '    sizes'];
ReduceOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1045;  23; 118;31;  872; 5;447;296;438;284;0.03;115;['    C10FlagParser_caffe2_force_shared_col_buffer'];['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)', '    C10FlagParser_caffe2_force_shared_col_buffer(const std::string & content)'];
ReduceOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 40;  1; 10;4;  26; 0;21;19;5;84;0.04;0;[];['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)'];
ReflectionPad.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 544;  16; 63;3;  465; 0;325;162;194;109;0.03;20;[];['    createSharedBuffer(Workspace *ws)', '    runWithSharedBuffer(Workspace *ws,std::function)'];
Repeat.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 47;  0; 8;3;  36; 0;24;8;16;8;0.00;4;['    IDEEPConvPoolOpBase'];['    CalcOutputDims(const ideep::tensor & input,int output_channel)', '    IDEEPConvPoolOpBase(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    Output(int index)', '    pad_br', '    pad_tl', '    RunOnDevice', '    ~IDEEPConvPoolOpBase', '    get_dims', '    get_size'];
Repeat.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 26;  0; 4;2;  20; 0;14;11;10;10;0.00;1;['    ConvPoolDNNLowPOpBase'];['    arguments_parsed_', '    ConvPoolDNNLowPOpBase(const OperatorDef & operator_def,Workspace *ws)', '    CreateSharedInt32Buffer_', '    debug_def', '    engine', '    Fp32Op_', '    GetOutputQuantizationParams_', '    GetQuantizedOutputData_', '    InputTensorCPU_(int idx)', '    measure_quantization_error_', '    MeasureQuantizationError_', '    output', '    OutputTensorCPU_(int idx)', '    OutputTensorCPU_(int idx,at::IntArrayRef dims,at::TensorOptions options)', '    ParseDNNLowPOperatorArguments_', '    RunOnDeviceEpilogue_', '    RunWithSharedBuffer_(Tensor *col_buffer,vector *Y_int32,std::function)', '    static_assert(std::is_integral,)', '    type', '    ~ConvPoolDNNLowPOpBase', '    Output', '    RunOnDevice'];
Resize.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 92;  30; 6;5;  54; 0;29;24;19;9;0.56;2;['    ConvPoolOpBase'];['    check_and_set_default_value', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int dilation,LegacyPadding legacy_pad,int *pad_head,int *pad_tail,int *out_size)', '    ComputeSizeAndPad64(const int in_size,const int stride,const int kernel,const int dilation,LegacyPadding legacy_pad,int *pad_head,int *pad_tail,int64_t *out_size)', '    CostInferenceForConv(const OperatorDef & def,const vector & inputs)', '    InferOutputSize(const at::IntArrayRef & input_dims,const int output_channel,const StorageOrder order,const bool global_pooling,const LegacyPadding legacy_pad,const std::vector & dilation,const std::vector & stride,std::vector *kernel,std::vector *pads,std::vector *output_dims)', '    InferOutputSize64(const at::IntArrayRef & input_dims,const int output_channel,const StorageOrder order,const bool global_pooling,const LegacyPadding legacy_pad,const std::vector & dilation,const std::vector & stride,std::vector *kernel,std::vector *pads,std::vector *output_dims)', '    TensorInferenceForConv(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForLC(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForPool(const OperatorDef & def,const std::vector & in)', '    TensorInferenceForSchema(const OperatorDef & def,const vector & in,int output_channel)', '    AllocateAndCopy(const vector & vec,Tensor & tensor)', '    ComputePads(const vector & dims)', '    ConvPoolOpBase(const OperatorDef & operator_def,Workspace *ws)', '    dilation_h', '    dilation_w', '    GetDims(const Tensor & input)', '    GetDimsSize(const Tensor & input)', '    GetOutputSize(const Tensor & input,int output_channel)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasPad', '    HasStride', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    SetBiasMultiplier(const int size,Tensor *bias_multiplier_)', '    SetDeviceTensor(const std::vector & data,Tensor *tensor)', '    SetOutputSize(const Tensor & input,Tensor *output,int output_channel)', '    stride_h', '    stride_w', '    ~ConvPoolOpBase', '    begin', '    dim', '    end', '    size_from_dim', '    copy_n'];
Resize.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 141;  27; 18;5;  90; 1;45;24;50;12;0.30;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConvRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvRelu', '    RunOnDeviceWithOrderNCHW'];
ResizeCommon.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 30;  0; 3;3;  24; 0;4;6;7;3;0.00;1;['    final'];['    ConvReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~ConvReluOp', '    CreateBlob', '    GetBlob'];
RNN.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 45;  1; 8;3;  34; 0;30;29;8;95;0.03;1;[];[];
Scalar.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 31;  1; 4;2;  25; 0;16;7;66;18;0.04;2;['    ConvToNNPackTransform'];['    MatchOperator(const OperatorDef & op)', '    ReplaceOperator(OperatorDef *op)'];
ScatterGatherShapeChecks.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 27;  9; 7;4;  9; 0;2;9;0;5;1.00;0;[];['    TEST(ConvToNNPackTest,TestSimple)'];
SobolEngineOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 159;  28; 24;5;  104; 0;72;42;67;40;0.27;4;['    GetConvTransposeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUConvTransposeGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvTransposeGradient', '    vector', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs'];
SobolEngineOpsUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1265;  10; 8;1;  1246; 0;1236;1235;11;12;0.01;4;['    final', '    final'];['    IDEEPConvTransposeGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPConvTransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPConvTransposeGradientOp', '    ~IDEEPConvTransposeOp'];
SoftMax.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 294;  1; 25;8;  261; 0;187;91;150;84;0.00;18;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConvTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConvTranspose'];
Sorting.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 12;  1; 5;3;  4; 0;2;3;1;9;0.25;0;['    final', '    final'];['    ConvTransposeGradientOp(Args,...)', '    ConvTransposeOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
SortingUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 117;  11; 6;2;  102; 0;61;27;41;14;0.11;3;['    CudnnConvTransposeOpBase', '    final', '    final'];['    CudnnConvTransposeOpBase(Args,...)', '    SetTensor4DDescriptorWithGroup(const cudnnDataType_t data_type,const int N,const int C,const int H,const int W,cudnnTensorDescriptor_t *desc)', '    ~CudnnConvTransposeOpBase', '    CudnnConvTransposeGradientOp(Args,...)', '    CudnnConvTransposeOp(Args,...)', '    ~CudnnConvTransposeGradientOp', '    ~CudnnConvTransposeOp', '    RunOnDevice', '    RunOnDevice'];
SparseCUDATensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/sparse/cuda; 66;  6; 10;4;  48; 0;32;13;35;14;0.13;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAConvTranspose', '    CAFFE_ANONYMOUS_VARIABLE_CUDAConvTransposeGradient'];
SparseTensorMath.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/sparse; 1400;  210; 214;11;  992; 0;711;350;722;337;0.21;59;[];['    dtype', '    MessageLogger(,,)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    func(& col_buffer_)', '    runWithSharedBuffer(ws_,func)', '    device', '    kernel_w', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    kernel_w', '    RunOnDeviceWithOrderNCHW', '    GetOutputSize', '    Add', '    Col2Im', '    Gemm', '    Gemm(CblasNoTrans,CblasTrans,M,kernel_dim,X_HxW,,X_data,col_buffer_data,,dfilter_data,& context_)', '    Gemm(CblasNoTrans,CblasNoTrans,M,X_HxW,kernel_dim,,filter_data,col_buffer_data,,dX_data,& context_)', '    Gemm(CblasTrans,CblasNoTrans,M,kernel_dim,X_HxW,,X_data,col_buffer_data,,dfilter_data,& context_)', '    Gemm(CblasNoTrans,CblasTrans,X_HxW,M,kernel_dim,,col_buffer_data,filter_data,,dX_data,& context_)', '    GemmEx', '    GemmEx(CblasTrans,CblasNoTrans,M,kernel_dim,X_HxW,,X_data,M,col_buffer_data,G *kernel_dim,,dfilter_data,kernel_dim,& context_)', '    GemmEx(CblasNoTrans,CblasTrans,X_HxW,M,kernel_dim,,col_buffer_data,G *kernel_dim,filter_data,kernel_dim,,dX_data,M,& context_)', '    GemmStridedBatched', '    GemmStridedBatched(CblasNoTrans,CblasTrans,G,M,kernel_dim,X_HxW,,X_data,M,col_buffer_data,col_buffer_,,dfilter_data,M,& context_)', '    GemmStridedBatched(CblasNoTrans,CblasNoTrans,G,M,X_HxW,kernel_dim,,filter_data,M,col_buffer_data,col_buffer_,,dX_data,M,& context_)', '    Im2Col(C,dY,dY,kernel_h,kernel_w,,,pad_t,pad_l,pad_b,pad_r,stride_h,stride_w,dY_data,col_buffer_data,& context_)', '    Im2Col(C,dY,dY,kernel_h,kernel_w,,,pad_t,pad_l,pad_b,pad_r,stride_h,stride_w,dY_data,col_buffer_data,& context_,G)', '    ReduceSum(,Y_dims,b_dims,T,dY_data,dbias_data,& context_)', '    Set'];
SparseTensorMath.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/sparse; 11;  0; 4;3;  4; 0;0;4;0;4;0.00;0;[];[];
SpectralOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 260;  34; 27;25;  187; 0;114;46;119;54;0.18;10;[];[];
SummaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 67;  5; 10;3;  52; 0;25;21;55;21;0.10;2;[];[];
TensorAdvancedIndexing.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 642;  88; 78;13;  465; 0;304;149;298;161;0.19;37;[];['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int adjH,int adjW,float maxRelErr,float absErrForRelErrFailure)', '    relativeError(float a,float b)', '    randInt(int a,int b)'];
TensorAdvancedIndexing.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 34;  2; 9;3;  21; 0;16;13;8;60;0.10;0;['    IDEEPConvTransposeUnpoolBase'];['    Input(int index)', '    Output(int index)', '    get_dim', '    get_dims', '    get_size', '    adj_h', '    adj_w', '    CalcOutputDims(const ideep::tensor & input,int output_channel)', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int adj,int *pad_head,int *pad_tail,int *out_size)', '    IDEEPConvTransposeUnpoolBase(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    kernel_h', '    kernel_w', '    Output(int index)', '    pad_b', '    pad_br', '    pad_l', '    pad_r', '    pad_t', '    pad_tl', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    stride_h', '    stride_w', '    ~IDEEPConvTransposeUnpoolBase'];
TensorCompare.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 19;  1; 6;5;  8; 0;6;5;2;21;0.13;0;['    ConvTransposeUnpoolBase'];['    adj_h', '    adj_w', '    ComputeSizeAndPad(const int in_size,const int stride,const int kernel,const int adj,int *pad_head,int *pad_tail,int *out_size)', '    ConvTransposeUnpoolBase(const OperatorDef & operator_def,Workspace *ws)', '    GetOutputSize(const Tensor & input,int output_channel)', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    stride_h', '    stride_w', '    ~ConvTransposeUnpoolBase', '    dim32'];
TensorConversions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 121;  8; 19;4;  91; 0;56;23;46;22;0.09;8;[];['    conv_param_t(const std::array kernel,const std::array subsampling,const std::array dil,const std::array pd,const uint32_t grp,const size_t in_ch,const size_t out_ch,const uint8_t kernel_zp,const float kernel_s,const uint8_t out_min,const uint8_t out_max)', '    isnormal'];
TensorDimApply.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 52;  1; 3;1;  47; 0;34;16;24;14;0.02;1;[];['    Get(IN x)', '    To(const IN in)'];
TensorFactories.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 88;  32; 9;2;  50; 0;30;17;29;13;0.64;4;['    C10FlagParser_batch_size', '    C10FlagParser_color', '    C10FlagParser_crop', '    C10FlagParser_input_image_files', '    C10FlagParser_input_text_files', '    C10FlagParser_preprocess', '    C10FlagParser_report_time', '    C10FlagParser_scale', '    C10FlagParser_warp'];['    backendCudaSet(const string & backend)', '    benchmark(int argc,char *[] argv,const string & FLAGS_backend,const string & FLAGS_init_net,const string & FLAGS_input_dims,int FLAGS_iter,const string & FLAGS_net,const string & FLAGS_output,const string & FLAGS_output_folder,bool FLAGS_run_individual,int FLAGS_sleep_before_run,int FLAGS_sleep_between_iteration,int FLAGS_sleep_between_net_and_operator,bool FLAGS_text_output,int FLAGS_warmup,bool FLAGS_wipe_cache)', '    convertImages(std::string & image_file)', '    convertOneImage(std::string & filename,int *height_ptr,int *width_ptr)', '    convertToVector(cv::Mat & img)', '    convertValues(std::string & file_name)', '    cropToRec(cv::Mat & img,int *height_ptr,int *width_ptr)', '    getBatchSize(int num_items)', '    reportTime(std::string type,double ts,std::string metric,std::string unit)', '    resizeImage(cv::Mat & img)', '    splitSizes(const std::string & arg,int *ptr0,int *ptr1)', '    splitString(std::string & line)', '    writeValues(std::vector,std::vector)', '    fillInputBlob(shared_ptr workspace,map & tensor_protos_map,int iteration)', '    main(int argc,char **argv)', '    observerConfig', '    runNetwork(shared_ptr workspace,caffe2::NetDef & net_def,map & tensor_protos_map,const bool wipe_cache,const bool run_individual,const bool run_on_gpu,const bool text_output,const int warmup,const int iter,const int num_blobs,const int sleep_before_run,const int sleep_between_iteration,const int sleep_between_net_and_operator,const std::string & output,const std::string & output_folder)', '    setOperatorEngine(caffe2::NetDef *net_def,const string & backend)', '    writeOutput(shared_ptr workspace,const bool run_on_gpu,const string & output,const string & output_folder,const bool text_output,const int index,const int num_blobs)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_crop(const std::string & content)', '    C10FlagParser_input_image_files(const std::string & content)', '    C10FlagParser_input_text_files(const std::string & content)', '    C10FlagParser_preprocess(const std::string & content)', '    C10FlagParser_report_time(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_warp(const std::string & content)'];
TensorIterator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1171;  86; 104;19;  965; 0;662;289;559;240;0.09;64;['    C10FlagParser_batch_size', '    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_output_db', '    C10FlagParser_output_db_type'];['    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_output_db(const std::string & content)', '    C10FlagParser_output_db_type(const std::string & content)'];
TensorIterator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 432;  115; 68;11;  243; 0;92;169;70;169;0.47;43;['    C10FlagParser_batch_size', '    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_output_db', '    C10FlagParser_output_db_type'];['    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_output_db(const std::string & content)', '    C10FlagParser_output_db_type(const std::string & content)'];
TensorProperties.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 113;  17; 15;11;  72; 0;40;28;33;19;0.24;11;['    C10FlagParser_color', '    C10FlagParser_input_db_name', '    C10FlagParser_output_db_name', '    C10FlagParser_scale', '    C10FlagParser_warp'];['    ConvertToRawDataset(const string & input_db_name,const string & output_db_name)', '    main(int argc,char **argv)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_input_db_name(const std::string & content)', '    C10FlagParser_output_db_name(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_warp(const std::string & content)'];
TensorShape.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1468;  149; 169;19;  1140; 0;741;417;614;394;0.13;82;['    C10FlagParser_batch_size', '    C10FlagParser_color', '    C10FlagParser_crop', '    C10FlagParser_input_image_file', '    C10FlagParser_input_images', '    C10FlagParser_input_text_file', '    C10FlagParser_output_tensor', '    C10FlagParser_output_text_tensor', '    C10FlagParser_preprocess', '    C10FlagParser_report_time', '    C10FlagParser_scale', '    C10FlagParser_text_output', '    C10FlagParser_warp'];['    convertImages', '    convertOneImage(std::string & filename,int *height_ptr,int *width_ptr)', '    convertToVector(cv::Mat & img)', '    convertValues', '    cropToRec(cv::Mat & img,int *height_ptr,int *width_ptr)', '    getBatchSize(int num_items)', '    reportTime(std::string type,double ts,std::string metric,std::string unit)', '    resizeImage(cv::Mat & img)', '    splitSizes(const std::string & arg,int *ptr0,int *ptr1)', '    splitString(std::string & line)', '    writeValues(std::vector,std::vector,std::string output_file)', '    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_crop(const std::string & content)', '    C10FlagParser_input_image_file(const std::string & content)', '    C10FlagParser_input_images(const std::string & content)', '    C10FlagParser_input_text_file(const std::string & content)', '    C10FlagParser_output_tensor(const std::string & content)', '    C10FlagParser_output_text_tensor(const std::string & content)', '    C10FlagParser_preprocess(const std::string & content)', '    C10FlagParser_report_time(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_text_output(const std::string & content)', '    C10FlagParser_warp(const std::string & content)'];
TensorTransformations.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 133;  7; 21;7;  99; 0;69;32;71;32;0.07;4;[];[];
TriangularOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 158;  5; 16;6;  135; 0;94;38;239;74;0.04;8;[];['    ConvertToSSA(std::shared_ptr & graph)', '    addBlockInput(Block *b,const TypePtr & type,const std::string & name)', '    addBlockOutput(Block *exit_block,const TypePtr & type,const std::string & name)', '    addNodeInput(Node *n,const TypePtr & type,const std::string & name)', '    addNodeOutput(Node *n,const TypePtr & type,const std::string & name)', '    addControlFlowLoadStores(Block *block)', '    addIfLoadStores(Node *n)', '    addLoopLoadStores(Node *n)', '    popFrame', '    pushFrame(Block *b)', '    run(std::shared_ptr & graph)', '    eraseBlockLoadStores(Block *block)', '    popFrame', '    pushFrame(Block *b)', '    run(std::shared_ptr & graph)', '    addLoopCarriedOutputs(Node *n)', '    assignExitContinuations(Block *block)', '    run(std::shared_ptr & graph)', '    run(Block *b)'];
TriangularOpsUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 59;  14; 7;2;  38; 0;22;12;19;10;0.37;2;[];['    ConvertToSSA(std::shared_ptr & graph)'];
TypeProperties.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 144;  3; 23;5;  114; 0;49;29;40;73;0.03;16;['    AveragePoolConverter', '    BatchNormalizationConverter', '    ClipConverter', '    ConcatConverter', '    ConvConverter', '    ConvTransposeConverter', '    FCConverter', '    FlattenConverter', '    MaxPoolConverter', '    ReluConverter', '    SumConverter'];['    convertToCaffe2Proto(repr::NNModule & m)', '    convertToCaffe2Proto(repr::NNModule & m,const caffe2::NetDef & oldNet)', '    convertToNeuralNetOperator(const caffe2::OperatorDef & op)', '    convertToNNModule(const caffe2::NetDef & net,bool strict,std::vector *opNodeVec)', '    convertToOperatorDef(const repr::NNGraph::NodeRef & instrNode)', '    getKernelShape(std::map argMap)', '    getLayout(std::map argMap)', '    getOrAddCaffe2Annotation(nom::repr::NNGraph::NodeRef & instrNode)', '    injectDataEdgeIndicators(caffe2::NetDef *net)', '    mergeExternalTensors(const std::unordered_set & currExternal,const std::vector & oldExternal)', '    pushOpToFront(caffe2::OperatorDef & op,caffe2::NetDef *net)', '    RegistryName', '    removeDataEdgeIndicators(caffe2::NetDef *net)', '    getDilations(std::map argMap)', '    getGroup(std::map & argMap)', '    getPads(std::map argMap)', '    getStrides(std::map argMap)', '    getArgumentsFromOperator(caffe2::OperatorDef op)', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~AveragePoolConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchNormalizationConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ClipConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConcatConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConvConverter', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    getDeviceOption(const nom::repr::NeuralNetOperator *nnOp)', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ConvTransposeConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~FCConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~FlattenConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~MaxPoolConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ReluConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~SumConverter'];
UnaryOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 394;  18; 59;49;  275; 0;156;186;211;230;0.07;132;['    AddConverter', '    BatchGatherConverter', '    BatchMatMulConverter', '    CastConverter', '    ClipRangesConverter', '    ClipRangesGatherSigridHashConverter', '    ConcatAddMulReplaceNaNClipConverter', '    MulConverter', '    ReplaceNaNConverter', '    SigridHashConverter', '    SliceConverter'];['    convertToNeuralNetOperator(const OperatorDef & op)', '    ~AddConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchGatherConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~BatchMatMulConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~CastConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ClipRangesConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ClipRangesGatherSigridHashConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~ConcatAddMulReplaceNaNClipConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~MulConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ReplaceNaNConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~SigridHashConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    ~SliceConverter'];
UnaryOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 78;  9; 7;5;  58; 0;55;56;2;273;0.16;0;['    Converter'];['    convertToCaffe2Proto(repr::NNModule & m)', '    convertToCaffe2Proto(repr::NNModule & m,const caffe2::NetDef & oldNet)', '    convertToNeuralNetOperator(const caffe2::OperatorDef & op)', '    convertToNNModule(const caffe2::NetDef & net,bool strict,std::vector *opNodeVec)', '    convertToOperatorDef(const nom::repr::NNGraph::NodeRef & instrNode)', '    RegistryName', '    getArgumentsFromOperator(caffe2::OperatorDef op)', '    Converter', '    convertToNeuralNetOperator(const OperatorDef &)', '    convertToOperatorDef(const nom::repr::NeuralNetOperator *nnOp)', '    getDeviceOption(const nom::repr::NeuralNetOperator *nnOp)', '    ~Converter'];
Unfold2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 8;  0; 3;1;  4; 0;0;4;0;4;0.00;0;[];['    fakeNet', '    TEST(Converter,Basic)', '    TEST(Converter,UnknownType)', '    TEST(Converter,SpecializeConverter)', '    TEST(Converter,ExternalInputs)', '    TEST(Converter,ExternalOutputs)', '    TEST(Converter,InjectDataEdgeIndicators)'];
Unfold3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 525;  7; 18;8;  396; 102;233;164;105;51;0.02;11;[];['    TEST(Converter,ClipRangesGatherSigridHashConverter)'];
Unfold3d.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 49;  2; 5;2;  42; 0;0;42;0;4;0.05;0;['    ConvolutionOperatorTester', '    Mode'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    dilatedKernelHeight', '    dilatedKernelWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    groupInputChannels(size_t groupInputChannels)', '    groupInputChannels', '    groupInputChannels_', '    groupOutputChannels(size_t groupOutputChannels)', '    groupOutputChannels', '    groupOutputChannels_', '    groups(uint32_t groups)', '    groups', '    groups_', '    inputHeight(uint32_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(uint32_t inputHeight,uint32_t inputWidth)', '    inputWidth(uint32_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize(uint32_t kernelSize)', '    kernelSize(uint32_t kernelHeight,uint32_t kernelWidth)', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    subsampling(uint32_t subsampling)', '    subsampling(uint32_t subsamplingHeight,uint32_t subsamplingWidth)', '    subsamplingHeight(uint32_t subsamplingHeight)', '    subsamplingHeight', '    subsamplingHeight_', '    subsamplingWidth(uint32_t subsamplingWidth)', '    subsamplingWidth', '    subsamplingWidth_', '    testQ8(const Mode mode)'];
Unique.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 279;  12; 37;6;  227; 0;129;104;148;394;0.05;9;[];['    compute_output_dimension(size_t padded_input_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t subsampling_dimension)', '    pytorch_qnnp_create_convolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t kernel_height,uint32_t kernel_width,uint32_t subsampling_height,uint32_t subsampling_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *convolution_out)', '    pytorch_qnnp_setup_convolution2d_nhwc_q8(pytorch_qnnp_operator_t convolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)'];
UpSampleBicubic2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 335;  13; 44;3;  282; 0;170;140;108;78;0.05;8;[];['    TEST(CONVOLUTION_OP,zero_batch)', '    TEST(CONVOLUTION_OP,grouped_1x1)', '    TEST(CONVOLUTION_OP,xzp_1x1)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_qmin)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_qmax)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_input_stride)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_output_stride)', '    TEST(CONVOLUTION_OP,xzp_1x1_with_batch)', '    TEST(CONVOLUTION_OP,grouped_xzp_1x1)', '    TEST(CONVOLUTION_OP,grouped_xzp_1x1_runtime_quant)', '    TEST(CONVOLUTION_OP,grouped_1x3)', '    TEST(CONVOLUTION_OP,grouped_1x3_runtime_quant)', '    TEST(CONVOLUTION_OP,grouped_3x1)', '    TEST(CONVOLUTION_OP,grouped_3x3)', '    TEST(CONVOLUTION_OP,depthwise_3x3)', '    TEST(CONVOLUTION_OP,depthwise_3x3_runtime_quant)', '    TEST(CONVOLUTION_OP,depthwise_3x3s2)', '    TEST(CONVOLUTION_OP,depthwise_3x3s1x2)', '    TEST(CONVOLUTION_OP,depthwise_3x3s2x1)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2)', '    TEST(CONVOLUTION_OP,depthwise_3x3d1x2)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2x1)', '    TEST(CONVOLUTION_OP,depthwise_3x3d2x1_runtime_quant)', '    TEST(CONVOLUTION_OP,depthwise_5x5)', '    TEST(CONVOLUTION_OP,depthwise_5x5s2)', '    TEST(CONVOLUTION_OP,depthwise_5x5s1x2)', '    TEST(CONVOLUTION_OP,depthwise_5x5s2x1)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2)', '    TEST(CONVOLUTION_OP,depthwise_5x5d1x2)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2x1)', '    TEST(CONVOLUTION_OP,depthwise_5x5d2x1_runtime_quant)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)', '    TEST(CONVOLUTION_OP)'];
UpSampleBilinear2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 332;  11; 50;3;  275; 0;167;149;107;83;0.04;8;[];['    convolution_q8(benchmark::State & state,const char *net)', '    DWConv3x3(benchmark::internal::Benchmark *b)', '    DWConv3x3d2(benchmark::internal::Benchmark *b)', '    DWConv5x5(benchmark::internal::Benchmark *b)', '    MobileNetV1(benchmark::internal::Benchmark *b)', '    MobileNetV2(benchmark::internal::Benchmark *b)', '    ResNet18(benchmark::internal::Benchmark *b)', '    ResNet50(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X05(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X10(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X15(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X20(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)'];
UpSampleLinear1d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 259;  10; 37;3;  214; 0;124;111;97;61;0.05;8;[];['    check_shape_forward(const at::Tensor & input,const c10::IntArrayRef & weight_sizes,const at::Tensor & bias,const ConvParams & params)', '    subtensor(at::Tensor & tensor,int dim,int groups,int g)', '    subvariable(const Tensor & var,int dim,int groups,int g)', '    view3d(const at::Tensor & tensor)', '    view4d(const at::Tensor & tensor)', '    _convolution(const Tensor & input_r,const Tensor & weight_r,const Tensor & bias_r,IntArrayRef stride_,IntArrayRef padding_,IntArrayRef dilation_,bool transposed_,IntArrayRef output_padding_,int64_t groups_,bool benchmark,bool deterministic,bool cudnn_enabled)', '    _convolution_double_backward(const Tensor & ggI,const Tensor & ggW_r,const Tensor & ggb,const Tensor & gO_r,const Tensor & weight_r,const Tensor & input,IntArrayRef stride_,IntArrayRef padding_,IntArrayRef dilation_,bool transposed_,IntArrayRef output_padding_,int64_t groups_,bool benchmark,bool deterministic,bool cudnn_enabled,std::array output_mask)', '    _convolution_nogroup(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding)', '    check_cudnn_depthwise_workload(const at::Tensor & input,int stride)', '    conv1d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv2d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv3d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,int64_t groups)', '    conv_transpose1d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    conv_transpose2d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    conv_transpose3d(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,int64_t groups,IntArrayRef dilation)', '    convolution(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    convolution_backward_overrideable(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups,std::array output_mask)', '    convolution_overrideable(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    operator<<(std::ostream & out,const ConvParams & params)', '    is_depthwise(const at::Tensor & input,const at::Tensor & weight)', '    is_dilated', '    is_output_padding_big', '    is_output_padding_neg', '    is_padded', '    is_padding_neg', '    is_stride_nonpos', '    is_strided', '    needs_64bit_indexing_no_split(const at::Tensor & input,const at::Tensor & weight)', '    use_cpu_depthwise3x3_winograd(const at::Tensor & input,const at::Tensor & weight)', '    use_cudnn(const at::Tensor & input,const at::Tensor & weight)', '    use_cudnn_depthwise(const at::Tensor & input,const at::Tensor & weight)', '    use_miopen(const at::Tensor & input,bool bias_defined)', '    use_mkldnn(const at::Tensor & input)', '    use_nnpack(const at::Tensor & input)', '    view1d_as_2d'];
UpSampleNearest2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 130;  3; 20;3;  107; 0;49;57;23;27;0.03;6;[];[];
UpSampleNearest3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 146;  3; 19;3;  124; 0;58;67;23;31;0.02;6;[];[];
UpSampleTrilinear3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 419;  13; 47;3;  365; 0;241;197;119;105;0.04;8;[];['    slow_conv2d_backward_parameters_out_cpu_template(Tensor & grad_weight,Tensor & grad_bias,const Tensor & input_,const Tensor & grad_output_,const Tensor & finput,Tensor fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width,bool weight_optional)', '    slow_conv2d_update_output_frame(Tensor & input,Tensor & output,const Tensor & weight,const Tensor & bias,Tensor & finput,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t n_output_plane,int64_t output_height,int64_t output_width)', '    view_weight_2d(const Tensor & weight_)', '    slow_conv2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input,std::array output_mask)', '    slow_conv2d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input)', '    slow_conv2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input_,const Tensor & weight_,const Tensor & finput,Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_backward_parameters_frame(Tensor & grad_weight,Tensor & grad_bias,Tensor & grad_output,const Tensor & finput)', '    slow_conv2d_backward_update_grad_input_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & weight,Tensor & fgrad_input,int64_t kernel_height,int64_t kernel_width,int64_t stride_height,int64_t stride_width,int64_t pad_height,int64_t pad_width)', '    slow_conv2d_forward_cpu(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv2d_forward_out_cpu(Tensor & output,Tensor & finput,Tensor & fgrad_input,const Tensor & self,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)'];
ParamsHash.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/utils; 42;  8; 8;3;  24; 0;9;15;6;13;0.33;2;[];['    slow_conv3d_backward_parameters_out_cpu_template(Tensor & grad_weight,Tensor & grad_bias,const Tensor & input,const Tensor & grad_output,const Tensor & finput,Tensor fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width,bool weight_optional)', '    slow_conv3d_update_output_frame(Tensor & input,Tensor & output,const Tensor & weight,const Tensor & bias,Tensor & finput,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width,int64_t n_input_plane,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t n_output_plane,int64_t output_depth,int64_t output_height,int64_t output_width)', '    view_weight_2d(const Tensor & weight_)', '    slow_conv3d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input,std::array output_mask)', '    slow_conv3d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,const Tensor & finput,const Tensor & fgrad_input)', '    slow_conv3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & weight,const Tensor & finput,Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_backward_parameters_frame(Tensor & grad_weight,Tensor & grad_bias,Tensor & grad_output,const Tensor & finput)', '    slow_conv3d_backward_update_grad_input_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & weight,Tensor & fgrad_input,int64_t kernel_depth,int64_t kernel_height,int64_t kernel_width,int64_t stride_depth,int64_t stride_height,int64_t stride_width,int64_t pad_depth,int64_t pad_height,int64_t pad_width)', '    slow_conv3d_forward_cpu(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_forward_out_cpu(Tensor & output,Tensor & finput,Tensor & fgrad_input,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    slow_conv3d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)'];
ParamUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/utils; 27;  2; 4;3;  20; 0;10;8;10;3;0.10;1;[];['    conv_tbc(const Tensor & self,const Tensor & weight,const Tensor & bias,int64_t pad)', '    conv_tbc_backward(const Tensor & dOutput,const Tensor & input,const Tensor & weight,const Tensor & bias,int64_t pad)'];
VariableMethodStubs.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 44;  5; 11;2;  28; 0;8;12;32;10;0.18;8;[];['    conv_input_size(IntArrayRef output_size,IntArrayRef weight_size,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    conv_output_size(IntArrayRef input_size,IntArrayRef weight_size,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation)', '    conv_weight_size(IntArrayRef input_size,IntArrayRef output_size,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    cudnn_conv_use_channels_last(const at::Tensor & input,const at::Tensor & weight)', '    reshape_bias(int64_t dim,const Tensor & bias)', '    getCUDAHooks', '    reshape', '    scalar_type', '    suggest_memory_format'];
WeightNorm.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 113;  26; 16;7;  68; 0;36;31;27;31;0.38;3;[];['    copy_impl(Tensor & self,const Tensor & src,bool non_blocking)', '    copy_(Tensor & self,const Tensor & src,bool non_blocking)', '    copy_same_type_transpose_(Tensor & self,const Tensor & src)', '    copy_transpose_valid(const Tensor & self,const Tensor & src)', '    is_supported_device(Device device)'];
Common.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 122;  1; 2;6;  0; 116;0;0;0;0;0.00;0;[];['    quantized_copy_from_float_(Tensor & self,const Tensor & src)'];
Convolution.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 299;  1; 0;8;  0; 297;0;0;0;0;0.00;0;[];['    copy_stub', '    copy_stub', '    operator='];
Factory.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 56;  1; 0;4;  0; 54;0;0;0;0;0.00;0;[];['    quantized_copy_from_float_(Tensor & self,const Tensor & src)'];
Factory.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 27;  1; 2;4;  0; 21;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCopy', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyFromCPUInput', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyOnDeviceLike', '    schema_CopyCPUToGPU', '    schema_CopyGPUToCPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Copy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyCPUToGPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyFromCPUInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyGPUToCPU', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyOnDeviceLike', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs'];
Init.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 63;  1; 0;3;  0; 61;0;0;0;0;0.00;0;['    CopyOnDeviceLikeOp', '    CopyOp'];['    schema_CopyCPUToGPU', '    schema_CopyGPUToCPU', '    CopyOnDeviceLikeOp(Args,...)', '    CopyOp(Args,...)', '    Input', '    Output', '    RunOnDevice', '    ~CopyOp'];
Linear.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 41;  1; 1;6;  0; 37;0;0;0;0;0.00;0;['    GetCopyRowsToTensorGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUCopyRowsToTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyRowsToTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyRowsToTensorGradient', '    GetGradientDefs'];
OpContext.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 76;  1; 0;5;  0; 74;0;0;0;0;0.00;0;['    CopyRowsToTensorGradientOp', '    CopyRowsToTensorOp'];['    CopyRowsToTensorGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice', '    CopyRowsToTensorOp(const OperatorDef & operator_def,Workspace *ws)', '    DoRunWithType', '    RunOnDevice'];
OpContext.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 132;  1; 1;6;  0; 128;0;0;0;0;0.00;0;[];['    THPCopy(const THPCopyList & v,PyObject *dst,PyObject *src,bool non_blocking,bool broadcast)', '    THPInsertStorageCopyFunction(PyTypeObject *srcType,THPCopyList & copyList,void (*) (LIBRARY_STATE_TYPE StorageDst *, StorageSrc *) copyFunc,bool non_blocking)', '    THPStorageCopyMethod(const THPCopyList & v,PyObject *self,PyObject *args,PyObject *kwargs)', '    tryTHPCopy(const THPCopyList & v,PyObject *dst,PyObject *src,bool non_blocking,bool broadcast)', '    push_back'];
Shim.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 64;  6; 12;3;  49; 0;7;39;7;11;0.12;5;[];['    CopyBytes(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device,bool async)', '    _CopyBytesFunctionRegisterer(DeviceType fromType,DeviceType toType,CopyBytesFunction func_sync,CopyBytesFunction func_async)'];
NumericUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 46;  4; 9;13;  20; 2;3;11;3;8;0.20;3;[];[];
OpaqueTensorImpl.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 134;  37; 22;4;  80; 0;34;33;48;20;0.46;15;[];['    copy_kernel(TensorIterator & iter,bool non_blocking)'];
ParallelCommon.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 110;  2; 21;27;  51; 13;37;13;26;10;0.04;4;[];['    deleteTHManagedMapAllocator(void *ptr)', '    get_alloc_info(const char *filename)', '    get_manager_socket(const std::string & manager_handle)', '    libshm_init(const char *manager_exec_path)', '    manager', '    start_manager', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    close', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    THManagedMapAllocatorInit(const char *manager_handle,const char *filename)'];
ParallelNative.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 279;  0; 0;43;  0; 277;0;0;0;0;0.00;0;[];['    deleteTHManagedMapAllocator(void *ptr)', '    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)'];
ParallelNative.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 92;  5; 9;5;  76; 0;41;31;22;12;0.07;3;[];['    BM_APILogging(benchmark::State & state)', '    BM_NoAPILogging(benchmark::State & state)', '    call(int id)', '    call_no_logging(int id)'];
ParallelNativeTBB.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 105;  5; 12;11;  78; 0;49;22;26;8;0.06;3;['    DummyEmptyOp'];['    BM_CUDAContextCreation(benchmark::State & state)', '    BM_CUDAContextStreamAccess(benchmark::State & state)', '    BM_cudaEventRecord(benchmark::State & state)', '    BM_cudaGetDevice(benchmark::State & state)', '    BM_CudaPointerAffinity(benchmark::State & state)', '    BM_cudaSetAndGetDevice(benchmark::State & state)', '    BM_cudaSetDevice(benchmark::State & state)', '    BM_cudaSetSameDevice(benchmark::State & state)', '    BM_cudaStreamCreateSyncDelete(benchmark::State & state)', '    BM_cudaStreamSynchronize(benchmark::State & state)', '    BM_cudaStreamWaitEventThenStreamSynchronize(benchmark::State & state)', '    BM_OperatorCreationCPU(benchmark::State & state)', '    BM_OperatorCreationCUDA(benchmark::State & state)', '    BM_RawAllocDeallocCPU(benchmark::State & state)', '    BM_TensorAllocDeallocCPU(benchmark::State & state)', '    BM_TensorAllocDeallocCUDA(benchmark::State & state)', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyEmpty', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyEmpty', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyEmpty', '    DummyEmptyOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice'];
ParallelOpenMP.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 95;  0; 0;23;  0; 93;0;0;0;0;0.00;0;['    GetCosGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCos', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cos', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
ParallelOpenMP.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 100;  1; 6;13;  53; 31;26;24;22;11;0.02;2;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
PTThreadPool.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 19;  1; 4;3;  12; 0;3;1;2;3;0.08;0;['    GetCoshGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCosh', '    CAFFE_ANONYMOUS_VARIABLE_CPUCoshGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cosh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CoshGradient', '    Forward(const std::vector &,const std::vector & X_dims,const T *dY,const T *X,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
QTensorImpl.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/quantized; 12;  1; 3;1;  8; 0;0;8;0;2;0.13;1;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)'];
QTensorImpl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/quantized; 92;  36; 11;4;  50; 0;23;22;15;11;0.72;5;['    GetCosineEmbeddingCriterionGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCosineEmbeddingCriterion', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosineEmbeddingCriterionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineEmbeddingCriterion', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineEmbeddingCriterionGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
Quantizer.h;C++;pytorch-master/pytorch-master/aten/src/ATen/quantized; 275;  94; 40;11;  132; 0;32;88;18;60;0.71;17;['    final', '    final'];['    CosineEmbeddingCriterionGradientOp(Args,...)', '    CosineEmbeddingCriterionOp(Args,...)', '    RunOnDevice'];
Scalar.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 3;  0; 1;2;  0; 0;0;0;0;0;0.00;0;['    CounterDeserializer', '    CounterSerializer'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCheckCounterDone', '    CAFFE_ANONYMOUS_VARIABLE_CPUCountDown', '    CAFFE_ANONYMOUS_VARIABLE_CPUCountUp', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateCounter', '    CAFFE_ANONYMOUS_VARIABLE_CPUResetCounter', '    CAFFE_ANONYMOUS_VARIABLE_CPURetrieveCount', '    kCountExample', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckCounterDone', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CountDown', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CountUp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResetCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RetrieveCount', '    noexcept', '    Deserialize(const BlobProto & proto,Blob *blob)', '    CounterSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~CounterSerializer'];
ScalarOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 38;  4; 4;4;  26; 0;0;0;0;0;0.15;0;['    Counter', '    final', '    final', '    final', '    final', '    final', '    final'];['    checkIfDone', '    countDown', '    Counter(T count)', '    countUp', '    reset(T init_count)', '    retrieve', '    CheckCounterDoneOp(Args,...)', '    CountDownOp(Args,...)', '    CountUpOp(Args,...)', '    CreateCounterOp(Args,...)', '    GetSingleArgument', '    ResetCounterOp(Args,...)', '    RetrieveCountOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
SmallVector.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACheckCounterDone', '    CAFFE_ANONYMOUS_VARIABLE_CUDACountDown', '    CAFFE_ANONYMOUS_VARIABLE_CUDACountUp', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateCounter', '    CAFFE_ANONYMOUS_VARIABLE_CUDAResetCounter', '    CAFFE_ANONYMOUS_VARIABLE_CUDARetrieveCount'];
SparseTensorImpl.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 119;  14; 15;4;  87; 0;45;30;98;20;0.16;14;[];['    cast(const Tensor & packed)', '    create(std::unique_ptr ptr,TensorOptions options)', '    isa(const Tensor & packed)', '    data_ptr', '    get', '    scalar_type', '    storage'];
SparseTensorImpl.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 244;  78; 33;4;  141; 0;89;60;79;52;0.55;14;[];['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    add_new_buffer(const std::string & name,torch::Tensor tensor)', '    add_new_parameter(const std::string & name,torch::Tensor tensor)', '    add_new_submodule(const std::string & name)', '    fc', '    forward(torch::Tensor x)', '    get_bias', '    Net(int64_t in,int64_t out)', '    reset', '    set_bias(torch::Tensor bias)'];
Storage.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    check_single_result(Variable,Variable result,std::string hook_name)', '    CppFunctionPreHook(const std::shared_ptr & hooks,int value_idx)', '    operator()(const variable_list & values)'];
BackendSelectRegister.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 26;  6; 9;6;  7; 0;3;7;0;4;0.86;2;[];['    CppFunctionPreHook(const std::shared_ptr & hooks,int value_idx)', '    operator()(const variable_list & values)'];
Functions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 94;  8; 12;13;  65; 0;30;42;12;15;0.12;7;[];['    TEST(CPUGenerator,TestGeneratorDynamicCast)', '    TEST(CPUGenerator,TestDefaultGenerator)', '    TEST(CPUGenerator,TestCloning)', '    TEST(CPUGenerator,TestMultithreadingGetEngineOperator)', '    TEST(CPUGenerator,TestGetSetCurrentSeed)', '    TEST(CPUGenerator,TestMultithreadingGetSetCurrentSeed)', '    TEST(CPUGenerator,TestRNGForking)', '    TEST(CPUGenerator,TestPhiloxEngineReproducibility)', '    TEST(CPUGenerator,TestPhiloxEngineOffset1)', '    TEST(CPUGenerator,TestPhiloxEngineOffset2)', '    TEST(CPUGenerator,TestPhiloxEngineOffset3)', '    TEST(CPUGenerator,TestPhiloxEngineIndex)', '    TEST(CPUGenerator,TestMT19937EngineReproducibility)', '    thread_func_get_engine_op(CPUGenerator *generator)', '    thread_func_get_set_current_seed(Generator generator)'];
LegacyTHFunctions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 28;  6; 6;4;  17; 0;0;12;0;11;0.35;0;[];[];
NativeFunctions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 53;  5; 8;29;  14; 0;2;14;50;69;0.36;51;[];[];
OpsAlreadyMovedToC10.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 38;  3; 8;6;  21; 0;5;10;3;8;0.14;4;['    C10FlagParser_caffe2_cpu_allocator_do_junk_fill', '    C10FlagParser_caffe2_cpu_allocator_do_zero_fill', '    C10FlagParser_caffe2_report_cpu_memory_usage', '    MemoryAllocationReporter'];['    alloc_cpu(size_t nbytes)', '    free_cpu(void *data)', '    GetCPUAllocator', '    GetDefaultCPUAllocator', '    memset_junk(void *data,size_t num)', '    NoDelete(void *)', '    SetCPUAllocator(at::Allocator *alloc)', '    getMemoryAllocationReporter', '    ReportAndDelete(void *ptr)', '    C10FlagParser_caffe2_cpu_allocator_do_junk_fill(const std::string & content)', '    C10FlagParser_caffe2_cpu_allocator_do_zero_fill(const std::string & content)', '    C10FlagParser_caffe2_report_cpu_memory_usage(const std::string & content)', '    allocate(size_t nbytes)', '    DefaultCPUAllocator', '    raw_deleter', '    ~DefaultCPUAllocator', '    Delete(void *ptr)', '    MemoryAllocationReporter', '    New(void *ptr,size_t nbytes)'];
SparseTypeDerived.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 52;  5; 12;20;  16; 0;7;14;0;10;0.31;3;[];['    alloc_cpu(size_t nbytes)', '    free_cpu(void *data)', '    GetCPUAllocator', '    GetDefaultCPUAllocator', '    memset_junk(void *data,size_t num)', '    NoDelete(void *)'];
TensorBody.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 566;  150; 86;21;  315; 2;80;302;72;161;0.48;51;[];['    _all_equal_numel(at::ArrayRef tensors)', '    _all_equal_numel_error(at::ArrayRef tensors)', '    _apply_preamble(ArrayRef tensors)', '    _max_dim_tensors(ArrayRef tensors)', '    apply_op', '    apply_op(int64_t numel,int64_t offset,const Op & op,Args,...)', '    collapse_dims(T *sizes,T *strides,int64_t dims,const int excludeDim)', '    CPU_tensor_apply1(Tensor tensor1,const Op op)', '    CPU_tensor_apply2(Tensor tensor1,Tensor tensor2,const Op op)', '    CPU_tensor_apply3(Tensor tensor1,Tensor tensor2,Tensor tensor3,const Op op)', '    CPU_tensor_apply4(Tensor tensor1,Tensor tensor2,Tensor tensor3,Tensor tensor4,const Op op)', '    forward(int64_t offset)', '    forward(int64_t offset,Arg & iter,Args &,...)', '    iterate(int64_t size)', '    iterate(int64_t size,Arg & iter,Args &,...)', '    iterate_continue', '    iterate_continue(Arg & iter,Args &,...)', '    iterate_overflow', '    iterate_overflow(Arg & iter,Args &,...)', '    max_dim', '    max_dim(Arg & iter,Args &,...)', '    max_iterate_size', '    max_iterate_size(Arg & iter,Args &,...)', '    sort_strides(Tensor & tensor_)', '    operator=', '    strided_tensor_iter', '    strided_tensor_iter', '    strided_tensor_iter(Tensor & tensor)', '    operator=', '    strided_tensor_iter_fixed', '    strided_tensor_iter_fixed', '    strided_tensor_iter_fixed(Tensor & tensor,bool sort_strides)', '    data', '    data_ptr', '    dim', '    ndimension', '    numel', '    permute', '    sizes', '    strides', '    vec', '    memset'];
TensorMethods.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 187;  24; 38;34;  97; 3;39;35;87;58;0.25;54;[];['    cpu_fixed_free(void *state,void *allocation)', '    cpu_fixed_malloc(void *,ptrdiff_t)', '    cpu_fixed_realloc(void *,void *,ptrdiff_t)'];
TypeDefault.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 36;  6; 9;9;  14; 0;3;12;2;13;0.43;1;[];['    createCPUGenerator(uint64_t seed_val)', '    getDefaultCPUGenerator', '    make64BitsFrom32Bits(uint32_t hi,uint32_t lo)', '    engine_', '    next_double_normal_sample_', '    next_float_normal_sample_', '    clone', '    clone_impl', '    CPUGenerator(uint64_t seed_in)', '    current_seed', '    device_type', '    engine', '    next_double_normal_sample', '    next_float_normal_sample', '    random', '    random64', '    seed', '    set_current_seed(uint64_t seed)', '    set_engine(at::mt19937 engine)', '    set_next_double_normal_sample(c10::optional randn)', '    set_next_float_normal_sample(c10::optional randn)'];
TypeDerived.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 63;  11; 13;22;  18; 0;7;16;0;10;0.61;3;[];[];
TypeDerived.h;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 38;  5; 10;9;  15; 0;3;9;2;18;0.33;1;[];[];
TensorAccessor.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    block(void *event,const Stream & stream)', '    CPUGuardImpl', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device)', '    exchangeStream(Stream s)', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device)', '    type', '    uncheckedSetDevice(Device d)'];
TensorGeometry.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 15;  1; 4;3;  8; 0;3;3;3;2;0.13;1;[];['    GetCpuId', '    CpuId', '  Static Member Variables', '    f1c_', '    f1d_', '    f7b_', '    f7c_'];
TensorGeometry.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 62;  3; 10;3;  48; 0;0;0;0;0;0.06;0;['    CpuId'];['    GetCpuId', '    acpi', '    adx', '    aes', '    apic', '    avx', '    avx2', '    avx512bw', '    avx512cd', '    avx512dq', '    avx512er', '    avx512f', '    avx512ifma', '    avx512pf', '    avx512vbmi', '    avx512vl', '    bmi1', '    bmi2', '    clflushopt', '    clfsh', '    clwb', '    cmov', '    cnxtid', '    CpuId', '    cx16', '    cx8', '    dca', '    de', '    ds', '    dscpl', '    dtes64', '    eist', '    erms', '    f16c', '    fma', '    fpu', '    fxsr', '    hle', '    htt', '    invpcid', '    mca', '    mce', '    mmx', '    monitor', '    movbe', '    mpx', '    msr', '    mtrr', '    osxsave', '    pae', '    pat', '    pbe', '    pcid', '    pclmuldq', '    pcommit', '    pdcm', '    pge', '    popcnt', '    prefetchwt1', '    pse', '    pse36', '    psn', '    rdrand', '    rdseed', '    rtm', '    sep', '    sha', '    smap', '    smep', '    smx', '    ss', '    sse', '    sse2', '    sse3', '    sse41', '    sse42', '    ssse3', '    tm', '    tm2', '    tsc', '    tscdeadline', '    vme', '    vmx', '    x2apic', '    xsave', '    xtpr'];
TensorIndexing.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 581;  128; 64;5;  402; 0;0;0;0;0;0.32;0;[];['    TEST(CpuIdTest,ShouldAlwaysHaveMMX)'];
TensorNames.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 127;  14; 20;2;  92; 0;48;23;48;22;0.15;9;[];[];
TensorNames.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 74;  27; 16;2;  31; 0;0;0;0;0;0.87;0;['    SubgraphSlicer'];['    CreateAutodiffSubgraphs(const std::shared_ptr & graph,size_t threshold)', '    inlineIfTooSmall(Node *n)', '    run(std::vector & diffGraphs)', '    scanNode(Node *consumer,AliasDb & aliasDb)', '    shouldConsiderForMerge(Node *node)', '    sortReverseTopological(ArrayRef inputs)', '    SubgraphSlicer(Block *block,std::shared_ptr graph,size_t minSubgraphSize)', '    tryMerge(Node *consumer,Node *producer,AliasDb & aliasDb)'];
TensorOptions.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    CreateAutodiffSubgraphs(const std::shared_ptr & graph,size_t threshold)'];
TensorUtils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 389;  26; 43;5;  317; 0;104;83;107;143;0.08;34;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateDB', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateDB'];
TensorUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 153;  30; 17;4;  107; 0;5;104;5;51;0.28;7;['    final'];['    CreateDBOp(const OperatorDef & operator_def,Workspace *ws)', '    CreateDBOp', '    operator=', '    RunOnDevice'];
atest.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 108;  6; 23;3;  76; 0;55;27;45;27;0.08;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACreateDB'];
backend_fallback_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 159;  29; 28;5;  99; 0;67;53;36;34;0.29;7;[];['    CreateFunctionalGraphs(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(const std::shared_ptr & graph)', '    RemoveMutation(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(Block *block)', '    AnalyzeFunctionalSubset(Node *n)', '    AnalyzeFunctionalSubset(at::ArrayRef blocks)', '    AnalyzeFunctionalSubset(Block *block)', '    CreateFunctionalGraphsImpl(Block *block)', '    FunctionalGraphSlicer(std::shared_ptr graph)', '    inlineIfTooSmall(Node *n)', '    isEmptyFunctionalGraph(Node *n)', '    nonConstNodes(Block *block,size_t *num)', '    run', '    inplaceOpVariant(Node *n)', '    listAppendFollowingListConstruct(Node *n)', '    MutationRemover(const std::shared_ptr & graph)', '    newMemoryLocation(Value *v)', '    RemoveAtenMutation(Block *block)', '    RemoveListMutation(Block *block)', '    run', '    tryMakeCreationAndMutationAtomic(Value *mutated_value,Node *mutating_op)'];
basic.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 431;  41; 52;14;  325; 0;239;135;183;138;0.13;32;[];['    CreateFunctionalGraphs(const std::shared_ptr & graph)', '    InlineFunctionalGraphs(const std::shared_ptr & graph)', '    RemoveMutation(const std::shared_ptr & graph)'];
complex_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 28;  0; 3;2;  23; 0;15;5;15;3;0.00;3;['    C10FlagParser_caffe2_workspace_stack_debug'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateScope', '    CAFFE_ANONYMOUS_VARIABLE_CPUHasScope', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateScope', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HasScope', '    C10FlagParser_caffe2_workspace_stack_debug(const std::string & content)', '    RunOnDevice', '    RunOnDevice', '    _typeMetaDataInstance'];
cpu_generator_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 235;  72; 24;8;  134; 0;85;54;59;55;0.54;15;['    WorkspaceStack', '    final', '    final'];['    checkBindingsMatch(const std::unordered_map & bindings,const std::unordered_map & test_bindings)', '    checkStack', '    clear', '    empty', '    popGradientWorkspace(Workspace *parent_ws,const std::unordered_map & grad_blob_bindings)', '    pushForwardWorkspace(Workspace *parent_ws)', '    pushForwardWorkspace(Workspace *parent_ws,const std::unordered_map & blob_bindings)', '    reuseLastForwardWorkspace(Workspace *parent_ws)', '    reuseLastForwardWorkspace(Workspace *parent_ws,const std::unordered_map & blob_bindings)', '    WorkspaceStack', '    CreateScopeOp(Args,...)', '    HasScopeOp(Args,...)', '    RunOnDevice'];
cpu_rng_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 261;  11; 59;11;  180; 0;0;0;0;3;0.06;0;['    SwapBestPathOp', '    ViterbiPathOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSwapBestPath', '    CAFFE_ANONYMOUS_VARIABLE_CPUViterbiPath', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SwapBestPath', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ViterbiPath', '    ColwiseMaxAndArg(const float *mat,int32_t N,int32_t D,float *colMax,int32_t *argMax)', '    RowwiseMaxAndArg(const float *mat,int32_t N,int32_t D,float *rowMax,int32_t *argMax)', '    RunOnDevice', '    SwapBestPathOp(Args,...)', '    AddColToMat(const TensorCPU & mat,const TensorCPU & col,TensorCPU *result)', '    GatherRow(const TensorCPU & data,int32_t rowIndex,int32_t block_size,int32_t block_bytesize,TensorCPU *outRow)', '    RunOnDevice', '    ViterbiPathOp(Args,...)'];
cuda_cudnn_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 14;  0; 3;5;  6; 0;2;1;5;3;0.00;1;[];['    cross(const Tensor & input,const Tensor & other,const c10::optional dimension)', '    cross_out(Tensor & out,const Tensor & input,const Tensor & other,const c10::optional dimension)'];
cuda_stream_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 303;  23; 71;22;  188; 0;148;74;133;73;0.12;15;[];['    cross_stub', '    cross_stub', '    operator='];
cuda_tensor_interop_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 162;  8; 26;7;  121; 0;0;0;0;1;0.07;0;['    GetLabelCrossEntropyGradient', '    GetCrossEntropyGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULabelCrossEntropy', '    CAFFE_ANONYMOUS_VARIABLE_CPULabelCrossEntropyGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUCrossEntropy', '    CAFFE_ANONYMOUS_VARIABLE_CPUCrossEntropyGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMakeTwoClass', '    CAFFE_ANONYMOUS_VARIABLE_CPUMakeTwoClassGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyWithLogits', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyWithLogitsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSigmoidCrossEntropyWithLogits', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSigmoidCrossEntropyWithLogitsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LabelCrossEntropy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LabelCrossEntropyGradient', '    sigmoid_partition(float lgt)', '    sigmoid_xent_backward(float lgt,float tgt)', '    sigmoid_xent_backward_with_log_d_trick(float lgt,float tgt)', '    sigmoid_xent_forward(float lgt,float tgt)', '    sigmoid_xent_forward_with_log_d_trick(float lgt,float tgt)', '    unjoined_sigmoid_xent_backward(float lgt,float tgt)', '    unjoined_sigmoid_xent_forward(float lgt,float tgt)', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CrossEntropy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CrossEntropyGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MakeTwoClass', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MakeTwoClassGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyWithLogits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyWithLogitsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSigmoidCrossEntropyWithLogits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSigmoidCrossEntropyWithLogitsGradient', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
Dimname_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 66;  0; 8;4;  54; 0;37;15;32;15;0.00;5;['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final'];['    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    kLOG_THRESHOLD', '    CrossEntropyGradientOp(Args,...)', '    CrossEntropyOp(Args,...)', '    LabelCrossEntropyGradientOp(Args,...)', '    LabelCrossEntropyOp(Args,...)', '    MakeTwoClassGradientOp(Args,...)', '    MakeTwoClassOp(Args,...)', '    RunOnDevice', '    SigmoidCrossEntropyWithLogitsGradientOp(Args,...)', '    SigmoidCrossEntropyWithLogitsOp(Args,...)', '    WeightedSigmoidCrossEntropyWithLogitsGradientOp(Args,...)', '    WeightedSigmoidCrossEntropyWithLogitsOp(Args,...)', '    ~CrossEntropyGradientOp', '    ~CrossEntropyOp', '    ~LabelCrossEntropyGradientOp', '    ~LabelCrossEntropyOp', '    ~MakeTwoClassGradientOp', '    ~MakeTwoClassOp', '    ~WeightedSigmoidCrossEntropyWithLogitsGradientOp', '    ~WeightedSigmoidCrossEntropyWithLogitsOp'];
dlconvertor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 32;  0; 10;6;  16; 0;11;8;6;9;0.00;2;[];['    apply_cross(Tensor & result,const Tensor & a,const Tensor & b,const int64_t dim)', '    cross_kernel_impl(Tensor & result,const Tensor & a,const Tensor & b,const int64_t dim)'];
extension_backend_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 55;  1; 10;5;  39; 0;29;18;18;11;0.03;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCTCBeamSearchDecoder', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTCBeamSearchDecoder', '    getTensorDataPtr(const Tensor & tensor,int t,int n)', '    RunOnDevice'];
ivalue_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 144;  3; 12;4;  126; 0;83;47;56;60;0.02;8;['    CTCBeamSearchDecoderOp'];['    CTCBeamSearchDecoderOp(Args,...)', '    RunOnDevice'];
memory_format_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 192;  20; 26;2;  144; 0;127;19;119;24;0.14;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCTCGreedyDecoder', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTCGreedyDecoder', '    getTensorDataPtr(const Tensor & tensor,int t,int n)', '    RunOnDevice'];
memory_overlapping_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 73;  0; 9;2;  62; 0;30;26;26;27;0.00;8;['    CTCGreedyDecoderOp'];['    CTCGreedyDecoderOp(Args,...)', '    RunOnDevice'];
native_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 222;  30; 34;9;  149; 0;108;61;73;58;0.20;11;['    GetCTCGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCTC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CTC', '    workspaceInfo(const CPUContext &)', '    vector', '    GetGradientDefs'];
pow_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 290;  1; 56;8;  225; 0;164;86;74;79;0.00;23;['    final'];['    workspaceInfo(const Context & context)', '    CTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike'];
quantized_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 148;  14; 15;10;  111; 0;88;66;37;59;0.13;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACTC', '    workspaceInfo(const CUDAContext & context)'];
rng_test.h;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 167;  0; 17;8;  142; 0;0;0;0;0;0.00;0;['    GetCubeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCube', '    CAFFE_ANONYMOUS_VARIABLE_CPUCubeGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Cube', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CubeGradient', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *X,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
scalar_tensor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 279;  36; 27;18;  200; 0;113;58;101;64;0.18;5;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)'];
scalar_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 130;  6; 20;11;  95; 0;70;33;76;41;0.06;4;[];['    createCublasHandle(cublasHandle_t *handle)', '    destroyCublasHandle(cublasHandle_t handle)', '    getCurrentCUDABlasHandle'];
tensor_iterator_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 228;  9; 20;92;  107; 0;79;38;280;321;0.08;60;[];['    cudnn_is_available', '    device_count', '    is_available'];
test_assert.h;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 67;  5; 11;44;  8; 1;4;3;4;2;0.63;1;[];['    cudnn_is_available', '    device_count', '    is_available'];
main.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test/test_install; 5;  0; 1;1;  3; 0;1;1;1;1;0.00;1;[];[];
thread_init_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 43;  5; 7;6;  25; 0;13;10;12;71;0.20;2;['    PrioritizeLoad', '    ScopedVarName'];['    as_int(const Expr *expr)', '    getMajorMinor(const cudaDeviceProp *const prop,int & major,int & minor)', '    is_zero(const Expr *expr)', '    nvrtc', '    cudaDtypeCppString(const Dtype & dtype)', '    CudaSetContext(CUcontext pctx)', '    AddMemLoadsFromList(Stmt *stmt)', '    mutate(const Load *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const IfThenElse *v)', '    PopList', '    Process(Stmt *stmt)', '    PushList', '    call(const std::vector & args)', '    CompileToNVRTC(const std::string & code,const std::string & func_name)', '    GetUniqueFuncName(const std::string & func_prefix)', '    Initialize', '    visit(const For *v)', '    visit(const Intrinsics *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const LetStmt *v)', '    visit(const IfThenElse *v)', '    ScopedVarName(VarNameMap *mapping,const Var *var,const std::string & name)', '    ScopedVarName(UniqueNameManager *manager,const Var *var,const std::string & name)'];
undefined_tensor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 52;  3; 10;4;  35; 0;9;26;8;30;0.09;1;['    CudaCodeGen', '    CudaPrinter'];['    call(const std::vector & args)', '    CompileToNVRTC(const std::string & code,const std::string & func_name)', '    CudaCodeGen(Stmt *stmt,Ts,...)', '    CudaCodeGen(Stmt *stmt,const std::vector & buffer_args,at::Device device)', '    GetUniqueFuncName(const std::string & func_prefix)', '    Initialize', '    name_manager', '    operator()(const Ts &,...)', '    os', '    ~CudaCodeGen', '    CudaPrinter(std::ostream *os,bool has_random)', '    gpu_block_extents', '    gpu_thread_extents', '    rand_func', '    visit(const For *v)', '    visit(const Intrinsics *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const LetStmt *v)', '    visit(const IfThenElse *v)', '    visit(const Cast *v)', '    name_manager', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)'];
variant_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 67;  8; 9;2;  50; 0;21;16;20;17;0.16;8;[];['    TEST(CUDNNTest,CUDNNTestCUDA)'];
weakref_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 65;  4; 7;6;  48; 0;33;13;26;16;0.08;3;[];['    cuda_enabled'];
wrapdim_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 43;  1; 8;2;  32; 0;21;11;16;12;0.03;5;[];['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    sigmoid_add(torch::Tensor x,torch::Tensor y)'];
xla_tensor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 33;  0; 6;2;  25; 0;9;12;8;11;0.00;5;[];['    simple_mappable', '    CudaFuseGraph(std::shared_ptr & graph)', '    insert_guard', '    insert_guard', '    insert_guard', '    PeepholeOptimizeShapeExpressions(Block *block)', '    registerCudaFuseGraph', '    broadcastSizes(at::ArrayRef sizes)', '    isSimpleMap(Node *node)', '    allUsersAreThisConsumerOrCalcSizes(Node *consumer,Value *producer)', '    broadcast_tensors(value_list inputs)', '    buildShapeExpressions(Node *fusion_group)', '    calculatesSize(Node *node)', '    canFuseChunk(Node *consumer,Value *producer)', '    canFuseWithConcat(Value *producer,Node *before_check)', '    createFusedConcat(Node *node)', '    createSingletonCudaFusionGroup(Node *n)', '    findFusedChunk(Node *group,Value *input)', '    fuseChunk(Node *consumer,Value *producer)', '    fuseChunkByReusingExistingFusedChunk(Node *group,Node *chunk,Node *existingFusedChunk)', '    fuseConcats', '    getSubgraph(Node *n)', '    GraphFuser(Block *block,std::shared_ptr graph)', '    GraphFuser(Block *block,std::shared_ptr graph,FusionCallback callback,Symbol kind)', '    insertExplicitBroadcast(Node *node)', '    isFusable(Node *node)', '    isFusableCatNode(Node *node)', '    isFusableDefault(Node *node)', '    isFusableDevice(Value *v)', '    isFusableMap(Node *node)', '    mergeCudaFusionGroups(Node *consumer_group,Node *producer_group)', '    mergeNodeIntoGroup(Node *group,Node *n)', '    optimizeFusedGraphs', '    promoteChunkToBroadcastingChunk(Node *chunk)', '    refreshAliasDb', '    removeOutputsUsedOnlyInSize(Node *fusion_group)', '    replaceIntermediateBroadcastingChunks', '    run', '    scanNode(Node *consumer)', '    scanNodeForChunks(Node *consumer)', '    setInputArgLimit(size_t limit)', '    sortReverseTopological(ArrayRef inputs)', '    tensorInputs(Node *node)', '    tryFuse(Node *consumer,Value *producer)', '    tryToMoveChunk(Node *consumer,Value *producer)', '    usedOnlyInSize(Value *v)'];
ThreadLocalDebugInfo.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 46;  8; 11;4;  24; 0;2;15;2;10;0.33;4;[];['    CudaFuseGraph(std::shared_ptr & graph)', '    registerCudaFuseGraph'];
Utils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 15;  1; 3;5;  7; 0;2;4;2;3;0.14;1;['    CudaHalfChecker'];['    hasHalf', '    hasHalf_', '    visit(const Load *v)', '    visit(const Store *v)', '    dtype'];
Utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 122;  18; 14;17;  74; 0;0;0;0;0;0.24;0;[];['    cuda_lazy_init', '    set_run_yet_variable_to_false'];
Version.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 14;  2; 6;1;  6; 0;0;0;0;0;0.33;0;[];['    maybe_initialize_cuda(const at::TensorOptions & options)', '    cuda_lazy_init', '    set_run_yet_variable_to_false'];
WrapDimUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 82;  10; 11;4;  58; 0;0;0;0;0;0.17;0;['    NCCLContext', '    ncclTypeWrapper', '    ncclTypeWrapper'];['    gContextsMutex', '    destroyContexts', '    getDevices(const NCCLExecution & ex)', '    getNCCLContext(const NCCLExecution & ex)', '    ncclKey(const NCCLExecution & ex)', '    runNCCL(const NCCLExecution & ex,InitF,F)', '    NCCLContext(const NCCLExecution & ex)', '    ~NCCLContext', '    AllGather(const NCCLExecution & ex)', '    AllReduce(const NCCLExecution & ex)', '    Reduce(const NCCLExecution & ex)', '    ReduceScatter(const NCCLExecution & ex)'];
WrapDimUtilsMulti.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 26;  2; 6;5;  13; 0;8;6;9;5;0.15;1;['    NCCL'];['    destroyContexts', '    AllGather(const NCCLExecution & ex)', '    AllReduce(const NCCLExecution & ex)', '    Broadcast(const NCCLExecution & ex)', '    Reduce(const NCCLExecution & ex)', '    ReduceScatter(const NCCLExecution & ex)', '    device', '    dst', '    src', '    root', '    stream', '    stream_gpu_id'];
THBlas.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 19;  0; 0;4;  0; 16;0;0;0;0;0.00;0;['    final', '    final', '    final', '    final', '    final', '    NCCLBaseOp'];['    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLAllGather', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDANCCLReduceScatter', '    AllInputsAre(OperatorBase *op)', '    getNCCLElements(OperatorBase *op,const CUDAContext & context)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLAllGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLAllreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLBroadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLReduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCCLReduceScatter', '    CostInference(const OperatorDef & def,const vector & inputs)', '    ShapeInference(const OperatorDef & def,const std::vector & in)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    NCCLBaseOp(const OperatorDef & operator_def,Workspace *ws)', '    ~NCCLBaseOp'];
THLapack.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 107;  8; 11;40;  36; 31;6;18;6;17;0.22;6;['    CudaProfileInitializeOp', '    CudaProfileStartOp', '    CudaProfileStopOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileInitialize', '    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileStart', '    CAFFE_ANONYMOUS_VARIABLE_CPUCudaProfileStop', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileInitialize', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileStart', '    CAFFE_ANONYMOUS_VARIABLE_CUDACudaProfileStop', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileInitialize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileStart', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CudaProfileStop', '    CudaProfileInitializeOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    ~CudaProfileInitializeOp', '    CudaProfileStartOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    CudaProfileStopOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)'];
THLapack.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 21;  0; 0;4;  0; 18;0;0;0;0;0.00;0;[];[];
THStorage.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 71;  0; 0;20;  0; 68;0;0;0;0;0.00;0;[];['    cuda_stream', '    cuda_stream', '    i', '    streams', '    TEST(TestStream,CopyAndMoveTest)', '    TEST(TestStream,GetAndSetTest)', '    TEST(TestStream,MultithreadGetAndSetTest)', '    TEST(TestStream,CUDAGuardTest)', '    TEST(TestStream,StreamPoolTest)', '    TEST(TestStream,MultiGPUTest)', '    TEST(TestStream,CUDAEventSyncTest)', '    TEST(TestStream,CrossDeviceTest)', '    TEST(TestStream,GenericInlineCUDAEventTest)', '    TEST(TestStream,GenericVirtualCUDAEventTest)', '    thread_fun(at::optional & cur_thread_stream)'];
THStorageCopy.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 48;  2; 5;19;  19; 4;15;14;44;44;0.11;11;[];[];
THStorageCopy.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 27;  0; 0;10;  0; 24;0;0;0;0;0.00;0;[];['    _cublasAdjustLdLevel2(int64_t m,int64_t n,int64_t *lda)', '    _cublasAdjustLdLevel3(char transa,char transb,int64_t m,int64_t n,int64_t k,int64_t *lda,int64_t *ldb,int64_t *ldc)', '    _cublasOpFromChar(char op)', '    _cublasGetErrorEnum(cublasStatus_t error)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *a,int64_t lda,const double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *a,int64_t lda,const float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    gemv(char trans,int64_t m,int64_t n,double alpha,const double *a,int64_t lda,const double *x,int64_t incx,double beta,double *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,float alpha,const float *a,int64_t lda,const float *x,int64_t incx,float beta,float *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *x,int64_t incx,at::Half beta,at::Half *y,int64_t incy)'];
THTensor.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 100;  13; 20;16;  51; 1;0;51;0;61;0.25;0;[];['    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,Dtype alpha,const Dtype *a,int64_t lda,const Dtype *b,int64_t ldb,Dtype beta,Dtype *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *a,int64_t lda,const double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *a,int64_t lda,const float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    gemv(char trans,int64_t m,int64_t n,Dtype alpha,const Dtype *a,int64_t lda,const Dtype *x,int64_t incx,Dtype beta,Dtype *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,double alpha,const double *a,int64_t lda,const double *x,int64_t incx,double beta,double *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,float alpha,const float *a,int64_t lda,const float *x,int64_t incx,float beta,float *y,int64_t incy)', '    gemv(char trans,int64_t m,int64_t n,at::Half alpha,const at::Half *a,int64_t lda,const at::Half *x,int64_t incx,at::Half beta,at::Half *y,int64_t incy)'];
THTensor.hpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 16;  4; 5;4;  3; 1;0;3;0;2;1.33;0;['    THCCachingAllocator'];['    assertValidDevice(int device)', '    BlockComparator(const Block *a,const Block *b)', '    format_size(uint64_t size)', '    cacheInfo(int dev_id,size_t *cachedAndFree,size_t *largestBlock)', '    emptyCache', '    get', '    getBaseAllocation(void *ptr,size_t *size)', '    getDeviceStats(int device)', '    getFreeMutex', '    getIpcDevPtr(std::string handle)', '    raw_alloc(size_t nbytes)', '    raw_alloc_with_stream(size_t nbytes,cudaStream_t stream)', '    raw_delete(void *ptr)', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    reset_accumulated_stat(Stat & stat)', '    reset_peak_stat(Stat & stat)', '    resetAccumulatedStats(int device)', '    resetPeakStats(int device)', '    snapshot', '    update_stat(Stat & stat,int64_t amount)', '    update_stat_array(StatArray & stat_array,int64_t amount,const StatTypes & stat_types)', '    RegistryName', '    find_free_block', '    Block(int device,cudaStream_t stream,size_t size,BlockPool *pool,void *ptr)', '    Block(int device,cudaStream_t stream,size_t size)', '    is_split', '    allocate(size_t size)', '    raw_deleter', '    cache_info_aux(BlockPool & blocks,int dev_id,size_t *total,size_t *largest)', '    cacheInfo(int dev_id,size_t *total,size_t *largest)', '    cuda_malloc_with_retry(int device,void **devPtr,size_t size)', '    emptyCache', '    find_allocated_block(void *ptr)', '    free(void *ptr)', '    free_block(Block *block)', '    free_blocks(BlockPool & blocks,BlockPool::iterator it,BlockPool::iterator end)', '    free_cached_blocks(int device)', '    get_all_blocks', '    get_allocation_size(size_t size)', '    get_pool(size_t size)', '    get_stat_type_for_pool(const BlockPool & pool)', '    get_stats_for_device(int device)', '    getBaseAllocation(void *ptr,size_t *outSize)', '    getCudaFreeMutex', '    getStatsForDevice(int dev_id)', '    insert_events(Block *block)', '    malloc(void **devPtr,size_t size,cudaStream_t stream)', '    process_events', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    resetAccumulatedStats(int dev_id)', '    resetPeakStats(int dev_id)', '    round_size(size_t size)', '    should_split(const Block *block,size_t size)', '    snapshot', '    synchronize_and_free_events(optional device)', '    THCCachingAllocator', '    try_merge_blocks(Block *dst,Block *src,BlockPool & pool)'];
THTensorApply.hpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 369;  23; 13;336;  6; 14;0;0;0;0;3.83;0;['    CUDAOutOfMemoryError', '    FreeMemoryCallback'];['    cacheInfo(int dev_id,size_t *cachedAndFree,size_t *largestBlock)', '    emptyCache', '    get', '    getBaseAllocation(void *ptr,size_t *size)', '    getDeviceStats(int device)', '    getFreeMutex', '    getIpcDevPtr(std::string handle)', '    raw_alloc(size_t nbytes)', '    raw_alloc_with_stream(size_t nbytes,cudaStream_t stream)', '    raw_delete(void *ptr)', '    recordStream(const DataPtr & ptr,cuda::CUDAStream stream)', '    resetAccumulatedStats(int device)', '    resetPeakStats(int device)', '    snapshot', '    RegistryName', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)', '    Execute', '    ~FreeMemoryCallback'];
THTensorFastGetSet.hpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 49;  0; 12;4;  33; 1;11;11;11;11;0.00;11;[];['    getCUDADeviceAllocator', '    getCurrentDeviceProperties', '    getDeviceProperties(int64_t device)', '    initCUDAContextVectors', '    initDeviceProperty(DeviceIndex device_index)', '    warp_size'];
THTensorFill.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 30;  0; 4;5;  21; 1;5;4;91;10;0.00;2;[];['    getCUDADeviceAllocator', '    getCurrentCUDABlasHandle', '    getCurrentCUDASparseHandle', '    getCurrentDeviceProperties', '    getDeviceProperties(int64_t device)', '    getNumGPUs', '    is_available', '    warp_size'];
THTensorFill.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 8;  0; 2;4;  2; 1;0;2;0;2;0.00;0;[];['    getDeviceFromPtr(void *ptr)'];
THTensorLapack.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 12;  0; 2;4;  6; 1;0;6;0;6;0.00;0;[];['    block(const CUDAStream & stream)', '    createEvent(DeviceIndex device_index)', '    CUDAEvent(DeviceIndex device_index,const cudaIpcEventHandle_t *handle)', '    CUDAEvent(const CUDAEvent &)', '    CUDAEvent(CUDAEvent)', '    device', '    device_index', '    elapsed_time(const CUDAEvent & other)', '    event', '    ipc_handle(cudaIpcEventHandle_t *handle)', '    isCreated', '    moveHelper(CUDAEvent)', '    operator cudaEvent_t', '    operator=(const CUDAEvent &)', '    operator=(CUDAEvent)', '    query', '    record', '    record(const CUDAStream & stream)', '    recordOnce(const CUDAStream & stream)', '    synchronize', '    ~CUDAEvent', '    operator<(const CUDAEvent & left,const CUDAEvent & right)', '    CUDAEvent', '    CUDAEvent(unsigned int flags)', '    isCreated'];
THTensorMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 381;  35; 59;16;  277; 1;205;43;124;42;0.13;6;[];[];
THTensorMath.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 69;  1; 19;16;  26; 9;0;26;0;26;0.04;0;[];['    current_device', '    device_count', '    set_device(DeviceIndex device)'];
THTensorRandom.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 280;  0; 4;25;  0; 261;0;0;0;0;0.00;0;[];['    initCUDAGenVector', '    createCUDAGenerator(DeviceIndex device_index)', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    clone', '    clone_impl', '    CUDAGenerator(DeviceIndex device_index)', '    current_seed', '    device_type', '    philox_engine_inputs(uint64_t increment)', '    philox_offset_per_thread', '    seed', '    set_current_seed(uint64_t seed)', '    set_philox_offset_per_thread(uint64_t offset)'];
THTensorRandom.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 19;  0; 4;10;  0; 6;0;0;0;0;0.00;0;[];['    createCUDAGenerator(DeviceIndex device_index)', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    device_type', '    clone', '    clone_impl', '    CUDAGenerator(DeviceIndex device_index)', '    current_seed', '    philox_engine_inputs(uint64_t increment)', '    philox_offset_per_thread', '    seed', '    set_current_seed(uint64_t seed)', '    set_philox_offset_per_thread(uint64_t offset)', '    ~CUDAGenerator'];
THVector.h;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 31;  0; 0;9;  0; 28;0;0;0;0;0.00;0;[];['    CUDAGuard(DeviceIndex device_index)', '    CUDAGuard(Device device)', '    CUDAGuard', '    CUDAGuard', '    CUDAGuard', '    current_device', '    operator=', '    operator=', '    original_device', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    CUDAStreamGuard', '    CUDAStreamGuard(Stream stream)', '    CUDAStreamGuard', '    CUDAStreamGuard', '    current_device', '    current_stream', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    current_device', '    operator=', '    operator=', '    OptionalCUDAGuard', '    OptionalCUDAGuard', '    OptionalCUDAGuard', '    OptionalCUDAGuard(optional device_opt)', '    OptionalCUDAGuard(optional device_index_opt)', '    original_device', '    reset', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_stream', '    operator=', '    operator=', '    OptionalCUDAStreamGuard', '    OptionalCUDAStreamGuard(Stream stream)', '    OptionalCUDAStreamGuard(optional stream_opt)', '    OptionalCUDAStreamGuard', '    OptionalCUDAStreamGuard', '    original_stream', '    reset', '    reset_stream(Stream stream)'];
THVectorDispatch.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 89;  20; 13;30;  22; 19;8;21;16;13;0.91;3;[];[];
TH.h;C++;pytorch-master/pytorch-master/aten/src/TH; 21;  0; 5;16;  0; 1;0;0;0;0;0.00;0;[];['    cs(s)', '    cuda_stream', '    cuda_stream', '    block(void *event,const Stream & stream)', '    createEvent(cudaEvent_t *cuda_event,const EventFlag flag)', '    CUDAGuardImpl', '    CUDAGuardImpl(DeviceType t)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDefaultStream(Device d)', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)'];
THAllocator.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 566;  14; 55;57;  219; 256;123;57;177;38;0.06;19;[];['    load_nvrtc', '    batchnormMinEpsilonCuDNN', '    compiledWithCuDNN', '    compiledWithMIOpen', '    cuFFTClearPlanCache(int64_t device_index)', '    cuFFTGetPlanCacheMaxSize(int64_t device_index)', '    cuFFTGetPlanCacheSize(int64_t device_index)', '    cuFFTSetPlanCacheMaxSize(int64_t device_index,int64_t max_size)', '    current_device', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    getDevceIndexWithPrimaryContext', '    getDeviceFromPtr(void *data)', '    getNumGPUs', '    getPinnedMemoryAllocator', '    hasCUDA', '    hasCuDNN', '    hasMAGMA', '    hasPrimaryContext(int64_t device_index)', '    initCUDA', '    isPinnedPtr(void *data)', '    nvrtc', '    showConfig', '    supportsDepthwiseConvolutionWithCuDNN', '    supportsDilatedConvolutionWithCuDNN', '    versionCuDNN'];
THBlas.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 7;  0; 2;5;  0; 0;0;0;0;0;0.00;0;[];['    batchnormMinEpsilonCuDNN', '    compiledWithCuDNN', '    compiledWithMIOpen', '    CUDAHooks(at::CUDAHooksArgs)', '    cuFFTClearPlanCache(int64_t device_index)', '    cuFFTGetPlanCacheMaxSize(int64_t device_index)', '    cuFFTGetPlanCacheSize(int64_t device_index)', '    cuFFTSetPlanCacheMaxSize(int64_t device_index,int64_t max_size)', '    current_device', '    getDefaultCUDAGenerator(DeviceIndex device_index)', '    getDevceIndexWithPrimaryContext', '    getDeviceFromPtr(void *data)', '    getNumGPUs', '    getPinnedMemoryAllocator', '    hasCUDA', '    hasCuDNN', '    hasMAGMA', '    hasPrimaryContext(int64_t device_index)', '    initCUDA', '    isPinnedPtr(void *data)', '    nvrtc', '    showConfig', '    supportsDepthwiseConvolutionWithCuDNN', '    supportsDilatedConvolutionWithCuDNN', '    versionCuDNN'];
THBlas.h;C++;pytorch-master/pytorch-master/aten/src/TH; 14;  0; 5;9;  0; 0;0;0;0;0;0.00;0;[];['    getCUDAHooks', '    RegistryName'];
THBlasUtils.h;C++;pytorch-master/pytorch-master/aten/src/TH; 114;  4; 17;54;  39; 0;5;39;35;39;0.10;35;[];[];
THDiskFile.h;C++;pytorch-master/pytorch-master/aten/src/TH; 19;  0; 5;4;  10; 0;0;10;0;10;0.00;0;[];[];
THFile.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 158;  0; 24;40;  94; 0;46;46;79;77;0.00;70;[];[];
THFile.h;C++;pytorch-master/pytorch-master/aten/src/TH; 93;  4; 13;4;  73; 0;0;73;0;73;0.05;0;[];[];
THGeneral.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 213;  16; 36;18;  143; 5;81;38;68;38;0.11;14;[];[];
THGenerateAllTypes.h;C++;pytorch-master/pytorch-master/aten/src/TH; 17;  0; 3;14;  0; 1;0;0;0;0;0.00;0;['    final'];['    CUDAMultiStreamGuard(ArrayRef streams)', '    CUDAMultiStreamGuard', '    CUDAMultiStreamGuard', '    operator=', '    operator=', '    original_streams', '    ~CUDAMultiStreamGuard'];
THGenerateBFloat16Type.h;C++;pytorch-master/pytorch-master/aten/src/TH; 19;  0; 2;17;  0; 0;0;0;0;0;0.00;0;[];['    initCudartBindings(PyObject *module)'];
THGenerateByteType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;['    StreamIdType'];['    check_gpu(DeviceIndex device_index)', '    CUDAStream_getStreamId(const LeakyStreamInternals *ptr)', '    get_idx(std::atomic & counter)', '    initCUDAStreamsOnce', '    initDeviceStreamState(DeviceIndex device_index)', '    initGlobalStreamState', '    pointer_within(const T *ptr,const A & arr)', '    streamIdIndex(StreamId s)', '    streamIdType(StreamId s)', '    CUDAStream_fromInternals(const LeakyStreamInternals *ptr)', '    CUDAStream_internals(CUDAStream s)', '    getCurrentCUDAStream(DeviceIndex device_index)', '    getDefaultCUDAStream(DeviceIndex device_index)', '    getStreamFromPool(const bool isHighPriority,DeviceIndex device_index)', '    makeStreamId(StreamIdType st,size_t si)', '    operator<<(std::ostream & stream,StreamIdType s)', '    operator<<(std::ostream & stream,const CUDAStream & s)', '    setCurrentCUDAStream(CUDAStream stream)', '    device_guard', '    i', '    i', '    i', '    stream', '    ~LeakyStreamInternals'];
THGenerateCharType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;['    CUDAStream'];['    getCurrentCUDAStream(DeviceIndex device_index)', '    getDefaultCUDAStream(DeviceIndex device_index)', '    getStreamFromPool(const bool isHighPriority,DeviceIndex device_index)', '    operator<<(std::ostream & stream,const CUDAStream & s)', '    setCurrentCUDAStream(CUDAStream stream)', '    guard', '    guard', '    guard', '    priority_range', '    unpack(uint64_t bits)', '    CUDAStream(Stream stream)', '    CUDAStream(Unchecked,Stream stream)', '    device', '    device_index', '    id', '    operator cudaStream_t', '    operator Stream', '    operator!=(const CUDAStream & other)', '    operator==(const CUDAStream & other)', '    pack', '    priority', '    query', '    stream', '    synchronize', '    unwrap', '    operator()(c10::cuda::CUDAStream s)'];
THGenerateDoubleType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;[];['    TEST(CUDATest,SmokeTest)'];
THGenerateFloatTypes.h;C++;pytorch-master/pytorch-master/aten/src/TH; 17;  0; 3;14;  0; 6;0;0;0;0;0.00;0;[];['    c10_cuda_private_test', '    c10_cuda_test', '    has_cuda_gpu'];
THGenerateHalfType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 19;  0; 2;17;  0; 1;0;0;0;0;0.00;0;[];['    c10_cuda_test'];
THGenerateIntType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;[];['    cudaNumDevices', '    cudaSleep(at::cuda::CUDAStream & stream,uint64_t clocks)'];
THGenerateLongType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;[];['    _atan__cuda(Tensor & self)', '    _atan_out_cuda(Tensor & result,const Tensor & self)', '    _clamp__cuda(Tensor & self,optional min,optional max)', '    _clamp_max__cuda(Tensor & self,Scalar max)', '    _clamp_max_out_cuda(Tensor & result,const Tensor & self,Scalar max)', '    _clamp_min__cuda(Tensor & self,Scalar min)', '    _clamp_min_out_cuda(Tensor & result,const Tensor & self,Scalar min)', '    _clamp_out_cuda(Tensor & result,const Tensor & self,optional min,optional max)', '    _cos__cuda(Tensor & self)', '    _cos_out_cuda(Tensor & result,const Tensor & self)', '    _cosh__cuda(Tensor & self)', '    _cosh_out_cuda(Tensor & result,const Tensor & self)', '    _erf__cuda(Tensor & self)', '    _erf_out_cuda(Tensor & result,const Tensor & self)', '    _erfc__cuda(Tensor & self)', '    _erfc_out_cuda(Tensor & result,const Tensor & self)', '    _exp__cuda(Tensor & self)', '    _exp_out_cuda(Tensor & result,const Tensor & self)', '    _tan__cuda(Tensor & self)', '    _tan_out_cuda(Tensor & result,const Tensor & self)', '    _tanh__cuda(Tensor & self)', '    _tanh_out_cuda(Tensor & result,const Tensor & self)'];
THGenerateQInt32Type.h;C++;pytorch-master/pytorch-master/aten/src/TH; 24;  0; 2;22;  0; 2;0;0;0;0;0.00;0;[];['    check_device(ArrayRef ts)'];
THGenerateQInt8Type.h;C++;pytorch-master/pytorch-master/aten/src/TH; 24;  0; 2;22;  0; 2;0;0;0;0;0.00;0;[];[];
THGenerateQUInt8Type.h;C++;pytorch-master/pytorch-master/aten/src/TH; 24;  0; 2;22;  0; 2;0;0;0;0;0.00;0;[];[];
THGenerateShortType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;[];['    cudnn_relu(const torch::Tensor & inputs,const torch::Tensor & outputs)', '    cudnn_relu_check(const torch::Tensor & inputs,const torch::Tensor & outputs)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)'];
THGenerator.hpp;C++;pytorch-master/pytorch-master/aten/src/TH; 39;  20; 5;2;  16; 0;0;14;0;14;1.25;0;['    CuDNNState', '    CuDNNWrapper'];['    f(this)', '    cudnn_states', '    after_', '    before_', '    cudnn_handle', '    cudnn_handle_', '    CuDNNState(size_t gpu_id)', '    CuDNNState', '    execute(cudaStream_t stream,F)', '    gpu_id_', '    operator=', '    stream_', '    workspace', '    ~CuDNNState', '    clear', '    data_', '    get(size_t nbytes)', '    nbytes_', '    reset', '    ~CuDNNWorkspace', '    CuDNNWrapper(CUDAContext *context)', '    CuDNNWrapper', '    inline_cudnn_handle', '    operator=', '    with_cudnn_state(size_t state_idx,F)', '    cudnn_handle', '    New'];
THLapack.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 4;  0; 1;3;  0; 0;0;0;0;1;0.00;0;['    CuFFTConfig', '    CuFFTParamsLRUCache'];['    is_pow_of_two(int64_t x)', '    setCuFFTParams(CuFFTParams *params,const Tensor & input,int64_t signal_ndim,bool complex_input,bool complex_output,IntArrayRef checked_signal_sizes,bool onesided)', '    cufft_clear_plan_cache_impl(int64_t device_index)', '    cufft_get_plan_cache_max_size_impl(int64_t device_index)', '    cufft_get_plan_cache_size_impl(int64_t device_index)', '    cufft_set_plan_cache_max_size_impl(int64_t device_index,int64_t max_size)', '    static_assert(CUFFT_MAX_PLAN_NUM,)', '    static_assert(CUFFT_DEFAULT_CACHE_SIZE,)', '    CuFFTConfig', '    CuFFTConfig(Tensor & input,int64_t signal_ndim,bool complex_input,bool complex_output,IntArrayRef checked_signal_sizes,bool onesided,IntArrayRef output_sizes)', '    operator=', '    plan', '    should_clone_input', '    workspace_size', '    operator()(cufftHandle *x)', '    _set_max_size(int64_t new_size)', '    clear', '    CuFFTParamsLRUCache', '    CuFFTParamsLRUCache(int64_t max_size)', '    CuFFTParamsLRUCache(CuFFTParamsLRUCache)', '    max_size', '    operator=(CuFFTParamsLRUCache)', '    resize(int64_t new_size)', '    size', '    try_emplace_value(K,VArgs,...)', '    prod_intlist', '    dim', '    is_contiguous', '    scalar_type', '    size', '    sizes', '    slice', '    stride', '    strides', '    forward_as_tuple'];
THLapack.h;C++;pytorch-master/pytorch-master/aten/src/TH; 27;  0; 5;22;  0; 0;0;0;0;0;0.00;0;[];['    _cudaGetErrorEnum(cufftResult error)', '    CUFFT_CHECK(cufftResult error)'];
THMemoryFile.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 689;  15; 75;127;  480; 1;276;113;655;190;0.03;33;[];['    createCusparseHandle(cusparseHandle_t *handle)', '    destroyCusparseHandle(cusparseHandle_t handle)', '    getCurrentCUDASparseHandle'];
THStorage.h;C++;pytorch-master/pytorch-master/aten/src/TH; 4;  1; 1;2;  0; 0;0;0;0;0;0.00;0;[];[];
THStorageFunctions.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 90;  2; 16;23;  49; 0;30;12;19;9;0.04;5;[];['    registerCustomClassMethod(std::unique_ptr fn)', '    customClasses', '    getCustomClass(const std::string & name)', '    isCustomClass(const c10::IValue & v)', '    registerCustomClass(at::ClassTypePtr class_type)'];
THStorageFunctions.h;C++;pytorch-master/pytorch-master/aten/src/TH; 39;  1; 13;24;  1; 0;0;1;0;1;1.00;0;[];[];
THTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 70;  7; 13;14;  35; 1;17;5;26;6;0.20;5;[];[];
THTensor.h;C++;pytorch-master/pytorch-master/aten/src/TH; 58;  5; 17;36;  0; 0;0;0;0;0;0.00;0;[];['    _wrap_outputs(const variable_list & input_vars,const std::unordered_set & non_differentiable,const std::unordered_set & dirty_inputs,const at::ArrayRef raw_outputs,const std::shared_ptr & cdata)', '    check_variable_result(const Variable & original,const Variable & result,std::string hook_name)', '    get_and_bump_dirty', '    get_non_differentiable', '    get_saved_variables', '    mark_dirty(const variable_list & inputs)', '    mark_non_differentiable(const variable_list & outputs)', '    save_for_backward(variable_list to_save)', '    save_variables', '    VariableInfo(const Variable & var)', '    zeros(at::OptionalDeviceGuard & device_guard)'];
THTensor.hpp;C++;pytorch-master/pytorch-master/aten/src/TH; 126;  21; 23;17;  65; 0;31;16;26;16;0.32;11;[];[];
THTensorDimApply.h;C++;pytorch-master/pytorch-master/aten/src/TH; 329;  69; 5;263;  0; 0;0;0;0;0;0.00;0;[];[];
THTensorEvenMoreMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 16;  0; 4;12;  0; 0;0;0;0;1;0.00;0;[];['    _cvtsh_ss(unsigned short x)', '    _cvtss_sh(float x,int imm8)'];
THTensorFill.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 14;  0; 4;10;  0; 0;0;0;0;1;0.00;0;[];[];
THTensorMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 13;  0; 3;10;  0; 0;0;0;0;1;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUDataCouple', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DataCouple'];
THTensorMoreMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 13;  0; 3;10;  0; 0;0;0;0;1;0.00;0;['    DataCoupleOp'];['    DataCoupleOp(Args,...)', '    RunOnDevice', '    ~DataCoupleOp'];
THTensorRandom.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 8;  0; 2;6;  0; 0;0;0;0;0;0.00;0;[];['    fill_with_type(const TensorFiller & filler,const std::string & type,TensorCPU *output)', '    fillRandomNetworkInputs(const NetDef & net,const std::vector,const std::vector,Workspace *workspace)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    DataRandomFiller(const NetDef & run_net,const std::vector,const std::vector)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    fillInputToWorkspace(Workspace *workspace)', '    TestDataRandomFiller(const NetDef & net,const std::vector,const std::vector)'];
THVector.h;C++;pytorch-master/pytorch-master/aten/src/TH; 21;  3; 6;13;  0; 0;0;0;0;0;0.00;0;['    DataNetFiller', '    DataRandomFiller', '    Filler', '    TestDataRandomFiller'];['    fill_with_type(const TensorFiller & filler,const std::string & type,TensorCPU *output)', '    fillRandomNetworkInputs(const NetDef & net,const std::vector,const std::vector,Workspace *workspace)', '    get_tensor_filler(const OperatorDef & op_def,int input_index,const std::vector)', '    DataNetFiller(const NetDef,const NetDef)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    DataRandomFiller(const NetDef & run_net,const std::vector,const std::vector)', '    DataRandomFiller', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    fill_input(TensorList_t *input_data)', '    fill_input_internal(TensorList_t *input_data)', '    fill_parameter(Workspace *ws)', '    get_input_names', '    ~Filler', '    fillInputToWorkspace(Workspace *workspace)', '    TestDataRandomFiller(const NetDef & net,const std::vector,const std::vector)', '    CreateBlob', '    InputFillers', '    Schema'];
AVX.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/vector; 77;  1; 0;9;  0; 75;0;0;0;0;0.00;0;[];['    TEST(DataFiller,FillNetInputTest)'];
AVX.h;C++;pytorch-master/pytorch-master/aten/src/TH/vector; 23;  0; 2;5;  16; 0;0;16;0;16;0.00;0;[];['    data_parallel(ModuleType module,Tensor input,optional,optional output_device,int64_t dim)', '    parallel_apply(std::vector & modules,const std::vector & inputs,const optional)', '    replicate_grad_edges(const std::shared_ptr & module,const std::vector,const std::vector & devices)', '    replicate_grad_edges(module,replicas,devices)', '    Gather', '    current_exception', '    device', '    forward', '    size', '    to', '    collect_next_edges', '    apply(autograd::variable_list)', '    ReduceAdd(const at::Device & destination_device)', '    ~ReduceAdd'];
simd.h;C++;pytorch-master/pytorch-master/aten/src/TH/vector; 121;  4; 12;36;  24; 54;7;15;7;5;0.17;1;['    DataShuttle'];['    drain', '    in_flight_jobs', '    pop_job', '    pop_result(optional timeout)', '    push_job(Job job)', '    push_result(Result result)'];
VSX.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/vector; 780;  1; 1;13;  0; 777;0;0;0;0;0.00;0;['    S'];['    counter', '    d', '    getter', '    output1', '    output1', '    output2', '    output2', '    rand_gen', '    sorting_policy', '    TEST(DataTest,DatasetCallsGetCorrectly)', '    TEST(DataTest,TransformCallsGetApplyCorrectly)', '    TEST(DataTest,ChunkDataSetWithInvalidInitParameter)', '    TEST(DataTest,InfiniteStreamDataset)', '    TEST(DataTest,NoSequencerIsIdentity)', '    TEST(DataTest,OrderedSequencerIsSetUpWell)', '    TEST(DataTest,OrderedSequencerReOrdersValues)', '    TEST(DataTest,BatchLambdaAppliesFunctionToBatch)', '    TEST(DataTest,LambdaAppliesFunctionToExample)', '    TEST(DataTest,CollateReducesBatch)', '    TEST(DataTest,CollationReducesBatch)', '    TEST(DataTest,SequentialSamplerReturnsIndicesInOrder)', '    TEST(DataTest,SequentialSamplerReturnsLessValuesForLastBatch)', '    TEST(DataTest,SequentialSamplerResetsWell)', '    TEST(DataTest,SequentialSamplerResetsWithNewSizeWell)', '    TEST(DataTest,CanSaveAndLoadSequentialSampler)', '    TEST(DataTest,RandomSamplerReturnsIndicesInCorrectRange)', '    TEST(DataTest,RandomSamplerReturnsLessValuesForLastBatch)', '    TEST(DataTest,RandomSamplerResetsWell)', '    TEST(DataTest,RandomSamplerResetsWithNewSizeWell)', '    TEST(DataTest,SavingAndLoadingRandomSamplerYieldsSameSequence)', '    TEST(DataTest,StreamSamplerReturnsTheBatchSizeAndThenRemainder)', '    TEST(DataTest,StreamSamplerResetsWell)', '    TEST(DataTest,StreamSamplerResetsWithNewSizeWell)', '    TEST(DataTest,TensorDatasetConstructsFromSingleTensor)', '    TEST(DataTest,TensorDatasetConstructsFromInitializerListOfTensors)', '    TEST(DataTest,StackTransformWorksForExample)', '    TEST(DataTest,StackTransformWorksForTensorExample)', '    TEST(DataTest,TensorTransformWorksForAnyTargetType)', '    TEST(DataTest,TensorLambdaWorksforAnyTargetType)', '    TEST(DataTest,NormalizeTransform)', '    TEST(DataTest,MapDoesNotCopy)', '    TEST(DataTest,QueuePushAndPopFromSameThread)', '    TEST(DataTest,QueuePopWithTimeoutThrowsUponTimeout)', '    TEST(DataTest,QueuePushAndPopFromDifferentThreads)', '    TEST(DataTest,QueueClearEmptiesTheQueue)', '    TEST(DataTest,DataShuttleCanPushAndPopJob)', '    TEST(DataTest,DataShuttleCanPushAndPopResult)', '    TEST(DataTest,DataShuttlePopResultReturnsNulloptWhenNoJobsInFlight)', '    TEST(DataTest,DataShuttleDrainMeansPopResultReturnsNullopt)', '    TEST(DataTest,DataShuttlePopResultTimesOut)', '    TEST(DataTest,SharedBatchDatasetReallyIsShared)', '    TEST(DataTest,SharedBatchDatasetDoesNotIncurCopyWhenPassedDatasetObject)', '    TEST(DataTest,CanUseCustomTypeAsIndexType)', '    TEST(DataTest,DistributedRandomSamplerSingleReplicaProduceCorrectSamples)', '    TEST(DataTest,DistributedRandomSamplerMultiReplicaProduceCorrectSamples)', '    TEST(DataTest,CanSaveAndLoadDistributedRandomSampler)', '    TEST(DataTest,DistributedSequentialSamplerSingleReplicaProduceCorrectSamples)', '    TEST(DataTest,DistributedSequentialSamplerMultiReplicaProduceCorrectSamples)', '    TEST(DataTest,CanSaveAndLoadDistributedSequentialSampler)', '    TEST(DataLoaderTest,DataLoaderOptionsDefaultAsExpected)', '    TEST(DataLoaderTest,DataLoaderOptionsCoalesceOptionalValues)', '    TEST(DataLoaderTest,MakeDataLoaderDefaultsAsExpected)', '    TEST(DataLoaderTest,MakeDataLoaderThrowsWhenConstructingSamplerWithUnsizedDataset)', '    TEST(DataLoaderTest,IteratorsCompareEqualToThemselves)', '    TEST(DataLoaderTest,ValidIteratorsCompareUnequalToEachOther)', '    TEST(DataLoaderTest,SentinelIteratorsCompareEqualToEachOther)', '    TEST(DataLoaderTest,IteratorsCompareEqualToSentinelWhenExhausted)', '    TEST(DataLoaderTest,IteratorsShareState)', '    TEST(DataLoaderTest,CanDereferenceIteratorMultipleTimes)', '    TEST(DataLoaderTest,CanUseIteratorAlgorithms)', '    TEST(DataLoaderTest,CallingBeginWhileOtherIteratorIsInFlightThrows)', '    TEST(DataLoaderTest,IncrementingExhaustedValidIteratorThrows)', '    TEST(DataLoaderTest,DereferencingExhaustedValidIteratorThrows)', '    TEST(DataLoaderTest,IncrementingSentinelIteratorThrows)', '    TEST(DataLoaderTest,DereferencingSentinelIteratorThrows)', '    TEST(DataLoaderTest,YieldsCorrectBatchSize)', '    TEST(DataLoaderTest,ReturnsLastBatchWhenSmallerThanBatchSizeWhenDropLastIsFalse)', '    TEST(DataLoaderTest,DoesNotReturnLastBatchWhenSmallerThanBatchSizeWhenDropLastIsTrue)', '    TEST(DataLoaderTest,RespectsTimeout)', '    TEST(DataLoaderTest,EnforcesOrderingAmongThreadsWhenConfigured)', '    TEST(DataLoaderTest,Reset)', '    TEST(DataLoaderTest,TestExceptionsArePropagatedFromWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithNoWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithManyWorkers)', '    TEST(DataLoaderTest,StatefulDatasetWithMap)', '    TEST(DataLoaderTest,StatefulDatasetWithCollate)', '    TEST(DataLoaderTest,ChunkDataSetGetBatch)', '    TEST(DataLoaderTest,ChunkDataSetWithBatchSizeMismatch)', '    TEST(DataLoaderTest,ChunkDataSetWithEmptyBatch)', '    TEST(DataLoaderTest,ChunkDataSetGetBatchWithUnevenBatchSize)', '    TEST(DataLoaderTest,CanAccessChunkSamplerWithChunkDataSet)', '    TEST(DataLoaderTest,ChunkDatasetDoesNotHang)', '    TEST(DataLoaderTest,ChunkDatasetSave)', '    TEST(DataLoaderTest,ChunkDatasetLoad)', '    TEST(DataLoaderTest,ChunkDatasetCrossChunkShuffle)', '    TEST(DataLoaderTest,CustomPreprocessPolicy)', '    Barrier(size_t target)', '    wait', '    chunk_count', '    chunk_count', '    chunk_count', '    D(std::shared_ptr b)', '    D(size_t chunk_count)', '    D(size_t chunk_count)', '    get(size_t index)', '    get(size_t index)', '    get(size_t index)', '    get_batch(torch::ArrayRef indices)', '    get_batch(size_t)', '    get_batch(size_t)', '    get_batch(size_t)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    load(torch::serialize::InputArchive & archive)', '    override', '    read_chunk(size_t chunk_index)', '    read_chunk(size_t chunk_index)', '    read_chunk(size_t chunk_index)', '    reset', '    reset', '    reset', '    reset', '    reset', '    reset', '    reset', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    save(torch::serialize::OutputArchive & archive)', '    size', '    size', '    size', '    size', '    size', '    size', '    size', '    size', '    tensor', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    DummyDataset(size_t size)', '    get(size_t index)', '    size', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    get(size_t index)', '    size', '    chunk_count', '    read_chunk(size_t chunk_index)', '    reset', '    get_batch(size_t batch_size)', '    size', '    Dataset(const Dataset & other)', '    get_batch(torch::ArrayRef indices)', '    size', '    index_', '    load(torch::serialize::InputArchive & archive)', '    override', '    reset(torch::optional new_size)', '    S(size_t size)', '    save(torch::serialize::OutputArchive & archive)', '    vector', '    apply_batch(std::vector input)', '    apply(int input)', '    operator()(torch::Tensor input)', '    get(size_t index)', '    size', '    size', '    TestIndex(size_t offset,std::vector index)', '    get_batch(TestIndex index)', '    size', '    TestIndexDataset(size_t size)', '    load(torch::serialize::InputArchive & archive)', '    next(size_t batch_size)', '    reset(torch::optional new_size)', '    save(torch::serialize::OutputArchive & archive)', '    TestIndexSampler(size_t size)', '    get(size_t index)', '    get(size_t index)', '    size', '    size', '    UncopyableDataset(const std::string &)', '    get(size_t i)', '    size'];
THCStorage.cpp;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 126;  0; 0;15;  0; 123;0;0;0;0;0.00;0;[];['    THPModule_errorIfAnyWorkerFails(PyObject *module,PyObject *_ignored)', '    THPModule_removeWorkerPIDs(PyObject *module,PyObject *_ignored)', '    THPModule_setWorkerPIDs(PyObject *module,PyObject *_ignored)', '    THPModule_setWorkerSignalHandlers(PyObject *module,PyObject *_ignored)'];
THCStorageCopy.cpp;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 96;  0; 7;37;  42; 12;36;24;86;43;0.00;22;[];[];
THCStorageCopy.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 45;  0; 0;4;  0; 42;0;0;0;0;0.00;0;[];[];
THCTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 474;  0; 0;6;  0; 471;0;0;0;0;0.00;0;[];['    drop_last(const bool & new_drop_last)', '    drop_last(bool)', '    drop_last', '    drop_last', '    enforce_ordering(const bool & new_enforce_ordering)', '    enforce_ordering(bool)', '    enforce_ordering', '    enforce_ordering', '    max_jobs(const optional & new_max_jobs)', '    max_jobs(optional)', '    max_jobs', '    max_jobs', '    timeout(const optional & new_timeout)', '    timeout(optional)', '    timeout', '    timeout', '    batch_size', '    batch_size', '    batch_size(size_t)', '    workers(const size_t & new_workers)', '    workers(size_t)', '    workers', '    workers', '    FullDataLoaderOptions(DataLoaderOptions options)', '    batch_size(const size_t & new_batch_size)', '    DataLoaderOptions', '    DataLoaderOptions(size_t batch_size)'];
THCTensor.hpp;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 16;  4; 5;4;  3; 1;0;3;0;2;1.33;0;['    CheckDatasetConsistencyOp', '    ComputeOffsetOp', '    CreateTreeCursorOp', '    final', '    final', '    final', '    final', '    final', '    final', '    GetCursorOffsetOp', '    PackRecordsOp', '    ReadNextBatchOp', '    ReadRandomBatchOp', '    ResetCursorOp', '    SortAndShuffleOp', '    TreeCursorDeserializer', '    TreeCursorSerializer', '    TrimDatasetOp', '    UnPackRecordsOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAppend', '    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicAppend', '    CAFFE_ANONYMOUS_VARIABLE_CPUCheckDatasetConsistency', '    CAFFE_ANONYMOUS_VARIABLE_CPUCollectTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUComputeOffset', '    CAFFE_ANONYMOUS_VARIABLE_CPUConcatTensorVector', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTensorVector', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTreeCursor', '    CAFFE_ANONYMOUS_VARIABLE_CPUGetCursorOffset', '    CAFFE_ANONYMOUS_VARIABLE_CPUPackRecords', '    CAFFE_ANONYMOUS_VARIABLE_CPUReadNextBatch', '    CAFFE_ANONYMOUS_VARIABLE_CPUReadRandomBatch', '    CAFFE_ANONYMOUS_VARIABLE_CPUResetCursor', '    CAFFE_ANONYMOUS_VARIABLE_CPUSortAndShuffle', '    CAFFE_ANONYMOUS_VARIABLE_CPUTensorVectorSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUTrimDataset', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnPackRecords', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Append', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicAppend', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CheckDatasetConsistency', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CollectTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ComputeOffset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConcatTensorVector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTensorVector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTreeCursor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetCursorOffset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackRecords', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReadNextBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReadRandomBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResetCursor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortAndShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorVectorSize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TrimDataset', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnPackRecords', '    noexcept', '    CheckDatasetConsistencyOp(Args,...)', '    RunOnDevice', '    ComputeOffsetOp(Args,...)', '    RunOnDevice', '    CreateTreeCursorOp(Args,...)', '    RunOnDevice', '    AppendOp(Args,...)', '    AtomicAppendOp(Args,...)', '    CollectTensorOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    TensorVectorSizeOp(Args,...)', '    ~TensorVectorSizeOp', '    GetCursorOffsetOp(Args,...)', '    RunOnDevice', '    PackRecordsOp(Args,...)', '    RunOnDevice', '    ReadNextBatchOp(Args,...)', '    RunOnDevice', '    ReadRandomBatchOp(Args,...)', '    RunOnDevice', '    ResetCursorOp(Args,...)', '    RunOnDevice', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    RunOnDevice', '    SortAndShuffleOp(Args,...)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    TreeCursorSerializer', '    ~TreeCursorSerializer', '    advance(const std::vector & lengths,std::vector & offsets,std::vector & sizes,std::vector & limits,TOffset num)', '    TreeIterator(const std::vector & fields)', '    advance', '    fieldDim(int fieldId)', '    fieldPtr(int fieldId)', '    gatherLengthData', '    gatherSizeLimits', '    TreeWalker(const vector & inputs,TreeCursor & cursor)', '    RunOnDevice', '    TrimDatasetOp(Args,...)', '    getShapeAndMetaFromInput(std::vector,std::vector & metas)', '    getShapeAndMetaFromPrototypeBlobs(std::vector,std::vector & metas)', '    RunOnDevice', '    UnPackRecordsOp(Args,...)', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
THCTensorCopy.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 11;  0; 3;4;  4; 1;0;4;0;4;0.00;0;['    SharedTensorVectorPtrDeserializer', '    SharedTensorVectorPtrSerializer', '    TreeCursor', '    TreeIterator', '    TreeWalker', '    Field'];['    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    TreeCursor(const TreeIterator & iterator)', '    advance(const std::vector & lengths,std::vector & offsets,std::vector & sizes,std::vector & limits,TOffset num)', '    fields', '    lengthField(int lengthFieldId)', '    lengthFieldFor(const FieldDesc & desc)', '    lengthFieldIds', '    numLengthFields', '    numOffsetFields', '    offsetFieldIdFor(const FieldDesc & fieldDesc)', '    TreeIterator(const std::vector & fields)', '    advance', '    field(int idx)', '    dim', '    Field(TreeWalker & walker,int fieldId)', '    fieldId', '    meta', '    offset', '    ptr', '    size', '    fieldDim(int fieldId)', '    fieldPtr(int fieldId)', '    fields', '    gatherLengthData', '    gatherSizeLimits', '    input(int32_t idx)', '    lengthIdx(int fieldId)', '    offset(int fieldId)', '    size', '    TreeWalker(const vector & inputs,TreeCursor & cursor)'];
THCTensorIndex.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 11;  0; 2;4;  5; 1;0;5;0;5;0.00;0;[];[];
THCTensorMath.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 17;  1; 5;6;  6; 1;0;6;0;6;0.17;0;['    MiniDB', '    MiniDBCursor', '    MiniDBTransaction'];['    RegistryName', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Close', '    MiniDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    ~MiniDB', '    key', '    MiniDBCursor(FILE *f,std::mutex *mutex)', '    Next', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    ~MiniDBCursor', '    Commit', '    MiniDBTransaction(FILE *f,std::mutex *mutex)', '    Put(const string & key,const string & value)', '    ~MiniDBTransaction', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
THCTensorMathBlas.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 12;  0; 2;4;  6; 1;0;6;0;6;0.00;0;['    Cursor', '    DB', '    DBReader', '    DBReaderDeserializer', '    DBReaderSerializer', '    Transaction'];['    CreateDB(const string & db_type,const string & source,Mode mode)', '    DBExists(const string & db_type,const string & full_db_name)', '    RegistryName', '    Cursor', '    Cursor', '    key', '    Next', '    operator=', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~Cursor', '    Close', '    DB(const string &,Mode mode)', '    DB', '    NewCursor', '    NewTransaction', '    operator=', '    ~DB', '    cursor', '    DBReader', '    DBReader(const string & db_type,const string & source,const int32_t num_shards,const int32_t shard_id)', '    DBReader(const DBReaderProto & proto)', '    DBReader(std::unique_ptr db)', '    DBReader', '    InitializeCursor(const int32_t num_shards,const int32_t shard_id)', '    MoveToBeginning', '    num_shards_', '    Open(const string & db_type,const string & source,const int32_t num_shards,const int32_t shard_id)', '    Open(unique_ptr,const int32_t num_shards,const int32_t shard_id)', '    operator=', '    Read(string *key,string *value)', '    SeekToFirst', '    shard_id_', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    Commit', '    operator=', '    Put(const string & key,const string & value)', '    Transaction', '    Transaction', '    ~Transaction'];
THCTensorMathMagma.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 15;  1; 2;6;  0; 8;0;0;0;0;0.00;0;[];['    CreateAndFill(const string & db_type,const string & name)', '    DBSeekTestWrapper(const string & db_type)', '    TestCursor(Cursor *cursor)', '    TEST(DBSeekTest,RocksDB)', '    TEST(DBSeekTest,LevelDB)', '    TEST(DBSeekTest,LMDB)', '    TEST(DBReaderTest,Reader)', '    TEST(DBReaderShardedTest,Reader)'];
THCTensorMathPointwise.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 38;  0; 6;8;  13; 12;0;13;0;13;0.00;0;['    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_num_read_threads', '    C10FlagParser_repeat', '    C10FlagParser_report_interval', '    C10FlagParser_use_reader'];['    main(int argc,char **argv)', '    TestThroughputWithDB', '    TestThroughputWithReader', '    TestThroughputWithReaderWorker(const DBReader *reader,int thread_id)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_num_read_threads(const std::string & content)', '    C10FlagParser_repeat(const std::string & content)', '    C10FlagParser_report_interval(const std::string & content)', '    C10FlagParser_use_reader(const std::string & content)'];
THCTensorMathReduce.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 45;  0; 11;8;  18; 9;0;18;0;9;0.00;0;[];['    copyBroadcastTensorsToReplicas(const std::vector,std::vector)', '    distBroadcastCoalesced(ProcessGroup & processGroup,std::vector & tensors,int64_t bufferSize,bool fineGrained)', '    queueReduction(ProcessGroup & processGroup,std::vector,const std::vector & devices)', '    syncParams(ProcessGroup & processGroup,std::vector,std::vector,const std::vector & devices,int64_t broadcastBucketSize,bool broadcastBuffers)', '    syncReduction(std::shared_ptr & reductionWork,std::vector & gradsBatch,at::Tensor & gradsBatchCoalesced)'];
THCTensorMathScan.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 8;  0; 2;4;  2; 1;0;2;0;2;0.00;0;[];['    distBroadcastCoalesced(ProcessGroup & processGroup,std::vector & tensors,int64_t bufferSize,bool fineGrained)', '    queueReduction(ProcessGroup & processGroup,std::vector,const std::vector & devices)', '    syncParams(ProcessGroup & processGroup,std::vector,std::vector,const std::vector & devices,int64_t broadcastBucketSize,bool broadcastBuffers)', '    syncReduction(std::shared_ptr & reductionWork,std::vector & gradsBatch,at::Tensor & gradsBatchCoalesced)'];
THCTensorRandom.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 13;  0; 2;7;  0; 5;0;0;0;0;0.00;0;['    DeadCodeElim'];['    deadCodeElim(NNModule *nn)', '    run'];
THCTensorScatterGather.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 10;  0; 2;4;  4; 1;0;4;0;4;0.00;0;[];['    TEST(DeadCodeElim,BasicElim)', '    TEST(DeadCodeElim,BasicNoElim)', '    TEST(DeadCodeElim,PartiallyUsedNoElim)'];
THCTensorSort.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 20;  4; 3;4;  9; 1;0;9;0;2;0.44;0;['    DeadCodeEliminator'];['    EliminateDeadCode(const std::shared_ptr & graph,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,bool recurse,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,std::function cb,DCESideEffectPolicy sideEffectPolicy)', '    DeadCodeEliminator(std::shared_ptr graph,DCESideEffectPolicy sideEffectPolicy)', '    DeadCodeEliminator(DCESideEffectPolicy sideEffectPolicy)', '    eliminateDeadForkInputs(Block *block,bool recurse)', '    hasSideEffects(Node *node)', '    hasUntrackedMutation(Node *node)', '    logDeadLoopOutputs(Node *node,size_t i,size_t loop_input_offset,size_t loop_body_offset)', '    mark(Block *block)', '    mark(Node *node)', '    markIfLive(Node *node)', '    markLoop(Node *node)', '    markReturnNode(Node *node)', '    removeDeadBlockOutputs(Node *node)', '    removeDeadLoopOutputs(Node *node)', '    run(Block *block,bool recurse)', '    setDeleteCallback(std::function deleteCallback)', '    sweep(Block *block,bool recurse)'];
THC.h;C++;pytorch-master/pytorch-master/aten/src/THC; 18;  0; 3;15;  0; 0;0;0;0;0;0.00;0;['    DCESideEffectPolicy'];['    EliminateDeadCode(const std::shared_ptr & graph,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,bool recurse,DCESideEffectPolicy sideEffectPolicy)', '    EliminateDeadCode(Block *block,std::function cb,DCESideEffectPolicy sideEffectPolicy)'];
THCAllocator.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 30;  13; 4;1;  12; 0;4;7;3;6;1.08;4;[];['    inputs', '    inputs', '    insert_guard', '    insert_guard', '    DecomposeOps(Block *block,CompilationUnit & decompose_funcs)', '    DecomposeOps(std::shared_ptr & graph)', '    aliasAnalysisFromSchema', '    isDecomposableNorm(Node *normalize_op)', '    isDefined(Value *tensor)'];
THCAllocator.h;C++;pytorch-master/pytorch-master/aten/src/THC; 17;  1; 4;4;  8; 0;0;5;0;5;0.13;0;[];['    DecomposeOps(std::shared_ptr & graph)'];
THCCachingHostAllocator.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 289;  34; 55;12;  193; 0;106;59;94;57;0.18;16;['    DeconvolutionOperatorTester'];['    adjustmentHeight(uint32_t adjustmentHeight)', '    adjustmentHeight', '    adjustmentHeight_', '    adjustmentWidth(uint32_t adjustmentWidth)', '    adjustmentWidth', '    adjustmentWidth_', '    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    dilatedKernelHeight', '    dilatedKernelWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    groupInputChannels(size_t groupInputChannels)', '    groupInputChannels', '    groupInputChannels_', '    groupOutputChannels(size_t groupOutputChannels)', '    groupOutputChannels', '    groupOutputChannels_', '    groups(uint32_t groups)', '    groups', '    groups_', '    inputHeight(uint32_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(uint32_t inputHeight,uint32_t inputWidth)', '    inputWidth(uint32_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize(uint32_t kernelSize)', '    kernelSize(uint32_t kernelHeight,uint32_t kernelWidth)', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingHeight', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    paddingWidth', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testQ8'];
THCCachingHostAllocator.h;C++;pytorch-master/pytorch-master/aten/src/THC; 33;  18; 7;5;  3; 0;0;3;0;3;6.00;0;[];['    compute_output_dimension(size_t input_dimension,size_t input_padding_dimension,size_t adjustment_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_deconvolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t adjustment_height,uint32_t adjustment_width,uint32_t kernel_height,uint32_t kernel_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *deconvolution_out)', '    pytorch_qnnp_setup_deconvolution2d_nhwc_q8(pytorch_qnnp_operator_t deconvolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)'];
THCGeneral.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 342;  24; 63;19;  237; 0;158;46;134;41;0.10;17;[];['    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP)', '    TEST(DECONVOLUTION_OP,zero_batch)', '    TEST(DECONVOLUTION_OP,grouped_1x1)', '    TEST(DECONVOLUTION_OP,grouped_1x3)', '    TEST(DECONVOLUTION_OP,grouped_3x1)', '    TEST(DECONVOLUTION_OP,grouped_3x3)', '    TEST(DECONVOLUTION_OP)'];
THCGenerateAllTypes.h;C++;pytorch-master/pytorch-master/aten/src/THC; 37;  0; 5;32;  0; 1;0;0;0;0;0.00;0;[];['    get_default_complex_dtype', '    get_default_dtype', '    set_default_dtype(caffe2::TypeMeta dtype)'];
THCGenerateBFloat16Type.h;C++;pytorch-master/pytorch-master/aten/src/THC; 27;  0; 6;21;  0; 0;0;0;0;0;0.00;0;[];[];
THCGenerateBoolType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 22;  0; 2;20;  0; 0;0;0;0;0;0.00;0;[];['    getDefaultTensorOptions', '    device', '    dtype', '    layout', '    requires_grad'];
THCGenerateCharType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 20;  0; 2;18;  0; 2;0;0;0;0;0.00;0;['    GetDeformConvGradient'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DeformConvGradient', '    vector', '    vector', '    vector', '    vector', '    GetGradientDefs'];
THCGenerateDoubleType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 22;  0; 2;20;  0; 4;0;0;0;0;0.00;0;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DeformConv'];
THCGenerateFloatType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 24;  2; 2;20;  0; 4;0;0;0;0;0.00;0;['    DeformConvOpBase', '    final', '    final'];['    DeformableCol2im(const T *data_col,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *grad_im)', '    DeformableCol2imCoord(const T *data_col,const T *data_im,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *grad_offset)', '    DeformableIm2col(const T *data_im,const T *data_offset,at::IntArrayRef im_shape,at::IntArrayRef col_shape,T *data_col)', '    DeformConvOpBase(const OperatorDef & operator_def,Workspace *ws)', '    ~DeformConvOpBase', '    col_buffer_', '    col_buffer_shape_device_', '    col_buffer_shape_device_', '    DeformConvGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    DeformConvOp(const OperatorDef & operator_def,Workspace *ws)', '    img_shape_device_', '    img_shape_device_', '    RunOnDeviceWithOrderNCHW', '    ~DeformConvGradientOp', '    ~DeformConvOp'];
THCGenerateHalfType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 28;  0; 7;21;  0; 4;0;0;0;0;0.00;0;[];['    ComputePads', '    SetOutputSize', '    GetDims', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    GetDimsSize', '    RunOnDeviceWithOrderNCHW', '    Gemm', '    Gemv', '    Set', '    dim', '    dim32', '    end', '    numel', '    sizes'];
THCGenerateIntType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 20;  0; 2;18;  0; 2;0;0;0;0;0.00;0;[];[];
THCGenerateLongType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 20;  0; 2;18;  0; 2;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUDenseVectorToIdList', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DenseVectorToIdList'];
THCSleep.h;C++;pytorch-master/pytorch-master/aten/src/THC; 10;  1; 3;5;  1; 0;0;1;0;1;1.00;0;['    DenseVectorToIdListOp'];['    DenseVectorToIdListOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    ~DenseVectorToIdListOp'];
THCStorage.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 71;  2; 15;11;  43; 0;28;12;16;5;0.05;3;[];[];
THCStorage.h;C++;pytorch-master/pytorch-master/aten/src/THC; 18;  0; 6;12;  0; 0;0;0;0;0;0.00;0;[];['    copy(const Tensor & src,bool non_blocking,c10::optional to_device)', '    unsafeStorageFromTH(void *th_pointer,bool retain)', '    unsafeTensorFromTH(void *th_pointer,bool retain)'];
THCStorageCopy.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 13;  0; 4;9;  0; 0;0;0;0;1;0.00;0;[];[];
THCStorageCopy.h;C++;pytorch-master/pytorch-master/aten/src/THC; 17;  0; 5;12;  0; 0;0;0;0;0;0.00;0;[];['    globalDeprecatedTypePropertiesRegistry', '    operator()(DeprecatedTypeProperties *ptr)', '    DeprecatedTypePropertiesRegistry', '    getDeprecatedTypeProperties(Backend p,ScalarType s)'];
THCStream.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
THCTensor.h;C++;pytorch-master/pytorch-master/aten/src/THC; 26;  0; 8;14;  4; 0;0;4;0;2;0.00;0;['    C10FlagParser_caffe2_profile_depthwise', '    final'];['    psimd_transpose4x4_f32(const psimd_f32 row0,const psimd_f32 row1,const psimd_f32 row2,const psimd_f32 row3,psimd_f32 *col0,psimd_f32 *col1,psimd_f32 *col2,psimd_f32 *col3)', '    winograd_f2k3_input_transform(const psimd_f32 d0,const psimd_f32 d1,const psimd_f32 d2,const psimd_f32 d3,psimd_f32 *transform0,psimd_f32 *transform1,psimd_f32 *transform2,psimd_f32 *transform3)', '    winograd_f2k3_kernel_transform(const psimd_f32 g0,const psimd_f32 g1,const psimd_f32 g2,psimd_f32 *transform0,psimd_f32 *transform1,psimd_f32 *transform2,psimd_f32 *transform3)', '    winograd_f2k3_output_transform(const psimd_f32 m0,const psimd_f32 m1,const psimd_f32 m2,const psimd_f32 m3,psimd_f32 *output0,psimd_f32 *output1)', '    runDepthwise3x3Conv(const DepthwiseArgs & args,const float *input,const float *kernel,const float *bias,float *output)', '    C10FlagParser_caffe2_profile_depthwise(const std::string & content)', '    batch', '    in_cols', '    in_rows', '    out_cols', '    out_rows', '    pad_cols', '    pad_rows', '    stride', '    bias_', '    Depthwise3x3ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW'];
THCTensor.hpp;C++;pytorch-master/pytorch-master/aten/src/THC; 63;  8; 16;13;  26; 0;1;26;0;25;0.31;0;[];['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int group,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    relativeError(float a,float b)', '    runConv(int kernelH,int kernelW,int strideH,int strideW,int group,int planesIn,int planesOut,int n)', '    TEST(DEPTHWISE3x3,Conv)'];
THCTensorCopy.h;C++;pytorch-master/pytorch-master/aten/src/THC; 18;  0; 6;12;  0; 0;0;0;0;0;0.00;0;[];['    args', '    _convolution_depthwise3x3_winograd(const Tensor & input,const Tensor & kernel,const Tensor & bias_potentially_undefined,const IntArrayRef stride,const IntArrayRef padding,const int64_t groups)', '    calculate_conv_output_size(const IntArrayRef input_size,const IntArrayRef weight_size,const IntArrayRef stride,const IntArrayRef padding)', '    convolution_depthwise3x3_winograd_impl(const Arguments &,const float *const,const float *const,const float *const,float *const)'];
THCTensorMath.h;C++;pytorch-master/pytorch-master/aten/src/THC; 91;  0; 30;61;  0; 0;0;0;0;0;0.00;0;[];['    convolution_depthwise3x3_winograd_stub', '    convolution_depthwise3x3_winograd_stub', '    operator='];
THCTensorRandom.h;C++;pytorch-master/pytorch-master/aten/src/THC; 17;  0; 6;9;  2; 0;0;2;0;2;0.00;0;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Dequantize', '    DequantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
common.h;C++;pytorch-master/pytorch-master/aten/src/THCUNN; 77;  2; 12;58;  5; 0;2;2;1;2;0.40;1;['    final'];['    DequantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
THCUNN.h;C++;pytorch-master/pytorch-master/aten/src/THCUNN; 13;  0; 4;8;  1; 0;0;1;0;1;0.00;0;[];['    getDataType(const at::Tensor & t)', '    miopenTypeToString(miopenDataType_t dtype)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    i', '    i', '    set(const at::Tensor & t,int64_t pad)', '    print', '    set(miopenDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad)', '    set(const at::Tensor & t,size_t pad)'];
extension.cpp;C++;pytorch-master/pytorch-master/benchmarks/operator_benchmark/pt_extension; 20;  5; 4;2;  9; 0;0;0;0;3;0.56;0;[];['    cudnnTypeToString(cudnnDataType_t dtype)', '    getDataType(const at::Tensor & t)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    i', '    i', '    set(const at::Tensor & t,int64_t pad,bool force_nhwc)', '    print', '    set(cudnnDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad)', '    set(cudnnDataType_t datatype,IntArrayRef t_sizes,IntArrayRef t_strides,size_t pad,bool nhwc)', '    set(const at::Tensor & t,size_t pad)'];
at_launch_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 93;  0; 16;8;  69; 0;47;19;34;43;0.00;8;['    Descriptor', '    FilterDescriptor', '    TensorDescriptor'];['    fixSizeOneDimStride(int dim,const int *size,int *stride)', '    dataSize(miopenDataType_t dataType)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    Constant(miopenDataType_t dataType,double value)', '    miopenDataType_t', '    desc', '    desc', '    init', '    mut_desc', '    operator()(T *x)', '    miopenDataType_t', '    int64_t', '    miopenDataType_t', '    print', '    TensorDescriptor(const at::Tensor & t,size_t pad)', '    TensorDescriptor'];
benchmark_helper.cc;C++;pytorch-master/pytorch-master/binaries; 513;  30; 26;45;  386; 29;233;123;215;57;0.08;11;['    Descriptor', '    FilterDescriptor', '    TensorDescriptor'];['    fixSizeOneDimStride(int dim,const int *size,int *stride,bool nhwc)', '    dataSize(cudnnDataType_t dataType)', '    operator<<(std::ostream & out,const TensorDescriptor & d)', '    empty', '    Constant(cudnnDataType_t dataType,double value)', '    cudnnDataType_t', '    cudnnDataType_t', '    desc', '    desc', '    init', '    mut_desc', '    operator()(T *x)', '    cudnnHandle_t', '    initialize_rng(cudnnHandle_t handle,float dropout,long long int seed,const TensorOptions & options)', '    set_no_dropout(cudnnHandle_t handle)', '    cudnnDataType_t', '    cudnnHandle_t', '    cudnnDataType_t', '    cudnnDataType_t', '    print', '    TensorDescriptor(const at::Tensor & t,size_t pad)', '    TensorDescriptor', '    data_ptr', '    size'];
benchmark_helper.h;C++;pytorch-master/pytorch-master/binaries; 168;  17; 7;9;  135; 0;45;92;38;33;0.13;1;['    DftiDescriptor'];['    get', '    init(DFTI_CONFIG_VALUE precision,DFTI_CONFIG_VALUE signal_type,MKL_LONG signal_ndim,MKL_LONG *sizes)', '    operator()(DFTI_DESCRIPTOR *desc)'];
caffe2_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 32;  0; 3;5;  24; 0;1;22;1;3;0.00;1;[];['    Device(const std::string & spec)'];
convert_caffe_image_db.cc;C++;pytorch-master/pytorch-master/binaries; 90;  18; 5;5;  62; 0;46;21;54;59;0.29;6;[];['    getInputEdges(const NNGraph::SubgraphType & sg,const NNGraph & g)', '    getOutputEdges(const NNGraph::SubgraphType & sg,const NNGraph & g)', '    insertCopies(NNModule *nn,std::function supported,std::function copyToFn,std::function copyFromFn)'];
convert_db.cc;C++;pytorch-master/pytorch-master/binaries; 51;  15; 5;4;  27; 0;20;7;23;40;0.56;6;[];['    THPDevice_hash(THPDevice *self)', '    ret', '    self', '    THPDevice_index(THPDevice *self,PyObject *noargs)', '    THPDevice_init(PyObject *module)', '    THPDevice_New(const at::Device & device)', '    THPDevice_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPDevice_rc(PyObject *a,PyObject *b,int op)', '    THPDevice_reduce(THPDevice *self,PyObject *noargs)', '    THPDevice_repr(THPDevice *self)', '    THPDevice_str(THPDevice *self)', '    THPDevice_type(THPDevice *self,PyObject *noargs)'];
convert_encoded_to_raw_leveldb.cc;C++;pytorch-master/pytorch-master/binaries; 155;  28; 14;10;  105; 0;76;20;73;48;0.27;7;[];['    operator<<(std::ostream & stream,const Device & device)', '    parse_type(const std::string & device_string)', '    Device(const std::string & device_string)', '    str'];
core_overhead_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 58;  15; 8;7;  28; 1;13;12;12;12;0.54;4;['    DeviceType'];['    Device(const std::string & spec)', '    device_id', '    operator()(const caffe2::onnx::DeviceType & k)'];
core_overhead_benchmark_gpu.cc;C++;pytorch-master/pytorch-master/binaries; 222;  20; 24;9;  170; 0;75;90;173;134;0.12;21;[];['    operator<<(std::ostream & stream,const Device & device)', '    Device(DeviceType type,DeviceIndex index)', '    Device(const std::string & device_string)', '    has_index', '    index', '    is_cpu', '    is_cuda', '    operator!=(const Device & other)', '    operator==(const Device & other)', '    set_index(DeviceIndex index)', '    str', '    type', '    validate', '    operator()(c10::Device d)'];
db_throughput.cc;C++;pytorch-master/pytorch-master/binaries; 104;  16; 8;7;  73; 0;45;26;38;65;0.22;10;[];['    THPDevice_Check(PyObject *obj)', '    THPDevice_init(PyObject *module)', '    THPDevice_New(const at::Device & device)'];
inspect_gpu.cc;C++;pytorch-master/pytorch-master/binaries; 58;  16; 10;7;  25; 0;15;9;25;12;0.64;1;[];[];
intra_inter_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 166;  0; 26;10;  130; 0;96;40;59;93;0.00;17;[];['    insertCopies(NNModule *nn,std::function supported,std::function copyToFn,std::function copyFromFn)'];
lite_interpreter_model_load.cc;C++;pytorch-master/pytorch-master/binaries; 33;  2; 5;7;  19; 0;15;2;10;8;0.11;2;[];[];
make_image_db.cc;C++;pytorch-master/pytorch-master/binaries; 280;  41; 37;12;  192; 0;118;59;99;111;0.21;18;[];['    TEST(DeviceTest,InsertCopies)'];
make_mnist_db.cc;C++;pytorch-master/pytorch-master/binaries; 146;  25; 12;7;  104; 0;71;32;79;69;0.24;9;[];[];
parallel_info.cc;C++;pytorch-master/pytorch-master/binaries; 41;  15; 7;9;  5; 7;3;1;3;1;3.00;1;[];[];
print_core_object_sizes_gpu.cc;C++;pytorch-master/pytorch-master/binaries; 40;  16; 4;8;  13; 0;11;1;11;1;1.23;1;[];['    TEST(DeviceGuard,ResetDeviceDifferentDeviceType)', '    TEST(OptionalDeviceGuard,ResetDeviceDifferentDeviceType)'];
print_registered_core_operators.cc;C++;pytorch-master/pytorch-master/binaries; 70;  15; 9;7;  39; 0;28;9;18;15;0.38;4;[];['    DeviceGuardImplRegistrar(DeviceType type,const DeviceGuardImplInterface *impl)'];
run_plan.cc;C++;pytorch-master/pytorch-master/binaries; 40;  16; 4;5;  15; 0;12;2;16;8;1.07;2;[];[];
speed_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 210;  19; 13;15;  162; 2;92;42;108;144;0.12;17;['    PoolWindow'];['    Handle(bool create)', '    Handle', '    Handle(Handle)', '    operator=(Handle rhs)', '    ~Handle', '    newPoolWindow', '    PoolWindow(DeviceThreadHandlePool & parent)', '    release', '    reserve(int device)', '    ~PoolWindow'];
speed_benchmark_torch.cc;C++;pytorch-master/pytorch-master/binaries; 189;  15; 17;10;  147; 0;82;45;75;122;0.10;11;[];['    DeviceTypeName(DeviceType d,bool lower_case)', '    isValidDeviceType(DeviceType d)', '    operator<<(std::ostream & stream,DeviceType type)'];
split_db.cc;C++;pytorch-master/pytorch-master/binaries; 77;  17; 11;6;  44; 0;31;12;46;35;0.39;6;['    DeviceType'];['    DeviceTypeName(DeviceType d,bool lower_case)', '    isValidDeviceType(DeviceType d)', '    operator<<(std::ostream & stream,DeviceType type)', '    static_assert(COMPILE_TIME_MAX_DEVICE_TYPES,)', '    operator()(c10::DeviceType k)'];
tutorial_blob.cc;C++;pytorch-master/pytorch-master/binaries; 89;  17; 21;4;  48; 0;43;7;35;8;0.35;1;[];[];
zmq_feeder.cc;C++;pytorch-master/pytorch-master/binaries; 63;  21; 9;4;  29; 0;21;8;25;25;0.72;4;[];[];
intrusive_ptr_benchmark.cpp;C++;pytorch-master/pytorch-master/c10/benchmark; 75;  2; 12;3;  59; 0;20;29;22;38;0.03;6;[];['    TEST(DictTest,givenEmptyDict_whenCallingEmpty_thenReturnsTrue)', '    TEST(DictTest,givenNonemptyDict_whenCallingEmpty_thenReturnsFalse)', '    TEST(DictTest,givenEmptyDict_whenCallingSize_thenReturnsZero)', '    TEST(DictTest,givenNonemptyDict_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(DictTest,givenNonemptyDict_whenCallingClear_thenIsEmpty)', '    TEST(DictTest,whenInsertingNewKey_thenReturnsTrueAndIteratorToNewElement)', '    TEST(DictTest,whenInsertingExistingKey_thenReturnsFalseAndIteratorToExistingElement)', '    TEST(DictTest,whenInsertingExistingKey_thenDoesNotModifyDict)', '    TEST(DictTest,whenInsertOrAssigningNewKey_thenReturnsTrueAndIteratorToNewElement)', '    TEST(DictTest,whenInsertOrAssigningExistingKey_thenReturnsFalseAndIteratorToChangedElement)', '    TEST(DictTest,whenInsertOrAssigningExistingKey_thenDoesModifyDict)', '    TEST(DictTest,givenEmptyDict_whenIterating_thenBeginIsEnd)', '    TEST(DictTest,givenMutableDict_whenIterating_thenFindsElements)', '    TEST(DictTest,givenMutableDict_whenIteratingWithForeach_thenFindsElements)', '    TEST(DictTest,givenConstDict_whenIterating_thenFindsElements)', '    TEST(DictTest,givenConstDict_whenIteratingWithForeach_thenFindsElements)', '    TEST(DictTest,givenIterator_thenCanModifyValue)', '    TEST(DictTest,givenOneElementDict_whenErasingByIterator_thenDictIsEmpty)', '    TEST(DictTest,givenOneElementDict_whenErasingByKey_thenReturnsOneAndDictIsEmpty)', '    TEST(DictTest,givenOneElementDict_whenErasingByNonexistingKey_thenReturnsZeroAndDictIsUnchanged)', '    TEST(DictTest,whenCallingAtWithExistingKey_thenReturnsCorrectElement)', '    TEST(DictTest,whenCallingAtWithNonExistingKey_thenReturnsCorrectElement)', '    TEST(DictTest,givenMutableDict_whenCallingFindOnExistingKey_thenFindsCorrectElement)', '    TEST(DictTest,givenMutableDict_whenCallingFindOnNonExistingKey_thenReturnsEnd)', '    TEST(DictTest,givenConstDict_whenCallingFindOnExistingKey_thenFindsCorrectElement)', '    TEST(DictTest,givenConstDict_whenCallingFindOnNonExistingKey_thenReturnsEnd)', '    TEST(DictTest,whenCallingContainsWithExistingKey_thenReturnsTrue)', '    TEST(DictTest,whenCallingContainsWithNonExistingKey_thenReturnsFalse)', '    TEST(DictTest,whenCallingReserve_thenDoesntCrash)', '    TEST(DictTest,whenCopyConstructingDict_thenAreEqual)', '    TEST(DictTest,whenCopyAssigningDict_thenAreEqual)', '    TEST(DictTest,whenCopyingDict_thenAreEqual)', '    TEST(DictTest,whenMoveConstructingDict_thenNewIsCorrect)', '    TEST(DictTest,whenMoveAssigningDict_thenNewIsCorrect)', '    TEST(DictTest,whenMoveConstructingDict_thenOldIsEmpty)', '    TEST(DictTest,whenMoveAssigningDict_thenOldIsEmpty)', '    TEST(DictTest,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(DictTest,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(DictTest,givenEqualIterators_thenAreEqual)', '    TEST(DictTest,givenDifferentIterators_thenAreNotEqual)', '    TEST(DictTest,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(DictTest,givenIterator_whenWritingToValue_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenWritingToValueFromIterator_thenChangesValue)', '    TEST(DictTest,isReferenceType)', '    TEST(DictTest,copyHasSeparateStorage)', '    TEST(DictTest,dictTensorAsKey)', '    TEST(DictTest,dictEquality)'];
Allocator.h;C++;pytorch-master/pytorch-master/c10/core; 217;  96; 16;10;  96; 0;24;62;27;46;1.00;23;[];['    all_nonnegative(std::vector & arr)', '    all_positive(IntArrayRef & arr)', '    get_output_size(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    get_output_size(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_shape_check(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)'];
Backend.h;C++;pytorch-master/pytorch-master/c10/core; 264;  19; 15;5;  226; 0;0;0;0;0;0.08;0;[];['    max_pool2d_with_indices_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int dW,int dH)', '    max_pool2d_with_indices_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int dW,int dH)', '    max_pool2d_with_indices_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t nbatch,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,int dilationW,int dilationH)', '    max_pool2d_with_indices_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *ind_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int kW,int kH,int dW,int dH,int padW,int padH,int dilationW,int dilationH)', '    max_pool2d_with_indices_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool2d_with_indices_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool2d_with_indices_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d_with_indices_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)'];
CopyBytes.cpp;C++;pytorch-master/pytorch-master/c10/core; 49;  3; 5;2;  39; 0;15;20;9;7;0.08;2;[];['    max_pool3d_with_indices_backward_out_frame(scalar_t *gradInput_data,scalar_t *gradOutput_data,int64_t *indices_data,int64_t nbatch,int64_t nslices,int64_t istride,int64_t ostride,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_backward_single_out_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *indz_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_out_frame(scalar_t *input_data,scalar_t *output_data,int64_t *indices_data,int64_t nbatch,int64_t nslices,int64_t istride,int64_t ostride,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t *indz_p,int64_t nslices,int64_t itime,int64_t iwidth,int64_t iheight,int64_t otime,int64_t owidth,int64_t oheight,int kT,int kW,int kH,int dT,int dW,int dH,int pT,int pW,int pH,int dilationT,int dilationW,int dilationH)', '    max_pool3d_with_indices_backward_cpu(const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool3d_with_indices_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,const Tensor & indices)', '    max_pool3d_with_indices_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,const Tensor & indices,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_out_cpu(Tensor & output,Tensor & indices,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d_with_indices_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)'];
CPUAllocator.cpp;C++;pytorch-master/pytorch-master/c10/core; 183;  10; 27;9;  125; 15;57;41;51;59;0.08;19;[];['    check_valid_identifier(const std::string & name)', '    operator<<(std::ostream & out,const Dimname & dimname)', '    fromSymbol(Symbol name)', '    isValidName(const std::string & name)', '    matches(Dimname other)', '    unify(Dimname other)', '    wildcard'];
CPUAllocator.h;C++;pytorch-master/pytorch-master/c10/core; 42;  11; 12;6;  14; 0;2;13;1;14;0.79;0;[];[];
DefaultDtype.cpp;C++;pytorch-master/pytorch-master/c10/core; 23;  1; 3;2;  18; 0;9;7;6;6;0.06;3;[];[];
DefaultTensorOptions.h;C++;pytorch-master/pytorch-master/c10/core; 36;  7; 9;5;  20; 0;11;16;5;15;0.35;5;[];['    check_unify_and_match(const std::string & dimname,const std::string & other,at::optional expected)', '    TEST(DimnameTest,isValidIdentifier)', '    TEST(DimnameTest,wildcardName)', '    TEST(DimnameTest,createNormalName)', '    TEST(DimnameTest,unifyAndMatch)'];
Device.cpp;C++;pytorch-master/pytorch-master/c10/core; 102;  26; 7;10;  62; 0;42;29;28;12;0.42;4;[];[];
Device.h;C++;pytorch-master/pytorch-master/c10/core; 132;  47; 20;8;  61; 0;21;32;18;26;0.77;11;[];[];
DeviceType.cpp;C++;pytorch-master/pytorch-master/c10/core; 73;  13; 5;2;  55; 0;40;5;41;4;0.24;3;[];[];
DeviceType.h;C++;pytorch-master/pytorch-master/c10/core; 70;  21; 13;4;  44; 0;21;28;1;16;0.48;1;[];['    ints', '    ints', '    ints', '    TEST_F(DispatchTest,TestAVX2)', '    TEST_F(DispatchTest,TestAVX)', '    TEST_F(DispatchTest,TestDefault)', '    vector', '    vector', '    vector'];
DispatchKey.cpp;C++;pytorch-master/pytorch-master/c10/core; 56;  1; 4;1;  51; 0;44;4;43;3;0.02;2;[];[];
DispatchKeySet.cpp;C++;pytorch-master/pytorch-master/c10/core; 31;  0; 4;1;  26; 0;16;6;15;5;0.00;2;['    final'];['    addListener(std::unique_ptr listener)', '    callOnOperatorDeregistered(const OperatorHandle & op)', '    callOnOperatorRegistered(const OperatorHandle & op)', '    addRegistrationListener(std::unique_ptr listener)', '    checkInvariants', '    checkSchemaCompatibility(const OperatorHandle & op,const FunctionSchema & schema)', '    cleanup(const OperatorHandle & op,const OperatorName & op_name)', '    deregisterDef_(const OperatorHandle & op,const OperatorName & op_name)', '    deregisterFallback_(DispatchKey dispatchKey)', '    deregisterImpl_(const OperatorHandle & op,const OperatorName & op_name,c10::optional dispatch_key,std::list::iterator handle)', '    Dispatcher', '    findOp(const OperatorName & overload_name)', '    findOrRegisterName_(const OperatorName & op_name)', '    findSchema(const OperatorName & overload_name)', '    findSchemaOrThrow(const char *name,const char *overload_name)', '    registerDef(FunctionSchema schema)', '    registerFallback(DispatchKey dispatchKey,KernelFunction kernel)', '    registerImpl(OperatorName op_name,c10::optional dispatch_key,KernelFunction kernel,std::unique_ptr inferred_function_schema,std::string debug)', '    singleton', '    ~Dispatcher', '    ~OpRegistrationListener'];
DispatchKeySet.h;C++;pytorch-master/pytorch-master/c10/core; 136;  63; 8;5;  60; 0;15;33;15;25;1.05;17;[];[];
Event.h;C++;pytorch-master/pytorch-master/c10/core; 113;  62; 14;3;  35; 0;17;21;10;22;1.77;11;[];['    operator<<(std::ostream & str,DispatchKey rhs)', '    toString(DispatchKey t)'];
GeneratorImpl.h;C++;pytorch-master/pytorch-master/c10/core; 103;  41; 20;13;  31; 0;12;25;3;23;1.32;3;['    DispatchKey'];['    XLATensorId', '    operator<<(std::ostream & str,DispatchKey rhs)', '    static_assert(,)', '    toString(DispatchKey t)', '    operator()(c10::DispatchKey x)'];
DeviceGuardImplInterface.cpp;C++;pytorch-master/pytorch-master/c10/core/impl; 13;  1; 4;1;  8; 0;1;6;1;4;0.13;1;[];['    checkInvariants(const FunctionSchema & schema)', '    dumpState', '    setOperatorHasKernelForBackend(DispatchKey k,bool has_kernel)'];
DeviceGuardImplInterface.h;C++;pytorch-master/pytorch-master/c10/core/impl; 224;  133; 27;9;  58; 0;0;0;0;0;2.29;0;[];[];
InlineDeviceGuard.h;C++;pytorch-master/pytorch-master/c10/core/impl; 391;  211; 37;6;  141; 0;0;0;0;0;1.50;0;[];['    operator<<(std::ostream & os,DispatchKeySet ts)', '    toString(DispatchKeySet ts)'];
InlineEvent.h;C++;pytorch-master/pytorch-master/c10/core/impl; 102;  4; 19;5;  76; 0;35;34;30;29;0.05;15;['    final'];['    legacyExtractDispatchKey(DispatchKeySet s)', '    operator<<(std::ostream & os,DispatchKeySet ts)', '    toString(DispatchKeySet ts)', '    add(DispatchKey t)', '    DispatchKeySet', '    DispatchKeySet(Full)', '    DispatchKeySet(Raw,uint64_t x)', '    DispatchKeySet(DispatchKey t)', '    DispatchKeySet(std::initializer_list ks)', '    empty', '    has(DispatchKey t)', '    highestPriorityTypeId', '    operator&(DispatchKeySet other)', '    operator-(DispatchKeySet other)', '    operator==(DispatchKeySet other)', '    operator|(DispatchKeySet other)', '    raw_repr', '    remove(DispatchKey t)', '    uint64_t', '    max'];
InlineStreamGuard.h;C++;pytorch-master/pytorch-master/c10/core/impl; 187;  72; 26;2;  91; 0;29;49;20;30;0.79;15;[];['    TEST(DispatchKeySet,Empty)', '    TEST(DispatchKeySet,Singleton)', '    TEST(DispatchKeySet,Doubleton)', '    TEST(DispatchKeySet,Full)'];
LocalDispatchKeySet.h;C++;pytorch-master/pytorch-master/c10/core/impl; 111;  37; 15;3;  58; 0;0;0;0;0;0.64;0;[];['    compute_cpu_capability', '    get_cpu_capability'];
VirtualGuardImpl.h;C++;pytorch-master/pytorch-master/c10/core/impl; 75;  8; 8;2;  58; 0;0;0;0;0;0.14;0;['    CPUCapability'];['    get_cpu_capability', '    choose_cpu_impl', '    cpu_dispatch_ptr', '    DispatchStub', '    DispatchStub', '    operator()(DeviceType device_type,ArgTypes,...)', '    operator=', '    RegisterCUDADispatch(DispatchStub & stub,FnPtr value)', '    RegisterHIPDispatch(DispatchStub & stub,FnPtr value)'];
Layout.h;C++;pytorch-master/pytorch-master/c10/core; 41;  1; 7;4;  30; 0;0;0;0;0;0.03;0;[];['    dumpState', '    dumpState'];
QEngine.h;C++;pytorch-master/pytorch-master/c10/core; 40;  6; 6;4;  25; 0;0;0;0;0;0.24;0;[];[];
QScheme.h;C++;pytorch-master/pytorch-master/c10/core; 44;  7; 6;3;  29; 0;22;10;11;9;0.24;1;[];['    getInstance', '    cleanupBackwardPass(const ContextPtr & autogradContext)', '    computeDependencies(const ContextPtr & autogradContext,const edge_list & rootEdges,const variable_list & grads,const std::shared_ptr & graphRoot,edge_list & outputEdges,bool retainGraph)', '    DistEngine', '    execute(int64_t contextId,const variable_list & roots,bool retainGraph)', '    executeSendFunctionAsync(const ContextPtr & autogradContext,const std::shared_ptr & sendFunction,bool retainGraph)', '    getDebugInfo', '    numBackwardPasses', '    runEngineAndAccumulateGradients(const ContextPtr & autogradContext,const std::shared_ptr & graphRoot,const edge_list & outputEdges)', '    validateRootsAndRetrieveEdges(const variable_list & roots,edge_list & rootEdges,variable_list & grads)'];
Scalar.cpp;C++;pytorch-master/pytorch-master/c10/core; 16;  1; 3;1;  12; 0;7;3;7;2;0.08;1;['    BackwardPassCleanupGuard', '    DistEngine'];['    getInstance', '    BackwardPassCleanupGuard(const ContextPtr & autogradContext)', '    ~BackwardPassCleanupGuard', '    cleanupBackwardPass(const ContextPtr & autogradContext)', '    computeDependencies(const ContextPtr & context,const torch::autograd::edge_list & rootEdges,const torch::autograd::variable_list & grads,const std::shared_ptr & graphRoot,torch::autograd::edge_list & outputEdges,bool retainGraph)', '    DistEngine', '    DistEngine', '    DistEngine', '    execute(int64_t context_id,const torch::autograd::variable_list & roots,bool retainGraph)', '    executeSendFunctionAsync(const ContextPtr & autogradContext,const std::shared_ptr & sendFunction,bool retainGraph)', '    getDebugInfo', '    numBackwardPasses', '    operator=', '    operator=', '    runEngineAndAccumulateGradients(const ContextPtr & autogradContext,const std::shared_ptr & graphRoot,const torch::autograd::edge_list & outputEdges)', '    validateRootsAndRetrieveEdges(const torch::autograd::variable_list & roots,torch::autograd::edge_list & rootEdges,torch::autograd::variable_list & grads)', '    ~DistEngine'];
ScalarType.h;C++;pytorch-master/pytorch-master/c10/core; 464;  87; 66;116;  228; 0;126;90;234;117;0.38;20;[];['    cdist_impl(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    _cdist_backward(const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & cdist)', '    _cdist_forward(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    _pdist_backward(const Tensor & grad,const Tensor & self,const double p,const Tensor & pdist)', '    _pdist_forward(const Tensor & self,const double p)', '    cdist(const Tensor & x1,const Tensor & x2,const double p,c10::optional compute_mode)', '    cosine_similarity(const Tensor & x1,const Tensor & x2,int64_t dim,double eps)', '    euclidean_dist_out(const Tensor & x1,const Tensor & x2)', '    pairwise_distance(const Tensor & x1,const Tensor & x2,double p,double eps,bool keepdim)', '    pdist(const Tensor & self,const double p)', '    result', '    result', '    tensor1_view', '    tensor2_view'];
Storage.cpp;C++;pytorch-master/pytorch-master/c10/core; 5;  1; 2;1;  2; 0;0;2;0;1;0.50;0;[];['    CosineSimilarityImpl(const CosineSimilarityOptions & options_)', '    forward(const Tensor & x1,const Tensor & x2)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & x1,const Tensor & x2)', '    PairwiseDistanceImpl(const PairwiseDistanceOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset'];
Storage.h;C++;pytorch-master/pytorch-master/c10/core; 184;  12; 35;2;  137; 0;0;0;0;0;0.09;0;[];[];
StorageImpl.h;C++;pytorch-master/pytorch-master/c10/core; 234;  29; 34;4;  168; 0;0;0;0;0;0.17;0;[];[];
Stream.cpp;C++;pytorch-master/pytorch-master/c10/core; 12;  3; 3;1;  6; 0;2;3;2;2;0.50;1;[];[];
Stream.h;C++;pytorch-master/pytorch-master/c10/core; 154;  79; 16;2;  59; 0;0;0;0;0;1.34;0;[];['    cdist_backward_stub', '    cdist_backward_stub', '    operator=', '    cdist_stub', '    cdist_stub', '    operator=', '    operator=', '    pdist_backward_stub', '    pdist_backward_stub', '    operator=', '    pdist_forward_stub', '    pdist_forward_stub'];
TensorImpl.cpp;C++;pytorch-master/pytorch-master/c10/core; 322;  30; 38;7;  248; 1;135;78;115;62;0.12;35;['    GetCosineSimilarityGradient', '    GetDotProductGradient', '    GetDotProductWithPaddingGradient', '    GetL1DistanceGradient', '    GetSquaredL2DistanceGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCosineSimilarity', '    CAFFE_ANONYMOUS_VARIABLE_CPUCosineSimilarityGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProduct', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductWithPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUDotProductWithPaddingGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUL1Distance', '    CAFFE_ANONYMOUS_VARIABLE_CPUL1DistanceGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSquaredL2Distance', '    CAFFE_ANONYMOUS_VARIABLE_CPUSquaredL2DistanceGradient', '    TensorInferenceForDotProduct(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineSimilarity', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CosineSimilarityGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProduct', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductWithPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DotProductWithPaddingGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_L1Distance', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_L1DistanceGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquaredL2Distance', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquaredL2DistanceGradient', '    CostInferenceForDotProduct(const OperatorDef & def,const vector & in)', '    dot_arg', '    vector', '    vector', '    vector', '    vector', '    vector', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs'];
TensorImpl.h;C++;pytorch-master/pytorch-master/c10/core; 1740;  785; 161;22;  781; 7;0;0;0;0;1.01;0;['    CosineSimilarityOp', '    DotProductOp', '    DotProductWithPaddingOp', '    final', '    final', '    final', '    final', '    L1DistanceGradientOp', '    L1DistanceOp', '    SquaredL2DistanceOp'];['    CosineSimilarityOp(Args,...)', '    RunOnDevice', '    DotProductOp(Args,...)', '    RunOnDevice', '    DotProductWithPaddingOp(Args,...)', '    RunOnDevice', '    CosineSimilarityGradientOp(Args,...)', '    DotProductGradientOp(Args,...)', '    DotProductWithPaddingGradientOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SquaredL2DistanceGradientOp(Args,...)', '    L1DistanceGradientOp(Args,...)', '    RunOnDevice', '    L1DistanceOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    SquaredL2DistanceOp(Args,...)'];
TensorOptions.cpp;C++;pytorch-master/pytorch-master/c10/core; 22;  1; 5;6;  11; 0;5;5;1;2;0.09;1;[];['    apply_backward_cdist(Tensor & result,const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & dist)', '    apply_backward_pdist(Tensor & result,const Tensor & grad,const Tensor & self,const double p,const Tensor & dist)', '    apply_cdist(Tensor & result,const Tensor & x1,const Tensor & x2,const scalar_t p)', '    apply_pdist(Tensor & result,const Tensor & self,const scalar_t p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)', '    backward_down_column_cdist(const scalar_t *t1,const scalar_t *t2,scalar_t *res,const scalar_t *grad_k,const scalar_t *dist_k,const Vec & pvec,int64_t r1,int64_t r2,int64_t m,int64_t d,int64_t gs,int64_t l1_size,int64_t l2_size,int64_t count)', '    backward_down_column_pdist(const scalar_t *self_i,scalar_t *res_i,const scalar_t *grad_k,const scalar_t *dist_k,const Vec & pvec,int64_t n,int64_t m,int64_t gs,int64_t count)', '    cdist_backward_kernel_impl(Tensor & result,const Tensor & grad,const Tensor & x1,const Tensor & x2,const double p,const Tensor & dist)', '    cdist_kernel_impl(Tensor & result,const Tensor & x1,const Tensor & x2,const double p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    finish(const scalar_t agg,const scalar_t p)', '    pdist_backward_kernel_impl(Tensor & result,const Tensor & grad,const Tensor & self,const double p,const Tensor & dist)', '    run_backward_parallel_cdist(Tensor & result,const Tensor & grad,const Tensor & t1,const Tensor & t2,const scalar_t p,const Tensor & dist)', '    run_backward_parallel_pdist(Tensor & result,const Tensor & grad,const Tensor & self,const scalar_t p,const Tensor & dist)', '    run_parallel_cdist(Tensor & result,const Tensor & t1,const Tensor & t2,const scalar_t p)', '    run_parallel_pdist(Tensor & result,const Tensor & self,const scalar_t p)', '    pdist_forward_kernel_impl(Tensor & result,const Tensor & self,const double p)', '    abs(Vec val)', '    abs(scalar_t val)', '    ceil(Vec val)', '    ceil(scalar_t val)', '    max(Vec val,Vec other)', '    max(scalar_t val,scalar_t)', '    min(Vec val,scalar_t)', '    min(scalar_t val,scalar_t)', '    pow(Vec val,Vec p)', '    pow(scalar_t val,scalar_t p)', '    sign(Vec val)', '    backward(const Vec & diff,const scalar_t grad,const scalar_t dist,const Vec & p)'];
thread_pool.cpp;C++;pytorch-master/pytorch-master/c10/core; 141;  21; 18;1;  103; 0;53;23;48;15;0.20;9;[];['    addBlobDeviceOptions(std::map blobMap,NNModule *nn)', '    convertToNNModule(caffe2::NetDef & net,std::map blobMap)', '    injectDataEdgeIndicators(nom::repr::NNModule *nn)', '    removeDataEdgeIndicators(nom::repr::NNModule *nn)', '    setDeviceOption(NNGraph::NodeRef n,caffe2::DeviceOption & d)'];
thread_pool.h;C++;pytorch-master/pytorch-master/c10/core; 125;  12; 26;13;  74; 1;7;42;2;34;0.16;4;[];['    DistributedRandomSampler(size_t size,size_t num_replicas,size_t rank,bool allow_duplicates)', '    index', '    load(serialize::InputArchive & archive)', '    populate_indices', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    DistributedSequentialSampler(size_t size,size_t num_replicas,size_t rank,bool allow_duplicates)', '    index', '    load(serialize::InputArchive & archive)', '    populate_indices', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)'];
UndefinedTensorImpl.cpp;C++;pytorch-master/pytorch-master/c10/core; 44;  1; 11;2;  30; 0;8;13;32;11;0.03;9;[];['    addBlobDeviceOptions(std::map blobMap,NNModule *nn)', '    injectDataEdgeIndicators(nom::repr::NNModule *nn)', '    removeDataEdgeIndicators(nom::repr::NNModule *nn)'];
WrapDimMinimal.h;C++;pytorch-master/pytorch-master/c10/core; 26;  1; 5;2;  19; 0;0;0;0;0;0.05;0;[];[];
CUDACachingAllocator.cpp;C++;pytorch-master/pytorch-master/c10/cuda; 981;  140; 155;17;  690; 0;425;214;420;218;0.20;57;['    DeclareConverter', '    ExportConverter'];['    convertToNeuralNetOperator(const OperatorDef & op)', '    ~DeclareConverter', '    convertToNeuralNetOperator(const OperatorDef & op)', '    ~ExportConverter'];
CUDACachingAllocator.h;C++;pytorch-master/pytorch-master/c10/cuda; 129;  30; 24;11;  67; 0;21;59;1;55;0.45;1;[];['    fakeNet', '    ns', '    ns', '    TEST(Converter,DeclareExport)', '    TEST(Distributed,InsertDeviceOptions)', '    TEST(Distributed,InsertDeviceOptionsFailureCase)', '    TEST(Converter,OverloadedConvertToNNModule)', '    TEST(Converter,OverloadedConvertToNNModuleFailure)', '    TEST(Converter,InjectDataEdgeIndicators)'];
CUDAFunctions.h;C++;pytorch-master/pytorch-master/c10/cuda; 48;  15; 8;5;  21; 0;9;12;13;14;0.71;3;[];['    _dirichlet_grad_cpu(const Tensor & x,const Tensor & alpha,const Tensor & total)', '    _s_dirichlet_cpu(const Tensor & alpha,Generator gen)', '    _s_gamma_cpu(const Tensor & alpha,Generator gen)', '    _s_poisson_cpu(const Tensor & lambda,Generator gen)', '    _standard_gamma_grad_cpu(const Tensor & self,const Tensor & output)', '    bernoulli(const Tensor & self,Generator gen)', '    bernoulli(const Tensor & self,double p,Generator gen)', '    bernoulli_out(Tensor & result,const Tensor & self,Generator gen)', '    bernoulli_scalar_cpu_(Tensor & self,double p,Generator gen)', '    bernoulli_tensor_cpu_(Tensor & self,const Tensor & p_,Generator gen)', '    cauchy_(Tensor & self,double median,double sigma,Generator gen)', '    exponential_(Tensor & self,double lambda,Generator gen)', '    geometric_(Tensor & self,double p,Generator gen)', '    log_normal_(Tensor & self,double mean,double std,Generator gen)', '    multinomial(const Tensor & self,int64_t n_sample,bool with_replacement,Generator gen)', '    multinomial_out(Tensor & result,const Tensor & self,int64_t n_sample,bool with_replacement,Generator gen)', '    normal(const Tensor & mean,double std,Generator gen)', '    normal(double mean,const Tensor & std,Generator gen)', '    normal(const Tensor & mean,const Tensor & std,Generator gen)', '    normal_(Tensor & self,double mean,double std,Generator gen)', '    normal_out(Tensor & output,const Tensor & mean,double std,Generator gen)', '    normal_out(Tensor & output,double mean,const Tensor & std,Generator gen)', '    normal_out(Tensor & output,const Tensor & mean,const Tensor & std,Generator gen)', '    random_(Tensor & self,Generator gen)', '    random_(Tensor & self,int64_t from,optional to,Generator gen)', '    random_(Tensor & self,int64_t to,Generator gen)', '    sample_poisson(double lambda,at::CPUGenerator *generator)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t from,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)'];
CUDAGuard.h;C++;pytorch-master/pytorch-master/c10/cuda; 236;  97; 50;7;  84; 0;46;60;24;59;1.15;29;[];['    _beta_grad_alpha_mid(accscalar_t,accscalar_t alpha,accscalar_t beta)', '    _beta_grad_alpha_small(scalar_t x,scalar_t alpha,scalar_t beta)', '    _beta_grad_beta_small(scalar_t x,scalar_t alpha,scalar_t beta)', '    digamma_one(scalar_t x)', '    dirichlet_grad_one(scalar_t x,scalar_t alpha,scalar_t total)', '    polevl(const scalar_t x,const scalar_t [] A,size_t len)', '    sample_gamma(scalar_t alpha,BaseSampler & standard_uniform,BaseSampler & standard_normal)', '    standard_gamma_grad_one(scalar_t alpha_,scalar_t x_)', '    BaseSampler(const sampler_t & sampler)', '    sample', '    tan'];
CUDAMacros.h;C++;pytorch-master/pytorch-master/c10/cuda; 38;  8; 5;26;  0; 10;0;0;0;0;0.00;0;[];['    bernoulli_distribution(T p_in)', '    operator()(RNG *generator)', '    cauchy_distribution(T median_in,T sigma_in)', '    operator()(RNG *generator)', '    exponential_distribution(T lambda_in)', '    operator()(RNG *generator)', '    geometric_distribution(T p_in)', '    operator()(RNG *generator)', '    lognormal_distribution(T mean_in,T stdv_in)', '    operator()(RNG *generator)', '    normal_distribution(T mean_in,T stdv_in)', '    operator()(RNG *generator)', '    operator()(RNG *generator)', '    uniform_real_distribution(T a_in,T b_in)'];
CUDAStream.cpp;C++;pytorch-master/pytorch-master/c10/cuda; 377;  93; 50;15;  220; 5;119;68;108;64;0.42;24;[];['    check_from_to_in_range(int64_t from,int64_t to_inc,caffe2::TypeMeta dtype)', '    resize_output_for_normal(at::Tensor & output,const at::Tensor & mean,const at::Tensor & std)', '    torch_warn_once_177', '    normal_impl(const Tensor & mean,double std,Generator gen)', '    normal_impl(double mean,const Tensor & std,Generator gen)', '    normal_impl(const Tensor & mean,const Tensor & std,Generator gen)', '    normal_impl_(Tensor & self,double mean,double std,Generator gen)', '    normal_out_impl(Tensor & output,const Tensor & mean,double std,Generator gen)', '    normal_out_impl(Tensor & output,double mean,const Tensor & std,Generator gen)', '    normal_out_impl(Tensor & output,const Tensor & mean,const Tensor & std,Generator gen)', '    random_from_to_impl(at::Tensor & self,int64_t from,c10::optional to_opt,at::Generator generator)', '    random_impl(at::Tensor & self,at::Generator generator)', '    update_from(int64_t from)', '    update_to(int64_t to)', '    are_expandable', '    full', '    resize_', '    dtype', '    equals', '    has_value'];
CUDAStream.h;C++;pytorch-master/pytorch-master/c10/cuda; 228;  106; 35;15;  73; 4;30;46;35;46;1.45;20;[];['    normal_fill_16(scalar_t *data,const scalar_t mean,const scalar_t)', '    cauchy_kernel(TensorIterator & iter,double median,double sigma,RNG generator)', '    normal_fill(Tensor & self,const scalar_t mean,const scalar_t,RNG generator)', '    normal_kernel(Tensor & self,double mean,double std,RNG generator)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,RNG generator)', '    random_full_64_bits_range_kernel(TensorIterator & iter,RNG generator)', '    random_kernel(TensorIterator & iter,RNG generator)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t base,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    operator()(TensorIterator & iter,at::Generator gen)', '    cos', '    sin'];
CUDAGuardImpl.cpp;C++;pytorch-master/pytorch-master/c10/cuda/impl; 11;  1; 4;1;  6; 0;0;6;0;6;0.17;0;[];['    normal_kernel(Tensor & self,double mean_,double std_,RNG gen)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,RNG gen)', '    random_full_64_bits_range_kernel(TensorIterator & iter,RNG gen)', '    random_kernel(TensorIterator & iter,RNG gen)', '    calc_execution_policy(int64_t total_elements)', '    distribution_nullary_kernel(at::TensorIterator & iter,RNG gen,const dist_t & dist_func,const transform_t transform_func)', '    operator()(Tensor & self,double mean,double std,Generator gen)', '    operator()(TensorIterator & iter,uint64_t range,int64_t base,RNG gen)', '    operator()(TensorIterator & iter,RNG gen)', '    operator()(TensorIterator & iter,RNG gen)'];
CUDATest.cpp;C++;pytorch-master/pytorch-master/c10/cuda/impl; 32;  3; 8;3;  19; 0;7;11;12;12;0.16;3;[];['    div_rtn(T x,T y)'];
CUDATest.h;C++;pytorch-master/pytorch-master/c10/cuda/impl; 11;  1; 4;2;  5; 0;0;5;0;4;0.20;0;[];['    PyInit__dl'];
CUDATest.cpp;C++;pytorch-master/pytorch-master/c10/cuda/test/impl; 9;  0; 3;2;  4; 0;1;1;2;2;0.00;1;[];['    getATenDevice(const DLContext & ctx)', '    deleter(DLManagedTensor *arg)', '    fromDLPack(const DLManagedTensor *src)', '    getDLContext(const Tensor & tensor,const int64_t & device_id)', '    getDLDataType(const Tensor & t)', '    toDLPack(const Tensor & src)', '    toScalarType(const DLDataType & dtype)'];
Macros.h;C++;pytorch-master/pytorch-master/c10/macros; 323;  98; 32;156;  7; 101;0;7;4;15;14.00;0;[];['    fromDLPack(const DLManagedTensor *src)', '    getDLContext(const Tensor & tensor,const int64_t & device_id)', '    getDLDataType(const Tensor & t)', '    toDLPack(const Tensor & src)', '    toScalarType(const DLDataType & dtype)'];
DeviceGuard_test.cpp;C++;pytorch-master/pytorch-master/c10/test/core; 41;  4; 7;3;  27; 0;19;4;21;6;0.15;2;[];['    TEST(TestDlconvertor,TestDlconvertor)', '    TEST(TestDlconvertor,TestDlconvertorNoStrides)'];
DispatchKeySet_test.cpp;C++;pytorch-master/pytorch-master/c10/test/core; 55;  1; 6;2;  47; 0;29;19;29;20;0.02;4;[];['    dlnnapi_free(struct dlnnapi *nnapi)', '    dlnnapi_load(struct dlnnapi *nnapi,uint32_t flags)'];
InlineStreamGuard_test.cpp;C++;pytorch-master/pytorch-master/c10/test/core/impl; 174;  2; 17;3;  152; 0;105;19;106;27;0.01;9;[];['    dlnnapi_free(struct dlnnapi *nnapi)', '    dlnnapi_load(struct dlnnapi *nnapi,uint32_t flags)'];
StreamGuard_test.cpp;C++;pytorch-master/pytorch-master/c10/test/core; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];[];
Array_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 92;  0; 11;2;  79; 0;1;77;2;69;0.00;0;[];[];
C++17_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 14;  0; 3;1;  10; 0;0;8;2;10;0.00;0;['    C10FlagParser_caffe2_dnnlowp_activation_p99_threshold', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_kind', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_precision', '    C10FlagParser_caffe2_dnnlowp_copy_to_32bit_frequency', '    C10FlagParser_caffe2_dnnlowp_eltwise_quantization_precision', '    C10FlagParser_caffe2_dnnlowp_force_scale_power_of_two', '    C10FlagParser_caffe2_dnnlowp_force_slow_path', '    C10FlagParser_caffe2_dnnlowp_nbits_in_non_outlier', '    C10FlagParser_caffe2_dnnlowp_preserve_activation_sparsity', '    C10FlagParser_caffe2_dnnlowp_preserve_weight_sparsity', '    C10FlagParser_caffe2_dnnlowp_requantization_multiplier_precision', '    C10FlagParser_caffe2_dnnlowp_weight_p99_threshold', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_kind', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_precision'];['    adjust_hist_to_include_zero(const Histogram & hist,float *min,float *max)', '    StringToKind(const string & s)', '    GetDefaultInstance', '    C10FlagParser_caffe2_dnnlowp_activation_p99_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_kind(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_activation_quantization_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_copy_to_32bit_frequency(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_eltwise_quantization_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_force_scale_power_of_two(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_force_slow_path(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_nbits_in_non_outlier(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_preserve_activation_sparsity(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_preserve_weight_sparsity(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_requantization_multiplier_precision(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_p99_threshold(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_kind(const std::string & content)', '    C10FlagParser_caffe2_dnnlowp_weight_quantization_precision(const std::string & content)', '    ChooseQuantizationParams(const float *values,int len,QuantizationKind kind,int precision,bool preserve_sparsity)', '    ChooseQuantizationParams(const float *values,int len,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,QuantizationKind kind,int precision,bool preserve_sparsity,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,bool is_weight)', '    ChooseRequantizationMultiplier(float real_multiplier,TensorQuantizationParams target_qparams)', '    QuantizationFactory(int activation_precision,int weight_precision,int requantization_multiplier_precision,int eltwise_quantize_precision,bool preserve_activation_sparsity,bool preserve_weight_sparsity,bool force_scale_power_of_two,QuantizationKind activation_kind,QuantizationKind weight_kind,float weight_p99_threshold,float activation_p99_threshold)'];
ConstexprCrc_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 17;  3; 3;1;  10; 0;0;8;2;6;0.30;0;['    QuantizationFactory'];['    adjust_hist_to_include_zero(const Histogram & hist,float *min,float *max)', '    StringToKind(const string & s)', '    GetDefaultInstance', '    ChooseQuantizationParams(float min,float max,int precision,bool preserve_sparsity,bool is_signed)', '    ChooseQuantizationParams(float min,float max,bool is_weight)', '    ChooseQuantizationParams(const float *values,int len,QuantizationKind kind,int precision,bool preserve_sparsity)', '    ChooseQuantizationParams(const float *values,int len,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,QuantizationKind kind,int precision,bool preserve_sparsity,bool is_weight)', '    ChooseQuantizationParams(const Histogram & hist,bool is_weight)', '    ChooseRequantizationMultiplier(float real_multiplier,TensorQuantizationParams target_qparams)', '    GetActivationKind', '    GetActivationPrecision', '    GetEltwiseQuantizePrecision', '    GetPreserveActivationSparsity', '    GetPreserveWeightSparsity', '    GetWeightKind', '    GetWeightPrecision', '    QuantizationFactory(int activation_precision,int weight_precision,int requantization_multiplier_precision,int eltwise_quantize_precision,bool preserve_activation_sparsity,bool preserve_weight_sparsity,bool force_scale_power_of_two,QuantizationKind activation_kind,QuantizationKind weight_kind,float weight_p99_threshold,float activation_p99_threshold)', '    SetActivationP99Threshold(float threshold)', '    SetWeightP99Threshold(float threshold)', '    ChooseQuantizationParams'];
either_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 1246;  44; 118;6;  1121; 0;819;199;452;279;0.04;97;['    DNNLowPOp'];['    dnnlowp_get_max_threads', '    dnnlowp_get_num_threads', '    dnnlowp_get_thread_num', '    arguments_parsed_', '    debug_def', '    dequantize_output_', '    DNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    engine', '    Fp32Op_', '    GetOutputQuantizationParams_', '    GetQuantizedOutputData_', '    InputTensorCPU_(int idx)', '    measure_quantization_error_', '    MeasureQuantizationError_', '    OutputTensorCPU_(int idx)', '    OutputTensorCPU_(int idx,at::IntArrayRef dims,at::TensorOptions options)', '    ParseDNNLowPOperatorArguments_', '    RunOnDeviceEpilogue_', '    static_assert(std::is_integral,)', '    type', '    ~DNNLowPOp', '    Output', '    RunOnDevice'];
flags_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 23;  2; 6;6;  7; 4;3;4;2;9;0.29;2;[];['    GetWorkPerThread_(size_t work,int nthreads,int work_align)', '    Get1DPartition(size_t work,int nthreads,int tid,int work_align)', '    Get1DPartitionOf2D(int m,int n,int nthreads,int tid,int *m_begin,int *m_end,int *n_begin,int *n_end,int n_align)'];
Half_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 108;  13; 14;3;  86; 0;63;24;44;17;0.15;3;[];['    Get1DPartition(size_t work,int nthreads,int tid,int work_align)', '    Get1DPartitionOf2D(int m,int n,int nthreads,int tid,int *m_begin,int *m_end,int *n_begin,int *n_end,int n_align)'];
intrusive_ptr_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 3384;  25; 333;14;  3013; 4;792;723;427;573;0.01;164;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUDo', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Do'];
logging_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 96;  8; 14;11;  59; 6;39;25;64;37;0.14;6;['    final'];['    checkAndGetOuterNames(const OperatorDef & operator_def)', '    DoOp(const OperatorDef & operator_def,Workspace *ws)', '    getInputBlobNames(const OperatorDef & operator_def)', '    getOutputBlobNames(const OperatorDef & operator_def)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    Output', '    RunOnDevice'];
Macros.h;C++;pytorch-master/pytorch-master/c10/test/util; 9;  1; 2;7;  0; 2;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDADo'];
Metaprogramming_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 220;  2; 34;3;  182; 0;84;83;76;91;0.01;32;['    DotGenerator'];['    convertToDotRecordString(GraphT *g,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(GraphT *g,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(GraphT *g,const std::vector & subgraphs,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    convertToDotString(const GraphT::SubgraphType & sg,DotGenerator::NodePrinter nodePrinter,DotGenerator::EdgePrinter edgePrinter)', '    defaultEdgePrinter(GraphT::EdgeRef)', '    createSubgraph', '    convert(const GraphT::SubgraphType & sg,const std::vector & subgraphs)', '    convert(const GraphT::SubgraphType & sg)', '    convertStruct(const GraphT::SubgraphType & sg)', '    DotGenerator(NodePrinter nodePrinter,EdgePrinter edgePrinter)', '    generateNode(GraphT::NodeRef node,const GraphT::SubgraphType & sg,std::ostringstream & output)', '    getOperatorDotString(GraphT::NodeRef op)', '    getOperatorSubtreeDotString(std::vector ops)'];
registry_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 91;  8; 16;7;  52; 9;9;24;9;27;0.15;12;[];['    Doubler(int A,int B)', '    forward', '    get'];
string_view_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 1685;  63; 142;12;  1522; 9;118;1392;79;937;0.04;33;[];['    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(Tensor input)', '    pretty_print(std::ostream & stream)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)'];
tempfile_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 9;  1; 1;4;  0; 4;0;0;0;1;0.00;0;[];['    DropoutOptions(double p)'];
TypeIndex_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 225;  8; 18;17;  188; 0;52;123;15;58;0.04;7;[];['    _alpha_dropout(Args,...)', '    _dropout(Args,...)', '    _dropout_impl(T & input,double p,bool train)', '    _feature_alpha_dropout(Args,...)', '    _feature_dropout(Args,...)', '    alpha_dropout(const Tensor & input,double p,bool train)', '    alpha_dropout_(Tensor & input,double p,bool train)', '    dropout(const Tensor & input,double p,bool train)', '    dropout_(Tensor & input,double p,bool train)', '    feature_alpha_dropout(const Tensor & input,double p,bool train)', '    feature_alpha_dropout_(Tensor & input,double p,bool train)', '    feature_dropout(const Tensor & input,double p,bool train)', '    feature_dropout_(Tensor & input,double p,bool train)', '    is_fused_kernel_acceptable(const Tensor & input,double p)', '    make_feature_noise(const Tensor & input)', '    multiply(Tensor & input,const Tensor & noise)', '    multiply(const Tensor & input,const Tensor & noise)', '    result'];
TypeList_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 154;  0; 22;3;  129; 0;22;104;18;101;0.00;8;[];[];
TypeTraits_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 155;  2; 25;2;  126; 0;25;103;19;93;0.02;8;[];[];
Array.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
Array.h;C++;pytorch-master/pytorch-master/c10/util; 323;  56; 61;8;  196; 3;0;0;0;0;0.29;0;['    GetDropoutGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUDropout', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Dropout', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DropoutGrad', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
ArrayRef.h;C++;pytorch-master/pytorch-master/c10/util; 280;  83; 48;8;  148; 0;43;65;46;55;0.56;33;['    final', '    final'];['    IDEEPDropoutGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPDropoutOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPDropoutGradientOp', '    ~IDEEPDropoutOp'];
Backtrace.h;C++;pytorch-master/pytorch-master/c10/util; 17;  2; 4;7;  6; 0;3;6;0;2;0.33;0;['    final', '    final'];['    DropoutGradientOp(Args,...)', '    DropoutOp(Args,...)', '    RunOnDevice'];
BFloat16-inl.h;C++;pytorch-master/pytorch-master/c10/util; 267;  11; 36;3;  219; 0;93;92;68;91;0.05;61;[];[];
BFloat16.h;C++;pytorch-master/pytorch-master/c10/util; 90;  5; 18;17;  40; 12;16;22;10;23;0.13;5;[];['    self', '    THPDtype_init(PyObject *module)', '    THPDtype_is_complex(THPDtype *self,PyObject *noargs)', '    THPDtype_is_floating_point(THPDtype *self,PyObject *noargs)', '    THPDtype_is_signed(THPDtype *self,PyObject *noargs)', '    THPDtype_New(at::ScalarType scalar_type,const std::string & name)', '    THPDtype_reduce(THPDtype *self,PyObject *noargs)', '    THPDtype_repr(THPDtype *self)'];
C++17.h;C++;pytorch-master/pytorch-master/c10/util; 209;  21; 41;40;  86; 27;11;61;11;62;0.24;11;[];['    THPDtype_Check(PyObject *obj)', '    THPDtype_init(PyObject *module)', '    THPDtype_New(at::ScalarType scalar_type,const std::string & name)', '    THPPythonScalarType_Check(PyObject *obj)'];
Complex.h;C++;pytorch-master/pytorch-master/c10/util; 45;  1; 16;5;  24; 0;8;23;8;18;0.04;8;[];[];
ConstexprCrc.h;C++;pytorch-master/pytorch-master/c10/util; 130;  5; 8;5;  115; 0;96;103;8;16;0.04;6;['    C10FlagParser_model', '    C10FlagParser_output'];['    main(int argc,char **argv)', '    dump_opnames(const Module & m,std::unordered_set & opnames)', '    C10FlagParser_model(const std::string & content)', '    C10FlagParser_output(const std::string & content)'];
either.h;C++;pytorch-master/pytorch-master/c10/util; 222;  21; 24;5;  187; 0;0;0;0;0;0.11;0;['    DWConvMicrokernelTester'];['    channels(uint32_t channels)', '    channels', '    channels_', '    cr(uint32_t cr)', '    cr', '    cr_', '    inputStride(uint32_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    kernelHeight(uint32_t kernelHeight)', '    kernelHeight', '    kernelHeight_', '    kernelSize', '    kernelWidth(uint32_t kernelWidth)', '    kernelWidth', '    kernelWidth_', '    kernelZeroPoint(uint8_t kernelZeroPoint)', '    kernelZeroPoint', '    kernelZeroPoint_', '    outputStride(uint32_t outputStride)', '    outputStride', '    outputStride_', '    packedChannels', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    subsampling(uint32_t subsampling)', '    subsampling', '    subsampling_', '    test(pytorch_q8dwconv_up_ukernel_function q8dwconv)', '    test(pytorch_q8dwconv_mp_ukernel_function q8dwconv)', '    width(uint32_t width)', '    width', '    width_'];
Exception.cpp;C++;pytorch-master/pytorch-master/c10/util; 126;  11; 24;10;  83; 1;21;49;15;31;0.13;12;[];['    RemapHistograms(Histogram & src_hist,Histogram & dst_hist)', '    Add(float f)', '    Add(const float *f,int len)', '    DynamicHistogram(int nbins)', '    Finalize', '    Add(float f,uint64_t cnt)', '    Add(const float *f,int len)'];
Exception.h;C++;pytorch-master/pytorch-master/c10/util; 417;  158; 51;138;  73; 33;10;50;10;43;2.16;8;['    DynamicHistogram', '    Histogram'];['    Add(float f)', '    Add(const float *f,int len)', '    DynamicHistogram(int nbins)', '    Finalize', '    Add(float f,uint64_t cnt)', '    Add(const float *f,int len)', '    GetHistogram', '    Histogram(int nbins,float min,float max)', '    Histogram(float min,float max,const std::vector & bins)', '    Max', '    Min'];
flags_use_gflags.cpp;C++;pytorch-master/pytorch-master/c10/util; 38;  1; 3;5;  0; 30;0;0;0;0;0.00;0;[];['    TEST(DynamicHistogram,HistSimilar)'];
flags_use_no_gflags.cpp;C++;pytorch-master/pytorch-master/c10/util; 206;  20; 19;11;  157; 2;104;39;69;28;0.13;11;[];['    DynamicLibrary(const char *name)', '    sym(const char *name)', '    ~DynamicLibrary'];
flat_hash_map.h;C++;pytorch-master/pytorch-master/c10/util; 1524;  29; 81;22;  1395; 5;677;617;534;510;0.02;340;[];[];
Half-inl.h;C++;pytorch-master/pytorch-master/c10/util; 289;  12; 39;23;  205; 14;85;87;60;86;0.06;56;[];['    createPyObject(const at::Storage & storage)', '    createStorage(PyObject *obj)', '    get_backend(bool is_cuda,bool is_sparse)', '    get_type(at::Backend backend,at::ScalarType scalarType)', '    getDtype(at::ScalarType scalarType)', '    getLayout(at::Backend backend)', '    getPyTypeObject(const at::Storage & storage)', '    isStorage(PyObject *obj)', '    registerDtypeObject(THPDtype *dtype,at::ScalarType scalarType)', '    registerLayoutObject(THPLayout *layout,at::Backend backend)', '    registerStoragePyTypeObject(PyTypeObject *pytype,at::Backend backend,at::ScalarType scalarType)'];
Half.cpp;C++;pytorch-master/pytorch-master/c10/util; 14;  1; 3;2;  9; 0;2;6;2;3;0.11;1;[];['    createPyObject(const at::Storage & storage)', '    createStorage(PyObject *obj)', '    isStorage(PyObject *obj)', '    registerDtypeObject(THPDtype *dtype,at::ScalarType scalarType)', '    registerLayoutObject(THPLayout *layout,at::Backend backend)', '    registerStoragePyTypeObject(PyTypeObject *pytype,at::Backend backend,at::ScalarType scalarType)'];
Half.h;C++;pytorch-master/pytorch-master/c10/util; 489;  208; 43;68;  162; 20;81;95;36;90;1.28;15;[];['    operator()(const argument_type & edge)', '    move', '    Edge', '    Edge(std::shared_ptr function_,uint32_t input_nr_)', '    is_valid', '    operator!=(const Edge & other)', '    operator==(const Edge & other)', '    get_hash'];
in_place.h;C++;pytorch-master/pytorch-master/c10/util; 17;  1; 7;2;  8; 0;3;8;0;9;0.13;1;[];['    ComputeEditDistance(const char *word1,const char *word2,size_t maxEditDistance)'];
intrusive_ptr.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    ComputeEditDistance(const char *word1,const char *word2,size_t maxEditDistance)'];
intrusive_ptr.h;C++;pytorch-master/pytorch-master/c10/util; 776;  191; 99;24;  465; 18;9;35;10;26;0.41;9;[];['    GetArrayIndices(const Eigen::ArrayBase & array)', '    GetSubArray(const Eigen::ArrayBase & array,const Eigen::ArrayBase & indices,Eigen::ArrayBase *out_array)', '    GetSubArray(const Eigen::ArrayBase & array,const Eigen::ArrayBase & indices)', '    GetSubArray(const Eigen::ArrayBase & array,const std::vector & indices)', '    GetSubArrayRows(const Eigen::ArrayBase & array2d,const Eigen::ArrayBase & row_indices,Eigen::ArrayBase *out_array)'];
LeftRight.h;C++;pytorch-master/pytorch-master/c10/util; 164;  49; 26;6;  83; 0;0;0;0;0;0.59;0;[];[];
llvmMathExtras.h;C++;pytorch-master/pytorch-master/c10/util; 864;  234; 100;72;  435; 39;225;156;180;123;0.54;72;['    ClassWithDestructorCallback', '    DestructorCallback', '    final', '    OnlyMoveableClassWithDestructorCallback'];['    operator==(const MovableOnly & lhs,const MovableOnly & rhs)', '    TEST(EitherTest,SpaceUsage)', '    TEST(EitherTest,givenLeft)', '    TEST(EitherTest,givenRight)', '    TEST(EitherTest,givenMakeLeft)', '    TEST(EitherTest,givenMakeLeftWithSameType)', '    TEST(EitherTest,givenMakeRight)', '    TEST(EitherTest,givenMakeRightWithSameType)', '    TEST(EitherTest,givenMovableOnlyMakeLeft)', '    TEST(EitherTest,givenMovableOnlyMakeRight)', '    TEST(EitherTest,givenMultiParamMakeLeft)', '    TEST(EitherTest,givenMultiParamMakeRight)', '    TEST(EitherTest,givenLeftCopyConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssignedFromValue_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssignedFromValue_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveConstructed_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftCopyAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightCopyAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenLeftMoveAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_thenOldIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_withSameType_thenNewIsCorrect)', '    TEST(EitherTest,givenRightMoveAssigned_withSameType_thenOldIsCorrect)', '    TEST(EitherTest,givenLeft_whenModified_thenValueIsChanged)', '    TEST(EitherTest,givenRight_whenModified_thenValueIsChanged)', '    TEST(EitherTest,canEmplaceConstructLeft)', '    TEST(EitherTest,canEmplaceConstructRight)', '    TEST(EitherTest,givenEqualLefts_thenAreEqual)', '    TEST(EitherTest,givenEqualLefts_thenAreNotUnequal)', '    TEST(EitherTest,givenEqualRights_thenAreEqual)', '    TEST(EitherTest,givenEqualRights_thenAreNotUnequal)', '    TEST(EitherTest,givenLeftAndRight_thenAreNotEqual)', '    TEST(EitherTest,givenLeftAndRight_thenAreUnequal)', '    TEST(EitherTest,OutputLeft)', '    TEST(EitherTest,OutputRight)', '    TEST(EitherTest,givenLeftAndRightWithSameType_thenAreNotEqual)', '    TEST(EitherTest,givenLeftAndRightWithSameType_thenAreUnequal)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalled)', '    TEST(EitherTest_Destructor,RightDestructorIsCalled)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterCopying)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterCopying)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterMoving)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterMoving)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterAssignment)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterAssignment)', '    TEST(EitherTest_Destructor,LeftDestructorIsCalledAfterMoveAssignment)', '    TEST(EitherTest_Destructor,RightDestructorIsCalledAfterMoveAssignment)', '    test_with_matrix(std::vector,std::vector)', '    TestSpaceUsage', '    ClassWithDestructorCallback(const DestructorCallback *destructorCallback)', '    ClassWithDestructorCallback(const ClassWithDestructorCallback & rhs)', '    ~ClassWithDestructorCallback', '    EXPECT_CALLED(int times)', '    MovableOnly(int value)', '    MovableOnly', '    operator=(MovableOnly)', '    value', '    OnlyMoveableClassWithDestructorCallback(const DestructorCallback *destructorCallback)', '    OnlyMoveableClassWithDestructorCallback(OnlyMoveableClassWithDestructorCallback)', '    ~OnlyMoveableClassWithDestructorCallback'];
Logging.cpp;C++;pytorch-master/pytorch-master/c10/util; 315;  51; 30;28;  137; 92;63;53;50;64;0.37;23;['    ElementwiseRTCFunction', '    final'];['    ElementwiseRTCFunction', '    GetSource(int input_size,int output_size,const string command_string)', '    KernelName(Args,...)', '    ElementwiseRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~ElementwiseRTCOp'];
logging_is_google_glog.h;C++;pytorch-master/pytorch-master/c10/util; 52;  10; 8;21;  3; 20;0;2;1;2;3.33;0;[];['    Abs(const int N,const float *X,float *Y,CPUContext *)', '    Abs(const int N,const double *X,double *Y,CPUContext *)', '    Abs(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Abs(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Acos(const int N,const float *X,float *Y,CPUContext *)', '    Acos(const int N,const double *X,double *Y,CPUContext *)', '    Add(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Add(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Add(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Add(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    And(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    Asin(const int N,const float *X,float *Y,CPUContext *)', '    Asin(const int N,const double *X,double *Y,CPUContext *)', '    Atan(const int N,const float *X,float *Y,CPUContext *)', '    Atan(const int N,const double *X,double *Y,CPUContext *)', '    Axpby(const std::int64_t N,const float alpha,const float *X,const float beta,float *Y,CPUContext *)', '    Axpby(const std::int64_t N,const float *alpha,const float *X,const float *beta,float *Y,CPUContext *)', '    Axpy(const std::int64_t N,const float alpha,const float *X,float *Y,CPUContext *)', '    Axpy(const std::int64_t N,const float *alpha,const float *X,float *Y,CPUContext *)', '    BitwiseAnd(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseAnd(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseAnd(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    BitwiseOr(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseOr(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseOr(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    BitwiseXor(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    BitwiseXor(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    BitwiseXor(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Cbrt(const int N,const float *X,float *Y,CPUContext *)', '    Cbrt(const int N,const double *X,double *Y,CPUContext *)', '    CdfNorm(const int N,const float *X,float *Y,CPUContext *)', '    CdfNorm(const int N,const double *X,double *Y,CPUContext *)', '    Cos(const int N,const float *X,float *Y,CPUContext *)', '    Cos(const int N,const double *X,double *Y,CPUContext *)', '    Cosh(const int N,const float *X,float *Y,CPUContext *)', '    Cosh(const int N,const double *X,double *Y,CPUContext *)', '    Cube(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Cube(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Cube(const int N,const float *X,float *Y,CPUContext *)', '    Cube(const int N,const double *X,double *Y,CPUContext *)', '    Div(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Div(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Div(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Div(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    EQ(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    EQ(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    EQ(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    EQ(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    EQ(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Erf(const int N,const float *X,float *Y,CPUContext *)', '    Erf(const int N,const double *X,double *Y,CPUContext *)', '    Exp(const int N,const float *X,float *Y,CPUContext *)', '    Exp(const int N,const double *X,double *Y,CPUContext *)', '    GE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    GE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    GE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    GE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    GE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    GT(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    GT(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    GT(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    GT(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    GT(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Inv(const int N,const float *X,float *Y,CPUContext *)', '    Inv(const int N,const double *X,double *Y,CPUContext *)', '    LE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    LE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    LE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    LE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    LE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Log(const int N,const float *X,float *Y,CPUContext *)', '    Log(const int N,const double *X,double *Y,CPUContext *)', '    LT(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    LT(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    LT(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    LT(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    LT(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Max(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Max(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Max(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Max(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Min(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Min(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Min(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Min(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Mul(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Mul(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Mul(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Mul(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    NE(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    NE(const int N,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    NE(const int N,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    NE(const int N,const float *A,const float *B,bool *C,CPUContext *)', '    NE(const int N,const double *A,const double *B,bool *C,CPUContext *)', '    Neg(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Neg(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Neg(const int N,const float *X,float *Y,CPUContext *)', '    Neg(const int N,const double *X,double *Y,CPUContext *)', '    Or(const int N,const bool *A,const bool *B,bool *C,CPUContext *)', '    Powx(const int N,const float *A,const float b,float *Y,CPUContext *)', '    Powx(const int N,const double *A,const double b,double *Y,CPUContext *)', '    Rsqrt(const int N,const float *X,float *Y,CPUContext *)', '    Rsqrt(const int N,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float alpha,const float *X,float *Y,CPUContext *)', '    Scale(const int N,const float *alpha,const float *X,float *Y,CPUContext *)', '    Scale(const int N,const double alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const double *alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const float *alpha,const double *X,double *Y,CPUContext *)', '    Scale(const int N,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Scale(const int N,const std::int32_t *alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Scale(const int N,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Scale(const int N,const std::int64_t *alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Set(const std::int64_t N,const float alpha,float *Y,CPUContext *)', '    Set(const std::int64_t N,const double alpha,double *Y,CPUContext *)', '    Set(const std::int64_t N,const int alpha,int *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int8_t alpha,std::int8_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int16_t alpha,std::int16_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::int64_t alpha,std::int64_t *Y,CPUContext *)', '    Set(const std::int64_t N,const bool alpha,bool *Y,CPUContext *)', '    Set(const std::int64_t N,const char alpha,char *Y,CPUContext *)', '    Set(const std::int64_t N,const std::uint8_t alpha,std::uint8_t *Y,CPUContext *)', '    Set(const std::int64_t N,const std::uint16_t alpha,std::uint16_t *Y,CPUContext *)', '    Sign(const int N,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Sign(const int N,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Sign(const int N,const float *X,float *Y,CPUContext *)', '    Sign(const int N,const double *X,double *Y,CPUContext *)', '    Sin(const int N,const float *X,float *Y,CPUContext *)', '    Sin(const int N,const double *X,double *Y,CPUContext *)', '    SinCos(const int N,const float *X,float *S,float *C,CPUContext *)', '    SinCos(const int N,const double *X,double *S,double *C,CPUContext *)', '    Sinh(const int N,const float *X,float *Y,CPUContext *)', '    Sinh(const int N,const double *X,double *Y,CPUContext *)', '    Sqr(const int N,const float *X,float *Y,CPUContext *)', '    Sqr(const int N,const double *X,double *Y,CPUContext *)', '    Sqrt(const int N,const float *X,float *Y,CPUContext *)', '    Sqrt(const int N,const double *X,double *Y,CPUContext *)', '    Sub(const int N,const float *A,const float *B,float *C,CPUContext *)', '    Sub(const int N,const double *A,const double *B,double *C,CPUContext *)', '    Sub(const int N,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    Sub(const int N,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    Tan(const int N,const float *X,float *Y,CPUContext *)', '    Tan(const int N,const double *X,double *Y,CPUContext *)', '    Tanh(const int N,const float *X,float *Y,CPUContext *)', '    Tanh(const int N,const double *X,double *Y,CPUContext *)', '    Xor(const int N,const bool *A,const bool *B,bool *C,CPUContext *)'];
logging_is_not_google_glog.h;C++;pytorch-master/pytorch-master/c10/util; 248;  41; 32;94;  87; 30;26;53;25;35;0.47;14;[];['    Abs(int N,const T *X,T *Y,Context *context)', '    Acos(int N,const T *X,T *Y,Context *context)', '    Add(int N,const T *A,const T *B,T *C,Context *context)', '    And(int N,const T *A,const T *B,T *C,Context *context)', '    Asin(int N,const T *X,T *Y,Context *context)', '    Atan(int N,const T *X,T *Y,Context *context)', '    Axpby(std::int64_t N,TAlpha alpha,const TData *X,TAlpha beta,TData *Y,Context *context)', '    Axpby(std::int64_t N,const TAlpha *alpha,const TData *X,const TAlpha *beta,TData *Y,Context *context)', '    Axpy(std::int64_t N,TAlpha alpha,const TData *X,TData *Y,Context *context)', '    Axpy(std::int64_t N,const TAlpha *alpha,const TData *X,TData *Y,Context *context)', '    BitwiseAnd(int N,const T *A,const T *B,T *C,Context *context)', '    BitwiseOr(int N,const T *A,const T *B,T *C,Context *context)', '    BitwiseXor(int N,const T *A,const T *B,T *C,Context *context)', '    Cbrt(int N,const T *X,T *Y,Context *context)', '    CdfNorm(int N,const T *X,T *Y,Context *context)', '    Cos(int N,const T *X,T *Y,Context *context)', '    Cosh(int N,const T *X,T *Y,Context *context)', '    Cube(int N,const T *X,T *Y,Context *context)', '    Div(int N,const T *A,const T *B,T *C,Context *context)', '    EQ(int N,const T *A,const T *B,bool *C,Context *context)', '    Erf(int N,const T *X,T *Y,Context *context)', '    Exp(int N,const T *X,T *Y,Context *context)', '    GE(int N,const T *A,const T *B,bool *C,Context *context)', '    GT(int N,const T *A,const T *B,bool *C,Context *context)', '    Inv(int N,const T *X,T *Y,Context *context)', '    LE(int N,const T *A,const T *B,bool *C,Context *context)', '    Log(int N,const T *X,T *Y,Context *context)', '    LT(int N,const T *A,const T *B,bool *C,Context *context)', '    Max(int N,const T *A,const T *B,T *C,Context *context)', '    Min(int N,const T *A,const T *B,T *C,Context *context)', '    Mul(int N,const T *A,const T *B,T *C,Context *context)', '    NE(int N,const T *A,const T *B,bool *C,Context *context)', '    Neg(int N,const T *X,T *Y,Context *context)', '    Not(int N,const T *X,T *Y,Context *context)', '    Or(int N,const T *A,const T *B,T *C,Context *context)', '    Powx(int N,const T *A,const T b,T *Y,Context *context)', '    Rsqrt(int N,const T *X,T *Y,Context *context)', '    Scale(int N,TAlpha alpha,const TData *X,TData *Y,Context *context)', '    Scale(int N,const TAlpha *alpha,const TData *X,TData *Y,Context *context)', '    Set(std::int64_t N,T alpha,T *X,Context *context)', '    Sign(int N,const T *X,T *Y,Context *context)', '    Sin(int N,const T *X,T *Y,Context *context)', '    SinCos(int N,const T *X,T *S,T *C,Context *context)', '    Sinh(int N,const T *X,T *Y,Context *context)', '    Sqr(int N,const T *X,T *Y,Context *context)', '    Sqrt(int N,const T *X,T *Y,Context *context)', '    Sub(int N,const T *A,const T *B,T *C,Context *context)', '    Tan(int N,const T *X,T *Y,Context *context)', '    Tanh(int N,const T *X,T *Y,Context *context)', '    Xor(int N,const T *A,const T *B,T *C,Context *context)'];
math_compat.h;C++;pytorch-master/pytorch-master/c10/util; 114;  3; 2;4;  0; 105;0;0;0;0;0.00;0;['    AddDNNLowPOp'];['    AddDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice'];
Metaprogramming.h;C++;pytorch-master/pytorch-master/c10/util; 136;  36; 16;6;  82; 0;0;0;0;0;0.44;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAddGradient', '    GetGradientDefs', '    vector'];
numa.cpp;C++;pytorch-master/pytorch-master/c10/util; 132;  5; 13;10;  19; 92;5;9;5;14;0.26;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAdd'];
numa.h;C++;pytorch-master/pytorch-master/c10/util; 40;  19; 10;3;  9; 0;0;9;0;8;2.11;0;[];['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *,const TOut *,TGrad *dA,TGrad *dB,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)'];
Optional.h;C++;pytorch-master/pytorch-master/c10/util; 949;  79; 170;30;  654; 28;149;387;114;371;0.12;126;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAAdd', '    CAFFE_ANONYMOUS_VARIABLE_CUDAAddGradient'];
order_preserving_flat_hash_map.h;C++;pytorch-master/pytorch-master/c10/util; 1643;  57; 111;22;  1456; 5;0;0;0;0;0.04;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUDivGradient', '    BinaryElementwiseWithArgsGradientOp(Args,...)', '    ComputeDivGradient(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const TGrad *dC,const TIn *B,const TOut *C,TGrad *dA,TGrad *dB,CPUContext *context)', '    DoRunWithType', '    RunOnDevice', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *B,const TOut *C,TGrad *dA,TGrad *dB,CPUContext *context)', '    GetGradientDefs', '    vector'];
python_stub.h;C++;pytorch-master/pytorch-master/c10/util; 4;  0; 1;1;  2; 0;1;1;1;3;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUDiv'];
qint8.h;C++;pytorch-master/pytorch-master/c10/util; 17;  6; 3;2;  7; 0;1;5;1;9;0.86;1;[];['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)'];
quint8.h;C++;pytorch-master/pytorch-master/c10/util; 15;  4; 3;2;  7; 0;1;5;1;9;0.57;1;['    BinaryElementwiseDNNLowPOp', '    UnaryElementwiseWithArgsDNNLowPOp'];['    BinaryElementwiseDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    arguments_parsed_', '    RunOnDevice', '    UnaryElementwiseWithArgsDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
Registry.h;C++;pytorch-master/pytorch-master/c10/util; 304;  56; 41;87;  120; 3;48;62;33;33;0.47;14;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAddFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUDivFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUMulFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSubFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumFakeFp16', '    getSizeFromDims(const std::vector & dims)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const float *A,const float *B,float *C,CPUContext *context)'];
SmallVector.cpp;C++;pytorch-master/pytorch-master/c10/util; 52;  20; 8;1;  25; 0;16;9;13;5;0.80;1;[];['    ElementwiseLinearDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_'];
SmallVector.h;C++;pytorch-master/pytorch-master/c10/util; 1051;  184; 169;14;  691; 0;385;217;339;190;0.27;95;['    final'];['    ElementwiseLinearDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice'];
sparse_bitset.h;C++;pytorch-master/pytorch-master/c10/util; 894;  112; 131;7;  645; 0;393;230;326;204;0.17;65;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUElementwiseLinear', '    CAFFE_ANONYMOUS_VARIABLE_CPUElementwiseLinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ElementwiseLinear', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ElementwiseLinearGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
string_view.h;C++;pytorch-master/pytorch-master/c10/util; 683;  41; 94;39;  429; 88;184;177;105;135;0.10;85;['    final', '    final'];['    ElementwiseLinearGradientOp(Args,...)', '    ElementwiseLinearOp(Args,...)', '    GetSingleArgument', '    RunOnDevice'];
StringUtil.cpp;C++;pytorch-master/pytorch-master/c10/util; 43;  2; 9;4;  30; 0;18;11;16;10;0.07;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUIsMemberOf', '    CAFFE_ANONYMOUS_VARIABLE_CPUWhere', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsMemberOf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Where', '    get', '    get', '    get', '    get'];
StringUtil.h;C++;pytorch-master/pytorch-master/c10/util; 154;  12; 23;10;  112; 0;64;35;61;29;0.11;10;['    final', '    IsMemberOfValueHolder', '    final'];['    has_values', '    DoRunWithType', '    RunOnDevice', '    WhereOp(Args,...)', '    get', '    DoRunWithType', '    GetRepeatedArgument', '    IsMemberOfOp(Args,...)', '    RunOnDevice', '    ~IsMemberOfOp'];
thread_name.cpp;C++;pytorch-master/pytorch-master/c10/util; 24;  1; 6;10;  4; 6;0;3;0;2;0.25;1;['    MulDNNLowPOp'];['    GetQuantizationParameters_', '    MulDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
thread_name.h;C++;pytorch-master/pytorch-master/c10/util; 11;  1; 5;3;  3; 0;0;3;0;2;0.33;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMulGradient', '    ComputeMulGradient(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const TGrad *dC,const TIn *A,const TIn *B,TGrad *dA,TGrad *dB,CPUContext *context)', '    ComputeMulGradient(const int common_size,const int broadcast_size,const float *dC,const float *A,const float *B,float *dA,float *dB,CPUContext *context)', '    ComputeMulGradient(const int size,const float *dC,const float *A,const float *B,float *dA,float *dB)', '    GetGradientDefs', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *A,const TIn *B,const TOut *,TGrad *dA,TGrad *dB,CPUContext *context)', '    vector'];
Type.cpp;C++;pytorch-master/pytorch-master/c10/util; 59;  3; 4;17;  5; 40;1;3;1;2;0.60;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMul'];
TypeCast.h;C++;pytorch-master/pytorch-master/c10/util; 160;  54; 17;29;  57; 8;0;0;0;0;0.95;0;[];['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)'];
typeid.cpp;C++;pytorch-master/pytorch-master/c10/util; 92;  16; 11;6;  62; 1;42;54;37;89;0.26;33;[];['    CopyVector(const int N,const bool *x,bool *y)', '    CreateOperatorDef', '    TEST(ElementwiseGPUTest,And)', '    TEST(ElementwiseGPUTest,Or)', '    TEST(ElementwiseGPUTest,Xor)', '    TEST(ElementwiseGPUTest,Not)'];
typeid.h;C++;pytorch-master/pytorch-master/c10/util; 511;  120; 65;52;  282; 8;85;151;59;115;0.43;40;[];['    CopyVector(const int N,const bool *x,bool *y)', '    CopyVector(const int N,const int32_t *x,int32_t *y)', '    TEST(ElementwiseCPUTest,And)', '    TEST(ElementwiseTest,Or)', '    TEST(ElementwiseTest,Xor)', '    TEST(ElementwiseTest,Not)', '    TEST(ElementwiseTest,EQ)'];
TypeList.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    CopyVector(const int N,const T *x,T *y)', '    CreateOperatorDef', '    DefineOperator(const std::string & op_type)', '    elementwiseAnd', '    elementwiseEQ', '    elementwiseNot', '    elementwiseOr', '    elementwiseXor', '    FillTensor(caffe2::Workspace *ws,const std::string & name,const std::vector & shape,const std::vector & values)', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    result', '    CreateBlob', '    GetBlob'];
TypeList.h;C++;pytorch-master/pytorch-master/c10/util; 331;  101; 52;3;  176; 0;0;0;0;0;0.57;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseAnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseOr', '    CAFFE_ANONYMOUS_VARIABLE_CPUBitwiseXor', '    CAFFE_ANONYMOUS_VARIABLE_CPUEQ', '    CAFFE_ANONYMOUS_VARIABLE_CPUGE', '    CAFFE_ANONYMOUS_VARIABLE_CPUGT', '    CAFFE_ANONYMOUS_VARIABLE_CPULE', '    CAFFE_ANONYMOUS_VARIABLE_CPULT', '    CAFFE_ANONYMOUS_VARIABLE_CPUNE', '    CAFFE_ANONYMOUS_VARIABLE_CPUNot', '    CAFFE_ANONYMOUS_VARIABLE_CPUOr', '    CAFFE_ANONYMOUS_VARIABLE_CPUSign', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumReduceLike', '    CAFFE_ANONYMOUS_VARIABLE_CPUXor', '    RunWithBroadcast2(const T *a,T *y,size_t pre,size_t n,size_t post,CPUContext *)', '    RunWithBroadcastBack(const T *x,T *y,size_t post,size_t n,CPUContext *)', '    RunWithBroadcastFront(const T *x,T *y,size_t pre,size_t n,CPUContext *)', '    sum2one(const T *x,T *y,size_t n)', '    DoRunWithType'];
TypeTraits.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;['    final', '    final', '    final', '    final'];['    RunWithBroadcast2(const T *a,T *y,size_t pre,size_t n,size_t post,CPUContext *)', '    RunWithBroadcastBack(const T *x,T *y,size_t post,size_t n,CPUContext *)', '    RunWithBroadcastFront(const T *x,T *y,size_t pre,size_t n,CPUContext *)', '    sum2one(const T *x,T *y,size_t n)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC_data,const TIn *A_data,const TIn *B_data,const TOut *C_data,TGrad *dA_data,TGrad *dB_data,Context *context)', '    BinaryFunctorWithDefaultCtor(OperatorBase &)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A_data,const TIn *B_data,TOut *C_data,Context *context)', '    functor', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    BinaryElementwiseWithArgsGradientOp(Args,...)', '    BinaryElementwiseWithArgsOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    ones_', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    sum_buffer_', '    SumReduceLikeOp(Args,...)', '    UnaryElementwiseWithArgsOp(Args,...)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    operator()(const int N,const bool *X,bool *Y,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    functor', '    operator()(const int size,const TIn *X,TOut *Y,Context *context)', '    UnaryFunctorWithDefaultCtor(OperatorBase &)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)', '    call', '    back_inserter'];
UniqueVoidPtr.cpp;C++;pytorch-master/pytorch-master/c10/util; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];['    BitwiseDocGenerator(const char *name)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Add', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AddGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_And', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseAnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseOr', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BitwiseXor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Div', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DivGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EQ', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MulGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NE', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Not', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Or', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sub', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SubGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumReduceLike', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Xor', '    ComparisonDocGenerator(const char *name,const char *desc,const char *extra)', '    ElementwiseOpShapeInference(const OperatorDef & def,const std::vector & in)', '    LogicalDocGenerator(const char *name,const char *extra)', '    MathDocGenerator(const char *name,const char *extra)'];
UniqueVoidPtr.h;C++;pytorch-master/pytorch-master/c10/util; 121;  44; 11;3;  65; 0;19;43;20;30;0.68;16;[];['    ComputeBinaryBroadcastBackwardAxes(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_axes,std::vector *B_axes)', '    ComputeBinaryBroadcastBackwardDims(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_back_dims,std::vector *B_back_dims)', '    ComputeBinaryBroadcastForwardDims(const std::vector & A_dims,const std::vector & B_dims)', '    ComputeLegacyBroadcastSizes(const Tensor & A,const Tensor & B,int axis)'];
variant.h;C++;pytorch-master/pytorch-master/c10/util; 2857;  296; 384;420;  1348; 514;0;0;0;0;0.22;0;[];['    ComputeBinaryBroadcastBackwardAxes(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_axes,std::vector *B_axes)', '    ComputeBinaryBroadcastBackwardDims(const std::vector & A_dims,const std::vector & B_dims,std::vector *A_back_dims,std::vector *B_back_dims)', '    ComputeBinaryBroadcastForwardDims(const std::vector & A_dims,const std::vector & B_dims)', '    ComputeLegacyBroadcastSizes(const Tensor & A,const Tensor & B,int axis)'];
aten_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/aten; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSubGradient', '    GetGradientDefs', '    vector'];
aten_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/aten; 12;  0; 3;2;  7; 0;0;5;0;8;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSub'];
aten_op_template.h;C++;pytorch-master/pytorch-master/caffe2/contrib/aten; 216;  7; 16;22;  166; 6;82;115;140;85;0.04;19;[];['    Backward(const std::vector & A_dims,const std::vector & B_dims,const TGrad *dC,const TIn *,const TIn *,const TOut *,TGrad *dA,TGrad *dB,Context *context)', '    Forward(const std::vector & A_dims,const std::vector & B_dims,const TIn *A,const TIn *B,TOut *C,Context *context)'];
elementwise_fp16_fake_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 82;  2; 16;7;  59; 0;18;26;14;33;0.03;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDASub', '    CAFFE_ANONYMOUS_VARIABLE_CUDASubGradient'];
fp16_fma.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 119;  44; 19;4;  53; 0;40;25;21;20;0.83;1;[];['    main(int argc,const char *[] argv)'];
fp16_fma.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 14;  3; 5;2;  5; 0;0;5;0;4;0.60;0;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumRelu', '    GetQuantizationParameters_', '    SumDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
fp16_fma_test.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 41;  0; 5;8;  17; 12;10;5;11;7;0.00;2;[];['    ElementWiseSumAVX2(const T *input0,const T *input1,T *output,int len,float a_scale,int32_t a_zero_point,float b_scale,int32_t b_zero_point,float c_scale,int32_t c_zero_point)'];
lengths_reducer_fused_4bit_rowwise_fp16_fake_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 163;  7; 21;1;  141; 0;117;123;4;33;0.05;8;['    final'];['    IDEEPSumOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPSumOp'];
lengths_reducer_fused_4bit_rowwise_fp16_fake_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 233;  14; 35;5;  180; 0;121;73;97;83;0.08;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sum'];
lengths_reducer_fused_8bit_rowwise_fp16_fake_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 332;  26; 50;4;  253; 0;181;81;134;86;0.10;4;['    SumReluOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSumRelu', '    DoRunWithType', '    RunOnDevice', '    SumReluOp(const OperatorDef & operator_def,Workspace *ws)'];
lengths_reducer_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 217;  7; 16;2;  196; 0;0;0;0;0;0.04;0;['    GetEluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUElu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Elu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EluGradient', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
lengths_reducer_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 268;  30; 31;5;  212; 0;153;67;84;78;0.14;5;[];['    EluFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    EluGradientFunctor(OperatorBase & op)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)'];
spatial_batch_norm_fp16_fake_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 392;  9; 52;12;  322; 0;200;160;185;160;0.03;9;[];['    final', '    final', '    CuDNNActivationGradientOp(Args,...)', '    CuDNNActivationOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice'];
unary_fp16_fake_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 613;  17; 202;3;  398; 0;334;258;57;66;0.04;17;[];['    EmbeddingBagImpl(const EmbeddingBagOptions & options_)', '    forward(const Tensor & input,const Tensor & offsets,const Tensor & per_sample_weights)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    EmbeddingImpl(const EmbeddingOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters'];
unary_fp16_fake_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 64;  3; 9;5;  50; 0;20;22;15;14;0.06;4;[];['    embedding(const Tensor & weight,const Tensor & indices,int64_t padding_idx,bool scale_grad_by_freq,bool sparse)', '    embedding_backward(const Tensor & grad,const Tensor & indices,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq,bool sparse)', '    embedding_dense_backward_cpu(const Tensor & grad_,const Tensor & indices,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq)', '    embedding_renorm_cpu_(Tensor & self,const Tensor & indices,double max_norm,double norm_type)', '    embedding_sparse_backward(const Tensor & grad_,const Tensor & indices_,int64_t num_weights,int64_t padding_idx,bool scale_grad_by_freq)', '    weight_size'];
allgather_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 130;  28; 22;8;  74; 0;26;36;51;90;0.38;5;[];['    EmbeddingBagOptions(int64_t num_embeddings,int64_t embedding_dim)', '    EmbeddingOptions(int64_t num_embeddings,int64_t embedding_dim)'];
allreduce_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 120;  16; 11;7;  90; 0;47;29;32;58;0.18;7;[];[];
allreduce_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 134;  12; 23;8;  93; 0;36;41;67;95;0.13;5;[];[];
barrier_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 11;  3; 3;1;  7; 0;0;7;0;7;0.43;0;[];[];
barrier_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 63;  5; 9;7;  44; 0;6;20;3;50;0.11;3;[];['    EmbeddingLookupGenericSlow(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)'];
broadcast_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 36;  3; 6;2;  28; 0;17;9;11;8;0.11;1;[];['    EmbeddingLookup(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)'];
broadcast_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 38;  3; 7;3;  28; 0;0;16;0;64;0.11;0;[];['    EmbeddingLookup_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)'];
common.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 48;  3; 7;10;  24; 8;13;8;10;5;0.13;2;[];['    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)'];
common.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 73;  6; 15;6;  48; 0;12;29;11;22;0.13;5;[];['    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)'];
common_world_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 249;  7; 35;15;  188; 7;79;81;102;107;0.04;13;[];['    EmbeddingLookupGenericSlowIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_float_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_half_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_IndexType_uint8_t_float_true__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)'];
common_world_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 35;  5; 8;4;  21; 0;0;14;0;13;0.24;0;[];['    EmbeddingLookupIdx(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,OutType *out)'];
context.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 12;  1; 5;3;  4; 0;2;4;2;7;0.25;2;[];['    EmbeddingLookupIdx_int32_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int32_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_float_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const float *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_half_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const at::Half *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float_false__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)', '    EmbeddingLookupIdx_int64_t_uint8_t_float_true__avx2_fma(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,const float *scale_bias,bool normalize_by_lengths,float *out)'];
py_export.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 15;  2; 4;2;  9; 0;2;6;2;5;0.22;1;[];['    _embedding_bag_dense_backward_cpu_max(const Tensor & grad,const Tensor & bag_size,const Tensor & max_indices,int64_t num_weights)', '    compute_counts(int64_t num_weights,int64_t *indices_data,int64_t indices_length)', '    compute_counts_uniq(int64_t num_weights,int64_t *indices_data,int64_t indices_length,const std::vector & counts)', '    apply_bag_size(const Tensor & offsets,const Tensor & indices,const int64_t mode,Tensor & output,const Tensor & bag_size)', '    apply_bag_size_backward(const Tensor & offsets,const Tensor & indices,const int64_t mode,Tensor & output,const Tensor & offset2bag,const Tensor & bag_size)', '    index_select_scale_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & scale,const Tensor & src,Tensor & output,const Tensor &,bool)', '    make_bag_size(const Tensor & offsets,const Tensor & indices,const int64_t mode,const bool requires_grad)', '    make_offset2bag(const Tensor & offsets,const Tensor & indices,Tensor & offset2bag)', '    _embedding_bag_sparse_backward(const Tensor & grad_,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,const Tensor & bag_size_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights)', '    _embedding_bag_backward(const Tensor & grad,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,const Tensor & bag_size_,const Tensor & max_indices_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,bool sparse,const Tensor & per_sample_weights)', '    _embedding_bag_dense_backward_cpu(const Tensor & grad_,const Tensor & indices_,const Tensor & offsets_,const Tensor & offset2bag__,const Tensor & bag_size_,const Tensor & max_indices_,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights_)', '    _embedding_bag_dense_backward_cpu_sum_mean(const Tensor & grad,const Tensor & indices_,const Tensor & offsets_,const Tensor & offset2bag__,int64_t num_weights,bool scale_grad_by_freq,int64_t mode,const Tensor & per_sample_weights_,Tensor & index_grad_weight)', '    _embedding_bag_per_sample_weights_backward_cpu(const Tensor & grad,const Tensor & weight,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,int64_t mode)', '    _embedding_bag_per_sample_weights_backward_cpu_template(const Tensor & grad,const Tensor & weight,const Tensor & indices,const Tensor & offsets,const Tensor & offset2bag,int64_t mode)', '    _embedding_bag_cpu(const Tensor & weight,const Tensor & indices,const Tensor & offsets,const bool scale_grad_by_freq,const int64_t mode,bool sparse,const Tensor & per_sample_weights,bool include_last_offset)', '    embedding_bag(const Tensor & weight,const Tensor & indices,const Tensor & offsets,const bool scale_grad_by_freq,const int64_t mode,bool sparse,const Tensor & per_sample_weights,bool include_last_offset)', '    embedding_bag_cpu_max(const Tensor & weight,const Tensor & indices,const Tensor & offset2bag,const Tensor & output,const Tensor & bag_size,const Tensor & offsets)', '    index_select_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & src,Tensor & output,const Tensor &,bool)', '    index_select_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & src,Tensor & output,const Tensor & offsets,bool include_last_offset)', '    index_select_scale_add(const Tensor & select_indices,const Tensor & add_indices,const Tensor & scale,const Tensor & src,Tensor & output,const Tensor & offsets,bool include_last_offset)', '    isFastPathIndexSelect(const Tensor & src,Tensor & output)', '    isFastPathIndexSelectScale(const Tensor & src,const Tensor & scale,Tensor & output)', '    fast_path_sum'];
reduce_scatter_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 53;  18; 7;3;  28; 0;14;9;7;8;0.64;1;[];[];
reduce_scatter_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 131;  28; 22;8;  75; 0;25;36;57;93;0.37;5;['    Emulator'];['    init', '    run(const uint64_t iterations)', '    ~Emulator'];
store_handler.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 35;  2; 11;4;  20; 0;1;13;1;10;0.10;3;[];['    enforce_finite_op_impl_cpu(const at::Tensor & input_)'];
cuda_nccl_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/nccl; 327;  15; 35;15;  249; 18;145;97;103;151;0.06;12;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUEnforceFinite', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnforceFinite', '    DoRunWithType'];
cuda_nccl_gpu.h;C++;pytorch-master/pytorch-master/caffe2/contrib/nccl; 63;  4; 11;25;  25; 0;6;21;0;18;0.16;6;['    final'];['    buffer_', '    DoRunWithType', '    EnforceFiniteOp(Args,...)', '    EnforceOnCPU(const Tensor & input)', '    RunOnDevice'];
nnpack_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/nnpack; 352;  25; 34;15;  278; 2;170;146;122;88;0.09;14;[];['    call_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputBuffer)', '    call_post_hooks(Node & fn,variable_list outputs,const variable_list & inputs)', '    call_pre_hooks(Node & fn,variable_list inputs)', '    is_compatible_type(const at::TensorOptions & expected,const at::TensorOptions & actual)', '    forked_autograd_child', '    track_bad_autograd_forks', '    event', '    guard', '    parent_stream_guard', '    queue', '    set_default_engine_stub(EngineStub stub)', '    graph_task_completed(const std::shared_ptr & graph_task)', '    validate_outputs(const edge_list & edges,variable_list & grads,const std::function & format_error)', '    add_thread_pool_task(const std::weak_ptr & graph_task)', '    compute_dependencies(Node *root,GraphTask & task)', '    Engine', '    enqueue_blocked_task_on_cpu(NodeTask task)', '    evaluate_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputs)', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_graph_task_with_continuation(const std::shared_ptr & graph_task)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    get_base_engine', '    get_default_engine', '    graph_task_exec_post_processing(const std::shared_ptr & graph_task)', '    init_local_ready_queue(std::shared_ptr ready_queue)', '    initialize_device_threads_pool', '    is_checkpoint_valid', '    mark_graph_task_completed(const std::shared_ptr & graph_task)', '    queue_callback(std::function callback)', '    ready_queue(const std::shared_ptr & graph_task,at::Device device)', '    ready_queue_by_index(const std::shared_ptr & graph_task,int device_index)', '    ready_queue_size(const std::shared_ptr & graph_task,at::Device device)', '    reentrant_thread_init', '    release_workers', '    set_device(int device)', '    start_device_threads', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_main(const std::shared_ptr & graph_task,bool reentrant_thread)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)', '    ~Engine', '    Frame(Node *fn)', '    get_next_fn', '    init_to_execute(Node & graph_root,const edge_list & outputs)', '    set_exception(std::exception & e,const std::shared_ptr & fn)', '    set_exception_without_signal(const std::shared_ptr & fn)', '    GraphTaskGuard(std::shared_ptr graph_task)', '    restore_current_graph_task', '    ~GraphTaskGuard', '    getReentrantDepth', '    empty', '    pop', '    push(NodeTask item,bool incrementOutstandingTasks)', '    pushShutdownTask', '    size'];
context.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/opencl; 107;  10; 20;5;  81; 0;45;42;31;50;0.12;13;[];['    set_default_engine_stub(EngineStub stub)', '    validate_outputs(const edge_list & edges,variable_list & grads,const std::function & format_error)', '    get_base_engine', '    get_default_engine', '    add_thread_pool_task(const std::weak_ptr & graph_task)', '    compute_dependencies(Node *root,GraphTask & task)', '    Engine', '    Engine', '    Engine', '    enqueue_blocked_task_on_cpu(NodeTask task)', '    evaluate_function(std::shared_ptr & graph_task,Node *func,InputBuffer & inputs)', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_graph_task_with_continuation(const std::shared_ptr & graph_task)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    graph_task_exec_post_processing(const std::shared_ptr & graph_task)', '    init_local_ready_queue(std::shared_ptr ready_queue)', '    initialize_device_threads_pool', '    is_checkpoint_valid', '    make_anomaly_metadata', '    mark_graph_task_completed(const std::shared_ptr & graph_task)', '    queue_callback(std::function callback)', '    ready_queue(const std::shared_ptr & graph_task,at::Device device)', '    ready_queue_by_index(const std::shared_ptr & graph_task,int device_index)', '    ready_queue_size(const std::shared_ptr & graph_task,at::Device device)', '    reentrant_thread_init', '    release_workers', '    set_device(int device)', '    start_device_threads', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_main(const std::shared_ptr & task,bool reentrant_thread)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)', '    ThreadPoolShared', '    ~Engine', '    can_checkpoint', '    Capture(int input_idx,int output_idx)', '    should_execute', '    GraphTask(bool keep_graph,bool grad_mode,int reentrant_depth,std::shared_ptr cpu_ready_queue,bool exit_on_error)', '    init_to_execute(Node & graph_root,const edge_list & outputs)', '    set_exception(std::exception & e,const std::shared_ptr & fn)', '    set_exception_without_signal(const std::shared_ptr & fn)', '    getReentrantDepth', '    NodeTask(std::weak_ptr base,std::shared_ptr fn,InputBuffer inputs,bool isShutdownTask)', '    operator()(NodeTask const & t1,NodeTask const & t2)', '    empty', '    pop', '    push(NodeTask item,bool incrementOutstandingTasks)', '    pushShutdownTask', '    size'];
context.h;C++;pytorch-master/pytorch-master/caffe2/contrib/opencl; 104;  10; 18;14;  67; 1;14;37;11;52;0.15;11;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureClipped', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureClipped', '    DoRunWithType'];
cl.hpp;C++;pytorch-master/pytorch-master/caffe2/contrib/opencl/OpenCL; 12906;  1085; 1087;774;  8536; 1620;2457;4864;929;1559;0.13;395;['    final'];['    DoRunWithType', '    EnsureClippedOp(Args,...)', '    GetSingleArgument', '    RunOnDevice'];
cuda_profile_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/prof; 104;  6; 17;5;  80; 0;49;54;39;58;0.07;16;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureCPUOutput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureCPUOutput'];
prof_dag_stats_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/prof; 26;  2; 4;1;  21; 0;17;21;1;8;0.10;2;['    EnsureCPUOutputOp'];['    CopyWithContext', '    EnsureCPUOutputOp(Args,...)', '    Input', '    InputIsTensorType', '    Output', '    RunOnDevice'];
script_module_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/pytorch; 158;  20; 19;5;  116; 0;54;61;66;83;0.17;12;[];['    TEST(EnumTest,AllEnums)'];
shm_mutex.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/shm_mutex; 17;  0; 3;1;  13; 0;6;5;5;5;0.00;3;[];[];
shm_mutex.h;C++;pytorch-master/pytorch-master/caffe2/contrib/shm_mutex; 343;  48; 37;13;  245; 0;136;73;110;83;0.20;14;[];[];
tensorrt_op_trt.h;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 33;  1; 8;6;  19; 0;3;15;17;37;0.05;4;[];['    EraseNumberTypesOnBlock(Block *block)', '    EraseNumberTypes(const std::shared_ptr & graph)'];
tensorrt_tranformer.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 532;  35; 57;12;  430; 0;284;186;215;134;0.08;15;[];['    EraseNumberTypes(const std::shared_ptr & graph)'];
tensorrt_tranformer.h;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 92;  12; 15;11;  55; 0;6;52;0;17;0.22;6;['    GetErfGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUErf', '    CAFFE_ANONYMOUS_VARIABLE_CPUErfGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Erf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ErfGradient', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    GetGradientDefs', '    vector'];
trt_utils.h;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 55;  1; 10;4;  40; 0;12;18;17;11;0.03;4;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
ctc_op.cpp;C++;pytorch-master/pytorch-master/caffe2/contrib/warpctc; 42;  4; 6;9;  23; 3;7;17;6;19;0.17;5;[];[];
ctc_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/warpctc; 127;  7; 17;20;  83; 0;37;35;50;53;0.08;2;[];['    requires_grad_leaf_error(bool requires_grad)'];
allocator.cc;C++;pytorch-master/pytorch-master/caffe2/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    get_stacked_errors(const std::vector & error_stack)', '    update_pending_range(const SourceRange & range)', '    current_call_stack', '    CallStack(const std::string & name)', '    ~CallStack', '    ErrorReport(const ErrorReport & e)', '    ErrorReport(SourceRange r)', '    what'];
allocator.h;C++;pytorch-master/pytorch-master/caffe2/core; 4;  1; 0;4;  0; 0;0;0;0;0;0.00;0;[];['    operator<<(const ErrorReport & e,const T & t)', '    update_pending_range(const SourceRange & range)', '    current_call_stack', '    CallStack(const std::string & name)', '    ~CallStack', '    ErrorReport(const ErrorReport & e)', '    ErrorReport(SourceRange r)', '    ErrorReport(const TreeRef & tree)', '    ErrorReport(const Token & tok)', '    what'];
asan.h;C++;pytorch-master/pytorch-master/caffe2/core; 32;  4; 6;22;  0; 10;0;0;0;0;0.00;0;[];[];
blob_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 227;  9; 15;46;  161; 0;116;55;343;143;0.06;17;['    ExprEval', '    SimpleIREvaluator', '    Value', '    VarSubMutator'];['    evaluateOp(const Expr *v)', '    args(,...)', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    as_vec', '    div_value(T lhs,T rhs)', '    div_value(T lhs,T rhs)', '    div_value(bool lhs,bool rhs)', '    handle(v)', '    mod_value(T lhs,T rhs)', '    mod_value(T lhs,T rhs)', '    mod_value(bool lhs,bool rhs)', '    Substitute(const Expr *expr,const VarMapping & var_mapping)', '    Substitute(Stmt *stmt,const VarMapping & var_mapping)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    compute_intrinsics(IntrinsicsOp op_type,float v)', '    compute_intrinsics(IntrinsicsOp op_type,float v1,float v2)', '    accept', '    accept_mutator', '    call(Ts,...)', '    call(const std::vector & call_args)', '    dtype', '    ExprEval(const ExprHandle & expr,Ts,...)', '    ExprEval(const ExprHandle & expr,const std::vector & buffer_args)', '    operator()(Ts,...)', '    operator()(const std::vector & call_args)', '    value(std::vector & args)', '    value(Ts,...)', '    body', '    var', '    dtype', '    binary_op(const Value & lhs,const Value & rhs,IRNodeType op_type,bool option)', '    bind(const BufferArg & buf,const CallArg & data)', '    bitwise_binary_op(const Value & lhs,const Value & rhs,IRNodeType op_type)', '    call(const std::vector & args)', '    castValues(const Dtype & src_dtype,const Value & v)', '    compare_select_op(const Value & lhs,const Value & rhs,const Value & retval1,const Value & retval2,CompareSelectOperation cmp_op)', '    doCastFromSrc(const Dtype & src_dtype,const Dtype & dst_dtype,const Value & v)', '    operator()(const Ts &,...)', '    value', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Var *v)', '    visit(const Cast *v)', '    visit(const For *v)', '    visit(const Ramp *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit_binary_op(const BinaryOpNode *v,bool option)', '    visit_compare_select_op(const CompareSelect *v,CompareSelectOperation cmp_op)', '    ~SimpleIREvaluator', '    modf', '    remainderf', '    accept', '    accept_mutator', '    base_handle', '    make', '    value', '    as', '    as', '    as', '    as', '    as', '    as', '    as', '    as', '    as_vec', '    dtype', '    Value(const std::vector & v)', '    Value', '    Value(uint8_t v)', '    Value(int8_t v)', '    Value(int16_t v)', '    Value(int v)', '    Value(int64_t v)', '    Value(float v)', '    Value(double v)', '    Value((*) () decltype)', '    Value((*) () decltype)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    Value(const std::vector & v)', '    name_hint', '    mutate(const Var *var)', '    VarSubMutator(const VarMapping & var_mapping)'];
blob_serialization.cc;C++;pytorch-master/pytorch-master/caffe2/core; 707;  59; 47;18;  584; 6;365;164;267;134;0.10;35;[];['    EventCreateCPU(const DeviceOption & option,Event *event)', '    EventErrorMessageCPU(const Event *event)', '    EventFinishCPU(const Event *event)', '    EventQueryCPU(const Event *event)', '    EventRecordCPU(Event *event,const void *,const char *err_msg)', '    EventResetCPU(Event *event)', '    EventSetCallbackCPU(Event *event,EventCallbackFunction callback)', '    EventSetFinishedCPU(const Event *event,const char *err_msg)', '    EventWaitCPUCPU(const Event *event,void *)', '  Static Member Variables', '    event_callback_setter_', '    event_creator_', '    event_err_msg_getter_', '    event_finished_setter_', '    event_finisher_', '    event_querier_', '    event_recorder_', '    event_resetter_', '    event_waiter_'];
blob_serialization.h;C++;pytorch-master/pytorch-master/caffe2/core; 244;  91; 28;12;  116; 0;34;79;30;38;0.78;7;[];['    THCPEvent_dealloc(THCPEvent *self)', '    THCPEvent_elapsed_time(THCPEvent *self,THCPEvent *other)', '    THCPEvent_from_ipc_handle(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPEvent_get_cuda_event(THCPEvent *self,void *unused)', '    THCPEvent_get_device(THCPEvent *self,void *unused)', '    THCPEvent_ipc_handle(THCPEvent *self,PyObject *noargs)', '    THCPEvent_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPEvent_query(THCPEvent *self,PyObject *noargs)', '    THCPEvent_record(THCPEvent *self,THCPStream *stream)', '    THCPEvent_synchronize(THCPEvent *self,PyObject *noargs)', '    THCPEvent_wait(THCPEvent *self,THCPStream *stream)', '    THCPEvent_init(PyObject *module)'];
blob_serializer_base.h;C++;pytorch-master/pytorch-master/caffe2/core; 98;  35; 14;10;  41; 0;9;25;4;19;0.85;5;[];['    THCPEvent_Check(PyObject *obj)', '    THCPEvent_init(PyObject *module)'];
blob_stats.cc;C++;pytorch-master/pytorch-master/caffe2/core; 36;  2; 7;1;  27; 0;10;13;8;9;0.07;4;['    Event'];['    CanSchedule(int parent_type,EventStatus parent_status,int child_type,bool child_supports_async)', '    CanSchedule(const Event & child_event,bool supports_async)', '    ErrorMessage', '    Event(const DeviceOption & option)', '    ExceptionTimestamp', '    Finish', '    GetDeviceOption', '    GetType', '    HasException', '    IsFinished', '    IsScheduled', '    Query', '    Record(DeviceType recorder_type,const void *context,const char *err_msg)', '    Reset', '    RethrowException', '    SetCallback(EventCallbackFunction callback)', '    SetFinished(const char *err_msg)', '    SetFinishedWithException(const char *err_msg)', '    SupportsCallback', '    Wait(DeviceType waiter_type,void *context)', '    ~Event', '    EventCreateFunctionRegisterer(EventCreateFunction f)', '    EventErrorMessageFunctionRegisterer(EventErrorMessageFunction f)', '    EventFinishFunctionRegisterer(EventFinishFunction f)', '    EventQueryFunctionRegisterer(EventQueryFunction f)', '    EventRecordFunctionRegisterer(EventRecordFunction f)', '    EventResetFunctionRegisterer(EventResetFunction f)', '    EventSetCallbackFunctionRegisterer(EventSetCallbackFunction f)', '    EventSetFinishedFunctionRegisterer(EventSetFinishedFunction f)', '    EventWaitFunctionRegisterer(EventWaitFunction f)'];
blob_stats.h;C++;pytorch-master/pytorch-master/caffe2/core; 46;  4; 10;8;  24; 0;2;16;1;13;0.17;2;[];['    block(const Stream & stream)', '    Event(const Event &)', '    Event', '    operator=(const Event &)', '    device_index', '    device_type', '    flag', '    operator=(Event)', '    query', '    record(const Stream & stream)', '    recordOnce(const Stream & stream)', '    was_marked_for_recording', '    ~Event', '    Event', '    Event(const DeviceType _device_type,const EventFlag _flag)'];
common.cc;C++;pytorch-master/pytorch-master/caffe2/core; 39;  5; 9;5;  22; 0;8;12;5;10;0.23;7;[];['    EventCanScheduleCPU(const Event *,const Event *)', '    EventCreateCPU(const DeviceOption & option,Event *event)', '    EventErrorMessageCPU(const Event *event)', '    EventFinishCPU(const Event *event)', '    EventQueryCPU(const Event *event)', '    EventRecordCPU(Event *event,const void *,const char *err_msg)', '    EventResetCPU(Event *event)', '    EventSetFinishedCPU(const Event *event,const char *err_msg)', '    EventWaitCPUCPU(const Event *event,void *)', '    CPUEventWrapper(const DeviceOption & option)', '    ~CPUEventWrapper'];
common.h;C++;pytorch-master/pytorch-master/caffe2/core; 142;  34; 22;46;  44; 10;5;23;11;22;0.77;5;[];['    EventCreateCUDA(const DeviceOption & option,Event *event)', '    EventErrorMessageCUDA(const Event *event)', '    EventFinishCUDA(const Event *event)', '    EventQueryCUDA(const Event *event)', '    EventRecordCUDA(Event *event,const void *context,const char *err_msg)', '    EventResetCUDA(Event *event)', '    EventSetFinishedCUDA(const Event *event,const char *err_msg)', '    EventWaitCPUCUDA(const Event *event,void *context)', '    EventWaitCUDACPU(const Event *event,void *context)', '    EventWaitCUDACUDA(const Event *event,void *context)', '    CudaEventWrapper(const DeviceOption & option)', '    ~CudaEventWrapper'];
common_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/core; 26;  4; 6;3;  15; 0;5;8;5;9;0.27;2;[];['    TEST(EventCUDATest,EventBasics)'];
common_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/core; 323;  22; 24;31;  225; 30;155;45;157;52;0.10;14;[];['    TEST(EventCPUTest,EventBasics)', '    TEST(EventCPUTest,EventErrors)'];
common_gpu.h;C++;pytorch-master/pytorch-master/caffe2/core; 483;  114; 52;264;  57; 21;0;0;0;0;2.00;0;[];[];
common_omp.h;C++;pytorch-master/pytorch-master/caffe2/core; 8;  2; 2;6;  0; 1;0;0;0;0;0.00;0;[];['    main(int argc,char *[] argv)'];
context.cc;C++;pytorch-master/pytorch-master/caffe2/core; 64;  5; 10;5;  47; 0;18;30;12;21;0.11;4;[];['    main(int argc,char *[] argv)'];
context.h;C++;pytorch-master/pytorch-master/caffe2/core; 178;  27; 32;14;  110; 0;39;48;42;45;0.25;23;[];['    main(int argc,char *[] argv)'];
context_base.cc;C++;pytorch-master/pytorch-master/caffe2/core; 20;  3; 7;2;  10; 0;1;5;1;4;0.30;1;[];['    tinfl_put_buf_func(const void *pBuf,int len,void *pUser)', '    main(int argc,char *[] argv)'];
context_gpu.h;C++;pytorch-master/pytorch-master/caffe2/core; 337;  62; 50;29;  179; 26;0;0;0;0;0.35;0;[];['    main(int argc,char *[] argv)'];
context_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 161;  22; 19;7;  117; 0;75;39;80;41;0.19;10;[];['    hsv_to_rgb(int hue,int min,int max,rgb_t *p)', '    main(int argc,char *[] argv)'];
context_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 36;  3; 5;4;  25; 0;14;14;12;13;0.12;2;['    ThreadWarningHandler'];['    caller_(caller)', '    getBaseHandler', '    warn(SourceLocation source_location,const std::string & msg)', '    GetExceptionString(const std::exception & e)', '    get_handler', '    set_handler(WarningHandler *handler)', '    AppendMessage(const std::string & new_msg)', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    msg', '    msg_without_backtrace', '    process(const SourceLocation & source_location,const std::string & msg)', '  Static Member Variables', '    warning_handler_'];
db.cc;C++;pytorch-master/pytorch-master/caffe2/core; 211;  19; 30;4;  162; 0;72;70;118;80;0.12;22;['    Error', '    WarningHandler', '    EnforceFiniteError', '    IndexError', '    ValueError'];['    deprecated_AT_ASSERT', '    deprecated_AT_ASSERTM', '    deprecated_AT_ERROR', '    process(const SourceLocation & source_location,const std::string & msg)', '    if_empty_then(std::string x,std::string y)', '    GetExceptionString(const std::exception & e)', '    get_warning_handler', '    warn(SourceLocation source_location,const std::string & msg)', '    AppendMessage(const std::string & new_msg)', '    caller', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)', '    msg', '    msg_stack', '    msg_without_backtrace', '    what', '    what_without_backtrace', '    ~WarningHandler'];
db.h;C++;pytorch-master/pytorch-master/caffe2/core; 318;  106; 33;9;  174; 0;78;80;76;64;0.61;22;[];['    operator<<(std::ostream & out,const ExceptionMessage & msg)', '    ExceptionMessage(const std::exception & e)'];
event.cc;C++;pytorch-master/pytorch-master/caffe2/core; 148;  11; 26;1;  113; 0;53;47;42;56;0.10;9;[];['    TEST(ExceptionTest,TORCH_INTERNAL_ASSERT_DEBUG_ONLY)', '    throw_func'];
event_cpu.h;C++;pytorch-master/pytorch-master/caffe2/core; 47;  3; 14;3;  30; 0;1;23;3;18;0.10;2;[];['    formatMessage(const char *format,va_list fmt_args)', '    THPException_init(PyObject *module)', '    processErrorMsg(std::string str)', '    replaceAll(std::string & str,const std::string & old_str,const std::string & new_str)', '    vector', '    IndexError(const char *format,...)', '    process(const c10::SourceLocation & source_location,const std::string & msg)', '    TypeError(const char *format,...)', '    ValueError(const char *format,...)'];
event_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/core; 224;  22; 29;5;  170; 0;80;65;80;92;0.13;12;[];['    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    THPException_init(PyObject *module)', '    wrap_pybind_function_impl_(Func,std::index_sequence)', '    processErrorMsg(std::string str)', '    wrap_pybind_function(Func)', '    build_message', '    persist', '    python_error', '    python_error(const python_error & other)', '    python_error(python_error)', '    restore', '    what', '    ~python_error', '    IndexError(const char *format,...)', '    python_type', '    python_type', '    what', '    process(const at::SourceLocation & source_location,const std::string & msg)', '    PyWarningHandler', '    set_in_exception', '    ~PyWarningHandler', '    python_type', '    TypeError(const char *format,...)', '    python_type', '    ValueError(const char *format,...)'];
event_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 50;  5; 11;4;  31; 0;21;9;21;8;0.16;1;['    CuDNNError'];['    _cublasGetErrorEnum(cublasStatus_t error)', '    cusparseGetErrorString(cusparseStatus_t status)', '    Error(const std::string & new_msg,const std::string & backtrace,const void *caller)', '    Error(const char *file,const uint32_t line,const char *condition,const std::string & msg,const std::string & backtrace,const void *caller)', '    Error(SourceLocation source_location,const std::string & msg)'];
export_c10_op_to_caffe2.cc;C++;pytorch-master/pytorch-master/caffe2/core; 10;  0; 2;1;  7; 0;1;3;1;3;0.00;1;['    malformed_input', '    out_of_range_index', '    unimplemented_lowering', '    unsupported_dtype'];['    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    malformed_input', '    malformed_input(const std::string & err)', '    malformed_input(const Expr *expr)', '    malformed_input(const Stmt *stmt)', '    out_of_range_index', '    out_of_range_index(const std::string & err)', '    unimplemented_lowering', '    unimplemented_lowering(const Expr *expr)', '    unimplemented_lowering(const Stmt *stmt)', '    unsupported_dtype', '    unsupported_dtype(const std::string & err)'];
export_c10_op_to_caffe2.h;C++;pytorch-master/pytorch-master/caffe2/core; 258;  27; 28;37;  169; 7;77;40;113;45;0.16;10;[];['    MKL_DFTI_CHECK(MKL_INT status)'];
export_caffe2_op_to_c10.h;C++;pytorch-master/pytorch-master/caffe2/core; 232;  72; 26;72;  67; 11;39;28;24;16;1.07;4;['    miopen_exception'];['    HIP_CHECK(hipError_t error)', '    MIOPEN_CHECK(miopenStatus_t status)', '    miopen_exception(miopenStatus_t status,const char *msg)', '    miopen_exception(miopenStatus_t status,const std::string & msg)', '    string'];
graph.cc;C++;pytorch-master/pytorch-master/caffe2/core; 285;  50; 30;5;  205; 0;109;64;99;104;0.24;6;[];[];
graph.h;C++;pytorch-master/pytorch-master/caffe2/core; 179;  75; 31;8;  67; 0;9;46;8;34;1.12;10;['    ExecutionCounter', '    ExecutionTrigger', '    ExecutionTriggerList'];['    GetInstance', '    elapsed_value', '    ExecutionCounter(ExecutionTrigger & trigger)', '    ExecutionTrigger(const std::string & name)', '    ExecutionTrigger', '    operator=', '    trigger', '    value', '    AddTrigger(const std::string & name,ExecutionTrigger *trigger)', '    ExecutionTriggerList', '    ExecutionTriggerList', '    FindByName(const std::string & name)', '    operator='];
graph_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 200;  6; 31;4;  162; 0;114;55;102;58;0.04;13;[];['    compressContiguous(const at::IntArrayRef & sizes,const at::IntArrayRef & strides,const std::vector & cont,uint32_t *c_sizes,uint32_t *c_strides)', '    computeMapSize(const at::Tensor & tensor,const PartitionDesc & chunkDesc)', '    computeNumel(const at::ArrayRef sizes)', '    expandArgs(const KernelSpec & spec,std::vector & args,std::vector & map_size,bool dry_run)', '    shouldExpandArgs(const KernelSpec & spec,std::vector & args,std::vector & map_size)', '    arg_spec', '    launchFusion(const FusedKernel & fusion,const at::Device device,const at::ArrayRef & inputs,const at::ArrayRef & all_inputs,std::vector & outputs)', '    runFusion(const int64_t key,Stack & stack,std::string *code_out)'];
miopen_wrapper.h;C++;pytorch-master/pytorch-master/caffe2/core/hip; 166;  37; 26;6;  98; 0;41;48;44;51;0.38;17;[];['    runFusion(const int64_t key,Stack & stack,std::string *code_out)'];
init.cc;C++;pytorch-master/pytorch-master/caffe2/core; 109;  20; 13;5;  74; 0;40;26;28;46;0.27;8;['    ExitStatus', '    Transform'];['    TransformExits(std::shared_ptr & graph)', '    addIfOutputs(Node *n,at::ArrayRef true_outs,at::ArrayRef false_outs)', '    isGraphOrClosureBlock(Block *block)', '    owningNodeKind(Block *block)', '    registerBlockOutputs(Block *b,at::ArrayRef outs)', '    removeOutputs(Block *b)', '    replaceBlockOutputs(Block *b,at::ArrayRef outs)', '    ExitPair(Value *exit_v,at::ArrayRef exit_val_ref)', '    exitValues', '    hasExited', '    calcIfExitStatus(ExitStatus then_status,ExitStatus else_status)', '    constructThrowsExitPair', '    constructWillExitPair(at::ArrayRef exit_val_ref)', '    constructWontExitPair', '    deleteAfterExitNodes(Block *block,graph_node_list_iterator & iter)', '    destroyNodeAfterExit(Node *n)', '    ExitTransformer(std::shared_ptr graph)', '    getExitStatus(ExitPair & exit_pair)', '    getUnitValue(const TypePtr & type)', '    guardBlockNodes(Block *block,const ExitPair & exit_pair,graph_node_list_iterator & iter)', '    matchValuesWithUnitialized(at::ArrayRef values_to_match)', '    transformExits(Block *block)', '    transformIf(Node *node)', '    transformLoop(Node *node)', '    transformLoopContinuations', '    transformReturnStmts', '    updateTargetBlock(Block *block)'];
init.h;C++;pytorch-master/pytorch-master/caffe2/core; 179;  55; 17;16;  96; 0;42;43;39;28;0.57;8;[];['    TransformExits(std::shared_ptr & graph)'];
init_intrinsics_check.cc;C++;pytorch-master/pytorch-master/caffe2/core; 80;  1; 11;17;  46; 6;24;15;18;15;0.02;4;['    GetExpGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUExp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Exp', '    GetGradientDefs', '    vector'];
init_omp.cc;C++;pytorch-master/pytorch-master/caffe2/core; 78;  5; 9;13;  13; 45;2;4;2;15;0.38;2;[];['    operator()(const int N,const T *X,T *Y,Context *context)'];
init_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 69;  2; 13;5;  51; 0;20;24;15;21;0.04;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAExp'];
logging.h;C++;pytorch-master/pytorch-master/caffe2/core; 3;  0; 0;3;  0; 0;0;0;0;0;0.00;0;['    final'];['    operator()(const at::Tensor & input_,const at::Tensor & output_,c10::List)'];
macros.h;C++;pytorch-master/pytorch-master/caffe2/core; 4;  2; 1;1;  0; 0;0;0;0;0;0.00;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUExpand', '    CAFFE_ANONYMOUS_VARIABLE_CPUExpandGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Expand', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExpandGradient', '    GetGradientDefs', '    vector'];
memonger.cc;C++;pytorch-master/pytorch-master/caffe2/core; 593;  46; 46;4;  499; 0;306;161;232;115;0.09;13;['    final', '    final'];['    DoRunWithType', '    DoRunWithType', '    ExpandGradientOp(Args,...)', '    ExpandOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
module.cc;C++;pytorch-master/pytorch-master/caffe2/core; 117;  4; 11;10;  38; 60;13;13;17;12;0.11;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAExpand', '    CAFFE_ANONYMOUS_VARIABLE_CUDAExpandGradient'];
module.h;C++;pytorch-master/pytorch-master/caffe2/core; 71;  35; 11;18;  9; 0;1;7;0;6;3.89;0;['    GetSqueezeGradient', '    GetExpandDimsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUExpandDims', '    CAFFE_ANONYMOUS_VARIABLE_CPUSqueeze', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExpandDims', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Squeeze', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs'];
module_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 77;  7; 10;8;  31; 23;16;13;14;21;0.23;6;['    final', '    final'];['    IDEEPExpandDimsOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSqueezeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPExpandDimsOp', '    ~IDEEPSqueezeOp'];
net.h;C++;pytorch-master/pytorch-master/caffe2/core; 173;  35; 29;24;  91; 0;0;0;0;0;0.38;0;['    ExpandDimsOp', '    SqueezeOp'];['    ComputeDims(at::IntArrayRef inputDims,std::vector)', '    ExpandDimsOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    GetRepeatedArgument', '    operator=', '    RunOnDevice', '    SqueezeOp(Args,...)', '    SqueezeOp'];
net_async_base.cc;C++;pytorch-master/pytorch-master/caffe2/core; 621;  24; 72;6;  504; 21;284;147;233;214;0.05;47;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAExpandDims', '    CAFFE_ANONYMOUS_VARIABLE_CUDASqueeze'];
net_async_base.h;C++;pytorch-master/pytorch-master/caffe2/core; 231;  19; 40;16;  160; 0;46;111;28;94;0.12;6;[];['    TEST_F(ExpandingArrayTest,CanConstructFromInitializerList)', '    TEST_F(ExpandingArrayTest,CanConstructFromVector)', '    TEST_F(ExpandingArrayTest,CanConstructFromArray)', '    TEST_F(ExpandingArrayTest,CanConstructFromSingleValue)', '    TEST_F(ExpandingArrayTest,ThrowsWhenConstructedWithIncorrectNumberOfArgumentsInInitializerList)', '    TEST_F(ExpandingArrayTest,ThrowsWhenConstructedWithIncorrectNumberOfArgumentsInVector)'];
net_async_scheduling.h;C++;pytorch-master/pytorch-master/caffe2/core; 42;  2; 13;4;  25; 0;2;22;0;20;0.08;0;[];[];
net_async_task.cc;C++;pytorch-master/pytorch-master/caffe2/core; 107;  11; 15;2;  83; 0;41;25;37;38;0.13;7;[];['    infer_size(IntArrayRef a,IntArrayRef b)'];
net_async_task.h;C++;pytorch-master/pytorch-master/caffe2/core; 39;  3; 12;7;  19; 0;1;16;0;12;0.16;0;[];[];
net_async_task_future.h;C++;pytorch-master/pytorch-master/caffe2/core; 76;  6; 20;10;  42; 0;7;33;4;31;0.14;2;['    EncoderBase', '    GraphEncoder'];['    ATenTypeToOnnxType(at::ScalarType at_type)', '    check_onnx_proto(const std::string & proto_string)', '    CloseFile(FILE *fp)', '    CreateExternalFile(const at::Tensor & tensor,const std::string & tensorName,const std::string & onnx_file_path)', '    dump(const onnx::TensorProto & tensor,std::ostream & stream)', '    dump(const onnx::TensorShapeProto & shape,std::ostream & stream)', '    dump(const onnx::TypeProto_Tensor & tensor_type,std::ostream & stream)', '    dump(const onnx::TypeProto & type,std::ostream & stream)', '    dump(const onnx::ValueInfoProto & value_info,std::ostream & stream)', '    dump(const onnx::GraphProto & graph,std::ostream & stream,size_t indent)', '    dump(const onnx::AttributeProto & attr,std::ostream & stream,size_t indent)', '    dump(const onnx::NodeProto & node,std::ostream & stream,size_t indent)', '    dump(const onnx::OperatorSetIdProto & operator_set_id,std::ostream & stream)', '    dump(const onnx::ModelProto & model,std::ostream & stream,size_t indent)', '    export_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool strip_doc_string,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    export_opnames(const script::Module & m,std::set & opnames)', '    export_opnames(const script::Module & m)', '    GetExternalFileName(const c10::optional external_ref)', '    GetFileRootPath(const std::string & rootPath)', '    getNodeStackTraceString(const Node *n)', '    idt(size_t indent)', '    nlidt(size_t indent)', '    pretty_print_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool google_printer,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names)', '    prettyPrint(const onnx::ModelProto & model)', '    validateBlock(Block *b,onnx_torch::OperatorExportTypes operator_export_type)', '    validateGraph(const std::shared_ptr & graph,onnx_torch::OperatorExportTypes operator_export_type)', '    writeArchiveAndTensors(const std::string & archive_name,const char *data,size_t size,const std::vector & tensors,caffe2::serialize::PyTorchStreamWriter & out)', '    AddAttribute(onnx::NodeProto *node_proto,const jit::Node *node,const jit::Symbol name)', '    EncodeBlock(onnx::GraphProto *graph_proto,const Block *block,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool keep_initializers_as_inputs,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    EncodeGraph(onnx::GraphProto *graph_proto,const std::shared_ptr & graph,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool keep_initializers_as_inputs,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    EncodeIntermediateValueInfo(onnx::GraphProto *graph_proto,const Value *n)', '    EncoderBase(onnx_torch::OperatorExportTypes operator_export_type,bool strip_doc)', '    EncodeValueInfo(onnx::GraphProto *graph_proto,onnx::ValueInfoProto *v,const Value *n,const std::unordered_map,std::unordered_map,std::string)', '    get_model_proto', '    EncodeTensor(onnx::TensorProto *tensor_proto,const at::Tensor & tensor,const c10::optional external_ref,const bool use_external_data_format,const std::string & onnx_file_path)', '    get_raw_data_export_map', '    GraphEncoder(const std::shared_ptr & graph,int64_t onnx_opset_version,onnx_torch::OperatorExportTypes operator_export_type,const std::map & initializers,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,bool strip_doc,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)'];
net_async_task_graph.cc;C++;pytorch-master/pytorch-master/caffe2/core; 139;  6; 24;2;  108; 0;68;32;79;32;0.06;7;[];[];
net_async_task_graph.h;C++;pytorch-master/pytorch-master/caffe2/core; 78;  12; 24;7;  37; 0;6;32;0;26;0.32;1;[];['    check_onnx_proto(const std::string & proto_string)', '    export_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,const std::unordered_map,std::unordered_map,std::string,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool strip_doc_string,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names,bool use_external_data_format,const std::string & onnx_file_path)', '    export_opnames(const Module & m)', '    ExportModule(const Module & module,std::ostream & out,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::string & filename,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::function & writer_func,const ExtraFilesMap & extra_files,bool bytecode_format)', '    pretty_print_onnx(const std::shared_ptr & graph,const std::map & initializers,int64_t onnx_opset_version,bool defer_weight_export,::torch::onnx::OperatorExportTypes operator_export_type,bool google_printer,bool keep_initializers_as_inputs,const std::map & custom_opsets,bool add_node_names)', '    SetExportModuleExtraFilesHook(ExportModuleExtraFilesHook hook)', '    writeArchiveAndTensors(const std::string & archive_name,const char *data,size_t size,const std::vector & tensors,caffe2::serialize::PyTorchStreamWriter & out)'];
net_async_tracing.h;C++;pytorch-master/pytorch-master/caffe2/core; 181;  29; 33;23;  101; 0;22;85;3;70;0.29;5;[];['    RegistryName'];
net_async_tracing_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 114;  20; 41;2;  53; 0;37;36;17;12;0.38;4;['    final'];['    createC10OperatorWrapper(const c10::OperatorName & op_name)', '    has_value', '    to', '    array_inputs_', '    C10OperatorWrapper(const c10::OperatorHandle & op,const OperatorDef & operator_def,Workspace *ws)', '    callKernel_', '    get_nontensor_argument_(const c10::Argument & argument)', '    get_nontensor_argument_(const std::string & name,const c10::optional & default_value)', '    GetSingleArgument', '    HasSingleArgumentOfType', '    popOutputs_', '    preallocated_outputs_', '    pushInputs_', '    RunOnDevice', '    singleton'];
net_dag_utils.cc;C++;pytorch-master/pytorch-master/caffe2/core; 516;  77; 41;10;  392; 0;262;120;204;133;0.20;11;[];['    _call_caffe2_op(const c10::FunctionSchema & schema,std::vector,c10::List)', '    _call_caffe2_op_from_c10(c10::Stack *stack,const c10::FunctionSchema & schema,_CallCaffe2OpFunc *call_op)', '    call_caffe2_op_from_c10(const c10::OperatorHandle &,c10::Stack *stack)', '    make_function_schema_for_c10(const char *schema_str)', '    op(schema,std::move inputs,std::move outputs)', '    ofTensors', '    create'];
net_dag_utils_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 296;  14; 65;3;  216; 0;164;164;38;60;0.06;19;['    ScriptModuleSerializer'];['    Table(const std::vector,IValue)', '    Tup(std::vector ivalues)', '    new_instr', '    ExportModule(const Module & module,std::ostream & out,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::string & filename,const ExtraFilesMap & extra_files,bool bytecode_format)', '    ExportModule(const Module & module,const std::function & writer_func,const ExtraFilesMap & extra_files,bool bytecode_format)', '    GetExtraFilesHook', '    getFunctionTuple(const Function & func)', '    moduleMethodsTuple(const Module & module,std::vector & elements)', '    SetExportModuleExtraFilesHook(ExportModuleExtraFilesHook hook)', '    setstateTuple(const IValue & ivalue,std::vector & elements)', '    convertNamedType(const c10::NamedTypePtr & class_type)', '    ScriptModuleSerializer(const std::string & filename)', '    ScriptModuleSerializer(const std::function & writer_func)', '    serialize(const Module & module,const ExtraFilesMap & extra_files,bool bytecode_format)', '    writeArchive(const std::string & archive_name,const IValue & value)', '    writeByteCode(const Module & module)', '    writeCode(const at::NamedTypePtr & root_type)', '    writeExtraFiles(const Module & module,const ExtraFilesMap & extra_files)'];
net_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 130;  8; 34;6;  85; 0;50;52;27;39;0.09;13;[];['    acos(const ExprHandle & v)', '    asin(const ExprHandle & v)', '    atan(const ExprHandle & v)', '    atan2(const ExprHandle & v1,const ExprHandle & v2)', '    ceil(const ExprHandle & v)', '    cos(const ExprHandle & v)', '    cosh(const ExprHandle & v)', '    erf(const ExprHandle & v)', '    erfc(const ExprHandle & v)', '    exp(const ExprHandle & v)', '    expm1(const ExprHandle & v)', '    fabs(const ExprHandle & v)', '    floor(const ExprHandle & v)', '    fmod(const ExprHandle & v1,const ExprHandle & v2)', '    frac(const ExprHandle & v)', '    ifThenElse(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    lgamma(const ExprHandle & v)', '    log(const ExprHandle & v)', '    log10(const ExprHandle & v)', '    log1p(const ExprHandle & v)', '    log2(const ExprHandle & v)', '    pow(const ExprHandle & v1,const ExprHandle & v2)', '    remainder(const ExprHandle & v1,const ExprHandle & v2)', '    round(const ExprHandle & v)', '    rsqrt(const ExprHandle & v)', '    sin(const ExprHandle & v)', '    sinh(const ExprHandle & v)', '    sqrt(const ExprHandle & v)', '    tan(const ExprHandle & v)', '    tanh(const ExprHandle & v)', '    trunc(const ExprHandle & v)', '    ExprHandle((*) () decltype)', '    ExprHandle(uint8_t v)', '    ExprHandle(int8_t v)', '    ExprHandle(int16_t v)', '    ExprHandle(int v)', '    ExprHandle(int64_t v)', '    ExprHandle(float v)', '    ExprHandle(double v)', '    ExprHandle((*) () decltype)', '    operator!=(const ExprHandle & other)', '    operator%(const ExprHandle & other)', '    operator&(const ExprHandle & other)', '    operator*(const ExprHandle & other)', '    operator+(const ExprHandle & other)', '    operator-(const ExprHandle & other)', '    operator/(const ExprHandle & other)', '    operator<(const ExprHandle & other)', '    operator<<(const ExprHandle & other)', '    operator<=(const ExprHandle & other)', '    operator==(const ExprHandle & other)', '    operator>(const ExprHandle & other)', '    operator>=(const ExprHandle & other)', '    operator>>(const ExprHandle & other)', '    operator^(const ExprHandle & other)', '    operator|(const ExprHandle & other)'];
net_parallel.cc;C++;pytorch-master/pytorch-master/caffe2/core; 199;  9; 29;3;  160; 0;93;47;96;50;0.06;13;['    Expr', '    ExprHandle', '    ExprNode', '    Var', '    VarHandle'];['    acos(const ExprHandle & v)', '    asin(const ExprHandle & v)', '    atan(const ExprHandle & v)', '    atan2(const ExprHandle & v1,const ExprHandle & v2)', '    ceil(const ExprHandle & v)', '    cos(const ExprHandle & v)', '    cosh(const ExprHandle & v)', '    erf(const ExprHandle & v)', '    erfc(const ExprHandle & v)', '    exp(const ExprHandle & v)', '    expm1(const ExprHandle & v)', '    fabs(const ExprHandle & v)', '    floor(const ExprHandle & v)', '    fmod(const ExprHandle & v1,const ExprHandle & v2)', '    frac(const ExprHandle & v)', '    ifThenElse(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    lgamma(const ExprHandle & v)', '    log(const ExprHandle & v)', '    log10(const ExprHandle & v)', '    log1p(const ExprHandle & v)', '    log2(const ExprHandle & v)', '    pow(const ExprHandle & v1,const ExprHandle & v2)', '    remainder(const ExprHandle & v1,const ExprHandle & v2)', '    round(const ExprHandle & v)', '    rsqrt(const ExprHandle & v)', '    same_node(const ExprHandle & expr1,const ExprHandle & expr2)', '    sin(const ExprHandle & v)', '    sinh(const ExprHandle & v)', '    sqrt(const ExprHandle & v)', '    tan(const ExprHandle & v)', '    tanh(const ExprHandle & v)', '    trunc(const ExprHandle & v)', '    make(const std::string & name_hint,Dtype dtype)', '    make(Dtype dtype)', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    dtype', '    Expr(Dtype dtype,IRNodeType expr_type)', '    expr_type', '    isConstant', '    AsNode', '    AsNode', '    dtype', '    empty', '    ExprHandle', '    ExprHandle(decltype)', '    ExprHandle(const Expr *node)', '    ExprHandle(uint8_t v)', '    ExprHandle(int8_t v)', '    ExprHandle(int16_t v)', '    ExprHandle(int v)', '    ExprHandle(int64_t v)', '    ExprHandle(float v)', '    ExprHandle(double v)', '    node', '    node', '    operator!=(const ExprHandle & other)', '    operator%(const ExprHandle & other)', '    operator&(const ExprHandle & other)', '    operator*(const ExprHandle & other)', '    operator+(const ExprHandle & other)', '    operator-(const ExprHandle & other)', '    operator/(const ExprHandle & other)', '    operator<(const ExprHandle & other)', '    operator<<(const ExprHandle & other)', '    operator<=(const ExprHandle & other)', '    operator==(const ExprHandle & other)', '    operator>(const ExprHandle & other)', '    operator>=(const ExprHandle & other)', '    operator>>(const ExprHandle & other)', '    operator^(const ExprHandle & other)', '    operator|(const ExprHandle & other)', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    name_hint', '    Var(const std::string & name_hint,Dtype dtype)', '    empty', '    name_hint', '    node', '    operator!=(const VarHandle & other)', '    operator==(const VarHandle & other)', '    VarHandle', '    VarHandle(Dtype dtype)', '    VarHandle(const std::string & name_hint,Dtype dtype)', '    VarHandle(const Var *node)'];
net_simple.cc;C++;pytorch-master/pytorch-master/caffe2/core; 285;  8; 18;15;  240; 6;161;79;119;62;0.03;6;[];[];
net_simple.h;C++;pytorch-master/pytorch-master/caffe2/core; 56;  11; 11;11;  25; 0;5;16;4;13;0.44;2;[];['    function_taking_optional(c10::optional tensor)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    sigmoid_add(torch::Tensor x,torch::Tensor y)', '    forward(torch::Tensor weights)', '    get', '    MatrixMultiplier(int A,int B)'];
net_simple_refcount.cc;C++;pytorch-master/pytorch-master/caffe2/core; 81;  8; 8;11;  55; 0;34;19;36;16;0.15;2;[];[];
net_simple_refcount_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 70;  14; 9;7;  42; 0;26;15;36;39;0.33;5;[];['    add_override(const Tensor & a,const Tensor & b,Scalar)', '    empty_override(IntArrayRef size,const TensorOptions & options,c10::optional optional_memory_format)', '    TEST(BackendExtensionTest,TestRegisterOp)'];
net_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 1109;  57; 276;13;  772; 3;550;500;200;199;0.07;60;[];[];
Dot.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Converters; 277;  51; 28;13;  195; 0;115;80;93;52;0.26;12;[];[];
OpEnum.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Generated; 4;  0; 0;0;  4; 0;0;0;0;0;0.00;0;[];['    fake_quant_grad_per_channel_stub', '    fake_quant_grad_per_channel_stub', '    operator=', '    fake_quant_grad_tensor_stub', '    fake_quant_grad_tensor_stub', '    operator=', '    fake_quant_per_channel_stub', '    fake_quant_per_channel_stub', '    operator=', '    fake_quant_tensor_stub', '    fake_quant_tensor_stub', '    operator='];
OpNames.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Generated; 84;  0; 28;0;  56; 0;56;0;56;0;0.00;0;[];['    fake_quantize_per_channel_affine(const Tensor & self,const Tensor & scale,const Tensor & zero_point,int64_t axis,int64_t quant_min,int64_t quant_max)', '    fake_quantize_per_channel_affine_backward(const Tensor & dY,const Tensor & X,const Tensor & scale,const Tensor & zero_point,int64_t axis,int64_t quant_min,int64_t quant_max)'];
Algorithms.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Graph; 213;  44; 18;11;  143; 0;78;50;54;56;0.31;5;[];['    fake_quantize_per_tensor_affine(const Tensor & self,double scale,int64_t zero_point,int64_t quant_min,int64_t quant_max)', '    fake_quantize_per_tensor_affine_backward(const Tensor & dY,const Tensor & X,double scale,int64_t zero_point,int64_t quant_min,int64_t quant_max)'];
Graph.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Graph; 561;  79; 79;14;  392; 0;181;138;163;141;0.20;57;['    C10FlagParser_fake_fp16_conversion_use_fp16_acc', '    C10FlagParser_fake_fp16_conversion_use_nnpi'];['    fakeFp16Transform(NetDef *net)', '    getFakeFp16OpMapping(bool use_fp16_acc,bool use_nnpi)', '    C10FlagParser_fake_fp16_conversion_use_fp16_acc(const std::string & content)', '    C10FlagParser_fake_fp16_conversion_use_nnpi(const std::string & content)'];
TarjansImpl.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Graph; 177;  35; 23;5;  117; 0;56;46;37;76;0.30;4;[];['    getFakeFp16OpMapping(bool use_fp16_acc,bool use_nnpi)'];
TopoSort.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Graph; 84;  17; 11;5;  54; 0;21;24;19;22;0.31;4;[];['    getCurrentStreamIdFor(DeviceIndex i)', '    getDeviceIndex', '    resetStreams', '    setDeviceIndex(DeviceIndex i)', '    block(void *event,const Stream & stream)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    FakeGuardImpl(DeviceType)', '    FakeGuardImpl', '    getDevice', '    getStream(Device d)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)'];
ControlFlow.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Representations; 185;  20; 23;8;  137; 0;67;64;40;57;0.15;16;[];['    aliasAnalysisIsSpecialCase', '    runFallback(int64_t key,Stack & stack)'];
NeuralNet.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Representations; 532;  63; 93;27;  354; 0;95;215;78;190;0.18;57;[];['    runFallback(int64_t key,Stack & stack)'];
Casting.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Support; 457;  84; 56;17;  305; 10;87;141;63;154;0.28;28;[];[];
Pointer.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Support; 27;  12; 6;4;  8; 0;1;6;1;3;1.50;1;[];['    fromVec(const std::vector & vec)', '    FaultyProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout,const std::vector & messagesToFail,int failNumSends)', '    parseMessagesToFailInput(const std::vector & messagesToFail)', '    send(const WorkerInfo & to,Message)', '    shouldFailMessage(MessageType type)'];
Match.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Transformations; 94;  17; 19;6;  54; 0;1;4;1;2;0.31;1;['    FaultyProcessGroupAgent'];['    FaultyProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout,const std::vector & messagesToFail,int failNumSends)', '    parseMessagesToFailInput(const std::vector & messagesToFail)', '    send(const WorkerInfo & to,Message)', '    shouldFailMessage(MessageType type)', '    FaultyProcessGroupRpcBackendOptions(int num_send_recv_threads,std::chrono::milliseconds rpc_timeout,std::string init_method,std::vector messages_to_fail,int num_fail_sends)'];
SubgraphMatcher.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Transformations; 430;  62; 53;10;  308; 0;181;123;96;77;0.20;24;[];['    original_tensor'];
AlgorithmsTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 126;  2; 13;2;  109; 0;93;41;57;42;0.02;4;[];[];
BinaryMatchImplTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 123;  38; 13;6;  66; 0;27;40;6;61;0.58;8;[];[];
GraphTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 219;  45; 31;6;  137; 0;109;51;76;53;0.33;8;[];['    QuantizeConvBias(const Blob & blob,int M,const TensorQuantizationParams & in_qparams,const vector & filter_qparams,vector & b_quantized)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvPackWeight', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FCPackWeight', '    ComputeColumnOffsets(int num_rows,int num_cols,const T *W,const vector & qparams,vector & col_offsets)', '    CountOutliers(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    ExtractOutlierMatrix(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    QuantizeWeight(const Blob & blob,int kernel_dim,int M,vector & qparams,vector & W_quantized,dnnlowp::QuantizationFactory *qfactory)', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ConvDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    GetConv3DParam_', '    GetConvParam_', '    RunOnDevice', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    FullyConnectedDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
NeuralNetTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 97;  25; 15;6;  51; 0;45;16;20;18;0.49;1;['    final', '    final', '    Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    Int8FCDNNLowpPackedWeightBlobShapeFunctions'];['    ComputeColumnOffsets(int num_rows,int num_cols,const T *W,const vector & qparams,vector & col_offsets)', '    CountOutliers(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    ExtractOutlierMatrix(int groups,int kernel_dim,int M,int nbits_in_non_outlier,vector & W_quantized)', '    QuantizeWeight(const Blob & blob,int kernel_dim,int M,vector & qparams,vector & W_quantized,dnnlowp::QuantizationFactory *qfactory)', '    ConvDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    FullyConnectedDNNLowPPackWeightOp(const OperatorDef & operator_def,Workspace *ws)', '    GetConv3DParam_', '    GetConvParam_', '    RunOnDevice', '    TakeDepthWise3x3FastPath_', '    TakeDepthWise3x3x3FastPath_', '    TakeGConvFastPath_', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~Int8ConvDNNLowpPackedWeightBlobShapeFunctions', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    Int8FCDNNLowpPackedWeightBlobShapeFunctions', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *blob,std::vector *scale,std::vector *offset,uint32_t *axis)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~Int8FCDNNLowpPackedWeightBlobShapeFunctions'];
SubgraphMatcherTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 642;  149; 90;5;  400; 0;213;206;99;309;0.37;18;[];[];
TarjansImplTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 58;  0; 8;3;  47; 0;26;29;15;34;0.00;5;[];[];
test_util.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 120;  53; 15;9;  44; 0;14;25;7;21;1.20;5;[];['    compute_q8gemm_dq(const struct q8gemm_dq_context *context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    qnnpackLinearDynamic(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *input,const size_t input_stride,void *packed_weights,const float *bias,float *output,const size_t output_stride,pthreadpool_t threadpool)'];
TopoSortTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 73;  0; 7;3;  63; 0;51;28;31;43;0.00;4;[];['    PackBMatrix(const size_t input_channels,const size_t output_channels,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *kernel,const int32_t *bias)'];
numa.cc;C++;pytorch-master/pytorch-master/caffe2/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    qnnpackLinear(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t output_zero_point,const float output_scale,const uint8_t output_min,const uint8_t output_max,const uint8_t *input,const size_t input_stride,void *packed_weights,uint8_t *output,const size_t output_stride,pthreadpool_t threadpool)'];
observer.h;C++;pytorch-master/pytorch-master/caffe2/core; 164;  18; 29;4;  114; 0;57;36;48;42;0.16;14;['    final'];['    dimErrorString', '    operator()(const at::Tensor & X_,const at::Tensor & W_,const at::Tensor & b_,const at::Tensor & Y_,int64_t axis,int64_t axis_w)'];
observer_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 182;  2; 19;10;  126; 27;57;66;40;70;0.02;13;[];['    test_case(const float v,const float v_fp16,const float v_bfp16)', '    test_vector_case(const float v,const float v_fp16,const float v_bfp16)', '    isclose(float x,float y)', '    isrelclose(float x,float y)', '    mse(std::array & a1,std::array & a2)', '    TEST(FP16Quant,fp32_to_fp16)'];
operator.cc;C++;pytorch-master/pytorch-master/caffe2/core; 816;  49; 73;37;  656; 9;339;235;283;225;0.07;37;[];['    CostInferenceForFC(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)'];
operator_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 63;  6; 9;4;  48; 0;15;18;16;25;0.13;9;[];['    CostInferenceForFC(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)'];
operator_gradient.h;C++;pytorch-master/pytorch-master/caffe2/core; 337;  70; 34;21;  212; 4;0;0;0;0;0.33;0;['    GetMergeMultiListFeatureTensorsGradient', '    GetMergeMultiMapFeatureTensorsGradient', '    GetMergeMultiScalarFeatureTensorsGradient', '    GetMergeSingleListFeatureTensorsGradient', '    GetMergeSingleMapFeatureTensorsGradient', '    GetMergeSingleScalarFeatureTensorsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiListFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiListFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiMapFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiMapFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiScalarFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeMultiScalarFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleListFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleListFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleMapFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleMapFeatureTensorsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleScalarFeatureTensors', '    CAFFE_ANONYMOUS_VARIABLE_CPUMergeSingleScalarFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiListFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiListFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiMapFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiMapFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiScalarFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeMultiScalarFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleListFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleListFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleMapFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleMapFeatureTensorsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleScalarFeatureTensors', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeSingleScalarFeatureTensorsGradient', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    input_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    output_blob_names', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs'];
operator_schema.cc;C++;pytorch-master/pytorch-master/caffe2/core; 504;  34; 56;8;  410; 0;239;94;153;89;0.08;48;['    MergeMultiListFeatureTensorsOp', '    MergeMultiListOrMapFeatureTensorsGradientOp', '    MergeMultiMapFeatureTensorsOp', '    MergeMultiScalarFeatureTensorsGradientOp', '    MergeMultiScalarFeatureTensorsOp', '    MergeSingleListFeatureTensorsOp', '    MergeSingleListOrMapFeatureTensorsGradientOp', '    MergeSingleMapFeatureTensorsOp', '    MergeSingleScalarFeatureTensorsGradientOp', '    MergeSingleScalarFeatureTensorsOp'];['    DoRunWithType', '    MergeMultiListFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiListFeatureTensorsOp', '    DoRunWithType', '    MergeMultiListOrMapFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeMultiListOrMapFeatureTensorsGradientOp', '    DoRunWithType', '    DoRunWithType2', '    MergeMultiMapFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiMapFeatureTensorsOp', '    DoRunWithType', '    MergeMultiScalarFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeMultiScalarFeatureTensorsGradientOp', '    DoRunWithType', '    MergeMultiScalarFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeMultiScalarFeatureTensorsOp', '    DoRunWithType', '    GetRepeatedArgument', '    MergeSingleListFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleListFeatureTensorsOp', '    DoRunWithType', '    MergeSingleListOrMapFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeSingleListOrMapFeatureTensorsGradientOp', '    DoRunWithType', '    DoRunWithType2', '    GetRepeatedArgument', '    MergeSingleMapFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleMapFeatureTensorsOp', '    DoRunWithType', '    MergeSingleScalarFeatureTensorsGradientOp(Args,...)', '    RunOnDevice', '    ~MergeSingleScalarFeatureTensorsGradientOp', '    DoRunWithType', '    GetRepeatedArgument', '    MergeSingleScalarFeatureTensorsOp(Args,...)', '    RunOnDevice', '    ~MergeSingleScalarFeatureTensorsOp'];
operator_schema_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 279;  8; 22;25;  206; 20;175;150;44;72;0.04;19;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFeedBlob', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FeedBlob'];
operator_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 628;  39; 62;10;  509; 16;287;165;246;194;0.08;60;['    FeedBlobOp'];['    FeedBlobOp(Args,...)', '    GetSingleArgument', '    HasSingleArgumentOfType', '    Output', '    RunOnDevice'];
parallel_net_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 312;  31; 41;5;  239; 0;199;197;35;51;0.13;16;[];['    ~FileAdapter', '    FileAdapter(const std::string & file_name)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size'];
plan_executor.h;C++;pytorch-master/pytorch-master/caffe2/core; 13;  0; 5;2;  6; 0;0;6;0;5;0.00;0;['    final'];['    FileAdapter', '    operator=', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    ~FileAdapter'];
prof_dag_counters.cc;C++;pytorch-master/pytorch-master/caffe2/core; 247;  9; 34;4;  201; 0;130;58;126;55;0.04;13;[];['    assertFind(const SourceRange & search_range,const std::string & sub,std::function extra_msg)', '    assertFind(const SourceRange & search_range,const std::string & sub,const Check & check)', '    assertFind(const std::shared_ptr & source,const std::string & sub,size_t start,const Check & check)', '    assertNotFind(const SourceRange & search_range,const std::string & sub,const Check & check)', '    operator<<(std::ostream & out,const Check & c)', '    operator<<(std::ostream & out,const FileCheckImpl & fc)', '    Check(CheckType type,std::string str,c10::optional count)', '    check(const std::string & str)', '    check_count(const std::string & str,size_t count,bool exactly)', '    check_dag(const std::string & str)', '    check_next(const std::string & str)', '    check_not(const std::string & str)', '    check_same(const std::string & str)', '    FileCheck', '    run(const std::string & test_file)', '    run(const Graph & graph)', '    run(const std::string & input_checks_string,const std::string & test_string)', '    run(const std::string & input_checks_string,const Graph & graph)', '    ~FileCheck', '    addCheck(Check check)', '    addCheck(CheckType type,const std::string & s,c10::optional count)', '    doCheckNot(const std::vector & nots,const std::shared_ptr & source,const SourceRange & prev,const SourceRange & next)', '    doChecks(const std::shared_ptr & source)', '    findNextStart(const std::shared_ptr & source,size_t prev_end)', '    matchDagGroup(const std::vector & group,const std::shared_ptr & source,const SourceRange & prev)', '    matchGroup(const std::vector & group,const std::shared_ptr & source,const SourceRange & prev)', '    parseSingleCheck(const std::shared_ptr & source,size_t *start)', '    parseStrings(const std::shared_ptr & source)', '    run(const std::string & test_file)', '    run(const std::string & checks_file,const std::string & test_file)'];
prof_dag_counters.h;C++;pytorch-master/pytorch-master/caffe2/core; 119;  11; 29;9;  71; 0;11;49;12;45;0.15;7;[];['    check(const std::string & str)', '    check_count(const std::string & str,size_t count,bool exactly)', '    check_dag(const std::string & str)', '    check_next(const std::string & str)', '    check_not(const std::string & str)', '    check_same(const std::string & str)', '    FileCheck', '    reset', '    run(const std::string & test_file)', '    run(const Graph & graph)', '    run(const std::string & input_checks_string,const std::string & test_string)', '    run(const std::string & input_checks_string,const Graph & graph)', '    ~FileCheck'];
qtensor.h;C++;pytorch-master/pytorch-master/caffe2/core; 260;  62; 40;11;  149; 0;74;60;75;55;0.42;27;[];['    encodeName(const std::string & name)', '    add(const std::string &,int64_t)', '    check(const std::vector & names)', '    FileStoreHandler(const std::string & path,const std::string & prefix)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    objectPath(const std::string & name)', '    realPath(const std::string & path)', '    set(const std::string & name,const std::string & data)', '    tmpPath(const std::string & name)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~FileStoreHandler'];
qtensor_serialization.cc;C++;pytorch-master/pytorch-master/caffe2/core; 10;  2; 1;1;  8; 0;0;6;0;8;0.25;0;['    FileStoreHandler'];['    add(const std::string &,int64_t)', '    check(const std::vector & names)', '    FileStoreHandler(const std::string & path,const std::string & prefix)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    objectPath(const std::string & name)', '    realPath(const std::string & path)', '    set(const std::string & name,const std::string & data)', '    tmpPath(const std::string & name)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~FileStoreHandler'];
qtensor_serialization.h;C++;pytorch-master/pytorch-master/caffe2/core; 89;  5; 12;5;  69; 0;26;38;24;20;0.07;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFileStoreHandlerCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FileStoreHandlerCreate'];
static_tracepoint.h;C++;pytorch-master/pytorch-master/caffe2/core; 11;  0; 1;9;  0; 5;0;0;0;0;0.00;0;['    final'];['    FileStoreHandlerCreateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
static_tracepoint_elfx86.h;C++;pytorch-master/pytorch-master/caffe2/core; 100;  17; 11;75;  0; 1;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAFileStoreHandlerCreate'];
stats.cc;C++;pytorch-master/pytorch-master/caffe2/core; 53;  1; 8;3;  41; 0;22;18;17;17;0.02;6;['    File', '    Lock'];['    refresh(File & file,off_t pos,std::unordered_map,std::vector)', '    syscall(F fn)', '    File(const std::string & path,int flags,std::chrono::milliseconds timeout)', '    lockExclusive', '    lockShared', '    read(void *buf,size_t count)', '    read(std::string & str)', '    read(std::vector & data)', '    seek(off_t offset,int whence)', '    size', '    tell', '    write(const void *buf,size_t count)', '    write(const std::string & str)', '    write(const std::vector & data)', '    ~File', '    add(const std::string & key,int64_t i)', '    addHelper(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    FileStore(const std::string & path,int numWorkers)', '    get(const std::string & key)', '    set(const std::string & key,const std::vector & value)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~FileStore', '    flock(int operation)', '    Lock(int fd,int operation)', '    Lock(Lock)', '    unlock', '    ~Lock'];
stats_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 147;  2; 19;6;  122; 0;65;71;36;77;0.02;23;['    FileStore'];['    add(const std::string & key,int64_t i)', '    addHelper(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    FileStore(const std::string & path,int numWorkers)', '    get(const std::string & key)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~FileStore'];
storage.h;C++;pytorch-master/pytorch-master/caffe2/core; 33;  2; 7;22;  4; 0;2;2;2;6;0.50;0;[];['    main(int argc,char **argv)', '    testHelper(const std::string prefix)', '    tmppath'];
tensor.cc;C++;pytorch-master/pytorch-master/caffe2/core; 327;  37; 35;16;  241; 0;119;69;115;50;0.15;25;[];['    fill_(Tensor & self,Scalar value)', '    fill_(Tensor & self,const Tensor & value)', '    fill_diagonal_(Tensor & self,Scalar fill_value,bool wrap)', '    fill_fast(Tensor & self,Scalar value_scalar)', '    fill_out(Tensor & self,Scalar value)', '    zero_(Tensor & self)'];
tensor_impl.h;C++;pytorch-master/pytorch-master/caffe2/core; 15;  0; 2;5;  8; 0;0;2;6;7;0.00;0;[];['    fill_stub', '    fill_stub', '    operator='];
tensor_int8.cc;C++;pytorch-master/pytorch-master/caffe2/core; 6;  1; 1;2;  3; 0;1;3;1;3;0.33;1;['    TensorFiller'];['    DebugString', '    Dist(FillerDistribution dist)', '    Fill(Tensor *tensor,Context *context)', '    FixedSum(Type fixed_sum)', '    Max(Type max)', '    Min(Type min)', '    Shape(const std::vector & shape)', '    SparseLengths(Type total_length)', '    SparseSegments(Type max_segment)', '    TensorFiller(const std::vector & shape,Type fixed_sum)', '    TensorFiller(const std::vector & shape)', '    TensorFiller'];
tensor_int8.h;C++;pytorch-master/pytorch-master/caffe2/core; 21;  5; 4;6;  9; 0;3;8;0;6;0.56;3;[];['    constant_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,int64_t dtype,c10::Scalar value)', '    filler_init(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape)', '    given_tensor_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,const at::Tensor & values_)', '    uniform_fill_op_cpu_impl(torch::List inputs,const at::Tensor & output_,torch::List shape,torch::List extra_shape,bool input_as_shape,double min,double max)', '    real_shape'];
test_utils.h;C++;pytorch-master/pytorch-master/caffe2/core; 219;  26; 31;10;  155; 0;43;107;52;47;0.17;13;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUConstantFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUDiagonalFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGaussianFill', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsRangeFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUMSRAFill', '    CAFFE_ANONYMOUS_VARIABLE_CPURangeFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniformIntFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUUniqueUniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUXavierFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ConstantFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DiagonalFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GaussianFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsRangeFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MSRAFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RangeFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniformIntFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UniqueUniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_XavierFill', '    Fill(Tensor *output)'];
timer.h;C++;pytorch-master/pytorch-master/caffe2/core; 48;  19; 6;5;  19; 0;8;13;6;13;1.00;6;['    FillerOp', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    LengthsRangeFillOp'];['    FillerTensorInference(const OperatorDef & def,const vector & in)', '    shape', '    Fill(Tensor *output)', '    FillerOp(Args,...)', '    GetRepeatedArgument', '    InputIsTensorType', '    RunOnDevice', '    ~FillerOp', '    CheckRange', '    ConstantFillOp(Args,...)', '    DiagonalFillOp(Args,...)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    Fill(Tensor *output)', '    FillWithString(Tensor *output)', '    FillWithType(Tensor *output)', '    FillWithType(Tensor *output)', '    GaussianFillOp(Args,...)', '    GetStepSize(Tensor *output)', '    MSRAFillOp(Args,...)', '    RangeFillOp(Args,...)', '    UniformFillOp(Args,...)', '    UniqueUniformFillOp(Args,...)', '    VerifyOutputShape(Tensor *output)', '    XavierFillOp(Args,...)', '    LengthsRangeFillOp(Args,...)', '    RunOnDevice', '    ~LengthsRangeFillOp', '    dim', '    dim32', '    size', '    vec', '    partial_sum'];
timer_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 59;  6; 9;5;  41; 0;28;15;27;13;0.15;2;[];['    fill_non_native_type(TensorIterator & iter,Scalar value_scalar)', '    fill_kernel(TensorIterator & iter,Scalar value_scalar)'];
transform.h;C++;pytorch-master/pytorch-master/caffe2/core; 174;  89; 19;8;  60; 0;5;48;4;21;1.48;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFindDuplicateElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FindDuplicateElements'];
transform_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 459;  47; 71;4;  344; 0;195;133;152;128;0.14;37;['    final'];['    DoRunWithType', '    FindDuplicateElementsOp(Args,...)', '    RunOnDevice', '    ~FindDuplicateElementsOp'];
types.cc;C++;pytorch-master/pytorch-master/caffe2/core; 61;  5; 5;6;  46; 0;37;8;5;7;0.11;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFind', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Find'];
workspace.cc;C++;pytorch-master/pytorch-master/caffe2/core; 316;  23; 31;10;  253; 0;156;64;152;66;0.09;21;['    final'];['    DoRunWithType', '    FindOp(Args,...)', '    GetSingleArgument', '    RunOnDevice'];
workspace.h;C++;pytorch-master/pytorch-master/caffe2/core; 336;  141; 37;17;  144; 0;0;0;0;0;0.98;0;['    FixedDivisor', '    FixedDivisor'];['    CalcSignedMagic', '    d', '    Div(const std::int32_t n)', '    DivMod(const std::int32_t n,std::int32_t *q,int32_t *r)', '    FixedDivisor', '    FixedDivisor(const std::int32_t d)', '    magic', '    Mod(const std::int32_t n)', '    shift'];
workspace_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 149;  21; 22;3;  104; 0;71;22;66;22;0.20;7;[];['    CompareDivMod(int32_t v,int32_t divisor)', '    TEST(FixedDivisorTest,FixedDivisorInt32Test)'];
elemenntwise_rtc_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/cuda_rtc; 130;  27; 10;4;  92; 0;49;41;28;28;0.29;6;[];['    FixupONNXConditionals(std::shared_ptr & graph)', '    FixupONNXIfs(Block *block)'];
pool_op_rtc_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/cuda_rtc; 313;  10; 105;5;  199; 0;98;99;49;59;0.05;14;[];['    FixupONNXConditionals(std::shared_ptr & graph)'];
create_db_op.cc;C++;pytorch-master/pytorch-master/caffe2/db; 9;  1; 3;1;  5; 0;2;5;1;9;0.20;2;[];['    FuseSequenceSplitConcat(Block *b)', '    ConvertSequenceDependencies(Block *block)', '    CreateCastToBoolNode(Value *val,Graph *graph)', '    FixupONNXLoops(Block *block)', '    FixupONNXLoops(std::shared_ptr & graph)', '    InsertCastForCond(Value *cond_val,Graph *graph,Node *consumer_node)', '    IsCondCastRequired(Value *cond_val)', '    IsErasableSequence(const Node *loop_node,size_t i)'];
create_db_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/db; 6;  1; 1;2;  3; 0;1;3;1;5;0.33;1;[];['    FixupONNXLoops(std::shared_ptr & graph)'];
db_test.cc;C++;pytorch-master/pytorch-master/caffe2/db; 204;  21; 17;10;  158; 0;125;30;118;29;0.13;8;[];['    convertReturnsToTuples(Block *b)', '    convertTracedForksToRealForks(const std::shared_ptr & g)', '    createMethodCalls(const std::shared_ptr & g)', '    FixupTraceScopeBlocks(std::shared_ptr & graph,Module *self)', '    inlineScopeBlocks(Block *b)', '    isEligibleNode(Node *n)', '    lambdaLiftBlocksAndConvertToGraph(Block *b)', '    mangleMethodName(const std::string & method_name,const ClassTypePtr & mod_type)', '    runCleanupPasses(const std::shared_ptr & g)', '    runCleanupPasses(Module *m)', '    addSelfArgToTracedForwardNodes(Block *b)', '    buildAttrMap(const std::shared_ptr & graph)', '    convertAttrReferencesToLocalGetAttrs(Block *b,const c10::QualifiedName & prefix,Value *self)', '    destroyTracedAttrNodes(const std::shared_ptr & graph)', '    replaceTracedAttrInputOnNode(Node *n,size_t inp_idx,const c10::QualifiedName & prefix,Value *self,std::unordered_map & local_remaps,std::vector & unresolved_tracedattrs)', '    run(const std::shared_ptr & graph)', '    MakeDefsDominateUses', '    processNode(Node *n,Block *b)', '    run(Block *b)'];
leveldb.cc;C++;pytorch-master/pytorch-master/caffe2/db; 96;  3; 12;5;  78; 0;30;34;36;40;0.04;18;[];['    FixupTraceScopeBlocks(std::shared_ptr & graph,Module *self)'];
protodb.cc;C++;pytorch-master/pytorch-master/caffe2/db; 109;  7; 15;4;  86; 0;24;38;28;36;0.08;17;['    C10FlagParser'];['    CommandLineFlagsHasBeenParsed', '    ParseCommandLineFlags(int *pargc,char ***pargv)', '    RegistryName', '    SetUsageMessage(const string & str)', '    UsageMessage', '    C10FlagParser', '    Parse(const std::string & content,T *value)', '    success'];
zmqdb.cc;C++;pytorch-master/pytorch-master/caffe2/db; 116;  11; 20;7;  84; 0;33;38;36;35;0.13;14;[];[];
file_store_handler.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 165;  14; 27;22;  103; 5;55;38;52;29;0.14;11;['    C10FlagParser_c10_flags_test_only_flag'];['    TEST(FlagsTest,TestGflagsCorrectness)', '    C10FlagParser_c10_flags_test_only_flag(const std::string & content)'];
file_store_handler_op.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 26;  1; 11;1;  14; 0;9;12;1;9;0.07;2;[];[];
file_store_handler_op.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 39;  1; 8;3;  28; 0;6;20;6;10;0.04;2;[];['    CommandLineFlagsHasBeenParsed', '    GlobalInitStream', '    ParseCommandLineFlags(int *pargc,char ***pargv)', '    RegistryName', '    SetUsageMessage(const string & str)', '    UsageMessage', '    Parse(const string & content,bool *value)', '    Parse(const string & content,double *value)', '    Parse(const string & content,int64_t *value)', '    Parse(const string & content,int *value)', '    Parse(const string & content,string *value)'];
file_store_handler_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 21;  1; 4;9;  5; 6;1;3;1;5;0.20;1;['    flat_hash_map', '    flat_hash_set', '    sherwood_v3_table'];['    operator!=(const templated_iterator & lhs,const templated_iterator & rhs)', '    operator!=(const flat_hash_map & lhs,const flat_hash_map & rhs)', '    operator!=(const flat_hash_set & lhs,const flat_hash_set & rhs)', '    operator==(const templated_iterator & lhs,const templated_iterator & rhs)', '    operator==(const flat_hash_map & lhs,const flat_hash_map & rhs)', '    operator==(const flat_hash_set & lhs,const flat_hash_set & rhs)', '    log2(uint64_t value)', '    next_power_of_two(uint64_t i)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    to_insert(std::forward key,std::forward args,...)', '    mod0(uint64_t)', '    mod1009(uint64_t hash)', '    mod10193(uint64_t hash)', '    mod102877(uint64_t hash)', '    mod1037059(uint64_t hash)', '    mod10453007(uint64_t hash)', '    mod105359939(uint64_t hash)', '    mod1061961721(uint64_t hash)', '    mod10703903591(uint64_t hash)', '    mod107888587883(uint64_t hash)', '    mod1087448823553(uint64_t hash)', '    mod10960797308051(uint64_t hash)', '    mod11(uint64_t hash)', '    mod110477914016779(uint64_t hash)', '    mod1113547595345903(uint64_t hash)', '    mod11223856443489329(uint64_t hash)', '    mod113129383953203213(uint64_t hash)', '    mod1140272737634240411(uint64_t hash)', '    mod11493228998133068689(uint64_t hash)', '    mod1259(uint64_t hash)', '    mod127(uint64_t hash)', '    mod12853(uint64_t hash)', '    mod129607(uint64_t hash)', '    mod13(uint64_t hash)', '    mod1306601(uint64_t hash)', '    mod13169977(uint64_t hash)', '    mod132745199(uint64_t hash)', '    mod1337987929(uint64_t hash)', '    mod13486073473(uint64_t hash)', '    mod135931102921(uint64_t hash)', '    mod1370099663459(uint64_t hash)', '    mod13809739252051(uint64_t hash)', '    mod139193449418173(uint64_t hash)', '    mod1402982055436147(uint64_t hash)', '    mod14141172994150357(uint64_t hash)', '    mod142534092204280003(uint64_t hash)', '    mod1436653624766633509(uint64_t hash)', '    mod14480561146010017169(uint64_t hash)', '    mod151(uint64_t hash)', '    mod1597(uint64_t hash)', '    mod16193(uint64_t hash)', '    mod163307(uint64_t hash)', '    mod1646237(uint64_t hash)', '    mod16593127(uint64_t hash)', '    mod167248483(uint64_t hash)', '    mod1685759167(uint64_t hash)', '    mod16991387857(uint64_t hash)', '    mod17(uint64_t hash)', '    mod171262457903(uint64_t hash)', '    mod1726217406467(uint64_t hash)', '    mod17399181177241(uint64_t hash)', '    mod175372756929481(uint64_t hash)', '    mod1767646624268779(uint64_t hash)', '    mod17816761525534927(uint64_t hash)', '    mod179581703095829107(uint64_t hash)', '    mod1810070143251252131(uint64_t hash)', '    mod18446744073709551557(uint64_t hash)', '    mod197(uint64_t hash)', '    mod2(uint64_t hash)', '    mod2011(uint64_t hash)', '    mod20399(uint64_t hash)', '    mod205759(uint64_t hash)', '    mod2074129(uint64_t hash)', '    mod20906033(uint64_t hash)', '    mod210719881(uint64_t hash)', '    mod2123923447(uint64_t hash)', '    mod21407807219(uint64_t hash)', '    mod215777175787(uint64_t hash)', '    mod2174897647073(uint64_t hash)', '    mod21921594616111(uint64_t hash)', '    mod220955828033581(uint64_t hash)', '    mod2227095190691797(uint64_t hash)', '    mod22447712886978529(uint64_t hash)', '    mod226258767906406483(uint64_t hash)', '    mod2280545475268481167(uint64_t hash)', '    mod23(uint64_t hash)', '    mod251(uint64_t hash)', '    mod2539(uint64_t hash)', '    mod25717(uint64_t hash)', '    mod259229(uint64_t hash)', '    mod2613229(uint64_t hash)', '    mod26339969(uint64_t hash)', '    mod265490441(uint64_t hash)', '    mod2675975881(uint64_t hash)', '    mod26972146961(uint64_t hash)', '    mod271862205833(uint64_t hash)', '    mod2740199326961(uint64_t hash)', '    mod27619478504183(uint64_t hash)', '    mod278386898836457(uint64_t hash)', '    mod2805964110872297(uint64_t hash)', '    mod28282345988300791(uint64_t hash)', '    mod285068184408560057(uint64_t hash)', '    mod2873307249533267101(uint64_t hash)', '    mod29(uint64_t hash)', '    mod3(uint64_t hash)', '    mod313(uint64_t hash)', '    mod3203(uint64_t hash)', '    mod32401(uint64_t hash)', '    mod326617(uint64_t hash)', '    mod3292489(uint64_t hash)', '    mod33186281(uint64_t hash)', '    mod334496971(uint64_t hash)', '    mod3371518343(uint64_t hash)', '    mod33982775741(uint64_t hash)', '    mod342524915839(uint64_t hash)', '    mod3452434812973(uint64_t hash)', '    mod34798362354533(uint64_t hash)', '    mod350745513859007(uint64_t hash)', '    mod3535293248537579(uint64_t hash)', '    mod35633523051069991(uint64_t hash)', '    mod359163406191658253(uint64_t hash)', '    mod3620140286502504283(uint64_t hash)', '    mod37(uint64_t hash)', '    mod397(uint64_t hash)', '    mod4027(uint64_t hash)', '    mod40823(uint64_t hash)', '    mod411527(uint64_t hash)', '    mod4148279(uint64_t hash)', '    mod41812097(uint64_t hash)', '    mod421439783(uint64_t hash)', '    mod4247846927(uint64_t hash)', '    mod42815614441(uint64_t hash)', '    mod431554351609(uint64_t hash)', '    mod4349795294267(uint64_t hash)', '    mod43843189232363(uint64_t hash)', '    mod441911656067171(uint64_t hash)', '    mod4454190381383713(uint64_t hash)', '    mod44895425773957261(uint64_t hash)', '    mod452517535812813007(uint64_t hash)', '    mod4561090950536962147(uint64_t hash)', '    mod47(uint64_t hash)', '    mod499(uint64_t hash)', '    mod5(uint64_t hash)', '    mod5087(uint64_t hash)', '    mod51437(uint64_t hash)', '    mod518509(uint64_t hash)', '    mod5226491(uint64_t hash)', '    mod52679969(uint64_t hash)', '    mod530980861(uint64_t hash)', '    mod5351951779(uint64_t hash)', '    mod53944293929(uint64_t hash)', '    mod543724411781(uint64_t hash)', '    mod5480398654009(uint64_t hash)', '    mod55238957008387(uint64_t hash)', '    mod556773797672909(uint64_t hash)', '    mod5611928221744609(uint64_t hash)', '    mod56564691976601587(uint64_t hash)', '    mod570136368817120201(uint64_t hash)', '    mod5746614499066534157(uint64_t hash)', '    mod59(uint64_t hash)', '    mod631(uint64_t hash)', '    mod6421(uint64_t hash)', '    mod64811(uint64_t hash)', '    mod653267(uint64_t hash)', '    mod6584983(uint64_t hash)', '    mod66372617(uint64_t hash)', '    mod668993977(uint64_t hash)', '    mod6743036717(uint64_t hash)', '    mod67965551447(uint64_t hash)', '    mod685049831731(uint64_t hash)', '    mod6904869625999(uint64_t hash)', '    mod69596724709081(uint64_t hash)', '    mod7(uint64_t hash)', '    mod701491027718027(uint64_t hash)', '    mod7070586497075177(uint64_t hash)', '    mod71267046102139967(uint64_t hash)', '    mod718326812383316683(uint64_t hash)', '    mod7240280573005008577(uint64_t hash)', '    mod73(uint64_t hash)', '    mod797(uint64_t hash)', '    mod8089(uint64_t hash)', '    mod81649(uint64_t hash)', '    mod823117(uint64_t hash)', '    mod8296553(uint64_t hash)', '    mod83624237(uint64_t hash)', '    mod842879579(uint64_t hash)', '    mod8495693897(uint64_t hash)', '    mod85631228929(uint64_t hash)', '    mod863108703229(uint64_t hash)', '    mod8699590588571(uint64_t hash)', '    mod87686378464759(uint64_t hash)', '    mod883823312134381(uint64_t hash)', '    mod8908380762767489(uint64_t hash)', '    mod89790851547914507(uint64_t hash)', '    mod905035071625626043(uint64_t hash)', '    mod9122181901073924329(uint64_t hash)', '    mod97(uint64_t hash)', '    compute_max_lookups(uint64_t num_buckets)', '    allocate', '    deallocate', '    max_size', '    select_on_container_copy_construction', '    log2', '    next_power_of_two', '    commit(int8_t shift)', '    index_for_hash(uint64_t hash,uint64_t)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    at(const K & key)', '    at(const K & key)', '    operator flat_hash_map::V', '    emplace', '    end', '    find', '    flat_hash_map', '    insert_or_assign(const key_type & key,M)', '    insert_or_assign(key_type,M)', '    insert_or_assign(Table::const_iterator,const key_type & key,M)', '    insert_or_assign(Table::const_iterator,key_type,M)', '    operator[](const K & key)', '    operator[](K)', '    size', '    emplace(key_type)', '    emplace(const key_type)', '    emplace(Args,...)', '    emplace(const key_type & arg)', '    emplace(key_type & arg)', '    end', '    find', '    flat_hash_set', '    size', '    commit(int8_t)', '    index_for_hash(uint64_t hash,uint64_t num_slots_minus_one)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    commit(mod_function new_mod_function)', '    index_for_hash(uint64_t hash,uint64_t)', '    keep_in_range(uint64_t index,uint64_t num_slots_minus_one)', '    next_size_over(uint64_t & size)', '    reset', '    operator()(T &,T)', '    operator()(T & lhs,T)', '    operator()(T &,const T &)', '    operator()(T & lhs,const T & rhs)', '    functor_storage', '    functor_storage(const Functor & functor)', '    functor_storage(function_ptr function)', '    operator const ska::detailv3::functor_storage::function_ptr &', '    operator ska::detailv3::functor_storage::function_ptr &', '    operator()(Args,...)', '    operator()(Args,...)', '    operator()(Args,...)', '    KeyOrValueEquality', '    KeyOrValueEquality(const key_equal & equality)', '    operator()(const key_type & lhs,const key_type & rhs)', '    operator()(const key_type & lhs,const value_type & rhs)', '    operator()(const value_type & lhs,const key_type & rhs)', '    operator()(const value_type & lhs,const value_type & rhs)', '    operator()(const key_type & lhs,const std::pair & rhs)', '    operator()(const std::pair & lhs,const key_type & rhs)', '    operator()(const value_type & lhs,const std::pair & rhs)', '    operator()(const std::pair & lhs,const value_type & rhs)', '    operator()(const std::pair & lhs,const std::pair & rhs)', '    KeyOrValueHasher', '    KeyOrValueHasher(const hasher & hash)', '    operator()(const key_type & key)', '    operator()(const key_type & key)', '    operator()(const value_type & value)', '    operator()(const value_type & value)', '    operator()(const std::pair & value)', '    operator()(const std::pair & value)', '    destroy_value', '    emplace(int8_t distance,Args,...)', '    has_value', '    is_at_desired_position', '    is_empty', '    sherwood_v3_entry', '    sherwood_v3_entry(int8_t distance_from_desired)', '    ~sherwood_v3_entry', '    begin', '    begin', '    bucket(const FindKey & key)', '    bucket_count', '    cbegin', '    cend', '    clear', '    compares_equal(const L & lhs,const R & rhs)', '    operator const_iterator', '    operator iterator', '    count(const FindKey & key)', '    deallocate_data(EntryPointer begin,uint64_t num_slots_minus_one,int8_t max_lookups)', '    emplace(Key,Args,...)', '    emplace_hint(const_iterator,Args,...)', '    emplace_new_key(int8_t distance_from_desired,EntryPointer current_entry,Key,Args,...)', '    empty', '    empty_default_table', '    end', '    end', '    equal_range(const FindKey & key)', '    equal_range(const FindKey & key)', '    erase(const_iterator to_erase)', '    erase(const_iterator begin_it,const_iterator end_it)', '    erase(const FindKey & key)', '    find(const FindKey & key)', '    find(const FindKey & key)', '    get_allocator', '    grow', '    hash_function', '    hash_object(const U & key)', '    hash_object(const U & key)', '    insert(const value_type & value)', '    insert(value_type)', '    insert(const_iterator,const value_type & value)', '    insert(const_iterator,value_type)', '    insert(It begin,It end)', '    insert(std::initializer_list il)', '    key_eq', '    load_factor', '    max_bucket_count', '    max_load_factor(float value)', '    max_load_factor', '    max_size', '    num_buckets_for_reserve(uint64_t num_elements)', '    operator=(const sherwood_v3_table & other)', '    operator=(sherwood_v3_table)', '    rehash(uint64_t num_buckets)', '    rehash_for_other_container(const sherwood_v3_table & other)', '    reserve(uint64_t num_elements)', '    reset_to_empty_state', '    sherwood_v3_table', '    sherwood_v3_table(size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(It first,It last,size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentHash & hash,const ArgumentEqual & equal,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentAlloc & alloc)', '    sherwood_v3_table(std::initializer_list il,size_type bucket_count,const ArgumentHash & hash,const ArgumentAlloc & alloc)', '    sherwood_v3_table(const sherwood_v3_table & other)', '    sherwood_v3_table(const sherwood_v3_table & other,const ArgumentAlloc & alloc)', '    sherwood_v3_table(sherwood_v3_table)', '    sherwood_v3_table(sherwood_v3_table,const ArgumentAlloc & alloc)', '    shrink_to_fit', '    size', '    swap(sherwood_v3_table & other)', '    swap_pointers(sherwood_v3_table & other)', '    operator ska::sherwood_v3_table::templated_iterator', '    operator*', '    operator++', '    operator++(int)', '    operator->', '    templated_iterator', '    templated_iterator(EntryPointer current)', '    ~sherwood_v3_table', '    addressof', '    ceil', '    lower_bound', '    next', '    swap', '    emplace'];
redis_store_handler.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 120;  7; 15;5;  94; 0;54;60;61;51;0.07;8;[];['    flatten_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_,int64_t axis)'];
redis_store_handler.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 42;  1; 14;4;  24; 0;2;20;0;15;0.04;0;['    GetFlattenGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFlatten', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Flatten', '    vector', '    GetGradientDefs'];
redis_store_handler_op.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 22;  1; 6;1;  15; 0;10;13;1;9;0.07;2;['    FlattenOp'];['    TensorInferenceForFlatten(const OperatorDef & def,const std::vector & in)', '    FlattenOp(Args,...)', '    RunOnDevice'];
redis_store_handler_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 21;  1; 4;9;  5; 6;1;3;1;5;0.20;1;['    GetFlexibleTopKGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFlexibleTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPUFlexibleTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlexibleTopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlexibleTopKGradient', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    operator()(const std::pair & lhs,const std::pair & rhs)'];
store_handler.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 19;  3; 7;3;  7; 0;1;6;1;8;0.43;2;['    FlexibleTopKGradientOp', '    FlexibleTopKOp'];['    FlexibleTopKGradientOp(Args,...)', '    RunOnDevice', '    FlexibleTopKOp(Args,...)', '    RunOnDevice'];
store_handler.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 81;  27; 14;13;  28; 0;9;22;0;14;0.96;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Floor'];
store_ops.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 55;  0; 15;3;  37; 0;0;25;0;24;0.00;0;['    final'];['    FloorOp(Args,...)', '    RunOnDevice', '    ~FloorOp'];
fully_connected_op_decomposition.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 40;  17; 5;1;  18; 0;9;15;8;23;0.94;6;[];['    set_flush_denormal(bool on)'];
fully_connected_op_decomposition.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 217;  47; 14;6;  152; 0;121;52;97;99;0.31;12;[];['    set_flush_denormal(bool on)'];
fully_connected_op_prune.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 44;  20; 4;1;  21; 0;10;18;8;24;0.95;6;[];['    FoldImpl(const FoldOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    UnfoldImpl(const UnfoldOptions & options_)'];
fully_connected_op_prune.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 359;  62; 31;6;  264; 0;175;108;130;126;0.23;17;[];[];
fully_connected_op_sparse.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 26;  17; 4;1;  6; 0;2;6;1;8;2.83;2;[];[];
funhash_op.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 84;  18; 25;1;  42; 0;28;30;6;26;0.43;6;[];[];
funhash_op.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 236;  26; 38;15;  161; 0;101;87;94;120;0.16;4;[];['    __printFormat(std::ostream & stream,const Tensor & self)', '    __printIndent(std::ostream & stream,int64_t indent)', '    __printMatrix(std::ostream & stream,const Tensor & self,int64_t linesize,int64_t indent)', '    printScale(std::ostream & stream,double scale)', '    __printTensor(std::ostream & stream,Tensor & self,int64_t linesize)', '    defaultfloat(std::ios_base & __base)', '    operator<<(std::ostream & out,const DeprecatedTypeProperties & t)', '    print(std::ostream & stream,const Tensor & tensor_,int64_t linesize)', '    operator<<(std::ostream & out,Backend b)', '    FormatGuard(std::ostream & out)', '    ~FormatGuard'];
sparse_funhash_op.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 96;  19; 25;1;  54; 0;37;38;6;26;0.35;6;[];[];
sparse_matrix_reshape_op.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 69;  18; 34;1;  19; 0;14;19;1;10;0.95;2;[];[];
sparse_matrix_reshape_op.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 130;  17; 21;6;  88; 0;43;25;75;43;0.19;2;[];['    fma_fp16(int N,const float *A,const float *B,float *Out)'];
tt_contraction_op.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 56;  16; 10;1;  30; 0;19;26;4;23;0.53;6;[];['    fma_fp16(int N,const float *A,const float *B,float *Out)', '    fma_fp16_slow(int N,const float *A,const float *B,float *Out)', '    fma_fp16_slow(const float A,const float B,float Out)'];
tt_contraction_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 27;  16; 4;2;  6; 0;2;4;2;9;2.67;2;[];['    countLeadingZeros32(bits32 a)', '    extractFloat16Exp(float16 a)', '    extractFloat16Frac(float16 a)', '    extractFloat16Sign(float16 a)', '    fake_fma_fp16_slow(float v1,float v2,float v3)', '    fake_fma_fp16_slow(int N,const float *A,const float *B,float *Out)', '    float16_is_quiet_nan(float16 a)', '    float16_is_signaling_nan(float16 a)', '    float16_muladd(float16 a,float16 b,float16 c,flag negate_product)', '    float_raise(int8 flags)', '    fma16(const Word16 input,const Word16 a,const Word16 b,const Word32 fcr,const Word32 fsr_i,Word16 *result,Word32 *fsr_o)', '    fp_mac_h(Word16 d0,Word16 d1,Word16 d2,Word32 negate_product,Word32 fcr,Word32 fsr_i,Word16 *res,Word32 *fsr_o)', '    GetException(Word32 fsr)', '    GetRound(Word32 fcr)', '    normalizeFloat16Subnormal(bits16 aSig,int16 *zExpPtr,bits16 *zSigPtr)', '    packFloat16(flag zSign,int16 zExp,bits16 zSig)', '    pickNaNMulAdd(flag aIsQNaN,flag aIsSNaN,flag bIsQNaN,flag bIsSNaN,flag cIsQNaN,flag cIsSNaN,flag infzero)', '    propagateFloat16MulAddNaN(float16 a,float16 b,float16 c,flag infzero)', '    roundAndPackFloat16(flag zSign,int16 zExp,bits16 zSig)', '    shift16RightJamming(bits16 a,int16 count,bits16 *zPtr)', '    shift32RightJamming(bits32 a,int16 count,bits32 *zPtr)'];
tt_pad_op.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 46;  17; 7;1;  23; 0;12;21;4;24;0.74;6;[];['    TEST(FP16_FMA,Simple)', '    TEST(FP16_FMA,Comprehensive)'];
tt_pad_op.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 94;  18; 19;6;  53; 0;26;28;55;68;0.34;4;['    final'];['    fp16_momentum_sgd_update(int N,const at::Half *g,const at::Half *m,at::Half *ng,at::Half *nm,const float *lr,float momentum,bool nesterov,float weight_decay,bool fp32_update,at::Half *param,Context *)', '    FP16MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    momentum_', '    RunOnDevice', '    weight_decay_'];
adam_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 181;  3; 13;10;  156; 3;88;94;62;86;0.02;8;[];['    pytorch_qnnp_requantize_fp32__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
channel_shuffle_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 55;  1; 17;1;  37; 0;10;20;51;90;0.03;4;[];[];
concat_split_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 173;  4; 22;3;  145; 0;0;0;0;1;0.03;0;[];[];
conv_pool_base_op.h;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 77;  5; 13;10;  54; 0;26;21;21;18;0.09;8;[];['    pytorch_qnnp_requantize_fp32__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
conv_transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 157;  2; 23;2;  132; 0;51;68;89;176;0.02;6;[];['    pytorch_qnnp_requantize_fp32__scalar_lrintf(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_magic(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
conv_transpose_unpool_base_op.h;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 264;  10; 39;7;  211; 0;110;66;150;94;0.05;20;[];[];
elementwise_sum_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 81;  4; 13;4;  61; 0;30;25;51;62;0.07;3;[];['    pytorch_qnnp_requantize_fp32__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
expand_squeeze_dims_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 131;  3; 24;3;  102; 0;47;43;107;123;0.03;6;[];[];
fully_connected_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 143;  5; 29;1;  109; 0;59;47;83;116;0.05;10;['    final'];['    fp32_momentum_sgd_update(int N,const float *g,const float *m,float *ng,float *nm,const float *lr,float momentum,bool nesterov,float weight_decay,float *param,Context *)', '    FP32MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    momentum_', '    RunOnDevice', '    weight_decay_'];
momentum_sgd_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 127;  3; 17;4;  104; 1;53;41;84;102;0.03;5;[];['    fractional_max_pool2d_backward_out_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int numBatch,int numPlanes,int inputW,int inputH,int outputW,int outputH)', '    fractional_max_pool2d_backward_out_single_batch_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int numPlanes,int inputW,int inputH,int outputW,int outputH)', '    fractional_max_pool2d_generate_intervals(scalar_t sample,int inputSize,int outputSize,int poolSize)', '    fractional_max_pool2d_out_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int numBatch,int numPlanes,int inputW,int inputH,int outputW,int outputH,int poolSizeW,int poolSizeH)', '    fractional_max_pool2d_out_single_batch_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int numPlanes,int inputW,int inputH,int outputW,int outputH,int poolSizeW,int poolSizeH)', '    fractional_max_pool2d_backward_cpu(const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool2d_backward_out_cpu(at::Tensor & gradInput,const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool2d_backward_out_cpu_template(const at::Tensor & input,const at::Tensor & gradOutput_,at::Tensor & gradInput,IntArrayRef output_size,IntArrayRef pool_size,const at::Tensor & indices)', '    fractional_max_pool2d_cpu(const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool2d_out_cpu(at::Tensor & output,at::Tensor & indices,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool2d_out_cpu_template(const at::Tensor & input_,at::Tensor & output,IntArrayRef output_size,IntArrayRef pool_size,at::Tensor & indices,const at::Tensor & randomSamples)'];
operator_fallback_ideep.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 318;  6; 15;60;  210; 34;0;74;0;145;0.03;0;[];['    fractional_max_pool3d_backward_out_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int64_t numBatch,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW)', '    fractional_max_pool3d_backward_out_single_batch_frame(scalar_t *gradInput,scalar_t *gradOutput,int64_t *indices,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW)', '    fractional_max_pool3d_out_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int64_t numBatch,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW,int64_t poolSizeT,int64_t poolSizeH,int64_t poolSizeW)', '    fractional_max_pool3d_out_single_batch_frame(scalar_t *input,scalar_t *output,int64_t *indices,scalar_t *randomSamples,int64_t numPlanes,int64_t inputT,int64_t inputH,int64_t inputW,int64_t outputT,int64_t outputH,int64_t outputW,int64_t poolSizeT,int64_t poolSizeH,int64_t poolSizeW)', '    generate_intervals(scalar_t sample,int64_t inputSize,int64_t outputSize,int64_t poolSize)', '    fractional_max_pool3d_backward_cpu(const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool3d_backward_out_cpu(at::Tensor & gradInput,const at::Tensor & gradOutput_,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & indices)', '    fractional_max_pool3d_backward_out_cpu_template(const Tensor & input,const Tensor & gradOutput_,Tensor & gradInput,IntArrayRef output_size,IntArrayRef pool_size,const Tensor & indices)', '    fractional_max_pool3d_cpu(const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool3d_out_cpu(at::Tensor & output,at::Tensor & indices,const at::Tensor & input,IntArrayRef pool_size,IntArrayRef output_size,const at::Tensor & randomSamples)', '    fractional_max_pool3d_out_cpu_template(Tensor & output,Tensor & indices,const Tensor & input_,IntArrayRef pool_size,IntArrayRef output_size,const Tensor & randomSamples)'];
operator_fallback_ideep.h;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 190;  45; 10;6;  130; 0;0;1;0;0;0.35;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFree', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Free'];
pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 118;  3; 22;1;  93; 0;35;35;76;124;0.03;6;['    FreeOp'];['    Reset', '    FreeOp(Args,...)', '    RunOnDevice'];
int8_add_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 76;  1; 14;1;  61; 0;27;30;62;69;0.02;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAFree'];
int8_conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 240;  4; 28;1;  208; 0;84;166;156;236;0.02;11;['    AttributePropagator'];['    freeze_module(const Module & module)', '    AttributePropagator(Module & module)', '    cleanupFrozenModule(std::shared_ptr & graph)', '    findConstantAttr(Value *input,std::string & name,Module & attrModule)', '    insertMutableAttr(const std::string & name,const IValue & attr,Module & attrModule)', '    overrideGradient(IValue)', '    propagateAttributes(std::shared_ptr & graph)', '    recordMutableAttrs(std::shared_ptr & graph)', '    recordReferencedAttrs(std::shared_ptr & graph)', '    run(std::shared_ptr & graph)'];
int8_fully_connected_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 94;  2; 18;1;  74; 0;39;29;66;82;0.03;5;[];['    freeze_module(const Module & module)'];
int8_given_tensor_fill_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 147;  2; 23;1;  122; 0;71;51;98;119;0.02;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFtrl', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFtrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Ftrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFtrl', '    ftrl_compute(const T w,const T n,const T z,const T g,T & nw,T & nn,T & nz,const FtrlParams & params)', '    ftrl_update(int N,const T *w,const T *nz,const T *g,T *new_w,T *new_nz,const FtrlParams & params,Context *)', '    sgn(const T x)', '    RunOnDevice', '    DoRun'];
int8_pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 64;  2; 13;1;  49; 0;17;18;39;62;0.04;3;['    final', '    final'];['    DoRun', '    FtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    SparseFtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    FtrlParams(OperatorBase *op)'];
int8_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 42;  2; 11;1;  29; 0;10;13;32;50;0.07;3;['    FullyConnectedOperatorTester', '    Mode'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    inputChannels(size_t inputChannels)', '    inputChannels', '    inputChannels_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputChannels(size_t outputChannels)', '    outputChannels', '    outputChannels_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8(const Mode mode)'];
queue_ops.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 73;  1; 14;2;  57; 0;27;33;69;104;0.02;5;[];['    pytorch_qnnp_create_fully_connected_nc_q8(size_t input_channels,size_t output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *fully_connected_out)', '    pytorch_qnnp_setup_fully_connected_nc_q8(pytorch_qnnp_operator_t fully_connected,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 89;  3; 19;1;  67; 0;28;27;69;103;0.04;6;[];['    TEST(FULLY_CONNECTED_OP,integration_test_static)', '    TEST(FULLY_CONNECTED_OP,integration_test_runtime)', '    TEST(FULLY_CONNECTED_OP,integration_test_dynamic)', '    TEST(FULLY_CONNECTED_OP,zero_batch_static)', '    TEST(FULLY_CONNECTED_OP,zero_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,zero_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmin_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_qmax_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_input_stride_dynamic)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_static)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_runtime)', '    TEST(FULLY_CONNECTED_OP,unit_batch_with_output_stride_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmin_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax_runtime)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_qmax_dynamic)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_input_stride_static)', '    TEST(FULLY_CONNECTED_OP,small_batch_with_output_stride_static)'];
shape_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 70;  4; 14;1;  52; 0;31;25;50;63;0.08;2;[];['    block', '    FullyConnectedDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
sigmoid_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 62;  1; 18;1;  43; 0;12;23;55;97;0.02;6;['    final'];['    FullyConnectedDNNLowPAcc16Op(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
spatial_batch_norm_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 105;  1; 19;1;  85; 0;43;48;82;120;0.01;6;['    C10FlagParser_caffe2_dnnlowp_enforce_default_operators'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FCRelu', '    C10FlagParser_caffe2_dnnlowp_enforce_default_operators(const std::string & content)', '    FullyConnectedDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    RunOnDevice'];
utility_ops.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 127;  1; 15;3;  109; 0;67;52;106;154;0.01;13;['    FullyConnectedDNNLowPOp'];['    axis_', '    axis_w_', '    b_dequantized_data_', '    b_quantized_data_', '    FullyConnectedDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    is_weight_constant_', '    requantization_param_selected_', '    RunOnDevice'];
ideep_context.h;C++;pytorch-master/pytorch-master/caffe2/ideep/utils; 171;  6; 30;5;  133; 0;50;54;66;44;0.05;25;[];['    dimErrorString', '    DoRunWithType', '    DoRunWithType'];
ideep_operator.h;C++;pytorch-master/pytorch-master/caffe2/ideep/utils; 151;  24; 20;30;  85; 0;38;33;33;25;0.28;11;['    final', '    FullyConnectedGradientFakeLowpFPOp'];['    fp32_to_bfp14(const float *source,size_t size,float *dest)', '    fp32_to_bfp16(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_round(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_scalar(const float *source,size_t size,float *dest)', '    fp32_to_bfp24(const float *source,size_t size,float *dest)', '    fp32_to_fp16(const float *source,size_t size,float *dest)', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedFakeLowpFPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedFakeLowpFPOp', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedGradientFakeLowpFPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedGradientFakeLowpFPOp'];
image_input_op.cc;C++;pytorch-master/pytorch-master/caffe2/image; 167;  2; 23;7;  136; 3;127;134;1;16;0.01;2;[];['    fp32_to_bfp14(const float *source,size_t size,float *dest)', '    fp32_to_bfp16(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_round(const float *source,size_t size,float *dest)', '    fp32_to_bfp16_scalar(const float *source,size_t size,float *dest)', '    fp32_to_bfp24(const float *source,size_t size,float *dest)', '    fp32_to_fp16(const float *source,size_t size,float *dest)'];
image_input_op.h;C++;pytorch-master/pytorch-master/caffe2/image; 1346;  136; 109;14;  1095; 0;557;482;384;676;0.12;22;['    GetFCGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUFC', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCTransposed', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCTransposed', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCTransposedGradient', '    CostInferenceForFCGradient(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    FCGradientShapeInference(const OperatorDef & def,const vector & in,bool pretransposed_weight)', '    vector', '    GetGradientDefs'];
image_input_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/image; 38;  2; 4;3;  30; 0;5;23;1;26;0.07;1;['    final', '    final'];['    axis_', '    axis_', '    axis_w_', '    axis_w_', '    IDEEPFullyConnectedGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPFullyConnectedOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPFullyConnectedGradientOp', '    ~IDEEPFullyConnectedOp'];
ios_caffe.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 56;  1; 5;4;  46; 0;30;18;21;10;0.02;2;['    final', '    FullyConnectedGradientOp'];['    dimErrorString', '    dimErrorString', '    has_value', '    numel', '    Resize', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedOp', '    axis_', '    axis_w_', '    DoRunWithType', '    FullyConnectedGradientOp(Args,...)', '    GetSingleArgument', '    RunOnDevice', '    ~FullyConnectedGradientOp'];
ios_caffe.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 25;  0; 5;7;  13; 0;0;13;0;4;0.00;0;['    GetFCDecompGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Decomp', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCGradient_Decomp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Decomp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient_Decomp', '    vector', '    GetGradientDefs'];
ios_caffe_defines.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 2;  0; 1;1;  0; 0;0;0;0;0;0.00;0;['    final', '    FullyConnectedDecompGradientOp'];['    bias_multiplier_', '    FullyConnectedOpDecomp(const OperatorDef & operator_def,Workspace *ws)', '    multi_buffer_', '    RunOnDevice', '    ~FullyConnectedOpDecomp', '    bias_multiplier_', '    du_buffer_', '    dv_buffer_', '    dx_buffer_', '    FullyConnectedDecompGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedDecompGradientOp'];
ios_caffe_predictor.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 36;  5; 6;5;  20; 0;3;7;2;7;0.25;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAFC_Decomp', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCGradient_Decomp'];
mpscnn.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios/mpscnn; 23;  6; 4;3;  11; 0;3;11;0;10;0.55;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAFC', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCTransposed', '    CAFFE_ANONYMOUS_VARIABLE_CUDAFCTransposedGradient', '    RunFullyConnectedGradientOpOnCUDADevice(const bool float16_compute,FullyConnectedGradientOp *op)', '    RunFullyConnectedOpOnCUDADevice(const bool float16_compute,FullyConnectedOp *op)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
mpscnn_context.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios/mpscnn; 33;  2; 8;9;  15; 0;0;12;0;10;0.13;0;['    GetFCPruneGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Prune', '    CAFFE_ANONYMOUS_VARIABLE_CPUFCGradient_Prune', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Prune', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FCGradient_Prune', '    vector', '    GetGradientDefs'];
mpscnn_kernels.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios/mpscnn; 1165;  1; 1162;0;  2; 0;2;2;0;1;0.50;0;['    final', '    FullyConnectedPruneGradientOp'];['    AggrDW(T *ag_dw,const T *dw,int N,int K,Context *context)', '    AggrDW(float *ag_dw,const float *dw,int N,int K,CPUContext *context)', '    MaskMatrix(const T *mask,T *mat,int M,int N)', '    MaskMatrix(const float *mask,float *mat,int M,int N)', '    MaskMatrix_Inc(T *mask_seq,T *mat,int M,int N,int seq_len,T target)', '    MaskMatrix_Inc(float *mask_seq,float *mat,int,int,int seq_len,float target)', '    MatrixCompare_LT(const T *mat,float thres,T *mask_seq,int M,int N)', '    MatrixCompare_LT(const float *mat,float thres,float *mask_seq,int M,int N)', '    shape(int i,int j)', '    shape(Shape vs)', '    shape(int i)', '    bias_multiplier_', '    FullyConnectedOpPrune(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedOpPrune', '    bias_multiplier_', '    comp_r_buf_', '    FullyConnectedPruneGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    sum_buffer_', '    ~FullyConnectedPruneGradientOp', '    ResizeLike'];
mpscnn_test.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios/mpscnn; 10;  1; 3;2;  5; 0;0;5;0;4;0.20;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFC_Sparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FC_Sparse'];
pool_test.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 161;  7; 23;8;  125; 0;78;71;51;55;0.06;8;['    final'];['    shape(int i,int j)', '    shape(int i)', '    shape(Shape vs)', '    Sparse_mm(const T *acsr,const int *ia,const int *ja,int m,int k,int n,const T *b,T *c,Context *context)', '    Sparse_mm(const float *acsr,const int *ia,const int *ja,int m,int k,int n,const float *b,float *c,CPUContext *)', '    trans_mat(const T *o,T *t,int m,int n,Context *context)', '    trans_mat(const float *o,float *t,int m,int n,CPUContext *)', '    bias_multiplier_', '    FullyConnectedOp_SPARSE(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~FullyConnectedOp_SPARSE'];
cl.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 1213;  531; 150;374;  600; 1;0;600;0;155;0.89;0;[];['    gatherFunctions(Node *func,std::vector)', '    deleteNode(Node *function)', '    get_next_sequence_nr', '    metadata', '    name', '    peek_at_next_sequence_nr'];
cl.hpp;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 12453;  1072; 1062;672;  8530; 1251;2443;4863;918;1568;0.13;405;[];['    append_constant(const c10::IValue & constant)', '    append_instruction(OpCode op,int X,int N)', '    append_operator(const std::string & name,const std::string & overload_name)', '    append_type(const at::TypePtr & type)', '    Function(c10::QualifiedName name)', '    run(Stack & stack)', '    set_register_size(size_t size)'];
cl_ext.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 251;  138; 49;55;  48; 2;0;48;0;16;2.88;0;[];['    unpack_dim_args(const std::vector & dim_args,std::vector *dims,std::vector *vars)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    total_index', '    ElementStmt(size_t index)'];
cl_gl_ext.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 69;  44; 10;13;  6; 1;0;6;0;2;7.33;0;[];[];
cl_platform.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 1254;  90; 90;590;  186; 484;0;467;0;104;0.48;0;[];[];
opencl.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 54;  24; 9;18;  2; 6;0;1;0;1;12.00;0;['    Function'];['    append_constant(const c10::IValue & constant)', '    append_instruction(OpCode op,int X,int N)', '    append_operator(const std::string & name,const std::string & overload_name)', '    append_type(const c10::TypePtr & type)', '    Function(c10::QualifiedName name)', '    name', '    qualname', '    run(Stack & stack)', '    set_register_size(size_t size)'];
libopencl.c;C;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/src; 2153;  10; 333;6;  1785; 20;763;701;631;207;0.01;102;['    Function'];['    arg(int index)', '    args', '    bodies', '    body(size_t index)', '    dim(int index)', '    dims', '    ElementStmt(size_t index)', '    func_var(size_t index)', '    func_vars', '    Function(const std::string & func_name,const std::vector & dims,const std::vector & args,const Expr *body)', '    Function(const std::vector & func_names,const std::vector & dims,const std::vector & args,const std::vector & bodies)', '    ndim'];
libvulkan-stub.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libvulkan-stub/include; 387;  21; 8;179;  177; 2;0;177;0;177;0.12;0;[];[];
vk_platform.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libvulkan-stub/include/vulkan; 120;  44; 16;47;  8; 26;0;8;0;8;5.50;0;[];['    operator()(const variable_list & outputs,const variable_list & inputs)', '    ~FunctionPostHook', '    operator()(const variable_list & grads)', '    ~FunctionPreHook'];
libvulkan-stub.c;C;pytorch-master/pytorch-master/caffe2/mobile/contrib/libvulkan-stub/src; 553;  21; 15;12;  481; 25;282;178;552;178;0.04;11;[];['    ensure_defined', '    getSchema', '    run(Stack)', '    run(Stack & stack)', '    defaultSchemaFor(const Function & function)', '    placeholderCreator(GraphFunction &)', '    preoptimizeGraph(std::shared_ptr & graph)', '    vector'];
dlnnapi.c;C;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 129;  20; 14;20;  68; 9;53;33;26;8;0.29;2;[];[];
dlnnapi.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 104;  5; 30;10;  57; 2;0;54;0;56;0.09;0;[];['    dump'];
nnapi.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 715;  39; 89;5;  584; 0;440;193;382;175;0.07;13;[];[];
nnapi.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 110;  8; 20;6;  77; 0;28;62;6;41;0.10;15;[];[];
nnapi_benchmark.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 468;  32; 21;7;  410; 0;271;182;146;84;0.08;10;[];['    convertToList(TypeKind kind,const SourceRange & range,std::vector vs)', '    parseArgument(size_t idx,bool is_return,bool kwarg_only)', '    parseConstantList(TypeKind kind)', '    parseDefaultValue(const TypePtr & arg_type,c10::optional arg_N)', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseName(const std::string & name)', '    parseSchema(const std::string & schema)', '    parseSchemaOrName(const std::string & schemaOrName)', '    parseSingleConstant(TypeKind kind)', '    parseTensorDefault(const SourceRange & range)', '    parseDeclaration', '    parseName', '    SchemaParser(const std::string & str)'];
snpe_ffi.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/snpe; 131;  5; 30;18;  80; 0;39;45;44;138;0.06;9;[];[];
snpe_ffi.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/snpe; 35;  1; 14;5;  16; 0;1;16;0;9;0.06;0;[];['    align_corners', '    align_corners', '    alpha', '    alpha', '    beta', '    dim', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    lambda', '    lambda', '    lower', '    max_val', '    min_val', '    negative_slope', '    rate', '    rate', '    rate', '    rate', '    rate', '    scale_factor', '    scale_factor', '    test_allclose(const at::Device & device)', '    TEST_F(FunctionalTest,Conv1d)', '    TEST_F(FunctionalTest,Conv2dEven)', '    TEST_F(FunctionalTest,Conv2dUneven)', '    TEST_F(FunctionalTest,Conv3d)', '    TEST_F(FunctionalTest,MaxPool1d)', '    TEST_F(FunctionalTest,MaxPool2d)', '    TEST_F(FunctionalTest,MaxPool3d)', '    TEST_F(FunctionalTest,AvgPool1d)', '    TEST_F(FunctionalTest,AvgPool2d)', '    TEST_F(FunctionalTest,AvgPool3d)', '    TEST_F(FunctionalTest,FractionalMaxPool2d)', '    TEST_F(FunctionalTest,FractionalMaxPool3d)', '    TEST_F(FunctionalTest,LPPool1d)', '    TEST_F(FunctionalTest,LPPool2d)', '    TEST_F(FunctionalTest,CosineSimilarity)', '    TEST_F(FunctionalTest,SmoothL1LossDefaultOptions)', '    TEST_F(FunctionalTest,SmoothL1LossNoReduction)', '    TEST_F(FunctionalTest,SoftMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,MultiLabelSoftMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,SoftMarginLossNoReduction)', '    TEST_F(FunctionalTest,MultiLabelSoftMarginLossWeightedNoReduction)', '    TEST_F(FunctionalTest,PairwiseDistance)', '    TEST_F(FunctionalTest,PDist)', '    TEST_F(FunctionalTest,AdaptiveMaxPool1d)', '    TEST_F(FunctionalTest,AdaptiveMaxPool2d)', '    TEST_F(FunctionalTest,AdaptiveMaxPool3d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool1d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool2d)', '    TEST_F(FunctionalTest,AdaptiveAvgPool3d)', '    TEST_F(FunctionalTest,L1Loss)', '    TEST_F(FunctionalTest,MSELoss)', '    TEST_F(FunctionalTest,BCELoss)', '    TEST_F(FunctionalTest,KLDivLoss)', '    TEST_F(FunctionalTest,HingeEmbeddingLoss)', '    TEST_F(FunctionalTest,GridSample)', '    TEST_F(FunctionalTest,AffineGrid)', '    TEST_F(FunctionalTest,MultiMarginLoss)', '    TEST_F(FunctionalTest,CosineEmbeddingLoss)', '    TEST_F(FunctionalTest,MultiLabelMarginLossDefaultOptions)', '    TEST_F(FunctionalTest,MultiLabelMarginLossNoReduction)', '    TEST_F(FunctionalTest,TripletMarginLoss)', '    TEST_F(FunctionalTest,NLLLoss)', '    TEST_F(FunctionalTest,CrossEntropy)', '    TEST_F(FunctionalTest,MaxUnpool1d)', '    TEST_F(FunctionalTest,MaxUnpool2d)', '    TEST_F(FunctionalTest,MaxUnpool3d)', '    TEST_F(FunctionalTest,ELU)', '    TEST_F(FunctionalTest,SELU)', '    TEST_F(FunctionalTest,GLU)', '    TEST_F(FunctionalTest,GELU)', '    TEST_F(FunctionalTest,Hardshrink)', '    TEST_F(FunctionalTest,OneHot)', '    TEST_F(FunctionalTest,Hardtanh)', '    TEST_F(FunctionalTest,LeakyReLU)', '    TEST_F(FunctionalTest,LogSigmoid)', '    TEST_F(FunctionalTest,GumbelSoftmax)', '    TEST_F(FunctionalTest,Softmax)', '    TEST_F(FunctionalTest,Softmin)', '    TEST_F(FunctionalTest,LogSoftmax)', '    TEST_F(FunctionalTest,PReLU)', '    TEST_F(FunctionalTest,LayerNorm)', '    TEST_F(FunctionalTest,GroupNorm)', '    TEST_F(FunctionalTest,LocalResponseNorm)', '    TEST_F(FunctionalTest,Linear)', '    TEST_F(FunctionalTest,Embedding)', '    TEST_F(FunctionalTest,EmbeddingBag)', '    TEST_F(FunctionalTest,Bilinear)', '    TEST_F(FunctionalTest,Normalize)', '    TEST_F(FunctionalTest,ReLU)', '    TEST_F(FunctionalTest,ReLUDefaultOptions)', '    TEST_F(FunctionalTest,ReLU6)', '    TEST_F(FunctionalTest,ReLU6DefaultOptions)', '    TEST_F(FunctionalTest,RReLU)', '    TEST_F(FunctionalTest,RReLUDefaultOptions)', '    TEST_F(FunctionalTest,CELU)', '    TEST_F(FunctionalTest,CELUDefaultOptions)', '    TEST_F(FunctionalTest,PixelShuffle)', '    TEST_F(FunctionalTest,Softplus)', '    TEST_F(FunctionalTest,SoftplusDefaultOptions)', '    TEST_F(FunctionalTest,Fold)', '    TEST_F(FunctionalTest,Unfold)', '    TEST_F(FunctionalTest,Softshrink)', '    TEST_F(FunctionalTest,SoftshrinkDefaultOptions)', '    TEST_F(FunctionalTest,Softsign)', '    TEST_F(FunctionalTest,Tanhshrink)', '    TEST_F(FunctionalTest,Threshold)', '    TEST_F(FunctionalTest,BatchNorm1d)', '    TEST_F(FunctionalTest,BatchNorm1dDefaultOptions)', '    TEST_F(FunctionalTest,BatchNorm2d)', '    TEST_F(FunctionalTest,BatchNorm2dDefaultOptions)', '    TEST_F(FunctionalTest,BatchNorm3d)', '    TEST_F(FunctionalTest,BatchNorm3dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm1d)', '    TEST_F(FunctionalTest,InstanceNorm1dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm2d)', '    TEST_F(FunctionalTest,InstanceNorm2dDefaultOptions)', '    TEST_F(FunctionalTest,InstanceNorm3d)', '    TEST_F(FunctionalTest,InstanceNorm3dDefaultOptions)', '    TEST_F(FunctionalTest,Interpolate)', '    TEST_F(FunctionalTest,Pad)', '    TEST_F(FunctionalTest,CTCLoss)', '    TEST_F(FunctionalTest,PoissonNLLLoss)', '    TEST_F(FunctionalTest,MarginRankingLoss)', '    TEST_F(FunctionalTest,ConvTranspose1d)', '    TEST_F(FunctionalTest,ConvTranspose2dEven)', '    TEST_F(FunctionalTest,ConvTranspose2dUneven)', '    TEST_F(FunctionalTest,ConvTranspose3d)', '    TEST_F(FunctionalTest,AlphaDropout)', '    TEST_F(FunctionalTest,FeatureAlphaDropout)', '    TEST_F(FunctionalTest,Dropout)', '    TEST_F(FunctionalTest,Dropout2d)', '    TEST_F(FunctionalTest,Dropout3d)', '    TEST_F(FunctionalTest,isfinite)', '    TEST_F(FunctionalTest,isfinite_CUDA)', '    TEST_F(FunctionalTest,isinf)', '    TEST_F(FunctionalTest,isinf_CUDA)', '    TEST_F(FunctionalTest,AllClose)', '    TEST_F(FunctionalTest,AllClose_CUDA)', '    TEST_F(FunctionalTest,BCEWithLogitsLoss)', '    test_isfinite(const at::Device & device)', '    test_isinf(const at::Device & device)', '    threshold', '    threshold', '    upper', '    value'];
snpe_globals.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/snpe; 17;  0; 4;3;  10; 0;4;5;2;4;0.00;1;[];['    forward(Tensor input)', '    FunctionalImpl(Function)', '    is_serializable', '    operator()(Tensor input)', '    pretty_print(std::ostream & stream)', '    reset'];
snpe_op_benchmark.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/snpe; 194;  1; 0;32;  3; 187;1;1;1;1;0.33;1;[];[];
ulp.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ulp2; 387;  18; 26;10;  330; 4;238;149;177;137;0.05;13;[];[];
ulp.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ulp2; 69;  3; 14;3;  50; 0;10;47;2;33;0.06;8;[];[];
ulp_neon.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ulp2; 11;  0; 4;2;  5; 0;2;5;0;4;0.00;0;[];['    map2_reduce_all(const MapOp & map_fun,const ReduceOp & red_fun,const scalar_t *data,const scalar_t *data2,int64_t size)', '    map_reduce_all(const MapOp & map_fun,const ReduceOp & red_fun,scalar_t *data,int64_t size)', '    reduce_all(const Op & vec_fun,scalar_t *data,int64_t size)', '    vec_reduce_all(const Op & vec_fun,vec256::Vec256 acc_vec,int64_t size)', '    map2(const Op & vec_fun,scalar_t *output_data,scalar_t *input_data,scalar_t *input_data2,int64_t size)', '    store', '    set'];
ulp_test.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ulp2; 459;  12; 40;3;  405; 0;312;112;216;105;0.03;17;['    function_ref'];['    callback_fn(intptr_t callable,Params,...)', '    function_ref', '    function_ref(std::nullptr_t)', '    function_ref(Callable,std::enable_if::type *,std::enable_if::type *)', '    operator bool', '    operator()(Params,...)'];
mpi_common.cc;C++;pytorch-master/pytorch-master/caffe2/mpi; 178;  24; 30;4;  121; 0;75;45;114;42;0.20;8;[];['    _maybe_overlapping_memory(IntArrayRef sizes,IntArrayRef strides)', '    _min_storage_size(IntArrayRef sizes,IntArrayRef strides,int64_t storage_offset)', '    $', '    _cudnn_ctc_loss_backward(const Tensor & grad_out,const Tensor & loss,const Tensor & raw_grad,bool zero_infinity)', '    _trilinear_backward(const Tensor & grad_out,const Tensor & i1,const Tensor & i2,const Tensor & i3,IntArrayRef expand1,IntArrayRef expand2,IntArrayRef expand3,IntArrayRef sumdim,int64_t unroll_dim,std::array grad_mask)', '    batchnorm_double_backward(const Tensor & input,const Tensor & gamma,const Tensor & ggI,const Tensor & ggG,const Tensor & ggB,const Tensor & gO,const Tensor & running_mean,const Tensor & running_var,bool training,double eps,const Tensor & save_mean,const Tensor & save_invstd,std::array output_mask)', '    constant_pad_nd_backward(const Tensor & grad,IntArrayRef pad)', '    embedding_dense_double_backward(const Tensor & grad,const Tensor & indices)', '    expand_as_dim1(const Tensor & src,const Tensor & target)', '    fft_backward(const Tensor & self,const Tensor & grad,int64_t signal_ndim,bool complex_input,bool complex_output,bool inverse,IntArrayRef checked_signal_sizes,bool normalized,bool onesided,IntArrayRef output_sizes)', '    first_back_grad_input', '    index_backward(Tensor zeros_like_self,TensorList indices,const Tensor & grad)', '    infinitely_differentiable_native_layer_norm_backward(const Tensor & dY,const Tensor & dmean,const Tensor & drstd,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,double eps,std::array grad_input_mask)', '    log1p_backward(const Tensor & grad,const Tensor & self)', '    nonsingular_case_backward', '    nonsingular_case_backward', '    nonsingular_case_backward', '    singular_case_backward', '    singular_case_backward', '    singular_case_backward', '    sparse_constructor_values_backward(const Tensor & sparse_grad_out,const Tensor & indices,IntArrayRef values_shape)', '    sum_exclude_dim1(const Tensor & to_sum,bool keepdim)', '    det_backward(const Tensor & grad,const Tensor & self,const Tensor & det)', '    eig_backward(const std::vector & grads,const Tensor & self,bool eigenvectors,const Tensor & lambda,const Tensor & v)', '    _fused_dropout_backward(Tensor grad,Tensor mask,double p1m)', '    _safe_size(IntArrayRef sizes,IntArrayRef dim)', '    _sparse_addmm_sparse_backward(const Tensor & grad,const Tensor & sparse_,const Tensor & dense,const Scalar & alpha)', '    as_strided_backward(Tensor grad,TensorGeometry input_geometry,IntArrayRef sizes,IntArrayRef strides,optional storage_offset_)', '    atan2_backward(const Tensor & grad,const Tensor & self,const Tensor & other,std::array output_mask)', '    binary_cross_entropy_double_backward(const Tensor & grad_output,const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_with_logits_target_backward(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    cat_tensors_backward(const Tensor & grad,const std::vector,int64_t dim)', '    cholesky_backward(Tensor grad,bool upper,Tensor L)', '    cholesky_inverse_backward(Tensor grad,Tensor L,bool upper,Tensor inverse)', '    clamp_backward(const Tensor & grad,const Tensor & self,const optional & min,const optional & max)', '    copy_range(variable_list & out,IndexRange range,const Tensor & t)', '    copy_range(variable_list & out,IndexRange range,at::ArrayRef)', '    cummax_backward(const Tensor & indices,const Tensor & grad,const Tensor & input,int64_t dim)', '    cummin_backward(const Tensor & indices,const Tensor & grad,const Tensor & input,int64_t dim)', '    cumprod_backward(const Tensor & grad,const Tensor & input,int64_t dim)', '    cumprod_backward(const Tensor & grad,const Tensor & input,int64_t dim,optional dtype)', '    cumsum_backward(const Tensor & x,int64_t dim)', '    diag_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t diagonal)', '    diagonal_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t offset,int64_t dim1,int64_t dim2)', '    glu_double_backward(const Tensor & grad,const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_double_backward_grad_output(const Tensor & grad,const Tensor & input,int64_t dim)', '    index_select_backward(Tensor grad,int64_t dim,Tensor indices,IntArrayRef sizes,bool keepdim)', '    infinitely_differentiable_gelu_backward(const Tensor & grad,const Tensor & self)', '    kl_div_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    kl_div_target_backward(Tensor grad_output,Tensor self,Tensor target,int64_t reduction)', '    l1_loss_double_backward_grad_output(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    log_sigmoid_double_backward(const Tensor & grad,const Tensor & input)', '    log_softmax_double_backward(const Tensor & grad,const Tensor & grad_output,int dim,const Tensor & output)', '    logsumexp_backward(Tensor grad,const Tensor & self,Tensor result,IntArrayRef dim,bool keepdim)', '    masked_scatter_backward(const Tensor & grad,const Tensor & mask,IntArrayRef sizes)', '    max_pool_double_backward(const Tensor & grad,const Tensor & indices,int dim)', '    maybe_multiply(const Tensor & t,const Scalar & s)', '    mean_backward(Tensor grad,const IntArrayRef sizes,IntArrayRef dim,bool keepdim)', '    mean_backward(Tensor grad,const IntArrayRef sizes,int numel)', '    mm_mat1_backward(const Tensor & grad,const Tensor & mat2,const Tensor & mat1,const Scalar & alpha)', '    mm_mat2_backward(const Tensor & grad,const Tensor & mat1,IntArrayRef sizes,IntArrayRef strides,const Scalar & alpha)', '    mse_loss_double_backward(const Tensor & grad,const Tensor & input,int64_t reduction)', '    mse_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mvlgamma_backward(Tensor grad,const Tensor & self,int64_t p)', '    norm_backward(const Tensor & grad,const Tensor & self,const optional & p_,const Tensor & norm)', '    norm_backward(Tensor grad,const Tensor & self,const optional & p_,Tensor norm,IntArrayRef dim,bool keepdim)', '    not_implemented(const char *name)', '    permute_backwards(const Tensor & grad,IntArrayRef fwd_dims)', '    pow_backward(Tensor grad,const Tensor & self,const Scalar & exponent_)', '    pow_backward_exponent(Tensor grad,const Tensor & self,const Tensor & exponent,Tensor result)', '    pow_backward_exponent(Tensor grad,const Scalar & base,const Tensor & exponent,Tensor result)', '    pow_backward_self(Tensor grad,const Tensor & self,const Tensor & exponent)', '    prelu_double_backward(const Tensor & grad_grad_input,const Tensor & grad_grad_weight,const Tensor & grad_out,const Tensor & input_,const Tensor & weight_)', '    prod_backward(const Tensor & grad,const Tensor & input,const Tensor & result)', '    prod_backward(Tensor grad,const Tensor & input,Tensor result,int64_t dim,bool keepdim)', '    prod_safe_zeros_backward(const Tensor & grad,const Tensor & inp,int64_t dim)', '    renorm_backward(const Tensor & grad,const Tensor & self,Scalar p,int64_t dim,Scalar maxnorm)', '    repeat_backward(Tensor grad,int64_t input_dims,IntArrayRef repeats)', '    reverse_dim(const Tensor & t,int64_t dim)', '    reverse_list(const IntArrayRef list)', '    select_backward(Tensor grad,IntArrayRef input_sizes,int64_t dim,int64_t index)', '    select_equals_backward(Tensor grad,const Tensor & input,const Tensor & value)', '    slice_backward(Tensor grad,IntArrayRef input_sizes,int64_t dim,int64_t start,int64_t end,int64_t step)', '    smooth_l1_loss_double_backward(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_double_backward(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_double_backward_grad_output(const Tensor & grad,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    softmax_double_backward(const Tensor & grad,const Tensor & grad_output,int dim,const Tensor & output)', '    softplus_double_backward(const Tensor & grad,const Tensor & input,Scalar beta,Scalar threshold)', '    solve_backward_A(const Tensor & grad,const Tensor & self,const Tensor & A,const Tensor & solution)', '    solve_backward_self(const Tensor & grad,const Tensor & self,const Tensor & A)', '    split_backward(const std::vector & grads,int64_t split_size,int64_t dim,IntArrayRef sizes,const at::TensorOptions & options)', '    split_with_sizes_backward(const std::vector & grads,IntArrayRef split_sizes,int64_t dim,IntArrayRef sizes,const at::TensorOptions & options)', '    std_backward(const Tensor & result,const Tensor & grad,const Tensor & self,bool unbiased)', '    std_backward(const Tensor & result,Tensor grad,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    sum_backward(const Tensor & grad,IntArrayRef sizes,IntArrayRef dims,bool keepdim)', '    sum_scan_exclusive(const Tensor & x,int64_t dim)', '    sum_tensorlist(TensorList tl)', '    trace_backward(const Tensor & grad,IntArrayRef sizes)', '    unbind_backward(const variable_list & grads,int64_t dim)', '    unfold_backward(const Tensor & grad,IntArrayRef input_sizes,int64_t dim,int64_t size,int64_t step)', '    unsqueeze_multiple(const Tensor & t,IntArrayRef dim,size_t n_dims)', '    unsqueeze_to(const Tensor & self,IntArrayRef sizes)', '    unsqueeze_to(const Tensor & self,int64_t dim,IntArrayRef sizes)', '    var_backward(const Tensor & grad,const Tensor & self,bool unbiased)', '    var_backward(Tensor grad,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_std_mean_backward(const variable_list & grads,const Tensor & self,const Tensor & r1,const Tensor & r2,IntArrayRef dim,bool unbiased,bool keepdim,bool is_std)', '    var_std_mean_backward(const variable_list & grads,const Tensor & self,const Tensor & r1,const Tensor & r2,bool unbiased,bool is_std)', '    logdet_backward(const Tensor & grad,const Tensor & self,const Tensor & logdet)', '    qr_backward(const std::vector & grads,const Tensor & self,bool some,const Tensor & Q,const Tensor & R)', '    slogdet_backward(const Tensor & grad_logabsdet,const Tensor & self,const Tensor & signdet,const Tensor & logabsdet)', '    svd_backward(const std::vector & grads,const Tensor & self,bool some,bool compute_uv,const Tensor & raw_u,const Tensor & sigma,const Tensor & raw_v)', '    symeig_backward(const std::vector & grads,const Tensor & self,bool eigenvectors,bool upper,const Tensor & lambda,const Tensor & v)', '    triangular_solve_backward(const Tensor & grad_x,const Tensor & grad_m,const Tensor & b,const Tensor & a,const Tensor & x,const bool upper,const bool transpose,const bool unitriangular,std::array output_mask)', '    cholesky_solve_backward(const Tensor & grad_x,const Tensor & self,const Tensor & input2,const Tensor & result,const bool upper)', '    unsqueeze_dim1(const Tensor & src,const Tensor & target)', '    range(size_t range_size)', '    size'];
mpi_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/mpi; 337;  10; 101;6;  221; 0;164;136;100;84;0.05;7;[];['    Tensor', '    Tensor', '    optional', '    optional(c10::in_place,)', '    optional(dummyTensor)', '    optional(c10::nullopt)', '    optional', '    optional', '    $', '    unpack_list(at::ArrayRef xs)', '    Scalar', '    options', '    sizes', '    TypeAndSize', '    TypeAndSize(const Tensor & t)', '    zeros'];
mpi_ops.cc;C++;pytorch-master/pytorch-master/caffe2/mpi; 33;  1; 4;1;  28; 0;26;28;7;43;0.04;14;[];['    $', '    $', '    from_blob(void *data,IntArrayRef sizes,const std::function & deleter,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,IntArrayRef strides,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,const TensorOptions & options)', '    from_blob(void *data,IntArrayRef sizes,IntArrayRef strides,const std::function & deleter,const TensorOptions & options)', '    numel(const Tensor & tensor)'];
mpi_ops.h;C++;pytorch-master/pytorch-master/caffe2/mpi; 248;  14; 24;6;  206; 0;60;82;194;224;0.07;18;[];[];
mpi_test.cc;C++;pytorch-master/pytorch-master/caffe2/mpi; 315;  10; 87;5;  214; 0;164;129;100;77;0.05;7;['    GetFunHashGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFunHash', '    CAFFE_ANONYMOUS_VARIABLE_CPUFunHashGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FunHash', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FunHashGradient', '    vector', '    GetGradientDefs'];
operator_attaching_net_observer.h;C++;pytorch-master/pytorch-master/caffe2/observers; 31;  2; 5;4;  21; 0;6;14;3;9;0.10;2;['    FunHashGradientOp', '    FunHashOp'];['    FunHashGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    FunHashOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
profile_observer.cc;C++;pytorch-master/pytorch-master/caffe2/observers; 82;  16; 10;2;  55; 0;30;25;28;29;0.29;3;[];['    FuseLinear(std::shared_ptr & graph)'];
runcnt_observer.cc;C++;pytorch-master/pytorch-master/caffe2/observers; 38;  1; 8;4;  23; 3;3;14;5;15;0.04;6;[];['    FuseLinear(std::shared_ptr & graph)'];
runcnt_observer.h;C++;pytorch-master/pytorch-master/caffe2/observers; 52;  1; 12;5;  35; 0;1;25;0;20;0.03;3;[];['    FloatToFused8BitRowwiseQuantized(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantized__base(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf__base(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat__base(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat__base(const std::uint8_t *input,int input_rows,int input_columns,float *output)'];
time_observer.cc;C++;pytorch-master/pytorch-master/caffe2/observers; 36;  1; 7;2;  27; 0;11;11;10;15;0.04;4;[];['    FloatToFused8BitRowwiseQuantized(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    FloatToFused8BitRowwiseQuantizedSBHalf(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedSBHalfToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)', '    Fused8BitRowwiseQuantizedToFloat(const std::uint8_t *input,int input_rows,int input_columns,float *output)'];
time_observer_test.cc;C++;pytorch-master/pytorch-master/caffe2/observers; 72;  3; 9;8;  55; 0;34;21;39;24;0.05;6;[];['    FloatToFused8BitRowwiseQuantized__avx2_fma(const float *input,int input_rows,int input_columns,std::uint8_t *output)', '    Fused8BitRowwiseQuantizedToFloat__avx2_fma(const std::uint8_t *input,int input_rows,int input_columns,float *output)'];
backend.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 1871;  123; 184;26;  1540; 4;1051;607;675;487;0.08;69;[];['    Fused8BitRowwiseEmbeddingLookupGenericSlow(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,bool normalize_by_lengths,OutType *out)', '    Fused8BitRowwiseEmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int32_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookup_int64_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int *lengths,const float *weights,bool normalize_by_lengths,float *out)'];
backend.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 274;  17; 65;10;  184; 0;28;138;23;93;0.09;9;[];['    Fused8BitRowwiseEmbeddingLookup(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int *lengths,const float *weights,bool normalize_by_lengths,OutType *out)'];
backend_rep.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 48;  0; 7;6;  35; 0;7;20;6;16;0.00;7;[];['    Fused8BitRowwiseEmbeddingLookupGenericSlowIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,OutType *out)', '    Fused8BitRowwiseEmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int32_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int32_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)', '    Fused8BitRowwiseEmbeddingLookupIdx_int64_t_uint8_t_float_false__base(const int64_t block_size,const int64_t output_size,const int64_t index_size,const int64_t data_size,const uint8_t *input,const int64_t *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,float *out)'];
device.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 18;  0; 4;3;  11; 0;7;9;1;6;0.00;1;[];['    Fused8BitRowwiseEmbeddingLookupIdx(const std::int64_t block_size,const std::int64_t output_size,const std::int64_t index_size,const std::int64_t data_size,const InType *input,const IndexType *indices,const int64_t *offsets,const float *weights,bool normalize_by_lengths,OutType *out)'];
device.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 24;  1; 6;3;  15; 0;3;11;1;11;0.07;2;[];['    ceilDiv(const int a,const int b)', '    createFusionKernel(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    getMajorMinor(const cudaDeviceProp *const prop,int & major,int & minor)', '    nvrtc', '    FusedKernelCUDA(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    ~FusedKernelCUDA'];
helper.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 117;  3; 18;6;  92; 0;33;49;31;27;0.03;9;[];['    createFusionKernel(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    disas(const std::string & so_file)', '    getArchFlags', '    getConfig', '    getTempPath', '    programExists(const std::string & program)', '    runCompiler(const std::string & cpp_file,const std::string & so_file)', '    activate', '    exec(const std::string & cmd)', '    rtrim(std::string & s,const char *t)', '    run(const std::string & cmd)', '    CompilerConfig', '    FusedKernelCPU(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)'];
offline_tensor.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 91;  7; 14;3;  71; 0;45;34;29;24;0.10;6;[];['    backend', '    FusedKernelCUDA(int16_t device,std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    ~FusedKernelCUDA'];
offline_tensor.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 53;  6; 5;6;  41; 0;7;30;5;14;0.15;6;[];['    backend', '    chunkDesc', '    code', '    concatDesc', '    FusedKernel(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    FusedKernel', '    hasRandom', '    inputDesc', '    launch_raw(const uint32_t numel,std::vector & arguments)', '    name', '    operator=', '    outputDesc', '    ~FusedKernel'];
onnx_exporter.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 138;  10; 29;9;  93; 0;10;76;10;42;0.11;1;[];['    data', '    backend', '    FusedKernelCPU(std::string name,std::string code,std::vector input_desc,std::vector output_desc,std::vector chunk_desc,std::vector concat_desc,bool has_random)', '    launch_raw(const uint32_t numel,std::vector & arguments)'];
onnxifi_graph_info.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 55;  7; 6;2;  42; 0;20;15;20;11;0.17;4;[];['    bit_rate', '    bit_rate', '    bit_rate', '    bit_rate', '    TEST(OperatorSchemaTest,TensorInferenceNbit)', '    TEST(OperatorSchemaTest,TensorInferenceNbitHalf)', '    TEST(OperatorSchemaTest,TensorInferenceNbitBack)', '    TEST(OperatorSchemaTest,TensorInferenceNbitHalfBack)'];
onnxifi_graph_info.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 114;  10; 16;8;  82; 0;32;41;28;31;0.12;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused8BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedHalfScaleBiasToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedHalfScaleBiasToHalfFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused8BitRowwiseQuantizedToHalfFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfFloatToFused8BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused8BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused8BitRowwiseQuantizedHalfScaleBias', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedHalfScaleBiasToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedHalfScaleBiasToHalfFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused8BitRowwiseQuantizedToHalfFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfFloatToFused8BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfFloatToFused8BitRowwiseQuantizedHalfScaleBias', '    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp16(at::Half *dst,const float *src,size_t N)'];
onnxifi_init.h;C++;pytorch-master/pytorch-master/caffe2/onnx; 10;  2; 3;2;  5; 0;0;5;0;3;0.40;0;['    FloatToFused8BitRowwiseQuantizedOp', '    Fused8BitRowwiseQuantizedToFloatOp'];['    schema_Fused8BitRowwiseQuantizedToFloat', '    convert(tmp,input_data,input_columns)', '    convert(output_data,tmp,output_columns)', '    FloatToFused8BitRowwiseQuantizedOp(Args,...)', '    RunOnDevice', '    ~FloatToFused8BitRowwiseQuantizedOp', '    Fused8BitRowwiseQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~Fused8BitRowwiseQuantizedToFloatOp'];
ssa_test.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 82;  0; 5;7;  70; 0;60;10;56;10;0.00;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused2BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused4BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused2BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused2BitRowwiseQuantizedToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused4BitRowwiseQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUFused4BitRowwiseQuantizedToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused2BitRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused4BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused2BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused4BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused2BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused2BitRowwiseQuantizedToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused4BitRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fused4BitRowwiseQuantizedToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused2BitRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused4BitRowwiseQuantized', '    convertfp32fp16(at::Half *dst,const float *src,size_t N)'];
constants.h;C++;pytorch-master/pytorch-master/caffe2/onnx/torch_ops; 7;  1; 2;0;  5; 0;3;5;0;4;0.20;0;['    final', '    final'];['    convert(tmp,input_data,input_columns)', '    convert(output_data,tmp,output_columns)', '    FloatToFusedNBitRowwiseQuantizedOp(const OperatorDef & def,Workspace *ws)', '    FusedNBitRowwiseQuantizedToFloatOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~FloatToFusedNBitRowwiseQuantizedOp', '    ~FusedNBitRowwiseQuantizedToFloatOp'];
operator_sets.h;C++;pytorch-master/pytorch-master/caffe2/onnx/torch_ops; 46;  2; 6;2;  37; 0;17;16;9;12;0.05;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused2BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFused4BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused2BitFakeRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFused4BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused2BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFused4BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused2BitFakeRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFused4BitFakeRowwiseQuantized', '    compress_uniform_simplified_(const float *X,int N,float xmin,float xmax,float *Xq,int bit_rate)', '    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp32(float *dst,const float *src,size_t N)', '    param_search_greedy(const float *X,int N,const int n_bins,const float ratio,float & Xmin,float & Xmax,int bit_rate)'];
schema.cc;C++;pytorch-master/pytorch-master/caffe2/onnx/torch_ops; 17;  1; 1;2;  14; 0;5;5;3;5;0.07;2;['    final'];['    convertfp16fp32(float *dst,const at::Half *src,size_t N)', '    convertfp32fp32(float *dst,const float *src,size_t N)', '    is_little_endian', '    param_search_greedy(const float *X,int N,const int n_bins,const float ratio,float & Xmin,float & Xmax,int bit_rate)', '    convert(tmp,input_data,input_columns)', '    FloatToFusedNBitFakeRowwiseQuantizedOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    ~FloatToFusedNBitFakeRowwiseQuantizedOp', '    lrintf'];
schema.h;C++;pytorch-master/pytorch-master/caffe2/onnx/torch_ops; 8;  0; 2;6;  0; 0;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToFusedRandRowwiseQuantized', '    CAFFE_ANONYMOUS_VARIABLE_CPUFusedRandRowwiseQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToFusedRandRowwiseQuantized', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FusedRandRowwiseQuantizedToFloat', '    RunOnDevice', '    RunOnDevice'];
abs_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;['    FloatToFusedRandRowwiseQuantizedOp', '    FusedRandRowwiseQuantizedToFloatOp'];['    bitwidth_', '    FloatToFusedRandRowwiseQuantizedOp(Args,...)', '    random_', '    RunOnDevice', '    ~FloatToFusedRandRowwiseQuantizedOp', '    FusedRandRowwiseQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~FusedRandRowwiseQuantizedToFloatOp', '    now'];
accumulate_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 29;  1; 12;1;  16; 0;13;16;1;9;0.06;2;['    FuseConvBN'];['    fuseConvBN(nom::repr::NNModule *nn,caffe2::Workspace *ws)', '    fuseConvBNHelper(repr::NNModule *nn,caffe2::Workspace *ws)', '    run'];
accumulate_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 41;  3; 8;6;  26; 0;10;13;19;30;0.12;2;[];['    fuseActivation(repr::NNModule *nn,std::function should_fuse,std::function postprocess)', '    fuseConvBN(repr::NNModule *nn,caffe2::Workspace *ws)', '    get', '    getConsumers', '    getInputs', '    getOutputs'];
accuracy_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 27;  2; 7;5;  15; 0;0;11;17;29;0.13;1;['    final', '    final'];['    addCallback(const Callback & callback)', '    completed', '    completed_', '    error', '    hasError', '    markCompleted(T value)', '    setError(std::string errorMsg)', '    setErrorIfNeeded(std::string errorMsg)', '    setErrorInternal(std::string errorMsg,std::unique_lock & lock)', '    swap', '    Future', '    Future(T)', '    FutureError(std::string errorMsg)', '    FutureError', '    lock(mutex_)', '    wait', '    waitNoThrow', '    what'];
acos_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 74;  4; 12;4;  58; 0;28;41;8;24;0.07;7;[];['    glu(const Tensor & self,int64_t dim)', '    glu_backward(const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,int64_t dim)', '    glu_out(Tensor & result,const Tensor & self,int64_t dim)'];
acos_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherFused8BitRowwise'];
affine_channel_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 191;  3; 22;3;  166; 0;99;107;26;78;0.02;9;['    GatherFused8BitRowwiseOp'];['    DoRunWithType', '    GatherFused8BitRowwiseOp(Args,...)', '    Input', '    RunOnDevice', '    ~GatherFused8BitRowwiseOp'];
affine_channel_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 123;  2; 19;8;  96; 0;46;46;56;80;0.02;6;['    GetGatherGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Gather', '    vector', '    GetGradientDefs', '    vector'];
alias_with_name.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 25;  1; 6;1;  18; 0;13;15;2;13;0.06;3;['    GatherOp'];['    calc_output_shape_vector(const DataDimsVec & data_dims,const IndexDimsVec & indices_dims,int axis,bool match_outer)', '    check_indexarray_range(const IndexType *indices,int64_t n,IndexType indexing_axis_dim,bool wrap_indices)', '    gather_impl(Operator *op,int dataIdx,int indicesIdx,int outputIdx,int axis,bool wrap_indices,bool match_outer)', '    DoRunWithType', '    GatherOp(Args,...)', '    RunOnDevice', '    ~GatherOp', '    dim', '    raw_data', '    size', '    size_from_dim', '    size_to_dim', '    getContext', '    Input', '    Output'];
apmeter_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 130;  11; 21;1;  99; 0;57;70;19;80;0.11;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherRangesToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherRangesToDense'];
apmeter_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  6; 10;5;  23; 0;1;17;18;34;0.26;1;['    final'];['    outputDims', '    debug_def', '    DoRunWithType', '    GatherRangesToDenseOp(Args,...)', '    GetRepeatedArgument', '    GetSingleArgument', '    has_debug_def', '    Input', '    RunOnDevice', '    ~GatherRangesToDenseOp'];
arg_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 246;  3; 116;3;  127; 0;75;99;28;36;0.02;8;['    GAvgPoolMicrokernelTester'];['    iterations(size_t iterations)', '    iterations', '    iterations_', '    m(size_t m)', '    m', '    m_', '    n(size_t n)', '    n', '    n_', '    nr(size_t nr)', '    nr', '    nr_', '    packedN', '    test(pytorch_q8gavgpool_up_ukernel_function q8gavgpool)', '    test(pytorch_q8gavgpool_mp_ukernel_function q8gavgpool)', '    xScale(float xScale)', '    xScale', '    xScale_', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    xZeroPoint(uint8_t xZeroPoint)', '    xZeroPoint', '    xZeroPoint_', '    yMax(uint8_t yMax)', '    yMax', '    yMax_', '    yMin(uint8_t yMin)', '    yMin', '    yMin_', '    yScale(float yScale)', '    yScale', '    yScale_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_'];
asin_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 74;  4; 12;4;  58; 0;28;41;8;24;0.07;7;['    GetGeluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUGeluGradient', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Gelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GeluGradient', '    CostInferenceForGelu(const OperatorDef & def,const vector & in)', '    operator()(const int N,const T *X,T *Y,CPUContext *context)', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *X,T *dX,CPUContext *context)', '    GetGradientDefs', '    vector'];
asin_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    schema_Gelu', '    GeluFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)', '    GeluGradientFunctor(OperatorBase & op)'];
assert_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  1; 44;1;  20; 0;18;20;1;7;0.05;2;['    GemmMicrokernelTester'];['    q8gemm_compute_row_sum(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *row_sum,pytorch_q8sum_rows_ukernel_function q8sum_rows)', '    aStride(size_t aStride)', '    aStride', '    aStride_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    biasN', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    cStride(size_t cStride)', '    cStride', '    cStride_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    k(size_t k)', '    k', '    k_', '    kr(size_t kr)', '    kr', '    kr_', '    ks(size_t ks)', '    ks', '    ks_', '    m(size_t m)', '    m', '    m_', '    mr(size_t mr)', '    mr', '    mr_', '    multiplier(const float multiplier)', '    multiplier', '    multiplier_', '    n(size_t n)', '    n', '    n_', '    np(size_t np)', '    np', '    np_', '    nr(size_t nr)', '    nr', '    nr_', '    packedK', '    packedN', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_q8gemm_ukernel_function qgemm)', '    test(pytorch_q8gemm_dq_ukernel_function qgemm)', '    test(pytorch_q8conv_ukernel_function qconv)', '    test(pytorch_q8gemm_xzp_ukernel_function qgemm)', '    test(pytorch_hgemm_ukernel_function hgemm)', '    test(pytorch_sgemm_ukernel_function sgemm)', '    test(pytorch_sconv_ukernel_function sconv)', '    aZeroPoint', '    bZeroPoint', '    multiplier', '    shuffle'];
atan_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 74;  4; 12;4;  58; 0;28;41;8;24;0.07;7;[];['    pytorch_qnnp_requantize_gemmlowp__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
atan_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];[];
atomic_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 175;  3; 31;10;  131; 5;82;93;25;76;0.02;19;[];[];
batch_box_cox_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 94;  3; 11;9;  29; 45;1;23;18;31;0.10;2;[];['    pytorch_qnnp_requantize_gemmlowp__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
batch_bucketize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 126;  1; 48;3;  75; 0;64;58;46;43;0.01;3;[];['    gemmlowp_scalar_rdivbypo2_s32(int32_t x,int exponent)', '    gemmlowp_scalar_vqrdmulh_s32(int32_t a,int32_t b)'];
batch_bucketize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 30;  3; 9;6;  14; 0;0;10;17;29;0.21;1;[];['    gemmlowp_sse_mul_s32(__m128i a,__m128i b)', '    gemmlowp_sse_rdivbypo2_s32(__m128i x,int exponent)', '    gemmlowp_sse_vqrdmulh_s32(__m128i a,__m128i b)'];
batch_gather_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  11; 27;7;  126; 0;65;58;79;94;0.09;9;[];[];
batch_matmul_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 254;  9; 27;2;  217; 0;101;121;49;178;0.04;10;[];['    pytorch_qnnp_requantize_gemmlowp__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
batch_matmul_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 325;  2; 14;11;  300; 0;251;85;101;89;0.01;3;[];['    pytorch_qnnp_requantize_gemmlowp__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
batch_matmul_op_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 78;  2; 10;4;  64; 0;38;24;31;19;0.03;5;[];[];
batch_moments_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 122;  2; 15;5;  102; 0;48;64;33;45;0.02;9;[];['    pytorch_qnnp_requantize_gemmlowp__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
batch_moments_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 118;  2; 18;6;  94; 0;32;74;46;85;0.02;4;[];[];
batch_permutation_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 37;  2; 9;8;  20; 0;0;14;34;56;0.10;2;[];['    bbox_weights', '    CAFFE_ANONYMOUS_VARIABLE_CPUGenerateProposals', '    CAFFE_ANONYMOUS_VARIABLE_CPUGenerateProposalsCPP', '    schema_OperatorName', '    schema_OperatorName', '    ComputeStartIndex(const TensorCPU & tensor,const std::vector & index)', '    GetSubTensorView(const TensorCPU & tensor,int dim0_start_index)', '    ComputeAllAnchors(const TensorCPU & anchors,int height,int width,float feat_stride)', '    ComputeSortedAnchors(const Eigen::Map & anchors,int height,int width,float feat_stride,const vector & order)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GenerateProposals', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GenerateProposalsCPP', '    ProposalsForOneImage(const Eigen::Array3f & im_info,const Eigen::Map & anchors,const utils::ConstTensorView & bbox_deltas_tensor,const utils::ConstTensorView & scores_tensor,ERArrXXf *out_boxes,EArrXf *out_probs)'];
batch_permutation_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 269;  23; 40;6;  202; 0;110;100;80;52;0.11;15;['    final', '    ConstTensorView'];['    schema_GenerateProposals', '    ComputeAllAnchors(const TensorCPU & anchors,int height,int width,float feat_stride)', '    ComputeSortedAnchors(const Eigen::Map & anchors,int height,int width,float feat_stride,const vector & order)', '    angle_bound_hi_', '    angle_bound_lo_', '    angle_bound_on_', '    clip_angle_thresh_', '    dev_boxes_', '    dev_boxes_keep_flags_', '    dev_conv_layer_indexes_', '    dev_cub_select_buffer_', '    dev_cub_sort_buffer_', '    dev_image_boxes_keep_list_', '    dev_image_offset_', '    dev_image_prenms_boxes_', '    dev_image_prenms_scores_', '    dev_nms_mask_', '    dev_postnms_rois_', '    dev_postnms_rois_probs_', '    dev_prenms_nboxes_', '    dev_sorted_conv_layer_indexes_', '    dev_sorted_scores_', '    feat_stride_', '    GenerateProposalsOp(Args,...)', '    host_nms_mask_', '    host_prenms_nboxes_', '    legacy_plus_one_', '    ProposalsForOneImage(const Eigen::Array3f & im_info,const Eigen::Map & anchors,const utils::ConstTensorView & bbox_deltas_tensor,const utils::ConstTensorView & scores_tensor,ERArrXXf *out_boxes,EArrXf *out_probs)', '    rpn_min_size_', '    rpn_nms_thresh_', '    rpn_post_nms_topN_', '    rpn_pre_nms_topN_', '    RunOnDevice', '    spatial_scale_', '    ~GenerateProposalsOp', '    ConstTensorView(const T *data,const std::vector & dims)', '    data', '    dim(int i)', '    dims', '    ndim', '    size'];
batch_sparse_to_dense_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 204;  5; 60;1;  143; 0;87;107;34;44;0.03;10;[];['    AddLinSpacedInput(const vector & shape,const float min_val,const float max_val,const string & name,Workspace *ws)', '    anchors', '    bbx', '    AddConstInput(const vector & shape,const float value,const string & name,Context *context,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    scores', '    TEST(GenerateProposalsTest,TestRealDownSampledGPU)', '    im_info', '    rois', '    rois_probs', '    rois_probs_gt'];
bbox_transform_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 228;  10; 24;2;  194; 0;145;122;67;68;0.05;5;[];['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddLinSpacedInput(const vector & shape,const float min_val,const float max_val,const string & name,Workspace *ws)', '    anchors', '    angles', '    angles', '    bbx', '    TEST(GenerateProposalsTest,TestComputeAllAnchors)', '    TEST(GenerateProposalsTest,TestComputeSortedAnchors)', '    TEST(GenerateProposalsTest,TestComputeAllAnchorsRotated)', '    TEST(GenerateProposalsTest,TestComputeSortedAnchorsRotated)', '    TEST(GenerateProposalsTest,TestEmpty)', '    TEST(GenerateProposalsTest,TestRealDownSampled)', '    im_info', '    rois_probs_gt', '    scores', '    TEST(GenerateProposalsTest,TestRealDownSampledRotatedAngle0)', '    TEST(GenerateProposalsTest,TestRealDownSampledRotated)'];
bbox_transform_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 73;  16; 9;8;  42; 0;8;34;21;40;0.38;8;[];['    bbox_ctrwh_to_xyxy(const Eigen::ArrayBase & boxes,const bool legacy_plus_one)', '    bbox_transform(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool legacy_plus_one,const bool angle_bound_on,const int angle_bound_lo,const int angle_bound_hi)', '    bbox_transform_rotated(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool angle_bound_on,const int angle_bound_lo,const int angle_bound_hi)', '    bbox_transform_upright(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & deltas,const std::vector & weights,const float bbox_xform_clip,const bool legacy_plus_one)', '    bbox_xyxy_to_ctrwh(const Eigen::ArrayBase & boxes,bool legacy_plus_one)', '    clip_boxes(const Eigen::ArrayBase & boxes,int height,int width,float angle_thresh,bool legacy_plus_one)', '    clip_boxes_rotated(const Eigen::ArrayBase & boxes,int height,int width,float angle_thresh,bool legacy_plus_one)', '    clip_boxes_upright(const Eigen::ArrayBase & boxes,int height,int width,bool legacy_plus_one)', '    filter_boxes(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info,const bool legacy_plus_one)', '    filter_boxes_rotated(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info)', '    filter_boxes_upright(const Eigen::ArrayBase & boxes,double min_size,const Eigen::Array3f & im_info,const bool legacy_plus_one)', '    col', '    Zero'];
bisect_percentile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 92;  1; 45;1;  46; 0;43;46;1;9;0.02;2;[];['    TEST(UtilsBoxesTest,TestBboxTransformRandom)', '    TEST(UtilsBoxesTest,TestBboxTransformRotated)', '    TEST(UtilsBoxesTest,TestBboxTransformRotatedNormalized)', '    TEST(UtilsBoxesTest,ClipRotatedBoxes)'];
boolean_mask_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 631;  36; 159;3;  445; 0;296;236;152;176;0.08;30;['    RotatedRect'];['    bbox_intersection_rotated(const Eigen::ArrayBase & box1,const Eigen::ArrayBase & box2)', '    bbox_overlaps_rotated(const Eigen::ArrayBase & boxes,const Eigen::ArrayBase & query_boxes)', '    bbox_to_rotated_rect(const Eigen::ArrayBase & box)', '    convex_hull_graham(const Eigen::Vector2f *p,const int & num_in,Eigen::Vector2f *q,bool shift_to_zero)', '    cross_2d(const Eigen::Vector2f & A,const Eigen::Vector2f & B)', '    nms_cpu_upright(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN,bool legacy_plus_one)', '    rotated_rect_intersection_pts(const RotatedRect & rect1,const RotatedRect & rect2,Eigen::Vector2f *intersections,int & num)', '    soft_nms_cpu_upright(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    nms_cpu(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN,bool legacy_plus_one)', '    nms_cpu(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,float thres,bool legacy_plus_one)', '    nms_cpu_rotated(const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & sorted_indices,float thresh,int topN)', '    polygon_area(const Eigen::Vector2f *q,const int & m)', '    rotated_rect_intersection(const RotatedRect & rect1,const RotatedRect & rect2)', '    soft_nms_cpu(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    soft_nms_cpu(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN,bool legacy_plus_one)', '    soft_nms_cpu_rotated(Eigen::ArrayBase *out_scores,const Eigen::ArrayBase & proposals,const Eigen::ArrayBase & scores,const std::vector & indices,float sigma,float overlap_thresh,float score_thresh,unsigned int method,int topN)', '    get_vertices(Eigen::Vector2f *pt)', '    RotatedRect', '    RotatedRect(const Eigen::Vector2f & p_center,const Eigen::Vector2f & p_size,float p_angle)'];
boolean_mask_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 91;  7; 14;7;  64; 0;11;35;63;88;0.11;4;[];['    nms_gpu(const float *d_desc_sorted_boxes,const int N,const float thresh,const bool legacy_plus_one,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context,const int box_dim)', '    nms_gpu_rotated(const float *d_desc_sorted_boxes,const int N,const float thresh,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context)', '    nms_gpu_upright(const float *d_desc_sorted_boxes,const int N,const float thresh,const bool legacy_plus_one,int *d_keep_sorted_list,int *h_nkeep,TensorCUDA & dev_delete_mask,TensorCPU & host_delete_mask,CUDAContext *context)'];
boolean_unmask_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 156;  1; 82;3;  70; 0;53;52;36;37;0.01;3;[];['    generateRandomBoxes(float *h_boxes,float *h_scores,const int nboxes)', '    generateRandomRotatedBoxes(float *h_boxes,float *h_scores,const int nboxes)', '    TEST(UtilsNMSTest,TestNMSGPU)', '    TEST(UtilsNMSTest,TestPerfNMS)', '    TEST(UtilsNMSTest,GPUEqualsCPUCorrectnessTest)', '    TEST(UtilsNMSTest,TestNMSGPURotatedAngle0)', '    TEST(UtilsNMSTest,TestPerfRotatedNMS)', '    dev_boxes', '    dev_boxes', '    dev_boxes', '    dev_boxes_valid_flags', '    dev_boxes_valid_flags', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_delete_mask', '    dev_list', '    dev_list', '    dev_list', '    dev_list', '    dev_list', '    dev_list_nitems', '    dev_list_nitems', '    dev_scores', '    dev_scores', '    dev_sorted_boxes', '    dev_sorted_boxes', '    host_boxes', '    host_boxes', '    host_boxes', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_delete_mask', '    host_list', '    host_list', '    host_scores', '    host_scores', '    host_scores', '    input_thresh', '    input_thresh', '    vector', '    vector'];
boolean_unmask_ops_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 70;  8; 15;5;  43; 0;29;16;23;10;0.19;2;[];['    TEST(UtilsNMSTest,TestNMS)', '    TEST(UtilsNMSTest,TestNMS1)', '    TEST(UtilsNMSTest,TestSoftNMS)', '    TEST(UtilsNMSTest,TestNMSRotatedAngle0)', '    TEST(UtilsNMSTest,TestSoftNMSRotatedAngle0)', '    TEST(UtilsNMSTest,RotatedBBoxOverlaps)', '    input_thresh', '    input_thresh', '    keep_gt', '    keep_gt', '    method', '    method', '    output_gt', '    overlap_thresh', '    overlap_thresh', '    vector', '    vector'];
box_with_nms_limit_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 366;  21; 39;3;  306; 0;226;114;127;89;0.07;6;[];[];
box_with_nms_limit_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 118;  30; 12;6;  73; 0;24;53;28;47;0.41;10;[];['    THPGenerator_dealloc(THPGenerator *self)', '    THPGenerator_get_device(THPGenerator *self,void *unused)', '    THPGenerator_getState(THPGenerator *self,PyObject *noargs)', '    THPGenerator_initialSeed(THPGenerator *self,PyObject *noargs)', '    THPGenerator_manualSeed(THPGenerator *self,PyObject *seed)', '    THPGenerator_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPGenerator_seed(THPGenerator *self,PyObject *noargs)', '    THPGenerator_setState(THPGenerator *self,PyObject *_new_state)', '    pyobj(const Generator & self)', '    self', '    set_pyobj(const Generator & self,PyObject *pyobj)', '    THPGenerator_init(PyObject *module)', '    THPGenerator_initDefaultGenerator(at::Generator cdata)', '    THPGenerator_NewWithVar(PyTypeObject *type,Generator gen)', '    THPGenerator_Wrap(Generator gen)'];
bucketize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 50;  3; 12;8;  29; 0;8;14;23;35;0.10;2;[];['    make_generator(Args,...)', '    clone', '    defined', '    Generator', '    Generator(std::shared_ptr gen_impl)', '    Generator(std::nullptr_t gen_impl)', '    get', '    operator!=(const Generator & rhs)', '    operator->', '    operator==(const Generator & rhs)', '    make_shared', '    runtime_error'];
byte_weight_dequant_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 11;  1; 5;2;  4; 0;2;4;1;7;0.25;2;[];[];
byte_weight_dequant_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 55;  2; 9;6;  40; 0;18;20;34;39;0.05;2;[];[];
cast_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 55;  2; 11;8;  35; 0;13;22;24;41;0.06;3;[];['    getNonDeterministicRandom(bool is_cuda)', '    key_set_(key_set)', '    clone', '    device', '    GeneratorImpl(Device device_in,DispatchKeySet key_set)'];
cbrt_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 73;  4; 11;5;  57; 0;27;41;6;24;0.07;7;[];['    getNonDeterministicRandom(bool is_cuda)', '    clone', '    clone_impl', '    current_seed', '    device', '    GeneratorImpl(Device device_in,DispatchKeySet key_set)', '    GeneratorImpl', '    GeneratorImpl', '    key_set', '    operator=', '    pyobj', '    seed', '    set_current_seed(uint64_t seed)', '    set_pyobj(PyObject *pyobj)', '    ~GeneratorImpl'];
cbrt_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGFtrl', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GFtrl', '    gftrl_compute(const T & w,const T & n,const T & z,const T & g,T & nw,T & nn,T & nz,const T & z_norm,const int OutputDim,const GFtrlParams & params)', '    gftrl_update(int OutputDim,int InputDim,const T *w,const T *nz,const T *g,T *new_w,T *new_nz,const GFtrlParams & params,Context *)', '    RunOnDevice'];
cc_bmm_bg_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 143;  12; 17;9;  108; 0;59;39;52;65;0.11;2;['    final'];['    GFtrlOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    GFtrlParams(OperatorBase *op)'];
ceil_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 71;  2; 50;2;  18; 0;15;18;1;9;0.11;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorByteStringToUInt8Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorByteStringToUInt8Fill'];
ceil_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  2; 8;7;  18; 0;7;11;21;33;0.11;3;['    final'];['    Extract', '    Fill(Tensor *output)', '    GivenTensorByteStringToUInt8FillOp(const OperatorDef & operator_def,Workspace *ws)'];
channel_backprop_stats_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  1; 8;6;  19; 0;1;13;18;32;0.05;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorBoolFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorDoubleFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorInt16Fill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorInt64Fill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorIntFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUGivenTensorStringFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorBoolFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorDoubleFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorInt16Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorInt64Fill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorIntFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GivenTensorStringFill'];
channel_shuffle_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  5; 23;8;  138; 1;84;103;39;101;0.04;11;['    final'];['    ExtractValues', '    Fill(Tensor *output)', '    FillWithType(Tensor *output)', '    GivenTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    Make'];
channel_shuffle_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 68;  2; 16;6;  46; 0;6;30;44;65;0.04;4;['    GlobalAveragePoolingOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputMax(uint8_t outputMax)', '    outputMax', '    outputMax_', '    outputMin(uint8_t outputMin)', '    outputMin', '    outputMin_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    testQ8', '    width(size_t width)', '    width', '    width_'];
channel_stats_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 60;  2; 12;7;  41; 0;15;30;25;43;0.05;3;[];['    pytorch_qnnp_create_global_average_pooling_nwc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *global_average_pooling_out)', '    pytorch_qnnp_setup_global_average_pooling_nwc_q8(pytorch_qnnp_operator_t global_average_pooling_op,size_t batch_size,size_t width,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
clip_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 131;  1; 55;2;  74; 0;59;62;18;36;0.01;8;[];['    global_average_pooling_q8(benchmark::State & state)', '    ImageNetArguments(benchmark::internal::Benchmark *b)'];
clip_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 64;  3; 11;8;  44; 0;8;22;42;57;0.07;2;[];['    TEST(GLOBAL_AVERAGE_POOLING_OP,zero_batch)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_small_width_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_many_channels_large_width_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_input_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_scale)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_zero_point)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_min)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,unit_batch_few_channels_with_output_max)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_small_width_with_output_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_many_channels_large_width_with_output_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(GLOBAL_AVERAGE_POOLING_OP,small_batch_few_channels_with_output_stride)'];
collect_and_distribute_fpn_rpn_proposals_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 198;  35; 24;8;  134; 0;22;99;67;124;0.26;22;[];['    RegistryName', '    makeDeviceForHostname(const std::string & hostname)', '    makeDeviceForInterface(const std::string & interface)'];
communicator_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 203;  2; 27;2;  173; 0;160;173;11;89;0.01;22;['    GlooDeviceFactory'];['    RegistryName', '    makeDeviceForHostname(const std::string & hostname)', '    makeDeviceForInterface(const std::string & interface)'];
communicator_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 16;  2; 2;3;  10; 0;8;10;8;33;0.20;8;['    C10FlagParser_merge_fp32_inputs_into_fp16', '    C10FlagParser_onnxifi_adjust_batch', '    C10FlagParser_onnxifi_blacklist', '    C10FlagParser_onnxifi_blacklist_ops', '    C10FlagParser_onnxifi_debug_mode', '    C10FlagParser_onnxifi_input_output_observe_list', '    C10FlagParser_onnxifi_loop_test_mode', '    C10FlagParser_onnxifi_min_ops', '    C10FlagParser_onnxifi_shape_hints'];['    onnxifi(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const std::unordered_set & blacklist,const ShapeInfoMap & shape_hints,bool use_onnx,size_t max_batch_size,size_t max_seq_size,bool load_model_by_blob,bool predictor_net_ssa_rewritten)', '    ParseBlackListOps(const std::string & str)', '    ParseNetPositionList(const std::string & str)', '    C10FlagParser_merge_fp32_inputs_into_fp16(const std::string & content)', '    C10FlagParser_onnxifi_adjust_batch(const std::string & content)', '    C10FlagParser_onnxifi_blacklist(const std::string & content)', '    C10FlagParser_onnxifi_blacklist_ops(const std::string & content)', '    C10FlagParser_onnxifi_debug_mode(const std::string & content)', '    C10FlagParser_onnxifi_input_output_observe_list(const std::string & content)', '    C10FlagParser_onnxifi_loop_test_mode(const std::string & content)', '    C10FlagParser_onnxifi_min_ops(const std::string & content)', '    C10FlagParser_onnxifi_shape_hints(const std::string & content)'];
concat_split_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 336;  17; 23;8;  291; 0;0;0;0;0;0.06;0;[];['    onnxifi(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const std::unordered_set & blacklist,const ShapeInfoMap & shape_hints,bool use_onnx,size_t max_batch_size,size_t max_seq_size,bool load_model_by_blob,bool predictor_net_ssa_rewritten)', '    ParseBlackListOps(const std::string & str)', '    ParseNetPositionList(const std::string & str)'];
concat_split_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 13;  2; 3;2;  7; 0;5;7;5;21;0.29;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGlu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Glu', '    sigmoid(const float x)', '    ComputeGlu(const int M,const int split_dim,const int N,const float *Xdata,float *Ydata)'];
conditional_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  4; 12;3;  47; 0;38;31;30;27;0.09;3;['    final'];['    ComputeGlu(const int M,const int split_dim_size,const int N,const T *X,T *output)', '    GetSingleArgument', '    GluOp(Args,...)', '    RunOnDevice'];
conv_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 147;  3; 21;3;  121; 0;76;65;42;96;0.02;15;[];['    is_enabled', '    set_enabled(bool enabled)'];
conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 209;  43; 87;3;  77; 0;66;49;5;27;0.56;9;[];[];
conv_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 101;  10; 14;7;  72; 0;11;48;95;172;0.14;10;[];[];
conv_op_cache_cudnn.h;C++;pytorch-master/pytorch-master/caffe2/operators; 66;  12; 11;8;  37; 0;12;21;10;10;0.32;1;[];['    AddOp(NetDef *netdef_ptr,string op_type,std::vector inputs,std::vector outputs)', '    MatchArguments(const OperatorDef & p_op,const OperatorDef & g_op)', '    MatchStrings(string p,string s)', '    Graph(const NetDef & net)', '    DeactivateSubgraph(std::vector subgraph)', '    GetNetDef'];
conv_op_cache_cudnn_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  1; 15;5;  41; 0;29;25;13;15;0.02;6;['    Edge', '    Graph', '    Node', '    Subgraph'];['    Edge(NodeRef tail,NodeRef head,U,...)', '    head', '    setHead(NodeRef n)', '    setTail(NodeRef n)', '    tail', '    createEdge(NodeRef tail,NodeRef head,U,...)', '    createNode(T)', '    createNode(Arg)', '    createNode', '    createNodeInternal(Node)', '    deleteEdge(EdgeRef e)', '    deleteNode(NodeRef n)', '    deleteNodes(const std::unordered_set & nodes)', '    getEdge(NodeRef tail,NodeRef head)', '    getEdgeIfExists(NodeRef tail,NodeRef head)', '    getEdgesCount', '    getMutableEdges', '    getMutableNodes', '    getNodesCount', '    Graph', '    Graph', '    Graph', '    hasEdge(NodeRef tail,NodeRef head)', '    hasEdge(EdgeRef e)', '    hasNode(NodeRef node)', '    isValid', '    moveEdge(EdgeRef edge,Graph *destGraph)', '    moveNode(NodeRef node,Graph *destGraph)', '    moveSubgraph(const Subgraph & subgraph,Graph *destGraph)', '    operator=', '    printEdges', '    printNodes', '    replaceInEdges(const NodeRef & oldNode,const NodeRef & newNode)', '    replaceNode(const NodeRef & oldNode,const NodeRef & newNode)', '    replaceOutEdges(const NodeRef & oldNode,const NodeRef & newNode)', '    swapNodes(NodeRef n1,NodeRef n2)', '    ~Graph', '    addInEdge(EdgeRef e)', '    addOutEdge(EdgeRef e)', '    getInEdges', '    getOutEdges', '    Node(T)', '    Node', '    Node', '    Node', '    operator=', '    removeEdgeInternal(std::vector & edges,EdgeRef e)', '    removeInEdge(EdgeRef e)', '    removeOutEdge(EdgeRef e)', '    setInEdges(std::vector edges)', '    setOutEdges(std::vector edges)', '    addEdge(EdgeRef e)', '    addNode(NodeRef n)', '    getEdges', '    getNodes', '    getNodesCount', '    hasEdge(EdgeRef e)', '    hasNode(NodeRef n)', '    printEdges', '    printNodes', '    removeEdge(EdgeRef e)', '    removeNode(NodeRef n)', '    Subgraph'];
conv_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 1468;  91; 86;53;  1125; 137;494;375;515;868;0.08;15;[];['    AddOp(NetDef *netdef_ptr,string op_type,std::vector inputs,std::vector outputs)', '    MatchArguments(const OperatorDef & p_op,const OperatorDef & g_op)', '    MatchStrings(string p,string s)', '    DeactivateSubgraph(std::vector subgraph)', '    external_input', '    external_output', '    GetNetDef', '    Graph(const NetDef & net)', '    is_node_active(size_t idx)', '    node(size_t idx)', '    node(size_t idx)', '    push_node(const Node & new_node)', '    resize_nodes(size_t new_size)', '    size', '    Node', '    Node(const OperatorDef & op,bool active,std::map,std::vector,std::map,std::vector)'];
conv_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 4;3;  10; 0;8;10;8;33;0.10;8;[];['    mayIntroduceGradient(const Block *b)', '    unpackReturnTuple(Stack & stack)', '    getGradExecutor(Operation & op)', '    needsGradient(const std::shared_ptr & graph)', '    packGradient(const Gradient & gradient,Node *dnode)', '    runNondiffOptimization(std::shared_ptr & graph,bool strict_fuser_check)', '    runOptimization(std::shared_ptr & graph,bool unroll)', '    runRequiredPasses(const std::shared_ptr & g)', '    getGradient(const Node *n)', '    aliasAnalysisInternalSpecialCase', '    debugSetAutodiffSubgraphInlining(bool state)', '    getAutodiffSubgraphInlining', '    lastExecutedOptimizedGraph', '    getDebugState', '    getDefaultNumBailOuts', '    getPlanFor(Stack & inputs,size_t remaining_bailout_depth)', '    graph', '    GraphExecutor(std::shared_ptr graph,std::string function_name)', '    run(Stack & inputs)', '    compileSpec(const ArgumentSpec & spec)', '    getDebugState', '    getOrCompile(const Stack & stack)', '    getOrCompileFallback', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    GraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    run(Stack & stack)', '    addInputIValue(const IValue & v)', '    addInputVariable(Variable output)', '    addOutputForIValue(const IValue & value)', '    addOutputForTensor(const at::Tensor & tensor)', '    apply(variable_list)', '    capture(const IValue & val,bool is_output)', '    DifferentiableGraphBackward(GraphExecutor executor,size_t input_size,size_t capture_size)', '    produceOutput(size_t i,at::Tensor output,variable_list & outputs)', '    captureInputs(DifferentiableGraphBackward & grad_fn,at::ArrayRef inputs)', '    captureOutputs(DifferentiableGraphBackward & grad_fn,at::ArrayRef outputs)', '    detach(at::Tensor t)', '    detach(IValue & v)', '    detachVariables(Stack & stack)', '    DifferentiableGraphOp(Gradient grad)', '    operator()(Stack & stack)', '    capture(const IValue & val,bool is_output)', '    CaptureList(size_t capture_size)', '    captureTensor(const at::Tensor & tensor,bool is_output)', '    size', '    unpack(Stack & stack,const std::shared_ptr & saved_for)', '    pushTensor', '    pushTensorList(size_t size)', '    unpack(variable_list,Stack & stack)', '    UnpackInstructions(size_t num_inputs)'];
conv_op_impl.h;C++;pytorch-master/pytorch-master/caffe2/operators; 953;  58; 55;13;  831; 0;693;363;192;328;0.07;5;[];[];
conv_op_shared.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  0; 5;4;  25; 0;11;16;7;15;0.00;3;[];['    debugSetAutodiffSubgraphInlining(bool state)', '    getAutodiffSubgraphInlining', '    needsGradient(const std::shared_ptr & graph)', '    packGradient(const Gradient & gradient,Node *dnode)', '    runNondiffOptimization(std::shared_ptr & graph,bool strict_fuser_check)', '    runOptimization(std::shared_ptr & graph,bool unroll)', '    prepareGraph(const std::shared_ptr & graph)', '    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    GraphExecutorImplBase(const std::shared_ptr & graph,std::string function_name)', '    run(Stack & stack)', '    ~GraphExecutorImplBase'];
conv_op_shared_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 27;  0; 4;2;  21; 0;10;15;6;8;0.00;2;[];['    simple_mappable', '    CustomFuseGraph(std::shared_ptr & graph,std::function fn,Symbol kind,size_t arg_limit)', '    FuseGraph(std::shared_ptr & graph,bool strict_fuser_check)', '    insert_guard', '    insert_guard', '    insert_guard', '    PeepholeOptimizeShapeExpressions(Block *block)', '    broadcastSizes(at::ArrayRef sizes)', '    isSimpleMap(Node *node)', '    allUsersAreThisConsumerOrCalcSizes(Node *consumer,Value *producer)', '    broadcast_tensors(value_list inputs)', '    buildShapeExpressions(Node *fusion_group)', '    calculatesSize(Node *node)', '    canFuseChunk(Node *consumer,Value *producer)', '    canFuseWithConcat(Value *producer,Node *before_check)', '    createFusedConcat(Node *node)', '    createSingletonFusionGroup(Node *n)', '    findFusedChunk(Node *group,Value *input)', '    fuseChunk(Node *consumer,Value *producer)', '    fuseChunkByReusingExistingFusedChunk(Node *group,Node *chunk,Node *existingFusedChunk)', '    fuseConcats', '    getSubgraph(Node *n)', '    GraphFuser(Block *block,std::shared_ptr graph,FusionCallback callback,Symbol kind)', '    GraphFuser(Block *block,std::shared_ptr graph,bool strict_fuser_check)', '    insertExplicitBroadcast(Node *node)', '    isFusable(Node *node)', '    isFusableCatNode(Node *node)', '    isFusableDefault(Node *node,bool strict_fuser_check)', '    isFusableDevice(Value *v,bool strict_fuser_check)', '    isFusableMap(Node *node)', '    mergeFusionGroups(Node *consumer_group,Node *producer_group)', '    mergeNodeIntoGroup(Node *group,Node *n)', '    optimizeFusedGraphs', '    promoteChunkToBroadcastingChunk(Node *chunk)', '    refreshAliasDb', '    removeOutputsUsedOnlyInSize(Node *fusion_group)', '    replaceIntermediateBroadcastingChunks', '    run', '    scanNode(Node *consumer)', '    scanNodeForChunks(Node *consumer)', '    setInputArgLimit(size_t limit)', '    sortReverseTopological(ArrayRef inputs)', '    tensorInputs(Node *node)', '    tryFuse(Node *consumer,Value *producer)', '    tryToMoveChunk(Node *consumer,Value *producer)', '    usedOnlyInSize(Value *v)'];
conv_pool_op_base.h;C++;pytorch-master/pytorch-master/caffe2/operators; 899;  77; 68;37;  719; 0;462;209;411;182;0.11;35;[];['    CustomFuseGraph(std::shared_ptr & graph,std::function is_fusable,Symbol kind,size_t arg_limit)', '    FuseGraph(std::shared_ptr & graph,bool strict_fuser_check)'];
conv_transpose_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 50;  1; 6;2;  42; 0;16;16;8;48;0.02;8;[];[];
conv_transpose_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 57;  6; 10;6;  37; 0;1;25;69;127;0.16;2;[];['    getFuncName(Value *func_value)', '    getIValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    getValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    replaceConvolutionWithConv2d(std::shared_ptr & graph)'];
conv_transpose_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 818;  39; 48;31;  609; 93;265;186;373;463;0.06;9;[];['    getFuncName(Value *func_value)', '    getIValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    getValue(const std::string & name,const std::unordered_map & match_vmap,const std::unordered_map & vmap)', '    replaceConvolutionWithConv2d(std::shared_ptr & graph)'];
conv_transpose_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 10;  1; 1;3;  6; 0;2;4;2;9;0.17;2;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUGraphDummyOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GraphDummyOp3', '    compare_netdefs(const NetDef & net_a,const NetDef & net_b)', '    TEST(GraphTest,TestGenerateGraphChain)', '    TEST(GraphTest,TestGenerateGraphChainInPlace)', '    TEST(GraphTest,TestGenerateGraphBranch)', '    TEST(GraphTest,TestReusedInputs)', '    TEST(GraphTest,TestGetPerimeter)', '    Run(int)'];
conv_transpose_op_mobile.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 3;4;  2; 5;0;2;0;1;0.50;0;[];['    computeDedupRenameMap(const std::vector & nodes)', '    getNameForBlob(NNGraph::NodeRef node,const std::unordered_map & renameMap)', '    getNQLStringForBlob(NNGraph::NodeRef node,const std::unordered_map & renameMap)', '    convertToNQLString(NNGraph & g)', '    getNodeName(const NNGraph::NodeRef node)', '    deallocTokenStrings', '    testMatchPredicate(const Criteria & criteria)', '    getMatches(nom::repr::NNGraph & df)', '    genMatcherFromASTExpr(ASTExpr *expr,bool insertTemp)', '    genMatcherFromASTGraph(ASTGraph *ast)', '    genMatcherFromASTStmt(ASTStmt *stmt)', '    genMatcherFromIRFile(const char *fname)', '    genMatcherFromIRStr(const char *str)', '    operator[](const std::string & key)'];
conv_transpose_op_mobile.h;C++;pytorch-master/pytorch-master/caffe2/operators; 45;  2; 3;9;  0; 36;0;0;0;0;0.00;0;['    GraphMatcher'];['    deallocTokenStrings', '    getNodeName(const nom::repr::NNGraph::NodeRef)', '    testMatchPredicate(const Criteria & criteria)', '    doesMatch(nom::repr::NNGraph & df)', '    findSubgraph(nom::repr::NNGraph & df)', '    genMatcherFromASTExpr(ASTExpr *expr,bool insertTemp)', '    genMatcherFromASTGraph(ASTGraph *ast)', '    genMatcherFromASTStmt(ASTStmt *stmt)', '    genMatcherFromIRFile(const char *fname)', '    genMatcherFromIRStr(const char *str)', '    getMatcher', '    getMatcherGraph', '    getMatches(nom::repr::NNGraph & df)', '    getMatchMap', '    initFromFile(const char *fname)', '    initFromString(const char *str)', '    replaceSubgraphWith', '    operator[](const std::string & key)'];
conv_transpose_op_mobile_impl.h;C++;pytorch-master/pytorch-master/caffe2/operators; 701;  4; 3;65;  0; 690;0;0;0;0;0.00;0;[];['    genTensors(NNGraph & graph,std::vector names)', '    TEST(Basic,MatchSingleNode)', '    TEST(Basic,SyntaxError)', '    TEST(Basic,Diamond)', '    TEST(Basic,BadDiamond)', '    TEST(Basic,StarInputs)', '    TEST(Basic,StarOutputs)', '    TEST(Caffe2ToNQL,Basic)', '    TEST(Caffe2ToNQL,TensorsNameDeduplication)'];
conv_transpose_unpool_op_base.h;C++;pytorch-master/pytorch-master/caffe2/operators; 318;  15; 36;28;  243; 0;139;71;160;76;0.06;17;[];['    TEST(Basic,CreateNodeAndEdge)', '    TEST(Basic,DeleteNode)', '    TEST(Basic,DeleteEdge)', '    TEST(Basic,ReplaceEdges)', '    TEST(Basic,HasNode)', '    TEST(Basic,Moves)', '    TEST(Basic,MoveSubgraph)', '    TEST(Basic,DotGenerator)'];
copy_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 206;  2; 59;1;  145; 0;93;119;15;65;0.01;14;[];['    grid_sampler_2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_2d_cpu(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_backward_cpu_impl(const Tensor & grad_output,const Tensor & input,const Tensor & grid,GridSamplerInterpolation interpolation_mode,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler_3d_cpu(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_3d_cpu_impl(const Tensor & input,const Tensor & grid,GridSamplerInterpolation interpolation_mode,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)'];
copy_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 43;  2; 8;6;  29; 0;10;16;20;38;0.07;4;[];['    checkGridSize(CheckedFrom,TensorArg grid,TensorArg input)', '    cudnn_grid_sampler_backward(const Tensor & input_t,const Tensor & grid_t,const Tensor & grad_output_t)', '    cudnn_grid_sampler_forward(const Tensor & input_t,const Tensor & grid_t)', '    setSamplerDescriptor(SpatialTransformerDescriptor & desc,cudnnDataType_t dataType,const at::Tensor & tensor)', '    gdesc', '    idesc', '    idesc', '    input', '    input', '    odesc', '    odesc'];
copy_rows_to_tensor_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 82;  2; 10;6;  65; 0;32;34;62;77;0.03;6;['    GridSamplerInterpolation', '    GridSamplerPadding'];['    clip_coordinates(scalar_t in,int64_t clip_limit)', '    clip_coordinates_set_grad(scalar_t in,int64_t clip_limit,scalar_t *grad_in)', '    grid_sampler_compute_source_index(scalar_t coord,int64_t size,GridSamplerPadding padding_mode,bool align_corners)', '    grid_sampler_compute_source_index_set_grad(scalar_t coord,int64_t size,GridSamplerPadding padding_mode,bool align_corners,scalar_t *grad_in)', '    grid_sampler_unnormalize(scalar_t coord,int64_t size,bool align_corners)', '    grid_sampler_unnormalize_set_grad(scalar_t coord,int64_t size,bool align_corners,scalar_t *grad_in)', '    reflect_coordinates(scalar_t in,int64_t twice_low,int64_t twice_high)', '    reflect_coordinates_set_grad(scalar_t in,int64_t twice_low,int64_t twice_high,scalar_t *grad_in)', '    safe_add_2d(scalar_t *data,int64_t h,int64_t w,int64_t sH,int64_t sW,int64_t H,int64_t W,scalar_t delta)', '    safe_add_3d(scalar_t *data,int64_t d,int64_t h,int64_t w,int64_t sD,int64_t sH,int64_t sW,int64_t D,int64_t H,int64_t W,scalar_t delta)', '    within_bounds_2d(int64_t h,int64_t w,int64_t H,int64_t W)', '    within_bounds_3d(int64_t d,int64_t h,int64_t w,int64_t D,int64_t H,int64_t W)', '    fmod'];
cos_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 109;  4; 47;4;  58; 0;31;44;8;24;0.07;7;[];['    grid_sample_2d_grid_slice_iterator(const TensorAccessor & grid_slice,const ApplyFn & apply_fn)', '    mask_scatter_add(const scalar_t *src,scalar_t *base_addr,const int_same_size_t *offsets,const int_same_size_t *mask,int64_t len)', '    grid_sampler_2d_backward_cpu_kernel_impl(const Tensor & grad_output_,const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    grid_sampler_2d_cpu_kernel_impl(const Tensor & input,const Tensor & grid,int64_t interpolation_mode,int64_t padding_mode,bool align_corners)', '    ApplyGridSample(const TensorAccessor & input)', '    ApplyGridSample(const TensorAccessor & input)', '    backward(TensorAccessor & gInp_slice,TensorAccessor & gGrid_slice,const TensorAccessor & gOut_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    backward(TensorAccessor & gInp_slice,TensorAccessor & gGrid_slice,const TensorAccessor & gOut_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    compute_interp_params(const Vec & x,const Vec & y)', '    forward(TensorAccessor & out_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    forward(TensorAccessor & out_slice,const TensorAccessor & inp_slice,int64_t offset,const Vec & grid_x,const Vec & grid_y,int64_t len)', '    apply(const Vec & in)', '    apply(const Vec & in)', '    apply(const Vec & in)', '    apply_get_grad(const Vec & in)', '    apply_get_grad(const Vec & in)', '    apply_get_grad(const Vec & in)', '    clip_coordinates(const Vec & in)', '    clip_coordinates(const Vec & in)', '    clip_coordinates_get_grad(const Vec & in)', '    clip_coordinates_get_grad(const Vec & in)', '    ComputeLocationBase(int64_t size)', '    ComputeLocationBase(int64_t size)', '    reflect_coordinates(const Vec & in)', '    reflect_coordinates(const Vec & in)', '    reflect_coordinates_get_grad(const Vec & in)', '    reflect_coordinates_get_grad(const Vec & in)', '    unnormalize(const Vec & in)', '    unnormalize(const Vec & in)'];
cos_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    grid_sampler_2d_backward_cpu_kernel', '    grid_sampler_2d_backward_cpu_kernel', '    operator=', '    grid_sampler_2d_cpu_kernel', '    grid_sampler_2d_cpu_kernel', '    operator='];
cosh_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GroupNorm', '    AffineBatchChannelDequantizedNCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelDequantizedNHWC(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelQuantizedNCHW(const int N,const int C,const int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelQuantizedNHWC(const int N,const int C,const int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeDequantizedFusedParams(const int N,const int G,const int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    ComputeQuantizedFusedParams(const int N,const int G,const int K,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,const int32_t *beta,int32_t *scale,int32_t *bias)', '    ComputeQuantizedInvStd(const int N,const float *var,float *rsig,int32_t *rsig_quantized)', '    DequantizedGroupMomentsNCHW(const int N,const int G,const int K,const int HxW,const T *X,float *mu,float *rsig)', '    DequantizedGroupMomentsNHWC(const int N,const int G,const int K,const int HxW,const T *X,float *mu,float *rsig)', '    GetQuantizationParameters', '    GroupNormDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    QuantizeBeta', '    QuantizedGroupMomentsNCHW(const int N,const int G,const int K,const int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizedGroupMomentsNHWC(const int N,const int G,const int K,const int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizeGamma', '    QuantizeGammaImpl', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
cosine_embedding_criterion_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 85;  1; 19;3;  63; 0;39;42;15;39;0.02;8;['    final'];['    AffineBatchChannelAndRequantizeNCHWAVX2(const int N,const int C,const int HxW,const dnnlowp::RequantizationParams & params,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelAndRequantizeNHWCAVX2(const int N,const int C,const int HxW,const dnnlowp::RequantizationParams & params,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeQuantizedFusedParamsAVX2(const int N,const int G,const int K,const int32_t X_zero_point,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,int32_t *scale,int32_t *bias)', '    VectorMomentsAVX2(const int N,const T *src,int64_t *sum,int64_t *sumsq)', '    AffineBatchChannelDequantizedNCHW(int N,int C,int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelDequantizedNHWC(int N,int C,int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    AffineBatchChannelQuantizedNCHW(int N,int C,int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    AffineBatchChannelQuantizedNHWC(int N,int C,int HxW,const T *X,const int32_t *scale,const int32_t *bias,T *Y)', '    ComputeDequantizedFusedParams(int N,int G,int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    ComputeQuantizedFusedParams(int N,int G,int K,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,const int32_t *beta,int32_t *scale,int32_t *bias)', '    ComputeQuantizedInvStd(int N,const float *var,float *rsig,int32_t *rsig_quantized)', '    DequantizedGroupMomentsNCHW(int N,int G,int K,int HxW,const T *X,float *mu,float *rsig)', '    DequantizedGroupMomentsNHWC(int N,int G,int K,int HxW,const T *X,float *mu,float *rsig)', '    GetQuantizationParameters', '    GroupNormDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    QuantizeBeta', '    QuantizedGroupMomentsNCHW(int N,int G,int K,int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizedGroupMomentsNHWC(int N,int G,int K,int HxW,const T *X,int32_t *mu,int32_t *rsig)', '    QuantizeGamma', '    QuantizeGammaImpl', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
cosine_embedding_criterion_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  2; 10;6;  26; 0;0;18;34;55;0.08;2;[];['    AffineBatchChannelAndRequantizeNCHWAVX2(const int N,const int C,const int HxW,const fbgemm::RequantizationParams & params,const uint8_t *X,const int32_t *scale,const int32_t *bias,uint8_t *Y)', '    AffineBatchChannelAndRequantizeNHWCAVX2(const int N,const int C,const int HxW,const fbgemm::RequantizationParams & params,const uint8_t *X,const int32_t *scale,const int32_t *bias,uint8_t *Y)', '    ComputeQuantizedFusedParamsAVX2(const int N,const int G,const int K,const int32_t X_zero_point,const int32_t *mu,const int32_t *rsig,const int32_t *gamma,int32_t *scale,int32_t *bias)', '    SegmentMomentsAVX2(const int N,const uint8_t *src,int64_t *sum,int64_t *sumsq)', '    VectorMomentsAVX2(const int N,const uint8_t *src,int64_t *sum,int64_t *sumsq)'];
counter_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 164;  7; 24;7;  128; 0;40;64;135;182;0.05;18;['    GetGroupNormGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGroupNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPUGroupNormGradient', '    ComputeGradientFusedParams(const int N,const int G,const int K,const int HxW,const T *ds,const T *db,const T *mu,const T *rsig,const T *gamma,T *dY_scale,T *X_scale,T *bias)', '    ComputeInternalGradients(const int N,const int C,const int HxW,const float *dY,const float *X,float *ds,float *db)', '    ComputeInternalGradients(const int N,const int C,const int HxW,const float *dY,const float *X,float *ds,float *db)', '    GammaBetaBackward(const int N,const int G,const int K,const T *ds,const T *db,const T *mu,const T *rsig,T *dgamma,T *dbeta)', '    GroupNormBackward(const int N,const int G,const int K,const int HxW,const float *dY_scale,const float *dY,const float *X_scale,const float *X,const float *bias,float *dX)', '    GroupNormBackward(const int N,const int G,const int K,const int HxW,const float *dY_scale,const float *dY,const float *X_scale,const float *X,const float *bias,float *dX)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupNormGradient', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW(const int N,const int G,const int K,const int HxW,const float *dY_data,const float *X_data,const float *mu_data,const float *rsig_data,const float *gamma_data,float *dX_data,float *dgamma_data,float *dbeta_data)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)', '    ComputeFusedParams(const int N,const int G,const int K,const float *mu,const float *rsig,const float *gamma,const float *beta,float *scale,float *bias)', '    GroupNormForwardNHWC(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const float *X,const float *gamma,const float *beta,float *Y,float *mu,float *rsig)', '    vector'];
counter_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 13;  1; 1;2;  10; 0;6;8;6;25;0.10;6;['    final', '    final'];['    ComputeFusedParams(int N,int G,int K,const T *mu,const T *rsig,const T *gamma,const T *beta,T *scale,T *bias)', '    GetSingleArgument', '    GroupNormForwardNCHW(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y)', '    GroupNormForwardNHWC(const int N,const int C,const int HxW,const T *X,const T *scale,const T *bias,T *Y)', '    GroupNormGradientOp(Args,...)', '    GroupNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(const int N,const int G,const int K,const int HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mu,T *rsig)', '    RunOnDeviceWithOrderNCHW(int N,int G,int K,int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)', '    RunOnDeviceWithOrderNHWC(const int N,const int G,const int K,const int HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mu,T *rsig)', '    RunOnDeviceWithOrderNHWC(int N,int G,int K,int HxW,const T *dY_data,const T *X_data,const T *mu_data,const T *rsig_data,const T *gamma_data,T *dX_data,T *dgamma_data,T *dbeta_data)'];
crash_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  0; 0;5;  0; 24;0;0;0;0;0.00;0;['    GetGroupSpatialSoftmaxGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGroupSpatialSoftmax', '    CAFFE_ANONYMOUS_VARIABLE_CPUGroupSpatialSoftmaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupSpatialSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GroupSpatialSoftmaxGradient', '    vector', '    GetGradientDefs'];
create_scope_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 178;  8; 24;11;  137; 0;59;52;98;87;0.06;12;['    final', '    final'];['    GetSingleArgument', '    GroupSpatialSoftmaxGradientOp(const OperatorDef & def,Workspace *ws)', '    GroupSpatialSoftmaxOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice'];
crf_viterbi_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 221;  6; 27;9;  181; 0;108;92;57;65;0.03;12;['    GetGRUUnitGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGRUUnit', '    CAFFE_ANONYMOUS_VARIABLE_CPUGRUUnitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GRUUnit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GRUUnitGradient', '    vector', '    GetGradientDefs'];
cross_entropy_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 701;  5; 188;2;  509; 0;367;311;197;243;0.01;47;['    GRUUnitGradientOp', '    GRUUnitOp'];['    GRUUnit(int N,int D,int t,const T *H_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *H,Context *)', '    GRUUnitGradient(int N,int D,int t,const T *H_prev,const T *X,const int32_t *seqLengths,const T *H,const T *H_diff,bool drop_states,T *H_prev_diff,T *X_diff,Context *)', '    host_tanh(T x)', '    sigmoid(T x)', '    GetSingleArgument', '    GRUUnitGradientOp(Args,...)', '    RunOnDevice', '    GetSingleArgument', '    GRUUnitOp(Args,...)', '    RunOnDevice'];
ctc_beam_search_decoder_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 188;  13; 21;1;  155; 0;125;89;71;50;0.08;4;[];['    TEST(JitTest,ADFormulas)', '    TEST(JitTest,Attributes)', '    TEST(JitTest,Blocks)', '    TEST(JitTest,CallStack)', '    TEST(JitTest,CallStackCaching)', '    TEST(JitTest,CodeTemplate)', '    TEST(JitTest,ControlFlow)', '    TEST(JitTest,CreateAutodiffSubgraphs)', '    TEST(JitTest,CustomOperators)', '    TEST(JitTest,CustomOperatorAliasing)', '    TEST(JitTest,IValueKWargs)', '    TEST(JitTest,CustomFusion)', '    TEST(JitTest,SchemaMatching)', '    TEST(JitTest,Differentiate)', '    TEST(JitTest,DifferentiateWithRequiresGrad)', '    TEST(JitTest,FromQualString)', '    TEST(JitTest,InternedStrings)', '    TEST(JitTest,PassManagement)', '    TEST(JitTest,Proto)', '    TEST(JitTest,RegisterFusionCachesKernel)', '    TEST(JitTest,SchemaParser)', '    TEST(JitTest,TopologicalIndex)', '    TEST(JitTest,TopologicalMove)', '    TEST(JitTest,SubgraphUtils)', '    TEST(JitTest,AliasAnalysis)', '    TEST(JitTest,ContainerAliasing)', '    TEST(JitTest,AliasRegistration)', '    TEST(JitTest,WriteTracking)', '    TEST(JitTest,Wildcards)', '    TEST(JitTest,MemoryDAG)', '    TEST(JitTest,IRParser)', '    TEST(JitTest,ConstantPooling)', '    TEST(JitTest,THNNConv)', '    TEST(JitTest,ATenNativeBatchNorm)', '    TEST(JitTest,NoneSchemaMatch)', '    TEST(JitTest,ClassParser)', '    TEST(JitTest,UnifyTypes)', '    TEST(JitTest,Profiler)', '    TEST(JitTest,InsertAndEliminateRedundantGuards)', '    TEST(JitTest,InsertBailOuts)', '    TEST(JitTest,PeepholeOptimize)', '    TEST(JitTest,RecordFunction)', '    TEST(JitTest,ThreadLocalDebugInfo)', '    TEST(JitTest,SubgraphMatching)', '    TEST(JitTest,SubgraphRewriter)', '    TEST(JitTest,ModuleClone)', '    TEST(JitTest,ModuleCloneInstance)', '    TEST(JitTest,ModuleConstant)', '    TEST(JitTest,ModuleParameter)', '    TEST(JitTest,ModuleDefine)', '    TEST(JitTest,QualifiedName)', '    TEST(JitTest,ClassImport)', '    TEST(JitTest,ProfiledTensorTypeHashing)', '    TEST(JitTest,ScriptObject)', '    TEST(JitTest,SaveExtraFilesHook)', '    TEST(JitTest,TypeTags)', '    TEST(JitTest,DCE)', '    TEST(JitTest,CustomFusionNestedBlocks)', '    TEST(JitTest,ClassDerive)', '    TEST(JitTest,SaveLoadTorchbind)', '    TEST(JitTest,ModuleInterfaceSerialization)', '    TEST(JitTest,ClassTypeAddRemoveAttr)', '    TEST(JitTest,Inliner)', '    TEST(JitTest,LiteInterpreterAdd)', '    TEST(JitTest,LiteInterpreterConv)', '    TEST(JitTest,LiteInterpreterInline)', '    TEST(JitTest,LiteInterpreterTuple)', '    TEST(JitTest,LiteInterpreterUpsampleNearest2d)', '    TEST(JitTest,CommonAncestor)', '    TEST(JitTest,AutogradSymbols)', '    TEST(JitTest,MobileTypeParser)', '    TEST(JitTest,LiteInterpreterBuiltinFunction)', '    TEST(JitTest,LiteInterpreterPrim)', '    TEST(JitTest,LiteInterpreterLoadOrigJit)', '    TEST(JitTest,LiteInterpreterWrongMethodName)', '    TEST(JitTest,LiteInterpreterParams)', '    TEST(JitTest,LiteInterpreterSetState)', '    TEST(JitTest,TorchbindIValueAPI)', '    TEST(JitTest,ArgumentSpec_CUDA)', '    TEST(JitTest,CompleteArgumentSpec_CUDA)', '    TEST(JitTest,Fusion_CUDA)', '    TEST(JitTest,GraphExecutor_CUDA)', '    TEST(JitTest,ModuleConversion_CUDA)', '    TEST(JitTest,Interp_CUDA)'];
ctc_beam_search_decoder_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 37;  3; 7;5;  24; 0;6;13;21;32;0.13;1;[];['    TEST(TensorExprTest,ExprBasicValueTest)', '    TEST(TensorExprTest,ExprBasicValueTest02)', '    TEST(TensorExprTest,ExprLetTest01)', '    TEST(TensorExprTest,ExprLetStmtTest01)', '    TEST(TensorExprTest,ExprLetTest02)', '    TEST(TensorExprTest,ExprIntTest)', '    TEST(TensorExprTest,ExprFloatTest)', '    TEST(TensorExprTest,ExprByteTest)', '    TEST(TensorExprTest,ExprCharTest)', '    TEST(TensorExprTest,ExprShortTest)', '    TEST(TensorExprTest,ExprLongTest)', '    TEST(TensorExprTest,ExprHalfTest)', '    TEST(TensorExprTest,ExprDoubleTest)', '    TEST(TensorExprTest,ExprVectorAdd01)', '    TEST(TensorExprTest,ExprCompareSelectEQ)', '    TEST(TensorExprTest,ExprSubstitute01)', '    TEST(TensorExprTest,ExprMath01)', '    TEST(TensorExprTest,ExprUnaryMath01)', '    TEST(TensorExprTest,ExprBinaryMath01)', '    TEST(TensorExprTest,ExprDynamicShapeAdd)', '    TEST(TensorExprTest,ExprBitwiseOps)', '    TEST(TensorExprTest,IRPrinterBasicValueTest)', '    TEST(TensorExprTest,IRPrinterBasicValueTest02)', '    TEST(TensorExprTest,IRPrinterLetTest01)', '    TEST(TensorExprTest,IRPrinterLetTest02)', '    TEST(TensorExprTest,IRPrinterCastTest)', '    TEST(TensorExprTest,ExprSimple01)', '    TEST(TensorExprTest,ExprLower01)', '    TEST(TensorExprTest,ExprSimple02)', '    TEST(TensorExprTest,ExprSplitWithTailNone)', '    TEST(TensorExprTest,ExprSplitWithMask01)', '    TEST(TensorExprTest,ScheduleBroadcastAddBuffer)', '    TEST(TensorExprTest,ScheduleFunctionCall01)', '    TEST(TensorExprTest,ScheduleInlineFunc01)', '    TEST(TensorExprTest,ScheduleFuserStyle)', '    TEST(TensorExprTest,ScheduleFuserThreeArg)', '    TEST(TensorExprTest,ScheduleDynamicShape2D)', '    TEST(TensorExprTest,TypeTest01)', '    TEST(TensorExprTest,TypePropagation)', '    TEST(TensorExprTest,Cond01)', '    TEST(TensorExprTest,IfThenElse01)', '    TEST(TensorExprTest,IfThenElse02)', '    TEST(TensorExprTest,ATen_cast_Float)', '    TEST(TensorExprTest,ATennegInt)', '    TEST(TensorExprTest,ATennegFloat)', '    TEST(TensorExprTest,ATenaddInt)', '    TEST(TensorExprTest,ATenaddFloat)', '    TEST(TensorExprTest,ATensubInt)', '    TEST(TensorExprTest,ATensubFloat)', '    TEST(TensorExprTest,ATenlerp)', '    TEST(TensorExprTest,ATenaddcmulInt)', '    TEST(TensorExprTest,ATenaddcmulFloat)', '    TEST(TensorExprTest,ATenmulInt)', '    TEST(TensorExprTest,ATenmulFloat)', '    TEST(TensorExprTest,ATendivInt)', '    TEST(TensorExprTest,ATendivFloat)', '    TEST(TensorExprTest,ATenmaxInt)', '    TEST(TensorExprTest,ATenmaxFloat)', '    TEST(TensorExprTest,ATenminInt)', '    TEST(TensorExprTest,ATenminFloat)', '    TEST(TensorExprTest,ATen_sigmoid_backward)', '    TEST(TensorExprTest,ATen_tanh_backward)', '    TEST(TensorExprTest,ATenreciprocal)', '    TEST(TensorExprTest,ATenreluInt)', '    TEST(TensorExprTest,ATenreluFloat)', '    TEST(TensorExprTest,ATenlogFloat)', '    TEST(TensorExprTest,ATenlog10Float)', '    TEST(TensorExprTest,ATenlog2Float)', '    TEST(TensorExprTest,ATenexpFloat)', '    TEST(TensorExprTest,ATenerfFloat)', '    TEST(TensorExprTest,ATencosFloat)', '    TEST(TensorExprTest,ATeneqInt)', '    TEST(TensorExprTest,ATengeInt)', '    TEST(TensorExprTest,ATengtInt)', '    TEST(TensorExprTest,ATenleInt)', '    TEST(TensorExprTest,ATenltInt)', '    TEST(TensorExprTest,ConstantFoldSimple)', '    TEST(TensorExprTest,ConstantFoldTwoLayer)', '    TEST(TensorExprTest,ConstantFoldShifts)', '    TEST(TensorExprTest,ConstantFoldBitwise)', '    TEST(TensorExprTest,ConstantFoldMultiOp)', '    TEST(TensorExprTest,ConstantFoldMinMax)', '    TEST(TensorExprTest,ConstantFoldIntrinsics)', '    TEST(TensorExprTest,ConstantFoldWithVar)', '    TEST(TensorExprTest,UnFoldableExpr)', '    TEST(TensorExprTest,HashSimple)', '    TEST(TensorExprTest,HashEquivalence)', '    TEST(TensorExprTest,HashEquivalenceAfterFolding)', '    TEST(TensorExprTest,HashDifferenceTypes)', '    TEST(TensorExprTest,HashLargeExpression)', '    TEST(TensorExprTest,SimplifyAdd)', '    TEST(TensorExprTest,SimplifySub)', '    TEST(TensorExprTest,SimplifyMultiLayer)', '    TEST(TensorExprTest,SimplifyMultiTerm)', '    TEST(TensorExprTest,SimplifyCasts)', '    TEST(TensorExprTest,SimplifyEliminatesNoOps)', '    TEST(TensorExprTest,SimplifyMultiVar)', '    TEST(TensorExprTest,SimplifyEliminatesVar)', '    TEST(TensorExprTest,SimplifyAdds)', '    TEST(TensorExprTest,SimplifyMuls)', '    TEST(TensorExprTest,SimplifySubs)', '    TEST(TensorExprTest,SimplifyMultiOp)', '    TEST(TensorExprTest,SimplifyManyOps)', '    TEST(TensorExprTest,SimplifyFactorization)', '    TEST(TensorExprTest,SimplifyFactorizeUneven)', '    TEST(TensorExprTest,SimplifyDeeperTerms)', '    TEST(TensorExprTest,SimplifyDeeperDifference)', '    TEST(TensorExprTest,SimplifyFoldComplexDifference)', '    TEST(TensorExprTest,SimplifyIfComponents)', '    TEST(TensorExprTest,SimplifyOpaqueTerms)', '    TEST(TensorExprTest,SimplifyWontReorderFloat)', '    TEST(TensorExprTest,StmtClone)'];
ctc_greedy_decoder_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 99;  6; 13;1;  81; 0;66;65;30;39;0.07;4;[];['    DistanceBetweenSignAndMagnitudeNumbers(const Bits & sam1,const Bits & sam2)', '    SignAndMagnitudeToBiased(const Bits & sam)', '    AlmostEquals(float lhs,float rhs)'];
cube_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 68;  4; 11;5;  52; 0;25;39;6;24;0.08;7;[];['    no_exceptions', '    EliminateRedundantGuards(std::shared_ptr graph)', '    isLoweredGradOf(Node *n)', '    checkInputs(Node *n,const std::unordered_set & except,bool allow_numbers)', '    coalesceGuards(Block *b)', '    eliminateRedundantGuards(Block *b)', '    GuardElimination(std::shared_ptr graph)', '    guardsOutput(Node *guard)', '    moveGuardsToDefs(Block *b)', '    removableGuard(Node *n)', '    run'];
cube_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    EliminateRedundantGuards(std::shared_ptr graph)'];
data_couple.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 9;1;  7; 0;5;7;1;7;0.14;2;['    GetHSoftmaxGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmax', '    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUHSoftmaxSearch', '    CAFFE_ANONYMOUS_VARIABLE_CPUHuffmanTreeHierarchy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HSoftmaxSearch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HuffmanTreeHierarchy', '    get_next_node', '    intermediate_data', '    vector', '    RunForwardSingle(const float *X,const float *W,const float *b,int target,float *int_output,const float *bias_multiplier,int dim_out,int dim_in,int & int_output_offset)', '    RunOnDevice', '    GetGradientDefs', '    RunBackwardSingle(const float *X,const float *dY,const float *W,int target,const float *int_output,float *dX,float *dW,float *db,float *dint_output,int dim_in,int dim_out,int & int_output_offset)', '    extractNodes(const NodeProto & node,std::vector,float)', '    pruning(const float *X,int sample,int K,const float *W,const float *b,const NodeProto & src_node,NodeProto & dst_node,float parent_score,float beam)', '    RunOnDevice', '    RunOnDevice'];
dataset_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 1562;  85; 329;9;  1155; 0;701;608;624;614;0.07;86;['    final', '    final', '    HSoftmaxOp', '    HSoftmaxOpBase', '    HuffmanTreeHierarchyOp'];['    getHierarchyForLabels(int M,const int *labels,const std::unordered_map & hierarchy_all_map)', '    kLOG_THRESHOLD', '    extractNodes(const NodeProto & node,std::vector,float)', '    HSoftmaxSearchOp(Args,...)', '    pruning(const float *X,int sample,int K,const float *W,const float *b,const NodeProto & src_node,NodeProto & dst_node,float parent_score,float beam)', '    RunBackwardSingle(const float *X,const float *dY,const float *W,int target,const float *int_output,float *dX,float *dW,float *db,float *dOutput,int dim_in,int w_length,int & output_offset)', '    RunOnDevice', '    RunForwardSingle(const float *X,const float *W,const float *b,int target,float *int_output,const float *bias_multiplier,int dim_out,int dim_in,int & int_output_offset)', '    RunOnDevice', '    getIntermediateOutputSize(const int *labels,int M,std::unordered_map & hierarchy)', '    GetSingleArgument', '    HSoftmaxOpBase(Args,...)', '    GetSingleArgument', '    HuffmanTreeHierarchyOp(Args,...)', '    Node(T l,int count)', '    operator()(const Node & node_a,const Node & node_b)', '    RunOnDevice'];
dataset_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 213;  27; 43;10;  136; 0;29;72;25;68;0.20;21;[];['    denorm_min', '    epsilon', '    infinity', '    lowest', '    max', '    min', '    quiet_NaN', '    round_error', '    signaling_NaN', '    operator float', '    operator*(const Half & a,const Half & b)', '    operator*(Half a,float b)', '    operator*(float a,Half b)', '    operator*(Half a,double b)', '    operator*(double a,Half b)', '    operator*(Half a,int b)', '    operator*(int a,Half b)', '    operator*(Half a,int64_t b)', '    operator*(int64_t a,Half b)', '    operator*=(Half & a,const Half & b)', '    operator*=(float & a,const Half & b)', '    operator+(const Half & a,const Half & b)', '    operator+(Half a,float b)', '    operator+(float a,Half b)', '    operator+(Half a,double b)', '    operator+(double a,Half b)', '    operator+(Half a,int b)', '    operator+(int a,Half b)', '    operator+(Half a,int64_t b)', '    operator+(int64_t a,Half b)', '    operator+=(Half & a,const Half & b)', '    operator+=(float & a,const Half & b)', '    operator-(const Half & a,const Half & b)', '    operator-(const Half & a)', '    operator-(Half a,float b)', '    operator-(float a,Half b)', '    operator-(Half a,double b)', '    operator-(double a,Half b)', '    operator-(Half a,int b)', '    operator-(int a,Half b)', '    operator-(Half a,int64_t b)', '    operator-(int64_t a,Half b)', '    operator-=(Half & a,const Half & b)', '    operator-=(float & a,const Half & b)', '    operator/(const Half & a,const Half & b)', '    operator/(Half a,float b)', '    operator/(float a,Half b)', '    operator/(Half a,double b)', '    operator/(double a,Half b)', '    operator/(Half a,int b)', '    operator/(int a,Half b)', '    operator/(Half a,int64_t b)', '    operator/(int64_t a,Half b)', '    operator/=(Half & a,const Half & b)', '    operator/=(float & a,const Half & b)', '    Half(float value)', '    fp16_ieee_from_fp32_value', '    from_bits'];
deform_conv_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 57;  2; 8;3;  46; 0;21;16;10;37;0.04;6;[];['    operator<<(std::ostream & out,const Half & value)'];
deform_conv_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 112;  8; 17;13;  76; 0;8;55;139;264;0.11;11;[];['    from_bits', '    fp16_ieee_from_fp32_value(float f)', '    fp16_ieee_to_fp32_bits(uint16_t h)', '    fp16_ieee_to_fp32_value(uint16_t h)', '    fp32_from_bits(uint32_t w)', '    fp32_to_bits(float f)', '    Half', '    Half(unsigned short bits,from_bits_t)', '    Half(float value)', '    operator float', '    ComplexHalf', '    ComplexHalf(std::complex value)', '    imag', '    operator std::complex', '    operator<<(std::ostream & out,const Half & value)', '    overflows(From f)', '    overflows(From f)', '    overflows(From f)', '    overflows(From f)', '    real', '    lowest', '    max', '    isinf'];
deform_conv_op_impl.h;C++;pytorch-master/pytorch-master/caffe2/operators; 407;  25; 42;10;  332; 0;229;117;142;80;0.08;2;['    GetFloatToHalfGradient', '    GetHalfToFloatGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloat16ConstantFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloat16UniformFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToHalf', '    CAFFE_ANONYMOUS_VARIABLE_CPUHalfToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Float16ConstantFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Float16UniformFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToHalf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HalfToFloat', '    Float16ToFloat_ref(const at::Half *in,float *out,size_t N)', '    FloatToFloat16_ref(const float *in,at::Half *out,size_t N,bool do_clip)', '    vector', '    vector', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs', '    RunOnDevice', '    GetGradientDefs'];
dense_vector_to_id_list_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 29;  2; 14;1;  14; 0;9;14;1;10;0.14;2;['    Float16ConstantFillOp', '    Float16UniformFillOp', '    FloatToHalfOp', '    HalfToFloatOp'];['    Float16FillerTensorInference(const OperatorDef & def,const vector & in)', '    Float16ConstantFillOp(Args,...)', '    GetRepeatedArgument', '    RunOnDevice', '    ~Float16ConstantFillOp', '    Float16UniformFillOp(Args,...)', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    RunOnDevice', '    ~Float16UniformFillOp', '    FloatToHalfOp(const OperatorDef & operator_def,Workspace *ws)', '    GetSingleArgument', '    RunOnDevice', '    HalfToFloatOp(Args,...)', '    RunOnDevice', '    ~HalfToFloatOp'];
distance_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 761;  18; 245;8;  494; 5;379;302;242;249;0.04;41;[];['    TEST(Float16,SimpleTest)', '    TEST(Float16,UniformDistributionTest)'];
distance_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 296;  10; 42;6;  241; 0;96;118;248;317;0.04;12;[];['    float2halfbits(float src)', '    halfbits2float(unsigned short h)', '    TEST(HalfDoubleConversionTest,Half2Double)'];
do_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  1; 8;1;  24; 0;22;24;1;7;0.04;2;[];['    to_string(const Half & h)', '    TEST(TestHalf,Arithmetic)', '    TEST(TestHalf,Comparisions)', '    TEST(TestHalf,Cast)', '    TEST(TestHalf,Construction)', '    TEST(TestHalf,Half2String)', '    TEST(TestHalf,HalfNumericLimits)', '    TEST(TestHalf,CommonMath)'];
do_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 4;2;  3; 0;1;3;1;5;0.33;1;[];['    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)', '    operator()(const at::Half a,const at::Half b)'];
dropout_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 188;  3; 69;1;  116; 0;87;76;28;50;0.03;8;[];['    createCuDNNHandle(cudnnHandle_t *handle)', '    destroyCuDNNHandle(cudnnHandle_t handle)', '    getCudnnHandle'];
dropout_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 57;  4; 10;7;  38; 0;4;28;50;65;0.11;2;[];['    getMiopenHandle', '    Handle', '    ~Handle'];
elementwise_add_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  2; 9;3;  21; 0;6;14;3;14;0.10;3;[];['    getMiopenHandle'];
elementwise_add_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;1;  5; 0;1;3;1;5;0.20;1;[];['    getCudnnHandle'];
elementwise_add_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 76;  5; 7;9;  60; 0;32;28;6;7;0.08;2;[];[];
elementwise_div_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 292;  6; 19;6;  265; 0;159;99;84;92;0.02;8;['    GetHardSigmoidGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUHardSigmoid', '    CAFFE_ANONYMOUS_VARIABLE_CPUHardSigmoidGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HardSigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HardSigmoidGradient', '    CostInferenceForHardSigmoid(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector'];
elementwise_div_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 10;  1; 4;1;  5; 0;1;3;1;5;0.20;1;[];['    HardSigmoidFunctor(OperatorBase & op)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)', '    HardSigmoidGradientFunctor(OperatorBase & op)'];
elementwise_div_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 48;  2; 7;6;  35; 0;10;23;2;4;0.06;1;[];['    simple_get_hash(const T & o)', '    get_hash(const Types &,...)', '    operator()(const std::tuple & t)', '    operator()(const std::vector & v)', '    dispatch_hash(const T & o)', '    simple_get_hash(const T & o)', '    type_if_not_enum', '    dispatch_hash(const T & o)', '    hash_combine(size_t seed,size_t value)', '    size_t', '    dispatch_hash', '    simple_get_hash', '    operator()(const T & o)', '    get', '    hash', '    tie', '    hash', '    operator()(const std::tuple & t)', '    operator()(const std::tuple & t)'];
elementwise_linear_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 41;  2; 9;6;  26; 0;0;18;34;55;0.08;2;[];['    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Block *v)', '    visit(const For *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    operator!=(const SimplifierHashType & other)', '    operator!=(const size_t other)', '    operator<(const SimplifierHashType & other)', '    operator==(const SimplifierHashType & other)', '    operator==(const size_t other)'];
elementwise_logical_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 117;  4; 57;1;  57; 0;39;49;6;23;0.07;8;['    HashProvider'];['    hash', '    intval', '    operator()(const torch::jit::tensorexpr::SimplifierHashType & k)', '    value', '    value', '    _hash_combine(SimplifierHashType & seed,const T & val)', '    _hash_combine(SimplifierHashType & seed,const char *val)', '    _hash_combine(SimplifierHashType & seed,const at::Half & val)', '    _hash_combine(SimplifierHashType & seed,const Dtype & val)', '    _hash_combine(SimplifierHashType & seed,const Expr *e)', '    _hash_combine(SimplifierHashType & seed,const T & val,const Types &,...)', '    cachedHash(const KernelScopedObject *e)', '    hash(const T *e)', '    hash_combine(const Types &,...)', '    hashOf(const Expr *e)', '    hashOf(const Stmt *s)', '    putHash(const KernelScopedObject *e,SimplifierHashType h)', '    te_hash(SimplifierHashType val)', '    te_hash(int64_t val)', '    te_hash(int32_t val)', '    te_hash(uint32_t val)', '    te_hash(uint64_t val)', '    te_hash(int16_t val)', '    te_hash(std::string val)', '    te_hash(double d)', '    te_hash(float d)', '    te_hash(at::Half d)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const Store *v)', '    visit(const Block *v)', '    visit(const For *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    _h', '    operator!=(const SimplifierHashType & other)', '    operator!=(const size_t other)', '    operator<(const SimplifierHashType & other)', '    operator==(const SimplifierHashType & other)', '    operator==(const size_t other)', '    SimplifierHashType', '    SimplifierHashType(size_t s)'];
elementwise_logical_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 174;  4; 27;9;  136; 0;76;67;91;109;0.03;8;[];['    pred', '    pred', '    add(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    set(const std::string & key,const std::vector & data)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)'];
elementwise_mul_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;1;  5; 0;1;3;1;5;0.20;1;['    HashStore'];['    add(const std::string & key,int64_t i)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    wait(const std::vector & keys)', '    ~HashStore'];
elementwise_mul_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 48;  2; 7;6;  35; 0;10;23;2;4;0.06;1;[];['    main(int,char **)', '    testHelper(std::string prefix)'];
elementwise_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  0; 8;3;  31; 0;16;10;17;9;0.00;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUHeatmapMaxKeypoint', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HeatmapMaxKeypoint', '    RunOnDevice'];
elementwise_op_test.h;C++;pytorch-master/pytorch-master/caffe2/operators; 266;  10; 13;8;  245; 0;169;88;123;74;0.04;18;['    final'];['    schema_HeatmapMaxKeypoint', '    GetSingleArgument', '    HeatmapMaxKeypointOp(Args,...)', '    RunOnDevice'];
elementwise_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 127;  1; 20;21;  86; 0;42;54;38;76;0.01;20;[];['    ExtraTypeProto(const ::ONNX_NAMESPACE::TensorProto & tensor)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::vector & attributes,const std::string & name)', '    NewDummyName', '    Reset(const std::unordered_set & used_names)'];
elementwise_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 533;  33; 57;39;  410; 0;151;219;190;247;0.08;34;[];['    buildValueToParamsMap(Block *b,const ParamMap & paramsDict)', '    eraseUnusedValuesFromMap(ValueToParamPairMap & valsToParamsMap)'];
elementwise_ops_utils.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 124;  2; 7;1;  116; 0;66;39;71;28;0.02;4;['    DummyName'];['    ExtraTypeProto(const ::ONNX_NAMESPACE::TensorProto & tensor)', '    MakeAttribute(const std::string & name,const std::vector & vals)', '    MakeAttribute(const std::string & name,const std::vector & vals)', '    MakeAttribute(const std::string & name,int64_t val)', '    MakeAttribute(const std::string & name,const std::string & val)', '    MakeAttribute(const std::string & name,::ONNX_NAMESPACE::TensorProto & val)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::vector & attributes,const std::string & name)', '    MakeNode(const std::string & type,const std::vector & inputs,const std::vector & outputs,const std::string & name)', '    MakeTensor(const string & name,const std::vector & v,const ::ONNX_NAMESPACE::TensorProto_DataType & data_type_)', '    AddName(const std::string & new_used)', '    counter_', '    NewDummyName', '    Reset(const std::unordered_set & used_names)'];
elementwise_ops_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  3; 9;7;  19; 0;0;19;0;6;0.16;0;[];['    buildValueToParamsMap(Block *b,const ParamMap & paramsDict)', '    eraseUnusedValuesFromMap(ValueToParamPairMap & valsToParamsMap)'];
elementwise_sub_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  2; 9;3;  21; 0;6;14;3;14;0.10;3;[];[];
elementwise_sub_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 76;  5; 7;9;  60; 0;32;28;6;7;0.08;2;['    HGEMM', '    HGEMM_L1', '    HGEMM_Op'];['    GemmArguments(benchmark::internal::Benchmark *b)', '    MobileNetV1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8GemmArguments(benchmark::internal::Benchmark *b)', '    SqueezeNetV10GemmArguments(benchmark::internal::Benchmark *b)', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)', '    a', '    b', '    c', '    clampingParams', '    clampingParams_', '    HGEMM(uint32_t mr,uint32_t nr,uint32_t kr)', '    k', '    kc', '    kc_', '    kcStride', '    kr', '    kr_', '    mc', '    mc_', '    mr', '    mr_', '    nc', '    nc_', '    ncStride', '    nr', '    nr_', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    w', '    w', '    HGEMM_L1', '    HGEMM_Op', '    SetUp(const benchmark::State & state)'];
elementwise_sub_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 4;2;  11; 0;2;4;2;9;0.09;2;[];['    pytorch_hgemm_ukernel_8x8__aarch32_neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params *clamping_params)', '    pytorch_hgemm_ukernel_8x8__neonfp16arith(size_t mr,size_t nr,size_t k,const void *a,size_t a_stride,const void *w,void *c,size_t c_stride,const struct pytorch_qnnp_fp16_clamping_params [1] clamping_params)'];
elementwise_sum_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 116;  0; 77;1;  38; 0;36;38;1;7;0.00;2;['    final'];['    device', '    unsafe_set_device', '    allocate(size_t size)', '    HIPAllocatorMasqueradingAsCUDA(Allocator *allocator)', '    raw_deleter'];
elu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 40;  2; 11;5;  24; 0;0;22;0;9;0.08;2;[];['    get', '    recordStreamMasqueradingAsCUDA(const DataPtr & ptr,HIPStreamMasqueradingAsCUDA stream)'];
elu_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 111;  2; 16;2;  93; 0;27;33;80;62;0.02;8;[];['    get', '    recordStreamMasqueradingAsCUDA(const DataPtr & ptr,HIPStreamMasqueradingAsCUDA stream)'];
enforce_finite_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 24;  1; 7;1;  16; 0;9;13;3;10;0.06;3;[];[];
ensure_clipped_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 47;  3; 6;2;  37; 0;28;26;12;20;0.08;3;[];['    hip_stream', '    hip_stream', '    block(void *event,const Stream & stream)', '    createEvent(hipEvent_t *hip_event,const EventFlag flag)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDefaultStream(Device d)', '    getDevice', '    getStream(Device d)', '    HIPGuardImplMasqueradingAsCUDA', '    HIPGuardImplMasqueradingAsCUDA(DeviceType t)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)', '    current_device', '    HIPGuardMasqueradingAsCUDA', '    HIPGuardMasqueradingAsCUDA(DeviceIndex device_index)', '    HIPGuardMasqueradingAsCUDA(Device device)', '    HIPGuardMasqueradingAsCUDA', '    HIPGuardMasqueradingAsCUDA', '    operator=', '    operator=', '    original_device', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_device', '    current_stream', '    HIPStreamGuardMasqueradingAsCUDA', '    HIPStreamGuardMasqueradingAsCUDA(Stream stream)', '    HIPStreamGuardMasqueradingAsCUDA', '    HIPStreamGuardMasqueradingAsCUDA', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    current_device', '    operator=', '    operator=', '    OptionalHIPGuardMasqueradingAsCUDA(optional device_index_opt)', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA', '    OptionalHIPGuardMasqueradingAsCUDA(optional device_opt)', '    original_device', '    reset', '    reset_device(Device device)', '    set_device(Device device)', '    set_index(DeviceIndex device_index)', '    current_stream', '    operator=', '    operator=', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    OptionalHIPStreamGuardMasqueradingAsCUDA(Stream stream)', '    OptionalHIPStreamGuardMasqueradingAsCUDA(optional stream_opt)', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    OptionalHIPStreamGuardMasqueradingAsCUDA', '    original_stream', '    reset', '    reset_stream(Stream stream)'];
ensure_clipped_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 57;  2; 9;4;  43; 0;16;19;29;36;0.05;2;[];['    getHIPHooks', '    RegistryName'];
ensure_cpu_output_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 31;  3; 7;1;  21; 0;18;21;1;9;0.14;2;[];[];
erf_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 74;  4; 12;4;  58; 0;28;41;8;24;0.07;7;['    HIPStreamMasqueradingAsCUDA'];['    getCurrentHIPStreamMasqueradingAsCUDA(DeviceIndex device_index)', '    getDefaultHIPStreamMasqueradingAsCUDA(DeviceIndex device_index)', '    getStreamFromPoolMasqueradingAsCUDA(const bool isHighPriority,DeviceIndex device)', '    operator<<(std::ostream & stream,const HIPStreamMasqueradingAsCUDA & s)', '    setCurrentHIPStreamMasqueradingAsCUDA(HIPStreamMasqueradingAsCUDA stream)', '    priority_range', '    unpack(uint64_t bits)', '    device', '    device_index', '    hip_stream', '    HIPStreamMasqueradingAsCUDA(Stream stream)', '    HIPStreamMasqueradingAsCUDA(Unchecked,Stream stream)', '    HIPStreamMasqueradingAsCUDA(HIPStream stream)', '    id', '    operator hipStream_t', '    operator Stream', '    operator!=(const HIPStreamMasqueradingAsCUDA & other)', '    operator==(const HIPStreamMasqueradingAsCUDA & other)', '    pack', '    priority', '    query', '    stream', '    synchronize', '    unwrap', '    operator()(c10::hip::HIPStreamMasqueradingAsCUDA s)'];
erf_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 36;  2; 8;6;  22; 0;3;17;2;6;0.09;1;[];['    didFinishEmitFunction(StrongFunctionPtr fn)', '    didFinishEmitModule(Module module)', '    getEmitHooks', '    setEmitHooks(ModuleHook for_mod,FunctionHook for_fn)'];
exp_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 91;  2; 50;3;  38; 0;26;34;3;16;0.05;4;[];['    didFinishEmitFunction(StrongFunctionPtr fn)', '    didFinishEmitModule(Module module)', '    getEmitHooks', '    setEmitHooks(ModuleHook for_mod,FunctionHook for_fn)'];
exp_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 4;2;  8; 0;1;3;1;5;0.13;1;['    final'];['    GetDeviceType', '    HasAsyncPartDefault', '    IsStreamFree(const DeviceOption &,int)', '    SupportsAsyncScheduling', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytesFromCPU(size_t nbytes,const void *src,void *dst)', '    CopyBytesToCPU(size_t nbytes,const void *src,void *dst)', '    CopyItems(const TypeMeta & meta,size_t n,const void *src,void *dst)', '    device', '    device_type', '    override', '    random_seed_', '    size_t', '    SupportsNonFundamentalTypes', '    SwitchToDevice(int)', '    SwitchToDevice', '    FinishDeviceComputation', '    IDEEPContext', '    IDEEPContext(const DeviceOption & option)', '    IDEEPContext(const at::Device & device)', '    RandGenerator', '    Record(Event *ev,const char *err_msg)', '    SwitchToDevice(int)', '    WaitEvent(const Event & ev)', '    ~IDEEPContext', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(size_t nbytes,const void *src,void *dst)', '    CopyBytes(size_t nbytes,const void *src,void *dst)'];
expand_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 58;  2; 18;5;  35; 0;17;25;4;22;0.06;6;['    IDEEPOperator'];['    CanonicalDims(ideep::tensor::dims adims,int32_t axis)', '    ConvertScales(const std::vector scales_z)', '    RegistryName', '    getErrorMsg', '    IDEEPOperator(const OperatorDef & operator_def,Workspace *ws)', '    Input(int index)', '    Output(int index)', '    RecordEvent(const char *err_msg)', '    Run(int)', '    RunOnDevice', '    WaitEvent(const Event & ev,int)', '    WaitEvents(const std::vector & events,int)', '    ~IDEEPOperator', '    Record', '    WaitEvent'];
expand_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 117;  6; 16;8;  89; 0;48;40;56;77;0.07;6;[];['    CopyBytesWrapper(size_t nbytes,const void *src,Device src_device,void *dst,Device dst_device)', '    RegistryName', '    _typeMetaDataInstance'];
expand_squeeze_dims_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 194;  0; 88;1;  105; 0;91;101;6;28;0.00;8;[];[];
expand_squeeze_dims_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 120;  4; 14;5;  101; 0;41;37;85;76;0.04;5;[];[];
expand_squeeze_dims_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 7;  1; 1;2;  4; 0;2;4;2;9;0.25;2;['    IdWrapper'];['    noexcept((*) () noexcept)', '    hash_value(const concrete_type & v)', '    operator!=(const concrete_type & lhs,const concrete_type & rhs)', '    operator==(const concrete_type & lhs,const concrete_type & rhs)', '    IdWrapper(underlying_type id)'];
averaged_loss_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 57;  2; 11;4;  42; 0;20;18;7;15;0.05;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUIf', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_If'];
batch_gather_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 78;  2; 12;4;  62; 0;29;37;25;29;0.03;2;['    final'];['    GetSingleArgument', '    HasSingleArgumentOfType', '    IfOp(const OperatorDef & operator_def,Workspace *ws)', '    InputIsTensorType', '    RunOnDevice'];
batch_matmul_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 278;  38; 23;4;  218; 0;147;89;84;56;0.17;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAIf'];
concat_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 120;  4; 9;4;  106; 0;49;38;39;31;0.04;1;[];['    im2col_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_backward_cpu(const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_cpu(const Tensor & input,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)', '    im2col_out_cpu(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef dilation,IntArrayRef padding,IntArrayRef stride)'];
enforce_finite_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 40;  2; 7;4;  29; 0;10;17;7;11;0.07;1;[];['    col2im(const T *data_col,const int64_t channels,const int64_t height,const int64_t width,const int64_t output_height,const int64_t output_width,const int64_t kernel_h,const int64_t kernel_w,const int64_t pad_h,const int64_t pad_w,const int64_t stride_h,const int64_t stride_w,const int64_t dilation_h,const int64_t dilation_w,T *data_im)', '    im2col(const T *data_im,const int64_t channels,const int64_t height,const int64_t width,const int64_t output_height,const int64_t output_width,const int64_t kernel_h,const int64_t kernel_w,const int64_t pad_h,const int64_t pad_w,const int64_t stride_h,const int64_t stride_w,const int64_t dilation_h,const int64_t dilation_w,T *data_col)'];
expand_dims_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 68;  2; 11;4;  53; 0;23;23;25;16;0.04;1;[];['    Im2Col3DNHWC(const int channels,const int num_frames,const int height,const int width,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const int groups,const T & zero_point)', '    Im2ColNCHW(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const T & zero_point)', '    Im2ColNdNCHW(const int N,const int,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *X_data,T *Y_data,CPUContext *,const T & zero_point)', '    Im2ColNHWC(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *data_im,T *data_col,CPUContext *,const int groups,const T & zero_point)'];
filler_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 192;  4; 17;4;  169; 0;91;84;46;37;0.02;5;['    GetIm2ColGradient', '    GetCol2ImGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCol2Im', '    CAFFE_ANONYMOUS_VARIABLE_CPUIm2Col', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Col2Im', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Im2Col', '    GetGradientDefs', '    GetGradientDefs', '    vector', '    vector'];
flatten_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 42;  2; 6;4;  32; 0;13;20;8;12;0.06;1;['    final', '    final'];['    Col2ImOp(Args,...)', '    GetSingleArgument', '    Im2ColOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
mul_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 85;  2; 9;5;  71; 0;41;31;23;22;0.03;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACol2Im', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIm2Col'];
sigmoid_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 39;  2; 7;5;  27; 0;12;17;4;8;0.07;1;[];['    col2im_shape_check(const Tensor & input,const Tensor & grad_output,int64_t output_height,int64_t output_width,int64_t kernel_height,int64_t kernel_width,int64_t dilation_height,int64_t dilation_width,int64_t pad_height,int64_t pad_width,int64_t stride_height,int64_t stride_width)', '    im2col_shape_check(const Tensor & input,const Tensor & grad_output,int64_t kernel_height,int64_t kernel_width,int64_t dilation_height,int64_t dilation_width,int64_t pad_height,int64_t pad_width,int64_t stride_height,int64_t stride_width)', '    ndimension', '    numel', '    size'];
sigmoid_cross_entropy_with_logits_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 86;  3; 14;4;  67; 0;37;35;22;25;0.04;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUImageInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ImageInput'];
sparse_lengths_sum_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 97;  4; 14;5;  77; 0;42;44;28;27;0.05;3;['    final'];['    ApplyTransformOnGPU(const std::vector & dims,const c10::Device & type)', '    Brightness(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    MessageLogger(,,INFO)', '    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    color_lighting_eigvals_', '    ColorJitter(float *img,const int img_size,const float saturation,const float brightness,const float contrast,std::mt19937 *randgen)', '    ColorLighting(float *img,const int img_size,const float alpha_std,const std::vector,const std::vector & eigvals,std::mt19937 *randgen)', '    ColorNormalization(float *img,const int img_size,const int channels,const std::vector & mean,const std::vector & std)', '    Contrast(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    CropTransposeImage(const cv::Mat & scaled_img,const int channels,uint8_t *cropped_data,const int crop,const bool mirror,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_image,bool is_test)', '    DecodeAndTransform(const std::string & value,float *image_data,int item_id,const int channels,std::size_t thread_index)', '    DecodeAndTransposeOnly(const std::string & value,uint8_t *image_data,int item_id,const int channels,std::size_t thread_index)', '    dims', '    GetImageAndLabelAndInfoFromDBValue(const string & value,cv::Mat *img,PerImageArg & info,int item_id,std::mt19937 *randgen)', '    jitter_order', '    num_decode_errors_in_batch_', '    OutputTensorCopyFrom(,type,prefetched_image_on_device_,)', '    OutputTensorCopyFrom(,type,prefetched_label_on_device_,)', '    OutputTensorCopyFrom(i,type,[i-2] prefetched_additional_outputs_on_device_,)', '    RandomSizedCropping(cv::Mat *img,const int crop,std::mt19937 *randgen)', '    ReinitializeTensor(& prefetched_image_,,int64_t crop_,int64_t crop_,int64_t color_,at::dtype)', '    ReinitializeTensor(& prefetched_label_,sizes,at::dtype)', '    Saturation(float *img,const int img_size,const float alpha_rand,std::mt19937 *randgen)', '    sizes', '    sizes', '    TransformImage(const cv::Mat & scaled_img,const int channels,float *image_data,const bool color_jitter,const float saturation,const float brightness,const float contrast,const bool color_lighting,const float color_lighting_std,const std::vector,const std::vector & color_lighting_eigvals,const int crop,const bool mirror,const std::vector & mean,const std::vector & std,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_image,bool is_test)', '    CopyPrefetched', '    ImageInputOp(const OperatorDef & operator_def,Workspace *ws)', '    Prefetch', '    ~ImageInputOp', '    GetCastDataType', '    cvtColor', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *image_data,int item_id,const int channels,std::size_t thread_index)', '    DecodeAndTransposeOnly(const std::string & value,uint8_t *image_data,int item_id,const int channels,std::size_t thread_index)', '    GetImageAndLabelAndInfoFromDBValue(const string & value,cv::Mat *img,PerImageArg & info,int item_id,std::mt19937 *randgen)', '    ImageInputOp(const OperatorDef & operator_def,Workspace *ws)', '    Prefetch', '    srand', '    time', '    now', '    byte_data', '    data_type', '    dims', '    dims_size', '    float_data', '    float_data_size', '    int32_data', '    int32_data_size', '    size', '    string_data', '    string_data_size'];
fc_inference.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  1; 9;1;  51; 0;33;36;20;25;0.02;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAImageInput'];
fc_inference.h;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 2;5;  10; 0;1;10;0;3;0.10;0;['    final'];['    obj_loader', '    reader', '    import_ir_module(std::shared_ptr cu,std::istream & in,c10::optional device,ExtraFilesMap & extra_files)', '    import_ir_module(std::shared_ptr cu,const std::string & filename,c10::optional device,ExtraFilesMap & extra_files)', '    import_ir_module(std::shared_ptr cu,std::unique_ptr rai,c10::optional device,ExtraFilesMap & extra_files)', '    load(const std::string & filename,c10::optional device,ExtraFilesMap & extra_files)', '    load(std::unique_ptr rai,c10::optional device,ExtraFilesMap & extra_files)', '    load(std::istream & in,c10::optional device,ExtraFilesMap & extra_files)', '    postSetStateValidate(const IValue & v)', '    readArchiveAndTensors(const std::string & archive_name,c10::optional type_resolver,c10::optional obj_loader,c10::optional device,PyTorchStreamReader & stream_reader)', '    deserialize(c10::optional device,ExtraFilesMap & extra_files)', '    readArchive(const std::string & archive_name)', '    ScriptModuleDeserializer(std::shared_ptr cu,std::unique_ptr reader)'];
feature_maps_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 405;  8; 75;2;  323; 0;226;205;58;126;0.02;42;['    final'];['    find_custom_class_with_setstate', '    obj_loader', '    reader', '    _load_for_mobile(std::istream & in,c10::optional device)', '    _load_for_mobile(const std::string & filename,c10::optional device)', '    _load_for_mobile(std::unique_ptr rai,c10::optional device)', '    expect_field(IValue tup,const std::string & expected_name,size_t entry)', '    parseMethods(const std::vector & vals,mobile::CompilationUnit & mcu)', '    print_unsupported_ops_and_throw(const std::unordered_set & unsupported_ops)', '    BytecodeDeserializer(std::unique_ptr reader)', '    deserialize(c10::optional device)', '    readArchive(const std::string & archive_name,std::shared_ptr mcu)'];
feed_blob_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 18;  1; 4;1;  13; 0;10;13;1;9;0.08;2;[];[];
feed_blob_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  1; 8;5;  21; 0;4;9;23;28;0.05;2;[];['    _load_for_mobile(std::istream & in,c10::optional device)', '    _load_for_mobile(const std::string & filename,c10::optional device)', '    _load_for_mobile(std::unique_ptr rai,c10::optional device)'];
filler_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 693;  3; 397;1;  293; 0;239;260;14;137;0.01;21;[];[];
find_duplicate_elements_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 68;  2; 43;1;  24; 0;17;22;1;11;0.08;2;[];['    expect_field(IValue tup,const std::string & expected_name,size_t entry)', '    moduleMethodsTuple(const Module & module,std::vector & elements)'];
find_duplicate_elements_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 56;  3; 12;8;  35; 0;15;31;27;48;0.09;4;[];['    findSourceInArchiveFromQualifier(caffe2::serialize::PyTorchStreamReader & reader,const std::string & export_prefix,const std::string & qualifier)', '    qualifierToArchivePath(const std::string & qualifier,const std::string & export_prefix)'];
find_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  1; 9;1;  16; 0;14;16;1;6;0.06;2;[];['    findSourceInArchiveFromQualifier(caffe2::serialize::PyTorchStreamReader & reader,const std::string & export_prefix,const std::string & qualifier)', '    qualifierToArchivePath(const std::string & qualifier,const std::string & export_prefix)'];
flatten_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 84;  1; 47;1;  36; 0;28;34;3;15;0.03;4;['    final'];['    LEGACY_deserialize(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)', '    LEGACY_convertModule(const torch::ModuleDef & module_def)', '    LEGACY_deserialize', '    LEGACY_loadPickleArchive(const std::string & name)', '    LEGACY_loadTensor(const torch::TensorDef & tensor_proto,std::unordered_map & storageMap)', '    LEGACY_loadTensorTable(torch::ModelDef *model_def)', '    LEGACY_moduleSetState(const Module & module,IValue state)', '    ClassResolver(SourceImporter source_importer)', '    resolveType(const std::string & name,const SourceRange & loc)', '    ScriptModuleDeserializer(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)'];
flatten_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  2; 9;4;  48; 0;24;22;34;39;0.04;3;[];['    LEGACY_deserialize(std::shared_ptr cu,std::unique_ptr reader,const c10::optional & device)'];
flexible_top_k.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 182;  8; 39;2;  135; 0;89;81;52;67;0.06;9;[];['    definitions', '    resolvers', '    attr(const SourceRange & loc,Function & m,const std::string & name)', '    ClassNamespaceValue(c10::QualifiedName name,std::shared_ptr si)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    ConstantTableValue(const std::vector *constants)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    OpsValue(size_t version)', '    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    loadNamedType(const QualifiedName & name)', '    SourceImporter(std::shared_ptr cu,const std::vector *tensor_table,SourceLoader loader,size_t version)', '    findFunction(const QualifiedName & name)', '    findNamedType(const QualifiedName & name)', '    importClass(const QualifiedName & qualified_classname,const ClassDef & class_def,bool is_module)', '    importFunction(const std::string & qualifier,const Def & def)', '    importNamedTuple(const QualifiedName & qualified_name,const ClassDef & named_tuple_def)', '    importNamedType(const std::string & qualifier,const ClassDef & class_def)', '    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    parseImports(Lexer & L)', '    parsePossibleVersionNumber(Lexer & L)', '    parseSourceIfNeeded(const std::string & qualifier)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    SourceImporterImpl(const std::shared_ptr cu,const std::vector *tensor_table,SourceLoader source_loader,size_t version)'];
floor_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 73;  2; 52;2;  18; 0;15;18;1;9;0.11;2;[];['    LEGACY_import_methods(const Module & mod,const std::shared_ptr & src)', '    loadNamedType(const QualifiedName & name)', '    SourceImporter(std::shared_ptr cu,const std::vector *tensor_table,SourceLoader loader,size_t version)', '    ~SourceImporter'];
floor_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  2; 8;7;  18; 0;7;11;21;33;0.11;3;[];['    in_place', '    in_place_index_t', '    in_place_t', '    in_place_type_t'];
free_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 15;  1; 3;1;  11; 0;8;11;1;9;0.09;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUIndexHash', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexHash'];
free_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 6;  1; 1;2;  3; 0;1;3;1;5;0.33;1;['    IndexHashOp'];['    schema_IndexHash', '    DoRunWithType', '    GetSingleArgument', '    hash(T id)', '    IndexHashOp(Args,...)', '    RunOnDevice'];
fully_connected_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 239;  6; 84;3;  152; 0;108;121;30;67;0.04;12;['    IndexCreateOp', '    IndexDeserializer', '    IndexFreezeOp', '    IndexGetOp', '    IndexLoadOp', '    IndexSerializer', '    IndexSizeOp', '    IndexStoreOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUIndexFreeze', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexLoad', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUIndexStore', '    CAFFE_ANONYMOUS_VARIABLE_CPUIntIndexCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPULongIndexCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPUStringIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexFreeze', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexLoad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexSize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IndexStore', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LongIndexCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StringIndexCreate', '    noexcept', '    isFrozen', '    maxElements', '    IndexCreateOp(Args,...)', '    RunOnDevice', '    Deserialize(const BlobProto & proto,Blob *blob)', '    doLoad(std::unique_ptr *base,int64_t maxElements,const Tensor & tensor_in)', '    IndexFreezeOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexGetOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexLoadOp(Args,...)', '    RunOnDevice', '    doStore(const std::unique_ptr & base,Tensor *tensor_out)', '    IndexSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    ~IndexSerializer', '    IndexSizeOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    IndexStoreOp(Args,...)', '    RunOnDevice'];
fully_connected_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 334;  31; 32;8;  278; 0;204;82;100;90;0.11;14;[];['    Freeze', '    frozen_', '    isFrozen', '    maxElements', '    nextId_', '    Size', '    Type', '    ~IndexBase', '    frozen_', '    IndexBase(int64_tValue maxElements,const TypeMeta & type)', '    FrozenGet(const T *keys,int64_tValue *values,size_t numKeys)', '    Get(const T *keys,int64_tValue *values,size_t numKeys)', '    Index(int64_tValue maxElements)', '    Load(const T *keys,size_t numKeys)', '    Store(Tensor *out)', '    Resize', '    Make'];
fused_rowwise_8bit_conversion_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 339;  11; 87;2;  249; 0;172;177;16;78;0.04;19;[];['    checkIndexTensorTypes(TensorList indices)', '    expandTensors(const Tensor & self,TensorList indices)', '    hasContiguousSubspace(TensorList tl)', '    if_empty_then(::c10::str __VA_ARGS__,)', '    AdvancedIndex(const Tensor & src,TensorList indices_list)', '    find_if', '    move(transposedIndices)', '    move(invPerm)'];
fused_rowwise_8bit_conversion_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 182;  11; 30;16;  128; 0;81;56;82;95;0.09;6;[];['    is_constant_index(int ntensor,const int64_t *strides)', '    cpu_masked_fill_kernel(TensorIterator & iter,scalar_t value)', '    index_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride)', '    index_put_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride,bool accumulate)', '    masked_fill_kernel(TensorIterator & iter,Scalar value)', '    cpu_index_kernel(TensorIterator & iter,IntArrayRef index_size,IntArrayRef index_stride,const func_t & f,bool serial_execution)', '    get(int64_t idx)', '    Indexer(int64_t num_indexers,char **indexers,const int64_t *indexer_strides,IntArrayRef original_sizes,IntArrayRef original_strides)'];
fused_rowwise_nbit_conversion_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 303;  16; 67;3;  231; 0;166;182;13;78;0.07;17;[];['    pytorch_qnnp_indirection_init_conv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_deconv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_dwconv2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)', '    pytorch_qnnp_indirection_init_maxpool2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)'];
fused_rowwise_nbitfake_conversion_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 272;  18; 34;8;  200; 27;111;122;26;65;0.09;12;[];['    pytorch_qnnp_indirection_init_conv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_deconv2d(pytorch_qnnp_operator_t op,size_t output_tile_size,size_t tiled_output_size)', '    pytorch_qnnp_indirection_init_dwconv2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)', '    pytorch_qnnp_indirection_init_maxpool2d(pytorch_qnnp_operator_t op,size_t batch_start,size_t step_height,size_t step_width)'];
fused_rowwise_nbitfake_conversion_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 139;  13; 23;15;  88; 5;49;56;21;36;0.15;4;[];['    findSchemaDifferences(const FunctionSchema & lhs,const FunctionSchema & rhs)'];
fused_rowwise_random_quantization_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 204;  12; 49;12;  122; 10;95;82;38;48;0.10;6;[];[];
gather_fused_8bit_rowwise_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 41;  1; 8;1;  32; 0;28;30;1;7;0.03;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInferenceLSTM', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InferenceLSTM', '    RunOnDevice'];
gather_fused_8bit_rowwise_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  3; 13;4;  46; 0;26;25;40;49;0.07;4;['    InferenceLSTMOp'];['    _lstm_impl(const Tensor & input,const std::vector & params,const Tensor & hx,const Tensor & cx,int64_t num_layers,bool bidirectional,CPUContext *context)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    schema_LSTMOp', '    gather_params(const std::vector & params,bool has_biases,CPUContext *context)', '    CellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,CPUContext *_context)', '    CellParams(const CellParams & rhs)', '    initParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,CPUContext *_context)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    operator=(const CellParams & rhs)', '    FullBidirectionalLSTMLayer(LSTMCell & cell,CPUContext *context)', '    operator()(const Tensor & input,const bidir_hidden_type & input_hidden,const param_type & params)', '    reverse(std::vector)', '    FullLSTMLayer(LSTMCell & cell,CPUContext *context)', '    operator()(const std::vector & step_inputs,const std::tuple & input_hidden,const CellParams & params)', '    operator()(const Tensor & inputs,const std::tuple & input_hidden,const CellParams & params)', '    operator()(const Tensor & input,const hidden_type & input_hidden,const param_type & params)', '    ~Layer', '    LayerOutput(const output_type & _outputs,const hidden_type & _hidden)', '    LSTMCell(CPUContext *context)', '    operator()(const Tensor & input,const t_tuple & hidden,const CellParams & params)', '    GetSingleArgument', '    InferenceLSTMOp(Args,...)', '    RunOnDevice'];
gather_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 151;  14; 64;1;  73; 0;50;51;7;48;0.19;5;[];[];
gather_ranges_to_dense_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 106;  2; 54;1;  51; 0;46;51;1;10;0.04;2;[];['    infer_size(IntArrayRef shape,int64_t numel)'];
gather_ranges_to_dense_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 227;  15; 21;14;  179; 0;93;68;112;89;0.08;5;[];['    init', '    init_win(PINIT_ONCE InitOnce,PVOID Parameter,PVOID *lpContex)', '    pytorch_qnnp_deinitialize', '    pytorch_qnnp_initialize'];
gelu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 134;  8; 21;15;  95; 0;59;57;23;38;0.08;10;['    C10FlagParser_caffe2_version', '    State'];['    GlobalInit(int *pargc,char ***pargv)', '    GlobalInitAlreadyRun', '    GlobalInitState', '    GlobalInit', '    init_state_guard', '    unsafeRunCaffe2InitFunction(const char *name,int *pargc,char ***pargv)', '    Registry', '    C10FlagParser_caffe2_version(const std::string & content)'];
generate_proposals_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 456;  67; 57;3;  332; 0;197;203;78;266;0.20;12;[];['    cast(Item src,return_value_policy policy,handle parent)', '    load(handle src,bool convert)', '    bind_ordered_dict(py::module module,const char *dict_name)', '    init_bindings(PyObject *module)', '    cast(Item src,return_value_policy policy,handle parent)', '    load(handle src,bool convert)'];
generate_proposals_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 180;  44; 23;8;  108; 0;36;89;23;73;0.41;36;['    PythonStore'];['    python_functions', '    c10d_init(PyObject *_unused)', '    add(const std::string & key,int64_t value)', '    split(char separator,const std::string & string)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)'];
generate_proposals_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 643;  8; 24;9;  201; 403;148;70;48;47;0.04;12;['    BufferAdapter'];['    initJITBindings(PyObject *module)', '    loadPythonClasses', '    BufferAdapter(const py::object & buffer)', '    getMemview(void *buf,size_t n)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size'];
generate_proposals_op_util_boxes.h;C++;pytorch-master/pytorch-master/caffe2/operators; 396;  96; 53;5;  253; 0;176;153;131;98;0.38;11;[];['    python_functions', '    rpc_init(PyObject *)'];
generate_proposals_op_util_boxes_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 139;  22; 23;3;  106; 0;85;47;26;30;0.21;4;[];[];
generate_proposals_op_util_nms.h;C++;pytorch-master/pytorch-master/caffe2/operators; 795;  166; 97;8;  541; 0;355;271;242;231;0.31;19;[];['    initThroughputBenchmarkBindings(PyObject *module)'];
generate_proposals_op_util_nms_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 706;  138; 96;10;  474; 0;360;211;189;194;0.29;45;[];['    _calculate_fan_in_and_fan_out(const Tensor & tensor)', '    calculate_gain(NonlinearityType nonlinearity,double param)', '    calculate_kaiming_std(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    constant_(Tensor tensor,Scalar)', '    dirac_(Tensor tensor)', '    eye_(Tensor matrix)', '    Fan(Tensor & tensor)', '    kaiming_normal_(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    kaiming_uniform_(Tensor tensor,double a,FanModeType mode,NonlinearityType nonlinearity)', '    normal_(Tensor tensor,double mean,double std)', '    ones_(Tensor tensor)', '    orthogonal_(Tensor tensor,double gain)', '    sparse_(Tensor tensor,double sparsity,double std)', '    uniform_(Tensor tensor,double low,double high)', '    xavier_normal_(Tensor tensor,double gain)', '    xavier_uniform_(Tensor tensor,double gain)', '    zeros_(Tensor tensor)'];
generate_proposals_op_util_nms_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 529;  74; 65;3;  419; 0;337;154;122;106;0.18;17;[];['    multiprocessing_init(PyObject *_unused,PyObject *noargs)', '    python_functions'];
given_tensor_byte_string_to_uint8_fill_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 74;  2; 40;1;  33; 0;28;31;1;10;0.06;2;[];['    autocast_decrement_nesting(PyObject *_unused,PyObject *arg)', '    autocast_increment_nesting(PyObject *_unused,PyObject *arg)', '    clear_autocast_cache(PyObject *_unused,PyObject *arg)', '    is_anomaly_mode_enabled(PyObject *_unused,PyObject *arg)', '    is_autocast_enabled(PyObject *_unused,PyObject *arg)', '    is_grad_enabled(PyObject *_unused,PyObject *arg)', '    set_anomaly_mode_enabled(PyObject *_unused,PyObject *arg)', '    set_autocast_enabled(PyObject *_unused,PyObject *arg)', '    set_grad_enabled(PyObject *_unused,PyObject *arg)', '    THPAutograd_initExtension(PyObject *_unused,PyObject *unused)', '    python_functions'];
given_tensor_fill_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 237;  8; 50;1;  186; 0;169;178;7;57;0.04;14;[];['    accumulateGradVar(PyObject *_self,void *_unused)', '    addClass(PyObject *module,PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    getTupleAttr(PyObject *obj,void *_unused)', '    getValueAttr(PyObject *obj,void *_unused)', '    THPAutograd_initFunctions', '    operator()(PyObject *args)', '    operator()(PyObject *args)'];
given_tensor_fill_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 91;  5; 7;7;  73; 0;46;61;49;50;0.07;4;[];['    check_exact_values(const std::vector & parameters,const std::vector)', '    check_initializer_against_baseline(std::function initializer,std::vector)', '    initializer', '    initializer', '    initializer', '    initializer', '    parameters', '    TEST(InitTest,ProducesPyTorchValues_XavierUniform)', '    TEST(InitTest,ProducesPyTorchValues_XavierNormal)', '    TEST(InitTest,ProducesPyTorchValues_KaimingNormal)', '    TEST(InitTest,ProducesPyTorchValues_KaimingUniform)', '    TEST(InitTest,CanInitializeTensorThatRequiresGrad)', '    TEST(InitTest,CalculateGainWithTanh)', '    TEST(InitTest,CalculateGainWithRelu)', '    TEST(InitTest,CalculateGainWithLeakyRelu)', '    TEST(InitTest,CanInitializeCnnWithOrthogonal)'];
glu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 57;  2; 10;2;  45; 0;27;34;11;24;0.04;4;[];['    initONNXBindings(PyObject *module)'];
group_norm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 497;  29; 30;2;  439; 0;240;252;126;85;0.07;17;[];['    faulty_agent_init(PyObject *)', '    python_functions'];
group_norm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 316;  6; 24;10;  278; 0;137;166;102;137;0.02;6;[];['    python_functions', '    dist_autograd_init(PyObject *)'];
gru_unit_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 55;  1; 10;1;  44; 0;30;29;6;27;0.02;6;['    GlobalInitIsCalledGuard', '    InitRegisterer', '    Caffe2InitializeRegistry'];['    GlobalInit(int *pargc,char ***pargv)', '    GlobalInit', '    GlobalInitAlreadyRun', '    unsafeRunCaffe2InitFunction(const char *name,int *pargc,char ***pargv)', '    Registry', '    GlobalInitIsCalledGuard', '    InitRegisterer(internal::Caffe2InitializeRegistry::InitFunction function,bool run_early,const char *description,const char *name)', '    Caffe2InitializeRegistry', '    Register(InitFunction function,bool run_early,const char *description,const char *name)', '    RunNamedFunction(const char *name,int *pargc,char ***pargv)', '    RunRegisteredEarlyInitFunctions(int *pargc,char ***pargv)', '    RunRegisteredInitFunctions(int *pargc,char ***pargv)', '    RunRegisteredInitFunctionsInternal(vector,const char *,int *pargc,char ***pargv)'];
h_softmax_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 658;  53; 94;3;  514; 0;391;249;187;187;0.10;19;[];[];
h_softmax_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 180;  4; 17;9;  152; 0;25;98;109;163;0.03;8;[];[];
half_float_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 189;  4; 25;12;  134; 18;93;95;38;70;0.03;18;[];['    python_functions'];
half_float_ops_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 106;  8; 16;6;  77; 0;61;29;51;28;0.10;2;[];['    initJITBindings(PyObject *module)'];
hard_sigmoid_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 154;  8; 59;5;  88; 0;47;61;11;28;0.09;9;[];['    initONNXBindings(PyObject *module)'];
hard_sigmoid_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 41;  2; 11;5;  25; 0;0;23;0;9;0.08;2;[];['    initThroughputBenchmarkBindings(PyObject *module)'];
heatmap_max_keypoint_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  3; 9;8;  17; 0;1;13;17;31;0.18;1;[];['    tensor(,,,,,,)', '    tensor(,,,,,,,,,,,,,,)'];
activation_ops_miopen.h;C++;pytorch-master/pytorch-master/caffe2/operators/hip; 153;  10; 17;8;  120; 0;47;42;131;122;0.08;8;[];[];
if_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  1; 7;1;  12; 0;10;12;1;7;0.08;2;['    C10FlagParser_caffe2_quit_on_unsupported_cpu_feature'];['    WarnIfFeatureUnused(const bool cpu_has_feature,const string & feature)', '    Caffe2CheckIntrinsicsFeatures(int *,char ***)', '    QuitIfFeatureUnsupported(const bool cpu_has_feature,const string & feature)', '    C10FlagParser_caffe2_quit_on_unsupported_cpu_feature(const std::string & content)'];
if_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 4;2;  3; 0;1;3;1;5;0.33;1;['    C10FlagParser_caffe2_mkl_num_threads', '    C10FlagParser_caffe2_omp_num_threads'];['    C10FlagParser_caffe2_mkl_num_threads(const std::string & content)', '    C10FlagParser_caffe2_omp_num_threads(const std::string & content)'];
im2col_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 104;  1; 10;1;  93; 0;79;89;6;28;0.01;8;[];['    initQNNPACK'];
im2col_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 298;  3; 23;7;  267; 0;175;112;153;103;0.01;4;[];[];
index_hash_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 38;  3; 10;1;  27; 0;19;24;2;16;0.11;3;[];[];
index_hash_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 78;  4; 16;7;  53; 0;19;33;34;51;0.08;4;[];['    LateRegisterEarlyInitFunction', '    LateRegisterFailInitFunction', '    LateRegisterInitFunction', '    TEST(InitTest,TestInitFunctionHasRun)', '    TEST(InitTest,CanRerunGlobalInit)', '    TEST(InitTest,FailLateRegisterInitFunction)', '    TestFailInitFunction(int *,char ***)', '    TestInitFunction(int *,char ***)'];
index_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 355;  2; 62;10;  282; 0;162;180;76;135;0.01;40;[];['    initialTensorOptions'];
inference_lstm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  2; 6;1;  54; 0;35;35;11;28;0.04;4;[];['    canRunWithAutograd(Node *node)', '    InlineAutodiffSubgraphs(Block *block,size_t threshold)', '    InlineAutodiffSubgraphs(std::shared_ptr & graph,size_t threshold)', '    scanNode(Node *node,size_t threshold)'];
inference_lstm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 310;  6; 34;14;  261; 0;106;164;64;151;0.02;19;[];['    canRunWithAutograd(Node *node)', '    InlineAutodiffSubgraphs(std::shared_ptr & graph,size_t threshold)'];
instance_norm_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 268;  3; 19;4;  245; 0;124;127;86;57;0.01;9;[];['    basename(const std::string & name)', '    getPadding(size_t cursor,size_t filename_size,size_t size,std::string & padding_buf)', '    read_le_16(uint8_t *buf)', '    istream_read_func(void *pOpaque,mz_uint64 file_ofs,void *pBuf,size_t n)', '    ostream_write_func(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    ~PyTorchStreamReader', '    ~PyTorchStreamWriter', '    getAllRecords', '    getRecord(const std::string & name)', '    getRecordID(const std::string & name)', '    getRecordOffset(const std::string & name)', '    hasRecord(const std::string & name)', '    init', '    PyTorchStreamReader(const std::string & file_name)', '    PyTorchStreamReader(std::istream *in)', '    PyTorchStreamReader(std::unique_ptr in)', '    PyTorchStreamWriter(std::string file_name)', '    PyTorchStreamWriter(const std::function & writer_func)', '    read(uint64_t pos,char *buf,size_t n)', '    setup(const string & file_name)', '    valid(const char *what,const char *info)', '    valid(const char *what,const char *info)', '    writeEndOfFile', '    writeRecord(const std::string & name,const void *data,size_t size,bool compress)'];
instance_norm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 279;  2; 24;7;  248; 0;128;136;100;132;0.01;4;[];[];
integral_image_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 153;  15; 25;2;  118; 0;84;76;45;71;0.13;8;[];['    TEST(PyTorchStreamWriterAndReader,SaveAndLoad)'];
integral_image_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 38;  2; 9;7;  22; 0;0;15;34;54;0.09;2;[];['    InlineForkWait(const std::shared_ptr & graph)', '    InlineForkWait(Block *b,std::unordered_map & future_remap)'];
is_empty_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  2; 7;5;  14; 0;4;8;20;30;0.14;3;[];['    InlineForkWait(const std::shared_ptr & graph)'];
jsd_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 97;  7; 12;1;  82; 0;55;60;21;57;0.09;11;[];['    inlineForkedClosure(Node *fork_closure)', '    inlineForkedClosures(Block *block)', '    inlineForkedClosures(std::shared_ptr & to_clean)'];
jsd_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 29;  2; 6;7;  16; 0;0;10;34;55;0.13;4;[];['    inlineForkedClosures(std::shared_ptr & to_clean)'];
key_split_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  1; 6;5;  42; 0;19;26;44;46;0.02;2;[];['    InlineBlockBeforeNode(Node *before_node,Block *block)', '    inlineLoopCondition(Node *n)', '    inlineLoopCondition(Block *block)', '    InlineLoopCondition(std::shared_ptr & graph)'];
last_n_window_collector.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 197;  7; 52;5;  136; 0;101;75;82;76;0.05;5;[];['    InlineBlockBeforeNode(Node *before_node,Block *block)', '    InlineLoopCondition(std::shared_ptr & graph)'];
layer_norm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 296;  3; 39;5;  252; 0;115;171;43;104;0.01;12;[];[];
leaky_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 128;  1; 62;3;  63; 0;47;46;18;30;0.02;8;[];['    dev(DeviceIndex index)', '    i', '    i', '    TEST(InlineDeviceGuard,Constructor)', '    TEST(InlineDeviceGuard,ConstructorError)', '    TEST(InlineDeviceGuard,SetDevice)', '    TEST(InlineDeviceGuard,ResetDevice)', '    TEST(InlineDeviceGuard,SetIndex)', '    TEST(InlineOptionalDeviceGuard,Constructor)', '    TEST(InlineOptionalDeviceGuard,NullaryConstructor)', '    TEST(InlineOptionalDeviceGuard,SetDevice)', '    TEST(InlineOptionalDeviceGuard,SetIndex)', '    test_body', '    test_body', '    test_body'];
leaky_relu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 49;  1; 11;4;  34; 0;6;16;38;55;0.03;2;[];['    block(const Stream & stream)', '    device_index', '    device_type', '    flag', '    InlineEvent(const InlineEvent &)', '    InlineEvent', '    operator=(const InlineEvent &)', '    operator=(InlineEvent)', '    query', '    record(const Stream & stream)', '    recordOnce(const Stream & stream)', '    swap(InlineEvent)', '    was_marked_for_recording', '    ~InlineEvent', '    device_type_', '    flag_', '    InlineEvent', '    InlineEvent(const DeviceType _device_type,const EventFlag _flag)'];
length_split_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 37;  2; 17;1;  18; 0;15;18;1;9;0.11;2;[];['    Inline(Graph & graph)', '    inlineCalls(Block *block)'];
lengths_pad_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 60;  1; 26;1;  33; 0;30;33;1;9;0.03;2;[];['    Inline(Graph & graph)'];
lengths_pad_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 88;  5; 19;5;  61; 0;32;35;52;57;0.08;4;['    InlineOptionalStreamGuard', '    InlineStreamGuard'];['    current_stream', '    InlineOptionalStreamGuard', '    InlineOptionalStreamGuard(optional stream_opt)', '    InlineOptionalStreamGuard(Args,...)', '    InlineOptionalStreamGuard', '    operator=', '    original_stream', '    reset', '    reset_stream(Stream stream)', '    current_device', '    current_stream', '    InlineStreamGuard(Stream stream)', '    InlineStreamGuard(Stream stream,const DeviceGuardImplInterface *impl)', '    InlineStreamGuard', '    InlineStreamGuard', '    InlineStreamGuard', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_device', '    reset_stream(Stream stream)', '    ~InlineStreamGuard', '    has_value', '    value'];
lengths_reducer_fused_8bit_rowwise_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 111;  4; 14;2;  95; 0;81;86;3;25;0.04;6;[];['    dev(DeviceIndex index)', '    stream(DeviceIndex index,StreamId sid)', '    TEST(InlineStreamGuard,Constructor)', '    TEST(InlineStreamGuard,ResetStreamSameSameDevice)', '    TEST(InlineStreamGuard,ResetStreamDifferentSameDevice)', '    TEST(InlineStreamGuard,ResetStreamDifferentDevice)', '    TEST(InlineOptionalStreamGuard,Constructor)', '    TEST(InlineOptionalStreamGuard,ResetStreamSameDevice)', '    TEST(InlineOptionalStreamGuard,ResetStreamDifferentDevice)'];
lengths_reducer_fused_nbit_rowwise_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 578;  16; 62;2;  514; 0;444;461;15;121;0.03;30;[];['    CheckInplace(Block *block)', '    CheckInplace(std::shared_ptr & graph)'];
lengths_reducer_fused_nbit_rowwise_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 562;  18; 38;22;  233; 262;141;125;135;119;0.08;8;[];['    CheckInplace(std::shared_ptr & graph)'];
lengths_reducer_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 146;  7; 13;5;  125; 0;106;87;19;61;0.06;14;['    OurAdapter', '    OurAdapter'];['    OurAdapter(const char *data,size_t size)', '    OurAdapter(const std::function & read_func,const std::function & size_func)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    size', '    InputArchive', '    keys', '    load_from(const std::string & filename,c10::optional device)', '    load_from(std::istream & stream,c10::optional device)', '    load_from(const char *data,size_t size,c10::optional device)', '    load_from(const std::function & read_func,const std::function & size_func,c10::optional device)', '    read(const std::string & key,c10::IValue & ivalue)', '    read(const std::string & key,Tensor & tensor,bool is_buffer)', '    read(const std::string & key,InputArchive & archive)', '    try_read(const std::string & key,c10::IValue & ivalue)', '    try_read(const std::string & key,Tensor & tensor,bool is_buffer)', '    try_read(const std::string & key,InputArchive & archive)'];
lengths_reducer_rowwise_8bit_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 233;  0; 53;2;  178; 0;158;166;6;49;0.00;12;[];[];
lengths_reducer_rowwise_8bit_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 184;  4; 21;10;  151; 0;87;80;107;144;0.03;10;[];['    accumulate(std::vector & buffer,const size_t pos,Variable)', '    event', '    event', '    guard', '    stream_guard', '    variables(InputBuffer)', '    add(size_t pos,Variable,const c10::optional & opt_producer_stream,const c10::optional & opt_consumer_stream)', '    device'];
lengths_tile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 97;  8; 31;1;  59; 0;45;45;35;40;0.14;5;[];['    variables(InputBuffer)', '    add(size_t pos,Variable,const c10::optional & opt_producer_stream,const c10::optional & opt_consumer_stream)', '    device', '    InputBuffer(size_t size)', '    InputBuffer', '    InputBuffer', '    operator=', '    operator[](size_t pos)'];
lengths_top_k_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 156;  7; 23;1;  127; 0;96;84;51;65;0.06;9;[];[];
lengths_top_k_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  2; 11;8;  34; 0;2;24;42;63;0.06;2;[];['    InsertGuards(std::shared_ptr graph)', '    GuardInserter(std::shared_ptr graph)', '    insertGuards(Block *b)', '    removeProfilingNodes(Block *b)', '    run'];
listwise_l2r_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 263;  22; 42;16;  186; 0;127;85;79;107;0.12;11;[];['    InsertGuards(std::shared_ptr graph)'];
load_save_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 295;  8; 99;1;  189; 0;166;170;18;50;0.04;12;[];['    main(int argc,char **argv)'];
load_save_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 465;  31; 36;14;  386; 0;175;161;248;189;0.08;12;['    GetInstanceNormGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUInstanceNormGradient', '    ComputeInternalGradientsNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,T *ds,T *db)', '    GammaBetaBackward(const int64_t N,const int64_t C,const T *ds,const T *db,const T *mean,const T *rstd,T *dgamma,T *dbeta)', '    InstanceNormBackwardNCHW(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *ds,T *db)', '    InstanceNormBackwardNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *dY,const T *X,const T *ds,const T *db,const T *mean,const T *rstd,const T *gamma,T *dX,T *c1,T *c2,T *c3)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InstanceNormGradient', '    GetGradientDefs', '    ComputeMoments(const int64_t N,const int64_t C,const int64_t HxW,const float *X,float *mean,float *rstd)', '    RunOnDeviceWithOrderNHWC(const int64_t N,const int64_t C,const int64_t HxW,const float *dY,const float *X,const float *mean,const float *rstd,const float *gamma,float *dX,float *dgamma,float *dbeta)'];
load_save_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 19;  1; 3;2;  14; 0;4;8;3;32;0.07;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInstanceNorm', '    ComputeFusedParams(const int64_t N,const int64_t C,const T *mean,const T *rstd,const T *gamma,const T *beta,T *scale,T *bias)', '    InstanceNormForwardNHWC(const int64_t N,const int64_t C,const int64_t HxW,const T *X,const T *scale,const T *bias,T *Y)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_InstanceNorm', '    RunOnDeviceWithOrderNCHW(const int64_t N,const int64_t C,const int64_t HxW,const float *X,const float *gamma,const float *beta,float *Y,float *mean,float *rstd)'];
load_save_op_util.h;C++;pytorch-master/pytorch-master/caffe2/operators; 49;  5; 10;8;  29; 0;5;28;0;12;0.17;1;['    final', '    final'];['    ComputeMoments(int64_t N,int64_t C,int64_t HxW,const T *X,T *mean,T *rstd)', '    GetSingleArgument', '    InstanceNormGradientOp(Args,...)', '    InstanceNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mean,T *rstd)', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *dgamma,T *dbeta)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t HxW,const T *X,const T *gamma,const T *beta,T *Y,T *mean,T *rstd)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t HxW,const T *dY,const T *X,const T *mean,const T *rstd,const T *gamma,T *dX,T *dgamma,T *dbeta)'];
local_response_normalization_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 529;  25; 194;1;  310; 0;239;153;99;173;0.08;9;[];['    InstanceNormOptions(int64_t num_features)'];
local_response_normalization_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  6; 14;7;  70; 0;18;43;63;95;0.09;6;[];['    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    _check_input_dim(const Tensor & input)', '    pretty_print(std::ostream & stream)'];
locally_connected_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 165;  3; 40;4;  121; 0;81;55;19;97;0.02;22;[];[];
locally_connected_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 131;  10; 24;9;  90; 0;13;71;93;173;0.11;10;[];[];
locally_connected_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 27;  1; 6;3;  18; 0;8;10;8;33;0.06;8;[];[];
locally_connected_op_util.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  2; 5;2;  54; 0;29;22;6;4;0.04;2;[];['    supported_ops_in_mobile', '    isOpSupportedInMobile(OpCode op)', '    operator<<(std::ostream & out,Instruction inst)', '    operator<<(std::ostream & out,OpCode op)', '    OpInfo(OpCode op)', '    parseOpCode(const char *str)', '    toString(OpCode op)'];
locally_connected_op_util.h;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  3; 9;5;  47; 0;0;45;0;27;0.06;0;[];['    isOpSupportedInMobile(OpCode op)', '    Instruction(OpCode op,int32_t X,uint16_t N)'];
log_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 90;  2; 50;3;  37; 0;25;33;3;16;0.05;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Add', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AddRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Sum', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8SumRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Add', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AddRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Sum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SumRelu'];
log_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 4;2;  8; 0;1;3;1;5;0.13;1;['    final'];['    IDEEPInt8SumReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8SumReluOp'];
logit_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 88;  3; 17;5;  66; 0;43;41;15;30;0.05;8;['    final'];['    GetSingleArgument', '    Int8AddOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8AddOp', '    GetThreadPool'];
logit_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  2; 10;6;  26; 0;2;20;25;37;0.08;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AveragePool', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8AveragePoolRelu', '    AveragePoolDocGenerator(const char *dim,bool relu_fused)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AveragePool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8AveragePoolRelu'];
loss_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  4; 6;9;  18; 0;0;14;0;7;0.22;4;['    final'];['    Int8AveragePoolOp(Args,...)', '    qnnpackGlobalOperator_', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8AveragePoolOp'];
lp_pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 318;  14; 70;1;  235; 0;167;156;83;190;0.06;10;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ChannelShuffle', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ChannelShuffle'];
lpnorm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 175;  7; 62;4;  106; 0;88;70;27;38;0.07;8;['    final'];['    Int8ChannelShuffleOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ChannelShuffleOp', '    GetThreadPool'];
lstm_unit_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 52;  0; 10;1;  41; 0;27;25;6;27;0.00;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Concat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Concat'];
lstm_unit_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 307;  16; 32;6;  259; 0;151;143;114;138;0.06;10;['    final'];['    GetSingleArgument', '    Int8ConcatOp(Args,...)', '    RunOnDevice'];
lstm_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators; 318;  10; 24;5;  281; 0;177;105;103;125;0.04;18;['    final', '    final', '    final', '    IDEEPInt8ConvOp'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvSumRelu', '    IDEEPInt8ConvReluOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8ConvSumOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8ConvSumReluOp(const OperatorDef & operator_def,Workspace *ws)', '    ~IDEEPInt8ConvReluOp', '    ~IDEEPInt8ConvSumOp', '    ~IDEEPInt8ConvSumReluOp', '    IDEEPInt8ConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPInt8ConvOp'];
map_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 265;  3; 44;13;  207; 0;99;119;104;172;0.01;19;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Conv', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvRelu', '    ConvDocGenerator(const char *dim,bool relu_fused)'];
margin_ranking_criterion_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 110;  1; 27;3;  80; 0;55;57;23;50;0.01;8;['    final'];['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    Int8ConvOp(Args,...)', '    lastBatchSize_', '    lastInputHeight_', '    lastInputPointer_', '    lastInputWidth_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ConvOp'];
margin_ranking_criterion_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  2; 10;6;  26; 0;0;18;34;55;0.08;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ConvRelu'];
matmul_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 104;  7; 14;6;  79; 0;54;29;40;44;0.09;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ConvTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ConvTranspose'];
matmul_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  0; 4;2;  3; 0;1;3;1;5;0.00;1;['    final'];['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    Int8ConvTransposeOp(Args,...)', '    lastBatchSize_', '    lastInputHeight_', '    lastInputPointer_', '    lastInputWidth_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDeviceWithOrderNHWC', '    ~Int8ConvTransposeOp', '    GetThreadPool'];
max_pool_with_index_gpu.h;C++;pytorch-master/pytorch-master/caffe2/operators; 46;  5; 11;9;  22; 0;0;16;84;158;0.23;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Dequantize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Dequantize'];
mean_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 125;  7; 22;10;  90; 0;57;29;58;69;0.08;7;['    final'];['    IDEEPInt8DequantizeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    Y_fmt_', '    ~IDEEPInt8DequantizeOp'];
merge_id_lists_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 32;  0; 16;1;  15; 0;10;15;1;10;0.00;2;['    final'];['    Int8Dequantize(const uint8_t *in,float *out,const int64_t N,const float X_scale,const int32_t X_offset)', '    RunOnDevice'];
merge_id_lists_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 80;  7; 15;7;  53; 0;34;33;53;58;0.13;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8FC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8FC'];
minmax_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 157;  1; 98;1;  58; 0;56;58;2;13;0.02;4;['    final'];['    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    GetSingleArgument', '    Int8FCOp(const OperatorDef & operator_def,Workspace *ws)', '    lastBatchSize_', '    lastInputPointer_', '    lastOutputPointer_', '    qnnpackObject_', '    RunOnDevice', '    ~Int8FCOp', '    GetThreadPool'];
minmax_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 139;  2; 16;8;  115; 0;42;50;87;116;0.02;10;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Flatten', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Flatten'];
mod_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 99;  2; 54;3;  42; 0;31;34;7;17;0.05;3;['    Int8FlattenOp'];['    GetSingleArgument', '    Int8FlattenOp(Args,...)', '    RunOnDevice'];
moments_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 82;  2; 17;3;  62; 0;40;51;9;30;0.03;7;['    final'];['    axis_', '    axis_w_', '    IDEEPInt8FullyConnectedOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8FullyConnectedOp'];
moments_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 134;  2; 16;8;  110; 0;56;50;74;83;0.02;4;['    final', '    final'];['    IDEEPInt8GivenIntTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPInt8GivenTensorFillOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    values_', '    values_'];
multi_class_accuracy_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 85;  3; 12;1;  70; 0;57;47;24;27;0.04;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8GivenIntTensorFill', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8GivenTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GivenIntTensorFill', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8GivenTensorFill'];
negate_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  1; 7;1;  18; 0;10;16;7;17;0.06;4;['    final', '    final'];['    dtype', '    ExtractValues', '    Fill(Int8TensorCPU *output)', '    Int8GivenTensorFillOp(Args,...)', '    RunOnDevice', '    ExtractValues', '    Fill(Int8TensorCPU *output)', '    Int8GivenIntTensorFillOp(Args,...)', '    RunOnDevice', '    numel'];
negate_gradient_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 27;  4; 6;3;  16; 0;5;8;20;30;0.25;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8LeakyRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8LeakyRelu'];
negate_gradient_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 6;  1; 1;2;  3; 0;1;3;1;4;0.33;1;['    final'];['    GetSingleArgument', '    Int8LeakyReluOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8LeakyReluOp', '    GetThreadPool'];
negative_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  2; 5;5;  10; 0;2;6;2;3;0.20;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8MaxPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUInt8MaxPoolRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8MaxPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8MaxPoolRelu', '    MaxPoolDocGenerator(const char *dim,bool relu_fused)'];
negative_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 4;2;  8; 0;1;3;1;5;0.13;1;['    final'];['    Int8MaxPoolOp(Args,...)', '    qnnpackOperator_', '    RunOnDeviceWithOrderNHWC', '    ~Int8MaxPoolOp'];
ngram_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 13;  1; 3;3;  7; 0;2;5;1;9;0.14;2;['    final'];['    IDEEPInt8PoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPInt8PoolOp'];
no_default_engine_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  10; 6;6;  15; 0;5;6;18;28;0.67;3;['    final'];['    IDEEPInt8QuantizeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    Y_fmt_', '    ~IDEEPInt8QuantizeOp'];
norm_planar_yuv_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 56;  5; 9;4;  43; 0;29;25;37;50;0.12;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Quantize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Quantize'];
normalize_l1_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 41;  1; 7;3;  31; 0;17;21;11;16;0.03;3;['    final'];['    Int8Quantize(const float *in,uint8_t *out,const int64_t N,const float Y_scale,const int32_t Y_offset)', '    GetSingleArgument', '    RunOnDevice'];
normalize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 66;  1; 10;2;  54; 0;31;41;18;35;0.02;7;['    final'];['    IDEEPInt8ReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPInt8ReluOp'];
normalize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 105;  2; 18;8;  79; 0;36;56;48;85;0.03;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Relu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Relu', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)'];
numpy_tile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 18;  1; 4;1;  13; 0;11;13;1;7;0.08;2;['    final'];['    GetSingleArgument', '    Int8ReluOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8ReluOp', '    GetThreadPool'];
one_hot_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 359;  12; 109;3;  245; 0;188;180;112;134;0.05;16;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Reshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Reshape'];
one_hot_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 97;  4; 20;7;  68; 0;14;40;65;96;0.06;5;['    final'];['    DoRunWithType', '    GetSingleArgument', '    Int8ReshapeOp(Args,...)', '    RunOnDevice'];
onnx_while_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 82;  1; 51;1;  30; 0;28;30;1;7;0.03;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8ResizeNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8ResizeNearest'];
op_utils_cudnn.h;C++;pytorch-master/pytorch-master/caffe2/operators; 54;  13; 8;7;  20; 9;9;15;6;10;0.65;1;['    final'];['    GetRepeatedArgument', '    GetSingleArgument', '    Int8ResizeNearestOp(Args,...)', '    RunOnDevice'];
operator_fallback_gpu.h;C++;pytorch-master/pytorch-master/caffe2/operators; 110;  37; 9;8;  58; 0;30;17;53;40;0.64;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8RoIAlign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8RoIAlign'];
operator_fallback_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 82;  1; 11;4;  67; 0;43;35;35;34;0.01;7;['    final'];['    pre_calc_for_bilinear_interpolate(const int height,const int width,const int pooled_height,const int pooled_width,const int iy_upper,const int ix_upper,float roi_start_h,float roi_start_w,float bin_size_h,float bin_size_w,int roi_bin_grid_h,int roi_bin_grid_w,std::vector & pre_calc)', '    ROIAlignForward(const int nthreads,const uint8_t *bottom_data,const float & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,const float *bottom_rois,int roi_cols,uint8_t *top_data,const float x_scale,const float y_scale,const int32_t x_offset,const int32_t y_offset,StorageOrder order,bool continuous_coordinate)', '    ROIAlignForward(output_size,X,spatial_scale_,X,X,X,pooled_height_,pooled_width_,sampling_ratio_,R,R,Y,X,Y_scale,X,Y_offset,order_,aligned_)', '    GetSingleArgument', '    Int8RoIAlignOp(Args,...)', '    RunOnDevice'];
order_switch_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 91;  5; 14;6;  68; 0;44;28;62;75;0.07;6;[];['    TEST(Int8RoIAlign,RoIAlign)'];
order_switch_ops_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  3; 21;7;  140; 0;63;75;84;103;0.02;9;['    Int8TensorCPUDeserializer', '    Int8TensorCPUSerializer'];['    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)'];
order_switch_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 10;  1; 4;2;  4; 0;2;4;2;9;0.25;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Sigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Sigmoid'];
pack_rnn_sequence_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 93;  12; 13;8;  62; 0;39;33;45;53;0.19;3;['    final'];['    GetSingleArgument', '    Int8SigmoidOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8SigmoidOp', '    GetThreadPool'];
pack_segments.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 250;  13; 23;1;  215; 0;118;141;45;199;0.06;12;[];[];
pack_segments.h;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  3; 18;11;  65; 0;16;47;39;76;0.05;14;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Slice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Slice'];
pad_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 94;  14; 14;8;  63; 0;10;32;101;164;0.22;4;['    final'];['    DoRunWithType', '    GetSingleArgument', '    Int8SliceOp(Args,...)', '    RunOnDevice'];
partition_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 157;  6; 49;1;  104; 0;74;81;11;62;0.06;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Softmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Softmax'];
partition_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 316;  14; 43;5;  258; 0;143;123;172;166;0.05;12;['    final'];['    GetSingleArgument', '    Int8SoftmaxOp(const OperatorDef & operator_def,Workspace *ws)', '    qnnpackOperator_', '    RunOnDevice', '    ~Int8SoftmaxOp', '    GetThreadPool'];
percentile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  5; 8;8;  16; 0;0;12;17;31;0.31;1;[];['    biassetq(int8::Int8TensorCPU *dst,const std::vector & vs)', '    TEST(Int8,ReLU)', '    setq(int8::Int8TensorCPU *dst,const std::vector & vs)', '    TEST(Int8,DISABLED_LeakyReLU)', '    TEST(Int8,Softmax)', '    TEST(Int8,Sigmoid)', '    TEST(Int8,MaxPool)', '    TEST(Int8,AveragePool)', '    TEST(Int8,ResizeNearest)', '    TEST(Int8,ChannelShuffle)', '    TEST(Int8,Concat)', '    TEST(Int8,Add)', '    TEST(Int8,SumRelu)', '    TEST(Int8,Conv)', '    TEST(Int8,Grouped1x1Conv)', '    TEST(Int8,Conv2)', '    TEST(Int8,DepthwiseConv)', '    TEST(Int8,DepthwiseConv3x3)', '    TEST(Int8,DepthwiseConv5x5)', '    TEST(Int8,ConvTranspose)', '    TEST(Int8,FC)', '    TEST(Int8,GivenTensorFill)', '    TEST(Int8,GivenIntTensorFill)', '    TEST(Int8,QuantDeQuant)', '    TEST(Int8,Reshape)', '    TEST(Int8,Flatten)', '    TEST(Int8,Slice)', '    TEST(Int8,DISABLED_Transpose)'];
perplexity_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 39;  1; 13;1;  25; 0;18;19;7;16;0.04;3;[];['    add_input(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    addErrorTolerance(float scale)', '    biasdq(const int8::Int8TensorCPU & XQ)', '    biasq(const std::vector & dims,double scale)', '    dq(const int8::Int8TensorCPU & XQ)', '    int8Copy(int8::Int8TensorCPU *dst,const int8::Int8TensorCPU & src)', '    q(const std::vector & dims)', '    randomInt(int a,int b)', '    CreateBlob'];
perplexity_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 19;  2; 5;5;  9; 0;0;6;17;28;0.22;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUInt8Transpose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8Transpose'];
piecewise_linear_transform_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 254;  17; 31;6;  202; 0;114;99;127;112;0.08;12;['    final'];['    GetSingleArgument', '    Int8TransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
pool_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 941;  21; 50;3;  888; 0;385;595;167;240;0.02;42;['    Activation'];['    initQNNPACK', '    activationLimits(float scale,int32_t zero_point,Activation Ac)', '    CalculateInputRadius(int input_integer_bits,int input_left_shift)', '    MultiplyByQuantizedMultiplierGreaterThanOne(int32_t x,int32_t quantized_multiplier,int left_shift)', '    MultiplyByQuantizedMultiplierSmallerThanOne(int32_t x,int32_t quantized_multiplier,int right_shift)', '    QuantizeMultiplierGreaterThanOne(double double_multiplier,int32_t *quantized_multiplier,int *left_shift)', '    QuantizeMultiplierSmallerThanOne(double double_multiplier,int32_t *quantized_multiplier,int *right_shift)', '    QuantizeUint8(float scale,int32_t zero_point,float value)', '    Round(const T x)', '    frexp'];
pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 1130;  34; 174;202;  728; 0;313;546;202;210;0.05;44;['    GetIntegralImageGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUIntegralImage', '    CAFFE_ANONYMOUS_VARIABLE_CPUIntegralImageGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntegralImage', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IntegralImageGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
pool_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 564;  6; 53;10;  496; 1;208;233;156;178;0.01;21;['    final', '    final'];['    IntegralImageGradientOp(Args,...)', '    IntegralImageOp(Args,...)', '    RunOnDevice'];
pool_op_util.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 361;  3; 10;16;  104; 231;46;54;46;7;0.03;4;['    CartPole'];['    finishEpisode', '    forward', '    forward', '    forward', '    selectAction', '    TEST_F(IntegrationTest,CartPole)', '    TEST_F(IntegrationTest,MNIST_CUDA)', '    TEST_F(IntegrationTest,MNISTBatchNorm_CUDA)', '    test_mnist(size_t batch_size,size_t number_of_epochs,bool with_cuda,M,F,O)', '    CartPole', '    getReward', '    getState', '    isDone', '    reset', '    step(int action)'];
pool_op_util.h;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  3; 8;5;  52; 0;0;52;0;6;0.06;0;[];['    do_trapz(const Tensor & y,const Tensor & dx,int64_t dim)', '    do_trapz(const Tensor & y,double dx,int64_t dim)', '    trapz(const Tensor & y,const Tensor & x,int64_t dim)', '    trapz(const Tensor & y,double dx,int64_t dim)', '    zeros_like_except(const Tensor & y,int64_t dim)'];
pow_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 136;  10; 10;10;  113; 0;57;45;61;54;0.09;3;[];['    canFuseOnCPU', '    canFuseOnGPU', '    debugGetFusedKernelCode(Graph & graph,at::ArrayRef inputs)', '    debugLaunchGraph(Graph & graph,at::ArrayRef inputs)', '    nCompiledKernels', '    overrideCanFuseOnCPU(bool value)', '    overrideCanFuseOnGPU(bool value)', '    registerFusion(const Node *fusion_group)', '    runFusion(const int64_t key,Stack & stack)'];
prefetch_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 142;  29; 14;8;  95; 0;55;26;48;18;0.31;5;[];['    canFuseOnCPU', '    canFuseOnGPU', '    debugGetFusedKernelCode(Graph & graph,at::ArrayRef inputs)', '    debugLaunchGraph(Graph & graph,at::ArrayRef inputs)', '    nCompiledKernels', '    overrideCanFuseOnCPU(bool value)', '    overrideCanFuseOnGPU(bool value)', '    registerFusion(const Node *fusion_group)', '    runFusion(const int64_t key,Stack & stack)'];
prelu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 357;  10; 84;13;  161; 94;129;78;66;61;0.06;8;[];['    globalStrings', '    domain_prefix', '    domainString', '    fromDomainAndUnqualString(const std::string & d,const std::string & s)', '    fromQualString(const std::string & s)', '    ns', '    toDisplayString', '    toQualString', '    toUnqualString', '    _symbol(const std::string & s)', '    customString(Symbol sym)', '    ns(Symbol sym)', '    string(Symbol sym)', '    symbol(const std::string & s)'];
prepend_dim_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 46;  2; 11;1;  33; 0;23;29;5;22;0.06;7;[];[];
prepend_dim_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  4; 17;7;  69; 0;31;26;64;65;0.06;4;[];['    _symbol(const std::string & s)', '    customString(Symbol sym)', '    InternedStrings', '    ns(Symbol sym)', '    symbol(const std::string & s)'];
prepend_dim_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;2;  4; 0;2;4;2;9;0.25;2;[];['    InterpreterState(std::shared_ptr code)', '    reg(size_t reg)', '    run(Stack & stack)'];
quant_decode_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 170;  11; 28;19;  117; 0;54;68;90;134;0.09;9;[];['    build_bailout_graph', '    Code(const std::shared_ptr & graph,std::string function_name,size_t remaining_bailout_depth)', '    constant_table', '    createDropIfUnused', '    dump(std::ostream & out,const Stack & stack)', '    enterFrame(const Code & code,size_t base_pointer)', '    formatStackTrace(std::ostream & out)', '    getFuture', '    grad_executors', '    handleError(const ExceptionMessage & msg,bool is_jit_exception)', '    instructions', '    instructions_source', '    InterpreterState(const Code & code)', '    InterpreterState(c10::intrusive_ptr pImpl_)', '    leaveFrame', '    location', '    num_bailouts', '    num_inputs', '    num_outputs', '    operator()', '    operator<<(std::ostream & out,const Code & code)', '    register_size', '    request_bailout(size_t index)', '    run(Stack & stack)', '    runAsync(Stack & stack)', '    runBuiltinFunction(Stack & stack,Function *fn,ActiveFrame *af)', '    runGraphFunction(Stack & stack,Function *fn,ActiveFrame *af)', '    runImpl(Stack & stack)', '    dropUnused(Block *b)', '    insertLastUses(Graph & g)', '    tensorTypeInCurrentExecutionContext(const at::Tensor & t)', '    run(Stack & stack)', '    runAsync(Stack & stack)', '    type_table', '    ActiveFrame(const Frame & frame)', '    Callback(c10::intrusive_ptr state,Stack stack)', '    operator()', '    addToDropIfNotExists(Node *drop,Value *v)', '    findOrCreateDropInstructionForNode(Node *n)', '    findOwnerInBlock(Node *n,Block *block)', '    InsertLastUses(Graph & g)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanUse(Node *n,size_t i)', '    CanEmitInline(const std::shared_ptr & graph)', '    canInline(Value *v)', '    previousNonConstant(Node *n)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanValue(Node *block_point,Value *v)', '    allocRegs(at::ArrayRef vs)', '    CodeImpl(const std::shared_ptr & graph,std::string function_name,size_t remaining_bailout_depth)', '    constant_table', '    createBailoutBlock(size_t jf_index)', '    dump(std::ostream & out,size_t i)', '    dump(std::ostream & out)', '    emitBailOut(Node *node)', '    emitCall(Function *func,at::ArrayRef inputs)', '    emitCodeForBlock(Block *block)', '    emitConstant(Node *node)', '    emitContainerConstruct(OpCode op,Node *node)', '    emitCreateObject(Node *node)', '    emitDrop(at::ArrayRef to_drop)', '    emitFork(Node *node)', '    emitGetAttr(Node *node)', '    emitGuard(Node *node)', '    emitIf(Node *node)', '    emitInterfaceCall(std::string method_name_str,c10::ArrayRef inputs)', '    emitIsinstance(Node *node)', '    emitListUnpack(Node *node)', '    emitLoadInputs(at::ArrayRef inputs)', '    emitLoop(Node *loop)', '    emitNode(Node *node)', '    emitNodeAtBlockLevel(Node *node)', '    emitOperator(Node *node)', '    emitSetAttr(Node *node)', '    emitStoreOutputs(Node *node)', '    emitTupleConstruct(Node *node)', '    emitTupleSlice(Node *node)', '    emitType(TypePtr t)', '    emitUse(Value *input,bool drop)', '    emitWait(Node *node)', '    emitWarn(Node *node)', '    grad_executors', '    insertBailoutBlocks', '    insertConstant(IValue value)', '    insertInstruction(OpCode op,int64_t X,uint64_t N)', '    instructions', '    instructions_source', '    registerFor(Value *v)', '    request_bailout(size_t index)', '    truncateInstructions(size_t size)', '    PreprocessGraph(Graph & g)', '    WithCurrentNode(Node **loc,Node *new_value)', '    ~WithCurrentNode'];
quantile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 18;  1; 4;1;  13; 0;10;13;1;9;0.08;2;[];[];
quantile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 149;  7; 12;4;  127; 0;59;47;86;67;0.06;5;[];['    InterpreterState(std::shared_ptr code)', '    reg(size_t reg)', '    run(Stack & stack)'];
int8_add_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 74;  8; 12;3;  52; 0;50;52;4;25;0.15;8;['    C10FlagParser_benchmark_iter', '    C10FlagParser_extra_stats', '    C10FlagParser_inter_op_threads', '    C10FlagParser_intra_op_threads', '    C10FlagParser_iter_pow', '    C10FlagParser_sub_iter', '    C10FlagParser_task_type', '    C10FlagParser_tensor_dim', '    C10FlagParser_warmup_iter_pow'];['    _launch_tasks_tree(int level,int end_level,at::Tensor & left,at::Tensor & right)', '    counter', '    launch_tasks_and_wait(at::Tensor & left,at::Tensor & right,int iter_pow)', '    main(int argc,char **argv)', '    print_extra_stats', '    print_runtime_stats(const std::vector & runtimes)', '    reset_extra_stats', '    wait', '    C10FlagParser_benchmark_iter(const std::string & content)', '    C10FlagParser_extra_stats(const std::string & content)', '    C10FlagParser_inter_op_threads(const std::string & content)', '    C10FlagParser_intra_op_threads(const std::string & content)', '    C10FlagParser_iter_pow(const std::string & content)', '    C10FlagParser_sub_iter(const std::string & content)', '    C10FlagParser_task_type(const std::string & content)', '    C10FlagParser_tensor_dim(const std::string & content)', '    C10FlagParser_warmup_iter_pow(const std::string & content)'];
int8_add_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 115;  15; 20;11;  76; 2;49;47;29;25;0.20;4;[];[];
int8_average_pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 64;  1; 12;1;  51; 0;42;23;3;15;0.02;5;[];[];
int8_channel_shuffle_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 14;  1; 4;1;  9; 0;7;9;1;7;0.11;2;[];[];
int8_channel_shuffle_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 101;  10; 17;12;  69; 2;43;34;30;19;0.14;4;['    intrusive_ptr_target'];['    assign_ptr_(TTarget *rhs)', '    incref(intrusive_ptr_target *self)', '    incref(intrusive_ptr_target *self)', '    singleton', '    intrusive_ptr_target', '    intrusive_ptr_target(intrusive_ptr_target)', '    intrusive_ptr_target(const intrusive_ptr_target & other)', '    operator=(intrusive_ptr_target)', '    operator=(const intrusive_ptr_target & other)', '    release_resources', '    ~intrusive_ptr_target'];
int8_concat_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 27;  1; 5;2;  20; 0;18;20;1;7;0.05;2;['    Bar', '    Foo'];['    BM_IntrusivePtrArray(benchmark::State & state)', '    BM_IntrusivePtrCtorDtor(benchmark::State & state)', '    BM_SharedPtrArray(benchmark::State & state)', '    BM_SharedPtrCtorDtor(benchmark::State & state)', '    Bar(int param_)', '    Foo(int param_)'];
int8_conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 79;  1; 17;1;  61; 0;56;26;2;13;0.02;4;['    DestructableMock', '    final', '    final', '    final', '    SomeClass0Parameters', '    SomeClass1Parameter', '    SomeClass2Parameters'];['    make_weak_intrusive(Args,...)', '    make_weak_only(Args,...)', '    TEST(MakeIntrusiveTest,ClassWith0Parameters)', '    TEST(MakeIntrusiveTest,ClassWith1Parameter)', '    TEST(MakeIntrusiveTest,ClassWith2Parameters)', '    TEST(MakeIntrusiveTest,TypeIsAutoDeductible)', '    TEST(MakeIntrusiveTest,CanAssignToBaseClassPtr)', '    TEST(IntrusivePtrTargetTest,whenAllocatedOnStack_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCallingGet_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCallingConstGet_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCallingGet_thenReturnsNullptr)', '    TEST(IntrusivePtrTest,givenValidPtr_whenDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenConstDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenArrowDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenConstArrowDereferencing_thenReturnsObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigning_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToSelf_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToSelf_thenStaysValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToSelf_thenStaysInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigning_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningFromInvalidPtr_thenNewInstanceIsInvalid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenMoveAssigningToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenMoveAssigningInvalidPtrToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenMoveAssigningToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigning_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigning_thenOldInstanceValid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToSelf_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToSelf_thenStaysValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToSelf_thenStaysInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigning_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenValidPtr_whenCopyAssigningToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToBaseClass_thenNewInstanceIsValid)', '    TEST(IntrusivePtrTest,givenInvalidPtr_whenCopyAssigningToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssigningInvalidPtrToBaseClass_thenNewInstanceIsInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenCopyAssigningToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructing_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClass_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructingToBaseClassFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenMoveConstructingToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenOldInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructing_thenNewInstanceValid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenPointsToSameObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenOldInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClass_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructingToBaseClassFromInvalidPtr_thenNewInstanceInvalid)', '    TEST(IntrusivePtrTest,givenNullPtr_whenCopyConstructingToDifferentNullptr_thenHasNewNullptr)', '    TEST(IntrusivePtrTest,SwapFunction)', '    TEST(IntrusivePtrTest,SwapMethod)', '    TEST(IntrusivePtrTest,SwapFunctionFromInvalid)', '    TEST(IntrusivePtrTest,SwapMethodFromInvalid)', '    TEST(IntrusivePtrTest,SwapFunctionWithInvalid)', '    TEST(IntrusivePtrTest,SwapMethodWithInvalid)', '    TEST(IntrusivePtrTest,SwapFunctionInvalidWithInvalid)', '    TEST(IntrusivePtrTest,SwapMethodInvalidWithInvalid)', '    TEST(IntrusivePtrTest,CanBePutInContainer)', '    TEST(IntrusivePtrTest,CanBePutInSet)', '    TEST(IntrusivePtrTest,CanBePutInUnorderedSet)', '    TEST(IntrusivePtrTest,CanBePutInMap)', '    TEST(IntrusivePtrTest,CanBePutInUnorderedMap)', '    TEST(IntrusivePtrTest,Equality_AfterCopyConstructor)', '    TEST(IntrusivePtrTest,Equality_AfterCopyAssignment)', '    TEST(IntrusivePtrTest,Equality_Nullptr)', '    TEST(IntrusivePtrTest,Nonequality)', '    TEST(IntrusivePtrTest,Nonequality_NullptrLeft)', '    TEST(IntrusivePtrTest,Nonequality_NullptrRight)', '    TEST(IntrusivePtrTest,HashIsDifferent)', '    TEST(IntrusivePtrTest,HashIsDifferent_ValidAndInvalid)', '    TEST(IntrusivePtrTest,HashIsSame_AfterCopyConstructor)', '    TEST(IntrusivePtrTest,HashIsSame_AfterCopyAssignment)', '    TEST(IntrusivePtrTest,HashIsSame_BothNullptr)', '    TEST(IntrusivePtrTest,OneIsLess)', '    TEST(IntrusivePtrTest,NullptrIsLess1)', '    TEST(IntrusivePtrTest,NullptrIsLess2)', '    TEST(IntrusivePtrTest,NullptrIsNotLessThanNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenIsInvalid)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenHoldsNullptr)', '    TEST(IntrusivePtrTest,givenPtr_whenDestructed_thenDestructsObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructed_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveConstructedToBaseClass_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssigned_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssignedToBaseClass_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenMoveAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithBaseClassCopy_whenMoveAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenMoveAssignedToBaseClass_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssigned_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenMoveAssignedToBaseClass_thenDestructsObjectAfterSecondDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedToBaseClassAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyConstructedToBaseClassAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClassAndDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClassAndOriginalDestructed_thenDestructsObjectAfterLastDestruction)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssigned_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtr_whenCopyAssignedToBaseClass_thenDestructsOldObject)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCopyAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithBaseClassCopy_whenCopyAssigned_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCopyAssignedToBaseClass_thenDestructsOldObjectAfterCopyIsDestructed)', '    TEST(IntrusivePtrTest,givenPtr_whenCallingReset_thenDestructs)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCallingReset_thenDestructsAfterCopyDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithCopy_whenCallingResetOnCopy_thenDestructsAfterOriginalDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithMoved_whenCallingReset_thenDestructsAfterMovedDestructed)', '    TEST(IntrusivePtrTest,givenPtrWithMoved_whenCallingResetOnMoved_thenDestructsImmediately)', '    TEST(IntrusivePtrTest,AllowsMoveConstructingToConst)', '    TEST(IntrusivePtrTest,AllowsCopyConstructingToConst)', '    TEST(IntrusivePtrTest,AllowsMoveAssigningToConst)', '    TEST(IntrusivePtrTest,AllowsCopyAssigningToConst)', '    TEST(IntrusivePtrTest,givenNewPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenNewPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenEmptyPtr_thenHasUseCount0)', '    TEST(IntrusivePtrTest,givenEmptyPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenResetPtr_thenHasUseCount0)', '    TEST(IntrusivePtrTest,givenResetPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenOldHasUseCount0)', '    TEST(IntrusivePtrTest,givenMoveConstructedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenIsUnique)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenOldHasUseCount0)', '    TEST(IntrusivePtrTest,givenMoveAssignedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenOldHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_thenOldIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenDestructingCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenDestructingCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenReassigningCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyConstructedPtr_whenReassigningCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_thenHasUseCount2)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_thenIsNotUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenDestructingCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenDestructingCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenReassigningCopy_thenHasUseCount1)', '    TEST(IntrusivePtrTest,givenCopyAssignedPtr_whenReassigningCopy_thenIsUnique)', '    TEST(IntrusivePtrTest,givenPtr_whenReleasedAndReclaimed_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenPtr_whenReleasedAndReclaimed_thenIsDestructedAtEnd)', '    TEST(IntrusivePtrTest,givenPtr_whenNonOwningReclaimed_thenDoesntCrash)', '    TEST(IntrusivePtrTest,givenPtr_whenNonOwningReclaimed_thenIsDestructedAtEnd)', '    singleton', '    singleton', '    DestructableMock(bool *resourcesReleased,bool *wasDestructed)', '    release_resources', '    ~DestructableMock', '    ChildDestructableMock(bool *resourcesReleased,bool *wasDestructed)', '    IntrusiveAndWeak(intrusive_ptr ptr_)', '    SomeBaseClass(int v_)', '    SomeChildClass(int v)', '    SomeClass1Parameter(int param_)', '    SomeClass2Parameters(int param1_,int param2_)'];
int8_conv_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 177;  13; 20;16;  131; 4;102;31;65;113;0.10;9;[];['    _argcountMatch(const Option & option,const std::vector & arguments,const std::unordered_map & kwargs)', '    _argDesc(const std::vector & arguments,const std::unordered_map & kwargs)', '    _buildType(std::string type_name,bool is_nullable)', '    _formattedArgDesc(const Option & option,const std::vector & arguments,const std::unordered_map & kwargs)', '    _parseOption(const std::string & _option_str,const std::unordered_map & kwargs)', '    _splitString(const std::string & s,const std::string & delim)', '    _tryMatchKwargs(const Option & option,const std::unordered_map & kwargs)', '    format_invalid_args(PyObject *given_args,PyObject *given_kwargs,const std::string & function_name,const std::vector & options)', '    py_typename(PyObject *object)', '    Argument(std::string name,std::unique_ptr type)', '    is_matching(PyObject *object)', '    MultiType(std::initializer_list accepted_types)', '    is_matching(PyObject *object)', '    NullableType(std::unique_ptr type)', '    Option(std::vector arguments,bool is_variadic,bool has_out)', '    Option(bool is_variadic,bool has_out)', '    Option(Option)', '    is_matching(PyObject *object)', '    SequenceType(std::unique_ptr type)', '    is_matching(PyObject *object)', '    SimpleType(std::string & name)', '    is_matching(PyObject *object)', '    TupleType(std::vector)'];
int8_conv_op_relu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 7;  1; 3;1;  3; 0;1;3;1;5;0.33;1;[];['    format_invalid_args(PyObject *given_args,PyObject *given_kwargs,const std::string & function_name,const std::vector & options)'];
int8_conv_transpose_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 176;  16; 21;16;  129; 4;101;33;57;99;0.12;9;[];['    GenerateStylizedImage(std::vector & originalImage,const std::string & init_net_str,const std::string & predict_net_str,int height,int width,std::vector & dataOut)', '    MakeCaffe2Predictor(const std::string & init_net_str,const std::string & predict_net_str,bool disableMultithreadProcessing,bool allowMetalOperators,std::string & errorMessage)'];
int8_dequantize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 14;  1; 4;1;  9; 0;7;9;1;7;0.11;2;[];['    __attribute__(visibility)'];
int8_dequantize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 52;  4; 12;7;  33; 0;13;19;6;13;0.12;2;[];[];
int8_fc_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 136;  11; 19;15;  93; 4;69;22;16;34;0.12;7;[];['    Caffe2IOSPredictor(const caffe2::NetDef & init_net,const caffe2::NetDef & predict_net,bool disableMultithreadProcessing,bool usingMetalOperators)', '    NewCaffe2IOSPredictor(const caffe2::NetDef & init_net,const caffe2::NetDef & predict_net,bool disableMultithreadProcessing,bool allowMetalOperators)', '    run(const Tensor & inData,Tensor & outData,std::string & errorMessage)'];
int8_flatten_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 33;  1; 8;2;  23; 0;21;23;1;7;0.04;2;[];['    run(const Tensor & inData,Tensor & outData,std::string & errorMessage)', '    visibility'];
int8_flatten_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 48;  3; 9;7;  32; 0;16;16;11;12;0.09;2;[];['    checkSameDevice(const Node *node)', '    indent(std::ostream & out,size_t level)', '    printAttribute(std::ostream & out,const at::Tensor & tensor)', '    printAttribute(std::ostream & out,const IValue & ival)', '    printTypeList(std::ostream & out,const std::vector & items)', '    printValueRef(std::ostream & out,const Value *n)', '    printValueRefs(std::ostream & out,const at::ArrayRef nodes)', '    allocNewInstance(Graph *g)', '    cloneFrom(Node *other_)', '    createTupleUnpack(Value *v)', '    env', '    fakeRange', '    findArgument(const FunctionSchema & the_schema,Symbol name)', '    inlineCallTo(Node *to_replace,Function *callee)', '    inputs_set', '    insertGraph(Graph & g,Graph & callee,ArrayRef inputs,std::unordered_map & value_map)', '    insertGraph(Graph & g,Graph & callee,ArrayRef inputs)', '    OperatorSet(std::initializer_list sig_literals)', '    output_set', '    tensor_s', '    LintGraph(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,const at::ArrayRef nodes)', '    operator<<(std::ostream & out,const const_value_list_with_types & l)', '    operator<<(std::ostream & out,const Node & n)', '    operator<<(std::ostream & out,const Graph & g)', '    operator<<(std::ostream & out,const std::vector & nodes)', '    operator<<(std::ostream & out,const at::ArrayRef nodes)', '    type', '    unpackOutputs(const std::vector & outputs)', '    create(NodeKind kind,ArrayRef inputs,size_t num_outputs)', '    create(NodeKind kind,size_t num_outputs)', '    createAutogradZero', '    createClone(Node *n,const std::function & value_map,bool copy_blocks)', '    createDict(const TypePtr & key_type,const TypePtr & value_type,at::ArrayRef keys,at::ArrayRef values)', '    createGetAttr(Value *obj,const std::string & field)', '    createIsInstance(Value *v,at::ArrayRef types)', '    createList(const TypePtr & elem_type,at::ArrayRef values)', '    createListUnpack(Value *v,size_t size)', '    createLoad(const std::string & name,const TypePtr & type)', '    createNone', '    createNumToTensor(Value *value)', '    createObject(const ClassTypePtr & type)', '    createSetAttr(Value *obj,const std::string & field,Value *newValue)', '    createStore(const std::string & name,Value *v)', '    createTuple(at::ArrayRef values,TupleTypePtr tuple_type)', '    createTupleIndex(Value *tup,Value *idx,const TypePtr & output_type)', '    createTupleSlice(Value *tup,int64_t beg,int64_t end)', '    createTupleUnpack(Value *v)', '    createUninitialized(TypePtr typ)', '    createWithSubgraph(Symbol kind)', '    freeBlock(Block *b)', '    freeNode(Node *n)', '    freeValue(Value *v)', '    insert(Symbol opname,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & range)', '    insertConstant(const IValue & val,c10::optional loc,c10::optional scope)', '    insertFunctionCall(Function *callee,const MatchedSchema & matched)', '    insertMethodCall(std::string method_name,const MatchedSchema & matched)', '    insertToList(Value *v,TypePtr type)', '    insertUncheckedCast(Value *v,TypePtr type)', '    toString(bool print_source_locations)', '    ~Graph', '    check_block(const Block *b)', '    check_graph', '    check_node(const Node *n)', '    check_value(const Value *v)', '    LintImpl(const Graph & g)', '    contains(const Value *v)', '    contains(const Node *n)', '    insert(const Value *v)', '    insert(const Node *n)', '    LintScope(std::unique_ptr parent)', '    addBlock', '    addInput(Value *value)', '    addOutput', '    assignTopoPosition', '    blocksFromGraphBlock', '    cloneFrom(Node *s)', '    destroy', '    dropInput(size_t i)', '    dump', '    eraseBlock(size_t i)', '    eraseOutput(size_t i)', '    findCommonAncestorBlockWith(Node *n)', '    findUseForInput(size_t i)', '    get(Symbol name)', '    getOperation', '    getOperator', '    hasSideEffects', '    insertAfter(Node *n)', '    insertBefore(Node *n)', '    insertInput(size_t i,Value *value)', '    insertOutput(size_t i)', '    isAfter(const Node *n)', '    isBefore(const Node *n)', '    isBeforeOrAfter(const Node *n,MoveSide moveSide)', '    isMemberOf(const OperatorSet & os)', '    isNondeterministic', '    matches(const FunctionSchema & schema)', '    matches(const char *signature_literal,at::ArrayRef const_inputs)', '    maybeOperator', '    maybeSchema', '    moveAfter(Node *n)', '    moveBefore(Node *n)', '    mustBeNone', '    namedInput(Symbol name)', '    Node(Graph *graph_,NodeKind kind_)', '    permuteInputs(const std::vector & new_order)', '    permuteOutputs(const std::vector & new_order)', '    removeAllInputs', '    removeFromList', '    removeInput(size_t i)', '    replaceAllUsesWith(Node *n)', '    replaceInput(size_t i,Value *newValue)', '    replaceInputWith(Value *from,Value *to)', '    schema', '    const_value_list_with_types(ArrayRef values,std::string delim_)', '    copy', '    dump', '    lint', '    pop_scope', '    print(std::ostream & out,bool print_source_locations)', '    push_scope(const std::string & scope_name)', '    remapTypes(const std::function & type_map)', '    lint', '    print(std::ostream & out,size_t level,std::vector *groups,bool print_source_locations,bool print_attributes,bool print_scopes,bool print_body)', '    printAttributes(std::ostream & out,bool ignore_subgraph)', '    printAttrValue(std::ostream & out,const Symbol & name)', '    sourceRange', '    Block(Graph *graph_,Node *node_)', '    cloneFrom(Block *src,std::function value_map)', '    destroy', '    reIndexTopology', '    remapTypes(const std::function & type_map)', '    copyMetadata(Value *from)', '    debugNameBase', '    inferTypeFrom(const at::Tensor & output)', '    isValidName(const std::string & name)', '    mustBeNone', '    mustNotBeNone', '    replaceAllUsesAfterNodeWith(const Node *node,Value *newValue)', '    replaceAllUsesWith(Value *newValue)', '    replaceFirstUseWith(Value *newValue)', '    setDebugName(const std::string & name)'];
int8_given_tensor_fill_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 118;  3; 14;10;  94; 0;40;70;18;53;0.03;8;[];['    ChooseDtype(const Dtype & buffer_dtype,const Dtype & index_dtype)', '    ExprHandleVectorToExprVector(const std::vector & v)', '    ExprVectorToExprHandleVector(const std::vector & v)', '    VarHandleVectorToVarVector(const std::vector & v)', '    VarVectorToVarHandleVector(const std::vector & v)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1,Dtype dt2)', '    IntrinsicsDtype(IntrinsicsOp op_type,const std::vector & params)', '    OpArgCount(IntrinsicsOp op_type)', '    Load(const Buffer & buffer,const Expr *index,const Expr *mask)', '    Load(Dtype dtype,const Var *base_handle,const Expr *index,const Expr *mask)', '    Store(const Buffer & buffer,const Expr *index,const Expr *value,const Expr *mask)'];
int8_leaky_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 24;  1; 7;1;  16; 0;14;16;1;7;0.06;2;[];[];
int8_leaky_relu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 110;  16; 18;11;  73; 2;48;43;32;24;0.22;4;['    BaseCallNode', '    Broadcast', '    CallNode', '    CompareSelect', '    IfThenElse', '    Intrinsics', '    Let', '    Load', '    Ramp', '    HalfImm', '    Add', '    And', '    BinaryOpNode', '    BoolImm', '    ByteImm', '    Cast', '    CharImm', '    Div', '    DoubleImm', '    FloatImm', '    IntImm', '    LongImm', '    Lshift', '    Max', '    Min', '    Mod', '    Mul', '    Or', '    Rshift', '    ShortImm', '    Sub', '    Xor'];['    newBinaryOpOfType(IRNodeType expr_type,const Expr *lhs,const Expr *rhs,bool option)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    ExprHandleVectorToExprVector(const std::vector &)', '    ExprVectorToExprHandleVector(const std::vector &)', '    getImmediateByType(ScalarType immType,T initialVal)', '    getImmediateByType(Dtype dtype,T initialVal)', '    immediateAs(const Expr *e)', '    immediateEquals(const Expr *e,T val)', '    immediateIsNegative(const T *e)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    cast(const ExprHandle & src_value)', '    getPrecedence(IRNodeType ty)', '    VarHandleVectorToVarVector(const std::vector &)', '    VarVectorToVarHandleVector(const std::vector &)', '    make(const ExprHandle & value,int lanes)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,CompareSelectOperation cmp_op)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,const ExprHandle & ret_val1,const ExprHandle & ret_val2,CompareSelectOperation cmp_op)', '    make(const ExprHandle & c,const ExprHandle & t,const ExprHandle & f)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1)', '    IntrinsicsDtype(IntrinsicsOp op_type,Dtype dt1,Dtype dt2)', '    IntrinsicsDtype(IntrinsicsOp op_type,const std::vector & params)', '    make(IntrinsicsOp op_type,const ExprHandle & v1)', '    make(IntrinsicsOp op_type,const ExprHandle & v1,const ExprHandle & v2)', '    make(IntrinsicsOp op_type,const std::vector & params)', '    make(IntrinsicsOp op_type,Dtype dtype)', '    OpArgCount(IntrinsicsOp op_type)', '    make(const ExprHandle & var,const ExprHandle & value,const ExprHandle & body)', '    make(const Buffer & buffer,const ExprHandle & index,const ExprHandle & mask)', '    make(Dtype dtype,const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & mask)', '    make(const ExprHandle & base,const ExprHandle & stride,int lanes)', '    CastIfNeeded(const Expr *expr,Dtype dst_dtype)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(uint8_t value)', '    make(Dtype dtype,const ExprHandle & src_value)', '    make(int8_t value)', '    make(double value)', '    make(float value)', '    make(int value)', '    make(int64_t value)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,bool propagate_nans)', '    make(const ExprHandle & lhs,const ExprHandle & rhs)', '    make(const ExprHandle & lhs,const ExprHandle & rhs,bool propagate_nans)', '    make(int16_t value)', '    BaseCallNode(Dtype dtype,CallType call_type,const std::vector & params)', '    call_type', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    nparams', '    param(int index)', '    params', '    Broadcast(const Expr *value,int lanes)', '    lanes', '    value', '    compare_select_op', '    CompareSelect(const Expr *lhs,const Expr *rhs,const Expr *ret_val1,const Expr *ret_val2,CompareSelectOperation cmp_op)', '    lhs', '    ret_val1', '    ret_val2', '    rhs', '    dtype', '    lanes', '    scalar_type', '    condition', '    false_value', '    IfThenElse(const Expr *c,const Expr *t,const Expr *f)', '    true_value', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    Intrinsics(IntrinsicsOp op_type,Dtype dtype)', '    Intrinsics(IntrinsicsOp op_type,const Expr *v1)', '    Intrinsics(IntrinsicsOp op_type,const Expr *v1,const Expr *v2)', '    Intrinsics(IntrinsicsOp op_type,const std::vector & params)', '    isPure', '    op_type', '    body', '    Let(const Expr *var,const Expr *value,const Expr *body)', '    value', '    var', '    base_handle', '    index', '    Load(const Buffer & buffer,const Expr *index,const Expr *mask)', '    Load(Dtype dtype,const Var *base_handle,const Expr *index,const Expr *mask)', '    mask', '    base', '    lanes', '    Ramp(const Expr *base,const Expr *stride,int lanes)', '    stride', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    HalfImm((*) () decltype)', '    isConstant', '    Add(const Expr *lhs,const Expr *rhs)', '    And(const Expr *lhs,const Expr *rhs)', '    BinaryOpNode(const Expr *lhs_v,const Expr *rhs_v,IRNodeType expr_type,ScalarType ret_type)', '    lhs', '    rhs', '    BoolImm((*) () decltype)', '    decltype(::c10::impl::ScalarTypeToCPPType::t)', '    isConstant', '    ByteImm(uint8_t value)', '    isConstant', '    value', '    Cast(Dtype dtype,const Expr *src_value)', '    isConstant', '    src_value', '    CharImm(int8_t value)', '    isConstant', '    value', '    Div(const Expr *lhs,const Expr *rhs)', '    DoubleImm(double value)', '    isConstant', '    value', '    dtype', '    FloatImm(float value)', '    isConstant', '    value', '    IntImm(int value)', '    isConstant', '    value', '    isConstant', '    LongImm(int64_t value)', '    value', '    Lshift(const Expr *lhs,const Expr *rhs)', '    Max(const Expr *lhs,const Expr *rhs,bool propagate_nans)', '    propagate_nans', '    Min(const Expr *lhs,const Expr *rhs,bool propagate_nans)', '    propagate_nans', '    Mod(const Expr *lhs,const Expr *rhs)', '    Mul(const Expr *lhs,const Expr *rhs)', '    Or(const Expr *lhs,const Expr *rhs)', '    Rshift(const Expr *lhs,const Expr *rhs)', '    isConstant', '    ShortImm(int16_t value)', '    value', '    Sub(const Expr *lhs,const Expr *rhs)', '    Xor(const Expr *lhs,const Expr *rhs)'];
int8_max_pool_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 101;  7; 16;12;  70; 2;44;38;26;16;0.10;4;['    LoopStatus'];['    asSimple(const SugaredValuePtr & value)', '    makeMagic(const std::string & name,SugaredValuePtr base)', '    materializeConstant(T val,Graph & graph,const SourceRange & r,std::unordered_map & map)', '    emit_body', '    emit_body', '    emit_body', '    emitBasicSlice(const SourceRange & loc,Value *sliceable,const List & subscript_exprs)', '    emitMultidimSlicing(const SourceRange & loc,Value *sliceable,const List & subscript_exprs)', '    emitSubscript(const Subscript & subscript)', '    emitTupleIndex(const SourceRange & loc,Value *tuple_val,Value *idx_val)', '    emitTupleSlice(const SourceRange & loc,const NamedValue & tuple_val,const NamedValue & beg_val,const at::optional & end_val)', '    false_expr', '    get_const_expr', '    get_continue_expr', '    getAdjTupleIndex(const SourceRange & loc,const TupleTypePtr & tuple_type,int64_t input_index,bool allow_out_of_bounds)', '    getSliceInd(Value *idx_val,const SourceRange & loc)', '    meaningfulName(const std::string & name)', '    runCleanupPasses(std::shared_ptr & to_clean)', '    canBeNone(Value *v)', '    isSupportedListElementType(const TypePtr & type)', '    true_expr', '    intersectSet(const Refinements & a,const Refinements & b)', '    sameVar(const Refinement & a,const Refinement & b)', '    unionSet(const Refinements & a,const Refinements & b)', '    getTypeForSetStateArg(const Def & def,const Self *self)', '    shouldDeriveSetStateType(const Def & def,const FunctionSchema & schema)', '    CompilationUnit(const std::string & source)', '    define(const c10::optional & prefix,const std::vector & definitions,const std::vector & resolvers,const Self *self,bool shouldMangle)', '    define(const c10::optional & prefix,const std::string & source,const ResolverPtr & resolver,const Self *self)', '    define(const c10::optional & prefix,const Def & def,const ResolverPtr & resolver,const Self *self,const std::unordered_map & function_table,bool shouldMangle)', '    define_interface(const c10::QualifiedName & qualifiedName,const ClassDef & classDef,ResolverPtr rcb,bool is_module)', '    mangle(const c10::QualifiedName & name)', '    FunctionResolver(Resolver *otherResolver,const std::unordered_map & functionTable)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    gather(Expr classinfo)', '    GatheredTypes(ScriptTypeParser parser)', '    maybeOfKind(TypeKind kind,const TypePtr & actual_type)', '    staticallyFalse(const TypePtr & actual_type)', '    staticallyTrue(const TypePtr & actual_type)', '    CondValue(Value *value,RefinementSet refinements,c10::optional static_if)', '    CondValue(Graph & g,const SourceRange & loc,bool static_value,RefinementSet refinements)', '    refinements', '    staticIf', '    value', '    block', '    definedVariables', '    Environment(Function & method,ResolverPtr resolver,Block *b,std::shared_ptr next)', '    findInAnyFrame(const std::string & name)', '    findInParentFrame(const std::string & name)', '    findInThisFrame(const std::string & name)', '    findVariableTypeError(const std::string & name)', '    getSugaredVar(const Ident & ident,bool required)', '    getSugaredVar(const std::string & ident,const SourceRange & range,bool required)', '    getVar(const Ident & ident)', '    getVar(const std::string & ident,const SourceRange & range)', '    insertLoad(const std::string & name,const TypePtr & type)', '    insertStore(const std::string & name,const SourceRange & loc,Value *v,TypePtr type)', '    setSugaredVar(const SourceRange & loc,const std::string & name,SugaredValuePtr value,TypePtr annotated_type)', '    setType(const std::string & name,TypePtr type)', '    setVar(const SourceRange & loc,const std::string & name,Value *value)', '    setVariableTypeError(const std::string & name,std::function msg)', '    identifier', '    Refinement(std::string identifier,TypePtr type)', '    type', '    activeRefinements', '    And(const RefinementSet & rhs)', '    Not', '    Or(const RefinementSet & rhs)', '    RefinementSet(Refinements true_refinements,Refinements false_refinements)', '    RefinementSet(Refinement single)', '    RefinementSet(Refinement single_true,Refinement single_false)', '    RefinementSet', '    checkApplyNumInputs(Apply & apply,size_t expected_inputs)', '    checkBreakContinue(const SourceRange & loc,const std::string & stmt_name)', '    create(Symbol kind,const SourceRange & loc,size_t n_outputs)', '    createTempName(const std::string & prefix)', '    emitApplyExpr(Apply & apply,size_t n_binders,const TypePtr & type_hint)', '    emitApplySpecialForm(Symbol form,Apply & apply,const TypePtr & type_hint)', '    emitAssert(const Assert & stmt)', '    emitAssignment(const Assign & stmt)', '    emitAttributes(const List & attributes)', '    emitAugAssignment(const AugAssign & stmt)', '    emitAugAssignmentGeneric(const AugAssign & stmt,const Subscript & lhs,Value *sliceable)', '    emitAugAssignmentHelper(const AugAssign & stmt,Value *lhs)', '    emitAugAssignmentToSelectVar(const AugAssign & stmt)', '    emitAugAssignmentToSubscript(const AugAssign & stmt)', '    emitAugAssignmentToVar(const AugAssign & stmt)', '    emitBreak(const Break & stmt)', '    emitClosure(const std::function & emit_body)', '    emitClosure(const Def & def)', '    emitCondExpr(const Expr & expr)', '    emitConst(const Const & c)', '    emitContinue(const Continue & stmt)', '    emitDef(const Def & def,const Self *self,Block *block)', '    emitDelete(const Delete & stmt)', '    emitExpr(const Expr & tree,const TypePtr & type_hint)', '    emitExprsAssign(const List & lhs_exprs,const at::ArrayRef outputs,const SourceRange & rhs_loc,size_t n_binders)', '    emitFor(const List & targets,const List & itrs,const SourceRange & loc,const std::function & emit_body)', '    emitFor(const For & stmt)', '    emitForkExpr(SourceRange loc,const std::shared_ptr & forked,at::ArrayRef inputs,at::ArrayRef attributes)', '    emitFormalArguments(const Def & def,const Self *self,const FunctionSchema & schema,Block *block)', '    emitHasAttr(const Expr & objExpr,const Expr & attrExpr)', '    emitIf(const If & stmt)', '    emitIfElseBlocks(const SourceRange & loc,const CondValue & cond_value,const List & trueBranch,const List & falseBranch)', '    emitIfExpr(const SourceRange & range,const CondValue & cond_value,std::function true_expr,std::function false_expr)', '    emitIndex(const SourceRange & loc,Value *input,at::ArrayRef indices)', '    emitIsInstance(const Expr & obj,const Expr & classinfo)', '    emitListComprehension(const ListComp & lc,const TypePtr & type_hint)', '    emitLoopCommon(SourceRange range,const std::function & emit_body,const SugaredValuePtr & iter_val,c10::optional,c10::optional cond)', '    emitOutput(const SourceRange & range,const FunctionSchema & schema,Block *block)', '    emitRaise(const SourceRange & loc)', '    emitReturn(const Return & stmt)', '    emitRpcAsyncExpr(const Apply & apply)', '    emitSelect(const SourceRange & loc,Value *input,Value *dim,Value *index)', '    emitSelectAssign(const Assign & stmt)', '    emitShortCircuitLogical(const SourceRange & loc,const Expr & first_expr,const Expr & second_expr,bool is_or)', '    emitSimpleExpr(const TreeRef & tree,const TypePtr & type_hint)', '    emitSingleAssignment(const Assign & stmt)', '    emitSingleIfBranch(Block *b,const List & branch,const RefinementSet & refinements)', '    emitSlice(const SourceRange & loc,Value *input,Value *dim,const SliceExpr & slice)', '    emitStatements(const List & statements)', '    emitStatements(List::const_iterator begin,List::const_iterator end)', '    emitStringLiteral(const StringLiteral & c)', '    emitSubscriptAssign(const SourceRange & stmtRange,const Subscript & lhs,const Expr & rhs)', '    emitSubscriptAssign(const SourceRange & stmtRange,const Subscript & lhs,const NamedValue & rhs)', '    emitSugaredExpr(const Expr & tree,size_t n_binders,const TypePtr & type_hint)', '    emitTernaryIf(const TernaryIf & expr)', '    emitToBool(Value *v)', '    emitTupleAssign(const TupleLiteral & tl,const Expr & rhs)', '    emitTupleAssign(const TupleLiteral & tl,const SugaredValuePtr & rhs_output,const SourceRange & rhs_loc,size_t n_binders,bool starred_unpack)', '    emitUnaryOp(const TreeRef & tree,const std::string & magicMethod,const c10::Symbol & opSymbol)', '    emitUnrolledLoop(const SourceRange & loc,const std::function & emit_body,SugaredValuePtr iterable,const List & targets)', '    emitUnsqueeze(const SourceRange & loc,Value *input,Value *dim_val)', '    emitWhile(const While & stmt)', '    findIsNoneRefinements(Expr lhs,Value *lhs_value,Expr rhs,Value *rhs_value,int tok)', '    getAugMagicMethod(const AugAssign & stmt)', '    getAugOp(const AugAssign & stmt,const TypePtr & type)', '    getNamedValues(const TreeList & trees,bool maybe_unpack)', '    getNamedValues(const List & trees,bool maybe_unpack)', '    getNodeKind(int kind,int ninputs)', '    getOperatorOverload(int kind,int ninputs)', '    getValues(const TreeList & trees,bool maybe_unpack)', '    getValues(const List & trees,bool maybe_unpack)', '    handleMaybeNoReturn(const Def & def,Block *block)', '    insertRefinements(const SourceRange & loc,const RefinementSet & ref)', '    popFrame(bool ends_def)', '    pushFrame(Block *b,bool starts_def)', '    reverseComparision(NodeKind kind)', '    to_ir(const Def & def,ResolverPtr resolver_,const Self *self,Function & method)', '    validateAssignLhsExpr(const List & lhs,const SourceRange & r)', '    WithLoopStatus(LoopStatus *prev,LoopStatus new_status)', '    ~WithLoopStatus'];
int8_quantize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 16;  1; 4;1;  11; 0;9;11;1;7;0.09;2;[];['    meaningfulName(const std::string & name)', '    runCleanupPasses(std::shared_ptr & to_clean)'];
int8_quantize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 93;  4; 12;10;  38; 33;18;20;9;14;0.11;2;['    StmtClone'];['    mutate_binary_op(const BinaryOpNode *v,IRMutator *mutator,bool option)', '    clone(Stmt *s)', '    DefaultMutator(const BaseCallNode *v,std::vector & params)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Or *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const ByteImm *v)', '    mutate(const CharImm *v)', '    mutate(const ShortImm *v)', '    mutate(const IntImm *v)', '    mutate(const LongImm *v)', '    mutate(const FloatImm *v)', '    mutate(const DoubleImm *v)', '    mutate(const BoolImm *v)', '    mutate(const HalfImm *v)', '    mutate(const Intrinsics *v)', '    mutate(const FunctionCall *v)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    mutate(const Block *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    mutate(const LetStmt *v)', '    mutate(const For *v)', '    mutate(const Block *v)', '    mutate(const Store *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    mutate(const Cond *v)'];
int8_relu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 94;  11; 16;11;  64; 2;41;34;25;16;0.17;4;['    IRMutator'];['    DefaultMutator(const BaseCallNode *v,std::vector & params)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    mutate(const LetStmt *v)', '    mutate(const Cond *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Or *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const ByteImm *v)', '    mutate(const CharImm *v)', '    mutate(const ShortImm *v)', '    mutate(const IntImm *v)', '    mutate(const LongImm *v)', '    mutate(const FloatImm *v)', '    mutate(const DoubleImm *v)', '    mutate(const BoolImm *v)', '    mutate(const HalfImm *v)', '    mutate(const Intrinsics *v)', '    mutate(const FunctionCall *v)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    mutate(const Block *v)', '    mutate(const Allocate *v)', '    mutate(const Free *v)', '    ~IRMutator'];
int8_reshape_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 31;  1; 14;1;  16; 0;14;16;1;7;0.06;2;[];['    formatFPSuffix(std::ostream & os,double v)', '    formatFPSuffix(std::ostream & os,T v)', '    formatImm(std::ostream & os,T v)', '    formatImm(std::ostream & os,T v)', '    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    operator<<(std::ostream & stream,const Expr & expr)', '    operator<<(std::ostream & stream,const ExprHandle & expr)', '    operator<<(std::ostream & stream,const Stmt & stmt)', '    print(const Expr *expr)', '    print(const Stmt *stmt)', '    visitBinaryOp(const BinaryOpNode *v,const std::string & op_str,IRPrinter *printer,bool parens)', '    emitIndent', '    print(ExprHandle expr)', '    print(const Expr & expr)', '    print(const Stmt & stmt)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)'];
int8_reshape_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 48;  3; 9;8;  31; 0;14;15;12;10;0.10;3;['    IRPrinter', '    PrinterStream'];['    to_string(const Expr *expr)', '    to_string(const Stmt *stmt)', '    operator<<(std::ostream & stream,const Expr & expr)', '    operator<<(std::ostream & stream,const ExprHandle & expr)', '    operator<<(std::ostream & stream,const Stmt & stmt)', '    operator<<(std::ostream & stream,Stmt *)', '    print(const Expr *expr)', '    print(const Stmt *stmt)', '    emitIndent', '    IRPrinter(std::ostream & os)', '    name_manager', '    os', '    print(ExprHandle expr)', '    print(const Expr & expr)', '    print(const Stmt & stmt)', '    printer', '    PrinterStream(IRPrinter *printer,std::ostream & os)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)'];
int8_resize_nearest_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 80;  4; 14;7;  58; 0;37;33;35;33;0.07;2;[];['    lastNode', '    lastNode', '    lastNode', '    combineMultilane(const Expr *lhs,const Expr *rhs)', '    gcd(T a,T b)', '    mulMultilane(const Expr *lhs,const Expr *rhs)', '    polyGCD(const Polynomial *poly)', '    hashVars', '    sort', '    addOrUpdateTerm(std::unordered_map & varmap,const Term *term)', '    addPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    insertTerm(const Polynomial *poly,const Term *term)', '    mulTerms(const Term *lhs,const Term *rhs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Intrinsics *v)', '    mutate(const Cast *v)', '    polyByTerm(const Polynomial *poly,const Term *term)', '    subPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    subTerms(const Term *lhs,const Term *rhs,bool negated)', '    hashVars', '    sort', '    factorizePolynomial(const Polynomial *poly)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)'];
int8_roi_align_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 45;  1; 5;1;  39; 0;37;39;1;8;0.03;2;['    IRSimplifier', '    Polynomial', '    PolynomialTransformer', '    Term', '    TermExpander'];['    isMultilanePrimitive(const Expr *e)', '    promoteTypesMap(const Expr *s,std::unordered_map & m)', '    promoteTypesVar(const ExprType *e)', '    promoteTypesVar(const ExprType *e,Args,...)', '    promoteTypesVec(const Expr *s,std::vector & v)', '    promoteTypesVec(std::vector & v)', '    simplify(const Expr *e)', '    simplify(const ExprHandle & e)', '    simplify(Stmt *s)', '    mutateBinaryOp(const BinaryOpNode *v,IRMutator *mutator,bool option)', '    simplify(const Expr *e)', '    simplify(const ExprHandle & e)', '    simplify(Stmt *e)', '    dtype', '    expr_type', '    addTerm(const Term *t)', '    addTerm(const Term *t,Ts,...)', '    hasher', '    hashVars', '    Polynomial(HashProvider & hasher,const Expr *s,Args,...)', '    Polynomial(HashProvider & hasher,const Expr *s,std::vector)', '    Polynomial(HashProvider & hasher,std::vector terms)', '    Polynomial(HashProvider & hasher,const Expr *s,std::unordered_map varmap)', '    scalar', '    sort', '    variables', '    addOrUpdateTerm(std::unordered_map & varmap,const Term *term)', '    addPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    insertTerm(const Polynomial *poly,const Term *term)', '    mulTerms(const Term *lhs,const Term *rhs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Mod *v)', '    mutate(const And *v)', '    mutate(const Xor *v)', '    mutate(const Lshift *v)', '    mutate(const Rshift *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const Intrinsics *v)', '    mutate(const Cast *v)', '    polyByTerm(const Polynomial *poly,const Term *term)', '    subPolynomials(const Polynomial *lhs,const Polynomial *rhs)', '    subTerms(const Term *lhs,const Term *rhs,bool negated)', '    addComponent', '    addComponent(const Expr *e)', '    addComponent(const Expr *e,Es,...)', '    hasher', '    hashVars', '    scalar', '    sort', '    Term(HashProvider & hasher,const Expr *s,Args,...)', '    Term(HashProvider & hasher,const Expr *s,std::vector)', '    Term(HashProvider & hasher,const Expr *s,std::unordered_map varmap)', '    variables', '    factorizePolynomial(const Polynomial *poly)', '    mutate(const Term *v)', '    mutate(const Polynomial *v)', '    TermExpander(PolynomialTransformer *simplifier)'];
int8_roi_align_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 358;  35; 43;11;  284; 0;157;190;96;100;0.12;4;[];['    adjustIndices(size_t adjust,const std::vector & index_ordering)', '    push_back', '    reserve', '    size', '    cond', '    elseBlock', '    elseOutputs', '    IfView(Node *node)', '    node', '    operator torch::jit::Node *', '    outputs', '    permuteOutputs(const std::vector & new_output_order)', '    thenBlock', '    thenOutputs', '    bodyBlock', '    bodyCarriedInputs', '    bodyCarriedOutputs', '    carriedInputs', '    carriedInputsWithCond', '    carriedOutputs', '    cond', '    currentTripCount', '    inputCond', '    loopType', '    LoopView(Node *node)', '    maxTripCount', '    nextCond', '    node', '    operator torch::jit::Node *', '    permuteLoopCarried(const std::vector & new_output_order)', '    replaceInputCondition(Value *new_input_condition)', '    replaceMaxTripCount(Value *new_max_trip_count)', '    at', '    blocks', '    input', '    inputs', '    outputs', '    permuteInputs', '    permuteOutputs', '    replaceInput', '    slice', '    at', '    inputs', '    outputs', '    permuteInputs', '    permuteOutputs', '    slice', '    uses'];
int8_sigmoid_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 33;  1; 11;1;  21; 0;19;21;1;7;0.05;2;[];['    visit_binary_op(const BinaryOpNode *v,IRVisitor *visitor)', '    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const FunctionCall *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)'];
int8_sigmoid_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 100;  16; 15;11;  66; 2;43;38;23;18;0.24;4;['    IRVisitor'];['    visit(const Add *v)', '    visit(const Sub *v)', '    visit(const Mul *v)', '    visit(const Div *v)', '    visit(const Mod *v)', '    visit(const Max *v)', '    visit(const Min *v)', '    visit(const And *v)', '    visit(const Or *v)', '    visit(const Xor *v)', '    visit(const Lshift *v)', '    visit(const Rshift *v)', '    visit(const CompareSelect *v)', '    visit(const ByteImm *v)', '    visit(const CharImm *v)', '    visit(const ShortImm *v)', '    visit(const IntImm *v)', '    visit(const LongImm *v)', '    visit(const FloatImm *v)', '    visit(const DoubleImm *v)', '    visit(const BoolImm *v)', '    visit(const HalfImm *v)', '    visit(const Cast *v)', '    visit(const Var *v)', '    visit(const Let *v)', '    visit(const LetStmt *v)', '    visit(const Ramp *v)', '    visit(const Load *v)', '    visit(const For *v)', '    visit(const Block *v)', '    visit(const Store *v)', '    visit(const Broadcast *v)', '    visit(const IfThenElse *v)', '    visit(const BaseCallNode *v)', '    visit(const Intrinsics *v)', '    visit(const FunctionCall *v)', '    visit(const Allocate *v)', '    visit(const Free *v)', '    visit(const Cond *v)', '    visit(const Term *v)', '    visit(const Polynomial *v)', '    ~IRVisitor'];
int8_simd.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 23;  8; 5;10;  0; 3;0;0;0;0;0.00;0;['    IRParser'];['    parseIR(const std::string & str,torch::jit::Graph *graph)', '    parseIR(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)', '    findValueInVMap(const std::string & name)', '    parse', '    parseAttr(Node *n)', '    parseAttrs(Node *n)', '    parseBlock(Node *parentNode)', '    parseBlockInputs(Block *b)', '    parseBlockOutputs(Block *b)', '    parseBlocks(Node *parentNode)', '    parseGraphInputs', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseOperator(Block *b)', '    parseOperatorInputs(Node *n)', '    parseOperatorName', '    parseOperatorsList(Block *b)', '    parseReturnOperator', '    parseScalarLiteral(Node *n)', '    IRParser(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)', '    parseOperatorOutputs(std::vector *outs)', '    parseVar', '    parseVarWithType(bool allow_optional)'];
int8_slice_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 86;  3; 14;8;  64; 0;40;22;27;32;0.05;3;[];['    parseIR(const std::string & str,torch::jit::Graph *graph)', '    parseIR(const std::string & str,torch::jit::Graph *graph,std::unordered_map & vmap)'];
int8_softmax_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 46;  1; 19;1;  26; 0;24;26;1;7;0.04;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUIsEmpty', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsEmpty'];
int8_softmax_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 102;  14; 19;11;  64; 2;41;36;23;18;0.22;4;['    IsEmptyOp'];['    IsEmptyOp(Args,...)', '    RunOnDevice', '    ~IsEmptyOp'];
int8_test_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 118;  4; 16;26;  74; 0;43;28;38;20;0.05;8;[];[];
int8_transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 28;  1; 11;1;  16; 0;14;16;1;7;0.06;2;[];[];
int8_transpose_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 38;  3; 8;8;  22; 0;11;15;12;13;0.14;2;[];['    IStreamAdapter(std::istream *istream)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    validate(const char *what)', '    ~IStreamAdapter'];
rank_loss_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 205;  9; 23;1;  175; 0;128;93;108;87;0.05;9;[];[];
rank_loss_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  2; 7;5;  22; 0;0;14;34;59;0.09;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAtomicIter', '    CAFFE_ANONYMOUS_VARIABLE_CPUIter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AtomicIter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Iter', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)'];
reciprocal_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  4; 10;6;  37; 0;12;25;7;16;0.11;4;['    final', '    final', '    MutexDeserializer', '    MutexSerializer'];['    IncrementIter(TensorCPU *output)', '    AtomicIterOp(const OperatorDef & operator_def,Workspace *ws)', '    AtomicIterOpStats(std::string name)', '    num_iter', '    IterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    Deserialize(const BlobProto &,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)'];
reciprocal_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 32;  2; 6;5;  21; 0;2;16;2;5;0.10;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAAtomicIter', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIter'];
reduce_front_back_max_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 290;  8; 114;17;  152; 0;86;110;28;76;0.05;13;['    Iterator'];['    get', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const ValidIterator & other)', '    operator==(const SentinelIterator & other)', '    ~IteratorImpl', '    get', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const ValidIterator & other)', '    operator==(const SentinelIterator & other)', '    get', '    lazy_initialize', '    next', '    operator==(const IteratorImpl & other)', '    operator==(const SentinelIterator &)', '    operator==(const ValidIterator & other)', '    ValidIterator(BatchProducer next_batch)', '    Iterator(std::unique_ptr)', '    operator!=(const Iterator & other)', '    operator*', '    operator++', '    operator->', '    operator==(const Iterator & other)'];
reduce_front_back_max_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 138;  2; 25;7;  106; 0;47;65;63;83;0.02;4;[];['    _triu_mask(int64_t n,int64_t dims,bool diagonal,TensorOptions opt)', '    cartesian_prod(TensorList tensors)', '    combinations(const Tensor & self,int64_t r,bool with_replacement)'];
reduce_front_back_sum_mean_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 166;  10; 27;7;  124; 0;57;69;69;84;0.08;7;[];['    CompareKeys(const std::pair & aWrap,const std::pair & bWrap)', '    checkCustomClassType(TypePtr expected_type,TypePtr actual_type)', '    operator<<(std::ostream & out,const IValue & v)', '    printDict(std::ostream & out,const Dict & v,IValueFormatter formatter)', '    printList(std::ostream & out,const T & list,const std::string start,const std::string finish,IValueFormatter formatter)', '    printMaybeAnnotatedDict(std::ostream & out,const IValue & the_dict,IValueFormatter formatter)', '    printMaybeAnnotatedList(std::ostream & out,const IValue & the_list,IValueFormatter formatter)', '    dump', '    getCustomClassTypeMap', '    getSubValues(HashAliasedIValues & subValues)', '    overlaps(const IValue & rhs)', '    repr(std::ostream & out,std::function customFormatter)', '    type', '    create(std::string str_)', '    getAttr(const std::string & name)', '    name', '    resizeObject(size_t slot)', '    setAttr(const std::string & name,IValue v)', '    type', '    unsafeRemoveAttr(const std::string & name)', '    StrongTypePtr(std::shared_ptr cu,std::shared_ptr type)', '    type'];
reduce_front_back_sum_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 289;  8; 114;17;  151; 0;84;108;28;75;0.05;13;[];[];
reduce_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 574;  8; 252;5;  317; 0;197;240;38;117;0.03;31;[];[];
reducer_functors.h;C++;pytorch-master/pytorch-master/caffe2/operators; 839;  85; 99;9;  709; 0;218;433;154;236;0.12;56;[];['    bar', '    TEST(IValueTest,Basic)', '    TEST(IValueTest,Tuple)', '    TEST(IValueTest,unsafeRemoveAttr)', '    TEST(IValueTest,TuplePrint)', '    TEST(IValueTest,BasicFuture)', '    TEST(IValueTest,FutureCallbacks)', '    TEST(IValueTest,FutureExceptions)'];
reduction_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 369;  2; 171;5;  191; 3;143;146;39;116;0.01;25;[];['    TEST(TorchScriptTest,CanCompileMultipleFunctions)', '    TEST(TorchScriptTest,TestNestedIValueModuleArgMatching)', '    TEST(TorchScriptTest,TestDictArgMatching)', '    TEST(TorchScriptTest,TestTupleArgMatching)', '    TEST(TorchScriptTest,TestOptionalArgMatching)', '    TEST(TorchScriptTest,TestPickle)'];
reduction_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 191;  1; 32;12;  147; 0;63;73;124;193;0.01;26;[];['    compile(const std::string & source)'];
relu_n_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 44;  2; 11;5;  28; 0;2;24;8;13;0.07;2;[];[];
relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  9; 65;7;  82; 13;41;59;10;28;0.11;9;[];['    JITException(const std::string & msg)'];
relu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 30;  2; 7;5;  18; 0;0;16;0;5;0.11;0;[];['    JITException(const std::string & msg)'];
remove_data_blocks_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 85;  3; 14;7;  63; 0;41;29;47;49;0.05;4;[];['    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    tanh_add(Tensor x,Tensor y)'];
replace_nan_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 37;  1; 7;1;  29; 0;16;22;6;11;0.03;3;[];['    exp_add(Tensor x,Tensor y)'];
replace_nan_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 45;  2; 13;7;  25; 0;8;17;20;34;0.08;3;[];['    parseJITLogOption(const char *option)', '    fname', '    getHeader(const Node *node)', '    is_enabled(const char *cfname,JitLoggingLevels level)', '    jit_log_prefix(const std::string & prefix,const std::string & in_str)', '    jit_log_prefix(JitLoggingLevels level,const char *fn,int l,const std::string & in_str)', '    log_function(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,JitLoggingLevels level)'];
reshape_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 199;  9; 64;2;  125; 0;115;121;4;16;0.07;5;['    JitLoggingLevels'];['    getHeader(const Node *node)', '    is_enabled(const char *cfname,JitLoggingLevels level)', '    jit_log_level', '    jit_log_prefix(const std::string & prefix,const std::string & in_str)', '    jit_log_prefix(JitLoggingLevels level,const char *fn,int l,const std::string & in_str)', '    log_function(const std::shared_ptr & graph)', '    operator<<(std::ostream & out,JitLoggingLevels level)'];
reshape_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 176;  16; 15;8;  139; 0;69;33;86;53;0.12;4;[];[];
reshape_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;3;  3; 0;1;3;1;5;0.33;1;['    _jarray', '    _jbooleanArray', '    _jbyteArray', '    _jcharArray', '    _jclass', '    _jdoubleArray', '    _jfloatArray', '    _jintArray', '    _jlongArray', '    _jobject', '    _jobjectArray', '    _jshortArray', '    _jstring', '    _jthrowable'];['    __attribute__(visibility)', '    JNI_CreateJavaVM(JavaVM **,JNIEnv **,void *)', '    JNI_GetCreatedJavaVMs(JavaVM **,jsize,jsize *)', '    JNI_GetDefaultJavaVMInitArgs(void *)', '    AttachCurrentThread(JNIEnv **p_env,void *thr_args)', '    AttachCurrentThreadAsDaemon(JNIEnv **p_env,void *thr_args)', '    DestroyJavaVM', '    DetachCurrentThread', '    GetEnv(void **env,jint version)', '    AllocObject(jclass clazz)', '    CallBooleanMethod(jobject obj,jmethodID methodID,...)', '    CallBooleanMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallBooleanMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallByteMethod(jobject obj,jmethodID methodID,...)', '    CallByteMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallByteMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallCharMethod(jobject obj,jmethodID methodID,...)', '    CallCharMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallCharMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallDoubleMethod(jobject obj,jmethodID methodID,...)', '    CallDoubleMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallDoubleMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallFloatMethod(jobject obj,jmethodID methodID,...)', '    CallFloatMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallFloatMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallIntMethod(jobject obj,jmethodID methodID,...)', '    CallIntMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallIntMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallLongMethod(jobject obj,jmethodID methodID,...)', '    CallLongMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallLongMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallNonvirtualBooleanMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualBooleanMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualBooleanMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualByteMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualByteMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualByteMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualCharMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualCharMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualCharMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualDoubleMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualDoubleMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualDoubleMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualFloatMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualFloatMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualFloatMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualIntMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualIntMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualIntMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualLongMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualLongMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualLongMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualObjectMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualObjectMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualObjectMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualShortMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualShortMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualShortMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallNonvirtualVoidMethod(jobject obj,jclass clazz,jmethodID methodID,...)', '    CallNonvirtualVoidMethodA(jobject obj,jclass clazz,jmethodID methodID,const jvalue *args)', '    CallNonvirtualVoidMethodV(jobject obj,jclass clazz,jmethodID methodID,va_list args)', '    CallObjectMethod(jobject obj,jmethodID methodID,...)', '    CallObjectMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallObjectMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallShortMethod(jobject obj,jmethodID methodID,...)', '    CallShortMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallShortMethodV(jobject obj,jmethodID methodID,va_list args)', '    CallStaticBooleanMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticBooleanMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticBooleanMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticByteMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticByteMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticByteMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticCharMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticCharMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticCharMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticDoubleMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticDoubleMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticDoubleMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticFloatMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticFloatMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticFloatMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticIntMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticIntMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticIntMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticLongMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticLongMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticLongMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticObjectMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticObjectMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticObjectMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticShortMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticShortMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticShortMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallStaticVoidMethod(jclass clazz,jmethodID methodID,...)', '    CallStaticVoidMethodA(jclass clazz,jmethodID methodID,const jvalue *args)', '    CallStaticVoidMethodV(jclass clazz,jmethodID methodID,va_list args)', '    CallVoidMethod(jobject obj,jmethodID methodID,...)', '    CallVoidMethodA(jobject obj,jmethodID methodID,const jvalue *args)', '    CallVoidMethodV(jobject obj,jmethodID methodID,va_list args)', '    DefineClass(const char *name,jobject loader,const jbyte *buf,jsize bufLen)', '    DeleteGlobalRef(jobject globalRef)', '    DeleteLocalRef(jobject localRef)', '    DeleteWeakGlobalRef(jweak obj)', '    EnsureLocalCapacity(jint capacity)', '    ExceptionCheck', '    ExceptionClear', '    ExceptionDescribe', '    ExceptionOccurred', '    FatalError(const char *msg)', '    FindClass(const char *name)', '    FromReflectedField(jobject field)', '    FromReflectedMethod(jobject method)', '    GetArrayLength(jarray array)', '    GetBooleanArrayElements(jbooleanArray array,jboolean *isCopy)', '    GetBooleanArrayRegion(jbooleanArray array,jsize start,jsize len,jboolean *buf)', '    GetBooleanField(jobject obj,jfieldID fieldID)', '    GetByteArrayElements(jbyteArray array,jboolean *isCopy)', '    GetByteArrayRegion(jbyteArray array,jsize start,jsize len,jbyte *buf)', '    GetByteField(jobject obj,jfieldID fieldID)', '    GetCharArrayElements(jcharArray array,jboolean *isCopy)', '    GetCharArrayRegion(jcharArray array,jsize start,jsize len,jchar *buf)', '    GetCharField(jobject obj,jfieldID fieldID)', '    GetDirectBufferAddress(jobject buf)', '    GetDirectBufferCapacity(jobject buf)', '    GetDoubleArrayElements(jdoubleArray array,jboolean *isCopy)', '    GetDoubleArrayRegion(jdoubleArray array,jsize start,jsize len,jdouble *buf)', '    GetDoubleField(jobject obj,jfieldID fieldID)', '    GetFieldID(jclass clazz,const char *name,const char *sig)', '    GetFloatArrayElements(jfloatArray array,jboolean *isCopy)', '    GetFloatArrayRegion(jfloatArray array,jsize start,jsize len,jfloat *buf)', '    GetFloatField(jobject obj,jfieldID fieldID)', '    GetIntArrayElements(jintArray array,jboolean *isCopy)', '    GetIntArrayRegion(jintArray array,jsize start,jsize len,jint *buf)', '    GetIntField(jobject obj,jfieldID fieldID)', '    GetJavaVM(JavaVM **vm)', '    GetLongArrayElements(jlongArray array,jboolean *isCopy)', '    GetLongArrayRegion(jlongArray array,jsize start,jsize len,jlong *buf)', '    GetLongField(jobject obj,jfieldID fieldID)', '    GetMethodID(jclass clazz,const char *name,const char *sig)', '    GetObjectArrayElement(jobjectArray array,jsize index)', '    GetObjectClass(jobject obj)', '    GetObjectField(jobject obj,jfieldID fieldID)', '    GetObjectRefType(jobject obj)', '    GetPrimitiveArrayCritical(jarray array,jboolean *isCopy)', '    GetShortArrayElements(jshortArray array,jboolean *isCopy)', '    GetShortArrayRegion(jshortArray array,jsize start,jsize len,jshort *buf)', '    GetShortField(jobject obj,jfieldID fieldID)', '    GetStaticBooleanField(jclass clazz,jfieldID fieldID)', '    GetStaticByteField(jclass clazz,jfieldID fieldID)', '    GetStaticCharField(jclass clazz,jfieldID fieldID)', '    GetStaticDoubleField(jclass clazz,jfieldID fieldID)', '    GetStaticFieldID(jclass clazz,const char *name,const char *sig)', '    GetStaticFloatField(jclass clazz,jfieldID fieldID)', '    GetStaticIntField(jclass clazz,jfieldID fieldID)', '    GetStaticLongField(jclass clazz,jfieldID fieldID)', '    GetStaticMethodID(jclass clazz,const char *name,const char *sig)', '    GetStaticObjectField(jclass clazz,jfieldID fieldID)', '    GetStaticShortField(jclass clazz,jfieldID fieldID)', '    GetStringChars(jstring string,jboolean *isCopy)', '    GetStringCritical(jstring string,jboolean *isCopy)', '    GetStringLength(jstring string)', '    GetStringRegion(jstring str,jsize start,jsize len,jchar *buf)', '    GetStringUTFChars(jstring string,jboolean *isCopy)', '    GetStringUTFLength(jstring string)', '    GetStringUTFRegion(jstring str,jsize start,jsize len,char *buf)', '    GetSuperclass(jclass clazz)', '    GetVersion', '    IsAssignableFrom(jclass clazz1,jclass clazz2)', '    IsInstanceOf(jobject obj,jclass clazz)', '    IsSameObject(jobject ref1,jobject ref2)', '    MonitorEnter(jobject obj)', '    MonitorExit(jobject obj)', '    NewBooleanArray(jsize length)', '    NewByteArray(jsize length)', '    NewCharArray(jsize length)', '    NewDirectByteBuffer(void *address,jlong capacity)', '    NewDoubleArray(jsize length)', '    NewFloatArray(jsize length)', '    NewGlobalRef(jobject obj)', '    NewIntArray(jsize length)', '    NewLocalRef(jobject ref)', '    NewLongArray(jsize length)', '    NewObject(jclass clazz,jmethodID methodID,...)', '    NewObjectA(jclass clazz,jmethodID methodID,const jvalue *args)', '    NewObjectArray(jsize length,jclass elementClass,jobject initialElement)', '    NewObjectV(jclass clazz,jmethodID methodID,va_list args)', '    NewShortArray(jsize length)', '    NewString(const jchar *unicodeChars,jsize len)', '    NewStringUTF(const char *bytes)', '    NewWeakGlobalRef(jobject obj)', '    PopLocalFrame(jobject result)', '    PushLocalFrame(jint capacity)', '    RegisterNatives(jclass clazz,const JNINativeMethod *methods,jint nMethods)', '    ReleaseBooleanArrayElements(jbooleanArray array,jboolean *elems,jint mode)', '    ReleaseByteArrayElements(jbyteArray array,jbyte *elems,jint mode)', '    ReleaseCharArrayElements(jcharArray array,jchar *elems,jint mode)', '    ReleaseDoubleArrayElements(jdoubleArray array,jdouble *elems,jint mode)', '    ReleaseFloatArrayElements(jfloatArray array,jfloat *elems,jint mode)', '    ReleaseIntArrayElements(jintArray array,jint *elems,jint mode)', '    ReleaseLongArrayElements(jlongArray array,jlong *elems,jint mode)', '    ReleasePrimitiveArrayCritical(jarray array,void *carray,jint mode)', '    ReleaseShortArrayElements(jshortArray array,jshort *elems,jint mode)', '    ReleaseStringChars(jstring string,const jchar *chars)', '    ReleaseStringCritical(jstring string,const jchar *carray)', '    ReleaseStringUTFChars(jstring string,const char *utf)', '    SetBooleanArrayRegion(jbooleanArray array,jsize start,jsize len,const jboolean *buf)', '    SetBooleanField(jobject obj,jfieldID fieldID,jboolean value)', '    SetByteArrayRegion(jbyteArray array,jsize start,jsize len,const jbyte *buf)', '    SetByteField(jobject obj,jfieldID fieldID,jbyte value)', '    SetCharArrayRegion(jcharArray array,jsize start,jsize len,const jchar *buf)', '    SetCharField(jobject obj,jfieldID fieldID,jchar value)', '    SetDoubleArrayRegion(jdoubleArray array,jsize start,jsize len,const jdouble *buf)', '    SetDoubleField(jobject obj,jfieldID fieldID,jdouble value)', '    SetFloatArrayRegion(jfloatArray array,jsize start,jsize len,const jfloat *buf)', '    SetFloatField(jobject obj,jfieldID fieldID,jfloat value)', '    SetIntArrayRegion(jintArray array,jsize start,jsize len,const jint *buf)', '    SetIntField(jobject obj,jfieldID fieldID,jint value)', '    SetLongArrayRegion(jlongArray array,jsize start,jsize len,const jlong *buf)', '    SetLongField(jobject obj,jfieldID fieldID,jlong value)', '    SetObjectArrayElement(jobjectArray array,jsize index,jobject value)', '    SetObjectField(jobject obj,jfieldID fieldID,jobject value)', '    SetShortArrayRegion(jshortArray array,jsize start,jsize len,const jshort *buf)', '    SetShortField(jobject obj,jfieldID fieldID,jshort value)', '    SetStaticBooleanField(jclass clazz,jfieldID fieldID,jboolean value)', '    SetStaticByteField(jclass clazz,jfieldID fieldID,jbyte value)', '    SetStaticCharField(jclass clazz,jfieldID fieldID,jchar value)', '    SetStaticDoubleField(jclass clazz,jfieldID fieldID,jdouble value)', '    SetStaticFloatField(jclass clazz,jfieldID fieldID,jfloat value)', '    SetStaticIntField(jclass clazz,jfieldID fieldID,jint value)', '    SetStaticLongField(jclass clazz,jfieldID fieldID,jlong value)', '    SetStaticObjectField(jclass clazz,jfieldID fieldID,jobject value)', '    SetStaticShortField(jclass clazz,jfieldID fieldID,jshort value)', '    Throw(jthrowable obj)', '    ThrowNew(jclass clazz,const char *message)', '    ToReflectedField(jclass cls,jfieldID fieldID,jboolean isStatic)', '    ToReflectedMethod(jclass cls,jmethodID methodID,jboolean isStatic)', '    UnregisterNatives(jclass clazz)'];
resize_3d_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 224;  6; 38;8;  170; 5;108;104;66;90;0.04;11;['    GetBernoulliJSDGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBernoulliJSD', '    CAFFE_ANONYMOUS_VARIABLE_CPUBernoulliJSDGradient', '    kLOG_THRESHOLD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BernoulliJSD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BernoulliJSDGradient', '    entropy(float p)', '    logit(float p)', '    vector', '    RunOnDevice', '    RunOnDevice', '    GetGradientDefs'];
resize_3d_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 92;  1; 17;4;  71; 0;23;41;73;79;0.01;2;['    final', '    final'];['    BernoulliJSDGradientOp(Args,...)', '    BernoulliJSDOp(Args,...)', '    RunOnDevice', '    ~BernoulliJSDGradientOp', '    ~BernoulliJSDOp'];
resize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 358;  9; 47;12;  271; 23;185;161;119;192;0.03;13;[];['    broadcastShapes(const std::vector & a,const std::vector & b)', '    broadcastShapes(const std::vector & a,const std::vector & b,Args,...)', '    checkInputs(const at::ArrayRef & inputs,std::vector & inputTypes)', '    isOne(ExprHandle e)', '    isValidPrimProperty(const c10::optional & a,T b)', '    isValidVaryingShape(const c10::VaryingShape & vs,at::IntArrayRef sz)', '    tensorType(Tensor *t)', '    texprDims(const torch::jit::Value *v)', '    texprSizes(const c10::VaryingShape & shape)', '    bufferSize(T t)', '    newOut', '    getTECudaPointwiseBlockCount', '    getTECudaPointwiseBlockSize', '    getTECudaPointwiseLoopLevels', '    v', '    bindInput(const torch::jit::Value *input)', '    codeGenRun(const std::vector & runArgs)', '    compile', '    computeConditionWithTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeFourOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeOneOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeThreeOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperandWithAlpha(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeValue(const torch::jit::Value *v)', '    constant(const torch::jit::Value *v)', '    createInputIndexExpr(const Buffer & buffer,const std::vector & axes,const c10::VaryingShape & sizes,const c10::VaryingStrides & strides,const c10::VaryingStrides & contiguity,const std::unordered_map & sizeVars)', '    demoteOutput(const ExprHandle & e,const torch::jit::Value *v)', '    lowerToBackend(BackendType backendType)', '    pickAndCheckBackendType(const at::ArrayRef & inputs)', '    promoteInputs(std::vector & inputs)', '    run(Stack & stack)', '    runKernel(Stack & stack)', '    TensorExprKernel(const std::shared_ptr & subgraph)', '    valueShape(const torch::jit::Value *v)'];
reverse_packed_segs_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  1; 6;1;  26; 0;18;24;3;15;0.04;4;['    TensorExprKernel'];['    bufferSizes(const T & t)', '    computeIndicesToBroadcast(const std::vector & outputAxes,const std::vector & inputSizes)', '    getTECudaPointwiseBlockCount', '    getTECudaPointwiseBlockSize', '    getTECudaPointwiseLoopLevels', '    rbegin', '    rend', '    bindInput(const torch::jit::Value *input)', '    broadcast(const T & t,const std::vector & axes)', '    chunk(const T & t,size_t chunkIdx,size_t dim,size_t chunks,const std::vector & axes)', '    codeGenRun(const std::vector & runArgs)', '    compile', '    computeConditionWithTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeFourOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeOneOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeThreeOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperand(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeTwoOperandWithAlpha(const std::string & name,const torch::jit::Value *v,const std::function & innerExpr)', '    computeValue(const torch::jit::Value *v)', '    constant(const torch::jit::Value *v)', '    createInputIndexExpr(const Buffer & buffer,const std::vector & axes,const c10::VaryingShape & sizes,const c10::VaryingStrides & strides,const c10::VaryingStrides & contiguity,const std::unordered_map & sizeVars)', '    demoteOutput(const ExprHandle & e,const torch::jit::Value *v)', '    fallback(Stack & stack)', '    fallback_', '    hasBroadcast_', '    hasRandom_', '    buffer', '    KernelArg(B)', '    KernelArg(B,T,T)', '    sizes', '    strides', '    lowerToBackend(BackendType backendType)', '    pickAndCheckBackendType(const at::ArrayRef & inputs)', '    promoteInputs(std::vector & inputs)', '    run(Stack & stack)', '    runKernel(Stack & stack)', '    ShapeArg(size_t i,VarHandle v)', '    TensorExprKernel(const std::shared_ptr & subgraph)', '    tensorOrConstant(const torch::jit::Value *v,const std::vector & axes)', '    valueShape(const torch::jit::Value *v)', '    unique'];
reverse_packed_segs_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 89;  2; 15;5;  69; 0;39;33;45;52;0.03;5;[];['    getKernelCache', '    nolock_retrieve(KernelCacheImpl & cache,const int64_t key)', '    debugNumCachedKernelSpecs', '    lookupGraph(std::shared_ptr graph)', '    normalizeGraphForCache(const std::shared_ptr & graph)', '    retrieve(const int64_t key)', '    store(std::shared_ptr graph)', '    kernel_counter'];
rmac_regions_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 127;  15; 20;2;  93; 0;75;58;36;41;0.16;3;[];['    debugNumCachedKernelSpecs', '    lookupGraph(std::shared_ptr graph)', '    normalizeGraphForCache(const std::shared_ptr & graph)', '    retrieve(const int64_t key)', '    store(std::shared_ptr graph)'];
recurrent_op_miopen.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn/hip; 140;  6; 24;23;  90; 0;4;69;108;207;0.07;4;[];[];
recurrent_network_blob_fetcher_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 28;  1; 7;1;  20; 0;15;18;1;10;0.05;2;[];['    func(Args,...)', '    concatKernel(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    decrementKernel(const Tensor & tensor,int64_t input)', '    errorKernel(const Tensor & tensor,int64_t input)', '    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    final', '    incrementKernel(const Tensor & tensor,int64_t input)', '    kernelForSchemaInference(Tensor arg1,int64_t arg2,const std::vector & arg3)', '    kernelWithDictInputWithoutOutput(Dict input1)', '    kernelWithDictInputWithOutput(Dict input1)', '    kernelWithDictOutput(Dict input)', '    kernelWithIntInputWithoutOutput(Tensor,int64_t input1)', '    kernelWithIntInputWithOutput(Tensor,int64_t input1)', '    kernelWithIntListInputWithoutOutput(Tensor,const std::vector & input1)', '    kernelWithIntListInputWithOutput(Tensor,const std::vector & input1)', '    kernelWithIntListOutput(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    kernelWithIntOutput(Tensor,int64_t a,int64_t b)', '    kernelWithLegacyTensorListInputWithoutOutput(std::vector input1)', '    kernelWithLegacyTensorListInputWithOutput(std::vector input1)', '    kernelWithLegacyTensorVectorInputWithoutOutput(const std::vector & input1)', '    kernelWithLegacyTensorVectorInputWithOutput(const std::vector & input1)', '    kernelWithOptInputWithoutOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithOptInputWithOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithoutInputs', '    kernelWithoutOutput(const Tensor &)', '    kernelWithoutTensorInputs(int64_t arg)', '    kernelWithStringListOutput(std::vector input)', '    kernelWithTensorInputByReferenceWithoutOutput(const Tensor & input1)', '    kernelWithTensorInputByReferenceWithOutput(const Tensor & input1)', '    kernelWithTensorInputByValueWithoutOutput(Tensor input1)', '    kernelWithTensorInputByValueWithOutput(Tensor input1)', '    kernelWithTensorListInputWithoutOutput(const std::vector & input1)', '    kernelWithTensorListInputWithOutput(const std::vector & input1)', '    kernelWithTensorListOutput(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    kernelWithTensorOutput(const Tensor & input)', '    kernelWithUnorderedMapInputWithoutOutput(std::unordered_map input1)', '    kernelWithUnorderedMapInputWithOutput(std::unordered_map input1)', '    kernelWithUnorderedMapOutput(std::unordered_map input)', '    kernelWithZeroOutputs(const Tensor &)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegisteredInConstructor_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorVectorInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithLegacyTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithStringListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithUnorderedMapOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMapOfList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithMapOfListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithListOfMapOfIntList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyFunctionBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    func(Args,...)'];
recurrent_network_blob_fetcher_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 70;  2; 15;10;  45; 0;21;41;25;47;0.04;2;[];['    func(Args,...)', '    concatKernel(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    decrementKernel(const Tensor & tensor,int64_t input)', '    errorKernel(const Tensor & tensor,int64_t input)', '    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectCannotCallConcatBoxed(DispatchKey dispatch_key)', '    final', '    incrementKernel(const Tensor & tensor,int64_t input)', '    kernelForSchemaInference(Tensor arg1,int64_t arg2,const c10::List & arg3)', '    kernelWithDictInputWithoutOutput(Dict input1)', '    kernelWithDictInputWithOutput(Dict input1)', '    kernelWithDictOutput(Dict input)', '    kernelWithIntInputWithoutOutput(Tensor,int64_t input1)', '    kernelWithIntInputWithOutput(Tensor,int64_t input1)', '    kernelWithIntListInputWithoutOutput(Tensor,const c10::List & input1)', '    kernelWithIntListInputWithOutput(Tensor,const c10::List & input1)', '    kernelWithIntListOutput(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    kernelWithIntOutput(Tensor,int64_t a,int64_t b)', '    kernelWithOptInputWithoutOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithOptInputWithOutput(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    kernelWithoutInputs', '    kernelWithoutOutput(const Tensor &)', '    kernelWithoutTensorInputs(int64_t arg)', '    kernelWithTensorInputByReferenceWithoutOutput(const Tensor & input1)', '    kernelWithTensorInputByReferenceWithOutput(const Tensor & input1)', '    kernelWithTensorInputByValueWithoutOutput(Tensor input1)', '    kernelWithTensorInputByValueWithOutput(Tensor input1)', '    kernelWithTensorListInputWithoutOutput(const c10::List & input1)', '    kernelWithTensorListInputWithOutput(const c10::List & input1)', '    kernelWithTensorListOutput(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    kernelWithTensorOutput(const Tensor & input)', '    kernelWithZeroOutputs(const Tensor &)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredUnboxedOnly_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredUnboxedOnly_thenCannotBeCalledBoxed)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctionBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    func(Args,...)'];
recurrent_network_executor.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 232;  41; 31;2;  160; 0;98;44;96;53;0.26;6;[];[];
recurrent_network_executor.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 530;  94; 58;11;  369; 0;201;133;169;104;0.25;16;['    final', '    final', '    final'];['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectThrows', '    expectThrows', '    final', '    operator()(Args,...)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithTupleInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithCache_thenCacheIsKeptCorrectly)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithConstructorArg_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithMultipleConstructorArgs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenKernel_whenRegisteredCatchAllWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_FunctorBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)', '    ConcatKernel(std::string prefix)', '    KernelWithCache', '    KernelWithConstructorArg(int64_t offset)', '    KernelWithMultipleConstructorArgs(int64_t offset1,int64_t offset2)', '    operator()(const Tensor & input1)', '    operator()(const Tensor & input1)', '    operator()(const Tensor & input)', '    operator()(Dict input)', '    operator()(Dict input1)', '    operator()(Tensor,int64_t a,int64_t b)', '    operator()(Dict input1)', '    operator()(const Tensor & input1,const Tensor & input2,const Tensor & input3)', '    operator()(const Tensor &,int64_t input1,int64_t input2,int64_t input3)', '    operator()(const Tensor &,int64_t input)', '    operator()(const Tensor &,int64_t input)', '    operator()(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    operator()(Tensor arg1,const c10::optional & arg2,c10::optional arg3,c10::optional arg4)', '    operator()(Tensor,int64_t input1)', '    operator()(Tensor,int64_t input1)', '    operator()(const Tensor & tensor,int64_t input)', '    operator()(std::tuple input1)', '    operator()(const Tensor &)', '    operator()(const Tensor &)', '    operator()', '    operator()(int64_t arg)', '    operator()(Tensor,const c10::List & input1)', '    operator()(Tensor,const c10::List & input1)', '    operator()(const Tensor & tensor1,std::string a,const std::string & b,int64_t c)', '    operator()(Tensor arg1,int64_t arg2,const c10::List & arg3)', '    operator()(Args,...)', '    operator()(Tensor input1)', '    operator()(const Tensor & tensor,int64_t input)', '    operator()(const Tensor &,int64_t)', '    operator()(Tensor)', '    operator()(Tensor input1)', '    operator()(const c10::List & input1)', '    operator()(const c10::List & input1)', '    Tensor', '    Tensor'];
recurrent_network_executor_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 155;  21; 19;2;  115; 0;69;43;69;35;0.18;5;[];[];
recurrent_network_executor_incl.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 74;  18; 12;5;  48; 0;21;26;19;24;0.38;6;[];['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegisteredInConstructor_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorVectorInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorVectorInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithLegacyTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithStringListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithUnorderedMapOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMapOfList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithMapOfListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithListOfMap_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithListOfMapOfIntList_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LegacyLambdaBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)'];
recurrent_network_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 260;  11; 46;8;  195; 2;110;91;87;85;0.06;16;[];['    expectCallsConcatUnboxed(DispatchKey dispatch_key)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    my_kernel', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenOutOfLineKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithZeroOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByReference_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByValue_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByReference_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorInputByValue_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithIntListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithTensorListInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictInput_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictInput_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithDictOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withoutOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withOutput_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernelWithOptionalInputs_withMultipleOutputs_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegistered_thenCanBeCalledUnboxed)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenInfersSchema)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentNumArguments_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentArgumentType_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentNumReturns_whenRegistering_thenFails)', '    TEST(OperatorRegistrationTest_LambdaBasedKernel,givenMismatchedKernel_withDifferentReturnTypes_whenRegistering_thenFails)'];
recurrent_network_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 945;  83; 111;10;  747; 0;449;330;430;338;0.11;37;[];['    cacheKernel(const ArgSpec & arg_spec,std::shared_ptr kernel)', '    code', '    graph', '    guard', '    hasRandom', '    inputChunks', '    inputChunks', '    key', '    nInputs', '    nTensorInputs', '    dim', '    nSubTensors', '    dim_', '    PartitionInfo(const int64_t _nSubTensors,const int64_t _dim)', '    code_', '    graph_', '    inputBroadcastGroups_', '    inputChunks_', '    kernels_', '    KernelSpec(const int64_t _key,const std::shared_ptr & _graph)', '    nInputs_', '    nTensorInputs_'];
recurrent_op_cudnn.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 150;  4; 24;24;  101; 0;9;79;131;226;0.04;5;[];['    decrementKernel(const OperatorHandle &,Stack *stack)', '    errorKernel(const OperatorHandle &,Stack *stack)', '    expectCallsDecrement(DispatchKey dispatch_key)', '    expectCallsIncrement(DispatchKey dispatch_key)', '    expectCallsIncrementUnboxed(DispatchKey dispatch_key)', '    incrementKernel(const OperatorHandle &,Stack *stack)', '    kernelForSchemaInference(const OperatorHandle &,Stack *stack)', '    kernelWithoutInputs(const OperatorHandle &,Stack *)', '    kernelWithoutTensorInputs(const OperatorHandle &,Stack *stack)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInOneRegistrar_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenMultipleOperatorsAndKernels_whenRegisteredInMultipleRegistrars_thenCallsRightKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistrationRunsOutOfScope_thenCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenFallbackKernelWithoutAnyArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenFallbackKernelWithoutTensorArguments_whenRegistered_thenCanBeCalled)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegisteredWithoutSpecifyingSchema_thenFailsBecauseItCannotInferFromStackBasedKernel)', '    TEST(OperatorRegistrationTest_StackBasedKernel,givenKernel_whenRegistered_thenCanAlsoBeCalledUnboxed)'];
roi_align_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 282;  40; 41;3;  217; 0;135;113;58;70;0.18;9;[];['    fallthrough_kernel(OperatorKernel *,const OperatorHandle &,Stack *)', '    _equalsBoxedAndUnboxed(const KernelFunction & other)', '    dumpState'];
roi_align_gradient_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 49;  3; 9;7;  32; 0;5;21;22;35;0.09;2;[];[];
roi_align_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 94;  2; 13;7;  74; 0;27;56;35;54;0.03;3;[];[];
roi_align_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 271;  7; 30;8;  228; 0;147;99;99;73;0.03;9;[];['    expectUnboxedCallingWithoutReturnWorks(const KernelFunction & func)', '    expectUnboxedCallingWithReturnWorks(const KernelFunction & func)', '    boxed_func_with_return(const OperatorHandle &,Stack *stack)', '    boxed_func_without_return(const OperatorHandle &,Stack *stack)', '    expectBoxedCallingFailsWith(const KernelFunction & func,const char *errorMessage)', '    expectBoxedCallingWithoutReturnWorks(const KernelFunction & func)', '    expectBoxedCallingWithReturnWorks(const KernelFunction & func)', '    makeDummyOperatorHandle', '    unboxed_function_with_return(int64_t a,int64_t b)', '    unboxed_function_without_return(int64_t a,int64_t b)', '    unboxed_lambda_with_return', '    unboxed_lambda_without_return', '    stack', '    stack', '    stack', '    TEST(KernelFunctionTest,givenBoxedFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenBoxedFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctor_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunctorFactory_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withoutReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunctor_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withoutReturn_whenCallingBoxed_thenFails)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedOnlyFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedRuntimeFunction_withoutReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withoutReturn_whenCallingBoxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withReturn_whenCallingUnboxed_thenWorks)', '    TEST(KernelFunctionTest,givenUnboxedLambda_withoutReturn_whenCallingUnboxed_thenWorks)', '    operator()(int64_t a,int64_t b)', '    operator()(int64_t a,int64_t b)', '    operator()', '    operator()'];
roi_align_rotated_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  4; 8;3;  22; 0;12;20;2;12;0.18;3;[];['    GET_BLOCKS(const int N)'];
roi_align_rotated_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 440;  40; 51;12;  357; 1;227;185;108;114;0.11;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUKeySplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_KeySplit'];
roi_align_rotated_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  3; 9;7;  36; 0;6;24;23;36;0.08;2;['    KeySplitOp'];['    GetSingleArgument', '    KeySplitOp(Args,...)', '    RunOnDevice'];
roi_pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 206;  22; 30;2;  157; 0;133;121;50;66;0.14;7;[];['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)'];
rowmul_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 52;  2; 11;1;  40; 0;20;37;4;25;0.05;6;['    final'];['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)'];
rowmul_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 76;  6; 15;7;  50; 0;25;30;52;76;0.12;6;[];['    main(int argc,const char *[] argv)'];
rsqrt_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 72;  4; 13;5;  54; 0;24;38;6;24;0.07;7;[];['    main(int argc,const char *[] argv)'];
scale_blobs_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 18;  1; 6;1;  11; 0;9;11;1;7;0.09;2;['    L2ErrorMinimization'];['    L2MinimizationKernelAVX2(int precision,float *bins,int nbins,float bin_width,float dst_bin_width,int start_bin)', '    L2ErrorMinimization'];
scale_blobs_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 58;  2; 10;6;  42; 0;16;25;25;42;0.05;3;[];['    main(int argc,const char *[] argv)'];
scale_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  2; 5;1;  19; 0;11;17;3;15;0.11;4;[];['    main(int argc,const char *[] argv)'];
scale_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 13;  1; 4;2;  7; 0;2;5;2;6;0.14;2;['    ChooseQuantizationTest'];['    TEST_P(ChooseQuantizationTest,L2MinimizationTest)'];
segment_reduction_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 614;  26; 196;84;  317; 0;140;123;47;381;0.08;64;[];[];
segment_reduction_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 2060;  252; 305;8;  1521; 0;63;103;56;152;0.17;9;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULars', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Lars', '    ComputeLearningRate(const float *wd,const float *trust,const float *lr_max,float offset,float lr_min,float *X_norm,float *dX_norm,float *lr_rescaled)'];
selu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 58;  4; 11;7;  38; 0;10;20;46;61;0.11;2;['    final'];['    ComputeLearningRate(const T *wd,const T *trust,const T *lr_max,T offset,T lr_min,T *X_norm,T *dX_norm,T *lr_rescaled)', '    ComputeNorms(int64_t N,const T *X_data,const T *dX_data,T *X_norm,T *dX_norm)', '    GetSingleArgument', '    LarsOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
sequence_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 537;  18; 147;5;  368; 0;263;241;111;205;0.05;18;['    LastNWindowCollectorOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPULastNWindowCollector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LastNWindowCollector', '    collect', '    LastNWindowCollectorOp(Args,...)', '    RunOnDevice'];
sequence_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 262;  18; 29;6;  215; 0;107;109;143;162;0.08;15;[];['    lastPow2(unsigned int n)'];
shape_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 54;  4; 10;3;  38; 0;20;23;35;43;0.11;2;[];['    layer_norm(const Tensor & input,IntArrayRef normalized_shape,const Tensor & weight,const Tensor & bias,double eps,bool)', '    layer_norm_backward_cpu(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,std::array grad_input_mask)', '    layer_norm_cpu(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,double eps)'];
shape_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 6;  0; 1;2;  3; 0;1;3;1;5;0.00;1;[];['    LayerNormBackwardKernel', '    LayerNormBackwardKernel', '    operator=', '    LayerNormKernel', '    LayerNormKernel', '    operator='];
sigmoid_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  4; 10;6;  37; 0;12;25;7;16;0.11;4;[];['    LayerNormBackwardKernelImpl(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,Tensor *dX,Tensor *dgamma,Tensor *dbeta)', '    LayerNormBackwardKernelImplInternal(const Tensor & dY,const Tensor & X,const Tensor & mean,const Tensor & rstd,const Tensor & gamma,int64_t M,int64_t N,Tensor *dX,Tensor *dgamma,Tensor *dbeta)', '    LayerNormKernelImpl(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,double eps,Tensor *Y,Tensor *mean,Tensor *rstd)', '    LayerNormKernelImplInternal(const Tensor & X,const Tensor & gamma,const Tensor & beta,int64_t M,int64_t N,T eps,Tensor *Y,Tensor *mean,Tensor *rstd)'];
sigmoid_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 30;  2; 7;5;  18; 0;0;16;0;5;0.11;0;['    GetLayerNormGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULayerNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPULayerNormGradient', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LayerNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LayerNormGradient', '    GetGradientDefs', '    ComputeFusedParams(const int M,const int N,const T *mean,const T *sigma,const T *ds,const T *db,T *rstd,T *X_scale,T *bias,T *g_scale)', '    ComputeInternalGradients(const int M,const int N,const T *dY,const T *X,const T *gamma,T *dYxX,T *ds,T *db)', '    GammaBetaBackward(const int M,const int N,const T *dYxX,const T *dY,const T *rstd,const T *g_scale,T *dgamma,T *dbeta)', '    LayerNormBackward(const int M,const int N,const T *dY,const T *X,const T *gamma,const T *dY_scale,const T *X_scale,const T *bias,T *dX)', '    ComputeSigmaAndFusedParams(const int N,const float eps,const T *mean,const T *var,T *sigma,T *scale,T *bias)', '    vector'];
sigmoid_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 12;  1; 4;2;  6; 0;0;4;0;5;0.17;0;['    final', '    final'];['    schema_LayerNorm', '    bias_', '    ComputeFusedParams(const int M,const int N,const T *mean,const T *sigma,const T *ds,const T *db,T *rstd,T *X_scale,T *bias,T *g_scale)', '    ComputeInternalGradients(const int M,const int N,const T *dY,const T *X,const T *gamma,T *dYxX,T *ds,T *db)', '    ComputeSigmaAndFusedParams(const int N,const float eps,const T *mean,const T *var,T *stddev,T *scale,T *bias)', '    DoRunWithType', '    DoRunWithType', '    GammaBetaBackward(const int M,const int N,const T *dYxX,const T *dY,const T *rstd,const T *g_scale,T *dgamma,T *dbeta)', '    LayerNormBackward(const int M,const int N,const T *dY,const T *X,const T *gamma,const T *dY_scale,const T *X_scale,const T *bias,T *dX)', '    LayerNormForward(const int M,const int N,const T *X,const T *scale,const T *bias,const T *gamma,const T *beta,T *Y)', '    LayerNormGradientOp(Args,...)', '    LayerNormOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    scale_'];
sin_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 108;  4; 46;4;  58; 0;31;44;8;24;0.07;7;[];['    self', '    THPLayout_init(PyObject *module)', '    THPLayout_New(at::Layout layout,const std::string & name)', '    THPLayout_repr(THPLayout *self)'];
sinh_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 115;  4; 46;3;  66; 0;36;49;8;24;0.06;7;[];['    THPLayout_Check(PyObject *obj)', '    THPLayout_init(PyObject *module)', '    THPLayout_New(at::Layout layout,const std::string & name)'];
sinh_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];[];
sinusoid_position_encoding_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  1; 16;1;  17; 0;13;15;1;7;0.06;2;[];[];
slice_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 144;  6; 52;2;  88; 0;71;76;5;29;0.07;5;[];['    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    _cubic_interpolate(double x1,double f1,double g1,double x2,double f2,double g2,c10::optional,double)', '    _strong_wolfe(const Function & obj_func,const std::vector & x,double t,const Tensor & d,double f,Tensor g,const Tensor & gtd,double c1,double c2,double tolerance_change,double max_ls)', '    if_container_equal(T lhs,T rhs)', '    operator==(const LBFGSOptions & lhs,const LBFGSOptions & rhs)', '    operator==(const LBFGSParamState & lhs,const LBFGSParamState & rhs)', '    _add_grad(const double step_size,const Tensor & update)', '    _clone_param', '    _directional_evaluate(const LossClosure & closure,const std::vector & x,double t,const Tensor & d)', '    _gather_flat_grad', '    _numel', '    _set_param(const std::vector & params_data)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    LBFGSOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)'];
slice_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 333;  8; 45;4;  279; 0;191;146;170;144;0.03;7;[];[];
softmax_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 187;  5; 68;2;  113; 0;90;61;31;43;0.04;8;['    LeakyReLUOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    negativeSlope(float negativeSlope)', '    negativeSlope', '    negativeSlope_', '    outputScale(float outputScale)', '    outputScale', '    outputScale_', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint(uint8_t outputZeroPoint)', '    outputZeroPoint', '    outputZeroPoint_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8'];
softmax_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 148;  3; 17;4;  127; 0;39;62;53;67;0.02;8;[];['    pytorch_qnnp_create_leaky_relu_nc_q8(size_t channels,float negative_slope,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *leaky_relu_out)', '    pytorch_qnnp_setup_leaky_relu_nc_q8(pytorch_qnnp_operator_t leaky_relu,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
softmax_utils.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 38;  2; 4;29;  5; 0;1;5;11;3;0.40;1;[];['    TEST(LEAKY_RELU_OP,zero_batch)', '    TEST(LEAKY_RELU_OP,unit_batch)', '    TEST(LEAKY_RELU_OP,unit_batch_with_qmin)', '    TEST(LEAKY_RELU_OP,unit_batch_with_qmax)', '    TEST(LEAKY_RELU_OP,unit_batch_with_negative_slope)', '    TEST(LEAKY_RELU_OP,unit_batch_with_input_scale)', '    TEST(LEAKY_RELU_OP,unit_batch_with_input_zero_point)', '    TEST(LEAKY_RELU_OP,unit_batch_with_output_scale)', '    TEST(LEAKY_RELU_OP,unit_batch_with_output_zero_point)', '    TEST(LEAKY_RELU_OP,small_batch)', '    TEST(LEAKY_RELU_OP,small_batch_with_input_stride)', '    TEST(LEAKY_RELU_OP,small_batch_with_output_stride)', '    TEST(LEAKY_RELU_OP,small_batch_with_input_and_output_stride)'];
softmax_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators; 23;  3; 5;5;  13; 0;0;13;0;3;0.23;0;['    GetLeakyReluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULeakyRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPULeakyReluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LeakyRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LeakyReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
softmax_with_loss_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 88;  9; 11;7;  68; 0;7;54;48;78;0.13;5;['    final', '    LeakyReluOp'];['    LeakyReluGradientOp(Args,...)', '    RunOnDevice', '    LeakyReluOp(Args,...)', '    RunOnDevice'];
softplus_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 122;  3; 57;3;  60; 0;46;45;12;31;0.05;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULearningRateAdaption', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LearningRateAdaption'];
softplus_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 36;  3; 10;7;  18; 0;0;10;34;55;0.17;4;['    final'];['    lr_update(int n,const float *grad,const float *effgrad,const float *lr,float *nlr,float lr_alpha,bool normalized_lr_adaption,Context *)', '    GetSingleArgument', '    LearningRateAdaptionOp(const OperatorDef & operator_def,Workspace *ws)', '    lr_alpha_', '    normalized_lr_adaption_', '    RunOnDevice', '    ResizeLike'];
softsign_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 31;  2; 7;6;  18; 0;0;16;0;5;0.11;0;['    AlternateLearningRate', '    CompositeCosineLearningRate', '    CompositeCyclicalLearningRate', '    CompositeLearningRate', '    CompositeLearningRateItem', '    ConstantThenLinearWarmupLearningRate', '    ConstantWarmupLearningRate', '    CosineLearningRate', '    CyclicalLearningRate', '    ExpLearningRate', '    FixedLearningRate', '    GateLearningRate', '    HillLearningRate', '    InvLearningRate', '    LearningRateFunctor', '    LinearWarmupLearningRate', '    PieceWarmupLearningRate', '    PolyLearningRate', '    StepLearningRate'];['    AlternateLearningRate(const int64_t active_period,const int64_t inactive_period,const bool active_first)', '    operator()(const int64_t iter)', '    CompositeCosineLearningRate(const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter,const T cosine_min_lr,const T cosine_max_lr,const int64_t cosine_period,const T consine_t_mult,const T cosine_lr_shrink)', '    operator()(const int64_t iter)', '    CompositeCyclicalLearningRate(const T base_lr,const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter,const T cyclical_max_lr,const int cyclical_step_size,const T cyclical_decay)', '    operator()(const int64_t iter)', '    CompositeLearningRate(const std::list)', '    operator()(const int64_t iter)', '    CompositeLearningRateItem(int64_t num_iter,float lr_scale,LearningRateFunctor *policy)', '    ConstantThenLinearWarmupLearningRate(const T start_warmup_multiplier,const int64_t constant_warmup_num_iter,const int64_t linear_warmup_num_iter)', '    operator()(const int64_t iter)', '    ConstantWarmupLearningRate(const T multiplier,const int64_t num_iter)', '    operator()(const int64_t iter)', '    CosineLearningRate(const T min_lr,const T max_lr,const int64_t period,const T t_mult,const T lr_shrink)', '    operator()(const int64_t iter)', '    CyclicalLearningRate(const T base_lr,const T max_lr,const int stepsize,const T)', '    operator()(const int64_t iter)', '    ExpLearningRate(const T gamma)', '    operator()(const int64_t iter)', '    operator()(const int64_t)', '    GateLearningRate(const T multiplier_1,const T multiplier_2,const int64_t num_iter)', '    operator()(const int64_t iter)', '    HillLearningRate(const int64_t num_iter,const T start_multiplier,const T gamma,const T,const T end_multiplier)', '    operator()(const int64_t iter)', '    InvLearningRate(const T gamma,const T)', '    operator()(const int64_t iter)', '    operator()(const int64_t iter)', '    ~LearningRateFunctor', '    LinearWarmupLearningRate(const T start_multiplier,const int64_t num_iter)', '    operator()(const int64_t iter)', '    operator()(const int64_t iter)', '    PieceWarmupLearningRate(const T m1,const int64_t n1,const T m2,const int64_t n2,const T m3)', '    operator()(const int64_t iter)', '    PolyLearningRate(const T,const int64_t max_iter)', '    operator()(const int64_t iter)', '    StepLearningRate(const int stepsize,const T gamma)'];
space_batch_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 121;  0; 72;1;  48; 0;34;44;6;28;0.00;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULearningRate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LearningRate'];
space_batch_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 209;  4; 22;7;  180; 0;104;112;104;145;0.02;5;['    final'];['    createLearningRateFunctor(const string & policy,const string & arg_prefix)', '    LearningRateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
sparse_dropout_with_replacement_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  3; 7;7;  20; 0;2;15;25;33;0.15;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDALearningRate'];
sparse_normalize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 77;  3; 16;3;  56; 0;30;44;2;42;0.05;3;[];[];
sparse_normalize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 33;  1; 7;3;  23; 0;1;18;21;34;0.04;1;[];[];
sparse_to_dense_mask_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 294;  12; 30;10;  244; 0;167;106;199;173;0.05;8;['    MyException'];['    TEST(LeftRightTest,givenInt_whenWritingAndReading_thenChangesArePresent)', '    TEST(LeftRightTest,givenVector_whenWritingAndReading_thenChangesArePresent)', '    TEST(LeftRightTest,givenVector_whenWritingReturnsValue_thenValueIsReturned)', '    TEST(LeftRightTest,readsCanBeConcurrent)', '    TEST(LeftRightTest,writesCanBeConcurrentWithReads_readThenWrite)', '    TEST(LeftRightTest,writesCanBeConcurrentWithReads_writeThenRead)', '    TEST(LeftRightTest,writesCannotBeConcurrentWithWrites)', '    TEST(LeftRightTest,whenReadThrowsException_thenThrowsThrough)', '    TEST(LeftRightTest,whenWriteThrowsException_thenThrowsThrough)', '    TEST(LeftRightTest,givenInt_whenWriteThrowsExceptionOnFirstCall_thenResetsToOldState)', '    TEST(LeftRightTest,givenInt_whenWriteThrowsExceptionOnSecondCall_thenKeepsNewState)', '    TEST(LeftRightTest,givenVector_whenWriteThrowsException_thenResetsToOldState)'];
sparse_to_dense_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 59;  1; 22;2;  35; 0;25;33;3;16;0.03;4;[];[];
sparse_to_dense_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 127;  4; 19;6;  100; 0;61;48;66;65;0.04;8;[];['    gather_cuda(const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    gather_out_cuda(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    masked_fill__cuda(Tensor & self,const Tensor & mask,Scalar value)', '    masked_fill__cuda(Tensor & self,const Tensor & mask,const Tensor & value)', '    masked_scatter__cuda(Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_select_cuda(const Tensor & self,const Tensor & mask)', '    masked_select_out_cuda(Tensor & result,const Tensor & self,const Tensor & mask)'];
spatial_batch_norm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 143;  6; 30;3;  110; 0;101;107;3;14;0.05;3;[];['    argsort(const Tensor & self,int64_t dim,bool descending)', '    masked_scatter__cpu(Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_select_cpu(const Tensor & self,const Tensor & mask)', '    masked_select_out_cpu(Tensor & result,const Tensor & self,const Tensor & mask)'];
spatial_batch_norm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 474;  6; 36;12;  422; 0;251;223;183;179;0.01;9;[];['    getLegacyDeviceTypeInit', '    RegistryName'];
spatial_softmax_with_loss_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 262;  25; 42;2;  204; 0;155;111;94;94;0.12;8;[];[];
sqr_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 93;  2; 48;3;  42; 0;24;37;5;21;0.05;5;[];['    log_sigmoid(const Tensor & self)', '    log_sigmoid_out(Tensor & output,const Tensor & self)', '    multilabel_margin_loss(const Tensor & self,const Tensor & target,int64_t reduction)', '    multilabel_margin_loss_out(Tensor & output,const Tensor & self,const Tensor & target,int64_t reduction)', '    nll_loss(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_out(Tensor & output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_out(Tensor & output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    thnn_conv2d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    thnn_conv2d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding)', '    thnn_conv_depthwise2d(const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)', '    thnn_conv_depthwise2d_out(Tensor & output,const Tensor & self,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)'];
sqr_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  2; 5;5;  10; 0;2;6;2;3;0.20;1;[];['    $', '    $', '    $', '    allocator', '    infer_scalar_type(const TensorList & tl)', '    options(ScalarType)'];
sqr_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 4;2;  8; 0;1;3;1;5;0.13;1;[];[];
sqrt_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  2; 5;5;  10; 0;2;6;2;3;0.20;1;[];['    globalLegacyTypeDispatch'];
sqrt_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  1; 4;2;  8; 0;1;3;1;5;0.13;1;[];[];
square_root_divide_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 43;  1; 22;1;  20; 0;12;18;3;15;0.05;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsSplit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsSplit'];
stats_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 345;  1; 107;5;  233; 0;150;168;58;115;0.00;36;['    final'];['    LengthsSplitOp(Args,...)', '    RunOnDevice', '    ~LengthsSplitOp'];
stats_put_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 110;  1; 23;10;  77; 0;66;68;3;31;0.01;12;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsPad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsPad'];
stats_put_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  9; 11;5;  71; 0;35;30;23;16;0.13;4;['    LengthsPadOp'];['    DoRunWithType', '    lengths_host_', '    LengthsPadOp(Args,...)', '    RunOnDevice'];
stop_gradient.h;C++;pytorch-master/pytorch-master/caffe2/operators; 25;  3; 5;4;  16; 0;5;8;20;30;0.19;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwiseFakeFP16NNPI'];
stop_gradient_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 6;  1; 1;2;  3; 0;1;3;1;5;0.33;1;['    final'];['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused4BitRowwiseFakeFP16Op(const OperatorDef & operator_def,Workspace *ws)', '    ~SparseLengthsFused4BitRowwiseFakeFP16Op'];
string_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 192;  1; 41;2;  149; 0;0;0;0;1;0.01;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwiseFakeFP32NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16AccInvScaleFP16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16EmbeddingOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwiseFakeFP32NNPI'];
string_ops_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 138;  0; 27;3;  108; 0;73;51;55;48;0.00;7;['    final'];['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused8BitRowwiseFakeFP16Op(const OperatorDef & operator_def,Workspace *ws)', '    static_assert(,)', '    ~SparseLengthsFused8BitRowwiseFakeFP16Op'];
stump_func_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 102;  16; 16;1;  70; 0;50;56;10;55;0.23;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused8BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused8BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused8BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused8BitRowwise'];
stump_func_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 71;  23; 15;5;  30; 0;0;22;34;57;0.77;2;['    SparseLengthsFused8BitRowwiseOp'];['    DoRunWithType', '    RunOnDevice', '    SparseLengthsFused8BitRowwiseOp(Args,...)', '    static_assert(,)', '    ~SparseLengthsFused8BitRowwiseOp'];
summarize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 69;  6; 10;1;  53; 0;43;34;23;24;0.11;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanFused4BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumFused4BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum2BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum4BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum8BitRowwiseSparse', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused2BitRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumFused4BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum2BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum4BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum8BitRowwiseSparse', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused2BitRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumFused4BitRowwise'];
summarize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  7; 10;7;  39; 0;16;19;25;38;0.18;2;['    final', '    final'];['    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SparseLengthsFusedNBitRowwiseOp(const OperatorDef & def,Workspace *ws)', '    SparseLengthsNBitRowwiseSparseOp(const OperatorDef & def,Workspace *ws)', '    static_assert(,)', '    ~SparseLengthsFusedNBitRowwiseOp', '    ~SparseLengthsNBitRowwiseSparseOp'];
swish_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 94;  6; 21;6;  64; 0;40;46;21;36;0.09;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsPositionalWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumGradient', '    FormatDoc'];
tan_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 69;  4; 13;4;  52; 0;25;38;8;24;0.08;7;[];[];
tan_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;['    CPUSparseLengthsReductionOp'];['    CPUSparseLengthsReductionOp(Args,...)', '    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    ~CPUSparseLengthsReductionOp', '    call'];
tanh_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 53;  4; 10;6;  37; 0;12;25;7;16;0.11;4;['    final'];['    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    SparseLengthsReductionFakeFp16Op(Args,...)', '    ~SparseLengthsReductionFakeFp16Op', '    call'];
tanh_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUFloatToRowwiseQuantized8Bits', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwise8BitQuantizedToFloat', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsMean8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsSum8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedMean8BitsRowwise', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsWeightedSum8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FloatToRowwiseQuantized8Bits', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Rowwise8BitQuantizedToFloat', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsMean8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsSum8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedMean8BitsRowwise', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSum8BitsRowwise'];
tanh_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 12;  1; 4;2;  6; 0;0;4;0;5;0.17;0;['    FloatToRowwiseQuantized8BitsOp', '    Rowwise8BitQuantizedToFloatOp', '    SparseLengths8BitsRowwiseOp'];['    FloatToRowwiseQuantized8BitsOp(Args,...)', '    RunOnDevice', '    ~FloatToRowwiseQuantized8BitsOp', '    Rowwise8BitQuantizedToFloatOp(Args,...)', '    RunOnDevice', '    ~Rowwise8BitQuantizedToFloatOp', '    DoRunWithType', '    RunOnDevice', '    SparseLengths8BitsRowwiseOp(Args,...)', '    ~SparseLengths8BitsRowwiseOp'];
tensor_protos_db_input.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 32;  1; 11;1;  20; 0;17;20;1;9;0.05;2;['    GetLengthsTileGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTile', '    vector', '    GetGradientDefs', '    RunOnDevice'];
tensor_protos_db_input_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 7;  1; 1;3;  3; 0;1;3;1;5;0.33;1;['    LengthsTileOp'];['    lengths_host_', '    LengthsTileOp(Args,...)', '    RunOnDevice', '    ~LengthsTileOp'];
text_file_reader.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 195;  8; 23;6;  159; 0;74;90;53;58;0.05;12;['    GetLengthsTopKGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsTopKGradient', '    vector', '    cmp', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
text_file_reader_utils.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 119;  2; 12;5;  100; 0;68;19;59;16;0.02;7;['    LengthsTopKGradientOp', '    LengthsTopKOp'];['    LengthsTopKGradientOp(Args,...)', '    RunOnDevice', '    LengthsTopKOp(Args,...)', '    RunOnDevice'];
text_file_reader_utils_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 122;  2; 13;11;  97; 0;61;44;54;36;0.02;5;[];['    lerp_cpu_scalar(const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_scalar_(Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_scalar_out(Tensor & result,const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_cpu_tensor(const Tensor & self,const Tensor & end,const Tensor & weight)', '    lerp_cpu_tensor_(Tensor & self,const Tensor & end,const Tensor & weight)', '    lerp_cpu_tensor_out(Tensor & result,const Tensor & self,const Tensor & end,const Tensor & weight)'];
thresholded_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  16; 18;3;  59; 0;43;43;17;33;0.27;8;[];['    lerp_kernel_scalar_weight', '    lerp_kernel_scalar_weight', '    operator=', '    lerp_kernel_tensor_weight', '    lerp_kernel_tensor_weight', '    operator='];
thresholded_relu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 45;  2; 10;7;  28; 0;2;16;36;55;0.07;2;[];['    lerp_kernel_scalar(Tensor & ret,const Tensor & self,const Tensor & end,Scalar weight)', '    lerp_kernel_tensor(Tensor & ret,const Tensor & self,const Tensor & end,const Tensor & weights)'];
tile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 268;  33; 30;13;  194; 0;106;62;127;90;0.17;10;['    C10FlagParser_caffe2_leveldb_block_size', '    LevelDB', '    LevelDBCursor', '    LevelDBTransaction'];['    C10FlagParser_caffe2_leveldb_block_size(const std::string & content)', '    Close', '    LevelDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    key', '    LevelDBCursor(leveldb::DB *db)', '    Next', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~LevelDBCursor', '    Commit', '    LevelDBTransaction(leveldb::DB *db)', '    Put(const string & key,const string & value)', '    ~LevelDBTransaction'];
top_k.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 367;  3; 98;8;  260; 0;198;164;81;76;0.01;11;[];['    kindToString(int kind)', '    sharedParserData', '    stringToKind(const std::string & str)', '    isBinary(int kind,int *prec)', '    isUnary(int kind,int *prec)'];
top_k.h;C++;pytorch-master/pytorch-master/caffe2/operators; 51;  2; 14;6;  31; 0;0;22;34;58;0.06;4;[];['    cur', '    expect(int kind)', '    expected(what,cur)', '    lex', '    lexRaw(bool whitespace_token)', '    lookahead', '    kindToString(int kind)', '    sharedParserData', '    stringToKind(const std::string & str)', '    back', '    emplace_back', '    get', '    insert', '    size', '    Lexer(const std::shared_ptr & source)', '    next', '    nextIf(int kind)', '    reportError(what,cur)', '    isBinary(int kind,int *prec)', '    isblank(int n)', '    isCharCount(char c,const std::string & str,size_t start,int len)', '    isNumber(const std::string & str,size_t start,size_t *len)', '    isRightAssociative(int kind)', '    isString(const std::string & str,size_t start,size_t *len)', '    isTypeComment(const std::string & str,size_t pos)', '    isUnary(int kind,int *prec)', '    match(const std::string & str,size_t pos,bool continuation,bool whitespace_token,int *kind,size_t *start,size_t *len)', '    SharedParserData', '    validIdent(size_t i,char n)', '    kindString', '    text', '    Token(int kind,SourceRange range)', '    insert(const char *str,int tok)', '    TokenTrie'];
transpose_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 76;  4; 11;8;  55; 0;26;21;38;38;0.07;4;[];['    access_file(const char *filename)', '    clBuildProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCompileProgram(cl_program program,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_headers,const cl_program *input_headers,const char **header_include_names,void (*) (cl_program, void *) pfn_notify,void *user_data)', '    clCreateBuffer(cl_context context,cl_mem_flags flags,size_t size,void *host_ptr,cl_int *errcode_ret)', '    clCreateCommandQueue(cl_context context,cl_device_id device,cl_command_queue_properties properties,cl_int *errcode_ret)', '    clCreateContext(const cl_context_properties *properties,cl_uint num_devices,const cl_device_id *devices,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateContextFromType(const cl_context_properties *properties,cl_device_type device_type,void (*) (const char *, const void *, size_t, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clCreateFromGLBuffer(cl_context context,cl_mem_flags flags,cl_GLuint bufobj,int *errcode_ret)', '    clCreateFromGLRenderbuffer(cl_context context,cl_mem_flags flags,cl_GLuint renderbuffer,cl_int *errcode_ret)', '    clCreateFromGLTexture(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture2D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateFromGLTexture3D(cl_context context,cl_mem_flags flags,cl_GLenum target,cl_GLint miplevel,cl_GLuint texture,cl_int *errcode_ret)', '    clCreateImage(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,const cl_image_desc *image_desc,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage2D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_row_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateImage3D(cl_context context,cl_mem_flags flags,const cl_image_format *image_format,size_t image_width,size_t image_height,size_t image_depth,size_t image_row_pitch,size_t image_slice_pitch,void *host_ptr,cl_int *errcode_ret)', '    clCreateKernel(cl_program program,const char *kernel_name,cl_int *errcode_ret)', '    clCreateKernelsInProgram(cl_program program,cl_uint num_kernels,cl_kernel *kernels,cl_uint *num_kernels_ret)', '    clCreateProgramWithBinary(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const size_t *lengths,const unsigned char **binaries,cl_int *binary_status,cl_int *errcode_ret)', '    clCreateProgramWithBuiltInKernels(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *kernel_names,cl_int *errcode_ret)', '    clCreateProgramWithSource(cl_context context,cl_uint count,const char **strings,const size_t *lengths,cl_int *errcode_ret)', '    clCreateSampler(cl_context context,cl_bool normalized_coords,cl_addressing_mode addressing_mode,cl_filter_mode filter_mode,cl_int *errcode_ret)', '    clCreateSubBuffer(cl_mem buffer,cl_mem_flags flags,cl_buffer_create_type buffer_create_type,const void *buffer_create_info,cl_int *errcode_ret)', '    clCreateSubDevices(cl_device_id in_device,const cl_device_partition_property *properties,cl_uint num_devices,cl_device_id *out_devices,cl_uint *num_devices_ret)', '    clCreateUserEvent(cl_context context,cl_int *errcode_ret)', '    clEnqueueAcquireGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueBarrier(cl_command_queue command_queue)', '    clEnqueueBarrierWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBuffer(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,size_t src_offset,size_t dst_offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferRect(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_buffer,const size_t *src_origin,const size_t *dst_origin,const size_t *region,size_t src_row_pitch,size_t src_slice_pitch,size_t dst_row_pitch,size_t dst_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyBufferToImage(cl_command_queue command_queue,cl_mem src_buffer,cl_mem dst_image,size_t src_offset,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImage(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_image,const size_t *src_origin,const size_t *dst_origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueCopyImageToBuffer(cl_command_queue command_queue,cl_mem src_image,cl_mem dst_buffer,const size_t *src_origin,const size_t *region,size_t dst_offset,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillBuffer(cl_command_queue command_queue,cl_mem buffer,const void *pattern,size_t pattern_size,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueFillImage(cl_command_queue command_queue,cl_mem image,const void *fill_color,const size_t *origin,const size_t *region,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMapBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_map,cl_map_flags map_flags,size_t offset,size_t size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMapImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_map,cl_map_flags map_flags,const size_t *origin,const size_t *region,size_t *image_row_pitch,size_t *image_slice_pitch,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event,cl_int *errcode_ret)', '    clEnqueueMarker(cl_command_queue command_queue,cl_event *event)', '    clEnqueueMarkerWithWaitList(cl_command_queue command_queue,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueMigrateMemObjects(cl_command_queue command_queue,cl_uint num_mem_objects,const cl_mem *mem_objects,cl_mem_migration_flags flags,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNativeKernel(cl_command_queue command_queue,void (*) (void *) user_func,void *args,size_t cb_args,cl_uint num_mem_objects,const cl_mem *mem_list,const void **args_mem_loc,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueNDRangeKernel(cl_command_queue command_queue,cl_kernel kernel,cl_uint work_dim,const size_t *global_work_offset,const size_t *global_work_size,const size_t *local_work_size,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,size_t offset,size_t size,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_read,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReadImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_read,const size_t *origin,const size_t *region,size_t row_pitch,size_t slice_pitch,void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueReleaseGLObjects(cl_command_queue command_queue,cl_uint num_objects,const cl_mem *mem_objects,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueTask(cl_command_queue command_queue,cl_kernel kernel,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueUnmapMemObject(cl_command_queue command_queue,cl_mem memobj,void *mapped_ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWaitForEvents(cl_command_queue command_queue,cl_uint num_events,const cl_event *event_list)', '    clEnqueueWriteBuffer(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,size_t offset,size_t size,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteBufferRect(cl_command_queue command_queue,cl_mem buffer,cl_bool blocking_write,const size_t *buffer_offset,const size_t *host_offset,const size_t *region,size_t buffer_row_pitch,size_t buffer_slice_pitch,size_t host_row_pitch,size_t host_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clEnqueueWriteImage(cl_command_queue command_queue,cl_mem image,cl_bool blocking_write,const size_t *origin,const size_t *region,size_t input_row_pitch,size_t input_slice_pitch,const void *ptr,cl_uint num_events_in_wait_list,const cl_event *event_wait_list,cl_event *event)', '    clFinish(cl_command_queue command_queue)', '    clFlush(cl_command_queue command_queue)', '    clGetCommandQueueInfo(cl_command_queue command_queue,cl_command_queue_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetContextInfo(cl_context context,cl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetDeviceIDs(cl_platform_id platform,cl_device_type device_type,cl_uint num_entries,cl_device_id *devices,cl_uint *num_devices)', '    clGetDeviceInfo(cl_device_id device,cl_device_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventInfo(cl_event event,cl_event_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetEventProfilingInfo(cl_event event,cl_profiling_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetExtensionFunctionAddress(const char *func_name)', '    clGetExtensionFunctionAddressForPlatform(cl_platform_id platform,const char *func_name)', '    clGetGLContextInfoKHR(const cl_context_properties *properties,cl_gl_context_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetGLObjectInfo(cl_mem memobj,cl_gl_object_type *gl_object_type,cl_GLuint *gl_object_name)', '    clGetGLTextureInfo(cl_mem memobj,cl_gl_texture_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetImageInfo(cl_mem image,cl_image_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelArgInfo(cl_kernel kernel,cl_uint arg_indx,cl_kernel_arg_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelInfo(cl_kernel kernel,cl_kernel_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetKernelWorkGroupInfo(cl_kernel kernel,cl_device_id device,cl_kernel_work_group_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetMemObjectInfo(cl_mem memobj,cl_mem_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetPlatformIDs(cl_uint num_entries,cl_platform_id *platforms,cl_uint *num_platforms)', '    clGetPlatformInfo(cl_platform_id platform,cl_platform_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramBuildInfo(cl_program program,cl_device_id device,cl_program_build_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetProgramInfo(cl_program program,cl_program_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSamplerInfo(cl_sampler sampler,cl_sampler_info param_name,size_t param_value_size,void *param_value,size_t *param_value_size_ret)', '    clGetSupportedImageFormats(cl_context context,cl_mem_flags flags,cl_mem_object_type image_type,cl_uint num_entries,cl_image_format *image_formats,cl_uint *num_image_formats)', '    clLinkProgram(cl_context context,cl_uint num_devices,const cl_device_id *device_list,const char *options,cl_uint num_input_programs,const cl_program *input_programs,void (*) (cl_program, void *) pfn_notify,void *user_data,cl_int *errcode_ret)', '    clReleaseCommandQueue(cl_command_queue command_queue)', '    clReleaseContext(cl_context context)', '    clReleaseDevice(cl_device_id device)', '    clReleaseEvent(cl_event event)', '    clReleaseKernel(cl_kernel kernel)', '    clReleaseMemObject(cl_mem memobj)', '    clReleaseProgram(cl_program program)', '    clReleaseSampler(cl_sampler sampler)', '    clRetainCommandQueue(cl_command_queue command_queue)', '    clRetainContext(cl_context context)', '    clRetainDevice(cl_device_id device)', '    clRetainEvent(cl_event event)', '    clRetainKernel(cl_kernel kernel)', '    clRetainMemObject(cl_mem memobj)', '    clRetainProgram(cl_program program)', '    clRetainSampler(cl_sampler sampler)', '    clSetEventCallback(cl_event event,cl_int command_exec_callback_type,void (*) (cl_event, cl_int, void *) pfn_notify,void *user_data)', '    clSetKernelArg(cl_kernel kernel,cl_uint arg_index,size_t arg_size,const void *arg_value)', '    clSetMemObjectDestructorCallback(cl_mem memobj,void (*) (cl_mem, void *) pfn_notify,void *user_data)', '    clSetUserEventStatus(cl_event event,cl_int execution_status)', '    clUnloadCompiler', '    clUnloadPlatformCompiler(cl_platform_id platform)', '    clWaitForEvents(cl_uint num_events,const cl_event *event_list)', '    get_libopencl_path(char **cl_path)', '    open_libopencl_so', '    stubOpenclReset'];
transpose_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  5; 21;11;  135; 0;68;64;103;92;0.04;8;[];['    get_libopencl_path(char **cl_path)', '    open_libopencl_so', '    stubOpenclReset'];
tt_linear_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 66;  5; 18;1;  44; 0;39;44;2;17;0.11;4;['    THManagedMapAllocator', '    THManagedMapAllocatorInit'];['    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr &)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    close', '    manager_handle', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    ~THManagedMapAllocator', '    THManagedMapAllocatorInit(const char *manager_handle,const char *filename)'];
unique_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 106;  23; 12;2;  70; 0;58;50;22;23;0.33;3;['    THManagedMapAllocator'];['    libshm_init(const char *manager_exec_path)', '    fromDataPtr(const at::DataPtr &)', '    makeDataPtr(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)', '    manager_handle', '    THManagedMapAllocator(const char *manager_handle,const char *filename,int flags,ptrdiff_t size)'];
unique_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 60;  22; 11;9;  20; 0;3;13;18;34;1.10;5;[];[];
upsample_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 205;  20; 26;3;  157; 0;128;109;58;98;0.13;8;[];['    vulkanSymbolWrapperInit(PFN_vkGetInstanceProcAddr getInstanceProcAddr)', '    vulkanSymbolWrapperInitLoader', '    vulkanSymbolWrapperInstanceProcAddr', '    vulkanSymbolWrapperLoadCoreDeviceSymbols(VkDevice device)', '    vulkanSymbolWrapperLoadCoreInstanceSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadCoreSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadDeviceSymbol(VkDevice device,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperLoadGetPhysicalDeviceProperties2ExtensionSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadGlobalSymbols', '    vulkanSymbolWrapperLoadInstanceSymbol(VkInstance instance,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperReset'];
utility_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 1064;  12; 460;3;  599; 0;497;513;95;286;0.02;73;[];['    vulkanSymbolWrapperInit(PFN_vkGetInstanceProcAddr getInstanceProcAddr)', '    vulkanSymbolWrapperInitLoader', '    vulkanSymbolWrapperInstanceProcAddr', '    vulkanSymbolWrapperLoadCoreDeviceSymbols(VkDevice device)', '    vulkanSymbolWrapperLoadCoreInstanceSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadCoreSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadDeviceSymbol(VkDevice device,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperLoadGetPhysicalDeviceProperties2ExtensionSymbols(VkInstance instance)', '    vulkanSymbolWrapperLoadGlobalSymbols', '    vulkanSymbolWrapperLoadInstanceSymbol(VkInstance instance,const char *name,PFN_vkVoidFunction *ppSymbol)', '    vulkanSymbolWrapperReset'];
utility_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 1518;  145; 185;14;  1181; 0;656;567;975;1100;0.12;100;[];['    env', '    liftClosure(Node *closure)', '    liftClosures(Block *block)', '    liftClosures(const std::shared_ptr & to_clean)'];
utility_ops_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 51;  2; 6;6;  38; 0;23;17;18;12;0.05;2;[];['    liftClosures(const std::shared_ptr & to_clean)'];
variable_length_sequence_padding.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 27;  1; 15;1;  11; 0;7;9;1;7;0.09;2;[];[];
variable_length_sequence_padding.h;C++;pytorch-master/pytorch-master/caffe2/operators; 56;  3; 11;5;  40; 0;11;28;24;38;0.07;3;[];[];
weighted_multi_sampling_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 114;  1; 15;2;  97; 0;80;73;22;23;0.01;3;[];['    BilinearImpl(const BilinearOptions & options_)', '    forward(const Tensor & input1,const Tensor & input2)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    FlattenImpl(const FlattenOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    LinearImpl(const LinearOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters'];
weighted_sample_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 114;  3; 20;1;  91; 0;72;59;35;31;0.03;3;[];['    mkldnn_linear(const Tensor & self,const Tensor & weight,const Tensor & bias)'];
weighted_sample_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 31;  3; 9;7;  14; 0;0;10;17;29;0.21;1;[];['    sumproduct_pair(const Tensor & left_,const Tensor & right_,IntArrayRef sum_dims_,bool keepdim)', '    _trilinear(const Tensor & i1_,const Tensor & i2_,const Tensor & i3_,IntArrayRef expand1_,IntArrayRef expand2_,IntArrayRef expand3_,IntArrayRef sumdim_,int64_t unroll_dim)', '    bilinear(const Tensor & input1,const Tensor & input2,const Tensor & weight,const Tensor & bias)', '    einsum(std::string eqn,TensorList tensors)', '    linear(const Tensor & input,const Tensor & weight,const Tensor & bias)', '    tensordot(const Tensor & input1,const Tensor & input2,IntArrayRef dims1,IntArrayRef dims2)'];
while_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 22;  1; 9;1;  12; 0;10;12;1;7;0.08;2;[];['    BilinearOptions(int64_t in1_features,int64_t in2_features,int64_t out_features)', '    LinearOptions(int64_t in_features,int64_t out_features)'];
while_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 4;2;  3; 0;1;3;1;5;0.33;1;[];[];
workspace_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 42;  0; 7;2;  33; 0;13;29;1;23;0.00;4;[];[];
zero_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 28;  1; 7;1;  20; 0;12;18;3;16;0.05;5;[];[];
zero_gradient_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 6;  0; 1;2;  3; 0;1;3;1;5;0.00;1;[];[];
annotations.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 109;  2; 18;2;  88; 0;30;29;41;26;0.02;22;[];['    _chain_matmul_general(TensorList matrices,std::vector,int64_t i,int64_t j)', '    _chain_matmul_three_matrices(TensorList matrices)', '    _lu_det_P_diag_U(const Tensor & self)', '    _matrix_rank_helper(const Tensor & self,bool symmetric)', '    bmm_out_or_baddbmm_(Tensor & self_or_result,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha,bool is_bmm_out)', '    check_1d(const Tensor & t,const char *arg,const char *fn)', '    baddbmm__cpu(Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    bmm_cpu(const Tensor & self,const Tensor & mat2)', '    bmm_out_cpu(Tensor & result,const Tensor & batch1,const Tensor & batch2)', '    chain_matmul(TensorList matrices)', '    dot_out(Tensor & result,const Tensor & self,const Tensor & tensor)', '    frobenius_norm(const Tensor & self)', '    frobenius_norm(const Tensor & self,IntArrayRef dim,bool keepdim)', '    frobenius_norm_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim)', '    matmul(c10::optional out_opt,const Tensor & tensor1,const Tensor & tensor2)', '    matmul(const Tensor & tensor1,const Tensor & tensor2)', '    matmul_out(Tensor & result,const Tensor & tensor1,const Tensor & tensor2)', '    matrix_power(const Tensor & a,int64_t n)', '    addr(const Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    addr_(Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    addr_out(Tensor & result,const Tensor & self,const Tensor & vec1,const Tensor & vec2,Scalar beta,Scalar alpha)', '    baddbmm_cpu(const Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    baddbmm_cpu_kernel(const Tensor & result,const Tensor & self,const Tensor & mat2,Scalar beta_,Scalar alpha_)', '    baddbmm_out_cpu(Tensor & result,const Tensor & self_,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)', '    det(const Tensor & self)', '    ger(const Tensor & self,const Tensor & vec2)', '    ger_out(Tensor & result,const Tensor & self,const Tensor & vec2)', '    logdet(const Tensor & self)', '    matrix_rank(const Tensor & self,double tol,bool symmetric)', '    matrix_rank(const Tensor & self,bool symmetric)', '    pinverse(const Tensor & self,double rcond)', '    slogdet(const Tensor & self)', '    nuclear_norm(const Tensor & self,bool keepdim)', '    nuclear_norm(const Tensor & self,IntArrayRef dim,bool keepdim)', '    nuclear_norm_out(Tensor & result,const Tensor & self,bool keepdim)', '    nuclear_norm_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim)'];
annotations.h;C++;pytorch-master/pytorch-master/caffe2/opt; 68;  3; 13;5;  48; 0;8;45;0;38;0.06;3;[];['    baddbmm_mkl_template(const Tensor & res,const Tensor & mat1,const Tensor & mat2,Scalar beta_,Scalar alpha_)', '    gemm_batched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float **A,const int lda,const float **B,const int ldb,const float beta,float **C,const int ldc)', '    gemm_batched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const double alpha,const double **A,const int lda,const double **B,const int ldb,const double beta,double **C,const int ldc)', '    _baddbmm_mkl_(Tensor & self,const Tensor & batch1,const Tensor & batch2,Scalar beta,Scalar alpha)'];
backend_cutting.h;C++;pytorch-master/pytorch-master/caffe2/opt; 18;  1; 3;5;  10; 0;1;10;0;7;0.10;0;[];['    _compute_geometry_for_Q(const Tensor & input,bool some)', '    _create_U_S_VT(const Tensor & input,bool some,bool compute_uv)', '    _move_to_end(const Tensor & self,IntArrayRef axes)', '    _get_epsilon(const ScalarType & sc_type)', '    _linalg_broadcast_batch_dims(const Tensor & arg1,const Tensor & arg2,const char *name)', '    batchCheckErrors(std::vector & infos,const char *name,bool allow_singular)', '    batchCheckErrors(const Tensor & infos,const char *name,bool allow_singular)', '    batchCount(const Tensor & batched_matrices)', '    checkAllSameDim(TensorList tensors,int64_t dim)', '    cloneBatchedColumnMajor(const Tensor & src)', '    linearSolveCheckInputs(const Tensor & self,const Tensor & A,const char *name)', '    matrixStride(const Tensor & batched_matrices)', '    singleCheckErrors(int64_t info,const char *name,bool allow_singular)', '    squareCheckInputs(const Tensor & self)', '    same_stride_to(const Tensor & original_tensor,const at::TensorOptions & options)', '    empty_strided', '    device', '    size', '    to', '    transpose'];
backend_cutting_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 153;  11; 13;5;  125; 0;104;21;96;21;0.09;7;[];[];
backend_transformer_base.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 179;  12; 14;3;  151; 0;86;60;68;47;0.08;9;[];[];
bound_shape_inference_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 668;  4; 19;6;  641; 0;538;109;136;97;0.01;18;[];['    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingEmpty_thenReturnsTrue)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingEmpty_thenReturnsFalse)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingSize_thenReturnsZero)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(ListTest_IValueBasedList,givenNonemptyList_whenCallingClear_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,whenCallingGetWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenCallingGetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithExistingPosition_thenListElementBecomesInvalid)', '    TEST(ListTest_IValueBasedList,whenCallingExtractWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingCopyingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_IValueBasedList,whenCallingMovingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_IValueBasedList,whenCallingCopyingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingMovingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingAccessOperatorWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_IValueBasedList,whenAssigningToAccessOperatorWithExistingPosition_thenSetsElement)', '    TEST(ListTest_IValueBasedList,whenAssigningToAccessOperatorFromAccessOperator_thenSetsElement)', '    TEST(ListTest_IValueBasedList,whenSwappingFromAccessOperator_thenSwapsElements)', '    TEST(ListTest_IValueBasedList,whenCallingAccessOperatorWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_IValueBasedList,whenCallingInsertOnIteratorWithLValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertOnIteratorWithRValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertWithLValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_IValueBasedList,whenCallingInsertWithRValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithLValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithRValue_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceWithConstructorArg_thenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingPushBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingPushBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,whenCallingEmplaceBackWithConstructorArg_ThenInsertsElement)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenIterating_thenBeginIsEnd)', '    TEST(ListTest_IValueBasedList,whenIterating_thenFindsElements)', '    TEST(ListTest_IValueBasedList,whenIteratingWithForeach_thenFindsElements)', '    TEST(ListTest_IValueBasedList,givenOneElementList_whenErasing_thenListIsEmpty)', '    TEST(ListTest_IValueBasedList,givenList_whenErasing_thenReturnsIterator)', '    TEST(ListTest_IValueBasedList,givenList_whenErasingFullRange_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,whenCallingReserve_thenDoesntCrash)', '    TEST(ListTest_IValueBasedList,whenCopyConstructingList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenCopyAssigningList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenCopyingList_thenAreEqual)', '    TEST(ListTest_IValueBasedList,whenMoveConstructingList_thenNewIsCorrect)', '    TEST(ListTest_IValueBasedList,whenMoveAssigningList_thenNewIsCorrect)', '    TEST(ListTest_IValueBasedList,whenMoveConstructingList_thenOldIsEmpty)', '    TEST(ListTest_IValueBasedList,whenMoveAssigningList_thenOldIsEmpty)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPostfixDecrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenPrefixDecrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenIncreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenDecreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAdding_thenReturnsNewIterator)', '    TEST(ListTest_IValueBasedList,givenIterator_whenSubtracting_thenReturnsNewIterator)', '    TEST(ListTest_IValueBasedList,givenIterator_whenCalculatingDifference_thenReturnsCorrectNumber)', '    TEST(ListTest_IValueBasedList,givenEqualIterators_thenAreEqual)', '    TEST(ListTest_IValueBasedList,givenDifferentIterators_thenAreNotEqual)', '    TEST(ListTest_IValueBasedList,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAssigningNewValue_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenAssigningNewValueFromIterator_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenIterator_whenSwappingValuesFromIterator_thenChangesValue)', '    TEST(ListTest_IValueBasedList,givenOneElementList_whenCallingPopBack_thenIsEmpty)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingResize_thenResizesAndSetsEmptyValue)', '    TEST(ListTest_IValueBasedList,givenEmptyList_whenCallingResizeWithValue_thenResizesAndSetsValue)', '    TEST(ListTest_IValueBasedList,isReferenceType)', '    TEST(ListTest_IValueBasedList,copyHasSeparateStorage)', '    TEST(ListTest_IValueBasedList,givenEqualLists_thenIsEqual)', '    TEST(ListTest_IValueBasedList,givenDifferentLists_thenIsNotEqual)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingEmpty_thenReturnsTrue)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingEmpty_thenReturnsFalse)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingSize_thenReturnsZero)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingSize_thenReturnsNumberOfElements)', '    TEST(ListTest_NonIValueBasedList,givenNonemptyList_whenCallingClear_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenCallingGetWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingGetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingExtractWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingExtractWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingCopyingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingMovingSetWithExistingPosition_thenChangesElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingCopyingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingMovingSetWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingAccessOperatorWithExistingPosition_thenReturnsElement)', '    TEST(ListTest_NonIValueBasedList,whenAssigningToAccessOperatorWithExistingPosition_thenSetsElement)', '    TEST(ListTest_NonIValueBasedList,whenAssigningToAccessOperatorFromAccessOperator_thenSetsElement)', '    TEST(ListTest_NonIValueBasedList,whenSwappingFromAccessOperator_thenSwapsElements)', '    TEST(ListTest_NonIValueBasedList,whenCallingAccessOperatorWithNonExistingPosition_thenThrowsException)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertOnIteratorWithLValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertOnIteratorWithRValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertWithLValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingInsertWithRValue_thenReturnsIteratorToNewElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithLValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithRValue_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceWithConstructorArg_thenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingPushBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingPushBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithLValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithRValue_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,whenCallingEmplaceBackWithConstructorArg_ThenInsertsElement)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenIterating_thenBeginIsEnd)', '    TEST(ListTest_NonIValueBasedList,whenIterating_thenFindsElements)', '    TEST(ListTest_NonIValueBasedList,whenIteratingWithForeach_thenFindsElements)', '    TEST(ListTest_NonIValueBasedList,givenOneElementList_whenErasing_thenListIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenList_whenErasing_thenReturnsIterator)', '    TEST(ListTest_NonIValueBasedList,givenList_whenErasingFullRange_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenCallingReserve_thenDoesntCrash)', '    TEST(ListTest_NonIValueBasedList,whenCopyConstructingList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenCopyAssigningList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenCopyingList_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,whenMoveConstructingList_thenNewIsCorrect)', '    TEST(ListTest_NonIValueBasedList,whenMoveAssigningList_thenNewIsCorrect)', '    TEST(ListTest_NonIValueBasedList,whenMoveConstructingList_thenOldIsEmpty)', '    TEST(ListTest_NonIValueBasedList,whenMoveAssigningList_thenOldIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPostfixIncrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPrefixIncrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPostfixDecrementing_thenMovesToNextAndReturnsOldPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenPrefixDecrementing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenIncreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenDecreasing_thenMovesToNextAndReturnsNewPosition)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAdding_thenReturnsNewIterator)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenSubtracting_thenReturnsNewIterator)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenCalculatingDifference_thenReturnsCorrectNumber)', '    TEST(ListTest_NonIValueBasedList,givenEqualIterators_thenAreEqual)', '    TEST(ListTest_NonIValueBasedList,givenDifferentIterators_thenAreNotEqual)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenDereferencing_thenPointsToCorrectElement)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAssigningNewValue_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenAssigningNewValueFromIterator_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenIterator_whenSwappingValuesFromIterator_thenChangesValue)', '    TEST(ListTest_NonIValueBasedList,givenOneElementList_whenCallingPopBack_thenIsEmpty)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingResize_thenResizesAndSetsEmptyValue)', '    TEST(ListTest_NonIValueBasedList,givenEmptyList_whenCallingResizeWithValue_thenResizesAndSetsValue)', '    TEST(ListTest_NonIValueBasedList,isReferenceType)', '    TEST(ListTest_NonIValueBasedList,copyHasSeparateStorage)', '    TEST(ListTest_NonIValueBasedList,givenEqualLists_thenIsEqual)', '    TEST(ListTest_NonIValueBasedList,givenDifferentLists_thenIsNotEqual)', '    TEST(ListTest_NonIValueBasedList,isChecksIdentity)', '    TEST(ListTest_NonIValueBasedList,sameValueDifferentStorage_thenIsReturnsFalse)'];
bound_shape_inferencer.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 680;  41; 45;6;  592; 0;379;177;297;153;0.07;26;['    GetLambdaRankNdcgGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULambdaRankNdcg', '    CAFFE_ANONYMOUS_VARIABLE_CPULambdaRankNdcgGradient', '    arg_sort(const TDATA *data,TIDX *idx,const size_t N,bool reverse)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LambdaRankNdcg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LambdaRankNdcgGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    LambdaRankNdcgSession(int start_index,int end_index,const Tensor & y,const Tensor & r,Tensor **dy)', '    ResizeInvLogITensor(int size)', '    RunOnDevice'];
bound_shape_inferencer.h;C++;pytorch-master/pytorch-master/caffe2/opt; 140;  23; 23;8;  87; 0;15;67;15;47;0.26;9;['    final', '    final'];['    ComputeDiscounts(int *,int)', '    GetSingleArgument', '    LambdaRankNdcgGradientOp(Args,...)', '    LambdaRankNdcgOp(Args,...)', '    LambdaRankNdcgSession(int start_index,int end_index,const Tensor & y,const Tensor & r,Tensor **dy)', '    ResizeInvLogITensor(int)', '    RunOnDevice', '    ~LambdaRankNdcgGradientOp'];
converter.h;C++;pytorch-master/pytorch-master/caffe2/opt; 78;  11; 16;21;  32; 0;4;29;0;18;0.34;1;['    C10FlagParser_model'];['    main(int argc,char **argv)', '    C10FlagParser_model(const std::string & content)'];
converter_nomigraph_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 114;  3; 17;3;  92; 0;63;29;42;34;0.03;7;[];['    dump(const std::unordered_map,std::vector)', '    dump(const std::vector & set)', '    processBlock(Block *b,SparseBitVector liveness)', '    toSparseBitVector(at::ArrayRef values)', '    toValueVector(const SparseBitVector & sbv)', '    LivenessAnalyzer(std::shared_ptr graph)'];
cc_amrc.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 11;  1; 4;1;  6; 0;2;4;1;7;0.17;2;[];[];
concat_elim.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 203;  19; 41;7;  138; 0;108;50;68;52;0.14;6;[];[];
concat_elim.h;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 18;  3; 5;6;  7; 0;0;7;0;5;0.43;0;[];[];
concat_elim_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 180;  12; 13;7;  153; 0;120;55;67;51;0.08;7;[];[];
converter_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 33;  0; 4;7;  22; 0;14;9;12;11;0.00;1;[];[];
fakefp16_transform.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 102;  6; 9;3;  86; 0;60;24;22;28;0.07;4;[];['    _BitScanForward(unsigned long *_Index,unsigned long _Mask)', '    _BitScanForward64(unsigned long *_Index,unsigned __int64 _Mask)', '    _BitScanReverse(unsigned long *_Index,unsigned long _Mask)', '    _BitScanReverse64(unsigned long *_Index,unsigned __int64 _Mask)', '    AbsoluteDifference(T X,T Y)', '    alignAddr(const void *Addr,size_t Alignment)', '    alignDown(uint64_t Value,uint64_t Align,uint64_t Skew)', '    alignmentAdjustment(const void *Ptr,size_t Alignment)', '    alignTo(uint64_t Value,uint64_t Align,uint64_t Skew)', '    alignTo(uint64_t Value)', '    BitsToDouble(uint64_t Bits)', '    BitsToFloat(uint32_t Bits)', '    countLeadingOnes(T Value,ZeroBehavior ZB)', '    countLeadingZeros(T Val,ZeroBehavior ZB)', '    countPopulation(T Value)', '    countTrailingOnes(T Value,ZeroBehavior ZB)', '    countTrailingZeros(T Val,ZeroBehavior ZB)', '    divideCeil(uint64_t Numerator,uint64_t Denominator)', '    DoubleToBits(double Double)', '    findFirstSet(T Val,ZeroBehavior ZB)', '    findLastSet(T Val,ZeroBehavior ZB)', '    FloatToBits(float Float)', '    GreatestCommonDivisor64(uint64_t A,uint64_t B)', '    Hi_32(uint64_t Value)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isInt(int64_t x)', '    isIntN(unsigned N,int64_t x)', '    isMask_32(uint32_t Value)', '    isMask_64(uint64_t Value)', '    isPowerOf2_32(uint32_t Value)', '    isPowerOf2_64(uint64_t Value)', '    isShiftedInt(int64_t x)', '    isShiftedMask_32(uint32_t Value)', '    isShiftedMask_64(uint64_t Value)', '    isShiftedUInt(uint64_t x)', '    isUInt(uint64_t X)', '    isUInt(uint64_t x)', '    isUInt(uint64_t x)', '    isUInt(uint64_t x)', '    isUInt(uint64_t X)', '    isUIntN(unsigned N,uint64_t x)', '    Lo_32(uint64_t Value)', '    Log2(double Value)', '    Log2_32(uint32_t Value)', '    Log2_32_Ceil(uint32_t Value)', '    Log2_64(uint64_t Value)', '    Log2_64_Ceil(uint64_t Value)', '    Make_64(uint32_t High,uint32_t Low)', '    maskLeadingOnes(unsigned N)', '    maskLeadingZeros(unsigned N)', '    maskTrailingOnes(unsigned N)', '    maskTrailingZeros(unsigned N)', '    maxIntN(int64_t N)', '    maxUIntN(uint64_t N)', '    MinAlign(uint64_t A,uint64_t B)', '    minIntN(int64_t N)', '    NextPowerOf2(uint64_t A)', '    OffsetToAlignment(uint64_t Value,uint64_t Align)', '    PowerOf2Ceil(uint64_t A)', '    PowerOf2Floor(uint64_t A)', '    reverseBits(T Val)', '    SaturatingAdd(T X,T Y,bool *ResultOverflowed)', '    SaturatingMultiply(T X,T Y,bool *ResultOverflowed)', '    SaturatingMultiplyAdd(T X,T Y,T A,bool *ResultOverflowed)', '    SignExtend32(uint32_t X)', '    SignExtend32(uint32_t X,unsigned B)', '    SignExtend64(uint64_t x)', '    SignExtend64(uint64_t X,unsigned B)', '    count(T Val,ZeroBehavior ZB)', '    count(T Val,ZeroBehavior)', '    count(T Value)', '    count(T Value)', '    count(T Val,ZeroBehavior ZB)', '    count(T Val,ZeroBehavior)', '    static_assert(Align,)', '    max', '    max', '    memcpy', '    min'];
fakefp16_transform.h;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 23;  4; 6;7;  8; 0;2;8;0;4;0.50;0;['    final', '    LMDB', '    LMDBCursor'];['    MDB_CHECK(int mdb_status)', '    Put(const string & key,const string & value)', '    Commit', '    LMDBTransaction(MDB_env *mdb_env)', '    ~LMDBTransaction', '    Close', '    LMDB(const string & source,Mode mode)', '    NewCursor', '    NewTransaction', '    ~LMDB', '    key', '    LMDBCursor(MDB_env *mdb_env)', '    Next', '    Seek(const string & key)', '    SeekLMDB(MDB_cursor_op op)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~LMDBCursor'];
glow_net_transform.h;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 41;  7; 7;8;  21; 0;4;21;0;7;0.33;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCheckpoint', '    CAFFE_ANONYMOUS_VARIABLE_CPUDBExists', '    CAFFE_ANONYMOUS_VARIABLE_CPULoad', '    CAFFE_ANONYMOUS_VARIABLE_CPUSave', '    CAFFE_ANONYMOUS_VARIABLE_CPUSnapshot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Checkpoint', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DBExists', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Load', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Save', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Snapshot', '    LoadTensorInference(const OperatorDef & def,const vector &)', '    SetCurrentDevice(BlobProto *proto)'];
pointwise_elim.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 40;  3; 10;7;  22; 0;13;10;13;13;0.14;2;['    final', '    final', '    final', '    final'];['    FormatString(const string & pattern,Ts,...)', '    CheckpointOp(const OperatorDef & operator_def,Workspace *ws)', '    DBExistsOp(const OperatorDef & operator_def,Workspace *ws)', '    extract(int db_id,Cursor *cursor,std::unordered_map *blob_states,int *total_loaded_blobs)', '    extractAll(int db_id,Cursor *cursor,std::unordered_map *blob_states,int *total_loaded_blobs)', '    extractFrom(int db_id,Cursor *cursor,const vector & outputs,std::unordered_map *blob_states,int *total_loaded_blobs)', '    LoadOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SaveOp(const OperatorDef & operator_def,Workspace *ws)', '    SetCurrentDevice(BlobProto *proto)', '    CreateBlob', '    RootFolder'];
pointwise_elim.h;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 15;  4; 4;4;  5; 0;0;5;0;3;0.80;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACheckpoint', '    CAFFE_ANONYMOUS_VARIABLE_CUDALoad', '    CAFFE_ANONYMOUS_VARIABLE_CUDASave'];
dead_code_elim_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 57;  1; 7;4;  45; 0;33;12;24;12;0.02;3;[];['    buildBlobNameFromDbKey(const std::string & dbKey,const std::string & strip_prefix,const std::string & add_prefix)', '    ProcessBlob(Blob *blob,const BlobProto & proto,std::unordered_map *blob_states_ptr,const std::string & key,int *loaded_blobs)', '    validateBlobStates(const std::unordered_map & blob_states)'];
device.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 147;  13; 22;3;  111; 0;75;46;68;37;0.12;3;[];['    buildBlobNameFromDbKey(const std::string & dbKey,const std::string & strip_prefix,const std::string & add_prefix)', '    ProcessBlob(Blob *blob,const BlobProto & proto,std::unordered_map *blob_states_ptr,const std::string & key,int *loaded_blobs)', '    validateBlobStates(const std::unordered_map & blob_states)', '    BlobState(int64_t total_size,int64_t current_size,bool is_tensor)'];
device.h;C++;pytorch-master/pytorch-master/caffe2/opt; 14;  2; 3;2;  9; 0;0;9;0;3;0.22;0;['    GetLRNGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULRN', '    CAFFE_ANONYMOUS_VARIABLE_CPULRNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LRN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LRNGradient', '    vector', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW'];
distributed.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 112;  2; 21;2;  88; 0;53;34;46;29;0.02;5;['    final', '    final'];['    IDEEPLRNGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPLRNOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPLRNGradientOp', '    ~IDEEPLRNOp'];
distributed.h;C++;pytorch-master/pytorch-master/caffe2/opt; 33;  14; 5;5;  10; 0;0;10;0;5;1.40;0;['    final', '    final', '    LRNOpBase'];['    local_scale_tensor_', '    local_scale_tensor_', '    LRNGradientOp(Args,...)', '    LRNOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    GetSingleArgument', '    LRNOpBase(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
distributed_converter.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 16;  2; 5;1;  10; 0;2;8;4;16;0.20;4;['    final', '    final'];['    CuDNNLRNGradientOp(Args,...)', '    CuDNNLRNOp(Args,...)', '    ~CuDNNLRNGradientOp', '    ~CuDNNLRNOp', '    DoRunWithType', '    RunOnDevice', '    DoRunWithType', '    RunOnDevice'];
fusion.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 125;  11; 21;10;  85; 0;67;41;53;58;0.13;3;['    C10FlagParser_disable_variable_dispatch'];['    tls_is_dispatch_key_excluded(DispatchKey x)', '    tls_is_dispatch_key_included(DispatchKey x)', '    tls_local_dispatch_key_set', '    tls_set_dispatch_key_excluded(DispatchKey x,bool desired_state)', '    tls_set_dispatch_key_included(DispatchKey x,bool desired_state)', '    C10FlagParser_disable_variable_dispatch(const std::string & content)', '    ExcludeDispatchKeyGuard(DispatchKey x)', '    ~ExcludeDispatchKeyGuard', '    IncludeDispatchKeyGuard(DispatchKey x)', '    ~IncludeDispatchKeyGuard'];
fusion.h;C++;pytorch-master/pytorch-master/caffe2/opt; 122;  36; 16;5;  68; 0;44;28;30;28;0.53;1;[];[];
mobile.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 132;  12; 22;5;  96; 0;69;50;46;35;0.13;6;['    GetLocallyConnectedGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULC', '    CAFFE_ANONYMOUS_VARIABLE_CPULC1D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULC2D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULC3D', '    CAFFE_ANONYMOUS_VARIABLE_CPULC3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULCGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LC3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LCGradient', '    LCDocGenerator(const char *dim)', '    GetGradientDefs', '    vector', '    vector', '    vector', '    vector'];
mobile_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 45;  0; 3;10;  32; 0;26;5;32;5;0.00;1;['    final', '    final'];['    bias_multiplier_', '    bias_multiplier_', '    column_buffer_', '    column_buffer_', '    column_transposed_buffer_', '    column_transposed_buffer_', '    dY_transposed_buffer_', '    LocallyConnectedGradientOp(Args,...)', '    LocallyConnectedOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *output_buffer)', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    Y_transposed_buffer_', '    ~LocallyConnectedGradientOp', '    ~LocallyConnectedOp'];
ast.h;C++;pytorch-master/pytorch-master/caffe2/opt/nql; 77;  0; 8;4;  65; 0;32;33;28;33;0.00;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDALC', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC1D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC2D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC3D', '    CAFFE_ANONYMOUS_VARIABLE_CUDALC3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDALCGradient'];
graphmatcher.cc;C++;pytorch-master/pytorch-master/caffe2/opt/nql; 281;  35; 27;4;  218; 0;132;73;107;65;0.16;14;[];['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    RunOnDeviceWithOrderNHWCImpl(shape,X_data,filter_data,bias_data,Y_data,& column_buffer_,& column_transposed_buffer_,& Y_transposed_buffer_)', '    SetBiasMultiplier(shape,& bias_multiplier_)', '    ComputePads', '    SetOutputSize', '    SetOutputSize(X,Y,shape)', '    SetColumnBufferShape', '    SetColumnBufferShape(shape,shape,shape,output_image_dims,order_,& shape,& shape,& shape,& shape)', '    SetYBufferShape', '    SetYBufferShape(shape,shape,shape,order_,& shape,& shape,& shape)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *dY_data,T *dfilter_data,T *dX_data,T *dbias_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *dY_transposed_buffer)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHWImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    RunOnDeviceWithOrderNHWCImpl(const lc_op_util::ShapeParams & shape,const T *X_data,const T *filter_data,const T *bias_data,T *Y_data,Tensor *column_buffer,Tensor *column_transposed_buffer,Tensor *Y_transposed_buffer)', '    Col2Im', '    Col2ImNd', '    Gemm', '    GemmStridedBatched', '    Gemv', '    Im2Col', '    Im2ColNd', '    Transpose', '    Resize'];
GraphMatcherTest.cc;C++;pytorch-master/pytorch-master/caffe2/opt/nql/tests; 446;  97; 110;2;  237; 0;186;72;133;71;0.41;9;[];['    SetColumnBufferShape(const int N,const int kernel_size,const int output_image_size,const std::vector & output_image_dims,const StorageOrder order,std::vector *column_slice_dims,std::vector *column_dims,std::vector *column_transposed_dims,std::vector *column_axes)', '    SetYBufferShape(const int N,const int M,const int output_image_size,const StorageOrder order,std::vector *Y_dims,std::vector *Y_transposed_dims,std::vector *Y_axes)'];
onnx_convert.h;C++;pytorch-master/pytorch-master/caffe2/opt; 37;  0; 8;1;  28; 0;11;15;8;14;0.00;8;[];['    SetColumnBufferShape(const int N,const int kernel_size,const int output_image_size,const std::vector & output_image_dims,const StorageOrder order,std::vector *column_slice_dims,std::vector *column_dims,std::vector *column_transposed_dims,std::vector *column_axes)', '    SetYBufferShape(const int N,const int M,const int output_image_size,const StorageOrder order,std::vector *Y_dims,std::vector *Y_transposed_dims,std::vector *Y_axes)'];
onnxifi_op.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 452;  19; 23;12;  361; 40;215;139;167;216;0.05;12;[];['    pytorch_qnnp_log_debug(const char *format,...)', '    pytorch_qnnp_log_error(const char *format,...)', '    pytorch_qnnp_log_fatal(const char *format,...)', '    pytorch_qnnp_log_info(const char *format,...)', '    pytorch_qnnp_log_warning(const char *format,...)'];
onnxifi_transformer.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 1368;  100; 103;16;  1151; 0;799;383;545;312;0.09;32;['    GetLogGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULog', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Log', '    GetGradientDefs', '    vector'];
onnxifi_transformer.h;C++;pytorch-master/pytorch-master/caffe2/opt; 164;  36; 34;9;  86; 0;10;82;0;36;0.42;11;[];['    operator()(const int N,const T *X,T *Y,Context *context)'];
optimize_ideep.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 1001;  3; 6;26;  11; 978;1;8;3;4;0.27;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDALog'];
optimizer.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 48;  2; 8;6;  32; 2;18;10;14;8;0.06;4;[];['    getLogger', '    global_logger', '    setLogger(LoggerBase *logger)', '    timePoint', '    recordDurationSince(const std::string & name,JITTimePoint tp)', '    addStatValue(const std::string & stat_name,int64_t val)', '    getCounterValue(const std::string & name)', '    setAggregationType(const std::string & stat_name,AggregationType)'];
optimizer.h;C++;pytorch-master/pytorch-master/caffe2/opt; 17;  3; 5;6;  6; 0;2;6;0;4;0.50;0;['    C10FlagParser_caffe2_log_level', '    C10FlagParser_caffe2_use_fatal_for_enforce', '    C10FlagParser_logtostderr', '    C10FlagParser_minloglevel', '    C10FlagParser_v'];['    func', '    APIUsageDebug(const string & event)', '    LogAPIUsageFakeReturn(const std::string & event)', '    GetAPIUsageLogger', '    GetFetchStackTrace', '    InitCaffeLogging(int *argc,char **argv)', '    IsAPIUsageDebugMode', '    LogAPIUsage(const std::string & event)', '    SetAPIUsageLogger(std::function logger)', '    SetStackTraceFetcher(std::function fetcher)', '    ShowLogInfoToStderr', '    ThrowEnforceFiniteNotMet(const char *file,const int line,const char *condition,const std::string & msg,const void *caller)', '    ThrowEnforceNotMet(const char *file,const int line,const char *condition,const std::string & msg,const void *caller)', '    UpdateLoggingLevelsFromFlags', '    C10FlagParser_caffe2_log_level(const std::string & content)', '    C10FlagParser_caffe2_use_fatal_for_enforce(const std::string & content)', '    C10FlagParser_logtostderr(const std::string & content)', '    C10FlagParser_minloglevel(const std::string & content)', '    C10FlagParser_v(const std::string & content)', '    EnforceFailMessage(std::string)', '    Error(SourceLocation source_location,const std::string & msg)', '    MessageLogger(const char *file,int line,int severity)', '    ~MessageLogger'];
passes.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 12;  1; 3;1;  8; 0;2;4;2;5;0.13;2;['    EnforceFailMessage'];['    LogAPIUsageFakeReturn(const std::string & event)', '    Equals(const T1 & x,const T2 & y)', '    Greater(const T1 & x,const T2 & y)', '    GreaterEquals(const T1 & x,const T2 & y)', '    Less(const T1 & x,const T2 & y)', '    LessEquals(const T1 & x,const T2 & y)', '    NotEquals(const T1 & x,const T2 & y)', '    InitCaffeLogging(int *argc,char **argv)', '    IsUsingGoogleLogging', '    LogAPIUsage(const std::string & event)', '    ShowLogInfoToStderr', '    UpdateLoggingLevelsFromFlags', '    bad', '    EnforceFailMessage(std::string)', '    EnforceFailMessage(EnforceOK)', '    EnforceFailMessage', '    EnforceFailMessage', '    EnforceFailMessage(Args,...)', '    get_message_and_free(std::string)', '    msg_', '    operator=', '    operator=', '    max'];
shape_info.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 88;  1; 6;6;  76; 0;48;22;26;15;0.01;4;[];[];
shape_info.h;C++;pytorch-master/pytorch-master/caffe2/opt; 132;  12; 20;2;  99; 0;27;70;23;32;0.12;13;['    LockingLogger', '    AggregationType', '    LoggerBase', '    NoopLogger'];['    getLogger', '    recordDurationSince(const std::string & name,JITTimePoint tp)', '    allRuntimeCounters', '    setLogger(LoggerBase *logger)', '    timePoint', '    addStatValue(const std::string & stat_name,int64_t val)', '    getCounterValue(const std::string & name)', '    RawCounter', '    setAggregationType(const std::string & stat_name,AggregationType)', '    ~LockingLogger', '    addStatValue(const std::string & stat_name,int64_t val)', '    ~LoggerBase', '    addStatValue(const std::string & stat_name,int64_t val)', '    ~NoopLogger'];
tvm_transformer.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 318;  32; 37;2;  248; 0;163;105;102;62;0.13;10;[];[];
adagrad.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 171;  20; 20;3;  145; 0;6;78;6;10;0.14;6;['    LoggerVoidify', '    MessageLogger'];['    CheckNotNull(const char *file,int line,const char *names,T *t)', '    CheckNotNull(const char *file,int line,const char *names,T & t)', '    CheckNotNullCommon(const char *file,int line,const char *names,T & t)', '    LogMessageFatal(const char *file,int line,const T & message)', '    PrintSequence(std::ostream & out,Iter begin,Iter end)', '    static_assert(INT_MIN,)', '    operator<<(std::ostream & out,const std::pair & p)', '    operator<<(std::ostream & out,const std::vector & seq)', '    operator<<(std::ostream & out,const std::map & seq)', '    operator<<(std::ostream & out,const std::set & seq)', '    operator<<(std::ostream & out,const std::nullptr_t &)', '    LoggerVoidify', '    operator&(const std::ostream & s)', '    DealWithFatal', '    MessageLogger(const char *file,int line,int severity)', '    stream', '    ~MessageLogger'];
adagrad.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 184;  53; 24;24;  75; 25;8;72;5;11;0.71;2;[];['    TEST(LoggingTest,TestEnforceTrue)', '    TEST(LoggingTest,TestEnforceFalse)', '    TEST(LoggingTest,TestEnforceEquals)', '    TEST(LoggingTest,EnforceShowcase)', '    TEST(LoggingTest,Join)', '    TEST(LoggingTest,TestDanglingElse)'];
adagrad_avx.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 117;  12; 17;4;  93; 0;48;68;21;28;0.13;3;['    GetLogitGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULogit', '    CAFFE_ANONYMOUS_VARIABLE_CPULogitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Logit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LogitGradient', '    GetGradientDefs', '    operator()(const int size,const T *X,T *Y,CPUContext *)', '    RunOnDevice', '    vector'];
common_avx.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 21;  4; 3;15;  0; 10;0;0;0;0;0.00;0;['    final'];['    LogitGradientOp(Args,...)', '    RunOnDevice', '    ~LogitGradientOp', '    LogitFunctor(OperatorBase & op)', '    operator()(const int size,const T *X,T *Y,Context *context)'];
common_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 21;  4; 3;15;  0; 10;0;0;0;0;0.00;0;[];['    insert_point_guard', '    insert_point_guard', '    insertPointGuard', '    inlineBody(Node *loop)', '    insertBlockCopy(Graph & graph,Block *body,at::ArrayRef inputs)', '    isForLoop(Node *node)', '    isSmallBlock(Block *body)', '    isTrueConstant(Value *val)', '    limitedBlockSize(Block *body,int64_t limit)', '    repeatBody(Block *body,size_t times,Block *dest)', '    replaceLoopCounter(Node *loop)', '    unroll(Node *loop)', '    UnrollLoops(std::shared_ptr & graph)', '    UnrollLoops(Block *block)'];
common_avx512.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 23;  4; 3;17;  0; 12;0;0;0;0;0.00;0;[];['    UnrollLoops(std::shared_ptr & graph)'];
embedding_lookup.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 221;  9; 11;137;  65; 3;36;39;348;166;0.14;37;['    DepTracker', '    Flattener', '    FunctionInliner', '    RandomInliner', '    Vectorizer'];['    InjectInlines(Stmt *stmt,const std::vector & inlined_funcs)', '    InlineRandom(Stmt *stmt,const std::vector & funcs)', '    EvalConstExpr(const ExprHandle & expr)', '    findUsedTensors(Tensor *tensor)', '    visit(const FunctionCall *v)', '    mutate(const FunctionCall *v)', '    FunctionInliner(const std::vector & funcs)', '    mutate(const FunctionCall *v)', '    mutate(const Var *v)', '    mutate(const Store *v)', '    should_inline(Function *func)', '    computeInline(Stmt *s)', '    computeInlineWithRandom(Stmt *s)', '    findAllNeededTensors(const std::vector & tensors)', '    getLoopBodyFor(Tensor *t)', '    getLoopStmtsFor(Tensor *t)', '    hasLoopBodyFor(Tensor *t)', '    insertAllocFree(Stmt *stmt)', '    LoopNest(const std::vector & output_tensors)', '    lowerToStmt(Tensor *t)', '    prepareForCodegen', '    setGPUBlockIndex(For *f,int block_index)', '    setGPUThreadIndex(For *f,int thread_index)', '    splitWithMask(For *f,int factor,For **outer,For **inner)', '    splitWithTail(For *f,int factor,For **outer,For **inner,For **tail)', '    vectorize(Stmt *stmt)', '    bind_random_vars(Stmt *s)', '    mutate(const Cond *v)', '    mutate(const For *v)', '    mutate(const FunctionCall *v)', '    mutate(const Intrinsics *v)', '    RandomInliner(const std::vector & funcs)', '    mutate(const Add *v)', '    mutate(const Sub *v)', '    mutate(const Mul *v)', '    mutate(const Div *v)', '    mutate(const Max *v)', '    mutate(const Min *v)', '    mutate(const CompareSelect *v)', '    mutate(const Cast *v)', '    mutate(const Var *v)', '    mutate(const Let *v)', '    mutate(const Ramp *v)', '    mutate(const Load *v)', '    mutate(const Broadcast *v)', '    mutate(const IfThenElse *v)', '    mutate(const BaseCallNode *v)', '    mutate(const Store *v)', '    mutate(const For *v)', '    try_vectorize(const Expr *e,std::vector & inputs,T)', '    try_vectorize(const Stmt *s,std::vector & inputs,T)', '    vectorize(const For *v)', '    vectorize_inputs(std::vector & inputs)'];
embedding_lookup.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 53;  31; 4;2;  19; 0;0;19;0;2;1.63;0;['    LoopNest', '    Range'];['    computeInline(Stmt *s)', '    computeInlineWithRandom(Stmt *s)', '    findAllNeededTensors(const std::vector & tensors)', '    getLoopBodyFor(Tensor *)', '    getLoopStmtsFor(Tensor *)', '    hasLoopBodyFor(Tensor *)', '    insertAllocFree(Stmt *stmt)', '    LoopNest(const std::vector & output_tensors)', '    lowerToStmt(Tensor *t)', '    prepareForCodegen', '    root_stmt', '    setGPUBlockIndex(For *f,int idx)', '    setGPUThreadIndex(For *f,int idx)', '    splitWithMask(For *f,int factor,For **outer,For **inner)', '    splitWithTail(For *f,int factor,For **outer,For **inner,For **tail)', '    vectorize(Stmt *)', '    Range', '    Range(const Expr *start,const Expr *stop)', '    start', '    stop'];
embedding_lookup_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 3080;  161; 8;2;  2910; 0;2406;848;1176;581;0.06;18;[];[];
embedding_lookup_fused_8bit_rowwise_idx_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 3136;  161; 8;2;  2966; 0;2480;910;1176;651;0.05;18;[];['    BCELossImpl(const BCELossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    BCEWithLogitsLossImpl(const BCEWithLogitsLossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CosineEmbeddingLossImpl(const CosineEmbeddingLossOptions & options_)', '    forward(const Tensor & input1,const Tensor & input2,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CrossEntropyLossImpl(const CrossEntropyLossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    CTCLossImpl(const CTCLossOptions & options_)', '    forward(const Tensor & log_probs,const Tensor & targets,const Tensor & input_lengths,const Tensor & target_lengths)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    HingeEmbeddingLossImpl(const HingeEmbeddingLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    KLDivLossImpl(const KLDivLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    L1LossImpl(const L1LossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input1,const Tensor & input2,const Tensor & target)', '    MarginRankingLossImpl(const MarginRankingLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MSELossImpl(const MSELossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiLabelMarginLossImpl(const torch::nn::MultiLabelMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiLabelSoftMarginLossImpl(const torch::nn::MultiLabelSoftMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    MultiMarginLossImpl(const MultiMarginLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    NLLLossImpl(const NLLLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & log_input,const Tensor & target)', '    PoissonNLLLossImpl(const PoissonNLLLossOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    SmoothL1LossImpl(const torch::nn::SmoothL1LossOptions & options_)', '    forward(const Tensor & input,const Tensor & target)', '    pretty_print(std::ostream & stream)', '    reset', '    SoftMarginLossImpl(const torch::nn::SoftMarginLossOptions & options_)', '    forward(const Tensor & anchor,const Tensor & positive,const Tensor & negative)', '    pretty_print(std::ostream & stream)', '    reset', '    TripletMarginLossImpl(const TripletMarginLossOptions & options_)'];
embedding_lookup_idx.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 226;  9; 11;139;  68; 3;39;42;348;169;0.13;37;[];['    apply_loss_reduction(const at::Tensor & unreduced,int64_t reduction)', '    binary_cross_entropy_backward_cpu(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_backward_out_cpu(Tensor & grad_input,const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_cpu(const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_out_cpu(Tensor & loss,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction)', '    binary_cross_entropy_with_logits(const Tensor & input,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    binary_cross_entropy_with_logits_backward(const Tensor & grad,const Tensor & input,const Tensor & target,const Tensor & weight,const Tensor & pos_weight,int64_t reduction)', '    cosine_embedding_loss(const Tensor & input1,const Tensor & input2,const Tensor & target,double margin,int64_t reduction)', '    hinge_embedding_loss(const Tensor & self,const Tensor & target,double margin,int64_t reduction)', '    kl_div(const Tensor & input,const Tensor & target,int64_t reduction)', '    kl_div_backward_cpu(const Tensor & grad,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    l1_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    margin_ranking_loss(const Tensor & input1,const Tensor & input2,const Tensor & target,double margin,int64_t reduction)', '    mse_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    mse_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    poisson_nll_loss(const Tensor & input,const Tensor & target,const bool log_input,const bool full,const double eps,const int64_t reduction)', '    smooth_l1_loss(const Tensor & input,const Tensor & target,const int64_t reduction)', '    smooth_l1_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    smooth_l1_loss_out(Tensor & result,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss(const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction)', '    soft_margin_loss_out(Tensor & output,const Tensor & input,const Tensor & target,int64_t reduction)', '    triplet_margin_loss(const Tensor & anchor,const Tensor & positive,const Tensor & negative,double margin,double p,double eps,bool swap,int64_t reduction)'];
embedding_lookup_idx.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 57;  35; 4;2;  19; 0;0;19;0;3;1.84;0;[];[];
fused_8bit_rowwise_conversion.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 191;  5; 23;5;  159; 0;60;76;45;34;0.03;8;[];[];
fused_8bit_rowwise_conversion.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 31;  1; 7;2;  22; 0;0;22;0;5;0.05;0;[];[];
fused_8bit_rowwise_conversion_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 169;  3; 18;5;  144; 0;120;90;49;34;0.02;2;['    GetAveragedLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragedLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragedLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragedLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragedLossGradient', '    vector', '    GetGradientDefs'];
fused_8bit_rowwise_embedding_lookup.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 55;  33; 4;2;  18; 0;0;18;0;2;1.83;0;['    final', '    final'];['    AveragedLoss(Args,...)', '    AveragedLossGradient(Args,...)', '    ~AveragedLoss', '    ~AveragedLossGradient'];
fused_8bit_rowwise_embedding_lookup_idx.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 210;  10; 11;129;  59; 4;32;37;69;50;0.17;7;[];['    get_target_prime(target_t *target,int64_t offset,int64_t stride,int64_t idx,int64_t BLANK)', '    ctc_loss_backward_cpu(const Tensor & grad,const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,const Tensor & neg_log_likelihood,const Tensor & log_alpha,int64_t BLANK,bool zero_infinity)', '    ctc_loss_backward_cpu_template(const Tensor & grad_out,const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,const Tensor & neg_log_likelihood,const Tensor & log_alpha,int64_t BLANK,bool zero_infinity)', '    ctc_loss_cpu(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK,bool zero_infinity)', '    ctc_loss_cpu_template(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK)', '    ctc_loss(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK,int64_t reduction,bool zero_infinity)', '    ctc_loss(const Tensor & log_probs,const Tensor & targets,const Tensor & input_lengths,const Tensor & target_lengths,int64_t BLANK,int64_t reduction,bool zero_infinity)'];
fused_8bit_rowwise_embedding_lookup_idx.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 57;  35; 4;2;  18; 0;0;18;0;2;1.94;0;[];['    _cudnn_ctc_loss(const Tensor & log_probs_t,const Tensor & targets_t,IntArrayRef input_lengths_,IntArrayRef target_lengths_,int64_t BLANK,bool deterministic,bool zero_infinity)', '    _use_cudnn_ctc_loss(const Tensor & log_probs,const Tensor & targets,IntArrayRef input_lengths,IntArrayRef target_lengths,int64_t BLANK)', '    grad_desc', '    log_probs', '    log_probs_desc', '    targets'];
math_cpu_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 216;  13; 15;3;  189; 0;159;120;54;58;0.07;2;[];['    multilabel_margin_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input_contiguous,const Tensor & target_contiguous,int64_t reduction,const Tensor & is_target_contiguous,int64_t nframe,int64_t dim)', '    multilabel_margin_loss_forward_out_cpu_template(const Tensor & input,const Tensor & target,Tensor & output,Tensor & is_target,int64_t reduction)', '    multilabel_margin_loss_forward_out_frame(const Tensor & input_contiguous,const Tensor & target_contiguous,Tensor & output,Tensor & is_target,int64_t reduction,int64_t nframe,int64_t dim)', '    multilabel_margin_loss_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_backward_cpu_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,int64_t reduction,const Tensor & is_target)', '    multilabel_margin_loss_forward_cpu(const Tensor & self,const Tensor & target,int64_t reduction)', '    multilabel_margin_loss_forward_inner_sum_cpu(scalar_t *input_data,int64_t *target_data,scalar_t *is_target_data,int64_t dim)', '    multilabel_margin_loss_forward_out_cpu(Tensor & output,Tensor & is_target,const Tensor & self,const Tensor & target,int64_t reduction)'];
math_cpu_base.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 161;  9; 17;5;  133; 0;75;72;36;47;0.07;4;[];['    multi_margin_loss_backward_cpu_kernel(scalar_t *grad_input_data,const Tensor & grad_output,scalar_t *input_data,int64_t *target_data,int p,scalar_t margin,scalar_t g,scalar_t *weight_data,int64_t nframe,int64_t dim,int64_t reduction)', '    multi_margin_loss_cpu_kernel(Tensor & output,scalar_t *input_data,int64_t *target_data,const int p,scalar_t margin,scalar_t *weight_data,const int64_t nframe,const int64_t dim,const int64_t reduction)', '    multi_margin_inner_sum_cpu(const scalar_t *input_data,const scalar_t *weight_data,const int p,const scalar_t margin,const int64_t dim,const int64_t target_idx)', '    multi_margin_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,int p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu(const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_backward(const Tensor & grad_output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_backward_out(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_cpu_out(Tensor & output,const Tensor & input,const Tensor & target,Scalar p,Scalar margin,const Tensor & weight,int64_t reduction)', '    multi_margin_loss_out_cpu_template(Tensor & output,const Tensor & input,const Tensor & target,int p,Scalar margin,const Tensor & weight,int64_t reduction)', '    target_index_checked(const int64_t *target_data,const int64_t index,const int64_t dim)'];
typed_axpy.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 81;  9; 8;4;  69; 0;17;41;20;20;0.13;6;[];['    nll_loss_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_out_frame(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss_forward_cpu(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_forward_out_cpu(Tensor & output,Tensor & total_weight,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss_forward_out_cpu_template(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    optional_contiguous(const Tensor & source)', '    optional_data(const Tensor & source)'];
typed_axpy_avx.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 65;  5; 9;4;  48; 0;31;20;17;14;0.10;2;[];['    nll_loss2d_backward_out_frame(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_forward_out_frame(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    check_gradout_shape_nll_loss2d(const Tensor & grad_output,const Tensor & target)', '    check_inputs_nll_loss2d(const Tensor & input,const Tensor & target,const Tensor & weight)', '    nll_loss2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index,const Tensor & total_weight)', '    nll_loss2d_forward_cpu(const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_forward_out_cpu(Tensor & output,Tensor & total_weight,const Tensor & self,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    nll_loss2d_forward_out_cpu_template(Tensor & output,Tensor & total_weight,const Tensor & input,const Tensor & target,const Tensor & weight,int64_t reduction,int64_t ignore_index)', '    optional_contiguous(const Tensor & source)', '    optional_data(const Tensor & source)'];
typed_axpy_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 99;  9; 14;4;  73; 0;46;30;29;19;0.12;3;[];['    LowerGradOf(Graph & g)'];
benchmark.cc;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 68;  5; 10;3;  52; 0;27;21;28;84;0.10;11;[];['    LowerGradOf(Graph & g)'];
data_filler.cc;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 258;  21; 23;2;  214; 0;126;75;144;62;0.10;9;[];['    loadTensors(const std::vector & slots)', '    obj_hash', '    offset_hash', '    getOrAddSlot', '    operator==(const Slot & other)', '    operator()(const Slot & slot)'];
data_filler.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 154;  26; 26;5;  99; 0;28;60;33;42;0.26;6;[];[];
data_filler_test.cc;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 25;  1; 3;4;  18; 0;9;7;8;7;0.06;1;[];['    EnsureNoTuples(ArrayRef values)', '    EnsureNoTuples(Block *block)', '    LowerAllTuples(Block *block)', '    RemoveTupleConstants(Node *n)', '    VisitNode(Node *n,Node *insert_point)', '    LowerAllTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(Block *block)', '    removeTupleNodes(Node *n,bool must_remove_tuples)'];
net_supplier.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 100;  16; 16;4;  66; 0;11;42;7;28;0.24;8;[];['    LowerAllTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(const std::shared_ptr & graph)', '    LowerSimpleTuples(Block *block)'];
output_formatter.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 21;  5; 4;2;  12; 0;1;10;0;5;0.42;1;['    GetPoolGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULpPool', '    CAFFE_ANONYMOUS_VARIABLE_CPULpPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpPoolGradient', '    vector', '    LpPoolFunctor(const OperatorBase &)', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNCHW'];
profiler.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 20;  6; 4;3;  9; 0;1;7;0;5;0.67;1;['    GetLpNormGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULpNorm', '    CAFFE_ANONYMOUS_VARIABLE_CPULpNormGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpNorm', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LpNormGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
time_profiler.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 20;  5; 3;2;  12; 0;2;7;2;5;0.42;1;['    LpNormGradientOp', '    LpNormOp'];['    LpNormGradientOp(Args,...)', '    RunOnDevice', '    LpNormOp(Args,...)', '    RunOnDevice'];
utils.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 67;  13; 6;3;  47; 0;28;14;25;9;0.28;3;[];['    LSTMUnit(int N,int D,int t,const T *H_prev,const T *C_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *C,T *H,const int32_t forget_bias,const Sigmoid & sigmoid,const Tanh & tanh,const TensorQuantizationParams & X_qparams,const TensorQuantizationParams & C_in_qparams,const TensorQuantizationParams & C_out_qparams,const TensorQuantizationParams & H_in_qparams,const TensorQuantizationParams & H_out_qparams,QuantizationFactory *qfactory)', '    Fp32Op_', '    GetQuantizationParameters_', '    InputTensorCPU_(int idx)', '    LSTMUnitDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    OutputTensorCPU_(int idx)', '    RunOnDevice'];
InferenceGraph.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 24;  10; 4;2;  9; 0;0;8;0;7;1.11;0;['    final'];['    arguments_parsed_', '    dequantize_output_', '    Fp32Op_', '    GetQuantizationParameters_', '    InputTensorCPU_(int idx)', '    LSTMUnitDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    measure_quantization_error_', '    OutputTensorCPU_(int idx)', '    RunOnDevice', '    static_assert(std::is_integral,)', '    ~LSTMUnitDNNLowPOp'];
predictor.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 71;  14; 19;5;  34; 0;9;21;6;18;0.41;5;['    GetLSTMUnitGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPULSTMUnit', '    CAFFE_ANONYMOUS_VARIABLE_CPULSTMUnitGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LSTMUnit', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LSTMUnitGradient', '    vector', '    GetGradientDefs'];
predictor_config.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 97;  6; 11;12;  63; 8;32;32;24;18;0.10;5;['    LSTMUnitGradientOp', '    LSTMUnitOp'];['    host_tanh(T x)', '    LSTMUnit(int N,int D,int t,const T *H_prev,const T *C_prev,const T *X,const int32_t *seqLengths,bool drop_states,T *C,T *H,const float forget_bias,Context *)', '    LSTMUnitGradient(int N,int D,int t,const T *C_prev,const T *X,const int32_t *seqLengths,const T *C,const T *H,const T *C_diff,const T *H_diff,bool drop_states,T *H_prev_diff,T *C_prev_diff,T *X_diff,const float forget_bias,Context *)', '    sigmoid(T x)', '    DoRunWithType', '    GetSingleArgument', '    LSTMUnitGradientOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    GetSingleArgument', '    LSTMUnitOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
predictor_config.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 58;  20; 11;6;  22; 0;6;21;1;13;0.91;0;[];['    unpair_vec(std::vector,T)', '    add(const Tensor & X,const Tensor & Y,CPUContext *context)', '    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    copy_ctor(const std::vector & X)', '    copy_ctor(const std::vector & X)', '    copy_ctor(const T & x)', '    copy_ctor(const Tensor & X)', '    copy_ctor(const t_tuple & X)', '    copy_ctor(const std::pair & X)', '    cat(const std::vector & tensorList,int axis,CPUContext *context)', '    chunk(const Tensor & input,int chunks,int axis,CPUContext *context)', '    copy_ctor([i+1] vals)', '    linear(const Tensor & X,const Tensor & W,const Tensor & B,CPUContext *context)', '    matmul(const Tensor & X,const Tensor & W,CPUContext *context)', '    mul(const Tensor & X,const Tensor & Y,CPUContext *context)', '    sigmoid(const Tensor & X)', '    stack(const std::vector & tensorList,int axis,CPUContext *context)', '    transform(X,X,Y,[])', '    tanh(const Tensor & X,CPUContext *context)', '    transpose(const Tensor & X,int dim0,int dim1,CPUContext *context)', '    unbind(const Tensor & input,int axis,CPUContext *context)', '    Add', '    CopyMatrix', '    Gemm', '    Mul', '    Set', '    Tanh', '    Transpose', '    canonical_axis_index', '    copy', '    dim', '    dim32', '    dtype', '    itemsize', '    numel', '    raw_data', '    raw_mutable_data', '    size_from_dim', '    size_to_dim', '    sizes', '    vec'];
predictor_utils.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 82;  6; 11;6;  61; 0;31;22;41;12;0.10;3;['    LUTMicrokernelTester'];['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_x8lut_ukernel_function x8lut)'];
predictor_utils.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 27;  4; 6;5;  14; 0;0;14;0;6;0.29;0;['    LUTNormMicrokernelTester'];['    inplace(bool inplace)', '    inplace', '    inplace_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_u8lut32norm_ukernel_function u8lut32norm)'];
ThreadLocalPtr.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 79;  10; 15;2;  53; 0;24;19;20;16;0.19;11;[];[];
transforms.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 329;  67; 33;1;  232; 0;153;59;116;38;0.29;10;[];[];
transforms.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 15;  2; 6;4;  4; 0;0;4;0;3;0.50;0;[];[];
caffe2_pb.h;C++;pytorch-master/pytorch-master/caffe2/proto; 142;  1; 10;4;  128; 0;90;24;86;22;0.01;6;[];[];
dlpack.h;C++;pytorch-master/pytorch-master/caffe2/python; 158;  85; 10;24;  41; 5;0;41;0;21;2.07;0;[];[];
mpi_python.cc;C++;pytorch-master/pytorch-master/caffe2/python; 47;  5; 5;3;  35; 0;15;14;4;40;0.14;1;[];['    main'];
fused_nbit_rowwise_test.cc;C++;pytorch-master/pytorch-master/caffe2/python/operator_test; 110;  1; 15;5;  90; 0;72;46;40;25;0.01;8;[];['    main'];
pybind_state.h;C++;pytorch-master/pytorch-master/caffe2/python; 498;  29; 45;46;  248; 148;97;110;90;100;0.12;15;[];['    add_negative_flag(const std::string & flag)', '    main(int argc,char *[] argv)'];
pybind_state_dlpack.cc;C++;pytorch-master/pytorch-master/caffe2/python; 73;  2; 6;1;  66; 0;48;14;10;12;0.03;6;['    C10FlagParser_db', '    C10FlagParser_input_folder', '    C10FlagParser_is_cifar100', '    C10FlagParser_output_test_db_name', '    C10FlagParser_output_train_db_name'];['    ConvertCIFAR', '    ReadImage(std::ifstream *file,int *label,char *buffer)', '    WriteToDB(const string & filename,const int num_items,const int & offset,db::DB *db)', '    main(int argc,char **argv)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_input_folder(const std::string & content)', '    C10FlagParser_is_cifar100(const std::string & content)', '    C10FlagParser_output_test_db_name(const std::string & content)', '    C10FlagParser_output_train_db_name(const std::string & content)'];
pybind_state_dlpack.h;C++;pytorch-master/pytorch-master/caffe2/python; 135;  5; 20;8;  104; 0;53;100;59;37;0.05;3;['    C10FlagParser_color', '    C10FlagParser_db', '    C10FlagParser_input_folder', '    C10FlagParser_list_file', '    C10FlagParser_num_threads', '    C10FlagParser_output_db_name', '    C10FlagParser_raw', '    C10FlagParser_scale', '    C10FlagParser_shuffle', '    C10FlagParser_warp', '    Converter'];['    ConvertImageDataset(const string & input_folder,const string & list_filename,const string & output_db_name,const bool)', '    main(int argc,char **argv)', '    C10FlagParser_color(const std::string & content)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_input_folder(const std::string & content)', '    C10FlagParser_list_file(const std::string & content)', '    C10FlagParser_num_threads(const std::string & content)', '    C10FlagParser_output_db_name(const std::string & content)', '    C10FlagParser_raw(const std::string & content)', '    C10FlagParser_scale(const std::string & content)', '    C10FlagParser_shuffle(const std::string & content)', '    C10FlagParser_warp(const std::string & content)', '    Converter', '    get', '    queue(const std::pair & pair)', '    run', '    start', '    ~Converter'];
pybind_state_hip.cc;C++;pytorch-master/pytorch-master/caffe2/python; 100;  2; 13;9;  78; 0;34;21;20;89;0.03;7;['    C10FlagParser_channel_first', '    C10FlagParser_data_limit', '    C10FlagParser_db', '    C10FlagParser_image_file', '    C10FlagParser_label_file', '    C10FlagParser_output_file'];['    convert_dataset(const char *image_filename,const char *label_filename,const char *db_path,const int data_limit)', '    swap_endian(uint32_t val)', '    main(int argc,char **argv)', '    C10FlagParser_channel_first(const std::string & content)', '    C10FlagParser_data_limit(const std::string & content)', '    C10FlagParser_db(const std::string & content)', '    C10FlagParser_image_file(const std::string & content)', '    C10FlagParser_label_file(const std::string & content)', '    C10FlagParser_output_file(const std::string & content)'];
pybind_state_ideep.cc;C++;pytorch-master/pytorch-master/caffe2/python; 207;  9; 16;18;  69; 99;31;25;37;40;0.13;7;[];['    free_used_object(const std::string & name)', '    main(int argc,char *[] argv)', '    object_exists(const char *name)', '    print_init_message(const char *message)', '    register_fd(int fd)', '    unregister_fd(int fd)', '    ClientSession(ManagerSocket s)'];
pybind_state_int8.cc;C++;pytorch-master/pytorch-master/caffe2/python; 66;  22; 7;8;  13; 19;1;7;1;6;1.69;1;[];[];
pybind_state_registry.cc;C++;pytorch-master/pytorch-master/caffe2/python; 11;  2; 4;1;  6; 0;1;6;1;5;0.33;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateMap', '    CAFFE_ANONYMOUS_VARIABLE_CPUKeyValueToMap', '    CAFFE_ANONYMOUS_VARIABLE_CPUMapToKeyValue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateMap', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_KeyValueToMap', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MapToKeyValue', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
pybind_state_registry.h;C++;pytorch-master/pytorch-master/caffe2/python; 30;  2; 7;12;  11; 0;0;10;0;10;0.18;3;['    final', '    final', '    final', '    MapDeserializer', '    MapSerializer'];['    dtype', '    MapTypeName', '    CreateMapOp(Args,...)', '    DoRunWithOtherType2', '    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2', '    DoRunWithType2', '    GetSingleArgument', '    KeyValueToMapOp(Args,...)', '    MapToKeyValueOp(Args,...)', '    Output', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~CreateMapOp', '    ~KeyValueToMapOp', '    ~MapToKeyValueOp', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    MapTypeName', '    numel', '    Resize'];
activation_distribution_observer.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 868;  28; 87;9;  745; 2;470;224;389;168;0.04;26;[];['    get_default(const Map & map,const Key & key,Value)'];
batch_matmul_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 740;  122; 67;39;  544; 30;141;318;13;766;0.22;5;['    GetMarginRankingCriterionGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMarginRankingCriterion', '    CAFFE_ANONYMOUS_VARIABLE_CPUMarginRankingCriterionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MarginRankingCriterion', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MarginRankingCriterionGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
batch_matmul_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 53;  17; 10;4;  24; 0;4;19;31;55;0.71;3;['    final', '    final'];['    MarginRankingCriterionGradientOp(Args,...)', '    MarginRankingCriterionOp(Args,...)', '    RunOnDevice'];
batch_permutation_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 66;  5; 14;4;  44; 1;22;19;19;22;0.11;2;[];['    equal(const T & a,const T & b)'];
caffe2_dnnlowp_utils.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 552;  19; 55;8;  473; 1;298;169;167;99;0.04;20;[];[];
caffe2_dnnlowp_utils.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 110;  30; 17;4;  60; 0;9;59;0;21;0.50;6;[];['    AxpyFixedSize(const int N,const float alpha,const T *x,T *y,Context *context)', '    ScaleFixedSize(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,CPUContext *)', '    operator()(const int N,const float alpha,const T *x,T *y,Context *context)', '    operator()(const int N,const float alpha,const T *x,T *y,CPUContext *)'];
channel_shuffle_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 134;  11; 21;13;  90; 3;49;46;34;46;0.12;3;['    DefaultEngine'];['    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    AddStripedBatch(const int N,const T *first,T *y,const int stripe,const int batch,Context *context)', '    And(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BiasCHW(const T *bias,const T *bias_multiplier,const int bias_channels,const int image_size,T *image,Context *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    Col2Im(const int channels,const int height,const int width,const int patch_h,const int patch_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *col_data,T *img_data,Context *context,const int groups)', '    Col2ImNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *col_data,T *img_data,Context *context,const int groups)', '    ColwiseAdd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseBitwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseDiv(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseEQ(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseGE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseGT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseLE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseLT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseMax(const int N,const int D,const T *x,T *y,Context *context)', '    ColwiseMul(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseNE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    ColwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseSub(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    ColwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    CopyMatrix(const size_t item_size,const int M,const int N,const void *A,const int lda,void *B,const int ldb,Context *context,TypeMeta::Copy copy)', '    CopyMatrix(const int M,const int N,const T *A,const int lda,T *B,const int ldb,Context *context)', '    CopyMatrix(const int M,const int N,const T *A,const int A_outer_stride,const int A_inner_stride,T *B,const int B_outer_stride,const int B_inner_stride,Context *context)', '    CopyVector(const int N,const T *A,T *B,Context *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Dot(const int N,const T *a,const T *b,T *y,Context *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Gemm(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const T *A,const T *B,const float beta,T *C,Context *context,TensorProto::DataType math_type)', '    GemmBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const T **A,const T **B,const float beta,T **C,Context *context,TensorProto::DataType math_type)', '    GemmEx(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const T alpha,const T *A,const int lda,const T *B,const int ldb,const T beta,T *C,const int ldc,Context *context)', '    GemmStridedBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const T *A,const int A_stride,const T *B,const int B_stride,const float beta,T *C,const int C_stride,Context *context,TensorProto::DataType math_type)', '    Gemv(const CBLAS_TRANSPOSE trans_A,const int M,const int N,const float alpha,const T *A,const T *x,const float beta,T *y,Context *context,TensorProto::DataType math_type)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Im2Col(const int channels,const int height,const int width,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const T *img_data,T *col_data,Context *context,const int groups)', '    Im2ColNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const T *img_data,T *col_data,Context *context,const int groups)', '    InvStd(const int N,const T epsilon,const T *var,T *inv_std,Context *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Maximum(const int N,const float alpha,const T *x,T *y,Context *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,bool *C,Context *context)', '    Or(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    RandFixedSum(const size_t n,const T a,const T b,const T sum,T *r,Context *context)', '    RandGaussian(const size_t n,const T mean,const T std,T *r,Context *context)', '    RandSyntheticData(const size_t n,const T a,const T b,T *r,Context *context)', '    RandUniform(const size_t n,const T a,const T b,T *r,Context *context)', '    RandUniformUnique(const size_t n,const T a,const T b,T *r,const size_t m,const T *avoid,Context *context)', '    RowwiseAdd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseAnd(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseBitwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseDiv(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseEQ(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseGE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseGT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseLE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseLT(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseMax(const int N,const int D,const T *x,T *y,Context *context)', '    RowwiseMul(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseNE(const int rows,const int cols,const T *A,const T *B,bool *C,Context *context)', '    RowwiseOr(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseSub(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    RowwiseXor(const int rows,const int cols,const T *A,const T *B,T *C,Context *context)', '    Select(const int N,const int D,const T *x,const int *idx,T *y,Context *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)', '    Sum(const int N,const T *x,T *y,Context *context,Tensor *scratch_ptr)', '    SumSqr(const int N,const T *x,T *y,Context *context,Tensor *scratch_ptr)', '    Xor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const T *A,const T *B,T *C,Context *context)'];
concat_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 198;  3; 24;8;  165; 2;43;82;20;191;0.02;2;[];['    divide_round_up(size_t n,size_t q)', '    doz(size_t a,size_t b)', '    max(size_t a,size_t b)', '    min(size_t a,size_t b)', '    round_up(size_t n,size_t q)'];
concat_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 28;  4; 8;3;  15; 0;1;11;31;47;0.27;0;[];['    decompress_and_dequantize(const std::uint8_t *input_data,float *output_data,std::uint64_t input_size)', '    quantize_and_compress(const float *input_data,std::uint8_t *output_data,std::uint64_t input_size,std::uint64_t bitwidth,bool random,const float *random_buffer)'];
conv_dnnlowp_acc16_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 873;  49; 96;55;  595; 96;385;363;88;385;0.08;10;[];[];
conv_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 1782;  130; 178;56;  1395; 66;1028;493;458;327;0.09;27;[];['    TEST(MathROCBLASTest,GemmNoTransNoTrans)', '    TEST(MathROCBLASTest,GemmNoTransTrans)', '    TEST(MathROCBLASTest,GemvNoTrans)', '    TEST(MathROCBLASTest,GemvTrans)', '    shapeA', '    shapeA', '    shapeW', '    shapeW', '    shapeX', '    shapeX', '    shapeX', '    shapeX', '    shapeY', '    shapeY', '    shapeY', '    shapeY'];
conv_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 137;  17; 31;8;  83; 0;10;74;58;141;0.20;7;[];[];
conv_pool_dnnlowp_op_base.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 240;  24; 37;27;  162; 5;93;62;97;112;0.15;15;[];['    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Add(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    AddStripedBatch(const int N,const float *first,float *y,const int stripe,const int batch,CPUContext *context)', '    And(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BiasCHW(const float *bias,const float *,const int bias_channels,const int image_size,float *image,CPUContext *)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseAnd(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseOr(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    BitwiseXor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    Broadcast(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    BroadcastBinaryOpImpl(const int ndim,const int *A_dims,const int *B_dims,const int *C_dims,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    BroadcastImpl(const int X_ndim,const int *X_dims,const int Y_ndim,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    Col2Im(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *col_data,float *img_data,CPUContext *context,const int groups)', '    Col2Im(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *col_data,float *img_data,CPUContext *context,const int)', '    Col2Im3dNHWCImpl(const int C,const int T,const int H,const int W,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const TData *col_data,TData *img_data,CPUContext *context,const int groups)', '    Col2ImNd(const int N,const int,const int,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *col_data,float *img_data,CPUContext *context,const int groups)', '    Col2ImNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *col_data,float *img_data,CPUContext *,const int)', '    Col2ImZeroPaddingAndNoDilationNCHW(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *col_data,T *img_data,CPUContext *context)', '    Col2ImZeroPaddingAndNoDilationNHWC(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *col_data,T *img_data,CPUContext *context)', '    ColwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBinaryOp(const int rows,const int cols,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    ColwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseMax(const int N,const int D,const float *x,float *y,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    ColwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    ColwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    ColwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    CopyMatrix(const size_t itemsize,const int M,const int N,const void *A,const int lda,void *B,const int ldb,CPUContext *,TypeMeta::Copy copy)', '    CopyMatrix(const int M,const int N,const float *A,const int lda,float *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const float *A,const int A_outer_stride,const int A_inner_stride,float *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const double *A,const int lda,double *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const double *A,const int A_outer_stride,const int A_inner_stride,double *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const int *A,const int lda,int *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const int *A,const int A_outer_stride,const int A_inner_stride,int *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const int64_t *A,const int lda,int64_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const int64_t *A,const int A_outer_stride,const int A_inner_stride,int64_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const std::uint8_t *A,const int lda,std::uint8_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const std::uint8_t *A,const int A_outer_stride,const int A_inner_stride,std::uint8_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyMatrix(const int M,const int N,const std::uint16_t *A,const int lda,std::uint16_t *B,const int ldb,CPUContext *)', '    CopyMatrix(const int M,const int N,const std::uint16_t *A,const int A_outer_stride,const int A_inner_stride,std::uint16_t *B,const int B_outer_stride,const int B_inner_stride,CPUContext *context)', '    CopyVector(const int N,const float *src,float *dst,CPUContext *)', '    CopyVector(const int N,const int32_t *src,int32_t *dst,CPUContext *)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Div(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Dot(const int N,const float *a,const float *b,float *y,CPUContext *)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    EQ(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    GE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Gemm(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const float *A,const float *B,const float beta,float *C,CPUContext *,TensorProto::DataType)', '    GemmBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float **A,const float **B,const float beta,float **C,CPUContext *context,TensorProto::DataType)', '    GemmEx(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int M,const int N,const int K,const float alpha,const float *A,const int lda,const float *B,const int ldb,const float beta,float *C,const int ldc,CPUContext *)', '    GemmStridedBatched(const CBLAS_TRANSPOSE trans_A,const CBLAS_TRANSPOSE trans_B,const int batch_size,const int M,const int N,const int K,const float alpha,const float *A,const int A_stride,const float *B,const int B_stride,const float beta,float *C,const int C_stride,CPUContext *context,TensorProto::DataType)', '    Gemv(const CBLAS_TRANSPOSE trans_A,const int M,const int N,const float alpha,const float *A,const float *x,const float beta,float *y,CPUContext *,TensorProto::DataType)', '    generate_stack_distance(std::vector & cum_val,std::vector & cum_dis,std::vector & cum_map,Ind_t max_i,Ind_t i,Context_t *context)', '    generate_trace_lru(std::vector & uni_ref,std::vector & cum_val,std::vector & cum_dis,std::vector & cum_map,Context_t *context,Ind_t cache_line_size,Ind_t n,Type min,Type max,Type *syn_ref)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    GT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Im2Col(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *img_data,float *col_data,CPUContext *context,const int groups)', '    Im2Col(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int dilation_h,const int dilation_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int stride_h,const int stride_w,const float *img_data,float *col_data,CPUContext *context,const int)', '    Im2Col3dNCHWImpl(const int channels,const int clip_len,const int height,const int width,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_a,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const T *img_data,T *col_data)', '    Im2Col3dNHWCImpl(const int C,const int T,const int H,const int W,const int kernel_t,const int kernel_h,const int kernel_w,const int dilation_t,const int dilation_h,const int dilation_w,const int pad_p,const int pad_t,const int pad_l,const int pad_n,const int pad_b,const int pad_r,const int stride_t,const int stride_h,const int stride_w,const TData *img_data,TData *col_data,const int groups)', '    Im2ColNd(const int N,const int,const int,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *img_data,float *col_data,CPUContext *,const int groups)', '    Im2ColNd(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *img_data,float *col_data,CPUContext *,const int)', '    Im2ColNdNCHWImpl(const int N,const int img_size,const int col_size,const int *img_shape,const int *col_shape,const int *kernel_shape,const int *stride,const int *dilation,const int *pad,const float *X_data,float *Y_data)', '    Im2ColZeroPaddingAndNoDilationNCHW(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *img_data,T *col_data,CPUContext *context)', '    Im2ColZeroPaddingAndNoDilationNHWC(const int C,const int H,const int W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const T *img_data,T *col_data,CPUContext *context)', '    InvStd(const int N,const float epsilon,const float *var,float *inv_std,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    LE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    LT(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Maximum(const int N,const float alpha,const float *x,float *y,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Mul(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *context)', '    NE(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    Not(const int N,const bool *x,bool *y,CPUContext *)', '    Or(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)', '    RandFixedSum(const size_t n,const float a,const float b,const float sum,float *r,CPUContext *context)', '    RandFixedSum(const size_t n,const double a,const double b,const double sum,double *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int8_t a,const int8_t b,const int8_t sum,int8_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int16_t a,const int16_t b,const int16_t sum,int16_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int32_t a,const int32_t b,const int32_t sum,int32_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const int64_t a,const int64_t b,const int64_t sum,int64_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint8_t a,const uint8_t b,const uint8_t sum,uint8_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint16_t a,const uint16_t b,const uint16_t sum,uint16_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint32_t a,const uint32_t b,const uint32_t sum,uint32_t *r,CPUContext *context)', '    RandFixedSum(const size_t n,const uint64_t a,const uint64_t b,const uint64_t sum,uint64_t *r,CPUContext *context)', '    RandGaussian(const size_t n,const float mean,const float std,float *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const float a,const float b,float *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const double a,const double b,double *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int8_t a,const int8_t b,int8_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int16_t a,const int16_t b,int16_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int32_t a,const int32_t b,int32_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const int64_t a,const int64_t b,int64_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint8_t a,const uint8_t b,uint8_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint16_t a,const uint16_t b,uint16_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint32_t a,const uint32_t b,uint32_t *r,CPUContext *context)', '    RandSyntheticData(const size_t n,const uint64_t a,const uint64_t b,uint64_t *r,CPUContext *context)', '    RandUniform(const size_t n,const float a,const float b,float *r,CPUContext *context)', '    RandUniform(const size_t n,const double a,const double b,double *r,CPUContext *context)', '    RandUniform(const size_t n,const int8_t a,const int8_t b,int8_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint8_t a,const uint8_t b,uint8_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int16_t a,const int16_t b,int16_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int32_t a,const int32_t b,int32_t *r,CPUContext *context)', '    RandUniform(const size_t n,const int64_t a,const int64_t b,int64_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint16_t a,const uint16_t b,uint16_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint32_t a,const uint32_t b,uint32_t *r,CPUContext *context)', '    RandUniform(const size_t n,const uint64_t a,const uint64_t b,uint64_t *r,CPUContext *context)', '    RandUniformUnique(const size_t n,const int32_t a,const int32_t b,int32_t *r,const size_t m,const int32_t *avoid,CPUContext *context)', '    RandUniformUnique(const size_t n,const int64_t a,const int64_t b,int64_t *r,const size_t m,const int64_t *avoid,CPUContext *context)', '    RowwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseAdd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBinaryOp(const int rows,const int cols,const BinaryOperator & op,const TIn *A,const TIn *B,TOut *C)', '    RowwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseAnd(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseOr(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseBitwiseXor(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseDiv(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseEQ(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseGT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseLT(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseMax(const int N,const int D,const float *x,float *y,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseMul(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const double *A,const double *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const float *A,const float *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseNE(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,bool *C,CPUContext *)', '    RowwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseOr(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const double *A,const double *B,double *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const float *A,const float *B,float *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseSub(const int rows,const int cols,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *)', '    RowwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    RowwiseXor(const int rows,const int cols,const bool *A,const bool *B,bool *C,CPUContext *)', '    Select(const int N,const int D,const float *x,const int *idx,float *y,CPUContext *)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const float *A,const float *B,float *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const double *A,const double *B,double *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int32_t *A,const std::int32_t *B,std::int32_t *C,CPUContext *context)', '    Sub(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const std::int64_t *A,const std::int64_t *B,std::int64_t *C,CPUContext *context)', '    Sum(const int N,const float *x,float *y,CPUContext *,Tensor *)', '    Sum(const int N,const int32_t *x,int32_t *y,CPUContext *,Tensor *)', '    Sum(const int N,const int64_t *x,int64_t *y,CPUContext *,Tensor *)', '    SumSqr(const int N,const float *x,float *y,CPUContext *,Tensor *)', '    Xor(const int A_ndim,const int *A_dims,const int B_ndim,const int *B_dims,const bool *A,const bool *B,bool *C,CPUContext *context)'];
conv_relu_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 35;  2; 6;3;  26; 0;7;15;7;12;0.08;2;[];['    decompress_and_dequantize__avx2(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    quantize_and_compress__avx2(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)'];
dequantize_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 80;  1; 12;3;  65; 0;15;32;4;42;0.02;2;[];['    decompress_and_dequantize(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    decompress_and_dequantize__base(const uint8_t *input_data,float *output_data,uint64_t input_size)', '    quantize_and_compress(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)', '    quantize_and_compress__base(const float *input_data,uint8_t *output_data,uint64_t input_size,uint64_t bitwidth,bool random,const float *random_buffer)'];
dequantize_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 20;  2; 6;3;  11; 0;0;7;17;28;0.18;0;['    BroadcastGPUTest', '    GemmBatchedGPUTest'];['    executeGpuBinaryOpTest(int shapex0,int shapex1,int shapey,std::function input0,std::function input1,std::function operation,std::function correct_output)', '    TEST(MathUtilGPUTest,testAddStripedBatch)', '    TEST(MathUtilGPUTest,testReduceMin)', '    TEST(MathUtilGPUTest,testReduceMax)', '    TEST(MathUtilGPUTest,testCopyVector)', '    TEST_F(BroadcastGPUTest,BroadcastGPUFloatTest)', '    TEST_P(GemmBatchedGPUTest,GemmBatchedGPUFloatTest)', '    TEST_P(GemmBatchedGPUTest,GemmStridedBatchedGPUFloatTest)', '    shapex', '    shapex0_vector', '    shapex1_vector', '    shapey', '    shapey_vector', '    RunBroadcastTest(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data,const std::vector & Y_data)', '    SetUp', '    SetUpData(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data)', '    VerifyResult(const std::vector & expected_output)', '    RunGemmBatched(const float alpha,const float beta)', '    RunGemmStridedBatched(const float alpha,const float beta)', '    SetUp', '    VerifyOutput(const float value)'];
dnnlowp.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 202;  50; 28;10;  117; 0;41;84;14;36;0.43;11;[];['    dot(const int N,const float *x,const float *y,float *z,CPUContext *ctx)', '    dot(const int N,const float *x,const at::Half *y,float *z,CPUContext *ctx)'];
dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 309;  85; 34;40;  158; 8;91;41;79;59;0.54;17;[];['    dot(const int N,const XT *x,const YT *y,ZT *z,CPUContext *ctx)', '    dot(const int N,const float *x,const float *y,float *z,CPUContext *ctx)', '    dot(const int N,const float *x,const at::Half *y,float *z,CPUContext *ctx)'];
dnnlowp_partition.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 57;  7; 8;2;  43; 0;24;27;17;16;0.16;3;['    BroadcastTest', '    GemmBatchedTest', '    RandFixedSumTest'];['    TEST(MathTest,GemmNoTransNoTrans)', '    TEST(MathTest,GemmNoTransTrans)', '    TEST(MathTest,GemvNoTrans)', '    TEST(MathTest,GemvTrans)', '    TEST(MathTest,FloatToHalfConversion)', '    TEST_F(BroadcastTest,BroadcastFloatTest)', '    TEST_F(RandFixedSumTest,UpperBound)', '    TEST_P(GemmBatchedTest,GemmBatchedFloatTest)', '    TEST_P(GemmBatchedTest,GemmStridedBatchedFloatTest)', '    RunBroadcastTest(const std::vector & X_dims,const std::vector & Y_dims,const std::vector & X_data,const std::vector & Y_data)', '    SetUp', '    RunGemmBatched(const float alpha,const float beta)', '    RunGemmStridedBatched(const float alpha,const float beta)', '    SetUp', '    VerifyOutput(const float value)', '    SetUp'];
dynamic_histogram.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 190;  8; 22;5;  156; 0;117;52;70;37;0.05;7;['    GetMatMulGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMatMul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MatMul', '    CopyArguments', '    GetGradientDefs'];
dynamic_histogram.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 72;  23; 13;3;  35; 0;4;23;3;20;0.66;5;['    final'];['    dimErrorString', '    axis_a_', '    axis_b_', '    GetSingleArgument', '    MatMulOp(Args,...)', '    RunOnDevice', '    Y_shape_cache_', '    ~MatMulOp'];
dynamic_histogram_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 75;  3; 13;7;  53; 0;37;20;44;21;0.06;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAMatMul'];
elementwise_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 137;  7; 11;47;  74; 0;26;30;61;68;0.09;4;['    MatrixRef'];['    data', '    empty', '    equals(MatrixRef RHS)', '    MatrixRef', '    MatrixRef(ArrayRef arr,size_type stride0)', '    numel', '    operator[](size_t Index)', '    size(size_t dim)'];
elementwise_linear_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 131;  22; 23;7;  82; 2;43;49;14;115;0.27;2;['    MaxPoolingOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    dilatedPoolingHeight', '    dilatedPoolingWidth', '    dilation(uint32_t dilation)', '    dilation(uint32_t dilationHeight,uint32_t dilationWidth)', '    dilationHeight(uint32_t dilationHeight)', '    dilationHeight', '    dilationHeight_', '    dilationWidth(uint32_t dilationWidth)', '    dilationWidth', '    dilationWidth_', '    inputHeight(size_t inputHeight)', '    inputHeight', '    inputHeight_', '    inputPixelStride(size_t inputPixelStride)', '    inputPixelStride', '    inputPixelStride_', '    inputSize(size_t inputHeight,size_t inputWidth)', '    inputWidth(size_t inputWidth)', '    inputWidth', '    inputWidth_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    nextBatchSize(size_t nextBatchSize)', '    nextBatchSize', '    nextBatchSize_', '    nextInputHeight(uint32_t nextInputHeight)', '    nextInputHeight', '    nextInputHeight_', '    nextInputSize(uint32_t nextInputHeight,uint32_t nextInputWidth)', '    nextInputWidth(uint32_t nextInputWidth)', '    nextInputWidth', '    nextInputWidth_', '    nextOutputHeight', '    nextOutputWidth', '    outputHeight', '    outputPixelStride(size_t outputPixelStride)', '    outputPixelStride', '    outputPixelStride_', '    outputWidth', '    padding(uint32_t padding)', '    padding(uint32_t paddingHeight,uint32_t paddingWidth)', '    paddingBottom(uint32_t paddingBottom)', '    paddingBottom', '    paddingBottom_', '    paddingHeight(uint32_t paddingHeight)', '    paddingLeft(uint32_t paddingLeft)', '    paddingLeft', '    paddingLeft_', '    paddingRight(uint32_t paddingRight)', '    paddingRight', '    paddingRight_', '    paddingTop(uint32_t paddingTop)', '    paddingTop', '    paddingTop_', '    paddingWidth(uint32_t paddingWidth)', '    poolingHeight(uint32_t poolingHeight)', '    poolingHeight', '    poolingHeight_', '    poolingSize(uint32_t poolingSize)', '    poolingSize(uint32_t poolingHeight,uint32_t poolingWidth)', '    poolingWidth(uint32_t poolingWidth)', '    poolingWidth', '    poolingWidth_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    stride(uint32_t stride)', '    stride(uint32_t strideHeight,uint32_t strideWidth)', '    strideHeight(uint32_t strideHeight)', '    strideHeight', '    strideHeight_', '    strideWidth(uint32_t strideWidth)', '    strideWidth', '    strideWidth_', '    testSetupU8', '    testU8'];
elementwise_linear_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 46;  16; 11;3;  17; 0;2;11;32;49;0.94;0;[];['    compute_output_dimension(size_t padded_input_dimension,size_t kernel_dimension,size_t dilation_dimension,size_t stride_dimension)', '    pytorch_qnnp_create_max_pooling2d_nhwc_u8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *max_pooling_out)', '    pytorch_qnnp_setup_max_pooling2d_nhwc_u8(pytorch_qnnp_operator_t max_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)'];
elementwise_sum_benchmark.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 36;  0; 6;5;  25; 0;21;5;10;6;0.00;1;[];['    TEST(MAX_POOLING_OP,zero_batch)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_small_pool_with_qmax)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_many_channels_large_pool_with_qmax)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_1xM_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_padding)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_Mx1_pool_with_dilation)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_input_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_output_stride)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_qmin)', '    TEST(MAX_POOLING_OP,unit_batch_few_channels_with_qmax)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_small_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_many_channels_large_pool_with_output_stride)', '    TEST(MAX_POOLING_OP,small_batch_few_channels)', '    TEST(MAX_POOLING_OP,small_batch_few_channels_with_input_stride)', '    TEST(MAX_POOLING_OP,small_batch_few_channels_with_output_stride)', '    TEST(MAX_POOLING_OP,setup_increasing_batch)', '    TEST(MAX_POOLING_OP,setup_decreasing_batch)', '    TEST(MAX_POOLING_OP,setup_changing_height)', '    TEST(MAX_POOLING_OP,setup_changing_width)', '    TEST(MAX_POOLING_OP,setup_swap_height_and_width)'];
elementwise_sum_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 258;  16; 39;26;  164; 22;54;89;12;170;0.10;3;[];['    max_pooling_u8(benchmark::State & state,const char *net)', '    ShuffleNet(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)'];
elementwise_sum_dnnlowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 205;  10; 27;4;  166; 0;102;53;23;33;0.06;1;['    final', '    final'];['    MaxPoolWithIndexGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolWithIndexOp(const OperatorDef & operator_def,Workspace *ws)', '    ~MaxPoolWithIndexGradientOp', '    ~MaxPoolWithIndexOp'];
fbgemm_pack_blob.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 47;  13; 11;5;  19; 0;1;17;0;14;0.68;1;['    MaxPoolMicrokernelTester'];['    iterations(size_t iterations)', '    iterations', '    iterations_', '    kc(size_t kc)', '    kc', '    kc_', '    kh(size_t kh)', '    kh', '    kh_', '    kr(size_t kr)', '    kr', '    kr_', '    ks', '    kw(size_t kw)', '    kw', '    kw_', '    mr(size_t mr)', '    mr', '    mr_', '    n(size_t n)', '    n', '    n_', '    packedKs', '    packedN', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    qr(size_t qr)', '    qr', '    qr_', '    s(size_t s)', '    s', '    s_', '    test(pytorch_u8maxpool_ukernel_function u8maxpool)', '    xStride(size_t xStride)', '    xStride', '    xStride_', '    yStride(size_t yStride)', '    yStride', '    yStride_'];
fbgemm_pack_matrix_cache.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 78;  10; 10;4;  58; 0;4;30;1;40;0.17;0;[];['    max_unpooling2d_backward_out_cpu_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nslices,int64_t iheight,int64_t iwidth,int64_t oheight,int64_t owidth)', '    max_unpooling3d_backward_out_cpu_frame(scalar_t *gradInput_p,scalar_t *gradOutput_p,int64_t *ind_p,int64_t nslices,int64_t iT,int64_t iH,int64_t iW,int64_t oT,int64_t oH,int64_t oW)', '    max_unpooling3d_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling2d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & indices,IntArrayRef output_size)', '    max_unpooling2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output_,const Tensor & self,const Tensor & indices_,IntArrayRef output_size)', '    max_unpooling2d_forward_cpu(const Tensor & self,const Tensor & indices,IntArrayRef output_size)', '    max_unpooling2d_forward_out_cpu(Tensor & output,const Tensor & self_,const Tensor & indices_,IntArrayRef output_size)', '    max_unpooling2d_forward_out_cpu_frame(Tensor & output,const Tensor & input,const Tensor & indices,int64_t oheight,int64_t owidth)', '    max_unpooling3d_backward_cpu(const Tensor & grad_output,const Tensor & self,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output_,const Tensor & self,const Tensor & indices_,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_cpu(const Tensor & self,const Tensor & indices,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_out_cpu(Tensor & output,const Tensor & self_,const Tensor & indices_,IntArrayRef output_size,IntArrayRef stride,IntArrayRef padding)', '    max_unpooling3d_forward_out_cpu_frame(Tensor & output,const Tensor & input,const Tensor & indices,int64_t oT,int64_t oH,int64_t oW,int64_t dT,int64_t dH,int64_t dW,int64_t pT,int64_t pH,int64_t pW)'];
fbgemm_pack_matrix_cache.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 22;  6; 4;2;  11; 0;0;11;0;3;0.55;0;['    GetMeanGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MeanGradient', '    GetGradientDefs'];
fbgemm_pack_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 174;  26; 22;6;  123; 0;8;101;76;163;0.21;6;['    final', '    MeanGradientOp'];['    DoRunWithType', '    MeanOp(Args,...)', '    RunOnDevice', '    ~MeanOp', '    DoRunWithType', '    MeanGradientOp(Args,...)', '    RunOnDevice'];
fc_fake_lowp_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 149;  4; 22;8;  115; 0;91;19;95;21;0.03;6;[];['    GetKernelArenaStack', '    GetCurrentKernelArena', '    SetCurrentKernelArena(KernelArena *new_kernel_arena)', '    ~KernelArena', '    KernelScope', '    KernelScope(KernelArena *arena_)', '    ~KernelScope', '    KernelScopedObject'];
fully_connected_dnnlowp_acc16_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 287;  29; 36;5;  237; 0;181;55;77;38;0.12;3;['    KernelArena', '    KernelScope', '    KernelScopedObject'];['    GetCurrentKernelArena', '    SetCurrentKernelArena(KernelArena *new_kernel_arena)', '    KernelArena', '    KernelArena', '    operator=', '    ~KernelArena', '    KernelScope', '    KernelScope(KernelArena *arena_)', '    KernelScope', '    operator=', '    ~KernelScope', '    KernelScopedObject', '    KernelScopedObject', '    operator=', '    ~KernelScopedObject'];
fully_connected_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 951;  64; 96;49;  643; 133;467;151;244;123;0.10;5;['    ComputeBlobRecyclingForDag'];['    compute_blob_recycling_for_dag(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    optimize_inference_net(const NetDef & net,const std::set & static_blobs)', '    apply_assignments(const NetDef & net)', '    apply_recurrent_blob_assignments(OperatorDef *op)', '    can_use_blob(const string & blob_name,std::unordered_set *tokens,const DeviceOption & device_option)', '    ComputeBlobRecyclingForDag(const int size)', '    get_blob_or_mapped_blob(const string & blob_name)', '    get_free_blob(const string & blob_name,const std::unordered_map,vector,std::unordered_set *tokens,std::vector,string,const DeviceOption & device)', '    has_key(const std::unordered_map & in_map,const K & key)', '    has_key(const std::unordered_set & in_set,const K & key)', '    infer_blob_size(const string & blob_name,const std::unordered_map,vector)', '    OptimizeNet(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    process_op(const NetDef & net,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector,int op_index,std::vector,string,std::unordered_set *tokens)'];
fully_connected_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 65;  9; 17;4;  37; 0;10;31;32;69;0.24;6;[];['    compute_blob_recycling_for_dag(const NetDef & net,const std::vector & heads,const std::vector & op_indices,const std::unordered_set & shareable_blob_names,const string & namescope,const std::unordered_set & dont_share_blob_names,const std::unordered_map,vector)', '    optimize_inference_net(const NetDef & net,const std::set & static_blobs)'];
fully_connected_fake_lowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 344;  40; 36;2;  267; 0;182;72;77;57;0.15;3;[];['    TEST(MakeUniqueTest,ForwardRvaluesCorrectly)', '    TEST(MakeUniqueTest,ForwardLvaluesCorrectly)', '    TEST(MakeUniqueTest,CanConstructUniquePtrOfArray)', '    TestValue(const int & x)', '    TestValue(int)'];
fully_connected_fake_lowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 134;  15; 16;1;  105; 0;68;57;34;35;0.14;6;[];['    _debug_has_internal_overlap(const Tensor & self)', '    is_pinned(const Tensor & self)', '    pin_memory(const Tensor & self)'];
group_norm_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 668;  5; 26;28;  611; 9;414;258;199;161;0.01;19;[];[];
group_norm_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 213;  4; 38;4;  169; 0;7;164;32;95;0.02;0;[];['    bfs(BfsDirection dir,MemoryLocations & res)', '    Element(MemoryDAG & dag_,const Value *value_,unsigned index_)', '    getMemoryLocations', '    addToContainedElements(Element *elem,Element *container)', '    collectAllContainedMemoryLocations(const Element *elem,MemoryLocations & cont)', '    fromIndex(unsigned x)', '    fromIndex(unsigned x)', '    makeFreshValue(const Value *v)', '    makePointerTo(Element *from,Element *to)', '    mayAlias(const Element *a,const Element *b)', '    mayAlias(Element *a,Element *b)', '    mayAliasImpl(const Element *a,const Element *b)', '    mayContainAlias(const Element *a,const Element *b)', '    mayContainAlias(Element *a,Element *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    mayContainAliasImpl(const Element *a,const Element *b)'];
im2col_dnnlowp.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 344;  43; 19;13;  292; 3;165;183;96;95;0.15;4;['    BfsDirection', '    MemoryDAG'];['    bfs(BfsDirection dir,MemoryLocations & res)', '    Element(MemoryDAG & dag_,const Value *value_,unsigned index_)', '    getMemoryLocations', '    addToContainedElements(Element *elem,Element *container)', '    collectAllContainedMemoryLocations(const Element *elem,MemoryLocations & cont)', '    fromIndex(unsigned x)', '    fromIndex(unsigned x)', '    makeFreshValue(const Value *v)', '    makePointerTo(Element *from,Element *to)', '    mayAlias(const Element *a,const Element *b)', '    mayAlias(Element *a,Element *b)', '    mayAliasImpl(const Element *a,const Element *b)', '    mayContainAlias(const Element *a,const Element *b)', '    mayContainAlias(Element *a,Element *b)', '    mayContainAlias(const at::ArrayRef a,const at::ArrayRef b)', '    mayContainAliasImpl(const Element *a,const Element *b)', '    MemoryDAG', '    MemoryDAG', '    operator='];
kl_minimization.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 174;  13; 22;5;  141; 1;107;47;85;42;0.09;1;[];['    memory_format', '    sliceFirst(Tensor & t,int dim,at::MemoryFormat format)', '    sliceStepTwo(Tensor & t,int dim,at::MemoryFormat format)', '    TEST(MemoryFormatTest,SetMemoryFormat)', '    TEST(MemoryFormatTest,TransposeMemoryFormat)', '    TEST(MemoryFormatTest,SliceStepTwoMemoryFormat)', '    TEST(MemoryFormatTest,SliceFirstMemoryFormat)'];
kl_minimization.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 18;  4; 4;2;  9; 0;2;7;0;3;0.44;0;[];['    size_to_add', '    size_to_add', '    TEST(MemoryOverlapTest,TensorExpanded)', '    TEST(MemoryOverlapTest,ScalarExpanded)', '    TEST(MemoryOverlapTest,NonContiguousTensor)', '    TEST(MemoryOverlapTest,NonContiguousExpandedTensor)', '    TEST(MemoryOverlapTest,ContiguousTensor)', '    TEST(MemoryOverlapTest,ContiguousExpandedTensor)'];
l1_minimization_example.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 67;  0; 14;6;  47; 0;29;16;25;18;0.00;1;[];['    self', '    THPMemoryFormat_init(PyObject *module)', '    THPMemoryFormat_New(at::MemoryFormat memory_format,const std::string & name)', '    THPMemoryFormat_repr(THPMemoryFormat *self)'];
l2_minimization.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 33;  5; 8;7;  15; 0;0;13;0;5;0.33;1;[];[];
l2_minimization_approx_example.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 67;  0; 14;5;  48; 0;30;16;27;18;0.00;1;[];['    THPMemoryFormat_Check(PyObject *obj)', '    THPMemoryFormat_init(PyObject *module)', '    THPMemoryFormat_New(at::MemoryFormat memory_format,const std::string & name)'];
l2_minimization_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 100;  4; 13;6;  78; 0;56;26;46;20;0.05;1;[];['    assert_no_internal_overlap(const Tensor & t)', '    assert_no_internal_overlap(TensorImpl *t)', '    assert_no_partial_overlap(const Tensor & a,const Tensor & b)', '    assert_no_partial_overlap(TensorImpl *a,TensorImpl *b)', '    get_overlap_status(const Tensor & a,const Tensor & b)', '    get_overlap_status(TensorImpl *a,TensorImpl *b)', '    has_internal_overlap(const Tensor & tensor)', '    has_internal_overlap(TensorImpl *t)'];
lstm_unit_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 359;  15; 52;5;  289; 0;206;134;78;75;0.05;7;['    MemOverlap', '    MemOverlapStatus'];['    assert_no_internal_overlap(const Tensor & t)', '    assert_no_partial_overlap(const Tensor & a,const Tensor & b)', '    get_overlap_status(const Tensor & a,const Tensor & b)', '    has_internal_overlap(const Tensor & tensor)'];
lstm_unit_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 44;  2; 12;6;  26; 0;2;23;0;20;0.08;3;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeIdLists', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeIdLists'];
norm_minimization.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 318;  37; 45;11;  231; 1;190;102;107;82;0.16;3;['    MergeIdListsOp'];['    DoRunWithType', '    MergeIdListsOp(Args,...)', '    RunOnDevice', '    ~MergeIdListsOp'];
norm_minimization_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 137;  12; 19;3;  107; 0;90;80;18;39;0.11;1;[];['    id', '    isRequest', '    isResponse', '    Message(std::vector,std::vector,MessageType type)', '    Message(std::vector,std::vector,MessageType type,int64_t id)', '    operator=(Message const & rhs)', '    operator=(Message)', '    payload', '    setId(int64_t id)', '    swap(Message & rhs)', '    tensors', '    tensors', '    createExceptionResponse(const std::exception & e,int64_t id)', '    createExceptionResponse(const std::string & exceptionStr,int64_t id)', '    type'];
op_wrapper.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 88;  10; 11;5;  65; 0;34;28;20;23;0.15;4;['    final'];['    createExceptionResponse(const std::exception & e,int64_t id)', '    createExceptionResponse(const std::string & exceptionStr,int64_t id)', '    id', '    isRequest', '    isResponse', '    isShutdown', '    Message(std::vector,std::vector,MessageType type)', '    Message(std::vector,std::vector,MessageType type,int64_t id)', '    Message(const Message & other)', '    operator=(Message const & rhs)', '    operator=(Message)', '    payload', '    setId(int64_t id)', '    swap(Message & rhs)', '    tensors', '    tensors', '    type'];
p99_example.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 47;  0; 11;4;  32; 0;16;13;15;15;0.00;1;[];[];
pool_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 791;  43; 70;42;  659; 12;478;306;395;448;0.07;14;[];[];
pool_dnnlowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 356;  14; 36;4;  310; 0;212;235;89;99;0.05;3;['    MyClass', '    MyClass'];['    expected', '    expected', '    expected', '    expected', '    expected', '    operator==(const MovableOnly & lhs,const MovableOnly & rhs)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_singleInput)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_movableOnly)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_onlyCopiesIfNecessary)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_onlyMovesIfNecessary)', '    TEST(MetaprogrammingTest,ExtractArgByFilteredIndex_keepsLValueReferencesIntact)', '    TEST(MetaprogrammingTest,FilterMap)', '    TEST(MetaprogrammingTest,FilterMap_emptyInput)', '    TEST(MetaprogrammingTest,FilterMap_emptyOutput)', '    TEST(MetaprogrammingTest,FilterMap_movableOnly_byRValue)', '    TEST(MetaprogrammingTest,FilterMap_movableOnly_byValue)', '    TEST(MetaprogrammingTest,DISABLED_FilterMap_onlyCopiesIfNecessary)', '    TEST(MetaprogrammingTest,DISABLED_FilterMap_onlyMovesIfNecessary_1)', '    TEST(MetaprogrammingTest,FilterMap_onlyMovesIfNecessary_2)', '    CopyCounting', '    CopyCounting(const CopyCounting & rhs)', '    CopyCounting(CopyCounting)', '    operator=(const CopyCounting & rhs)', '    operator=(CopyCounting)', '    operator()(CopyCounting v)', '    operator()(CopyCounting)', '    operator()(const CopyCounting & v)', '    operator()(MovableOnly a)', '    operator()(MovableOnly)', '    MovableOnly(int val_)', '    operator()(T a)'];
pybind.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 410;  4; 30;9;  370; 0;89;201;3;586;0.01;1;[];[];
quantization_error_minimization.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 57;  5; 11;2;  41; 0;9;32;0;16;0.12;4;[];['    begin', '    definedVariables', '    findInAnyFrame(const std::string & name)', '    findInThisFrame(const std::string & name)', '    MiniEnvironment(Block *b,std::shared_ptr next)', '    setVar(const std::string & name,T value)'];
quantize_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 95;  1; 18;11;  66; 2;13;36;2;67;0.02;2;[];['    mz_write_le16(mz_uint8 *p,mz_uint16 v)', '    mz_write_le32(mz_uint8 *p,mz_uint32 v)', '    mz_write_le64(mz_uint8 *p,mz_uint64 v)', '    mz_zip_array_clear(mz_zip_archive *pZip,mz_zip_array *pArray)', '    mz_zip_array_ensure_capacity(mz_zip_archive *pZip,mz_zip_array *pArray,size_t min_new_capacity,mz_uint growing)', '    mz_zip_array_ensure_room(mz_zip_archive *pZip,mz_zip_array *pArray,size_t n)', '    mz_zip_array_init(mz_zip_array *pArray,mz_uint32 element_size)', '    mz_zip_array_push_back(mz_zip_archive *pZip,mz_zip_array *pArray,const void *pElements,size_t n)', '    mz_zip_array_reserve(mz_zip_archive *pZip,mz_zip_array *pArray,size_t new_capacity,mz_uint growing)', '    mz_zip_array_resize(mz_zip_archive *pZip,mz_zip_array *pArray,size_t new_size,mz_uint growing)', '    mz_zip_compute_crc32_callback(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    mz_zip_file_stat_internal(mz_zip_archive *pZip,mz_uint file_index,const mz_uint8 *pCentral_dir_header,mz_zip_archive_file_stat *pStat,mz_bool *pFound_zip64_extra_data)', '    mz_zip_filename_compare(const mz_zip_array *pCentral_dir_array,const mz_zip_array *pCentral_dir_offsets,mz_uint l_index,const char *pR,mz_uint r_len)', '    mz_zip_get_cdh(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_heap_write_func(void *pOpaque,mz_uint64 file_ofs,const void *pBuf,size_t n)', '    mz_zip_locate_file_binary_search(mz_zip_archive *pZip,const char *pFilename,mz_uint32 *pIndex)', '    mz_zip_mem_read_func(void *pOpaque,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end_internal(mz_zip_archive *pZip,mz_bool set_last_error)', '    mz_zip_reader_filename_less(const mz_zip_array *pCentral_dir_array,const mz_zip_array *pCentral_dir_offsets,mz_uint l_index,mz_uint r_index)', '    mz_zip_reader_init_internal(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_reader_locate_header_sig(mz_zip_archive *pZip,mz_uint32 record_sig,mz_uint32 record_size,mz_int64 *pOfs)', '    mz_zip_reader_read_central_dir(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_reader_sort_central_dir_offsets_by_filename(mz_zip_archive *pZip)', '    mz_zip_set_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_string_equal(const char *pA,const char *pB,mz_uint len,mz_uint flags)', '    mz_zip_writer_add_put_buf_callback(const void *pBuf,int len,void *pUser)', '    mz_zip_writer_add_to_central_dir(mz_zip_archive *pZip,const char *pFilename,mz_uint16 filename_size,const void *pExtra,mz_uint16 extra_size,const void *pComment,mz_uint16 comment_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date,mz_uint64 local_header_ofs,mz_uint32 ext_attributes,const char *user_extra_data,mz_uint user_extra_data_len)', '    mz_zip_writer_compute_padding_needed_for_file_alignment(mz_zip_archive *pZip)', '    mz_zip_writer_create_central_dir_header(mz_zip_archive *pZip,mz_uint8 *pDst,mz_uint16 filename_size,mz_uint16 extra_size,mz_uint16 comment_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date,mz_uint64 local_header_ofs,mz_uint32 ext_attributes)', '    mz_zip_writer_create_local_dir_header(mz_zip_archive *pZip,mz_uint8 *pDst,mz_uint16 filename_size,mz_uint16 extra_size,mz_uint64 uncomp_size,mz_uint64 comp_size,mz_uint32 uncomp_crc32,mz_uint16 method,mz_uint16 bit_flags,mz_uint16 dos_time,mz_uint16 dos_date)', '    mz_zip_writer_create_zip64_extra_data(mz_uint8 *pBuf,mz_uint64 *pUncomp_size,mz_uint64 *pComp_size,mz_uint64 *pLocal_header_ofs)', '    mz_zip_writer_end_internal(mz_zip_archive *pZip,mz_bool set_last_error)', '    mz_zip_writer_update_zip64_extension_block(mz_zip_array *pNew_ext,mz_zip_archive *pZip,const mz_uint8 *pExt,uint32_t ext_len,mz_uint64 *pComp_size,mz_uint64 *pUncomp_size,mz_uint64 *pLocal_header_ofs,mz_uint32 *pDisk_start)', '    mz_zip_writer_validate_archive_name(const char *pArchive_name)', '    mz_zip_writer_write_zeros(mz_zip_archive *pZip,mz_uint64 cur_file_ofs,mz_uint32 n)', '    tdefl_calculate_minimum_redundancy(tdefl_sym_freq *A,int n)', '    tdefl_compress_block(tdefl_compressor *d,mz_bool static_block)', '    tdefl_compress_lz_codes(tdefl_compressor *d)', '    tdefl_compress_normal(tdefl_compressor *d)', '    tdefl_find_match(tdefl_compressor *d,mz_uint lookahead_pos,mz_uint max_dist,mz_uint max_match_len,mz_uint *pMatch_dist,mz_uint *pMatch_len)', '    tdefl_flush_block(tdefl_compressor *d,int flush)', '    tdefl_flush_output_buffer(tdefl_compressor *d)', '    tdefl_huffman_enforce_max_code_size(int *pNum_codes,int code_list_len,int max_code_size)', '    tdefl_optimize_huffman_table(tdefl_compressor *d,int table_num,int table_len,int code_size_limit,int static_table)', '    tdefl_output_buffer_putter(const void *pBuf,int len,void *pUser)', '    tdefl_radix_sort_syms(mz_uint num_syms,tdefl_sym_freq *pSyms0,tdefl_sym_freq *pSyms1)', '    tdefl_record_literal(tdefl_compressor *d,mz_uint8 lit)', '    tdefl_record_match(tdefl_compressor *d,mz_uint match_len,mz_uint match_dist)', '    tdefl_start_dynamic_block(tdefl_compressor *d)', '    tdefl_start_static_block(tdefl_compressor *d)', '    miniz_def_alloc_func(void *opaque,size_t items,size_t size)', '    miniz_def_free_func(void *opaque,void *address)', '    miniz_def_realloc_func(void *opaque,void *address,size_t items,size_t size)', '    mz_adler32(mz_ulong adler,const unsigned char *ptr,size_t buf_len)', '    mz_compress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_compress2(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len,int level)', '    mz_compressBound(mz_ulong source_len)', '    mz_crc32(mz_ulong crc,const mz_uint8 *ptr,size_t buf_len)', '    mz_deflate(mz_streamp pStream,int flush)', '    mz_deflateBound(mz_streamp pStream,mz_ulong source_len)', '    mz_deflateEnd(mz_streamp pStream)', '    mz_deflateInit(mz_streamp pStream,int level)', '    mz_deflateInit2(mz_streamp pStream,int level,int method,int window_bits,int mem_level,int strategy)', '    mz_deflateReset(mz_streamp pStream)', '    mz_error(int err)', '    mz_free(void *p)', '    mz_inflate(mz_streamp pStream,int flush)', '    mz_inflateEnd(mz_streamp pStream)', '    mz_inflateInit(mz_streamp pStream)', '    mz_inflateInit2(mz_streamp pStream,int window_bits)', '    mz_uncompress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_version', '    mz_zip_clear_last_error(mz_zip_archive *pZip)', '    mz_zip_end(mz_zip_archive *pZip)', '    mz_zip_get_archive_file_start_offset(mz_zip_archive *pZip)', '    mz_zip_get_archive_size(mz_zip_archive *pZip)', '    mz_zip_get_central_dir_size(mz_zip_archive *pZip)', '    mz_zip_get_cfile(mz_zip_archive *pZip)', '    mz_zip_get_error_string(mz_zip_error mz_err)', '    mz_zip_get_last_error(mz_zip_archive *pZip)', '    mz_zip_get_mode(mz_zip_archive *pZip)', '    mz_zip_get_type(mz_zip_archive *pZip)', '    mz_zip_is_zip64(mz_zip_archive *pZip)', '    mz_zip_peek_last_error(mz_zip_archive *pZip)', '    mz_zip_read_archive_data(mz_zip_archive *pZip,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end(mz_zip_archive *pZip)', '    mz_zip_reader_extract_file_iter_new(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_reader_extract_file_to_callback(mz_zip_archive *pZip,const char *pFilename,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_file_to_heap(mz_zip_archive *pZip,const char *pFilename,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem_no_alloc(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_extract_iter_free(mz_zip_reader_extract_iter_state *pState)', '    mz_zip_reader_extract_iter_new(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_reader_extract_iter_read(mz_zip_reader_extract_iter_state *pState,void *pvBuf,size_t buf_size)', '    mz_zip_reader_extract_to_callback(mz_zip_archive *pZip,mz_uint file_index,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_to_heap(mz_zip_archive *pZip,mz_uint file_index,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_to_mem(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_to_mem_no_alloc(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_file_stat(mz_zip_archive *pZip,mz_uint file_index,mz_zip_archive_file_stat *pStat)', '    mz_zip_reader_get_filename(mz_zip_archive *pZip,mz_uint file_index,char *pFilename,mz_uint filename_buf_size)', '    mz_zip_reader_get_num_files(mz_zip_archive *pZip)', '    mz_zip_reader_init(mz_zip_archive *pZip,mz_uint64 size,mz_uint flags)', '    mz_zip_reader_init_mem(mz_zip_archive *pZip,const void *pMem,size_t size,mz_uint flags)', '    mz_zip_reader_is_file_a_directory(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_encrypted(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_supported(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_locate_file(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags)', '    mz_zip_reader_locate_file_v2(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags,mz_uint32 *pIndex)', '    mz_zip_set_last_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_validate_archive(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_validate_file(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_validate_mem_archive(const void *pMem,size_t size,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_writer_add_from_zip_reader(mz_zip_archive *pZip,mz_zip_archive *pSource_zip,mz_uint src_file_index)', '    mz_zip_writer_add_mem(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,mz_uint level_and_flags)', '    mz_zip_writer_add_mem_ex(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32)', '    mz_zip_writer_add_mem_ex_v2(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32,mz_dummy_time_t *last_modified,const char *user_extra_data,mz_uint user_extra_data_len,const char *user_extra_data_central,mz_uint user_extra_data_central_len)', '    mz_zip_writer_end(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_archive(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_heap_archive(mz_zip_archive *pZip,void **ppBuf,size_t *pSize)', '    mz_zip_writer_init(mz_zip_archive *pZip,mz_uint64 existing_size)', '    mz_zip_writer_init_from_reader(mz_zip_archive *pZip,const char *pFilename)', '    mz_zip_writer_init_from_reader_v2(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_writer_init_heap(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size)', '    mz_zip_writer_init_heap_v2(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size,mz_uint flags)', '    mz_zip_writer_init_v2(mz_zip_archive *pZip,mz_uint64 existing_size,mz_uint flags)', '    mz_zip_zero_struct(mz_zip_archive *pZip)', '    tdefl_compress(tdefl_compressor *d,const void *pIn_buf,size_t *pIn_buf_size,void *pOut_buf,size_t *pOut_buf_size,tdefl_flush flush)', '    tdefl_compress_buffer(tdefl_compressor *d,const void *pIn_buf,size_t in_buf_size,tdefl_flush flush)', '    tdefl_compress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tdefl_compress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tdefl_compress_mem_to_output(const void *pBuf,size_t buf_len,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_compressor_alloc', '    tdefl_compressor_free(tdefl_compressor *pComp)', '    tdefl_create_comp_flags_from_zip_params(int level,int window_bits,int strategy)', '    tdefl_get_adler32(tdefl_compressor *d)', '    tdefl_get_prev_return_status(tdefl_compressor *d)', '    tdefl_init(tdefl_compressor *d,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_write_image_to_png_file_in_memory(const void *pImage,int w,int h,int num_chans,size_t *pLen_out)', '    tdefl_write_image_to_png_file_in_memory_ex(const void *pImage,int w,int h,int num_chans,size_t *pLen_out,mz_uint level,mz_bool flip)', '    tinfl_decompress(tinfl_decompressor *r,const mz_uint8 *pIn_buf_next,size_t *pIn_buf_size,mz_uint8 *pOut_buf_start,mz_uint8 *pOut_buf_next,size_t *pOut_buf_size,const mz_uint32 decomp_flags)', '    tinfl_decompress_mem_to_callback(const void *pIn_buf,size_t *pIn_buf_size,tinfl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tinfl_decompress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tinfl_decompress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tinfl_decompressor_alloc', '    tinfl_decompressor_free(tinfl_decompressor *pDecomp)'];
relu_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 80;  9; 15;5;  52; 1;35;20;29;21;0.17;1;[];['    miniz_def_alloc_func(void *opaque,size_t items,size_t size)', '    miniz_def_free_func(void *opaque,void *address)', '    miniz_def_realloc_func(void *opaque,void *address,size_t items,size_t size)', '    mz_adler32(mz_ulong adler,const unsigned char *ptr,size_t buf_len)', '    mz_compress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_compress2(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len,int level)', '    mz_compressBound(mz_ulong source_len)', '    mz_crc32(mz_ulong crc,const mz_uint8 *ptr,size_t buf_len)', '    mz_deflate(mz_streamp pStream,int flush)', '    mz_deflateBound(mz_streamp pStream,mz_ulong source_len)', '    mz_deflateEnd(mz_streamp pStream)', '    mz_deflateInit(mz_streamp pStream,int level)', '    mz_deflateInit2(mz_streamp pStream,int level,int method,int window_bits,int mem_level,int strategy)', '    mz_deflateReset(mz_streamp pStream)', '    mz_error(int err)', '    mz_free(void *p)', '    mz_inflate(mz_streamp pStream,int flush)', '    mz_inflateEnd(mz_streamp pStream)', '    mz_inflateInit(mz_streamp pStream)', '    mz_inflateInit2(mz_streamp pStream,int window_bits)', '    mz_uncompress(unsigned char *pDest,mz_ulong *pDest_len,const unsigned char *pSource,mz_ulong source_len)', '    mz_version', '    mz_zip_add_mem_to_archive_file_in_place(const char *pZip_filename,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags)', '    mz_zip_add_mem_to_archive_file_in_place_v2(const char *pZip_filename,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_zip_error *pErr)', '    mz_zip_clear_last_error(mz_zip_archive *pZip)', '    mz_zip_end(mz_zip_archive *pZip)', '    mz_zip_extract_archive_file_to_heap(const char *pZip_filename,const char *pArchive_name,size_t *pSize,mz_uint flags)', '    mz_zip_extract_archive_file_to_heap_v2(const char *pZip_filename,const char *pArchive_name,const char *pComment,size_t *pSize,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_get_archive_file_start_offset(mz_zip_archive *pZip)', '    mz_zip_get_archive_size(mz_zip_archive *pZip)', '    mz_zip_get_central_dir_size(mz_zip_archive *pZip)', '    mz_zip_get_cfile(mz_zip_archive *pZip)', '    mz_zip_get_error_string(mz_zip_error mz_err)', '    mz_zip_get_last_error(mz_zip_archive *pZip)', '    mz_zip_get_mode(mz_zip_archive *pZip)', '    mz_zip_get_type(mz_zip_archive *pZip)', '    mz_zip_is_zip64(mz_zip_archive *pZip)', '    mz_zip_peek_last_error(mz_zip_archive *pZip)', '    mz_zip_read_archive_data(mz_zip_archive *pZip,mz_uint64 file_ofs,void *pBuf,size_t n)', '    mz_zip_reader_end(mz_zip_archive *pZip)', '    mz_zip_reader_extract_file_iter_new(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_reader_extract_file_to_callback(mz_zip_archive *pZip,const char *pFilename,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_file_to_heap(mz_zip_archive *pZip,const char *pFilename,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_file_to_mem_no_alloc(mz_zip_archive *pZip,const char *pFilename,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_extract_iter_free(mz_zip_reader_extract_iter_state *pState)', '    mz_zip_reader_extract_iter_new(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_reader_extract_iter_read(mz_zip_reader_extract_iter_state *pState,void *pvBuf,size_t buf_size)', '    mz_zip_reader_extract_to_callback(mz_zip_archive *pZip,mz_uint file_index,mz_file_write_func pCallback,void *pOpaque,mz_uint flags)', '    mz_zip_reader_extract_to_heap(mz_zip_archive *pZip,mz_uint file_index,size_t *pSize,mz_uint flags)', '    mz_zip_reader_extract_to_mem(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags)', '    mz_zip_reader_extract_to_mem_no_alloc(mz_zip_archive *pZip,mz_uint file_index,void *pBuf,size_t buf_size,mz_uint flags,void *pUser_read_buf,size_t user_read_buf_size)', '    mz_zip_reader_file_stat(mz_zip_archive *pZip,mz_uint file_index,mz_zip_archive_file_stat *pStat)', '    mz_zip_reader_get_filename(mz_zip_archive *pZip,mz_uint file_index,char *pFilename,mz_uint filename_buf_size)', '    mz_zip_reader_get_num_files(mz_zip_archive *pZip)', '    mz_zip_reader_init(mz_zip_archive *pZip,mz_uint64 size,mz_uint flags)', '    mz_zip_reader_init_mem(mz_zip_archive *pZip,const void *pMem,size_t size,mz_uint flags)', '    mz_zip_reader_is_file_a_directory(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_encrypted(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_is_file_supported(mz_zip_archive *pZip,mz_uint file_index)', '    mz_zip_reader_locate_file(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags)', '    mz_zip_reader_locate_file_v2(mz_zip_archive *pZip,const char *pName,const char *pComment,mz_uint flags,mz_uint32 *pIndex)', '    mz_zip_set_last_error(mz_zip_archive *pZip,mz_zip_error err_num)', '    mz_zip_validate_archive(mz_zip_archive *pZip,mz_uint flags)', '    mz_zip_validate_file(mz_zip_archive *pZip,mz_uint file_index,mz_uint flags)', '    mz_zip_validate_file_archive(const char *pFilename,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_validate_mem_archive(const void *pMem,size_t size,mz_uint flags,mz_zip_error *pErr)', '    mz_zip_writer_add_from_zip_reader(mz_zip_archive *pZip,mz_zip_archive *pSource_zip,mz_uint src_file_index)', '    mz_zip_writer_add_mem(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,mz_uint level_and_flags)', '    mz_zip_writer_add_mem_ex(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32)', '    mz_zip_writer_add_mem_ex_v2(mz_zip_archive *pZip,const char *pArchive_name,const void *pBuf,size_t buf_size,const void *pComment,mz_uint16 comment_size,mz_uint level_and_flags,mz_uint64 uncomp_size,mz_uint32 uncomp_crc32,mz_dummy_time_t *last_modified,const char *user_extra_data,mz_uint user_extra_data_len,const char *user_extra_data_central,mz_uint user_extra_data_central_len)', '    mz_zip_writer_end(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_archive(mz_zip_archive *pZip)', '    mz_zip_writer_finalize_heap_archive(mz_zip_archive *pZip,void **ppBuf,size_t *pSize)', '    mz_zip_writer_init(mz_zip_archive *pZip,mz_uint64 existing_size)', '    mz_zip_writer_init_from_reader(mz_zip_archive *pZip,const char *pFilename)', '    mz_zip_writer_init_from_reader_v2(mz_zip_archive *pZip,const char *pFilename,mz_uint flags)', '    mz_zip_writer_init_heap(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size)', '    mz_zip_writer_init_heap_v2(mz_zip_archive *pZip,size_t size_to_reserve_at_beginning,size_t initial_allocation_size,mz_uint flags)', '    mz_zip_writer_init_v2(mz_zip_archive *pZip,mz_uint64 existing_size,mz_uint flags)', '    mz_zip_zero_struct(mz_zip_archive *pZip)', '    tdefl_compress(tdefl_compressor *d,const void *pIn_buf,size_t *pIn_buf_size,void *pOut_buf,size_t *pOut_buf_size,tdefl_flush flush)', '    tdefl_compress_buffer(tdefl_compressor *d,const void *pIn_buf,size_t in_buf_size,tdefl_flush flush)', '    tdefl_compress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tdefl_compress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tdefl_compress_mem_to_output(const void *pBuf,size_t buf_len,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_compressor_alloc', '    tdefl_compressor_free(tdefl_compressor *pComp)', '    tdefl_create_comp_flags_from_zip_params(int level,int window_bits,int strategy)', '    tdefl_get_adler32(tdefl_compressor *d)', '    tdefl_get_prev_return_status(tdefl_compressor *d)', '    tdefl_init(tdefl_compressor *d,tdefl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tdefl_write_image_to_png_file_in_memory(const void *pImage,int w,int h,int num_chans,size_t *pLen_out)', '    tdefl_write_image_to_png_file_in_memory_ex(const void *pImage,int w,int h,int num_chans,size_t *pLen_out,mz_uint level,mz_bool flip)', '    tinfl_decompress(tinfl_decompressor *r,const mz_uint8 *pIn_buf_next,size_t *pIn_buf_size,mz_uint8 *pOut_buf_start,mz_uint8 *pOut_buf_next,size_t *pOut_buf_size,const mz_uint32 decomp_flags)', '    tinfl_decompress_mem_to_callback(const void *pIn_buf,size_t *pIn_buf_size,tinfl_put_buf_func_ptr pPut_buf_func,void *pPut_buf_user,int flags)', '    tinfl_decompress_mem_to_heap(const void *pSrc_buf,size_t src_buf_len,size_t *pOut_len,int flags)', '    tinfl_decompress_mem_to_mem(void *pOut_buf,size_t out_buf_len,const void *pSrc_buf,size_t src_buf_len,int flags)', '    tinfl_decompressor_alloc', '    tinfl_decompressor_free(tinfl_decompressor *pDecomp)'];
relu_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 31;  2; 10;4;  17; 0;0;13;17;30;0.12;1;['    GetMaxGradient', '    GetMinGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MinGradient', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice'];
relu_dnnlowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 55;  2; 8;3;  44; 0;20;32;14;17;0.05;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Max', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Min'];
resize_nearest_3d_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 64;  6; 11;4;  44; 1;30;25;19;26;0.14;1;['    final', '    final', '    final', '    final', '    SelectGradientOpBase'];['    MaxGradientOp(Args,...)', '    MaxOp(Args,...)', '    MinGradientOp(Args,...)', '    MinOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~MaxGradientOp', '    ~MaxOp', '    ~MinGradientOp', '    ~MinOp', '    RunOnDevice', '    SelectGradientOpBase(Args,...)', '    ~SelectGradientOpBase'];
resize_nearest_3d_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 41;  1; 9;3;  29; 0;8;22;48;57;0.03;1;[];[];
resize_nearest_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 58;  5; 12;4;  38; 1;25;21;17;22;0.13;1;['    MIOPENState', '    MIOPENWrapper'];['    after_', '    before_', '    execute(hipStream_t stream,F)', '    gpu_id_', '    miopen_handle', '    miopen_handle_', '    MIOPENState(size_t gpu_id)', '    stream_', '    workspace', '    ~MIOPENState', '    get(size_t nbytes)', '    nbytes_', '    reset', '    ~MIOPENWorkspace', '    inline_miopen_handle', '    MIOPENWrapper(HIPContext *context)', '    with_miopen_state(size_t state_idx,F)', '  Static Member Variables', '    CAFFE2_COMPILE_TIME_MAX_MIOPEN_STATES'];
sigmoid.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 34;  3; 8;1;  23; 0;11;8;10;9;0.13;2;[];['    torch_warn_once_12', '    torch_warn_once_16', '    TEST(UtilsTest,WarnOnce)', '    TEST(NoGradTest,SetsGradModeCorrectly)', '    TEST_F(AutogradTest,CanTakeDerivatives)', '    TEST_F(AutogradTest,CanTakeDerivativesOfZeroDimTensors)', '    TEST_F(AutogradTest,CanPassCustomGradientInputs)', '    torch_warn', '    torch_warn_once_A', '    torch_warn_once_B', '    AutogradTest'];
sigmoid.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 33;  7; 7;2;  19; 0;5;12;2;10;0.37;2;[];['    pin_memory(int64_t size)'];
sigmoid_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 41;  1; 9;2;  30; 0;3;11;5;12;0.03;3;[];[];
spatial_batch_norm_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 185;  5; 23;2;  156; 0;101;74;69;62;0.03;4;[];[];
spatial_batch_norm_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 59;  6; 12;3;  40; 0;1;36;31;53;0.15;0;[];['    dense_to_mkldnn(const Tensor & cpu_tensor)', '    mkldnn_reorder_conv2d_weight(const Tensor & self,IntArrayRef padding,IntArrayRef stride,IntArrayRef dilation,int64_t groups)', '    mkldnn_to_dense(const Tensor & mkldnn_tensor)'];
spatial_batch_norm_dnnlowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 146;  3; 11;10;  125; 2;78;101;18;28;0.02;2;[];['    mkldnn_zero_(Tensor & self)'];
tanh.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 137;  12; 22;9;  92; 3;59;34;41;29;0.13;5;[];['    StoreMatrixInMatrixMarketFormat(int m,int n,const T *a,const std::string & matrix_name)'];
tanh.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 63;  12; 13;4;  36; 0;14;20;5;18;0.33;5;[];['    check_is_little_endian', '    expect_int32(std::ifstream & stream,uint32_t expected)', '    flip_endianness(uint32_t value)', '    join_paths(std::string head,const std::string & tail)', '    read_images(const std::string & root,bool train)', '    read_int32(std::ifstream & stream)', '    read_targets(const std::string & root,bool train)', '    get(size_t index)', '    images', '    is_train', '    MNIST(const std::string & root,Mode mode)', '    size', '    targets'];
tanh_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 37;  1; 9;2;  26; 0;3;11;5;12;0.04;3;[];[];
transpose.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 63;  18; 7;2;  37; 0;29;17;13;16;0.49;1;['    AddNNPACK', '    FuseNNPACKConvRelu'];['    addNNPACK(repr::NNModule *nn,bool low_memory)', '    fuseNNPACKConvRelu(repr::NNModule *nn)', '    isNNPACKConvReluEfficient(const std::string & algo,const repr::Conv & conv)', '    postprocess', '    run', '    run'];
transpose.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 13;  5; 4;2;  3; 0;0;3;0;2;1.67;0;[];['    addNNPACK(nom::repr::NNModule *nn,bool low_memory)', '    fuseNNPACKConvRelu(nom::repr::NNModule *nn)'];
utility_dnnlowp_ops.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 79;  3; 16;1;  60; 0;31;21;19;21;0.05;2;[];['    TEST(MobileTest,Convolution)'];
blobs_queue.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 173;  10; 13;12;  139; 0;68;61;68;170;0.07;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMod', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Mod', '    DoRunWithType'];
blobs_queue.h;C++;pytorch-master/pytorch-master/caffe2/queue; 70;  6; 12;11;  43; 0;12;36;2;28;0.14;11;['    final'];['    DoRunWithType', '    GetSingleArgument', '    ModOp(Args,...)', '    RunOnDevice'];
blobs_queue_db.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 71;  2; 12;15;  41; 5;27;28;4;15;0.05;4;[];['    CurrentModuleHandles', '    gModuleChangeMutex', '    MutableCurrentModules', '    CurrentModules', '    HasModule(const string & name)', '    LoadModule(const string & name,const string & filename)', '    ModuleSchema(const char *name,const char *description)'];
queue_ops.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 99;  0; 28;3;  68; 0;57;66;8;61;0.00;15;[];['    slot_params_recurse(const c10::intrusive_ptr & obj,std::vector *params)', '    find_function(const c10::QualifiedName & qn)', '    register_function(std::unique_ptr fn)', '    name', '    qualname', '    find_method(const std::string & basename)', '    parameters', '    run_method(const std::string & method_name,Stack stack)'];
queue_ops.h;C++;pytorch-master/pytorch-master/caffe2/queue; 263;  3; 36;5;  220; 0;112;99;247;248;0.01;14;[];['    LogAPIUsageOnceFromPython(const std::string & event)', '    THPModule_crashIfATenASAN(PyObject *module,PyObject *arg)', '    THPModule_crashIfCsrcASAN(PyObject *module,PyObject *arg)', '    THPModule_crashIfCsrcUBSAN(PyObject *module,PyObject *arg)', '    THPModule_getBackcompatBroadcastWarn(PyObject *module,PyObject *noargs)', '    THPModule_getBackcompatKeepdimWarn(PyObject *module,PyObject *noargs)', '    THPModule_getNumInteropThreads(PyObject *module,PyObject *noargs)', '    THPModule_getNumThreads(PyObject *module,PyObject *noargs)', '    THPModule_initExtension(PyObject *_unused,PyObject *shm_manager_path)', '    THPModule_initNames(PyObject *self,PyObject *arg)', '    THPModule_parallelInfo(PyObject *module,PyObject *noargs)', '    THPModule_setBackcompatBroadcastWarn(PyObject *module,PyObject *arg)', '    THPModule_setBackcompatKeepdimWarn(PyObject *module,PyObject *arg)', '    THPModule_setNumInteropThreads(PyObject *module,PyObject *arg)', '    THPModule_setNumThreads(PyObject *module,PyObject *arg)', '    THPModule_showConfig(PyObject *module,PyObject *noargs)', '    DLPack_Capsule_Destructor(PyObject *data)', '    initModule', '    pytorch_duplicate_guard', '    THPModule_addDocStr(PyObject *_unused,PyObject *args)', '    THPModule_benchmarkCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_deterministicCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_fromDLPack(PyObject *_unused,PyObject *data)', '    THPModule_getDefaultDevice(PyObject *_unused,PyObject *arg)', '    THPModule_getDefaultDtype(PyObject *_unused,PyObject *arg)', '    THPModule_hasDistributed(PyObject *_unused,PyObject *noargs)', '    THPModule_inferSize(PyObject *_unused,PyObject *args)', '    THPModule_isEnabledXNNPACK(PyObject *)', '    THPModule_qEngine(PyObject *)', '    THPModule_safeCall(PyObject *_unused,PyObject *args,PyObject *kwargs)', '    THPModule_setBenchmarkCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setDefaultDtype(PyObject *_unused,PyObject *dtype)', '    THPModule_setDefaultTensorType(PyObject *_unused,PyObject *type)', '    THPModule_setDeterministicCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setFlushDenormal(PyObject *_unused,PyObject *arg)', '    THPModule_setQEngine(PyObject *,PyObject *arg)', '    THPModule_setUserEnabledCuDNN(PyObject *_unused,PyObject *arg)', '    THPModule_setUserEnabledMkldnn(PyObject *_unused,PyObject *arg)', '    THPModule_supportedQEngines(PyObject *)', '    THPModule_toDLPack(PyObject *_unused,PyObject *data)', '    THPModule_userEnabledCuDNN(PyObject *_unused,PyObject *noargs)', '    THPModule_userEnabledMkldnn(PyObject *_unused,PyObject *noargs)', '    call_duplicate_guard'];
queue_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 16;  0; 5;3;  8; 0;6;8;6;25;0.00;6;[];['    create_module_object(c10::QualifiedName class_name,std::shared_ptr cu,bool shouldMangle)', '    isModule', '    Method(ModulePtr owner,Function *function)', '    operator()(std::vector stack,const Kwargs & kwargs)', '    owner', '    run(Stack & stack)', '    toModule', '    getInlineEverythingMode', '    module_state_to(autograd::Variable variable,const c10::optional & device,const c10::optional & dtype,bool non_blocking)', '    apply(const std::function & fn)', '    attributes(bool recurse)', '    buffers(bool recurse)', '    children', '    clone', '    clone_impl(std::unordered_map & type_remap)', '    clone_instance', '    clone_method(const Module & orig,const Function & method,const std::unordered_map & type_remap)', '    clone_method(const Module & orig,const std::string & name)', '    create_class(const c10::QualifiedName & name,Stack stack)', '    dump(bool print_method_bodies,bool print_attr_values,bool print_param_values)', '    dump_to_str(bool print_method_bodies,bool print_attr_values,bool print_param_values,int level)', '    Module(c10::QualifiedName class_name)', '    Module(std::shared_ptr cu,const c10::ClassTypePtr & type)', '    Module(c10::QualifiedName class_name,std::shared_ptr cu,bool shouldMangle)', '    modules', '    named_attributes(bool recurse)', '    named_buffers(bool recurse)', '    named_children', '    named_modules', '    named_parameters(bool recurse)', '    parameters(bool recurse)', '    to(at::Device device,at::ScalarType dtype,bool non_blocking)', '    to(at::ScalarType dtype,bool non_blocking)', '    to(at::Device device,bool non_blocking)', '    to_impl(const c10::optional & device,const c10::optional & dtype,bool non_blocking)', '    train(bool on)'];
rebatching_queue.h;C++;pytorch-master/pytorch-master/caffe2/queue; 68;  4; 21;10;  34; 0;3;31;0;23;0.12;3;['    A', '    ModuleWithNonTensorForward'];['    get_test_container_item(std::shared_ptr module)', '    make_deeply_nested_test_container', '    test_DeviceOrDtypeConversionSkipsUndefinedTensor(torch::Device to_device,torch::Dtype to_dtype)', '    TEST_F(ModuleTest,CanEnableAndDisableTrainingMode)', '    TEST_F(ModuleTest,ZeroGrad)', '    TEST_F(ModuleTest,ZeroGradWithUndefined)', '    TEST_F(ModuleTest,RegisterModuleThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterModuleThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,ReplaceModuleThrowsForUnknownModuleName)', '    TEST_F(ModuleTest,ReplaceModule)', '    TEST_F(ModuleTest,UnregisterModule)', '    TEST_F(ModuleTest,RegisterParameterThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterParameterThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,RegisterParameterUndefinedTensor)', '    TEST_F(ModuleTest,RegisterBufferThrowsForEmptyOrDottedName)', '    TEST_F(ModuleTest,RegisterBufferThrowsForDuplicateModuleName)', '    TEST_F(ModuleTest,CanGetName)', '    TEST_F(ModuleTest,AsCastsModulesCorrectly)', '    TEST_F(ModuleTest,DeviceOrDtypeConversionSkipsUndefinedTensor)', '    TEST_F(ModuleTest,DeviceOrDtypeConversionSkipsUndefinedTensor_CUDA)', '    TEST_F(ModuleTest,ParametersAndBuffersAccessorSkipsUndefinedTensor)', '    TEST_F(ModuleTest,Conversion_MultiCUDA)', '    TEST_F(ModuleTest,CallingCloneOnModuleThatDoesNotOverrideCloneThrows)', '    TEST_F(ModuleTest,CallingCloneOnModuleThatDoesOverrideCloneDoesNotThrow)', '    TEST_F(ModuleTest,CloneCreatesDistinctParameters)', '    TEST_F(ModuleTest,CloneCreatesDistinctParametersExplicitDevice_CUDA)', '    TEST_F(ModuleTest,CloneCreatesDistinctParametersExplicitDevice_MultiCUDA)', '    TEST_F(ModuleTest,ClonePreservesExternalReferences)', '    TEST_F(ModuleTest,CloneCopiesTheValuesOfVariablesOfSubmodules)', '    TEST_F(ModuleTest,CloneToDevicePreservesTheDeviceOfParameters_CUDA)', '    TEST_F(ModuleTest,CloningToAParticularDevicePlacesAllParametersThere_MultiCUDA)', '    TEST_F(ModuleTest,HasCorrectNumberOfParameters)', '    TEST_F(ModuleTest,ContainsParametersWithTheCorrectName)', '    TEST_F(ModuleTest,HasCorrectNumberOfBuffers)', '    TEST_F(ModuleTest,ContainsBuffersWithTheCorrectName)', '    TEST_F(ModuleTest,DefaultConstructorOfModuleHolderCallsDefaultConstructorOfImpl)', '    TEST_F(ModuleTest,ValueConstructorOfModuleHolderCallsCorrectConstructorInImpl)', '    TEST_F(ModuleTest,NullptrConstructorLeavesTheModuleHolderInEmptyState)', '    TEST_F(ModuleTest,ModulesReturnsExpectedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,ModulesExcludesSelfWhenIncludeSelfSetToFalse)', '    TEST_F(ModuleTest,NamedModulesReturnsExpectedNamedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,NamedModulesExcludesSelfWhenIncludeSelfSetToFalse)', '    TEST_F(ModuleTest,ChildrenReturnsExpectedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,NamedChildrenReturnsExpectedNamedSubmodulesForFlatModel)', '    TEST_F(ModuleTest,ParametersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,NamedParametersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,BuffersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,NamedBuffersReturnsExpectedTensorsForFlatModel)', '    TEST_F(ModuleTest,ModulesReturnsExpectedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,NamedModulesReturnsExpectedNamedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,ChildrensReturnsExpectedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,NamedChildrensReturnsExpectedNamedSubmodulesForDeepModel)', '    TEST_F(ModuleTest,ModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ConstModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,NamedModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ConstNamedModuleApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ModulePointerApplyIteratesCorreclty)', '    TEST_F(ModuleTest,NamedModulePointerApplyIteratesCorreclty)', '    TEST_F(ModuleTest,ThrowsWhenAttemptingtoGetTopLevelModuleAsSharedPtr)', '    TEST_F(ModuleTest,PrettyPrint)', '    TEST_F(ModuleTest,CanCallForwardOnNonTensorForwardThroughPimpl)', '    testDistinctParameters(std::shared_ptr m1,std::shared_ptr m2)', '    AImpl', '    AImpl(int x)', '    BufferTestModule', '    clone(const torch::optional & device)', '    forward(torch::Tensor x)', '    NestedModule', '    reset', '    ParameterTestModule', '    AGIUnit2', '    TestContainer(int64_t number,std::vector modules)', '    l1', '    l2', '    l3', '    reset', '    TestDistinctParametersModule', '    l1', '    TestModel', '    forward(torch::Tensor input)', '    l1', '    l1', '    l2', '    l2', '    l3', '    l3', '    pretty_print(std::ostream & stream)', '    reset', '    reset', '    reset', '    reset', '    TestModule', '    TestModule', '    TestModule', '    TestModule', '    TestModule', '    TestModule(int64_t size)', '    TestModule(int x,float y)'];
rebatching_queue_ops.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 72;  0; 21;1;  50; 0;42;50;5;36;0.00;9;[];['    apply_to_submodules(const NamedModulePointerApplyFunction & function,const std::string & name_prefix)', '    clone_(Module & other,const optional & device)', '    eval', '    is_serializable', '    is_training', '    load(serialize::InputArchive & archive)', '    operator<<(std::ostream & stream,const nn::Module & module)', '    operator<<(serialize::OutputArchive & archive,const std::shared_ptr & module)', '    operator>>(serialize::InputArchive & archive,const std::shared_ptr & module)', '    pretty_print(std::ostream & stream)', '    pretty_print_recursive(std::ostream & stream,const std::string & indentation)', '    register_buffer(std::string name,Tensor tensor)', '    register_parameter(std::string name,Tensor tensor,bool requires_grad)', '    save(serialize::OutputArchive & archive)', '    shared_from_this_checked', '    to(torch::Device device,torch::Dtype dtype,bool non_blocking)', '    to(torch::Dtype dtype,bool non_blocking)', '    to(torch::Device device,bool non_blocking)', '    join_name(const std::string & name_prefix,const std::string & name)', '    train(bool on)', '    unregister_module(const std::string & name)', '    zero_grad', '    apply(const ModuleApplyFunction & function)', '    apply(const ConstModuleApplyFunction & function)', '    apply(const NamedModuleApplyFunction & function,const std::string & name_prefix)', '    apply(const ConstNamedModuleApplyFunction & function,const std::string & name_prefix)', '    apply(const ModulePointerApplyFunction & function)', '    apply(const NamedModulePointerApplyFunction & function,const std::string & name_prefix)', '    buffers(bool recurse)', '    clone(const optional & device)', '    Module', '    Module(std::string name)', '    name', '    named_buffers(bool recurse)', '    named_parameters(bool recurse)', '    parameters(bool recurse)'];
rebatching_queue_ops.h;C++;pytorch-master/pytorch-master/caffe2/queue; 83;  1; 15;2;  66; 0;25;32;28;28;0.02;8;[];['    bindCudaDeviceProperties(PyObject *module)', '    forked_child', '    poison_fork', '    THCPModule_initExtension(PyObject *self,PyObject *noargs)', '    THCPModule_isInBadFork(PyObject *self,PyObject *noargs)', '    THCPModule_cudaCachingAllocator_raw_alloc(PyObject *_unused,PyObject *args)', '    THCPModule_cudaCachingAllocator_raw_delete(PyObject *_unused,PyObject *obj)', '    THCPModule_cudaHostAllocator(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaIPCCollect(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaLockMutex(PyObject *module,PyObject *noargs)', '    THCPModule_cudaSleep(PyObject *_unused,PyObject *cycles)', '    THCPModule_cudaSynchronize(PyObject *_unused,PyObject *noargs)', '    THCPModule_cudaUnlockMutex(PyObject *module,PyObject *noargs)', '    THCPModule_emptyCache(PyObject *_unused,PyObject *noargs)', '    THCPModule_getCompiledVersion(PyObject *self,PyObject *noargs)', '    THCPModule_getCurrentBlasHandle_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getCurrentStream_wrap(PyObject *,PyObject *device_index)', '    THCPModule_getDefaultStream_wrap(PyObject *,PyObject *device_index)', '    THCPModule_getDevice_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getDeviceCount_wrap(PyObject *self,PyObject *noargs)', '    THCPModule_getDriverVersion(PyObject *self,PyObject *noargs)', '    THCPModule_hasPrimaryContext(PyObject *_unused,PyObject *arg)', '    THCPModule_isDriverSufficient(PyObject *self,PyObject *noargs)', '    THCPModule_memorySnapshot(PyObject *_unused,PyObject *noargs)', '    THCPModule_memoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_methods', '    THCPModule_resetAccumulatedMemoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_resetPeakMemoryStats(PyObject *_unused,PyObject *arg)', '    THCPModule_setDevice(int device)', '    THCPModule_setDevice_wrap(PyObject *self,PyObject *arg)', '    THCPModule_setStream_wrap(PyObject *self,PyObject *obj)', '    initModule(PyObject *module)'];
file_adapter.h;C++;pytorch-master/pytorch-master/caffe2/serialize; 28;  2; 6;6;  16; 0;2;12;0;12;0.13;0;[];[];
inline_container.cc;C++;pytorch-master/pytorch-master/caffe2/serialize; 374;  9; 44;15;  309; 0;189;96;150;72;0.03;24;[];[];
inline_container.h;C++;pytorch-master/pytorch-master/caffe2/serialize; 175;  68; 25;11;  73; 0;0;0;0;0;0.93;0;['    CompilationUnit', '    Module'];['    find_function(const c10::QualifiedName & qn)', '    register_function(std::unique_ptr fn)', '    find_method(const std::string & basename)', '    forward(std::vector inputs)', '    Module(c10::intrusive_ptr object,std::shared_ptr cu)', '    Module', '    name', '    parameters', '    run_method(const std::string & method_name,Stack stack)', '    slots'];
istream_adapter.cc;C++;pytorch-master/pytorch-master/caffe2/serialize; 39;  2; 7;2;  30; 0;16;12;17;9;0.07;5;['    ModuleSchema'];['    CurrentModules', '    HasModule(const string & name)', '    LoadModule(const string & name,const string & filename)', '    ModuleSchema(const char *name,const char *description)'];
istream_adapter.h;C++;pytorch-master/pytorch-master/caffe2/serialize; 27;  3; 6;4;  16; 0;0;0;0;0;0.19;0;[];[];
read_adapter_interface.cc;C++;pytorch-master/pytorch-master/caffe2/serialize; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];['    THCPModule_getCurrentBlasHandle_wrap(PyObject *self)', '    THCPModule_getDevice_wrap(PyObject *self)', '    THCPModule_getDeviceName_wrap(PyObject *self,PyObject *arg)', '    THCPModule_getDriverVersion(PyObject *self)', '    THCPModule_isDriverSufficient(PyObject *self)', '    THCPModule_setDevice(int device)', '    THCPModule_setDevice_wrap(PyObject *self,PyObject *arg)'];
adadelta_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 72;  1; 22;1;  49; 0;45;49;2;17;0.02;4;[];['    as_module(const py::object & obj)', '    import', '    isinstance'];
adadelta_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 182;  5; 18;3;  159; 0;83;81;110;112;0.03;6;[];['    _save_for_mobile(std::ostream & out,const ExtraFilesMap & extra_files)', '    _save_for_mobile(const std::string & filename,const ExtraFilesMap & extra_files)', '    save(std::ostream & out,const ExtraFilesMap & extra_files)', '    save(const std::string & filename,const ExtraFilesMap & extra_files)'];
adagrad_fused.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 160;  6; 49;1;  110; 0;72;88;4;22;0.05;7;['    Caffe2ModuleTestStaticDummyOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCaffe2ModuleTestStaticDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Caffe2ModuleTestStaticDummy', '    TEST(ModuleTest,StaticModule)', '    gCaffe2ModuleSanityCheckcaffe2_module_test_static', '    Run(int)', '    type'];
adagrad_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 127;  8; 38;1;  82; 0;66;70;12;40;0.10;7;['    Caffe2ModuleTestDynamicDummyOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCaffe2ModuleTestDynamicDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Caffe2ModuleTestDynamicDummy', '    gCaffe2ModuleSanityCheckcaffe2_module_test_dynamic', '    Run(int)', '    type'];
adagrad_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 551;  36; 41;17;  351; 112;166;151;143;153;0.10;13;['    M'];['    M(const M & other)', '    TEST_F(ModuleListTest,RangeBasedForLoop)', '    TEST_F(ModuleListTest,PrettyPrintModuleList)', '    TEST_F(ModuleListTest,CloneToDevice_CUDA)', '    TEST_F(ModuleListTest,NestingIsPossible)', '    TEST_F(ModuleListTest,RegistersElementsAsSubmodules)', '    TEST_F(ModuleListTest,IsCloneable)', '    TEST_F(ModuleListTest,HasReferenceSemantics)', '    TEST_F(ModuleListTest,ExtendPushesModulesFromOtherModuleList)', '    TEST_F(ModuleListTest,SanityCheckForHoldingStandardModules)', '    TEST_F(ModuleListTest,AccessWithPtr)', '    TEST_F(ModuleListTest,ConstructsFromSharedPointer)', '    TEST_F(ModuleListTest,ConstructsFromConcreteType)', '    TEST_F(ModuleListTest,ConstructsFromModuleHolder)', '    TEST_F(ModuleListTest,PushBackAddsAnElement)', '    TEST_F(ModuleListTest,Insertion)', '    TEST_F(ModuleListTest,AccessWithAt)', '    MImpl(int value_)', '    MImpl(int value_)'];
adam_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 118;  2; 38;1;  78; 0;71;76;3;25;0.03;6;[];[];
clip_tensor_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 36;  1; 13;1;  22; 0;19;22;1;10;0.05;2;['    NestedModel', '    TestModel'];['    align_corners', '    align_corners', '    align_corners', '    align_corners', '    alpha', '    alpha', '    beta', '    _batchmatmul(const torch::Tensor & a,const torch::Tensor & b)', '    _combine_heads_ref(const torch::Tensor & X,at::IntArrayRef dims,int nheads,int d_head)', '    _fc(torch::Tensor X,torch::Tensor X_weight,torch::Tensor X_bias)', '    _multihead_attn_test_helper(bool add_key_padding_mask,bool add_bias_kv,bool add_zero_attn,bool saved_kv,bool same_embed_dim)', '    _scaled_dot_attn_ref(const torch::Tensor & Q,const torch::Tensor & K,const torch::Tensor & V,at::IntArrayRef dims,const torch::Tensor & unseen_mask,const torch::Tensor & key_padding_mask)', '    _softmax(const torch::Tensor & x)', '    _split_heads_ref(const torch::Tensor & X,at::IntArrayRef dims,int nheads,int d_head)', '    dims', '    ht', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    inplace', '    lambda', '    lambda', '    loss', '    loss', '    loss', '    loss', '    loss', '    loss', '    lower', '    max_val', '    min_val', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    model', '    negative_slope', '    pool', '    pool', '    pool', '    scale_factor', '    scale_factor', '    scale_factor', '    scale_factor', '    TEST_F(ModulesTest,Conv1d)', '    TEST_F(ModulesTest,Conv2dEven)', '    TEST_F(ModulesTest,Conv2dUneven)', '    TEST_F(ModulesTest,Conv3d)', '    TEST_F(ModulesTest,ConvTranspose1d)', '    TEST_F(ModulesTest,ConvTranspose2dEven)', '    TEST_F(ModulesTest,ConvTranspose2dUneven)', '    TEST_F(ModulesTest,ConvTranspose3d)', '    TEST_F(ModulesTest,MaxPool1d)', '    TEST_F(ModulesTest,MaxPool1dReturnIndices)', '    TEST_F(ModulesTest,MaxPool2dEven)', '    TEST_F(ModulesTest,MaxPool2dUneven)', '    TEST_F(ModulesTest,MaxPool2dReturnIndices)', '    TEST_F(ModulesTest,MaxPool3d)', '    TEST_F(ModulesTest,MaxPool3dReturnIndices)', '    TEST_F(ModulesTest,AvgPool1d)', '    TEST_F(ModulesTest,AvgPool2dEven)', '    TEST_F(ModulesTest,AvgPool2dUneven)', '    TEST_F(ModulesTest,AvgPool3d)', '    TEST_F(ModulesTest,FractionalMaxPool2d)', '    TEST_F(ModulesTest,FractionalMaxPool2dReturnIndices)', '    TEST_F(ModulesTest,FractionalMaxPool3d)', '    TEST_F(ModulesTest,FractionalMaxPool3dReturnIndices)', '    TEST_F(ModulesTest,LPPool1d)', '    TEST_F(ModulesTest,LPPool2d)', '    TEST_F(ModulesTest,Identity)', '    TEST_F(ModulesTest,Flatten)', '    TEST_F(ModulesTest,AdaptiveMaxPool1d)', '    TEST_F(ModulesTest,AdaptiveMaxPool1dReturnIndices)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dEven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dUneven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dReturnIndicesEven)', '    TEST_F(ModulesTest,AdaptiveMaxPool2dReturnIndicesUneven)', '    TEST_F(ModulesTest,AdaptiveMaxPool3d)', '    TEST_F(ModulesTest,AdaptiveMaxPool3dReturnIndices)', '    TEST_F(ModulesTest,AdaptiveAvgPool1d)', '    TEST_F(ModulesTest,AdaptiveAvgPool2dEven)', '    TEST_F(ModulesTest,AdaptiveAvgPool2dUneven)', '    TEST_F(ModulesTest,AdaptiveAvgPool3d)', '    TEST_F(ModulesTest,MaxUnpool1d)', '    TEST_F(ModulesTest,MaxPool1d_MaxUnpool1d)', '    TEST_F(ModulesTest,MaxUnpool2d)', '    TEST_F(ModulesTest,MaxPool2d_MaxUnpool2d)', '    TEST_F(ModulesTest,MaxUnpool3d)', '    TEST_F(ModulesTest,MaxUnpool3dOutputSize)', '    TEST_F(ModulesTest,MaxPool3d_MaxUnpool3d)', '    TEST_F(ModulesTest,Linear)', '    TEST_F(ModulesTest,LocalResponseNorm)', '    TEST_F(ModulesTest,LayerNorm)', '    TEST_F(ModulesTest,GroupNorm)', '    TEST_F(ModulesTest,Bilinear)', '    TEST_F(ModulesTest,Fold)', '    TEST_F(ModulesTest,Unfold)', '    TEST_F(ModulesTest,SimpleContainer)', '    TEST_F(ModulesTest,EmbeddingBasic)', '    TEST_F(ModulesTest,EmbeddingList)', '    TEST_F(ModulesTest,EmbeddingFromPretrained)', '    TEST_F(ModulesTest,EmbeddingBagFromPretrained)', '    TEST_F(ModulesTest,AlphaDropout)', '    TEST_F(ModulesTest,FeatureAlphaDropout)', '    TEST_F(ModulesTest,Dropout)', '    TEST_F(ModulesTest,Dropout2d)', '    TEST_F(ModulesTest,Dropout3d)', '    TEST_F(ModulesTest,Parameters)', '    TEST_F(ModulesTest,FunctionalCallsSuppliedFunction)', '    TEST_F(ModulesTest,FunctionalWithTorchFunction)', '    TEST_F(ModulesTest,FunctionalArgumentBinding)', '    TEST_F(ModulesTest,BatchNorm1dStateful)', '    TEST_F(ModulesTest,BatchNorm1dStateless)', '    TEST_F(ModulesTest,BatchNorm1d)', '    TEST_F(ModulesTest,BatchNorm2dStateful)', '    TEST_F(ModulesTest,BatchNorm2dStateless)', '    TEST_F(ModulesTest,BatchNorm2d)', '    TEST_F(ModulesTest,BatchNorm3dStateful)', '    TEST_F(ModulesTest,BatchNorm3dStateless)', '    TEST_F(ModulesTest,BatchNorm3d)', '    TEST_F(ModulesTest,InstanceNorm1dStateful)', '    TEST_F(ModulesTest,InstanceNorm1dStateless)', '    TEST_F(ModulesTest,InstanceNorm1d)', '    TEST_F(ModulesTest,InstanceNorm2dStateful)', '    TEST_F(ModulesTest,InstanceNorm2dStateless)', '    TEST_F(ModulesTest,InstanceNorm2d)', '    TEST_F(ModulesTest,InstanceNorm3dStateful)', '    TEST_F(ModulesTest,InstanceNorm3dStateless)', '    TEST_F(ModulesTest,InstanceNorm3d)', '    TEST_F(ModulesTest,Linear_CUDA)', '    TEST_F(ModulesTest,Linear2_CUDA)', '    TEST_F(ModulesTest,L1Loss)', '    TEST_F(ModulesTest,MSELoss)', '    TEST_F(ModulesTest,BCELoss)', '    TEST_F(ModulesTest,KLDivLoss)', '    TEST_F(ModulesTest,HingeEmbeddingLoss)', '    TEST_F(ModulesTest,MultiMarginLoss)', '    TEST_F(ModulesTest,CosineEmbeddingLoss)', '    TEST_F(ModulesTest,SmoothL1LossDefaultOptions)', '    TEST_F(ModulesTest,MultiLabelMarginLossDefaultOptions)', '    TEST_F(ModulesTest,SmoothL1LossNoReduction)', '    TEST_F(ModulesTest,MultiLabelMarginLossNoReduction)', '    TEST_F(ModulesTest,TripletMarginLoss)', '    TEST_F(ModulesTest,NLLLoss)', '    TEST_F(ModulesTest,CrossEntropyLoss)', '    TEST_F(ModulesTest,CosineSimilarity)', '    TEST_F(ModulesTest,SoftMarginLossDefaultOptions)', '    TEST_F(ModulesTest,MultiLabelSoftMarginLossDefaultOptions)', '    TEST_F(ModulesTest,SoftMarginLossNoReduction)', '    TEST_F(ModulesTest,MultiLabelSoftMarginLossWeightedNoReduction)', '    TEST_F(ModulesTest,PairwiseDistance)', '    TEST_F(ModulesTest,ELU)', '    TEST_F(ModulesTest,SELU)', '    TEST_F(ModulesTest,Hardshrink)', '    TEST_F(ModulesTest,Hardtanh)', '    TEST_F(ModulesTest,HardtanhMinValGEMaxVal)', '    TEST_F(ModulesTest,LeakyReLU)', '    TEST_F(ModulesTest,LogSigmoid)', '    TEST_F(ModulesTest,Softmax)', '    TEST_F(ModulesTest,Softmin)', '    TEST_F(ModulesTest,LogSoftmax)', '    TEST_F(ModulesTest,AdaptiveLogSoftmaxWithLoss)', '    TEST_F(ModulesTest,Softmax2d)', '    TEST_F(ModulesTest,PReLU)', '    TEST_F(ModulesTest,ReLU)', '    TEST_F(ModulesTest,ReLU6)', '    TEST_F(ModulesTest,RReLU)', '    TEST_F(ModulesTest,CELU)', '    TEST_F(ModulesTest,GLU)', '    TEST_F(ModulesTest,GELU)', '    TEST_F(ModulesTest,Sigmoid)', '    TEST_F(ModulesTest,PixelShuffle)', '    TEST_F(ModulesTest,Softplus)', '    TEST_F(ModulesTest,Softshrink)', '    TEST_F(ModulesTest,Softsign)', '    TEST_F(ModulesTest,Tanh)', '    TEST_F(ModulesTest,Tanhshrink)', '    TEST_F(ModulesTest,Threshold)', '    TEST_F(ModulesTest,Upsampling1D)', '    TEST_F(ModulesTest,Upsampling2D)', '    TEST_F(ModulesTest,Upsampling3D)', '    TEST_F(ModulesTest,CTCLoss)', '    TEST_F(ModulesTest,PoissonNLLLoss)', '    TEST_F(ModulesTest,MarginRankingLoss)', '    TEST_F(ModulesTest,BCEWithLogitsLoss)', '    TEST_F(ModulesTest,MultiheadAttention)', '    TEST_F(ModulesTest,PrettyPrintIdentity)', '    TEST_F(ModulesTest,PrettyPrintFlatten)', '    TEST_F(ModulesTest,ReflectionPad1d)', '    TEST_F(ModulesTest,ReflectionPad2d)', '    TEST_F(ModulesTest,ReplicationPad1d)', '    TEST_F(ModulesTest,ReplicationPad2d)', '    TEST_F(ModulesTest,ReplicationPad3d)', '    TEST_F(ModulesTest,ZeroPad2d)', '    TEST_F(ModulesTest,ConstantPad1d)', '    TEST_F(ModulesTest,ConstantPad2d)', '    TEST_F(ModulesTest,ConstantPad3d)', '    TEST_F(ModulesTest,CrossMapLRN2d)', '    TEST_F(ModulesTest,RNNCell)', '    TEST_F(ModulesTest,LSTMCell)', '    TEST_F(ModulesTest,GRUCell)', '    TEST_F(ModulesTest,PrettyPrintLinear)', '    TEST_F(ModulesTest,PrettyPrintBilinear)', '    TEST_F(ModulesTest,PrettyPrintConv)', '    TEST_F(ModulesTest,PrettyPrintConvTranspose)', '    TEST_F(ModulesTest,PrettyPrintUpsample)', '    TEST_F(ModulesTest,PrettyPrintFold)', '    TEST_F(ModulesTest,PrettyPrintUnfold)', '    TEST_F(ModulesTest,PrettyPrintMaxPool)', '    TEST_F(ModulesTest,PrettyPrintAvgPool)', '    TEST_F(ModulesTest,PrettyPrinFractionalMaxPool)', '    TEST_F(ModulesTest,PrettyPrintLPPool)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveMaxPool)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveAvgPool)', '    TEST_F(ModulesTest,PrettyPrintMaxUnpool)', '    TEST_F(ModulesTest,PrettyPrintDropout)', '    TEST_F(ModulesTest,PrettyPrintDropout2d)', '    TEST_F(ModulesTest,PrettyPrintDropout3d)', '    TEST_F(ModulesTest,PrettyPrintFunctional)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm1d)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm2d)', '    TEST_F(ModulesTest,PrettyPrintBatchNorm3d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm1d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm2d)', '    TEST_F(ModulesTest,PrettyPrintInstanceNorm3d)', '    TEST_F(ModulesTest,PrettyPrintLayerNorm)', '    TEST_F(ModulesTest,PrettyPrintGroupNorm)', '    TEST_F(ModulesTest,PrettyPrintLocalResponseNorm)', '    TEST_F(ModulesTest,PrettyPrintEmbedding)', '    TEST_F(ModulesTest,PrettyPrintEmbeddingBag)', '    TEST_F(ModulesTest,PrettyPrintL1Loss)', '    TEST_F(ModulesTest,PrettyPrintKLDivLoss)', '    TEST_F(ModulesTest,PrettyPrintMSELoss)', '    TEST_F(ModulesTest,PrettyPrintBCELoss)', '    TEST_F(ModulesTest,PrettyPrintHingeEmbeddingLoss)', '    TEST_F(ModulesTest,PrettyPrintCosineEmbeddingLoss)', '    TEST_F(ModulesTest,PrettyPrintTripletMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintNLLLoss)', '    TEST_F(ModulesTest,PrettyPrinCrossEntropyLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiLabelMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiLabelSoftMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintSoftMarginLoss)', '    TEST_F(ModulesTest,PrettyPrintCosineSimilarity)', '    TEST_F(ModulesTest,PrettyPrintPairwiseDistance)', '    TEST_F(ModulesTest,PrettyPrintReflectionPad)', '    TEST_F(ModulesTest,PrettyPrintReplicationPad)', '    TEST_F(ModulesTest,PrettyPrintZeroPad2d)', '    TEST_F(ModulesTest,PrettyPrintConstantPad)', '    TEST_F(ModulesTest,PrettyPrintNestedModel)', '    TEST_F(ModulesTest,PrettyPrintELU)', '    TEST_F(ModulesTest,PrettyPrintSELU)', '    TEST_F(ModulesTest,PrettyPrintGLU)', '    TEST_F(ModulesTest,PrettyPrintHardshrink)', '    TEST_F(ModulesTest,PrettyPrintHardtanh)', '    TEST_F(ModulesTest,PrettyPrintLeakyReLU)', '    TEST_F(ModulesTest,PrettyPrintLogSigmoid)', '    TEST_F(ModulesTest,PrettyPrintSoftmax)', '    TEST_F(ModulesTest,PrettyPrintSoftmin)', '    TEST_F(ModulesTest,PrettyPrintLogSoftmax)', '    TEST_F(ModulesTest,PrettyPrintSoftmax2d)', '    TEST_F(ModulesTest,PrettyPrintPReLU)', '    TEST_F(ModulesTest,PrettyPrintReLU)', '    TEST_F(ModulesTest,PrettyPrintReLU6)', '    TEST_F(ModulesTest,PrettyPrintRReLU)', '    TEST_F(ModulesTest,PrettyPrintCELU)', '    TEST_F(ModulesTest,PrettyPrintSigmoid)', '    TEST_F(ModulesTest,PrettyPrintPixelShuffle)', '    TEST_F(ModulesTest,PrettyPrintSoftplus)', '    TEST_F(ModulesTest,PrettyPrintSoftshrink)', '    TEST_F(ModulesTest,PrettyPrintSoftsign)', '    TEST_F(ModulesTest,PrettyPrintTanh)', '    TEST_F(ModulesTest,PrettyPrintTanhshrink)', '    TEST_F(ModulesTest,PrettyPrintThreshold)', '    TEST_F(ModulesTest,PrettyPrintCTCLoss)', '    TEST_F(ModulesTest,PrettyPrintPoissonNLLLoss)', '    TEST_F(ModulesTest,PrettyPrintMarginRankingLoss)', '    TEST_F(ModulesTest,PrettyPrintCrossMapLRN2d)', '    TEST_F(ModulesTest,PrettyPrintAlphaDropout)', '    TEST_F(ModulesTest,PrettyPrintFeatureAlphaDropout)', '    TEST_F(ModulesTest,PrettyPrintBCEWithLogitsLoss)', '    TEST_F(ModulesTest,PrettyPrintMultiheadAttention)', '    TEST_F(ModulesTest,PrettyPrintRNNCell)', '    TEST_F(ModulesTest,PrettyPrintLSTMCell)', '    TEST_F(ModulesTest,PrettyPrintGRUCell)', '    TEST_F(ModulesTest,PrettyPrintAdaptiveLogSoftmaxWithLoss)', '    threshold', '    threshold', '    unpool', '    unpool', '    unpool', '    upper', '    value', '    InnerTestModule', '    NestedModel', '    TestModel', '    TestModule'];
clip_tensor_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 66;  3; 15;8;  43; 0;26;20;41;44;0.07;2;[];[];
fp16_momentum_sgd_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 72;  4; 8;3;  58; 0;23;33;33;35;0.07;5;['    GetMomentsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMoments', '    CAFFE_ANONYMOUS_VARIABLE_CPUMomentsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Moments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentsGradient', '    GetGradientDefs', '    Compute(const std::vector & dY_dims,const std::vector & dX_dims,const T *dmean_data,const T *dvariance_data,const T *X_data,const T *mean_data,T *dX_data)', '    vector'];
ftrl_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 147;  8; 10;1;  129; 0;86;64;45;51;0.06;9;['    final', '    final'];['    Compute(const std::vector & dY_dims,const std::vector & dX_dims,const T *dmean_data,const T *dvariance_data,const T *X_data,const T *mean_data,T *dX_data)', '    GetRepeatedArgument', '    MomentsGradientOp(Args,...)', '    MomentsOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
ftrl_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 78;  3; 10;2;  63; 0;14;33;36;46;0.05;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMomentumSGD', '    CAFFE_ANONYMOUS_VARIABLE_CPUMomentumSGDUpdate', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseMomentumSGDUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentumSGD', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MomentumSGDUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseMomentumSGDUpdate'];
gftrl_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 104;  10; 10;1;  90; 0;52;47;33;30;0.11;5;['    final', '    final'];['    momentum_sgd_update(const int N,const float *g,const float *m,float *ng,float *nm,const float *lr,const float momentum,const bool nesterov,float *param)', '    IDEEPMomentumSGDOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPMomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice'];
iter_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 64;  2; 15;7;  41; 3;24;30;10;26;0.05;6;['    final', '    final', '    final'];['    momentum_sgd_update(const int N,const float *g,const float *m,float *ng,float *nm,const float *lr,const float momentum,const bool nesterov,float *param,Context *)', '    DoRunWithType', '    GetSingleArgument', '    momentum_', '    momentum_', '    MomentumSGDOp(const OperatorDef & operator_def,Workspace *ws)', '    MomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SparseMomentumSGDUpdateOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
iter_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 104;  13; 16;9;  68; 0;23;32;61;68;0.19;7;[];[];
iter_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 9;  1; 3;2;  4; 0;2;4;2;9;0.25;2;[];['    pytorch_q8dwconv_ukernel_mp8x25__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
lars_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 93;  4; 16;7;  68; 0;33;38;38;45;0.06;3;[];[];
learning_rate_adaption_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 41;  1; 16;1;  24; 0;19;22;1;9;0.04;2;[];['    pytorch_q8dwconv_ukernel_mp8x25__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
learning_rate_adaption_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 74;  2; 7;6;  61; 0;29;29;37;36;0.03;5;[];['    pytorch_q8gavgpool_ukernel_mp8x7p7q__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
learning_rate_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 146;  1; 62;1;  83; 0;79;81;1;13;0.01;2;[];[];
learning_rate_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 264;  6; 9;8;  245; 0;209;133;101;98;0.02;3;[];['    pytorch_q8gavgpool_ukernel_mp8x7p7q__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
learning_rate_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 6;  1; 1;2;  3; 0;1;3;1;5;0.33;1;[];[];
math_lp.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 33;  3; 5;5;  22; 1;1;20;1;5;0.14;1;[];['    pytorch_q8avgpool_ukernel_mp8x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
momentum_sgd_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 115;  3; 47;1;  67; 0;58;63;3;25;0.04;6;[];[];
momentum_sgd_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 186;  6; 23;2;  156; 0;86;74;118;123;0.04;10;[];[];
rmsprop_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 63;  0; 5;3;  55; 0;24;29;32;33;0.00;5;[];['    pytorch_q8avgpool_ukernel_mp8x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
rowwise_adagrad_fused.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 170;  2; 52;1;  117; 0;71;78;3;26;0.02;6;[];['    AssimilateComm(MPI_Comm intra,MPI_Comm inter)', '    GlobalMPIComm', '    MPICommRank(MPI_Comm comm)', '    MPICommSize(MPI_Comm comm)', '    MPIMutex', '    MPISetupPeers(const int replicas,const string & role,const string & job_path)', '    SetGlobalMPIComm(MPI_Comm new_comm)', '    _typeMetaDataInstance'];
rowwise_adagrad_fused.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 687;  56; 94;11;  482; 54;260;240;208;196;0.12;13;['    MPICommonWorldWrapper', '    MPIDataTypeWrapper', '    MPIDataTypeWrapper', '    MPIDataTypeWrapper'];['    CheckInitializedMPI', '    GlobalMPIComm', '    MPICommRank(MPI_Comm comm)', '    MPICommSize(MPI_Comm comm)', '    MPIMutex', '    MPISetupPeers(const int replicas,const string & role,const string & job_path)', '    SetGlobalMPIComm(MPI_Comm new_comm)', '    type', '    type', '    type', '    comm', '    MPICommonWorldWrapper(MPI_Comm src_comm,int color,int rank)', '    rank', '    size', '    ~MPICommonWorldWrapper'];
rowwise_counter.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 73;  1; 11;2;  60; 0;25;29;24;23;0.02;3;['    C10FlagParser_caffe_test_root'];['    TEST(MPITest,TestMPIAllreduce)', '    TEST(MPITest,TestMPIBroadcast)', '    TEST(MPITest,TestInPlaceMPIAllreduce)', '    TEST(MPITest,TestMPIAllgather)', '    TEST(MPITest,TestMPIReduce)', '    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)'];
weight_scale_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 40;  16; 6;1;  18; 0;15;18;1;9;0.89;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMPIAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPICreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPIReduce', '    CAFFE_ANONYMOUS_VARIABLE_CPUMPISendTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIAllgather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIAllreduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIBroadcast', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPICreateCommonWorld', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIReceiveTensor', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPIReduce', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MPISendTensor'];
weight_scale_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 84;  17; 10;4;  54; 0;18;32;24;35;0.31;3;['    final', '    final', '    final', '    final', '    final', '    final', '    final'];['    MPIAllgatherOp(Args,...)', '    MPIAllreduceOp(Args,...)', '    MPIBroadcastOp(const OperatorDef & operator_def,Workspace *ws)', '    MPICreateCommonWorldOp(const OperatorDef & operator_def,Workspace *ws)', '    MPIReceiveTensorOp(const OperatorDef & def,Workspace *ws)', '    MPIReduceOp(const OperatorDef & operator_def,Workspace *ws)', '    MPISendTensorOp(const OperatorDef & def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~MPIAllgatherOp', '    ~MPIAllreduceOp', '    ~MPIBroadcastOp', '    ~MPIReduceOp'];
wngrad_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 248;  5; 21;4;  222; 0;110;99;111;110;0.02;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIAllgather', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIAllreduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIBroadcast', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPICreateCommonWorld', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIReceiveTensor', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPIReduce', '    CAFFE_ANONYMOUS_VARIABLE_CUDAMPISendTensor'];
yellowfin_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 93;  2; 18;38;  36; 0;33;35;5;49;0.06;3;[];['    PYBIND11_MODULE(mpi_utils,m)'];
yellowfin_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 321;  26; 40;26;  230; 0;118;134;167;154;0.11;6;['    C10FlagParser_caffe_test_root'];['    TEST(MPITest,TestMPIAllreduce)', '    TEST(MPITest,TestMPIBroadcast)', '    TEST(MPITest,TestInPlaceMPIAllreduce)', '    TEST(MPITest,TestMPIAllgather)', '    TEST(MPITest,TestMPIReduce)', '    main(int argc,char **argv)', '    C10FlagParser_caffe_test_root(const std::string & content)'];
depthwise3x3_conv_op_test.cc;C++;pytorch-master/pytorch-master/caffe2/share/contrib/depthwise; 217;  7; 32;10;  170; 0;116;74;68;42;0.04;6;[];[];
conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/share/contrib/nnpack; 425;  64; 36;9;  337; 0;278;57;79;50;0.19;7;[];[];
nnpack_test.cc;C++;pytorch-master/pytorch-master/caffe2/share/contrib/nnpack; 389;  7; 45;10;  329; 0;230;137;120;99;0.02;18;[];[];
quant_decomp_zstd_op.h;C++;pytorch-master/pytorch-master/caffe2/share/contrib/zstd; 23;  4; 6;5;  10; 0;0;7;17;28;0.40;2;[];[];
caffe2_gtest_main.cc;C++;pytorch-master/pytorch-master/caffe2/test; 46;  29; 4;4;  9; 0;4;2;4;8;3.22;2;[];[];
common_subexpression_elimination.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 158;  30; 25;4;  101; 0;61;33;52;28;0.30;4;[];['    add_override(const Tensor & a,const Tensor & b,Scalar c)', '    empty_override(IntArrayRef size,const TensorOptions & options)', '    fake_convolution(const Tensor & input,const Tensor & weight,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups)', '    fake_convolution_backward(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool transposed,IntArrayRef output_padding,int64_t groups,std::array output_mask)', '    get_tensor(caffe2::TypeMeta dtype,IntArrayRef size)', '    get_test_int', '    init_msnpu_extension', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    block(void *event,const Stream & stream)', '    destroyEvent(void *event,const DeviceIndex device_index)', '    deviceCount', '    exchangeDevice(Device d)', '    exchangeStream(Stream s)', '    getDevice', '    getStream(Device d)', '    MSNPUGuardImpl', '    MSNPUGuardImpl(DeviceType t)', '    queryEvent(void *event)', '    record(void **event,const Stream & stream,const DeviceIndex device_index,const EventFlag flag)', '    setDevice(Device d)', '    type', '    uncheckedSetDevice(Device d)'];
common_subexpression_elimination_test.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 103;  32; 15;4;  58; 0;45;14;36;13;0.55;2;[];[];
conv_to_nnpack_transform.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 7;  1; 3;1;  3; 0;0;3;0;3;0.33;0;[];['    mul_op_cpu_impl(const at::Tensor & A_,const at::Tensor & B_,const at::Tensor & C_,bool legacy_broadcast,int64_t axis)'];
conv_to_nnpack_transform.h;C++;pytorch-master/pytorch-master/caffe2/transforms; 25;  3; 5;5;  13; 0;4;5;2;4;0.23;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUMultiClassAccuracy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MultiClassAccuracy', '    RunOnDevice'];
pattern_net_transform.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 261;  35; 31;5;  192; 0;129;68;95;52;0.18;5;['    final'];['    MultiClassAccuracyOp(Args,...)', '    RunOnDevice', '    ~MultiClassAccuracyOp'];
pattern_net_transform.h;C++;pytorch-master/pytorch-master/caffe2/transforms; 133;  68; 15;5;  46; 0;11;25;14;17;1.48;4;[];['    multinomial_kernel_impl(Tensor & result,const Tensor & self,const int64_t n_sample,const bool with_replacement,Generator gen)', '    multinomial_apply(Tensor & result,const Tensor & self,const int64_t n_sample,const bool with_replacement,Generator generator)'];
pattern_net_transform_test.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 532;  95; 84;4;  369; 0;264;125;226;141;0.26;19;[];['    MurmurHash3_x64_128(const void *key,const int len,const uint32_t seed,void *out)', '    MurmurHash3_x86_128(const void *key,const int len,uint32_t seed,void *out)', '    MurmurHash3_x86_32(const void *key,int len,uint32_t seed,void *out)', '    fmix32(uint32_t h)', '    fmix64(uint64_t k)', '    getblock32(const uint32_t *p,int i)', '    getblock64(const uint64_t *p,int i)'];
single_op_transform.h;C++;pytorch-master/pytorch-master/caffe2/transforms; 37;  11; 6;5;  16; 0;2;14;0;7;0.69;0;[];['    MurmurHash3_x64_128(const void *key,int len,uint32_t seed,void *out)', '    MurmurHash3_x86_128(const void *key,int len,uint32_t seed,void *out)', '    MurmurHash3_x86_32(const void *key,int len,uint32_t seed,void *out)'];
bench_utils.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 89;  2; 5;7;  28; 48;21;8;22;7;0.07;1;[];['    slow_conv_transpose2d_backward_out_cpu_template(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_input,const Tensor & weight_,const Tensor & grad_columns_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int kernel_height,int kernel_width,int stride_height,int stride_width,int pad_height,int pad_width,int output_padding_height,int output_padding_width,int dilation_height,int dilation_width,bool weight_nullable)', '    slow_conv_transpose2d_acc_grad_parameters_cpu(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_weight,Tensor & grad_bias,const Tensor & columns_,const Tensor & ones_,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,int scale_)', '    slow_conv_transpose2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & columns,const Tensor & ones,std::array output_mask)', '    slow_conv_transpose2d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & columns,const Tensor & ones)', '    slow_conv_transpose2d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_out_cpu(Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose2d_out_cpu_template(Tensor & output,const Tensor & input_,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias_,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,Tensor & columns_,Tensor & ones_)'];
bench_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils; 30;  17; 7;5;  3; 0;0;3;0;2;5.67;0;[];['    slow_conv_transpose3d_shape_check(const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & bias,int kernel_depth,int kernel_width,int kernel_height,int stride_depth,int stride_width,int stride_height,int padding_depth,int padding_width,int padding_height,int dilation_depth,int dilation_width,int dilation_height,int output_padding_depth,int output_padding_width,int output_padding_height,int weight_nullable)', '    slow_conv_transpose3d_acc_grad_parameters_cpu(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_weight,Tensor & grad_bias,const Tensor & finput,const Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,int scale_)', '    slow_conv_transpose3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & finput,const Tensor & fgrad,std::array output_mask)', '    slow_conv_transpose3d_backward_out_cpu(Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,const Tensor & finput,const Tensor & fgrad)', '    slow_conv_transpose3d_backward_out_cpu_template(const Tensor & input_,const Tensor & grad_output_,Tensor & grad_input,const Tensor & weight_,const Tensor & finput,const Tensor & fgrad_input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_out_cpu(Tensor & output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation)', '    slow_conv_transpose3d_out_cpu_template(Tensor & output,const Tensor & input_,const Tensor & weight_,IntArrayRef kernel_size,const Tensor & bias_,IntArrayRef stride,IntArrayRef padding,IntArrayRef output_padding,IntArrayRef dilation,Tensor & finput,Tensor & fgrad_input)'];
cast_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 39;  2; 7;9;  22; 0;18;9;12;3;0.09;1;[];['    col2hvol(const Dtype *data_col,const int channels,const IntArrayRef input_size,const IntArrayRef output_size,const IntArrayRef kernel_size,const IntArrayRef stride_size,const IntArrayRef pad_size,const IntArrayRef dilation_size,Dtype *data_hvol)', '    hvol2col(const Dtype *data_hvol,const int channels,const IntArrayRef input_size,const IntArrayRef output_size,const IntArrayRef kernel_size,const IntArrayRef stride_size,const IntArrayRef pad_size,const IntArrayRef dilation_size,Dtype *data_col)', '    slow_conv_dilated2d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size,const std::array output_mask)', '    slow_conv_dilated2d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated3d_backward_cpu(const Tensor & grad_output,const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size,const std::array output_mask)', '    slow_conv_dilated3d_cpu(const Tensor & input,const Tensor & weight,IntArrayRef kernel_size,const Tensor & bias,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_all_cpu_template(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output,Tensor & grad_input,Tensor & grad_weight,Tensor & grad_bias,IntArrayRef kernel_size,IntArrayRef stride_size,IntArrayRef pad_size,IntArrayRef dilation_size)', '    slow_conv_dilated_location_check(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & grad_output)'];
cblas.h;C++;pytorch-master/pytorch-master/caffe2/utils; 606;  61; 45;14;  489; 1;0;489;0;162;0.12;0;[];[];
conversions.h;C++;pytorch-master/pytorch-master/caffe2/utils; 46;  3; 12;19;  12; 5;2;8;2;5;0.25;2;[];[];
cpuid.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 80;  1; 5;6;  25; 47;15;11;10;10;0.04;2;[];['    check_unique_names(DimnameList names)', '    get_named_tensor_meta(TensorImpl *impl)', '    get_named_tensor_meta(const TensorImpl *impl)', '    check_names_valid_for(const Tensor & tensor,DimnameList names)', '    check_names_valid_for(size_t tensor_dim,DimnameList names)', '    default_names(size_t len)', '    check_names_valid_for(TensorImpl *impl,DimnameList names)', '    get_names(const TensorImpl *impl)', '    get_opt_names(const TensorImpl *impl)', '    has_names(const TensorImpl *impl)', '    internal_set_names_inplace(TensorImpl *impl,optional names,bool validate_names)', '    internal_set_names_inplace(TensorImpl *impl,std::vector,bool validate_names)', '    internal_set_names_inplace(Tensor & tensor,optional names)', '    internal_set_names_inplace(Tensor & tensor,std::vector,bool validate_names)', '    has_names', '    is_enabled', '    set_enabled(bool enabled)'];
cpuid.h;C++;pytorch-master/pytorch-master/caffe2/utils; 143;  12; 16;19;  97; 0;84;94;84;93;0.12;84;[];['    align(const Tensor & tensor,DimnameList names,bool is_aligning_two_tensors)', '    align_tensors_to(TensorList tensors,DimnameList names)', '    aligned_size(IntArrayRef tensor_sizes,DimnameList tensor_names,DimnameList aligned_names,bool is_aligning_two_tensors)', '    countUnset(std::bitset,int64_t up_to_idx)', '    cumprod(IntArrayRef sizes)', '    report_moving_unnamed_dim_error(DimnameList names,DimnameList,bool is_aligning_two_tensors)', '    report_not_a_subsequence_error(DimnameList names,DimnameList other,bool is_aligning_two_tensors)', '    align_as(const Tensor & tensor,const Tensor & other)', '    align_tensors(TensorList tensors)', '    align_to(const Tensor & tensor,DimnameList order,int64_t ellipsis_idx)', '    align_to(const Tensor & tensor,DimnameList names)', '    gather(const Tensor & self,Dimname dim,const Tensor & index,bool sparse_grad)', '    gather_out(Tensor & result,const Tensor & self,Dimname dim,const Tensor & index,bool sparse_grad)', '    index_add(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_add_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_copy(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_copy_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_fill(const Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    index_fill(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_fill_(Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    index_fill_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    index_select(const Tensor & self,Dimname dim,const Tensor & index)', '    index_select_out(Tensor & out,const Tensor & self,Dimname dim,const Tensor & index)', '    refine_names(const Tensor & self,DimnameList names)', '    rename(const Tensor & self,optional names)', '    rename_(Tensor & self,optional names)', '    scatter(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter(const Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    scatter_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter_(Tensor & self,Dimname dim,const Tensor & index,Scalar source)', '    scatter_add(const Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    scatter_add_(Tensor & self,Dimname dim,const Tensor & index,const Tensor & source)', '    sort(const Tensor & self,Dimname dim,bool keepdim)', '    sort_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    squeeze(const Tensor & self,Dimname dim)', '    squeeze_(Tensor & self,Dimname dim)', '    unflatten(const Tensor & self,int64_t dim,IntArrayRef sizes,DimnameList names)', '    unflatten(const Tensor & self,Dimname dim,IntArrayRef sizes,DimnameList names)'];
cpuid_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 10;  1; 3;2;  5; 0;1;3;1;2;0.20;1;[];[];
fatal_signal_asan_no_sig_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 148;  1; 0;37;  0; 145;0;0;0;0;0.00;0;[];[];
filler.h;C++;pytorch-master/pytorch-master/caffe2/utils; 140;  9; 21;7;  105; 0;58;43;56;33;0.09;12;[];['    check_unify(DimnameList names,DimnameList other_names,DimnameList expected)', '    check_unify_error(DimnameList names,DimnameList other_names)', '    dimnameFromString(const std::string & str)', '    dimnames_equal(at::DimnameList names,at::DimnameList other)', '    nchw', '    tensornames_unify_from_right(DimnameList names,DimnameList other_names)', '    TEST(NamedTensorTest,defaultMetadata)', '    TEST(NamedTensorTest,isNamed)', '    TEST(NamedTensorTest,attachMetadata)', '    TEST(NamedTensorTest,internalSetNamesInplace)', '    TEST(NamedTensorTest,empty)', '    TEST(NamedTensorTest,dimnameToPosition)', '    TEST(NamedTensorTest,unifyFromRight)', '    TEST(NamedTensorTest,alias)', '    TEST(NamedTensorTest,NoNamesGuard)', '    TEST(NamedTensorTest,TensorNamePrint)', '    TEST(NamedTensorTest,TensorNamesCheckUnique)'];
fixed_divisor.h;C++;pytorch-master/pytorch-master/caffe2/utils; 132;  36; 19;23;  75; 2;43;23;36;19;0.48;8;[];['    check_for_misalignment(const Dimname & name,DimnameList names,DimnameList other_names,const char *action)', '    are_distinct(DimnameList batch_dims,DimnameList feature_dims)', '    assert_names_equal(DimnameList a,DimnameList b)', '    batch_dims(DimnameList names)', '    check_feature_names_are_distinct(DimnameList self_names,DimnameList other_names,DimnameList outnames)', '    compute_dot_product_outnames(DimnameList tensor_names,int64_t tensor_dotted_dim,DimnameList other_names,int64_t other_dotted_dim)', '    compute_included_idxs(IntArrayRef excluded_idxs,int64_t ndims)', '    compute_matmul_outnames(DimnameList self_names,DimnameList other_names)', '    feature_dims(DimnameList names)', '    num_batch_dims(DimnameList names)', '    report_positional_error(const Dimname & name,const Dimname & other_name,DimnameList names,DimnameList other_names,const char *action)', '    toDimnameRepr(const Tensor & tensor)', '    dimname_to_position(const Tensor & tensor,Dimname dim)', '    dimnames_to_positions(const Tensor & tensor,DimnameList dims)', '    are_names_equal(TensorImpl *self,TensorImpl *other)', '    broadcast_to_outnames(const Tensor & tensor,const Tensor & reference_tensor,const char *op_name)', '    check_names_for_dot(TensorImpl *vec1,TensorImpl *vec2)', '    compute_baddbmm_outnames(TensorImpl *result,TensorImpl *batch1,TensorImpl *batch2,TensorImpl *bias)', '    compute_bmm_outnames(Tensor & result,const Tensor & self,const Tensor & other)', '    compute_broadcast_outnames(const Tensor & self,const Tensor & other)', '    compute_cat_outnames(TensorList tensors)', '    compute_cdist_outnames(const Tensor & self,const Tensor & other)', '    compute_diagonal_outnames(const Tensor & tensor,int64_t dim1,int64_t dim2)', '    compute_matmul_outnames(const Tensor & self,const Tensor & other)', '    compute_squeeze_outnames(const Tensor & tensor)', '    propagate_names(TensorImpl *result,DimnameList names,bool validate_names)', '    propagate_names(Tensor & result,const Tensor & src)', '    propagate_names(TensorImpl *result,TensorImpl *src)', '    propagate_names(Tensor & result,DimnameList names,bool validate_names)', '    propagate_names_except(Tensor & result,const Tensor & src,IntArrayRef excluded_idxs)', '    propagate_names_for_addmm(TensorImpl *result,TensorImpl *m1,TensorImpl *m2,TensorImpl *bias)', '    propagate_names_for_addmv(TensorImpl *result,TensorImpl *mat,TensorImpl *vec,TensorImpl *bias)', '    propagate_names_for_expand(Tensor & result,const Tensor & self)', '    propagate_names_for_reduction(Tensor & result,const Tensor & src,IntArrayRef reduced_dims,bool keepdim)', '    propagate_names_if_nonempty(TensorImpl *result,DimnameList maybe_names,bool validate_names)', '    propagate_names_if_nonempty(Tensor & result,DimnameList maybe_names,bool validate_names)', '    unify_from_right(DimnameList names,DimnameList other_names,const char *action)'];
math_blas_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils/hip; 379;  8; 31;9;  332; 0;298;86;126;85;0.02;16;[];[];
map_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils; 19;  4; 3;1;  12; 0;3;9;3;4;0.33;1;[];['    NotLeakingSymbolsFromTorchAutogradNamespace_test_func(Node *node)', '    TEST(NamespaceTests,NotLeakingSymbolsFromTorchAutogradNamespace)'];
math-detail.h;C++;pytorch-master/pytorch-master/caffe2/utils; 90;  9; 13;3;  71; 0;8;53;8;14;0.13;6;[];['    requireEqualTensorList(TensorList t1,TensorList t2)', '    test(TensorOptions T,TensorOptions AccT)', '    TEST(TestNative,NativeTestCPU)', '    TEST(TestNative,NativeTestGPU)', '    TestChunk(TensorOptions T,Tensor & t)', '    TestMatmul(TensorOptions T,Tensor & t,TensorOptions AccT)', '    TestSize(TensorOptions T,Tensor & t)', '    TestSplit(TensorOptions,Tensor & t)', '    TestStack(TensorOptions T,Tensor & t)', '    TestStandardGammaGrad(TensorOptions T,Tensor & t)', '    TestWhere(TensorOptions T,Tensor & t)'];
broadcast.cc;C++;pytorch-master/pytorch-master/caffe2/utils/math; 55;  4; 4;46;  5; 0;1;5;8;8;0.80;2;[];['    $', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values,const TensorOptions & options)', '    tensor(std::initializer_list values)', '    tensor(uint8_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(uint8_t value)', '    tensor(std::initializer_list values)', '    tensor(int8_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(int8_t value)', '    tensor(std::initializer_list values)', '    tensor(int16_t value,const TensorOptions & options)', '    tensor((*) () decltype,const TensorOptions & options)', '    tensor(int16_t value)', '    tensor(std::initializer_list values)', '    tensor(int value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(int value)', '    tensor(std::initializer_list values)', '    tensor(int64_t value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(int64_t value)', '    tensor(std::initializer_list values)', '    tensor(float value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(float value)', '    tensor(std::initializer_list values)', '    tensor(double value,const TensorOptions & options)', '    tensor(ArrayRef values)', '    tensor(double value)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)', '    tensor(std::initializer_list values)', '    tensor((*) () decltype)', '    tensor(ArrayRef values)', '    tensor(ArrayRef values)'];
broadcast.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 24;  3; 5;5;  14; 0;0;14;0;3;0.21;0;[];['    get_device', '    broadcast(TensorList tensors,const stream_list & streams,const comm_list & user_comms)', '    check_inputs(TensorList inputs,TensorList outputs,int input_multiplier,int output_multiplier)', '    get_communicators(TensorList inputs)', '    get_data_type(const Tensor & t)', '    throw_nccl_error(ncclResult_t status)', '    get_max_count', '    is_available(TensorList tensors)', '    reduce(const std::vector & inputs,std::vector & outputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    reduce(std::vector & inputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    version', '    NcclCommList(const std::vector & devices)', '    ref', '    ~NcclCommList'];
elementwise.cc;C++;pytorch-master/pytorch-master/caffe2/utils/math; 698;  54; 33;394;  176; 209;139;143;214;148;0.31;146;[];['    NCCL_CHECK(ncclResult_t status)', '    broadcast(at::TensorList tensors,const stream_list & streams,const comm_list & user_comms)', '    check_inputs(at::TensorList inputs,at::TensorList outputs,int input_multiplier,int output_multiplier)', '    get_data_type(const at::Tensor & t)', '    throw_nccl_error(ncclResult_t status)', '    get_max_count', '    reduce(const std::vector & inputs,std::vector & outputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    reduce(std::vector & inputs,int32_t root,int32_t op,const stream_list & streams,const comm_list & user_comms)', '    version', '    AutoNcclGroup', '    ~AutoNcclGroup'];
half_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 49;  4; 8;7;  34; 0;8;18;4;11;0.12;4;[];['    getNcclVersion', '    ncclGetErrorWithVersion(ncclResult_t error)'];
reduce.cc;C++;pytorch-master/pytorch-master/caffe2/utils/math; 670;  13; 36;140;  494; 2;232;274;600;255;0.03;61;['    NCCLComm'];['    getNcclVersion', '    ncclGetErrorWithVersion(ncclResult_t error)', '    create(int numRanks,int rank,ncclUniqueId commId)', '    checkForNcclError', '    getNcclComm', '    getNcclId', '    isAborted', '    NCCLComm(ncclComm_t ncclComm)', '    NCCLComm', '    NCCLComm', '    NCCLComm(NCCLComm)', '    ncclCommAbort', '    operator=', '    operator=', '    ~NCCLComm'];
reduce.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 107;  14; 17;5;  74; 0;0;74;0;12;0.19;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUNegateGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NegateGradient', '    vector', '    GetGradientDefs'];
transpose.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 31;  4; 7;5;  18; 0;0;18;0;5;0.22;0;['    final'];['    NegateGradientOp(Args,...)', '    RunOnDevice', '    ~NegateGradientOp'];
utils.cc;C++;pytorch-master/pytorch-master/caffe2/utils/math; 367;  3; 19;76;  272; 0;158;100;202;69;0.01;19;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDANegateGradient'];
utils.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 186;  23; 34;11;  122; 1;12;100;11;29;0.19;11;['    GetNegativeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUNegative', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Negative', '    GetGradientDefs', '    vector'];
math_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 431;  26; 40;10;  378; 0;280;116;104;92;0.07;21;[];['    operator()(const int N,const T *X,T *Y,Context *context)'];
math_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 500;  10; 35;10;  448; 0;334;122;145;113;0.02;16;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDANegative'];
murmur_hash3.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 463;  39; 89;24;  300; 28;240;61;202;52;0.13;7;[];['    pytorch_q8vadd_ukernel__neon(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)'];
proto_convert.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 5;  1; 1;2;  2; 0;0;2;0;1;0.50;0;[];['    pytorch_u8rmax_ukernel__neon(size_t n,const uint8_t *x)'];
proto_convert.h;C++;pytorch-master/pytorch-master/caffe2/utils; 11;  2; 3;6;  2; 0;0;2;0;1;1.00;0;[];['    pytorch_u8clamp_ukernel__neon(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)'];
proto_utils.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 648;  21; 62;105;  402; 68;236;149;550;203;0.05;86;[];[];
proto_utils_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 63;  5; 8;3;  48; 0;32;16;24;15;0.10;5;[];[];
proto_wrap.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 46;  12; 12;4;  21; 0;5;11;5;8;0.57;5;[];[];
proto_wrap.h;C++;pytorch-master/pytorch-master/caffe2/utils; 14;  4; 5;4;  3; 0;0;3;0;2;1.33;0;[];['    THFloatVector_fill_NEON(float *x,const float c,const ptrdiff_t n)', '    THFloatVector_muls_NEON(float *y,const float *x,const float c,const ptrdiff_t n)'];
signal_handler.h;C++;pytorch-master/pytorch-master/caffe2/utils; 45;  3; 9;10;  20; 8;0;0;0;0;0.15;0;['    C10FlagParser_caffe2_override_executor'];['    AddGlobalNetObserverCreator(NetObserverCreator creator)', '    ApplyPotentialExecutorOverride(std::string *net_type)', '    ClearGlobalNetObservers', '    CreateNet(const std::shared_ptr & net_def,Workspace *ws)', '    CreateNet(const NetDef & net_def,Workspace *ws)', '    defaultOverrides', '    GetNetObserverCreators', '    RegistryName', '    NetBase(const std::shared_ptr & def,Workspace *)', '    RunAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)', '    TEST_Benchmark_One_Run', '    C10FlagParser_caffe2_override_executor(const std::string & content)', '    GetNumWorkers', '    GetOperators', '    GetPool(const DeviceOption &)'];
simple_queue.h;C++;pytorch-master/pytorch-master/caffe2/utils; 79;  26; 11;7;  40; 0;0;0;0;0;0.65;0;[];[];
simple_queue_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 72;  2; 15;3;  54; 0;34;13;40;12;0.04;6;['    C10FlagParser_caffe2_net_async_check_stream_status', '    C10FlagParser_caffe2_net_async_inference_mode', '    C10FlagParser_caffe2_net_async_max_gpus', '    C10FlagParser_caffe2_net_async_max_numa_nodes', '    C10FlagParser_caffe2_net_async_profile_operators', '    C10FlagParser_caffe2_net_async_run_root_tasks_inline', '    C10FlagParser_caffe2_net_async_thread_pool_size', '    C10FlagParser_caffe2_net_async_use_per_net_pools', '    C10FlagParser_caffe2_net_async_use_single_pool', '    C10FlagParser_caffe2_streams_per_gpu'];['    getStreamCounters', '    GetOperatorStats', '    GetPerOperatorCost', '    GetProfReport', '    ~AsyncNetBase', '    C10FlagParser_caffe2_net_async_check_stream_status(const std::string & content)', '    C10FlagParser_caffe2_net_async_inference_mode(const std::string & content)', '    C10FlagParser_caffe2_net_async_max_gpus(const std::string & content)', '    C10FlagParser_caffe2_net_async_max_numa_nodes(const std::string & content)', '    C10FlagParser_caffe2_net_async_profile_operators(const std::string & content)', '    C10FlagParser_caffe2_net_async_run_root_tasks_inline(const std::string & content)', '    C10FlagParser_caffe2_net_async_thread_pool_size(const std::string & content)', '    C10FlagParser_caffe2_net_async_use_per_net_pools(const std::string & content)', '    C10FlagParser_caffe2_net_async_use_single_pool(const std::string & content)', '    C10FlagParser_caffe2_streams_per_gpu(const std::string & content)', '    AsyncNetBase(const std::shared_ptr & net_def,Workspace *ws)', '    asyncWait(int task_id,int stream_id,const std::vector & wait_task_ids)', '    canSchedule(int task_id,const std::vector *status,bool *parent_failed)', '    canSchedule(int parent_id,int child_id)', '    children(int task_id)', '    event(int task_id)', '    finalizeEvents', '    finishTasks(const std::unordered_set & task_ids)', '    firstTaskOp(int task_id)', '    firstTaskOp(int task_id)', '    firstTaskOpId(int task_id)', '    getParentCount(int child_id)', '    handleChainError(int task_id,OperatorBase *op,const char *err_str,bool save_exception)', '    handleRunError', '    isStreamFree(int task_id,int stream_id)', '    lastTaskOp(int task_id)', '    lastTaskOp(int task_id)', '    lastTaskOpId(int task_id)', '    numOps(int task_id)', '    parents(int task_id)', '    pool(const DeviceOption & device_option)', '    pool', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    query(int task_id)', '    reset', '    run(int task_id,int stream_id)', '    RunAsync', '    stream(int task_id)', '    tasksNum', '    testAndSetScheduled(int task_id)', '    updateParentCount(int child_id)', '    ExecutionOptions(const std::shared_ptr & net_def)'];
smart_tensor_printer.h;C++;pytorch-master/pytorch-master/caffe2/utils; 50;  11; 12;2;  25; 0;3;18;2;12;0.44;2;['    AsyncNetBase', '    AsyncNetExecutorHelper'];['    GetAsyncNetThreadPool(int device_id,int pool_size,bool create_new)', '    getStreamCounters', '    AsyncNetBase(const std::shared_ptr & net_def,Workspace *ws)', '    AsyncNetBase', '    asyncWait(int task_id,int stream_id,const std::vector & wait_task_ids)', '    canSchedule(int task_id,const std::vector *status,bool *parent_failed)', '    canSchedule(int parent_id,int child_id)', '    children(int task_id)', '    event(int task_id)', '    finalizeEvents', '    finishTasks(const std::unordered_set & task_ids)', '    firstTaskOp(int task_id)', '    firstTaskOp(int task_id)', '    firstTaskOpId(int task_id)', '    GetOperators', '    GetOperatorStats', '    getParentCount(int child_id)', '    GetPerOperatorCost', '    GetProfReport', '    handleChainError(int task_id,OperatorBase *op,const char *err_str,bool save_exception)', '    handleRunError', '    isStreamFree(int task_id,int stream_id)', '    lastTaskOp(int task_id)', '    lastTaskOp(int task_id)', '    lastTaskOpId(int task_id)', '    numOps(int task_id)', '    operator=', '    parents(int task_id)', '    pool(const DeviceOption & device_option)', '    pool', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    query(int task_id)', '    reset', '    run(int task_id,int stream_id)', '    RunAsync', '    stream(int task_id)', '    SupportsAsync', '    tasksNum', '    TEST_execution_chains', '    testAndSetScheduled(int task_id)', '    updateParentCount(int child_id)', '    ~AsyncNetBase', '    AsyncNetExecutorHelper(AsyncNetBase *net)', '    GetPool(const DeviceOption & option)', '    ExecutionOptions(const std::shared_ptr & net_def)', '    hardware_concurrency'];
smart_tensor_printer_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 53;  3; 11;7;  26; 10;11;15;7;9;0.12;4;[];['    schedule_func', '    AsyncSchedulingNet(const std::shared_ptr & net_def,Workspace *ws)', '    Cancel', '    CancelAndFinishAsyncTasks', '    finishRun', '    isInlineTask(int parent_id,int child_id)', '    parentCallback(int parent_id)', '    pollAndSchedule(int task_id)', '    reset', '    RunAsync', '    schedule(int task_id,bool run_inline)', '    Wait', '    ~AsyncSchedulingNet'];
string_utils.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 119;  1; 21;7;  91; 0;60;31;40;21;0.01;4;['    AsyncSchedulingNet'];['    AsyncSchedulingNet(const std::shared_ptr & net_def,Workspace *ws)', '    AsyncSchedulingNet', '    Cancel', '    CancelAndFinishAsyncTasks', '    finishRun', '    isInlineTask(int parent_id,int child_id)', '    operator=', '    parentCallback(int parent_id)', '    pollAndSchedule(int task_id)', '    reset', '    RunAsync', '    schedule(int task_id,bool run_inline)', '    Wait', '    ~AsyncSchedulingNet'];
pthreadpool.cc;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 376;  51; 22;14;  324; 3;165;223;59;130;0.16;12;[];['    GetDeviceOption', '    GetFuture', '    GetFuture', '    Reset', '    AsyncTask(const std::vector & ops)', '    handleChainError(OperatorBase *op,const char *err_str,bool save_exception)', '    Run(const ExecutionOptions & options)'];
pthreadpool.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 309;  68; 34;11;  200; 0;0;200;0;37;0.34;0;['    AsyncTask'];['    AsyncTask(const std::vector & ops)', '    GetDeviceOption', '    GetFuture', '    GetFuture', '    handleChainError(OperatorBase *op,const char *err_str,bool save_exception)', '    Reset', '    Run(const ExecutionOptions & options)'];
pthreadpool_impl.cc;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 59;  14; 7;2;  36; 0;20;11;14;6;0.39;4;[];['    AsyncTaskFuture', '    AsyncTaskFuture(const std::vector & futures)', '    ErrorMessage', '    IsCompleted', '    IsFailed', '    ResetState', '    SetCallback(std::function callback)', '    SetCompleted(const char *err_msg)', '    Wait', '    ~AsyncTaskFuture'];
pthreadpool_utils_new_if.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 62;  0; 6;22;  11; 24;2;6;1;5;0.00;3;['    AsyncTaskFuture'];['    AsyncTaskFuture', '    AsyncTaskFuture(const std::vector & futures)', '    AsyncTaskFuture', '    ErrorMessage', '    IsCompleted', '    IsFailed', '    operator=', '    ParentCounter(int init_parent_count)', '    Reset', '    ResetState', '    SetCallback(std::function callback)', '    SetCompleted(const char *err_msg)', '    Wait', '    ~AsyncTaskFuture'];
ThreadPool.cc;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 176;  18; 22;9;  112; 16;68;42;78;60;0.16;15;[];['    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    AsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    CreateNode(int node_id,const std::vector & ops)'];
ThreadPool.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 66;  20; 13;10;  26; 0;0;0;0;0;0.77;0;['    AsyncTaskGraph', '    AsyncTaskGraphBase'];['    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    AsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    CreateNode(int node_id,const std::vector & ops)', '    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    AddDependency(int child_node_id,const std::vector & parent_node_ids)', '    CreateNode(int node_id,const std::vector & ops)', '    ExecuteGraph', '    FreezeGraph', '    GetFuture', '    Reset', '    ~AsyncTaskGraphBase'];
ThreadPoolMobile.cc;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 21;  1; 4;6;  8; 3;2;4;2;3;0.13;2;['    C10FlagParser_caffe2_net_async_names_to_trace', '    C10FlagParser_caffe2_net_async_tracing_dumping_nth', '    C10FlagParser_caffe2_net_async_tracing_filepath', '    C10FlagParser_caffe2_net_async_tracing_nth'];['    create(const NetBase *net,const std::string & net_name)', '    extractShardId(const std::string & name)', '    getCounterForNetName(const std::string & net_name)', '    getTracingConfigFromNet(const NetBase *net)', '    getUniqueShardId(const OperatorDef & op_def)', '    hasEnableTracingFlag(const NetBase *net)', '    isTraceableNetName(const std::string & net_name)', '    startIter(const std::shared_ptr & tracer)', '    names', '    getCurrentTracerGuard', '    C10FlagParser_caffe2_net_async_names_to_trace(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_dumping_nth(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_filepath(const std::string & content)', '    C10FlagParser_caffe2_net_async_tracing_nth(const std::string & content)', '    bumpDumpingIter', '    bumpIter', '    dumpTracingResultAndClearEvents(const std::string & file_suffix)', '    getIter', '    isEnabled', '    linearizeEvents', '    opBlobsInfo(const OperatorBase & op)', '    opTraceName(const OperatorBase *op)', '    recordEvent(const TracerEvent & event)', '    renameThreads', '    serializeEvent(const TracerEvent & event)', '    setEnabled(bool enabled)', '    Tracer(const NetBase *net,const std::string & net_name,TracingConfig config)', '    ~Tracer', '    addArgument', '    addArgument(TracingField field,const char *value)', '    addArgument(TracingField field,int value)', '    disable', '    init(Tracer *tracer)', '    recordEventStart', '    ~TracerGuard'];
ThreadPoolMobile.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 24;  11; 6;2;  6; 0;0;6;0;6;1.83;0;['    Tracer', '    TracerGuard', '    TracingMode'];['    create(const NetBase *net,const std::string & net_name)', '    extractShardId(const std::string & name)', '    isTraceableNetName(const std::string & net_name)', '    startIter(const std::shared_ptr & tracer)', '    getCurrentTracerGuard', '    bumpDumpingIter', '    bumpIter', '    config', '    dumpTracingResultAndClearEvents(const std::string & file_suffix)', '    getIter', '    isEnabled', '    linearizeEvents', '    opBlobsInfo(const OperatorBase & op)', '    opTraceName(const OperatorBase *op)', '    recordEvent(const TracerEvent & event)', '    renameThreads', '    serializeEvent(const TracerEvent & event)', '    setEnabled(bool enabled)', '    Tracer(const NetBase *net,const std::string & net_name,TracingConfig config)', '    ~Tracer', '    addArgument', '    addArgument(TracingField field,const char *value)', '    addArgument(TracingField field,int value)', '    addArgument(TracingField field,const T & value,const Args &,...)', '    disable', '    init(Tracer *tracer)', '    recordEventStart', '    TracerGuard', '    ~TracerGuard', '    filepath', '    mode'];
ThreadPoolXNNPACK.cc;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 22;  4; 3;7;  7; 2;1;5;1;3;0.57;1;[];['    TEST(NetAsyncTracingTest,ExtractShardId)', '    TEST(NetAsyncTracingTest,EveryKIteration)', '    TEST(NetAsyncTracingTest,GlobalTimeSlice)', '    testExtractShardId(const string & name,int expectedId)'];
WorkersPool.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 372;  85; 42;35;  211; 9;107;69;155;69;0.40;21;[];['    computeChains(std::vector & orig_nodes)', '    computeGroups(std::vector & orig_nodes)', '    prepareOperatorNodes(const std::shared_ptr & net_def,Workspace *ws)', '    prune(int node_idx,std::vector & nodes)', '    pruneOpNodeGraph(const std::vector & nodes)', '    singleChains(std::vector & nodes)', '    updateOperatorNodes(std::vector & nodes,const ExecutionChains & chains)', '    check_current_for_chaining', '    commit_chain', '    depth_traverse', '    prepareChainGraphNodes(const std::vector & operator_nodes,const std::vector)'];
zmq_helper.h;C++;pytorch-master/pytorch-master/caffe2/utils; 137;  2; 26;5;  106; 0;57;53;74;63;0.02;18;[];['    computeChains(std::vector & orig_nodes)', '    computeGroups(std::vector & orig_nodes)', '    prepareChainGraphNodes(const std::vector & operator_nodes,const std::vector)', '    prepareOperatorNodes(const std::shared_ptr & net_def,Workspace *ws)', '    singleChains(std::vector & nodes)'];
optical_flow.cc;C++;pytorch-master/pytorch-master/caffe2/video; 85;  6; 9;4;  66; 1;44;24;38;17;0.09;3;['    DagUtilTestContext', '    final', '    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUDagUtilTestDummyAsync', '    CAFFE_ANONYMOUS_VARIABLE_CPUDagUtilTestDummySync', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DagUtilTestDummyAsync', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DagUtilTestDummySync', '    PrintChains(const dag_utils::ExecutionChains & chains)', '    TEST(DagUtilTest,Empty)', '    TEST(DagUtilTest,AllSync)', '    TEST(DagUtilTest,AllAsync)', '    TEST(DagUtilTest,Mixed0)', '    TEST(DagUtilTest,Mixed1)', '    TEST(DagUtilTest,Mixed2)', '    computeChains', '    DagUtilTestContext(const std::string & spec,Workspace *ws)', '    net_def_', '    DummyAsyncOp(const OperatorDef & operator_def,Workspace *ws)', '    DummySyncOp(const OperatorDef & operator_def,Workspace *ws)', '    HasAsyncPart', '    RunOnDevice', '    RunOnDevice'];
video_decoder.cc;C++;pytorch-master/pytorch-master/caffe2/video; 802;  97; 74;6;  628; 0;487;169;317;103;0.15;9;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy2', '    checkChainingAndRun(const char *spec,const dag_utils::ExecutionChains & expected)', '    TEST(NetTest,DISABLED_ChainingForDifferentDevices)', '    testExecution(std::unique_ptr & net,int num_ops)', '    HasAsyncPart', '    NetTestDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    SupportsAsyncScheduling'];
video_decoder.h;C++;pytorch-master/pytorch-master/caffe2/video; 525;  101; 74;17;  347; 0;140;190;87;116;0.29;35;['    NetObserverReporter'];['    report(NetBase *net,std::map &)', '    ~NetObserverReporter'];
video_input_op.cc;C++;pytorch-master/pytorch-master/caffe2/video; 93;  5; 9;1;  80; 0;77;80;1;10;0.06;2;[];['    get_op_args(PerformanceInformation p)', '    get_tensor_shapes(PerformanceInformation p)', '    sanatize(std::string json_s)', '    report(NetBase *net,std::map & info)', '  Static Member Variables', '    IDENTIFIER'];
video_input_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/video; 9;  1; 3;3;  3; 0;1;3;1;5;0.33;1;['    NetObserverReporterPrint'];['    report(NetBase *net,std::map &)'];
video_io.cc;C++;pytorch-master/pytorch-master/caffe2/video; 210;  14; 24;5;  168; 0;105;65;81;33;0.08;2;['    C10FlagParser_caffe2_task_graph_engine'];['    GetAsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    RegistryName', '    C10FlagParser_caffe2_task_graph_engine(const std::string & content)', '    finishRun', '    GetOperators', '    handleRunError', '    ParallelNet(const std::shared_ptr & net_def,Workspace *ws)', '    Pool(const DeviceOption & device_option)', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    reset', '    RunAsync', '    SupportsAsync', '    Wait'];
video_io.h;C++;pytorch-master/pytorch-master/caffe2/video; 51;  2; 7;10;  34; 0;0;34;0;3;0.06;0;['    ParallelNet', '    ParallelNetExecutorHelper'];['    GetAsyncTaskGraph(ExecutorHelper *helper,const ExecutionOptions & options)', '    RegistryName', '    finishRun', '    GetOperators', '    handleRunError', '    operator=', '    ParallelNet(const std::shared_ptr & net_def,Workspace *ws)', '    ParallelNet', '    Pool(const DeviceOption & device_option)', '    poolGetter(PoolsMap & pools,int device_type,int device_id,int pool_size)', '    reset', '    RunAsync', '    SupportsAsync', '    Wait', '    GetNumWorkers', '    GetOperators', '    GetPool(const DeviceOption & option)', '    ParallelNetExecutorHelper(ParallelNet *net)'];
AppDelegate.h;C++;pytorch-master/pytorch-master/ios/TestApp/TestApp; 7;  0; 3;1;  3; 0;0;2;0;2;0.00;0;['    C10FlagParser_caffe2_simple_net_benchmark_run_whole_net'];['    PairLargerThan(const std::pair & x,const std::pair & y)', '    C10FlagParser_caffe2_simple_net_benchmark_run_whole_net(const std::string & content)', '    SimpleNet(const std::shared_ptr & net_def,Workspace *ws)', '    Run', '    RunAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)'];
Benchmark.h;C++;pytorch-master/pytorch-master/ios/TestApp/TestApp; 12;  0; 5;1;  6; 0;0;4;0;5;0.00;0;['    SimpleNet'];['    GetOperators', '    operator=', '    Run', '    RunAsync', '    SimpleNet(const std::shared_ptr & net_def,Workspace *ws)', '    SimpleNet', '    SupportsAsync', '    TEST_Benchmark(const int warmup_runs,const int main_runs,const bool run_individual)'];
ViewController.h;C++;pytorch-master/pytorch-master/ios/TestApp/TestApp; 5;  0; 2;1;  2; 0;0;0;0;1;0.00;0;[];['    Run', '    SimpleRefCountNet(const std::shared_ptr & net_def,Workspace *ws)'];
group_spatial_softmax_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 76;  19; 11;7;  41; 0;4;25;44;62;0.46;4;['    final'];['    operator=', '    Run', '    SimpleRefCountNet(const std::shared_ptr & net_def,Workspace *ws)', '    SimpleRefCountNet'];
ps_roi_pool_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 106;  16; 9;1;  81; 0;71;77;4;21;0.20;6;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUNetSimpleRefCountTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetSimpleRefCountTest', '    TEST(NetSimpleRefCountTest,TestCorrectness)', '    NetSimpleRefCountTestOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
ps_roi_pool_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 93;  19; 11;7;  58; 0;10;36;44;69;0.33;4;['    MutatingNetSupplier', '    NetSupplier', '    SingleLoadedNetSupplier', '    SingleNetSupplier'];['    MutatingNetSupplier(std::unique_ptr,std::function m)', '    next', '    ~NetSupplier', '    RunnableNet(const caffe2::NetDef & netdef_,const Filler *filler_,const std::string & info_)', '    get_loaded_workspace', '    SingleLoadedNetSupplier(std::unique_ptr filler,caffe2::NetDef netdef,std::shared_ptr ws)', '    next', '    SingleNetSupplier(unique_ptr filler,caffe2::NetDef netdef)'];
roi_pool_f_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 81;  19; 11;7;  46; 0;8;26;42;59;0.41;4;['    final', '    final', '    final', '    final', '    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUExecutorHelperDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CPUNetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CPUNotFinishingOp', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDANetTestDummy2', '    CAFFE_ANONYMOUS_VARIABLE_CPUAsyncErrorOp', '    CAFFE_ANONYMOUS_VARIABLE_CPUSyncErrorOp', '    AsyncErrorNet(Workspace *ws,const std::string & net_name,bool throw_,bool fail_in_sync)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ExecutorHelperDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NetTestDummy2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NotFinishingOp', '    checkChainingAndRun(const char *spec,const dag_utils::ExecutionChains & expected)', '    checkNumChainsAndRun(const char *spec,const int expected_num_chains)', '    CreateNetTestHelper(Workspace *ws,const vector & input,const vector & output)', '    TEST(NetTest,ConstructionNoDeclaredInputOutput)', '    TEST(NetTest,ConstructionDeclaredInput)', '    TEST(NetTest,ConstructionDeclaredOutput)', '    TEST(NetTest,DeclaredInputInsufficient)', '    TEST(NetDeathTest,DeclaredOutputNotMet)', '    TEST(NetTest,DISABLED_ChainingForLinearModel)', '    TEST(NetTest,DISABLED_ChainingForFork)', '    TEST(NetTest,DISABLED_ChainingForForkJoin)', '    TEST(NetTest,DISABLED_ChainingForwardBackward)', '    TEST(NetTest,DISABLED_ChainingForHogwildModel)', '    TEST(NetTest,DISABLED_FailingOperator)', '    TEST(NetTest,OperatorWithExecutorHelper)', '    TEST(NetTest,DISABLED_OperatorWithDisabledEvent)', '    TEST(NetTest,ExecutorOverride)', '    TEST(NetTest,AsyncEmptyNet)', '    TEST(NetTest,DISABLED_RunAsyncFailure)', '    TEST(NetTest,NoTypeNet)', '    TEST(NetTest,PendingOpsAndNetFailure)', '    testExecution(std::unique_ptr & net,int num_ops)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AsyncErrorOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SyncErrorOp', '    ChainErrorNet(Workspace *ws,const std::string & net_name,bool throw_)', '    TEST(NetTest,AsyncErrorOpTest)', '    TEST(NetTest,AsyncErrorTimingsTest)', '    TEST(NetTest,ChainErrorTest)', '    TEST(NetTest,ProfDAGNetErrorTest)', '    testProfDAGNetErrorCase(bool test_error)', '    AsyncErrorOp(const OperatorDef & operator_def,Workspace *ws)', '    CancelAsyncCallback', '    ExecutorHelperDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    HasAsyncPart', '    HasAsyncPart', '    HasAsyncPart', '    NetTestDummyOp(const OperatorDef & operator_def,Workspace *ws)', '    NotFinishingOp(const OperatorDef & operator_def,Workspace *ws)', '    Run(int)', '    Run(int)', '    RunOnDevice', '    RunOnDevice', '    SupportsAsyncScheduling', '    ~AsyncErrorOp', '    RunOnDevice', '    SyncErrorOp(const OperatorDef & operator_def,Workspace *ws)', '    ~SyncErrorOp'];
sample_as_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 81;  16; 10;1;  55; 0;47;53;4;21;0.29;6;[];['    coalesceInsertedDataDependenciesHelper(repr::NNModule *m)', '    getTrackedNodes(repr::NNCFGraph & cf)', '    coalesceInsertedDataDependencies(repr::NNModule *m)', '    createOutput(NNModule *nn,NNGraph::NodeRef producer,std::string name)', '    getConsumers(NNGraph::NodeRef n)', '    getInputs(NNGraph::NodeRef n)', '    getInputs(const NNSubgraph & subgraph)', '    getName(NNGraph::NodeRef n)', '    getOutputs(NNGraph::NodeRef n)', '    getOutputs(const NNSubgraph & subgraph)', '    getProducer(NNGraph::NodeRef n)', '    hasConsumer(NNGraph::NodeRef n)', '    hasInputs(NNGraph::NodeRef n)', '    hasProducer(NNGraph::NodeRef n)', '    hasSingleOutputAndConsumer(NNGraph::NodeRef nodeRef)', '    hasUniqueConsumer(NNGraph::NodeRef nodeRef)', '    matchExternalTensorNode', '    replaceAllUsesWith(NNGraph::NodeRef oldTensorNode,NNGraph::NodeRef newTensorNode)', '    replaceAsConsumer(NNGraph::NodeRef oldConsumer,NNGraph::NodeRef newConsumer)', '    replaceProducer(NNGraph::NodeRef tensorNode,NNGraph::NodeRef newProducer)', '    getName', '    ~NeuralNetData', '    getName', '    ~NeuralNetOperator', '    createUniqueDataNode(const std::string & s)', '    deleteSubgraph(const NNSubgraph & subgraph)', '    replaceSubgraph(const NNSubgraph & subgraph,const NNGraph::NodeRef & node,const std::vector & node_inputs,const std::vector & node_outputs)'];
sample_as_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 55;  19; 9;7;  22; 0;2;12;36;53;0.86;4;['    Annotation', '    AnnotationKind', '    GenericOperator', '    NeuralNetData', '    NNDataKind', '    NeuralNetOperator', '    NNKind', '    NNLayout', '    NNPhi', '    Tensor', '    DataType', '    Layout', '    While'];['    impl(N n)', '    impl(N n)', '    impl(N n)', '    impl(N)', '    convertNode(NNGraph & g,NNGraph::NodeRef node)', '    createOperator(NNModule *nn,Args,...)', '    createOutput(NNModule *nn,NNGraph::NodeRef producer,std::string name)', '    filter(NNModule & nn)', '    get(N n)', '    getConsumers(NNGraph::NodeRef n)', '    getInputs(NNGraph::NodeRef n)', '    getInputs(const NNSubgraph & sg)', '    getName(NNGraph::NodeRef n)', '    getOutputs(NNGraph::NodeRef n)', '    getOutputs(const NNSubgraph & sg)', '    getProducer(NNGraph::NodeRef n)', '    hasConsumer(NNGraph::NodeRef n)', '    hasInputs(NNGraph::NodeRef n)', '    hasProducer(NNGraph::NodeRef n)', '    hasSingleOutputAndConsumer(NNGraph::NodeRef nodeRef)', '    hasUniqueConsumer(NNGraph::NodeRef nodeRef)', '    insertOp(NNGraph & g,NNGraph::NodeRef a,NNGraph::NodeRef b,Args,...)', '    matchExternalTensorNode', '    nodeIterator(G & g)', '    is(NNGraph::NodeRef n)', '    replaceAllUsesWith(NNGraph::NodeRef oldTensorNode,NNGraph::NodeRef newTensorNode)', '    replaceAsConsumer(NNGraph::NodeRef oldConsumer,NNGraph::NodeRef newConsumer)', '    replaceProducer(NNGraph::NodeRef tensorNode,NNGraph::NodeRef newProducer)', '    impl(N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    impl(N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetData *D)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    impl', '    impl', '    createEdge', '    createNode', '    deleteNode', '    replaceNode', '    Annotation(AnnotationKind kind)', '    Annotation', '    getKind', '    ~Annotation', '    GenericOperator', '    GenericOperator(std::string name)', '    getName', '    setName(std::string name)', '    ~GenericOperator', '    clone', '    getKind', '    getName', '    NeuralNetData(NNDataKind kind)', '    NeuralNetData', '    ~NeuralNetData', '    checkInputsAndOutputs(std::vector inputs,std::vector outputs)', '    getAnnotation', '    getKind', '    getLayout', '    getMutableAnnotation', '    getName', '    NeuralNetOperator(NNKind K,Opcode I,NNLayout L)', '    NeuralNetOperator(NNKind K,Opcode I)', '    NeuralNetOperator(NNKind K,NNLayout L)', '    NeuralNetOperator(NNKind K)', '    NeuralNetOperator', '    NeuralNetOperator', '    operator=', '    setAnnotation(std::unique_ptr extraAnnotation)', '    setLayout(NNLayout L)', '    ~NeuralNetOperator', '    createUniqueDataNode(const std::string & s)', '    deleteSubgraph(const NNGraph::SubgraphType & subgraph)', '    NNModule', '    NNModule', '    NNModule', '    replaceSubgraph(const NNGraph::SubgraphType & subgraph,const NNGraph::NodeRef & node,const std::vector & node_inputs,const std::vector & node_outputs)', '    replaceSubgraphWithOperator(const NNGraph::SubgraphType & sg,const std::vector & subgraph_inputs,const std::vector & subgraph_outputs,Args,...)', '    NNPhi', '    ~NNPhi', '    clone', '    getName', '    getType', '    setName(const std::string & name)', '    setType(DataType type)', '    Tensor(std::string name)', '    ~Tensor', '    While', '    ~While', '    make_unique'];
select_smooth_l1_loss_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 77;  27; 11;7;  42; 0;8;24;48;61;0.64;6;[];['    TEST(NeuralNetGraph,ReplaceGraph)'];
sigmoid_cross_entropy_loss_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 96;  16; 18;1;  62; 0;50;56;4;21;0.26;6;[];['    __BEGIN_DECLS', '    ANeuralNetworksCompilation_create(ANeuralNetworksModel *model,ANeuralNetworksCompilation **compilation)', '    ANeuralNetworksCompilation_finish(ANeuralNetworksCompilation *compilation)', '    ANeuralNetworksCompilation_free(ANeuralNetworksCompilation *compilation)', '    ANeuralNetworksCompilation_setPreference(ANeuralNetworksCompilation *compilation,int32_t preference)', '    ANeuralNetworksEvent_free(ANeuralNetworksEvent *event)', '    ANeuralNetworksEvent_wait(ANeuralNetworksEvent *event)', '    ANeuralNetworksExecution_create(ANeuralNetworksCompilation *compilation,ANeuralNetworksExecution **execution)', '    ANeuralNetworksExecution_free(ANeuralNetworksExecution *execution)', '    ANeuralNetworksExecution_setInput(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const void *buffer,size_t length)', '    ANeuralNetworksExecution_setInputFromMemory(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const ANeuralNetworksMemory *memory,size_t offset,size_t length)', '    ANeuralNetworksExecution_setOutput(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,void *buffer,size_t length)', '    ANeuralNetworksExecution_setOutputFromMemory(ANeuralNetworksExecution *execution,int32_t index,const ANeuralNetworksOperandType *type,const ANeuralNetworksMemory *memory,size_t offset,size_t length)', '    ANeuralNetworksExecution_startCompute(ANeuralNetworksExecution *execution,ANeuralNetworksEvent **event)', '    ANeuralNetworksMemory_createFromFd(size_t size,int protect,int fd,size_t offset,ANeuralNetworksMemory **memory)', '    ANeuralNetworksMemory_free(ANeuralNetworksMemory *memory)', '    ANeuralNetworksModel_addOperand(ANeuralNetworksModel *model,const ANeuralNetworksOperandType *type)', '    ANeuralNetworksModel_addOperation(ANeuralNetworksModel *model,ANeuralNetworksOperationType type,uint32_t inputCount,const uint32_t *inputs,uint32_t outputCount,const uint32_t *outputs)', '    ANeuralNetworksModel_create(ANeuralNetworksModel **model)', '    ANeuralNetworksModel_finish(ANeuralNetworksModel *model)', '    ANeuralNetworksModel_free(ANeuralNetworksModel *model)', '    ANeuralNetworksModel_identifyInputsAndOutputs(ANeuralNetworksModel *model,uint32_t inputCount,const uint32_t *inputs,uint32_t outputCount,const uint32_t *outputs)', '    ANeuralNetworksModel_setOperandValue(ANeuralNetworksModel *model,int32_t index,const void *buffer,size_t length)', '    ANeuralNetworksModel_setOperandValueFromMemory(ANeuralNetworksModel *model,int32_t index,const ANeuralNetworksMemory *memory,size_t offset,size_t length)'];
sigmoid_cross_entropy_loss_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 78;  19; 11;7;  43; 0;9;25;48;62;0.44;7;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUNGramFromCategorical', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NGramFromCategorical'];
sigmoid_focal_loss_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 83;  20; 11;7;  48; 0;8;32;42;65;0.42;8;['    NGramFromCategoricalOp'];['    GetRepeatedArgument', '    NGramFromCategoricalOp(Args,...)', '    RunOnDevice'];
smooth_l1_loss_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 117;  16; 25;1;  76; 0;66;72;4;21;0.21;6;[];[];
smooth_l1_loss_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 75;  25; 11;7;  40; 0;8;22;48;59;0.63;6;[];['    _compatibility_test', '    assert_is_equal_packed_sequence(const rnn_utils::PackedSequence & a,const rnn_utils::PackedSequence & b)', '    assert_is_same_packed_sequence(const rnn_utils::PackedSequence & a,const rnn_utils::PackedSequence & b)', '    batch_first', '    batch_first', '    batch_first', '    batch_first', '    compare_scaling', '    compute_norm', '    enforce_sorted', '    enforce_sorted', '    err_fn', '    generate_test_case', '    num_dim', '    num_dim', '    PackedSequenceTest_ordered_sequence(torch::ScalarType tensor_type)', '    PackedSequenceTest_padded_sequence(torch::ScalarType tensor_type)', '    pad', '    parameters', '    tensor_sizes', '    tensor_sizes', '    tensor_sizes', '    TEST_F(NNUtilsTest,ClipGradNorm)', '    TEST_F(NNUtilsTest,ClipGradValue)', '    TEST_F(NNUtilsTest,ConvertParameters)', '    TEST_F(PackedSequenceTest,WrongOrder)', '    TEST_F(PackedSequenceTest,TotalLength)', '    TEST_F(PackedSequenceTest,To)', '    TEST_F(NNUtilsTest,PackSequence)', '    TEST_F(NNUtilsTest,PackPaddedSequence)', '    TEST_F(NNUtilsTest,PadSequence)', '    total_length', '    total_length_delta', '    zero_parameters'];
softmax_focal_loss_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 91;  19; 11;7;  56; 0;6;38;50;69;0.34;4;[];['    reportError(int result_code)', '    addConv(const OperatorDef & op,bool fuse_relu)', '    addFloatOperand(float val)', '    addPooling(const OperatorDef & op,OperationCode op_code,bool fuse_relu)', '    addRelu(const OperatorDef & op)', '    addScalarOperand(int32_t val)', '    addSoftmax(const OperatorDef & op)', '    addTensorOperand(const std::string & blob,OperandCode type,std::vector & dims,float scale,int32_t zero_point)', '    getConvPoolArgs(const ArgumentHelper & helper,ConvPoolArgs & args)', '    init(const TensorVector & inputs,TensorVector *outputs)', '    loadNNApiLibrary', '    run(const TensorVector & inputs,TensorVector *outputs)', '    ~NNApi'];
spatial_narrow_as_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 79;  16; 8;1;  55; 0;45;51;4;21;0.29;6;['    NNApi'];['    addConv(const OperatorDef & op,bool fuse_relu)', '    addFloatOperand(float val)', '    addPooling(const OperatorDef & op,OperationCode op_code,bool fuse_relu)', '    addRelu(const OperatorDef & op)', '    addScalarOperand(int32_t val)', '    addSoftmax(const OperatorDef & op)', '    addTensorOperand(const std::string & blob,OperandCode type,std::vector & dims,float scale,int32_t zero_point)', '    compilation_', '    kernel_h', '    kernel_w', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    stride_x', '    stride_y', '    getConvPoolArgs(const ArgumentHelper & helper,ConvPoolArgs & args)', '    init(const TensorVector & inputs,TensorVector *outputs)', '    loadNNApiLibrary', '    model_', '    NNApi(const NetDef & init_net,const NetDef & run_net,Workspace *ws,const PreferenceCode pref)', '    operand_idx', '    operator_map_', '    run(const TensorVector & inputs,TensorVector *outputs)', '    run_', '    run_end_', '    ~NNApi', '    RunNetOnce'];
spatial_narrow_as_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 63;  19; 9;7;  30; 0;2;18;36;57;0.63;4;[];['    benchmark_conv_caffe2(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run,std::string engine)', '    benchmark_conv_nnapi(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run)', '    benchmark_conv_nnapi_int8(Workspace *ws,int N,int C,int H,int W,int K,int kernel,int group,int warmup,int run)', '    channel', '    input_channel', '    kernel', '    kernel', '    main(int argc,char **argv)', '    space', '    space'];
upsample_nearest_op.h;C++;pytorch-master/pytorch-master/modules/detectron; 110;  18; 16;14;  64; 5;29;33;54;72;0.28;4;[];['    test_conv_NHWC(int N,int C,int H,int W,int K,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_depthwise_conv_NHWC(int N,int C,int H,int W,int D,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_pooling(std::string type,int N,int C,int H,int W,int kernel,int pad_t,int pad_l,int pad_b,int pad_r,int stride_h,int stride_w)', '    test_relu(int N,int C,int H,int W)', '    test_softmax(int N,int C,int H,int W)', '    C', '    C', '    C', '    C', '    checkError(const TensorCPU & t1,const TensorCPU & t2,float error)', '    TEST(NNApi,TestConv)', '    TEST(NNApi,Depthwise)', '    TEST(NNApi,TestRelu)', '    TEST(NNApi,TestAveragePool)', '    TEST(NNApi,TestMaxPool)', '    TEST(NNApi,TestSoftmax)', '    K', '    K', '    K', '    K', '    M', '    P', '    P', '    P', '    P', '    S', '    S', '    S', '    S', '    W', '    W', '    W', '    W'];
module_test_dynamic.cc;C++;pytorch-master/pytorch-master/modules/module_test; 41;  19; 6;2;  16; 0;5;8;5;16;1.19;5;[];['    allocate_workspace', '    deallocate_workspace', '    init_nnpack', '    nnpack_threadpool', '    _nnpack_available', '    _nnpack_spatial_convolution(const at::Tensor & input,const at::Tensor & weight,const at::Tensor & bias,const IntArrayRef padding,const IntArrayRef stride)', '    _nnpack_spatial_convolution_backward(const at::Tensor & input,const at::Tensor & grad_output,const at::Tensor & weight,IntArrayRef padding,std::array output_mask)', '    _nnpack_spatial_convolution_backward_input(const at::Tensor & input,const at::Tensor & gradOutput,const at::Tensor & weight,IntArrayRef padding)', '    _nnpack_spatial_convolution_backward_weight(const at::Tensor & input,IntArrayRef weight_size,const at::Tensor & gradOutput,IntArrayRef padding)', '    compute', '    run', '    run', '    size_and_allocate_ws', '    size_and_allocate_ws', '    size_and_allocate_ws'];
macros.h;C++;pytorch-master/pytorch-master/modules/observers; 7;  0; 1;6;  0; 1;0;0;0;0;0.00;0;['    C10FlagParser_caffe2_nnpack_num_threads', '    C10FlagParser_caffe2_nnpack_use_mkl_num_threads', '    final', '    final', '    final', '    final'];['    get_nnp_convolution_algorithm(const std::string & algo)', '    get_nnp_convolution_transform_strategy(const std::string & kts)', '    has_nnpack', '    nnpack_threadpool', '    C10FlagParser_caffe2_nnpack_num_threads(const std::string & content)', '    C10FlagParser_caffe2_nnpack_use_mkl_num_threads(const std::string & content)', '    NNPACKConvOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKLeakyReluOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKMaxPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    NNPACKReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW'];
net_observer_reporter_print.cc;C++;pytorch-master/pytorch-master/modules/observers; 150;  5; 9;5;  131; 0;97;27;59;24;0.04;4;[];['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compare(int N,int inputC,int H,int W,int outputC,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,int group,const std::string & algorithm,const std::string & convolutionTransformStrategy,const std::string & activation,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    relativeError(float a,float b)', '    runConv(int kernelH,int kernelW,int strideH,int strideW,int group,std::string algo,int planesIn,int planesOut,int n,std::string convolutionTransformStrategy,std::string activation)', '    TEST(NNPACK,Conv_3x3s1)', '    TEST(NNPACK,Conv_3x3s1_precompute)', '    TEST(NNPACK,Conv_3x3s1_FP16)', '    TEST(NNPACK,Conv_3x3s1_FP16_precompute)', '    TEST(NNPACK,Conv_NxNs1)', '    TEST(NNPACK,Conv_1x1s1)', '    TEST(NNPACK,ConvRelu_1x1s1)', '    TEST(NNPACK,Conv_1x1s1_precompute)', '    TEST(NNPACK,Conv_NxNs_grouped)', '    TEST(NNPACK,Conv_NxNs_grouped_precompute)', '    TEST(NNPACK,Conv_NxNsW)', '    TEST(NNPACK,ConvRelu_NxNsW)', '    TEST(NNPACK,Conv_HxWsHxW)'];
net_observer_reporter_print.h;C++;pytorch-master/pytorch-master/modules/observers; 16;  1; 5;4;  7; 0;0;5;0;4;0.14;0;['    final'];['    NoDefaultEngineOp(Args,...)', '    RunOnDevice', '    ~NoDefaultEngineOp'];
observer_config.cc;C++;pytorch-master/pytorch-master/modules/observers; 12;  0; 2;1;  9; 0;7;9;0;8;0.00;0;[];['    dummy(int)'];
perf_observer.cc;C++;pytorch-master/pytorch-master/modules/observers; 319;  12; 40;39;  202; 38;106;77;71;90;0.06;21;[];['    attributesEqual(attribute_type a1,attribute_type a2)', '    attributesEqual(const at::Tensor & a1,const at::Tensor & a2)', '    attributesEqual(const std::vector & lhs,const std::vector & rhs)', '    attributesEqual(at::ArrayRef a1,at::ArrayRef a2)', '    attributesEqual(const IValue & a1,const IValue & a2)', '    attributesEqualCSE(const Node *lhs,const Node *rhs)', '    ivaluesEqual(const IValue & a1,const IValue & a2)', '    tensorEqual(const at::Tensor & lhs,const at::Tensor & rhs)', '    typeListEqual(const std::vector & lhs,const std::vector & rhs)', '    operator()(const Node *lhs,const Node *rhs)', '    operator()(const Node *k)'];
perf_observer.h;C++;pytorch-master/pytorch-master/modules/observers; 66;  7; 13;7;  40; 0;0;32;0;26;0.17;0;[];['    operator()(const Node *lhs,const Node *rhs)', '    operator()(const Node *k)'];
rocksdb.cc;C++;pytorch-master/pytorch-master/modules/rocksdb; 118;  18; 15;6;  81; 0;34;34;39;44;0.22;19;[];['    GetNorm(float begin,float end,float density,NormMinimization::Kind kind)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    NonlinearQuantizationParamsSearch(const Histogram & hist,bool preserve_sparsity,int precision)'];
autograd.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 676;  28; 118;5;  528; 0;313;228;209;255;0.05;71;[];['    L2MinimizationKernelAVX2(int precision,float *bins,int nbins,float bin_width,float dst_bin_width,int start_bin)'];
dataloader.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 2305;  174; 341;18;  1799; 0;1143;771;713;655;0.10;187;['    NormalizePlanarYUVOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUNormalizePlanarYUV', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizePlanarYUV', '    RunOnDevice'];
dispatch.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 52;  0; 6;10;  36; 0;24;22;14;24;0.00;9;[];['    forward(const torch::Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    GroupNormImpl(const GroupNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    forward(const Tensor & input)', '    LayerNormImpl(const LayerNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    reset_parameters', '    forward(const Tensor & input)', '    LocalResponseNormImpl(const LocalResponseNormOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset'];
expanding-array.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 59;  0; 10;6;  43; 0;18;17;32;13;0.00;6;[];['    mkldnn_batch_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool train,double momentum,double eps)'];
functional.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 2790;  71; 311;3;  2437; 0;1938;1434;707;905;0.03;156;[];['    conditional_accessor_1d(const Tensor & t)', '    repeat_if_defined(const Tensor & t,int64_t repeat)', '    _batch_norm_impl_index(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool training,double momentum,double eps,bool cudnn_enabled)', '    _batch_norm_impl_index_backward(int64_t impl_index,const Tensor & input,const Tensor & grad_output,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_var_transform,bool train,double epsilon,std::array output_mask,const Tensor & reservedSpace)', '    batch_norm_backward_cpu_template(const Tensor & grad_out_,const Tensor & input,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_invstd,bool train,double eps,std::array grad_input_mask)', '    batch_norm_cpu_inference_channels_last(Tensor & output,const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_inference_collect_linear_and_constant_terms(scalar_t *alpha,scalar_t *beta,int64_t n_channel,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & variance,double eps)', '    batch_norm_cpu_transform_input_template(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & save_mean,const Tensor & save_invstd,const Tensor & running_mean,const Tensor & running_var,bool train,double eps)', '    batch_norm_cpu_update_stats_template(const Tensor & input,const Tensor & running_mean,const Tensor & running_var,double momentum,double eps)', '    check_dims_match_num_input_features(const char *arg_name,int64_t expected,int64_t actual)', '    batch_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool training,double momentum,double eps,bool cudnn_enabled)', '    batch_norm_backward_cpu(const Tensor & grad_out,const Tensor & self,const Tensor & weight,const Tensor & running_mean,const Tensor & running_var,const Tensor & save_mean,const Tensor & save_invstd,bool train,double eps,std::array grad_input_mask)', '    batch_norm_cpu(const Tensor & self,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool train,double momentum,double eps)', '    batch_norm_update_stats_cpu(const Tensor & self,const Tensor & running_mean,const Tensor & running_var,double momentum)', '    group_norm(const Tensor & input,int64_t num_groups,const Tensor & weight,const Tensor & bias,double eps,bool cudnn_enabled)', '    instance_norm(const Tensor & input,const Tensor & weight,const Tensor & bias,const Tensor & running_mean,const Tensor & running_var,bool use_input_stats,double momentum,double eps,bool cudnn_enabled)', '    operator()(T var,double epsilon)', '    operator()(T var,double epsilon)'];
init.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 133;  2; 24;6;  102; 0;64;41;40;37;0.02;16;[];['    CrossMapLRN2dOptions(int64_t size)', '    GroupNormFuncOptions(int64_t num_groups)', '    GroupNormOptions(int64_t num_groups,int64_t num_channels)', '    LayerNormFuncOptions(std::vector normalized_shape)', '    LayerNormOptions(std::vector normalized_shape)'];
integration.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 317;  22; 48;6;  251; 0;179;126;86;145;0.09;15;[];[];
jit.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 127;  2; 51;5;  69; 0;51;29;31;24;0.03;6;[];[];
memory.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 36;  1; 7;3;  25; 0;13;12;9;12;0.04;5;[];[];
module.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 1018;  25; 131;3;  869; 0;465;316;422;358;0.03;98;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUNormalizeL1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizeL1', '    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)'];
modulelist.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 301;  11; 45;6;  239; 0;92;119;66;254;0.05;19;['    final'];['    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)', '    GetSingleArgument', '    NormalizeL1Op(Args,...)', '    RunOnDevice', '    ~NormalizeL1Op'];
modules.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 4731;  140; 557;8;  4133; 0;3212;1670;1385;1193;0.03;313;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUNormalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Normalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NormalizeGradient', '    vector', '    GetGradientDefs', '    DoNormalize(const T *xData,const T *gOutData,T *gInData,const int m,const int n,const int sf)'];
nn_utils.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 617;  40; 63;5;  525; 0;403;208;255;171;0.08;34;['    final', '    final'];['    DoNormalize(const T *xData,T *yData,const int m,const int n,const int sf)', '    DoNormalize(const T *xData,const T *gOutData,T *gInData,const int m,const int n,const int sf)', '    NormalizeGradientOp(Args,...)', '    NormalizeOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
optim.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 432;  13; 77;23;  320; 0;191;131;132;136;0.04;39;[];[];
optim_baseline.h;C++;pytorch-master/pytorch-master/test/cpp/api; 1145;  2; 20;2;  1122; 0;704;18;0;815;0.00;0;['    C10FlagParser_caffe2_cpu_numa_enabled'];['    GetCurrentNUMANode', '    GetNUMANode(const void *ptr)', '    GetNumNUMANodes', '    IsNUMAEnabled', '    NUMABind(int numa_node_id)', '    NUMAMove(void *ptr,size_t size,int numa_node_id)', '    C10FlagParser_caffe2_cpu_numa_enabled(const std::string & content)'];
parallel.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 293;  13; 52;15;  219; 0;133;109;84;119;0.06;21;[];[];
rnn.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 552;  48; 94;3;  417; 0;306;190;170;160;0.12;35;[];['    GetCurrentNUMANode', '    GetNUMANode(const void *ptr)', '    GetNumNUMANodes', '    IsNUMAEnabled', '    NUMABind(int numa_node_id)', '    NUMAMove(void *ptr,size_t size,int numa_node_id)'];
sequential.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 669;  13; 65;6;  585; 0;308;368;112;401;0.02;36;[];['    _isnan(T val)', '    _isnan(T val)', '    _isnan(at::BFloat16 val)', '    _isnan'];
static.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 101;  2; 15;6;  78; 0;0;0;0;0;0.03;0;[];[];
support.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUNumpyTile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NumpyTile'];
support.h;C++;pytorch-master/pytorch-master/test/cpp/api; 157;  22; 22;9;  106; 0;56;35;44;30;0.21;11;['    NumpyTileOp'];['    buffer', '    DoTile(const TypeMeta & meta,int item_size,int outer_dim,int inner_dim,int64_t num_tiles,const char *input_data,char *output_data)', '    NumpyTileOp(Args,...)', '    RunOnDevice', '    ~NumpyTileOp', '    itemsize', '    raw_data', '    Reshape', '    size_from_dim', '    size_to_dim'];
tensor_cuda.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 127;  1; 30;10;  86; 0;73;18;134;15;0.01;6;[];['    initNvtxBindings(PyObject *module)'];
tensor_indexing.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 844;  85; 126;3;  632; 0;441;241;381;231;0.13;61;[];['    _ivalue', '    define(const std::string & src,const ResolverPtr & resolver)', '    find_method(const std::string & basename)', '    Object(std::shared_ptr cu,const c10::ClassTypePtr & type)'];
tensor_options.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 157;  1; 37;16;  103; 0;69;26;111;27;0.01;9;[];[];
torch_include.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 14;  2; 3;2;  7; 0;5;1;5;1;0.29;1;[];['    free'];
main.cpp;C++;pytorch-master/pytorch-master/test/cpp/common; 32;  0; 5;4;  23; 0;17;2;14;2;0.00;2;['    THPPointer'];['    free', '    get', '    get', '    operator bool', '    operator THPPointer::T *', '    operator->', '    operator=(T *new_ptr)', '    operator=(THPPointer)', '    release', '    THPPointer', '    THPPointer(T *ptr)', '    THPPointer(THPPointer)', '    ~THPPointer'];
support.h;C++;pytorch-master/pytorch-master/test/cpp/common; 33;  2; 5;24;  4; 0;0;4;0;2;0.50;0;[];['    observerConfig'];
gtest.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 23;  2; 5;12;  6; 0;2;6;84;86;0.33;84;['    MobileDebugInfo', '    MobileModuleObserver', '    MobileObserverConfig'];['    observerConfig', '    getMethodName', '    getModelName', '    getOpIdx', '    setMethodName(const std::string & method_name)', '    setModelName(const std::string & model_name)', '    setOpIdx(size_t op_idx)', '    ~MobileDebugInfo', '    onEnter(const std::string & model_name,const std::string & method_name)', '    onExit', '    ~MobileModuleObserver', '    getModuleObserver', '    setModuleObserver(std::unique_ptr reporter)'];
test_alias_analysis.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 1336;  118; 256;7;  963; 0;571;489;494;1075;0.12;19;['    ObserverBase', '    Observable'];['    StartObserver(Observer *observer)', '    StopObserver(Observer *observer)', '    debugInfo', '    ObserverBase(T *subject)', '    Start', '    Stop', '    subject', '    ~ObserverBase', '    AttachObserver(std::unique_ptr observer)', '    DetachObserver(const Observer *observer_ptr)', '    NumObservers', '    Observable', '    Observable', '    Observable', '    operator=', '    operator=', '    StartAllObservers', '    StopAllObservers', '    UpdateCache', '    ~Observable'];
test_argument_spec.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 194;  13; 38;3;  148; 0;112;76;90;51;0.09;10;[];[];
test_base.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 27;  6; 4;3;  16; 0;9;14;1;4;0.38;1;['    ObserverConfig'];['    getMarker', '    getNetFollowupSampleCount', '    getNetFollowupSampleRate', '    getNetInitSampleRate', '    getOpoeratorNetSampleRatio', '    getReporter', '    getSkipIters', '    initSampleRate(int netInitSampleRate,int netFollowupSampleRate,int netFollowupSampleCount,int operatorNetSampleRatio,int skipIters)', '    setMarker(int marker)', '    setReporter(unique_ptr reporter)'];
test_base.h;C++;pytorch-master/pytorch-master/test/cpp/jit; 42;  3; 4;30;  6; 2;4;1;1;0;0.50;1;['    final', '    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUObsTestDummy', '    CAFFE_ANONYMOUS_VARIABLE_CUDAObsTestDummy', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ObsTestDummy', '    CreateNetTestHelper(Workspace *ws,bool isDAG)', '    TEST(ObserverTest,TestNotify)', '    TEST(ObserverTest,TestUniqueMap)', '    TEST(ObserverTest,TestNotifyAfterDetach)', '    TEST(ObserverTest,TestDAGNetBase)', '    DummyObserver(T *subject_)', '    ~DummyObserver', '    Start', '    Stop', '    Run(int)'];
test_class_import.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 157;  10; 45;6;  99; 0;71;50;41;36;0.10;5;[];['    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    IsSameMetaType(TypeIdentifier id)', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    _typeMetaDataInstance'];
test_class_type.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 58;  6; 9;3;  42; 0;34;10;50;8;0.14;2;['    OfflineTensorShapeFunctions'];['    create_legacy', '    setShapeAndType(const std::vector & sizes,at::Device device,caffe2::TypeMeta data_type)', '    shape_tensor', '    GetExternalTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetExternalTensorType(const void *c)', '    GetTypeMetaId', '    isQuantized', '    IsSameMetaType(TypeIdentifier id)', '    LoadInfoOfBlob(const Blob *,std::vector *,std::vector *,uint32_t *)', '    OfflineTensorShapeFunctions', '    SetupExternalTensorDescriptor(const Blob *blob,std::vector,std::vector,std::vector,ExternalTensorDescriptor *desc)', '    ~OfflineTensorShapeFunctions', '    dtype_initialized', '    storage_initialized', '    unsafeGetTensorImpl'];
test_code_template.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 64;  4; 28;3;  31; 0;19;13;18;12;0.13;1;['    SegmentOneHotOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchBucketOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUBatchOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUOneHot', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentOneHot', '    TensorInferenceForBatchOneHot(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchBucketOneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchOneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OneHot', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentOneHot', '    CostInferenceForBatchOneHot(const OperatorDef & def,const vector & in)', '    TensorInferenceForBucketBatchOneHot(const OperatorDef &,const vector & in)', '    RunOnDevice', '    DoRunWithType', '    DoOneHotOp(int64_t batch_size,int64_t index_size,const Tensor & indices,Tensor *one_hots)', '    RunOnDevice', '    SegmentOneHotOp(Args,...)'];
test_constant_pooling.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 85;  9; 30;8;  45; 0;33;8;10;6;0.20;1;['    final', '    final', '    final'];['    BatchBucketOneHotOp(Args,...)', '    BatchOneHotOp(Args,...)', '    DoOneHotOp(int64_t batch_size,int64_t index_size,const Tensor & indices,Tensor *output)', '    DoRunWithType', '    OneHotOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
test_custom_class.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 177;  15; 26;5;  137; 0;72;81;31;72;0.11;19;[];['    one_hot(const Tensor & self,int64_t num_classes)'];
test_custom_operators.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 195;  6; 42;7;  142; 0;94;40;108;76;0.04;3;[];['    ctx', '    envFn', '    BlockToONNX(Block *old_block,Block *new_block,::torch::onnx::OperatorExportTypes operator_export_type,std::unordered_map env)', '    checkONNXCompatibility(const c10::FunctionSchema & schema)', '    PreprocessCaffe2Ops(std::shared_ptr & graph)', '    preprocessCaffe2Ops(Block *block)', '    RemovePrintOps(std::shared_ptr & graph)', '    removePrintOps(Block *block)', '    ToONNX(std::shared_ptr & graph,::torch::onnx::OperatorExportTypes operator_export_type)'];
test_dce.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 52;  11; 26;4;  13; 0;7;9;3;5;0.85;1;['    OperatorExportTypes', '    TrainingMode'];[];
test_graph_executor.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 32;  2; 6;3;  23; 0;15;17;8;15;0.09;1;[];['    BlockToONNX(Block *old_block,Block *new_block,::torch::onnx::OperatorExportTypes operator_export_type,std::unordered_map env)', '    PreprocessCaffe2Ops(std::shared_ptr & graph)', '    RemovePrintOps(std::shared_ptr & graph)', '    ToONNX(std::shared_ptr & graph,::torch::onnx::OperatorExportTypes operator_export_type)'];
test_inliner.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 53;  4; 17;5;  30; 0;11;19;5;13;0.13;3;['    OnnxAnnotation'];['    classof(const Annotation *A)', '    getDevice', '    getMutableOperatorDef', '    getOperatorDef', '    OnnxAnnotation', '    OnnxAnnotation(std::string device)', '    setDevice(std::string device)', '    setOperatorDef(caffe2::OperatorDef *opDef)'];
test_interface.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 79;  4; 22;7;  50; 0;28;30;13;16;0.08;2;[];['    kRenamedAttrs', '    kRenamedOperators', '    AddShapeNode(const std::string & input,const std::string & output)', '    ApplyTrans(std::unordered_map *attrs,bool global,const std::string & k,int dim,const std::string & ks)', '    Caffe2TypeToOnnxType(caffe2::TensorProto::DataType t)', '    collectExternalsFromIfOpSubnet(const NetDef *net,std::vector *input,std::vector *output)', '    CreateOnnxShapeTensor(std::shared_ptr dummy,const std::vector & shape)', '    DimProd(const caffe2::TensorShape & shape,int start,int end)', '    getArgumentFromName(OperatorDef *op,const std::string & name)', '    rewriteSubnet(Argument *arg,std::map oldname_to_newname)', '    SsaName(const std::string & n,int version)', '    SsaRewrite(caffe2::NetDef *init_net,caffe2::NetDef *pred_net)', '    ssaRewriteForIfOp(OperatorDef *op,std::unordered_map *blob_versions,std::set *is_initialized_tensor)', '    get_renamed_attrs', '    get_renamed_operators', '    Caffe2OpToOnnxNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CommonCaffe2OpToOnnxNodes(const caffe2::OperatorDef & def)', '    CopyCaffe2ArgToOnnxAttr(AttributeProto *attr,const std::string & op_type,const caffe2::Argument & arg)', '    CreateArgMaxMinOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateBinaryElementwiseOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateCastNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateChannelShuffleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConcatNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConvPoolNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateElementwiseLinearNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateGemmNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateLrnNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateMergeDimNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReduceMeanNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReshapeNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateSliceNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateUpsampleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    get_special_operators', '    InitOpToTensorProto(const caffe2::OperatorDef & op,TensorProto *tensor)', '    IsBlackListed(const caffe2::Argument & arg)'];
test_ir.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 158;  10; 55;3;  92; 0;76;39;44;28;0.11;4;['    OnnxExporter'];['    Caffe2OpToOnnxNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CommonCaffe2OpToOnnxNodes(const caffe2::OperatorDef & def)', '    CopyCaffe2ArgToOnnxAttr(AttributeProto *attr,const std::string & op_type,const caffe2::Argument & arg)', '    CreateArgMaxMinOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateBinaryElementwiseOpNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateCastNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateChannelShuffleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConcatNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateConvPoolNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateElementwiseLinearNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateGemmNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateLrnNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateMergeDimNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReduceMeanNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateReshapeNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateSliceNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    CreateUpsampleNodes(const caffe2::OperatorDef & def,const std::unordered_map & shapes)', '    get_renamed_attrs', '    get_renamed_operators', '    get_special_operators', '    InitOpToTensorProto(const caffe2::OperatorDef & def,TensorProto *tensor)', '    IsBlackListed(const caffe2::Argument & arg)', '    OnnxExporter(DummyName *dummy)'];
test_irparser.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 248;  9; 85;7;  147; 0;80;27;116;27;0.06;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUONNXWhile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ONNXWhile'];
test_jit_type.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 49;  2; 8;5;  36; 0;28;22;18;19;0.06;1;['    final', '    LocalScope'];['    condition_true', '    valid_iter_num', '    get', '    DoRunWithType', '    GetSingleArgument', '    HasSingleArgumentOfType', '    iteration', '    lcd_tensor(int idx)', '    LocalScope(Workspace *loop_ws,const NetDef & body_net_def,size_t num_lcds)', '    net', '    output_condition', '    set_input_condition(bool cond_value)', '    set_iteration(int64_t itr)', '    workspace', '    ONNXWhileOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    itemsize', '    raw_data', '    vec', '    CreateBlob', '    CreateNet', '    GetBlob', '    GetNet'];
test_misc.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 1316;  100; 233;61;  934; 0;713;380;484;580;0.11;47;[];['    getOnnxBackendGraphMap', '    insert(const std::string & key,std::function creator)', '    lookup(const std::string & key)', '    remove(const std::string & key)'];
test_mobile_type_parser.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 59;  7; 13;1;  41; 0;18;37;42;32;0.17;1;['    OnnxBackendGraphMap'];['    getOnnxBackendGraphMap', '    BackendGraphInfo(onnxBackendID backend_id,onnxBackend backend,onnxGraph graph,onnxifi_library *lib,std::unordered_map,ShapeInfo)', '    BackendGraphInfo', '    BackendGraphInfo(BackendGraphInfo)', '    lib', '    operator=', '    operator=(BackendGraphInfo)', '    ~BackendGraphInfo', '    insert(const std::string & key,std::function creator)', '    lookup(const std::string & key)', '    OnnxBackendGraphMap', '    OnnxBackendGraphMap', '    OnnxBackendGraphMap', '    operator=', '    operator=', '    remove(const std::string & key)'];
test_module_api.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 101;  19; 11;3;  73; 0;55;35;51;38;0.26;4;[];['    core', '    initOnnxifiLibrary'];
test_qualified_name.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 68;  7; 4;3;  56; 0;39;24;57;23;0.13;1;[];['    initOnnxifiLibrary'];
test_save_load.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 99;  40; 6;7;  48; 0;22;14;24;14;0.83;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUOnnxifi', '    data_type_map', '    BlobToTensorDescriptor(const std::string & name,Workspace *ws,onnxTensorDescriptorV1 *desc,std::vector,std::vector,std::vector)', '    copyDescriptor(const ExternalTensorDescriptor *from,onnxTensorDescriptorV1 *to)', '    OnnxifiTypeToDataType(uint64_t onnxifi_type)', '    SetInputTensorDescriptorTypeAndBuffer(const Tensor & cpu_tensor,onnxTensorDescriptorV1 *desc)', '    SetInputTensorDescriptorTypeAndBuffer(const int8::Int8TensorCPU & cpu_int8tensor,onnxTensorDescriptorV1 *desc)', '    SetOutputTensorDescriptorTypeAndBuffer(uint64_t onnxifi_type,Tensor *cpu_tensor,onnxTensorDescriptorV1 *desc)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Onnxifi', '    buildInitializationList(Workspace *ws,const std::vector & initializers,std::vector *weight_names,std::vector,std::vector,std::vector)', '    maybeAdjustOutputBatchSizes', '    RunOnDevice'];
test_schema_matching.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 91;  2; 20;7;  64; 0;40;39;22;17;0.03;1;['    final'];['    backend', '    creator', '    graph', '    num_backends', '    adjust_output_batch_', '    backend_', '    backend_id_', '    buildBackendAndGraph(Workspace *ws,const std::vector & property_pointers,const std::string & onnx_model_str)', '    buildInitializationList(Workspace *ws,const std::vector & initializers,std::vector *weight_names,std::vector,std::vector,std::vector)', '    buildPropertyList(const OperatorDef &,std::vector *property_list,std::vector *,std::vector *)', '    enable_tracing_', '    extractOutputBatchSizes', '    getExtFunctionPointers', '    GetRepeatedArgument', '    GetSingleArgument', '    graph_', '    lib_', '    maybeAdjustOutputBatchSizes', '    nominal_batch_idx_', '    OnnxifiOp(const OperatorDef & operator_def,Workspace *ws)', '    skip', '    RunOnDevice', '    setEnableTracing(bool b)', '    SetOutputShapeAndType(int output_idx,std::vector *dims)', '    operator=', '    TensorInfo', '    TensorInfo', '    use_onnx_', '    ~OnnxifiOp', '    Blobs', '    size'];
test_subgraph_rewriter.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 97;  3; 34;5;  57; 0;42;33;15;18;0.05;3;[];['    addCast', '    buildLoopTestNet(const NetDef & net,const std::unordered_set & initialization_list,std::unordered_map *shape_hints,size_t batch_size)', '    collectInputsAndOutputs(const OperatorDef & op,std::set *inputs,std::set *outputs)', '    composeResultNet(const OperatorDef & onnxifi_op)', '    convertToValueInfo(const std::vector & names,const std::unordered_map & shape_hints,const std::unordered_map & extra_shape_hints)', '    fetchInputsToIfOpsSubnet(NetDef *net)', '    fillModelInfo(::ONNX_NAMESPACE::ModelProto *model)', '    getBlob1stDimSize(const ShapeInfo & shape_info)', '    getWeightsAndInputs(const NetDef & net,const std::unordered_set & weights_in_ws,const std::vector & extra_weights,std::unordered_set *initialization_list,std::vector *total_inputs_vec)', '    mergeFp32InputsAndConvertToFp16(size_t batch_size,const std::unordered_set & weights,NetDef *pred_net,ShapeInfoMap *shape_hints)', '    onnxifiDataType(caffe2::TensorProto::DataType t)', '    stripShapeInfoMap(const ShapeInfoMap & info_map)', '    MakeArgument', '    MakeArgument', '    MakeArgument', '    nominal_batch_idx', '    onnx_converter', '    applyFilteringRules(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    blacklistCpuPartition(const NetDef & net,std::unordered_set *blacklisted_ops)', '    buildOnnxifiOp(const std::string & onnx_model_str,const std::unordered_map & output_shape_hints,const std::unordered_set & initialization_list,const std::vector & external_inputs,const std::vector & external_outputs,const std::unordered_map & shape_hints)', '    extractPartitionInfo(const NetDef & net)', '    getBackendId', '    OnnxifiTransformer(const OnnxifiTransformerOptions & opts)', '    SubnetToOnnxifiOpViaC2(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,const ShapeInfoMap & shape_hints)', '    SubnetToOnnxifiOpViaOnnx(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,Workspace *ws,onnx::OnnxExporter *exporter,ShapeInfoMap *shape_hints)', '    supportOpC2(const caffe2::OperatorDef & op,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    supportOpOnnx(const caffe2::OperatorDef & op,onnx::OnnxExporter *exporter,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    tieGatherAndSparseLengthsWeightedSumOps(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & input_shape_hints,const std::unordered_set & blacklisted_ops)', '    TransformViaC2(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    TransformViaOnnx(Workspace *ws,NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,ShapeInfoMap *shape_hints)', '    ~OnnxifiTransformer'];
test_subgraph_utils.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 41;  4; 9;4;  26; 0;14;12;12;9;0.15;1;['    final'];['    adjust_batch', '    applyFilteringRules(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    blacklistCpuPartition(const NetDef & net,std::unordered_set *blacklisted_ops)', '    buildOnnxifiOp(const std::string & onnx_model_str,const std::unordered_map & output_size_hints,const std::unordered_set & initialization_list,const std::vector & external_inputs,const std::vector & external_outputs,const std::unordered_map & shape_hints)', '    extractPartitionInfo(const NetDef & net)', '    getBackendId', '    idx_', '    lib_', '    load_model_by_blob', '    loop_test', '    merge_fp32_inputs_into_fp16', '    num_backends_', '    onnxifi_op_id_', '    OnnxifiTransformer(const OnnxifiTransformerOptions & opts)', '    OnnxifiTransformerOptions', '    predictor_net_ssa_rewritten', '    SubnetToOnnxifiOpViaC2(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,const ShapeInfoMap & shape_hints)', '    SubnetToOnnxifiOpViaOnnx(const caffe2::NetDef & net,const std::unordered_set & weights_in_ws,Workspace *ws,onnx::OnnxExporter *exporter,ShapeInfoMap *shape_hints)', '    supportOpC2(const caffe2::OperatorDef & op,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    supportOpOnnx(const caffe2::OperatorDef & op,onnx::OnnxExporter *exporter,const std::unordered_set & blacklisted_ops,onnxBackendID backend_id)', '    tieGatherAndSparseLengthsWeightedSumOps(const NetDef & net,const ShapeInfoMap & shape_hints,std::unordered_set *blacklisted_ops)', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    TransformViaC2(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    TransformViaOnnx(Workspace *ws,NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,ShapeInfoMap *shape_hints)', '    use_onnx', '    ~OnnxifiTransformer'];
test_utils.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 141;  3; 39;3;  98; 0;56;51;38;36;0.03;14;[];['    custom_op(torch::Tensor tensor,double scalar,int64_t repeat)', '    custom_op2(std::string s1,std::string s2)', '    custom_op_with_autograd(torch::Tensor var1,int64_t mul,torch::Tensor var2)', '    backward(torch::autograd::AutogradContext *ctx,torch::autograd::variable_list grad_output)', '    forward(torch::autograd::AutogradContext *ctx,torch::Tensor var1,int64_t mul,torch::Tensor var2)'];
tests.h;C++;pytorch-master/pytorch-master/test/cpp/jit; 113;  9; 6;91;  9; 0;0;9;0;89;1.00;0;[];['    custom_op(torch::Tensor tensor,double scalar,int64_t repeat)', '    custom_op2(std::string s1,std::string s2)'];
torch_python_test.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 42;  6; 6;14;  17; 3;7;6;200;4;0.35;2;['    OpDependency', '    OutputFormatType'];['    callback', '    demangle(const std::string & mangled)', '    expand', '    expand', '    expandOperands', '    expandUsers', '    insert', '    extractOpSchema(Value *V)', '    extractStringValue(Value *V,const std::function & CB)', '    printAsDot(std::ostream & out,const SET & keys,const GRAPH & graph)', '    printAsPython(std::ostream & out,const SET & keys,const GRAPH & graph)', '    printAsYAML(std::ostream & out,const SET & keys,const GRAPH & graph,const PATH *path)', '    printDebugPath(const VALUE_MAP *debugPath,Value *src,Value *dest)', '    printDebugValue(Value *V)', '    scanAllFunctions(Module & M,GRAPH *deps,VALUE_SET *opRegistrationInsts,VALUE_SET *opInvocationInsts)', '    scanConnectedNodes(Value *src,const VALUE_SET & blocked,const std::function & CB,VALUE_MAP *debugPath)', '    scanOpInvocation(VALUE_SET & instructions,SET *opSchemaStrs,GRAPH *functionToSchemaStrs)', '    scanOpRegistration(VALUE_SET & instructions,SET *opSchemaStrs,GRAPH *schemaStrToFunctions)', '    scanOpSchemaStrAndFunction(Value *src,const VALUE_SET & blocked,SET *visitedOps,SET *visitedFunctions)', '    scanReferredFunctions(Instruction & I,const std::function & CB)', '    simplifyGraph(const GRAPH & input,SET & keyNodes,GRAPH *output,PATH *path)', '    OpDependency', '    runOnModule(Module & M)', '    operator=(const std::string & val)', '  Static Member Variables', '    ID'];
test_wire_serialization.cpp;C++;pytorch-master/pytorch-master/test/cpp/rpc; 78;  7; 9;6;  60; 0;49;45;10;27;0.12;4;[];['    def(FunctionSchema)', '    def(c10::either,CppFunction)', '    fallback(CppFunction)', '    impl(const char *name_str,CppFunction)', '    Module(std::string ns)', '    Module', '    schema', '    CppFunction(KernelFunction func,std::unique_ptr schema,std::string debug)', '    checkNoDuplicateKernels_(const Options & options)', '    checkSchemaAndRegisterOp_(Options)', '    inferSchemaFromKernels_(const OperatorName & opName,const RegisterOperators::Options & options)', '    registerOp_(Options)'];
gtest_assert_float_eq.h;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 118;  77; 11;2;  28; 0;16;14;8;14;2.75;3;[];[];
padded_buffer.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 35;  3; 5;3;  27; 0;11;14;11;8;0.11;2;[];['    autograd_kernel(Tensor a)', '    backend_fallback_kernel(const c10::OperatorHandle & op,c10::Stack *stack)', '    List', '    List', '    optional', '    optional', '    dummy_fn(const Tensor & x)', '    expectListEquals', '    expectListEquals', '    makeDeeplyNestedObject', '    nonautograd_kernel(Tensor a)', '    stackBasedKernel(const OperatorHandle &,c10::Stack *stack)', '    tuple', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithAliasAnalysisAfterRegisteringWithoutAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithoutAliasAnalysisAfterRegisteringWithAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithSameAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithNoAliasAnalysis_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringSameSchemaWithDifferentAliasAnalysis_thenShouldThrow)', '    TEST(OperatorRegistrationTest,whenRegisteringWithSchemaBeforeKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithSchemaAfterKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithNameBeforeKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithNameAfterKernelInOptionsObject_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringWithoutSchema_thenFails)', '    TEST(OperatorRegistrationTest,whenCallingOpWithWrongDispatchKey_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithCatchallKernel_whenCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithDispatchedKernelOutOfScope_whenRegisteringCatchallKernelAndCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithCatchallKernelOutOfScope_whenRegisteringDispatchedKernelAndCallingOp_thenCallsCatchallKernel)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringWithSchema_thenOnlyRegistersSchema)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringWithoutSchema_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRunningOutOfScope_thenSchemaIsGone)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwards_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwardsWithDifferentSchema_thenFails)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernels_whenRegisteringKernelAfterwardsAndRunsOutOfScope_thenSchemaIsStillThereButCannotBeCalledAnymore)', '    TEST(OperatorRegistrationTest,givenOpWithoutKernelsWithoutTensorInputs_whenRegistering_thenRegisters)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenRegistering_thenShowsWarning)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenRegisteringInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenRegistering_thenShowsWarning)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenRegisteringInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenNewerKernelDeletedAndOpCalled_thenCallsOlderKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenNewerKernelDeletedAndOpCalled_thenCallsOlderKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenOlderKernelDeletedAndOpCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenOlderKernelDeletedAndOpCalled_thenCallsNewerKernel)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenOlderAndThenNewerKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenOlderAndThenNewerKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleKernelsWithSameDispatchKey_whenNewerAndThenOlderKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,givenMultipleCatchallKernels_whenNewerAndThenOlderKernelDeletedAndOpCalled_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringCPUTensorType_thenCanOnlyCallUnboxedWithCPUTensorIdDispatchKey)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsInSameOpCallAndCalling_thenCallsCorrectKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsInSameOpCallOutOfScopeAndCalling_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsByNameAndNoneCanInferSchema_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsBySchemaAndNoneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsByNameAndOnlyOneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMultipleKernelsBySchemaAndOnlyOneCanInferSchema_thenSucceeds)', '    TEST(OperatorRegistrationTest,whenRegisteringMismatchingKernelsInSameOpCall_thenFails)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernel_thenCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelForWrongBackend_thenCannotBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForDifferentBackend_thenRegularKernelCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForDifferentBackend_thenFallbackKernelCanBeCalled)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndRegularKernelForSameBackend_thenCallsRegularKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringBackendFallbackKernelAndCatchallKernelForSameBackend_thenCallsFallbackKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithRegularKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithRegularKernel_thenCanCallRegularKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithCatchAllKernel_thenCanCallAutogradKernel)', '    TEST(OperatorRegistrationTest,whenRegisteringAutogradKernelWithCatchAllKernel_thenCanCallCatchallKernel)', '    TEST(OperatorRegistrationTest,xlaPreAutogradOverridesAutogradKernel)', '    TEST(OperatorRegistrationTest,testAvailableArgTypes)', '    TEST(NewOperatorRegistrationTest,testBasics)', '    TEST(NewOperatorRegistrationTest,importTopLevel)', '    TEST(NewOperatorRegistrationTest,overload)', '    TEST(NewOperatorRegistrationTest,importNamespace)', '    TEST(NewOperatorRegistrationTest,schema)', '    TEST(NewOperatorRegistrationTest,dispatch)', '    TEST(NewOperatorRegistrationTest,dispatchMultiple)', '    TEST(NewOperatorRegistrationTest,fallback)', '    TEST(NewOperatorRegistrationTest,CppFunction)', '    TEST(NewOperatorRegistrationTest,testDelayedListener)', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    testArgTypes', '    test(TestModernAndLegacyAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(TestModernAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(TestLegacyAPI,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test(InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    test_(std::function registration,InputType input,std::function inputExpectation,OutputType output,std::function outputExpectation,const std::string & schema)', '    ArgTypeTestKernel(InputType input,std::function inputExpectation,OutputType output)', '    MockKernel(bool *called)', '    operator()(Tensor)', '    operator()(Tensor)', '    operator()(Tensor,int64_t)', '    operator()(InputType input)', '    onOperatorDeregistered(const OperatorHandle & op)', '    onOperatorRegistered(const OperatorHandle & op)'];
padded_buffer.h;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 262;  14; 29;4;  219; 0;91;116;44;82;0.06;31;[];['    LogCuDNNPerfStats(const ArrayOfcudnnConvolutionAlgoPerf_t & perf_stat,int returned_algo_count)'];
test_base.h;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 69;  4; 7;38;  24; 2;6;16;9;8;0.17;2;['    OpWrapper'];['    DequantizeInput', '    Get', '    GetOutputQuantizationParams(dnnlowp::QuantizationFactory *qfactory,int index)', '    OpWrapper(OperatorBase *op,dnnlowp::QuantizationFactory *qfactory)', '    CreateBlob', '    GetBlob', '    Dequantize'];
test_cuda.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 333;  0; 0;13;  0; 331;0;0;0;0;0.00;0;[];['    copy_tensor_metadata(const OpaqueTensorImpl *src_opaque_impl,OpaqueTensorImpl *dest_opaque_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    has_storage', '    is_contiguous(c10::MemoryFormat memory_format)', '    OpaqueTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::Device device,OpaqueHandle opaque_handle,c10::IntArrayRef sizes)', '    release_resources', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    unsafe_opaque_handle'];
test_expr.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 508;  12; 62;15;  421; 0;253;326;97;307;0.03;26;['    Add', '    AveragePool', '    AveragePoolRelu', '    BatchNormalization', '    ChannelShuffle', '    Clip', '    Concat', '    Conv', '    ConvRelu', '    ConvTranspose', '    CopyFromOpenCL', '    CopyToOpenCL', '    Declare', '    Export', '    FC', '    Flatten', '    GivenTensorFill', '    MaxPool', '    MaxPoolRelu', '    NCHW2NHWC', '    NHWC2NCHW', '    Receive', '    Relu', '    Reshape', '    Send', '    Softmax', '    Sum', '    SumRelu'];['    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    classof(const NeuralNetOperator *N)', '    classof(const Value *N)', '    Add(int broadcast)', '    getBroadcast', '    setBroadcast(int broadcast)', '    ~Add', '    AveragePool(vector kernelShape,vector pads,vector strides)', '    getKernelShape', '    getPads', '    getStrides', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~AveragePool', '    AveragePoolRelu(vector kernelShape,vector pads,vector strides)', '    AveragePoolRelu(const AveragePool & averagePool)', '    getKernelShape', '    getPads', '    getStrides', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~AveragePoolRelu', '    BatchNormalization(float epsilon,float momentum,bool spatial,bool isTest)', '    getEpsilon', '    getIsTest', '    getMomentum', '    getSpatial', '    setEpsilon(float epsilon)', '    setIsTest(bool isTest)', '    setMomentum(float momentum)', '    setSpatial(bool spatial)', '    ~BatchNormalization', '    ChannelShuffle', '    ~ChannelShuffle', '    Clip(float min,float max)', '    getMax', '    getMin', '    setMax(float max)', '    setMin(float min)', '    ~Clip', '    Concat(int axis,bool addAxis)', '    getAddAxis', '    getAxis', '    setAddAxis(bool addAxis)', '    setAxis(int axis)', '    ~Concat', '    Conv(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~Conv', '    ConvRelu(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    ConvRelu(const Conv & conv)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~ConvRelu', '    ConvTranspose(vector kernelShape,vector pads,vector strides,int group,vector dilations)', '    getDilations', '    getGroup', '    getKernelShape', '    getPads', '    getStrides', '    setDilations(vector dilations)', '    setGroup(int group)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~ConvTranspose', '    CopyFromOpenCL', '    ~CopyFromOpenCL', '    CopyToOpenCL', '    ~CopyToOpenCL', '    Declare', '    ~Declare', '    Export', '    ~Export', '    FC(int axis,int axisW)', '    getAxis', '    getAxisW', '    setAxis(int axis)', '    setAxisW(int axisW)', '    ~FC', '    Flatten', '    ~Flatten', '    GivenTensorFill', '    ~GivenTensorFill', '    getKernelShape', '    getPads', '    getStrides', '    MaxPool(vector kernelShape,vector pads,vector strides)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~MaxPool', '    getKernelShape', '    getPads', '    getStrides', '    MaxPoolRelu(vector kernelShape,vector pads,vector strides)', '    MaxPoolRelu(const MaxPool & maxPool)', '    setKernelShape(vector kernelShape)', '    setPads(vector pads)', '    setStrides(vector strides)', '    ~MaxPoolRelu', '    NCHW2NHWC', '    ~NCHW2NHWC', '    NHWC2NCHW', '    ~NHWC2NCHW', '    getSource', '    Receive(string source)', '    setSource(string source)', '    ~Receive', '    Relu', '    ~Relu', '    Reshape', '    ~Reshape', '    getDestination', '    Send(string destination)', '    setDestination(string destination)', '    ~Send', '    Softmax', '    ~Softmax', '    Sum', '    ~Sum', '    SumRelu', '    SumRelu(const Sum & sum)', '    ~SumRelu'];
test_llvm.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 1183;  1; 0;143;  0; 1181;0;0;0;0;0.00;0;[];[];
test_loopnest.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 549;  6; 67;13;  466; 0;295;282;196;251;0.01;28;[];[];
test_simplify.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 1161;  93; 198;35;  837; 0;534;635;896;676;0.11;36;[];[];
test_utils.h;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 14;  2; 4;5;  5; 0;0;4;1;3;0.40;0;[];[];
tests.h;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 263;  5; 7;246;  5; 2;0;5;0;114;1.00;0;[];['    pytorch_qnnp_delete_operator(pytorch_qnnp_operator_t op)'];
cpp_frontend_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 54;  0; 11;3;  40; 0;18;13;11;13;0.00;10;[];['    compute_average_pooling_multipass(const struct average_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_average_pooling_unipass(const struct average_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_channel_shuffle_fixed(const struct channel_shuffle_context [1] context,size_t index)', '    compute_channel_shuffle_variable(const struct channel_shuffle_context [1] context,size_t index)', '    compute_clamp_contiguous(const struct clamp_contiguous_context [1] context,size_t offset,size_t size)', '    compute_clamp_strided(const struct clamp_strided_context [1] context,size_t batch_index)', '    compute_dwconv_multiipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_dwconv_unipass(const struct q8dwconv_context [1] context,size_t image,size_t output_y)', '    compute_global_average_pooling_multipass(const struct global_average_pooling_context [1] context,size_t batch_index)', '    compute_global_average_pooling_unipass(const struct global_average_pooling_context [1] context,size_t batch_index)', '    compute_lut_contiguous(const struct lut_contiguous_context [1] context,size_t offset,size_t size)', '    compute_lut_strided(const struct lut_strided_context [1] context,size_t batch_index)', '    compute_max_pooling(const struct max_pooling_context [1] context,size_t batch_index,size_t output_y)', '    compute_q8add_contiguous(const struct q8add_contiguous_context [1] context,size_t offset,size_t size)', '    compute_q8add_strided(const struct q8add_strided_context [1] context,size_t batch_offset,size_t batch_range)', '    compute_q8conv(const struct q8conv_context [1] context,size_t group_index,size_t image_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t image_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm(const struct q8gemm_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_q8gemm_xzp(const struct q8gemm_xzp_context [1] context,size_t group_index,size_t pixel_index,size_t mr_block_start,size_t nr_block_start,size_t group_range,size_t pixel_range,size_t mr_block_size,size_t nr_block_size)', '    compute_sum_rows(const struct q8sum_rows_context [1] context,size_t group_index,size_t batch_index,size_t block_start,size_t group_range,size_t batch_range,size_t block_size)', '    compute_u8softargmax(const struct u8softargmax_context [1] context,size_t batch_index)', '    pytorch_qnnp_run_operator(pytorch_qnnp_operator_t op,pthreadpool_t threadpool)'];
cudnn_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 80;  35; 6;4;  42; 0;21;14;40;13;0.83;3;['    C10FlagParser_caffe2_disable_implicit_engine_preference', '    C10FlagParser_caffe2_operator_max_engine_name_length', '    C10FlagParser_caffe2_operator_throw_if_fp_exceptions', '    C10FlagParser_caffe2_operator_throw_if_fp_overflow_exceptions'];['    g_global_engine_pref_', '    argumentIndexWithName(const std::string & name)', '    _CreateOperator(const OperatorDef & operator_def,Workspace *ws)', '    compute_input_size_(const std::vector & inputs)', '    CreateOperator(const OperatorDef & operator_def,Workspace *ws,int net_position)', '    g_global_engine_pref', '    g_per_op_engine_pref', '    gDeviceTypeRegistry', '    GetGradientForOp(const OperatorDef & def,const vector & g_output)', '    GetTensorShapeOfBlob(const Blob *b)', '    InferBlobShapesAndTypes(CaffeMap & blob_desc,const vector & nets)', '    InferBlobShapesAndTypesFromMap(const CaffeMap,std::vector,const vector & nets)', '    InferBlobShapesAndTypesFromMap(const CaffeMap,std::vector,const CaffeMap & blob_types,const vector & nets)', '    InferBlobShapesAndTypesFromWorkspace(Workspace *ws,const vector & nets)', '    LoadInt8TensorInfoOfBlob(std::vector *scale,std::vector *offset,uint32_t *axis,const Blob *b)', '    OpRegistryKey(const std::string & op_type,const std::string & engine)', '    RegistryName', '    RegistryName', '    RegistryName', '    RegistryName', '    SetEnginePref(const PerOpEnginePrefType & per_op_engine_pref,const GlobalEnginePrefType & global_engine_pref)', '    SetGlobalEnginePref(const GlobalEnginePrefType & global_engine_pref)', '    SetOpEnginePref(const std::string & op_type,const CaffeMap & op_pref)', '    SetPerOpEnginePref(const PerOpEnginePrefType & per_op_engine_pref)', '    TryCreateOperator(const string & key,const OperatorDef & operator_def,Workspace *ws)', '    engines', '    GetOperatorLogger', '    GetRegisteredOperators', '    InputTensorShapes', '    OperatorBase(const OperatorDef & operator_def,Workspace *ws)', '    OperatorBase(const c10::FunctionSchema & fn_schema,std::vector inputs,c10::List outputs)', '    RegistryName', '    SetOperatorLogger(std::function tracer)', '    C10FlagParser_caffe2_disable_implicit_engine_preference(const std::string & content)', '    C10FlagParser_caffe2_operator_max_engine_name_length(const std::string & content)', '    C10FlagParser_caffe2_operator_throw_if_fp_exceptions(const std::string & content)', '    C10FlagParser_caffe2_operator_throw_if_fp_overflow_exceptions(const std::string & content)'];
doubler.h;C++;pytorch-master/pytorch-master/test/cpp_extensions; 17;  0; 2;1;  14; 0;4;6;3;6;0.00;3;[];['    aliasAnalysisHasSpecialCaseFor(Symbol symbol)', '    canonicalSchemaString(const FunctionSchema & schema)', '    deregisterOperator(const FunctionSchema & schema)', '    findOperatorFor(const c10::OperatorName & full_name)', '    findSimilarOperators(Symbol input_op)', '    getOperatorForLiteral(const char *signature)', '    getRegistry', '    printerHasSpecialCaseFor(Symbol sym)', '    registerOperator(Operator)', '    deregisterOperator(const FunctionSchema & schema)', '    lookupByLiteral(const char *name)', '    registerOperator(Operator)', '    registerPendingOperators'];
extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 37;  0; 5;1;  31; 0;12;9;8;11;0.00;6;[];[];
jit_extension2.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 7;  0; 2;1;  4; 0;1;1;2;2;0.00;1;[];[];
msnpu_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 124;  5; 14;2;  103; 0;39;50;47;35;0.05;22;[];['    pytorch_qnnp_operator_get_log2_bias_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_input_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_kernel_element_size(const struct pytorch_qnnp_operator *convolution)', '    pytorch_qnnp_operator_get_log2_output_element_size(const struct pytorch_qnnp_operator *convolution)'];
no_python_abi_suffix_test.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions/no_python_abi_suffix_test; 1;  0; 0;0;  1; 0;0;1;0;1;0.00;1;['    OperatorAttachingNetObserver'];['    OperatorAttachingNetObserver(NetBase *subject_,TNetObserver *netObserver)', '    ~OperatorAttachingNetObserver'];
op.cpp;C++;pytorch-master/pytorch-master/test/custom_operator; 58;  4; 10;4;  40; 0;24;22;12;12;0.10;5;['    final'];['    debug_def', '    GPUFallbackOpEx(const OperatorDef & def,Workspace *ws)', '    InputIsTensorType', '    RunOnDevice', '    CreateBlob', '    GetBlob'];
op.h;C++;pytorch-master/pytorch-master/test/custom_operator; 24;  2; 4;13;  5; 3;0;5;0;2;0.40;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUIncrementByOne', '    CAFFE_ANONYMOUS_VARIABLE_CUDAIncrementByOne', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IncrementByOne', '    TEST(OperatorFallbackTest,IncrementByOneOp)', '    TEST(OperatorFallbackTest,GPUIncrementByOneOp)', '    IncrementByOneOp(Args,...)', '    RunOnDevice'];
test_custom_ops.cpp;C++;pytorch-master/pytorch-master/test/custom_operator; 184;  1; 40;7;  137; 0;93;38;92;25;0.01;10;[];[];
main.cc;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 19;  0; 2;3;  14; 0;12;2;11;2;0.00;1;[];[];
quantized_ops.cpp;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 72;  7; 14;4;  52; 0;30;34;11;15;0.13;4;['    JustTest', '    JustTestCUDA', '    JustTestCUDNN'];['    CAFFE_ANONYMOUS_VARIABLE_CUDAJustTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTest', '    TEST(EnginePrefTest,GPUDeviceDefaultPreferredEngines)', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type'];
quantized_ops.h;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 29;  1; 4;2;  22; 0;8;14;5;4;0.05;3;[];[];
simple_ops.h;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 49;  1; 9;2;  38; 0;24;20;6;14;0.03;6;[];['    operator<<(std::ostream & os,const OperatorName & opName)', '    toString(const OperatorName & opName)'];
utils.cpp;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 34;  0; 6;4;  24; 0;12;8;7;9;0.00;6;[];[];
utils.h;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 7;  0; 2;2;  3; 0;0;3;0;3;0.00;0;[];[];
example2.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 164;  18; 27;10;  108; 7;68;23;65;16;0.17;1;[];['    operator<<(std::ostream & out,const OpSchema & schema)', '    SparseLengthsFillerHelper(const std::vector,size_t value_index,size_t length_index,std::vector *fillers)', '    SparseSegmentsFillerHelper(const std::vector,size_t value_index,size_t segment_index,std::vector *fillers)', '    SparseWeightsFillerHelper(const std::vector,size_t weight_index,std::vector *fillers)', '    AllowInplace(std::function inplace)', '    AllowInplace(set,int)', '    AllowOneToOneInplace', '    Arg(const char *name,const char *description,bool required)', '    ArgIsTest(const char *description)', '    CalculateOutput(int num_input)', '    CostInferenceFunction(CostInferenceFunctionType)', '    DeviceInferenceFunction(DeviceInferenceFunctionType)', '    DisallowInputFillers', '    EnforceInplace(std::function inplace)', '    EnforceInplace(set,int)', '    EnforceOneToOneInplace', '    FillUsing(std::function populator)', '    IdenticalTypeAndShape', '    IdenticalTypeAndShapeOfInput(int idx)', '    IdenticalTypeAndShapeOfInputDim(int idx,int dim)', '    IdenticalTypeAndShapeOfMultipleInputs(const vector & indices)', '    InheritOnnxSchema(const std::string & onnx_schema_name)', '    Input(const int n,const char *name,const char *description)', '    InputFillers(const std::vector)', '    InputsCanCrossDevices', '    NeedsAllInputShapes(TensorInferenceFunctionType f)', '    NumInputs(int min,int max)', '    NumInputs(int n)', '    NumInputs(std::function func)', '    NumInputs(set allowed_input_nums)', '    NumInputsOutputs(std::function func)', '    NumOutputs(int min,int max)', '    NumOutputs(int n)', '    NumOutputs(std::function func)', '    NumOutputs(set allowed_output_nums)', '    Output(const int n,const char *name,const char *description)', '    OutputCalculator(std::function calc)', '    Private', '    SameNumberOfOutput', '    ScalarType(::caffe2::TensorProto_DataType dt)', '    SetDoc(const string & doc)', '    SupplyDenseFillers(const std::vector)', '    TensorInferenceFunction(TensorInferenceFunctionType)', '    ValueKeyLengthInputFillers(size_t value_index,size_t key_index,size_t length_index)', '    ValueLengthInputFillers(size_t value_index,size_t length_index)', '    Verify(const OperatorDef & def)', '    WeightedValueKeyLengthInputFillers(size_t value_index,size_t key_index,size_t length_index,size_t weight_index)', '    map'];
example3.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 269;  15; 39;6;  209; 0;128;23;116;23;0.07;1;[];[];
example4.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 102;  6; 16;5;  75; 0;44;11;44;11;0.08;2;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaArbitraryTensorInference', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaCalculateOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaInplace', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaInputOutputRelationOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSameInputOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSameInputOutputTensorInference', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaSpecifiedInputOutputOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaTestOp', '    TEST(OperatorSchemaTest,BasicSchema)', '    TEST(OperatorSchemaTest,SpecifiedInputOutput)', '    TEST(OperatorSchemaTest,InputOutputRelation)', '    TEST(OperatorSchemaTest,SameInputOutput)', '    TEST(OperatorSchemaTest,CalculateOutput)', '    TEST(OperatorSchemaTest,Inplace)', '    TEST(OperatorSchemaTest,TensorInferenceIdentical)', '    TEST(OperatorSchemaTest,TensorInferenceArbitrary)', '    TEST(OperatorSchemaTest,TestCastSchema)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_OpSchemaCostInference', '    TEST(OperatorSchemaTest,TestCostInference)'];
example6.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 162;  16; 33;7;  108; 0;74;40;75;38;0.15;2;['    OpSet_PyTorch_ver1'];['    RegisterPyTorchOperatorSetSchema', '    ForEachSchema(std::function fn)'];
miniz.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8; 7573;  396; 852;451;  4630; 1420;3076;810;3431;633;0.09;145;['    FooGradientDummyEngineOp', '    FooGradientOp', '    GetFooGradient', '    JustTest', '    JustTestAndDoesConstruct', '    JustTestAndNeverConstructs', '    JustTestWithSomeOutput', '    JustTestWithNonStandardIsTestArg', '    JustTestWithRequiredArg', '    JustTestWithStandardIsTestArg'];['    CAFFE_ANONYMOUS_VARIABLE_CPUJustTest', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestCPUOnly', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithSomeOutput', '    CAFFE_ANONYMOUS_VARIABLE_CUDAJustTest', '    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithNonStandardIsTestArg', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithRequiredArg', '    CAFFE_ANONYMOUS_VARIABLE_CPUJustTestWithStandardIsTestArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestCPUOnly', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithSomeOutput', '    GetNetDefForTest', '    TEST(OperatorTest,DeviceTypeRegistryWorks)', '    TEST(OperatorTest,RegistryWorks)', '    TEST(OperatorTest,RegistryWrongDevice)', '    TEST(OperatorTest,ExceptionWorks)', '    TEST(OperatorTest,FallbackIfEngineDoesNotBuild)', '    TEST(OperatorTest,MultipleEngineChoices)', '    TEST(OperatorTest,CannotUseUninitializedBlob)', '    TEST(OperatorTest,TestParameterAccess)', '    TEST(OperatorTest,CannotAccessParameterWithWrongType)', '    TEST(OperatorTest,TestDefaultValue)', '    TEST(OperatorTest,TestSetUp)', '    TEST(OperatorTest,TestSetUpInputOutputCount)', '    TEST(OperatorTest,TestOutputValues)', '    TEST(NetTest,TestScaffoldingSimpleNet)', '    TEST(NetTest,TestScaffoldingDAGNet)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FooGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithNonStandardIsTestArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithRequiredArg', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_JustTestWithStandardIsTestArg', '    TEST(OperatorGradientRegistryTest,GradientSimple)', '    TEST(EnginePrefTest,PerOpEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePrefAndPerOpEnginePref)', '    TEST(EnginePrefTest,GlobalEnginePrefAndPerOpEnginePrefAndOpDef)', '    TEST(EnginePrefTest,SetOpEnginePref)', '    TEST(EnginePrefTest,SetDefaultEngine)', '    TEST(RequiredArg,Basic)', '    TEST(IsTestArg,standard)', '    TEST(IsTestArg,non_standard)', '    type', '    type', '    GetGradientDefs', '    Run(int)', '    type', '    Run(int)', '    type', '    JustTestAndNeverConstructs(const OperatorDef & def,Workspace *ws)', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    Run(int)', '    type', '    vector'];
miniz.h;C++;pytorch-master/pytorch-master/third_party/miniz-2.0.8; 1322;  419; 212;221;  431; 148;0;462;0;243;0.97;0;[];['    checkSchema(const OperatorName & name,const FunctionSchema & from_def,const FunctionSchema & inferred)', '    listAllDispatchKeys(const ska::flat_hash_map,std::list)', '    toString(c10::optional k)', '    checkInvariants', '    deregisterKernel_(c10::optional dispatch_key,std::list::iterator kernel)', '    deregisterSchema', '    dumpState', '    OperatorEntry(FunctionSchema)', '    OperatorEntry(OperatorName)', '    prepareForDeregistration', '    registerKernel(c10::optional dispatch_key,KernelFunction kernel,std::unique_ptr inferred_function_schema,std::string debug)', '    registerSchema(FunctionSchema)', '    updateDispatchTable_(c10::optional dispatch_key)'];
Functions.h;C++;pytorch-master/pytorch-master/tools/autograd/templates; 50;  5; 11;9;  26; 0;5;12;10;19;0.19;5;[];[];
python_functions.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 26;  2; 7;5;  13; 0;5;6;3;5;0.15;2;[];[];
python_functions.h;C++;pytorch-master/pytorch-master/tools/autograd/templates; 11;  3; 5;1;  3; 0;0;3;0;4;1.00;0;[];[];
python_torch_functions.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 612;  75; 68;20;  493; 0;325;233;328;181;0.15;37;[];['    ops', '    is_aten_op(const c10::OperatorName & opName)', '    operator()(const std::pair & lhs,const std::pair & rhs)', '    operator()(const std::pair & p)'];
python_variable_methods.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 912;  55; 72;32;  753; 8;498;425;833;502;0.07;63;[];[];
RegistrationDeclarations.h;C++;pytorch-master/pytorch-master/tools/autograd/templates; 4;  2; 1;0;  1; 0;1;1;0;1;2.00;1;[];['    MergeOpticalFlow(cv::Mat & prev_flow,const cv::Mat & curr_flow)', '    MultiFrameOpticalFlowExtractor(const std::vector & grays,const int optical_flow_alg_type,cv::Mat & flow)', '    OpticalFlowExtractor(const cv::Mat & prev_gray,const cv::Mat & curr_gray,const int flow_alg_type,cv::Mat & flow)'];
VariableType.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 50;  27; 10;3;  11; 0;3;9;2;11;2.45;2;[];['    MergeOpticalFlow(cv::Mat & prev_flow,const cv::Mat & curr_flow)', '    MultiFrameOpticalFlowExtractor(const std::vector & grays,const int optical_flow_alg_type,cv::Mat & flow)', '    OpticalFlowExtractor(const cv::Mat & prev_gray,const cv::Mat & curr_gray,const int flow_alg_type,cv::Mat & flow)'];
VariableType.h;C++;pytorch-master/pytorch-master/tools/autograd/templates; 55;  8; 11;9;  31; 0;2;13;18;33;0.26;0;[];['    assign_parameter(const Parameters & parameters,const char *name,torch::Tensor new_tensor)', '    check_exact_values(Options options,std::vector)', '    closure', '    closure', '    lr', '    lr', '    step', '    TEST(OptimTest,OptimizerAccessors)', '    TEST(OptimTest,OldInterface)', '    TEST(OptimTest,XORConvergence_SGD)', '    TEST(OptimTest,XORConvergence_LBFGS)', '    TEST(OptimTest,XORConvergence_Adagrad)', '    TEST(OptimTest,XORConvergence_RMSprop)', '    TEST(OptimTest,XORConvergence_RMSpropWithMomentum)', '    TEST(OptimTest,XORConvergence_Adam)', '    TEST(OptimTest,XORConvergence_AdamWithAmsgrad)', '    TEST(OptimTest,ProducesPyTorchValues_Adam)', '    TEST(OptimTest,ProducesPyTorchValues_AdamWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_AdamWithWeightDecayAndAMSGrad)', '    TEST(OptimTest,ProducesPyTorchValues_Adagrad)', '    TEST(OptimTest,ProducesPyTorchValues_AdagradWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_AdagradWithWeightDecayAndLRDecay)', '    TEST(OptimTest,ProducesPyTorchValues_RMSprop)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecayAndCentered)', '    TEST(OptimTest,ProducesPyTorchValues_RMSpropWithWeightDecayAndCenteredAndMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_SGD)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecay)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecayAndMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_SGDWithWeightDecayAndNesterovMomentum)', '    TEST(OptimTest,ProducesPyTorchValues_LBFGS)', '    TEST(OptimTest,ProducesPyTorchValues_LBFGS_with_line_search)', '    TEST(OptimTest,ZeroGrad)', '    TEST(OptimTest,ExternalVectorOfParameters)', '    TEST(OptimTest,AddParameter_LBFGS)', '    test_optimizer_xor(Options options)', '    MyOptimizer(std::vector params,MyOptimizerOptions defaults)', '    step(LossClosure closure)', '    MyOptimizerOptions(double lr)'];
analyzer.cpp;C++;pytorch-master/pytorch-master/tools/code_analyzer; 32;  1; 6;7;  19; 0;7;13;5;7;0.05;1;[];[];
aten_interned_strings.h;C++;pytorch-master/pytorch-master/tools/jit/templates; 16;  7; 4;5;  0; 0;0;0;0;0;0.00;0;[];['    tensor(,,,,,)', '    tensor(,,)', '    tensor'];
aten_schema_declarations.cpp;C++;pytorch-master/pytorch-master/tools/jit/templates; 5;  0; 1;0;  4; 0;2;4;0;3;0.00;0;[];['    OptimizeForMkldnn(repr::NNModule *nn,caffe2::Workspace *ws,bool training_mode)'];
register_aten_ops.cpp;C++;pytorch-master/pytorch-master/tools/jit/templates; 133;  19; 21;18;  77; 0;20;48;34;24;0.25;6;[];['    OptimizeForMkldnn(nom::repr::NNModule *nn,caffe2::Workspace *ws,bool training_mode)'];
all.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 12;  0; 1;11;  0; 0;0;0;0;0;0.00;0;[];['    graphOptimzations(nom::repr::NNModule *nn,int level)', '    optimize(NetDef net,Workspace *ws,int level)', '    optimize(NetDef net,int level)', '    workspaceOptimizations(nom::repr::NNModule *nn,Workspace *ws,int level)'];
arg.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 22;  5; 2;20;  0; 0;0;0;0;0;0.00;0;[];['    clone', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    noexcept', '    noexcept', '    operator<<(serialize::OutputArchive & archive,const Optimizer & optimizer)', '    operator>>(serialize::InputArchive & archive,Optimizer & optimizer)', '    add_param_group(const OptimizerParamGroup & param_group)', '    add_parameters(const std::vector & parameters)', '    defaults', '    defaults', '    load(serialize::InputArchive & archive)', '    param_groups', '    param_groups', '    parameters', '    parameters', '    save(serialize::OutputArchive & archive)', '    size', '    zero_grad', '    has_options', '    options', '    options', '    params', '    params', '    set_options(std::unique_ptr options)', '    clone', '    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)'];
autograd.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 4;  0; 1;3;  0; 0;0;0;0;0;0.00;0;[];[];
data.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 14;  3; 2;5;  6; 0;0;0;0;0;0.50;0;[];['    optimize(NetDef net,Workspace *ws,int level)', '    optimize(NetDef net,int level)'];
dataloader.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 58;  8; 8;10;  34; 0;0;0;0;0;0.24;0;[];[];
base.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/dataloader; 246;  57; 31;18;  142; 0;0;0;0;0;0.40;0;['    optional', '    optional', '    optional'];['    assert', '    assert(initialized)', '    bad_optional_access(const char *what_arg)', '    constexpr', '    convert(U v)', '    static_addressof(T & ref)', '    noexcept', '    noexcept', '    noexcept', '    nullopt', '    trivial_init', '    clear', '    contained_val', '    emplace(Args,...)', '    emplace(std::initializer_list il,Args,...)', '    has_value', '    initialize(Args,...)', '    initialize(std::initializer_list il,Args,...)', '    initialize(std::move *rhs)', '    initialize(std::forward v)', '    make_optional(T)', '    make_optional(std::reference_wrapper v)', '    operator bool', '    operator!=(const optional & x,const optional & y)', '    operator!=(const optional & x,nullopt_t)', '    operator!=(nullopt_t,const optional & x)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator!=(const T & v,const optional & x)', '    operator!=(const optional & x,const T & v)', '    operator()(argument_type const & arg)', '    operator*', '    operator*', '    operator->', '    operator->', '    operator<(const optional & x,const optional & y)', '    operator<(const optional &,nullopt_t)', '    operator<(nullopt_t,const optional & x)', '    operator<(const T & v,const optional & x)', '    operator<(const T & v,const optional & x)', '    operator<(const optional & x,const T & v)', '    operator<(const T & v,const optional & x)', '    operator<(const optional & x,const T & v)', '    operator<(const optional & x,const T & v)', '    operator<=(const optional & x,const optional & y)', '    operator<=(const optional & x,nullopt_t)', '    operator<=(nullopt_t,const optional &)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator<=(const optional & x,const T & v)', '    operator<=(const T & v,const optional & x)', '    operator=(nullopt_t)', '    operator=(const optional & rhs)', '    operator=(optional)', '    operator=(U)', '    operator==(const optional & x,const optional & y)', '    operator==(const optional & x,nullopt_t)', '    operator==(nullopt_t,const optional & x)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator==(const T & v,const optional & x)', '    operator==(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const T & v)', '    operator>(const optional & x,const optional & y)', '    operator>(const optional & x,nullopt_t)', '    operator>(nullopt_t,const optional &)', '    operator>(const T & v,const optional & x)', '    operator>(const T & v,const optional & x)', '    operator>(const T & v,const optional & x)', '    operator>=(const optional & x,const optional & y)', '    operator>=(const optional &,nullopt_t)', '    operator>=(nullopt_t,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    operator>=(const optional & x,const T & v)', '    operator>=(const T & v,const optional & x)', '    optional(U)', '    optional(U)', '    optional', '    optional(nullopt_t)', '    optional(const optional & rhs)', '    optional(optional)', '    optional(in_place_t,Args,...)', '    optional(in_place_t,std::initializer_list il,Args,...)', '    reset', '    declval', '    operator()(argument_type const & arg)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    swap(optional & rhs)', '    swap(**this,*rhs)', '    swap(optional & x,optional & y)', '    T(std::forward args,...)', '    T(il,std::forward args,...)', '    T(std::move *rhs)', '    value', '    value', '    value_or(V)', '    value_or(V)', '    ~constexpr_optional_base', '    ~optional', '    ~optional_base', '    bad_optional_access(const std::string & what_arg)', '    nullopt_t(init)', '    constexpr_optional_base', '    constexpr_optional_base(const T & v)', '    constexpr_optional_base(T)', '    constexpr_optional_base(in_place_t,Args,...)', '    constexpr_storage_t(trivial_init_t)', '    constexpr_storage_t(Args,...)', '    ~constexpr_storage_t', '    convert', '    static_addressof', '    contained_val', '    dataptr', '    dataptr', '    emplace(T & v)', '    emplace', '    has_value', '    initialized', '    operator bool', '    operator*', '    operator->', '    operator=', '    operator=(U)', '    operator=(nullopt_t)', '    optional', '    optional(nullopt_t)', '    optional(U & u)', '    optional', '    optional(const optional & rhs)', '    optional(in_place_t,T & v)', '    optional', '    reset', '    static_assert(,nullopt_t,)', '    static_assert(,in_place_t,)', '    static_assert(,)', '    swap(optional & rhs)', '    value', '    value_or(V)', '    ~optional', '    optional_base', '    optional_base(const T & v)', '    optional_base(T)', '    optional_base(in_place_t,Args,...)', '    swap', '    storage_t(trivial_init_t)', '    storage_t(Args,...)', '    ~storage_t', '    ~T'];
stateless.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/dataloader; 82;  20; 10;8;  46; 0;0;0;0;0;0.43;0;[];[];
dataloader_options.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 65;  21; 12;5;  30; 0;7;26;12;111;0.70;14;[];[];
datasets.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 9;  0; 1;8;  0; 0;0;0;0;0;0.00;0;['    final', '    final'];['    IDEEPNCHW2NHWCOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPNHWC2NCHWOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPNCHW2NHWCOp', '    ~IDEEPNHWC2NCHWOp'];
chunk.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 521;  135; 69;8;  314; 0;0;0;0;0;0.43;0;['    GetNCHW2NHWCGradient', '    GetNHWC2NCHWGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUNCHW2NHWC', '    CAFFE_ANONYMOUS_VARIABLE_CPUNHWC2NCHW', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NCHW2NHWC', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NHWC2NCHW', '    GetGradientDefs', '    GetGradientDefs', '    vector', '    vector'];
map.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 117;  24; 17;7;  73; 0;0;0;0;0;0.33;0;['    final', '    final'];['    NCHW2NHWCOp(Args,...)', '    NHWC2NCHWOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~NCHW2NHWCOp', '    ~NHWC2NCHWOp'];
mnist.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 47;  14; 11;7;  18; 0;0;0;0;0;0.78;0;['    CuDNNOrderSwithOpBase', '    final', '    final'];['    CuDNNOrderSwithOpBase(Args,...)', '    SetTensorDescriptor(const cudnnDataType_t data_type,const StorageOrder order,const std::vector & data_dims,cudnnTensorDescriptor_t data_desc)', '    ~CuDNNOrderSwithOpBase', '    CuDNNNCHW2NHWCOp(Args,...)', '    CuDNNNHWC2NCHWOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice'];
stateful.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 68;  21; 10;5;  37; 0;0;0;0;0;0.57;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDANCHW2NHWC', '    CAFFE_ANONYMOUS_VARIABLE_CUDANHWC2NCHW'];
tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 38;  8; 9;6;  18; 0;0;0;0;0;0.44;0;[];['    TEST(OrderedDictTest,IsEmptyAfterDefaultConstruction)', '    TEST(OrderedDictTest,InsertAddsElementsWhenTheyAreYetNotPresent)', '    TEST(OrderedDictTest,GetReturnsValuesWhenTheyArePresent)', '    TEST(OrderedDictTest,GetThrowsWhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,CanInitializeFromList)', '    TEST(OrderedDictTest,InsertThrowsWhenPassedElementsThatArePresent)', '    TEST(OrderedDictTest,FrontReturnsTheFirstItem)', '    TEST(OrderedDictTest,FrontThrowsWhenEmpty)', '    TEST(OrderedDictTest,BackReturnsTheLastItem)', '    TEST(OrderedDictTest,BackThrowsWhenEmpty)', '    TEST(OrderedDictTest,FindReturnsPointersToValuesWhenPresent)', '    TEST(OrderedDictTest,FindReturnsNullPointersWhenPasesdKeysThatAreNotPresent)', '    TEST(OrderedDictTest,SubscriptOperatorThrowsWhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,SubscriptOperatorReturnsItemsPositionallyWhenPassedIntegers)', '    TEST(OrderedDictTest,SubscriptOperatorsThrowswhenPassedKeysThatAreNotPresent)', '    TEST(OrderedDictTest,UpdateInsertsAllItemsFromAnotherOrderedDict)', '    TEST(OrderedDictTest,UpdateAlsoChecksForDuplicates)', '    TEST(OrderedDictTest,CanIterateItems)', '    TEST(OrderedDictTest,EraseWorks)', '    TEST(OrderedDictTest,ClearMakesTheDictEmpty)', '    TEST(OrderedDictTest,CanCopyConstruct)', '    TEST(OrderedDictTest,CanCopyAssign)', '    TEST(OrderedDictTest,CanMoveConstruct)', '    TEST(OrderedDictTest,CanMoveAssign)', '    TEST(OrderedDictTest,CanInsertWithBraces)', '    TEST(OrderedDictTest,ErrorMessagesIncludeTheKeyDescription)', '    TEST(OrderedDictTest,KeysReturnsAllKeys)', '    TEST(OrderedDictTest,ValuesReturnsAllValues)', '    TEST(OrderedDictTest,ItemsReturnsAllItems)'];
data_shuttle.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/detail; 87;  28; 12;7;  43; 0;16;20;12;18;0.65;6;[];[];
sequencers.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/detail; 113;  41; 11;5;  61; 0;25;29;25;25;0.67;5;[];['    init_dict_size', '    TEST(OrderedPreservingDictTest,InsertAndDeleteBasic)', '    TEST(OrderedPreservingDictTest,InsertExistingDoesntAffectOrder)', '    TEST(OrderedPreservingDictTest,testRefType)', '    TEST(OrderedPreservingDictTest,DictCollisions)', '    TEST(OrderedPreservingDictTest,test_range_insert)', '    TEST(OrderedPreservingDictTest,test_range_erase_all)', '    TEST(OrderedPreservingDictTest,test_range_erase)', '    TEST(OrderedPreservingDictTest,test_move_constructor_empty)', '    TEST(OrderedPreservingDictTest,test_move_operator_empty)', '    TEST(OrderedPreservingDictTest,test_reassign_moved_object_move_constructor)', '    TEST(OrderedPreservingDictTest,test_reassign_moved_object_move_operator)', '    TEST(OrderedPreservingDictTest,test_copy_constructor_and_operator)', '    TEST(OrderedPreservingDictTest,test_copy_constructor_empty)', '    TEST(OrderedPreservingDictTest,test_copy_operator_empty)', '    TEST(OrderedPreservingDictTest,test_at)', '    TEST(OrderedPreservingDictTest,test_equal_range)', '    TEST(OrderedPreservingDictTest,test_access_operator)', '    TEST(OrderedPreservingDictTest,test_swap)', '    TEST(OrderedPreservingDictTest,test_swap_empty)', '    test_dict(dict_int_int & dict)', '    operator()(const int64_t input)'];
example.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 55;  13; 12;2;  32; 0;0;0;0;0;0.41;0;[];['    OutputArchive(std::shared_ptr cu)', '    save_to(const std::string & filename)', '    save_to(std::ostream & stream)', '    save_to(const std::function & func)', '    write(const std::string & key,const c10::IValue & ivalue)', '    write(const std::string & key,const Tensor & tensor,bool is_buffer)', '    write(const std::string & key,OutputArchive & nested_archive)'];
iterator.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 178;  38; 29;9;  106; 0;34;48;38;49;0.36;18;[];[];
base.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 47;  14; 10;6;  22; 0;0;9;0;4;0.64;0;['    OutputFormatter'];['    format(const std::vector & durations_ms,uint64_t threads,uint64_t iterations)', '    ~OutputFormatter'];
custom_batch_request.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 18;  5; 3;3;  10; 0;0;0;0;0;0.50;0;[];[];
distributed.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 134;  25; 26;5;  83; 0;0;0;0;0;0.30;0;[];['    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)'];
sequential.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 50;  13; 12;6;  24; 0;0;0;0;0;0.54;0;[];['    main(int argc,const char *[] argv)'];
serialize.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 28;  5; 3;3;  20; 0;0;0;0;0;0.25;0;[];['    pytorch_pack_hgemm_w(size_t nc,size_t kc,size_t nr,size_t kr,const uint16_t *k,const uint16_t *b,uint16_t *packed_w)', '    pytorch_pack_q8conv_wdq(size_t n,size_t ks,size_t kc,uint32_t nr,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8conv_wrq(const size_t n,const size_t ks,const size_t kc,const uint32_t nr,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8deconv_wdq(size_t n,size_t ks,size_t kc,uint32_t nr,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8deconv_wrq(const size_t n,const size_t ks,const size_t kc,const uint32_t nr,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8dw_w_dilation(size_t h,size_t w,size_t c,size_t cr,size_t y_start,size_t y_end,size_t x_start,size_t x_end,const uint8_t *k,const int32_t *b,void *packed_w,bool pytorch_pack_b)', '    pytorch_pack_q8dw_wdq(size_t h,size_t w,size_t c,size_t cr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8dw_wrq(const size_t h,const size_t w,const size_t c,const size_t cr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_q8gemm_wdq(size_t nc,size_t kc,uint32_t nr,uint32_t np,uint32_t kr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_q8gemm_wrq(const size_t nc,const size_t kc,const uint32_t nr,const uint32_t np,const uint32_t kr,const uint8_t *const k,const int32_t *const b,void *const packed_w)', '    pytorch_pack_sconv_w(size_t n,size_t ks,size_t kc,size_t nr,size_t kr,const float *k,const float *b,float *packed_w)', '    pytorch_pack_sgemm_w(size_t nc,size_t kc,size_t nr,size_t kr,const float *k,const float *b,float *packed_w)', '    pytorch_pack_swizzle_q8gemm_bdq(size_t n,size_t kc,uint32_t nr,uint32_t kr,uint32_t sr,uint8_t izp,uint8_t kzp,const uint8_t *k,const int32_t *b,void *packed_w)', '    pytorch_pack_swizzle_q8gemm_brq(const size_t n,const size_t kc,const uint32_t nr,const uint32_t kr,const uint32_t sr,const uint8_t *const k,const int32_t *const b,void *const packed_w)'];
stream.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 63;  21; 12;6;  29; 0;0;0;0;0;0.72;0;['    GetPackRNNSequenceGradient', '    GetUnpackRNNSequenceGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPackRNNSequence', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnpackRNNSequence', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackRNNSequence', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnpackRNNSequence', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs'];
base.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/transforms; 53;  13; 9;4;  30; 0;0;0;0;0;0.43;0;['    PackRNNSequenceOpBase'];['    DoRunWithType', '    PackRNNSequenceOpBase(Args,...)', '    RunOnDevice'];
collate.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/transforms; 35;  19; 5;4;  10; 0;0;0;0;0;1.90;0;['    GetPackSegmentsGradient', '    GetUnpackSegmentsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPackSegments', '    CAFFE_ANONYMOUS_VARIABLE_CPUUnpackSegments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackSegments', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnpackSegments', '    presence_shape', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType2'];
lambda.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/transforms; 56;  9; 12;5;  33; 0;0;0;0;0;0.27;0;['    final', '    final'];['    dev_buffer_', '    dev_buffer_', '    dev_lengths_prefix_sum_', '    dev_lengths_prefix_sum_', '    dev_max_length_', '    dev_max_length_', '    dev_num_cell_', '    DoRunWithType', '    DoRunWithType2', '    GetSingleArgument', '    host_max_length_', '    host_max_length_', '    host_num_cell_', '    PackSegmentsOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    UnpackSegmentsOp(Args,...)'];
tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/transforms; 77;  20; 13;6;  45; 0;0;0;0;0;0.44;0;[];['    _pack_padded_sequence(const Tensor & _input,const Tensor & _lengths,bool batch_first)', '    _pack_padded_sequence_backward(const Tensor & grad,at::IntArrayRef input_size,const Tensor & _batch_sizes,bool batch_first)', '    _pad_packed_sequence(const Tensor & data,const Tensor & _batch_sizes,bool batch_first,Scalar padding_value,int64_t total_length)', '    checkLongTensor(const Tensor & tensor)'];
worker_exception.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 38;  8; 7;4;  21; 0;0;0;0;0;0.38;0;['    GetPadImageGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUPadImage', '    StringToPadMode(const string & mode)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadImage', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadImageGradient', '    vector', '    GetGradientDefs', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    PadTensorInference(const OperatorDef & def,const vector & in)', '    RunOnDeviceWithOrderNCHW'];
static.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/detail; 65;  19; 10;5;  35; 0;0;0;0;0;0.54;0;['    final', '    final', '    PadMode'];['    StringToPadMode(const string & mode)', '    PadTensorInference(const OperatorDef & def,const vector & in)', '    PadImageGradientOp(Args,...)', '    PadImageOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    ~PadImageGradientOp', '    ~PadImageOp'];
enum.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 192;  55; 13;34;  94; 0;0;0;0;0;0.59;0;[];['    Index(const std::vector & indices)', '    PaddedBufferBase(const std::vector & dims,const std::string & name)'];
expanding_array.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 172;  56; 24;10;  93; 0;0;0;0;0;0.60;0;['    PaddedBuffer', '    PaddedBufferBase'];['    CompareErrorMsg(const PaddedBuffer & v1,const PaddedBuffer & v2,int index)', '    ExpectAllEqual(const PaddedBuffer & f1,const PaddedBuffer & f2)', '    ExpectAllNear(const PaddedBuffer & f1,const PaddedBuffer & f2,float abs_error)', '    resize', '    CallArg(const PaddedBuffer & buffer)', '    Backup', '    CheckBackup', '    data', '    data', '    operator()(int i0)', '    operator()(int i0)', '    operator()(int i0,int i1)', '    operator()(int i0,int i1)', '    operator()(int i0,int i1,int i2)', '    operator()(int i0,int i1,int i2)', '    operator()(int i0,int i1,int i2,int i3)', '    operator()(int i0,int i1,int i2,int i3)', '    operator()(const std::vector & indices)', '    operator()(const std::vector & indices)', '    PaddedBuffer(int d0,const std::string & name)', '    PaddedBuffer(int d0,int d1,const std::string & name)', '    PaddedBuffer(int d0,int d1,int d2,const std::string & name)', '    PaddedBuffer(int d0,int d1,int d2,int d3,const std::string & name)', '    PaddedBuffer(const std::vector & dims,const std::string & name)', '    PaddedBuffer(const PaddedBuffer & other,const std::string & name)', '    raw_data', '    raw_data', '    ValidateWatermark', '    Index(const std::vector & indices)', '    name', '    PaddedBufferBase(const std::vector & dims,const std::string & name)', '    raw_size', '    size', '    ~PaddedBufferBase'];
jit.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 36;  23; 5;5;  5; 0;0;0;0;0;4.60;0;[];['    ConstantPadImpl(const ConstantPadOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    pretty_print(std::ostream & stream)', '    ReflectionPadImpl(const ReflectionPadOptions & options_)', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    ReplicationPadImpl(const ReplicationPadOptions & options_)', '    reset', '    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    ZeroPad2dImpl(const ZeroPad2dOptions & options_)'];
cloneable.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 95;  19; 9;8;  63; 0;0;0;0;0;0.30;0;[];['    PadFuncOptions(std::vector pad)'];
functional.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 17;  0; 1;16;  0; 0;0;0;0;0;0.00;0;[];[];
activation.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 867;  283; 83;45;  521; 0;0;0;0;0;0.54;0;[];[];
conv.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 251;  82; 16;15;  153; 0;0;0;0;0;0.54;0;[];[];
distance.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 91;  33; 10;6;  49; 0;0;0;0;0;0.67;0;[];['    TEST_F(ParallelTest,DifferentiableScatter_MultiCUDA)', '    TEST_F(ParallelTest,DifferentiableGather_MultiCUDA)', '    TEST_F(ParallelTest,Replicate_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApply_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApplyWithDifferentOutputDevice_MultiCUDA)', '    TEST_F(ParallelTest,ParallelApplyRethrowsException_MultiCUDA)', '    TEST_F(ParallelTest,DataParallelPlacesTheOutputOnTheRequestedDevice_MultiCUDA)', '    TEST_F(ParallelTest,DataParallelUsesAllAvailableCUDADevices_CUDA)', '    TEST_F(ParallelTest,DataParallelNumericalEquivalence_MultiCUDA)', '    conv', '    fc', '    forward(torch::Tensor x)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    forward(torch::Tensor input)', '    M', '    reset', '    reset', '    reset', '    reset'];
dropout.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 180;  72; 27;12;  82; 0;0;0;0;0;0.88;0;[];['    divup(int64_t x,int64_t y)', '    get_num_interop_threads', '    get_num_threads', '    get_parallel_info', '    get_thread_num', '    in_parallel_region', '    init_num_threads', '    intraop_default_num_threads', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)', '    set_num_interop_threads(int)', '    set_num_threads(int)'];
fold.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 99;  30; 8;6;  62; 0;0;0;0;0;0.48;0;[];['    main(int argc,char **argv)'];
instancenorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 43;  16; 6;4;  22; 0;0;0;0;0;0.73;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSleep', '    CAFFE_ANONYMOUS_VARIABLE_CUDASleep', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sleep', '    RunNetAndGetDuration(const string & net_def_str,const string & type)', '    TEST(DAGNetTest,TestDAGNetTiming)', '    TEST(SimpleNetTest,TestSimpleNetTiming)', '    TEST(DAGNetTest,TestDAGNetTimingReadAfterRead)', '    TEST(SimpleNetTest,TestSimpleNetTimingReadAfterRead)', '    TEST(DAGNetTest,TestDAGNetTimingWriteAfterWrite)', '    TEST(SimpleNetTest,TestSimpleNetTimingWriteAfterWrite)', '    TEST(DAGNetTest,TestDAGNetTimingWriteAfterRead)', '    TEST(SimpleNetTest,TestSimpleNetTimingWriteAfterRead)', '    TEST(DAGNetTest,TestDAGNetTimingControlDependency)', '    TEST(SimpleNetTest,TestSimpleNetTimingControlDependency)', '    RunOnDevice', '    SleepOp(const OperatorDef & operator_def,Workspace *ws)'];
linear.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 31;  5; 6;2;  21; 0;0;0;0;0;0.24;0;[];['    get_env_num_threads(const char *var_name,size_t def_value)', '    get_env_var(const char *var_name,const char *def_value)', '    get_parallel_info', '    intraop_default_num_threads'];
normalization.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 178;  72; 14;13;  104; 0;0;0;0;0;0.69;0;[];[];
padding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 104;  22; 10;4;  79; 0;0;0;0;0;0.28;0;[];['    calc_num_tasks_and_chunk_size(int64_t begin,int64_t end,int64_t grain_size)', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)'];
pixelshuffle.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 41;  16; 5;4;  21; 0;0;0;0;0;0.76;0;[];[];
upsampling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 185;  18; 12;6;  154; 0;0;0;0;0;0.12;0;[];['    intraop_invoke(const F0 & f0,const F1 & f1)', '    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)'];
vision.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 114;  21; 14;5;  81; 0;0;0;0;0;0.26;0;[];[];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 125;  54; 22;4;  50; 0;0;0;0;0;1.08;0;[];['    parallel_for(const int64_t begin,const int64_t end,const int64_t grain_size,const F & f)', '    parallel_reduce(const int64_t begin,const int64_t end,const int64_t grain_size,const scalar_t ident,const F & f,const SF & sf)'];
modules.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 30;  3; 3;24;  0; 0;0;0;0;0;0.00;0;[];[];
_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 25;  3; 5;5;  15; 0;0;0;0;0;0.20;0;[];[];
activation.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 815;  404; 167;7;  239; 0;0;0;0;0;1.69;0;[];['    operator()(const Params & a,const Params & b)', '    static_assert(std::is_pod::value,)', '    operator()(const Params & params)', '    static_assert(std::is_pod::value,)'];
batchnorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 212;  72; 32;8;  107; 0;0;0;0;0;0.67;0;[];['    expand_param_if_needed(IntArrayRef list_param,const char *param_name,int64_t expected_dim)'];
common.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 93;  67; 1;25;  0; 0;0;0;0;0;0.00;0;[];['    isOctal(char c)', '    isCharCount(char c,const std::string & str,size_t start,int len)', '    parseOctal(const std::string & str,size_t pos)', '    parseStringLiteral(const SourceRange & range,const std::string & str)'];
any.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 370;  128; 48;16;  180; 0;0;0;0;0;0.71;0;[];['    mergeTypesFromTypeComment(const Decl & decl,const Decl & type_annotation_decl,bool is_method)', '    followsTuple(int kind)', '    lexer', '    parseClass', '    parseExp', '    parseFunction(bool is_method)', '    Parser(const std::shared_ptr & src)', '    parseTypeComment', '    create_compound(int kind,const SourceRange & range,TreeList)', '    createApply(const Expr & expr)', '    lexer', '    makeList(const SourceRange & range,TreeList)', '    maybeParseAssignmentOp', '    maybeParseTypeAnnotation', '    parseArguments(TreeList & inputs,TreeList & attributes)', '    parseAssign(const Expr & lhs)', '    parseAttributeValue', '    parseBareTypeAnnotation', '    parseBaseExp', '    parseClass', '    parseConcatenatedStringLiterals', '    parseConst', '    parseDecl', '    parseExp', '    parseExp(int precedence)', '    parseExpOrExpTuple', '    parseFor', '    parseFormalParam(bool kwarg_only)', '    parseFormalParams', '    parseFunction(bool is_method)', '    parseIdent', '    parseIf(bool expect_if)', '    parseLHSExp', '    parseList(int begin,int sep,int end,T (ParserImpl::*) () parse)', '    parseReturnAnnotation', '    ParserImpl(const std::shared_ptr & source)', '    parseSequence(int begin,int sep,int end,const std::function & parse)', '    parseStatements(bool expect_indent,bool in_class)', '    parseStmt(bool in_class)', '    parseSubscript(const TreeRef & value)', '    parseSubscriptExp', '    parseTrinary(TreeRef true_branch,const SourceRange & range,int binary_prec)', '    parseTypeComment', '    parseWhile'];
any_value.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 121;  27; 16;12;  68; 0;0;0;0;0;0.40;0;[];['    mergeTypesFromTypeComment(const Decl & decl,const Decl & type_annotation_decl,bool is_method)', '    lexer', '    parseClass', '    parseExp', '    parseFunction(bool is_method)', '    Parser(const std::shared_ptr & src)', '    parseTypeComment', '    ~Parser'];
functional.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 104;  58; 14;8;  27; 0;0;0;0;0;2.15;0;[];[];
modulelist.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 256;  93; 34;4;  127; 0;0;0;0;0;0.73;0;[];['    deprecated_AT_ASSERT', '    str(,,,,,::c10::str __VA_ARGS__)', '    dim', '    isNoop', '    nSubTensors', '    subTensorDesc', '    subTensorDesc', '    dim_', '    PartitionDesc(const TensorDesc & _desc,size_t _nSubTensors,size_t _dim)', '    dim_', '    PartitionDesc'];
sequential.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 381;  165; 42;16;  160; 0;0;0;0;0;1.03;0;['    GetGatherByKeyGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGatherByKey', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsPartition', '    CAFFE_ANONYMOUS_VARIABLE_CPUPartition', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherByKey', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsPartition', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Partition', '    GetGradientDefs', '    vector'];
conv.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 365;  114; 41;12;  202; 0;0;0;0;0;0.56;0;['    GatherByKeyOp', '    LengthsPartitionOp', '    PartitionOp', '    PartitionOpBase'];['    moduloPartition(Index key,int numPartitions)', '    DoRunWithType', '    GatherByKeyOp(Args,...)', '    RunOnDevice', '    DoRunWithType', '    LengthsPartitionOp(Args,...)', '    LengthsPartitionOp', '    operator=', '    RunOnDevice', '    DoRunWithType', '    operator=', '    PartitionOp(Args,...)', '    PartitionOp', '    RunOnDevice', '    ApplyPartition(bool skipFirstArgument)', '    PartitionOpBase(Args,...)'];
distance.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 85;  41; 17;7;  22; 0;0;0;0;0;1.86;0;[];['    getCustomPostFusionPasses', '    getCustomPreFusionPasses', '    RegisterPostFusionPass(GraphPass p)', '    RegisterPreFusionPass(GraphPass p)'];
embedding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 152;  50; 26;8;  70; 0;0;0;0;0;0.71;0;[];['    getCustomPostFusionPasses', '    getCustomPreFusionPasses', '    RegisterPostFusionPass(GraphPass p)', '    RegisterPreFusionPass(GraphPass p)'];
fold.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 86;  39; 16;7;  26; 0;0;0;0;0;1.50;0;[];['    RegistryName', '    RegistryName'];
instancenorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 111;  55; 18;3;  37; 0;0;0;0;0;1.49;0;['    OptimizationPass', '    WorkspaceOptimizationPass'];['    RegistryName', '    OptimizationPass(NNModule *nn)', '    run', '    ~OptimizationPass', '    WorkspaceOptimizationPass(NNModule *nn,Workspace *ws)', '    ~WorkspaceOptimizationPass'];
loss.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 697;  381; 136;10;  172; 0;0;0;0;0;2.22;0;[];['    compare_ops(const OperatorDef & p_op,const OperatorDef & g_op,bool arg_match)', '    GetPatternTraversalOrder(const transform::Graph & graph)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int g_idx)', '    ReplaceRule(const std::vector & match,transform::Graph *g_ptr)', '    ValidatorRule(const transform::Graph &,const std::vector & subgraph)'];
normalization.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 191;  91; 38;9;  55; 0;0;0;0;0;1.65;0;['    PatternNetTransform'];['    DisableArgumentMatching', '    EnableArgumentMatching', '    GetPatternTraversalOrder(const transform::Graph & graph)', '    PatternNetTransform(const NetDef & pattern_net,const NetDef & replace_net)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int g_idx)', '    ReplaceRule(const std::vector & match,transform::Graph *g_ptr)', '    TransformBlobWrapper(const string & blob_name)', '    ValidatorRule(const transform::Graph &,const std::vector & subgraph)'];
padding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 311;  168; 52;5;  88; 0;0;0;0;0;1.91;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUDummyCounterOp3', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp1', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp2', '    CAFFE_ANONYMOUS_VARIABLE_CUDADummyCounterOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DummyCounterOp3', '    TEST(PatternNetTransformTest,TestGenerateTransform)', '    TEST(PatternNetTransformTest,TestRepeatedTransform)', '    TEST(PatternNetTransformTest,TestHardTransform)', '    TEST(PatternNetTransformTest,TestGeneralStringMatching)', '    TEST(PatternNetTransformTest,TestDeviceOptionMatching)', '    TEST(PatternNetTransformTest,TestEngineMatching)', '    TEST(PatternNetTransformTest,TestSingularArgumentMatching)', '    TEST(PatternNetTransformTest,TestNonStrictTopographicTransform)', '    TEST(PatternNetTransformTest,TestMultiInputOutputTransform)', '    Run(int)'];
pooling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 711;  367; 118;7;  221; 0;0;0;0;0;1.66;0;[];['    mustBeEqual(const c10::optional & a,const c10::optional & b)', '    check_none_index', '    PeepholeOptimize(const std::shared_ptr & graph,bool addmm_fusion_enabled)', '    PeepholeOptimizeImpl(const std::shared_ptr & graph,bool onnx_export)', '    run(Block *block)', '    runAliasingSensitivePeepholeTransformations(Node *node)', '    safeToChangeAliasingRelationship(Node *node)'];
rnn.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 362;  127; 69;14;  156; 0;0;0;0;0;0.81;0;[];['    convertDynamicUnbindToSplitToSequence(Block *b,int opset_version)', '    convertSplitToDynamic(Block *b,int opset_version)', '    convertUnbindToSplit(Block *b,int opset_version)', '    fuseListConstructListUnpack(Block *b)', '    fuseSplitToSequenceListUnpack(Block *b)', '    fuseSplitListUnpack(Block *b)', '    fuseUnbindListUnpack(Block *b)', '    eraseListConstruct(Block *block,int opset_version)', '    isSafeToSpeculate(Node *n)', '    replaceInputWithList(Node *node,size_t i,ArrayRef to)', '    speculateOps(Block *block)', '    PeepholeOptimizeONNX(std::shared_ptr & graph,int opset_version,bool fixed_batch_size)', '    removeMaxPoolUnusedOutput(Block *b)', '    i', '    composeTransposes(const std::vector & t1,const std::vector & t2)', '    eliminateNopTranspose(Block *b)', '    fixDefaultLstmCellState(Block *b,int opset_version)', '    fixDefaultRnnHiddenState(Block *b,int opset_version)', '    fixDefaultRNNState(Graph *graph,Node *n,int input_index,int opset_version)', '    fuseBroadcast(Block *b)', '    fuseConsecutiveTransposes(Block *b)', '    fuseTransposeIntoGemm(Block *b)', '    fusibleExpandTo(at::IntArrayRef from,at::IntArrayRef to)', '    getBroadcastPositions(Node *node)', '    hackFixupPadPackedShapes(Block *graph)', '    isNopTranspose(const std::vector & perm)', '    isRNN(const Node *node)', '    pushPackingPastRnn(Block *b)', '    removeNopPacking(Block *graph)'];
upsampling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 54;  22; 12;9;  13; 0;0;0;0;0;1.69;0;[];['    PeepholeOptimize(const std::shared_ptr & graph,bool addmm_fusion_enabled)', '    PeepholeOptimize(Block *block,bool addmm_fusion_enabled)'];
options.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 15;  0; 1;14;  0; 0;0;0;0;0;0.00;0;[];['    PeepholeOptimizeONNX(std::shared_ptr & graph,int opset_version,bool fixed_batch_size)'];
activation.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 673;  368; 135;4;  191; 0;0;0;0;0;1.93;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUPercentile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Percentile', '    RunOnDevice'];
adaptive.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 37;  15; 9;4;  12; 0;0;0;0;0;1.25;0;['    final'];['    PercentileOp(Args,...)', '    RunOnDevice'];
conv.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 382;  202; 72;6;  107; 0;0;0;0;0;1.89;0;['    C10FlagParser_aiBench_netFollowupSampleCount', '    C10FlagParser_aiBench_netFollowupSampleRate', '    C10FlagParser_aiBench_netInitSampleRate', '    C10FlagParser_aiBench_operatorNetSampleRatio', '    C10FlagParser_aiBench_skipIters'];['    registerGlobalPerfNetObserverCreator(int *,char ***)', '    getCpuMilliseconds', '    getCpuTimeMilliseconds', '    getTensorShapes', '    getTicksPerMillisecond', '    getWallClockTimeMilliseconds', '    getWallMilliseconds', '    PerfOperatorObserver(OperatorBase *op,PerfNetObserver *netObserver)', '    Start', '    Stop', '    ~PerfOperatorObserver', '    C10FlagParser_aiBench_netFollowupSampleCount(const std::string & content)', '    C10FlagParser_aiBench_netFollowupSampleRate(const std::string & content)', '    C10FlagParser_aiBench_netInitSampleRate(const std::string & content)', '    C10FlagParser_aiBench_operatorNetSampleRatio(const std::string & content)', '    C10FlagParser_aiBench_skipIters(const std::string & content)', '    getObserverName(const OperatorBase *op,int idx)', '    PerfNetObserver(NetBase *subject_)', '    Start', '    Stop', '    ~PerfNetObserver'];
distance.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 69;  42; 8;4;  19; 0;0;0;0;0;2.21;0;['    PerfNetObserver', '    PerfOperatorObserver'];['    getClockTimeMilliseconds', '    getObserverName(const OperatorBase *op,int idx)', '    PerfNetObserver(NetBase *subject_)', '    Start', '    Stop', '    ~PerfNetObserver', '    getCpuMilliseconds', '    getTensorShapes', '    getWallMilliseconds', '    PerfOperatorObserver(OperatorBase *op,PerfNetObserver *netObserver)', '    Start', '    Stop', '    ~PerfOperatorObserver'];
dropout.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 128;  73; 23;4;  32; 0;0;0;0;0;2.28;0;[];['    registerer'];
fold.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 98;  52; 17;5;  28; 0;0;0;0;0;1.86;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUPerplexity', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Perplexity', '    RunOnDevice'];
instancenorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 85;  37; 21;5;  26; 0;0;0;0;0;1.42;0;['    final'];['    PerplexityOp(Args,...)', '    RunOnDevice', '    ~PerplexityOp'];
linear.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 64;  31; 10;4;  21; 0;0;0;0;0;1.48;0;['    philox_engine'];['    incr', '    incr_n(uint64_t n)', '    mulhilo32(uint32_t a,uint32_t b,uint32_t *result_high)', '    operator()', '    philox_engine(uint64_t seed,uint64_t subsequence,uint64_t offset)', '    single_round(detail::UINT4 ctr,detail::UINT2 in_key)'];
normalization.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 189;  96; 39;5;  60; 0;0;0;0;0;1.60;0;['    VectorReader'];['    pickle(const IValue & ivalue,std::vector *tensor_table)', '    pickle(std::function writer,const IValue & ivalue,std::vector *tensor_table)', '    pickle_load(const std::vector & data)', '    pickle_save(const at::IValue & ivalue)', '    unpickle(const char *data,size_t size,TypeResolver type_resolver,const std::vector *tensor_table)', '    unpickle(std::function reader,TypeResolver type_resolver,const std::vector *tensor_table)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    VectorReader(const std::vector & data)'];
padding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 174;  94; 31;7;  45; 0;0;0;0;0;2.09;0;[];[];
pixelshuffle.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 39;  20; 6;4;  12; 0;0;0;0;0;1.67;0;[];['    swapDouble(double value)', '    checkHasValidSetGetState(const std::shared_ptr & cls)', '    getTypeTags', '    getWriteableTensorData(const at::Tensor & tensor)', '    endTuple', '    endTypeTag(const IValue & ivalue)', '    protocol', '    pushBinGet(uint32_t memo_id)', '    pushBool(bool value)', '    pushBytes(const std::string & string)', '    pushDevice(const IValue & ivalue)', '    pushDict(const IValue & ivalue)', '    pushDouble(double value)', '    pushGenericList(const IValue & ivalue)', '    pushGlobal(const std::string & module_name,const std::string & class_name)', '    pushInt(int64_t n)', '    pushIValue(const IValue & ivalue)', '    pushIValueImpl(const IValue & ivalue)', '    pushLiteralTensor(const IValue & ivalue)', '    pushLong(const std::string & data)', '    pushNextBinPut', '    pushSpecializedList(const IValue & ivalue,const char *list_name,const std::function & item_pusher)', '    pushStorageOfTensor(const at::Tensor & tensor)', '    pushString(const std::string & string)', '    pushStringImpl(const std::string & string)', '    pushTensor(const IValue & ivalue)', '    pushTensorReference(const IValue & ivalue)', '    pushTuple(const IValue & ivalue)', '    startTuple', '    startTypeTag', '    stop', '    ~Pickler'];
rnn.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 219;  108; 26;5;  84; 0;0;0;0;0;1.29;0;[];[];
upsampling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 99;  46; 16;8;  32; 0;0;0;0;0;1.44;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUPiecewiseLinearTransform', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PiecewiseLinearTransform'];
vision.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 33;  13; 5;5;  13; 0;0;0;0;0;1.00;0;['    final'];['    schema_PiecewiseLinearTransform', '    bounds_device_', '    CheckBoundsSorted(const T *bounds,const int64_t num_bounds_per_group,const int64_t num_group)', '    CheckTransParamFromArg', '    GetRepeatedArgument', '    GetSingleArgument', '    GetTransParamData(const T **bounds,const T **slopes,const T **intercepts,int64_t *num_func_per_group,int64_t *num_group)', '    InferNumFunctionsPerGroup(const int64_t num_bounds,const int64_t num_slopes,const int64_t num_intercepts,int64_t *num_func_per_group,int64_t *num_group)', '    intercepts_device_', '    PiecewiseLinearTransform(const T x,const T *bounds,const T *slopes,const T *intercepts,const int64_t num_func_per_group)', '    PiecewiseLinearTransformOp(Args,...)', '    RunOnDevice', '    setUpTensors(int64_t & num_func_per_group,int64_t & num_group,int64_t M)', '    slopes_device_', '    TransformBinary', '    TransformGeneral'];
pimpl-inl.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 74;  26; 13;0;  35; 0;0;0;0;0;0.74;0;[];[];
pimpl.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 202;  57; 31;16;  104; 0;0;0;0;0;0.55;0;[];[];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 5;  0; 1;4;  0; 0;0;0;0;0;0.00;0;[];['    getPinnedMemoryAllocator'];
convert_parameters.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/utils; 77;  19; 14;3;  46; 0;0;0;0;0;0.41;0;[];['    getPinnedMemoryAllocator'];
rnn.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/utils; 346;  153; 24;2;  173; 0;0;0;0;0;0.88;0;[];['    pixel_shuffle(const Tensor & self,int64_t upscale_factor)'];
optim.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 8;  0; 1;7;  0; 0;0;0;0;0;0.00;0;[];['    forward(const Tensor & input)', '    PixelShuffleImpl(const PixelShuffleOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset'];
adam.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 75;  4; 10;7;  58; 0;0;0;0;0;0.07;0;[];[];
lbfgs.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 89;  2; 10;10;  69; 0;0;0;0;0;0.03;0;[];[];
optimizer.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 181;  44; 37;13;  93; 0;0;0;0;0;0.47;0;[];[];
serialize.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 275;  25; 30;47;  179; 0;0;0;0;0;0.14;0;['    C10FlagParser_caffe2_handle_executor_threads_exceptions', '    CompiledGuard'];['    getContinuationTest(Workspace *,const ExecutionStep & step)', '    ExecuteStepRecursive(ExecutionStepWrapper & stepWrapper)', '    getShouldStop(const Blob *b)', '    next_substep', '    reportWorker', '    RunPlanOnWorkspace(Workspace *ws,const PlanDef & plan,ShouldContinue shouldContinue)', '    worker', '    C10FlagParser_caffe2_handle_executor_threads_exceptions(const std::string & content)', '    done', '    ReporterInstance(int intervalMillis,bool *done,std::function)', '    start(int64_t intervalMillis,std::function)', '    ~Reporter', '    CompiledExecutionStep(const ExecutionStep *mainStep,Workspace *externalWorkspace,ShouldContinue externalShouldContinue,NetDefMap *netDefs,WorkspaceIdInjector *ws_id_injector)', '    gotFailure', '    shouldStop', '    compiled', '    CompiledGuard', '    operator->', '    reset(std::unique_ptr)', '    reset(CompiledExecutionStep *compiledRef)', '    doCompile', '    ExecutionStepWrapper(const ExecutionStep *step,Workspace *externalWorkspace,ShouldContinue externalShouldContinue,NetDefMap *netDefs,WorkspaceIdInjector *ws_id_injector)', '    step', '    InjectWorkspaceId(Workspace *workspace)', '    seq_', '  Static Member Variables', '    GLOBAL_WORKSPACE_ID', '    NODE_ID'];
sgd.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 73;  4; 12;10;  51; 0;0;0;0;0;0.08;0;[];['    RunPlanOnWorkspace(Workspace *ws,const PlanDef & plan,ShouldContinue)'];
ordered_dict.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 507;  102; 97;7;  303; 0;0;0;0;0;0.34;0;[];['    make_unique(Args,...)'];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/python; 10;  3; 2;2;  5; 0;0;5;0;3;0.60;0;['    FuseCastBatchOneHot'];['    fuseCastBatchOneHot(NNModule *nn)', '    run'];
serialize.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 145;  93; 9;5;  39; 0;0;0;0;0;2.38;0;[];['    fuseCastBatchOneHot(NNModule *nn)'];
archive.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/serialize; 4;  0; 1;3;  0; 0;0;0;0;0;0.00;0;[];['    torch_warn_once_74', '    addcdiv(const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcdiv_(Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcdiv_out(Tensor & result,const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul(const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul_(Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)', '    addcmul_out(Tensor & result,const Tensor & self,const Tensor & tensor1,const Tensor & tensor2,Scalar value)'];
output-archive.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/serialize; 80;  21; 16;7;  41; 0;0;0;0;0;0.51;0;[];['    addcdiv_stub', '    addcdiv_stub', '    operator=', '    addcmul_stub', '    addcmul_stub', '    operator=', '    mse_backward_stub', '    mse_backward_stub', '    operator=', '    operator=', '    smooth_l1_backward_stub', '    smooth_l1_backward_stub'];
tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/serialize; 20;  1; 3;3;  14; 0;0;0;0;0;0.07;0;[];['    addcdiv_cpu_kernel(TensorIterator & iter,Scalar value)', '    addcmul_cpu_kernel(TensorIterator & iter,Scalar value)', '    mse_backward_cpu_kernel(TensorIterator & iter,Scalar value)', '    smooth_l1_backward_cpu_kernel(TensorIterator & iter,Scalar norm)'];
torch.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 8;  1; 2;5;  0; 2;0;0;0;0;0.00;0;[];['    avg_pool2d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,int64_t nbatch,int kH,int kW,int dH,int dW,int padH,int padW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth)', '    avg_pool3d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth)', '    max_pool2d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,int64_t nbatch,int kH,int kW,int dH,int dW,int padH,int padW,int dilationH,int dilationW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth,bool cuda)', '    max_pool3d_backward_shape_check(const Tensor & input,const Tensor & gradOutput,const Tensor & indices,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int dilationT,int dilationH,int dilationW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth)', '    pool2d_shape_check(const Tensor & input,int kH,int kW,int dH,int dW,int padH,int padW,int dilationH,int dilationW,int64_t nInputPlane,int64_t inputHeight,int64_t inputWidth,int64_t outputHeight,int64_t outputWidth)', '    pool3d_shape_check(const Tensor & input,int64_t nslices,int kT,int kH,int kW,int dT,int dH,int dW,int pT,int pH,int pW,int dilationT,int dilationH,int dilationW,int64_t itime,int64_t iheight,int64_t iwidth,int64_t otime,int64_t oheight,int64_t owidth,bool check_input_size)', '    pooling_output_shape(T inputSize,T kernelSize,T pad,T stride,T dilation,bool ceil_mode)', '    pooling_output_shape_pad_lr(T inputSize,T kernelSize,T pad_l,T pad_r,T stride,T dilation,bool ceil_mode)', '    safe_downcast(src_t)', '    ndimension', '    numel'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 35;  8; 11;5;  12; 0;0;0;0;0;0.67;0;['    AveragePool', '    final', '    final', '    MaxPool'];['    finalize(const int size,T & y_data)', '    initialize', '    process(const int x_col,const int y_col,ConstEigenMatrixMap & x_mat,EigenMatrixMap & y_mat)', '    process(const T & x_data,T & y_data)', '    finalize(const int,T &)', '    initialize', '    process(const int x_col,const int y_col,ConstEigenMatrixMap & x_mat,EigenMatrixMap & y_mat)', '    process(const T & x_data,T & y_data)', '    AveragePoolDnnLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolDnnLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC'];
cuda.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src; 25;  6; 5;3;  13; 0;3;7;3;5;0.46;3;[];['    average_pool_3d_avx2(const uint8_t *Xdata,int n,int height,int width,int depth,int channels,int pooled_height,int pooled_width,int pooled_depth,int kernel_h,int kernel_w,int kernel_d,int stride_h,int stride_w,int stride_d,int pad_t,int pad_l,int pad_d,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    average_pool_avx2(const uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    max_pool_avx2(const uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,uint8_t *Ydata)'];
mnist.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/data/datasets; 125;  7; 24;8;  90; 0;52;46;35;37;0.08;13;[];['    average_pool_3d_avx2(const uint8_t *Xdata,int n,int height,int width,int depth,int channels,int pooled_height,int pooled_width,int pooled_depth,int kernel_h,int kernel_w,int kernel_d,int stride_h,int stride_w,int stride_d,int pad_t,int pad_l,int pad_d,uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    average_pool_avx2(const std::uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,std::uint8_t *Ydata,float in_scale,float out_scale,int32_t in_zero_point,int32_t out_zero_point,int32_t minimum,int32_t maximum)', '    max_pool_avx2(const std::uint8_t *Xdata,int n,int height,int width,int channels,int pooled_height,int pooled_width,int kernel_h,int kernel_w,int stride_h,int stride_w,int pad_t,int pad_l,std::uint8_t *Ydata)'];
random.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/data/samplers; 75;  15; 9;6;  53; 0;27;20;8;49;0.28;5;['    GetPoolGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePoolGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool1DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool2DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool3DGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool1DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool2DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool3DGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPoolGradient', '    ComputeAveragePoolGradient1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient2D(const int W,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient2D(const int,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeAveragePoolGradient3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & dY_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient1D(const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient1D(const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient2D(const int W,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient2D(const int,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    ComputeMaxPoolGradient3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & dY_arr,const ConstEigenArrayMap & X_arr,const ConstEigenArrayMap & Y_arr,EigenArrayMap *dX_arr)', '    RunAveragePoolGradient1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const bool count_include_pad,const T *dY,T *dX)', '    RunAveragePoolGradient2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const bool count_include_pad,const T *dY,T *dX)', '    RunAveragePoolGradient3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const bool count_include_pad,const T *dY,T *dX)', '    RunMaxPoolGradient1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const T *dY,const T *X,const T *Y,T *dX)', '    RunMaxPoolGradient2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const T *dY,const T *X,const T *Y,T *dX)', '    RunMaxPoolGradient3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const T *dY,const T *X,const T *Y,T *dX)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector &,const std::vector & stride,const std::vector & pads,const T *dY,const T *,const T *,T *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *,const float *,float *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *,const float *,float *dX,CPUContext *)', '    GetGradientDefs', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector &,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *X,const float *Y,float *dX,CPUContext *)', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const float *dY,const float *X,const float *Y,float *dX,CPUContext *)', '    vector'];
sequential.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/data/samplers; 55;  5; 8;6;  41; 0;16;16;7;26;0.12;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePool3D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool1D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool2D', '    CAFFE_ANONYMOUS_VARIABLE_CPUMaxPool3D', '    AveragePoolDocGenerator(const char *dim)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePool3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool1D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool2D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MaxPool3D', '    ComputeAveragePool1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool1D(const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool2D(const int W,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool2D(const int,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeAveragePool3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const float scale,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool1D(const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool1D(const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool2D(const int W,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool2D(const int,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool3D(const int H,const int W,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    ComputeMaxPool3D(const int H,const int,const int p,const int a,const int t,const int b,const int l,const int r,const int y,const ConstEigenArrayMap & X_arr,EigenArrayMap *Y_arr)', '    MaxPoolDocGenerator(const char *dim)', '    RunAveragePool1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const bool count_include_pad,const T *X,T *Y)', '    RunAveragePool2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const bool count_include_pad,const T *X,T *Y)', '    RunAveragePool3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const bool count_include_pad,const T *X,T *Y)', '    RunMaxPool1D(const int N,const int C,const int X_size,const int Y_size,const int kernel,const int stride,const int pad,const T *X,T *Y)', '    RunMaxPool2D(const int N,const int C,const int X_H,const int X_W,const int Y_H,const int Y_W,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const T *X,T *Y)', '    RunMaxPool3D(const int N,const int C,const int X_D,const int X_H,const int X_W,const int Y_D,const int Y_H,const int Y_W,const int kernel_d,const int kernel_h,const int kernel_w,const int stride_d,const int stride_h,const int stride_w,const int pad_p,const int pad_t,const int pad_l,const T *X,T *Y)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const float *X,float *Y,CPUContext *)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *context)'];
stream.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/data/samplers; 61;  5; 10;5;  46; 0;23;15;18;12;0.11;8;['    final', '    final'];['    IDEEPPoolGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    ~IDEEPPoolGradientOp', '    ~IDEEPPoolOp'];
jit.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src; 23;  2; 5;5;  13; 0;7;6;2;4;0.15;1;['    final', '    final'];['    AveragePoolFunctor(const OperatorBase & op)', '    Backward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    Forward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,Context *context)', '    GlobalPoolingBackward(int N,int C,int HxW,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    GlobalPoolingForward(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    ones', '    PoolGradientOp(Args,...)', '    PoolOp(Args,...)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC', '    ~PoolGradientOp', '    ~PoolOp', '    Backward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    Forward(int N,int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,Context *context)', '    GlobalPoolingBackward(int N,int C,int HxW,const T *dY,const T *X,const T *Y,T *dX,Context *context)', '    GlobalPoolingForward(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    MaxPoolFunctor(const OperatorBase &)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn; 249;  16; 42;9;  194; 0;97;87;74;70;0.08;17;['    final', '    final'];['    SetTensorDescriptor(const cudnnDataType_t data_type,const StorageOrder order,const std::vector & dims,cudnnTensorDescriptor_t *desc)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    CuDNNAveragePoolFunctor(const OperatorBase & op)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,CUDAContext *context)', '    GetPoolingMode', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const T *X,T *Y,CUDAContext *context)', '    Backward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    CuDNNMaxPoolFunctor(const OperatorBase & op)', '    Forward(const int N,const int C,const std::vector & X_dims,const std::vector & Y_dims,const std::vector & kernel,const std::vector & dilation,const std::vector & stride,const std::vector & pads,const T *X,T *Y,CUDAContext *context)', '    GetPoolingMode', '    GlobalPoolingBackward(const int N,const int C,const int HxW,const T *dY,const T *X,const T *Y,T *dX,CUDAContext *context)', '    GlobalPoolingForward(const int N,const int C,const int HxW,const T *X,T *Y,CUDAContext *context)', '    CuDNNPoolGradientOp(Args,...)', '    CuDNNPoolOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    ~CuDNNPoolGradientOp', '    ~CuDNNPoolOp'];
module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn; 414;  30; 44;12;  345; 0;144;118;117;117;0.09;36;['    AveragePool', '    final', '    final', '    MaxPool', '    MaxPoolGradientRTCFunction', '    MaxPoolRTCFunction'];['    MaxPoolGradientRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    MaxPoolRTCOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDeviceWithOrderNHWC', '    ~MaxPoolGradientRTCOp', '    ~MaxPoolRTCOp', '    GetSource(const int output_size,const int num,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l)', '    KernelName(Args,...)', '    MaxPoolGradientRTCFunction', '    GetSource(const int output_size,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int kernel_h,const int kernel_w,const int stride_h,const int stride_w,const int pad_t,const int pad_l)', '    KernelName(Args,...)', '    MaxPoolRTCFunction'];
activation.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 509;  52; 120;3;  362; 0;175;111;120;97;0.14;93;[];['    IsNeon2x2p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    IsNeon4x4p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    RunNeonAveragePool4x4p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)', '    RunNeonMaxPool2x2p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)'];
adaptive.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 166;  2; 36;3;  127; 0;80;63;48;54;0.02;9;[];['    IsNeon2x2p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    IsNeon4x4p0s0Eligible(const int input_h,const int input_w,const int output_h,const int output_w,const int kh,const int kw,const int stride_h,const int stride_w,const int pad_t,const int pad_l,const int pad_b,const int pad_r,const int dilation_h,const int dilation_w,const float *X,float *Y)', '    RunNeonAveragePool4x4p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)', '    RunNeonMaxPool2x2p0s0NCHW(int N,int C,int H,int W,const float *X,float *Y)'];
batchnorm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 53;  2; 11;9;  33; 0;10;10;7;10;0.06;4;[];['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compareMaxPooling(int N,int C,int H,int W,int kernelH,int kernelW,int strideH,int strideW,int padT,int padL,int padB,int padR,float maxRelErr,float absErrForRelErrFailure)', '    randInt(int a,int b)', '    runMaxPool(int kernel,int stride,int pad)', '    TEST(PoolOp,MaxPool2x2s2p0Randomized)', '    TEST(PoolOp,MaxPool4x4s3p2Randomized)', '    TEST(PoolOp,MaxPool2x2s2p0Special)', '    TEST(PoolOp,MaxPoolFullyRandomized)'];
conv.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 292;  24; 32;13;  246; 0;101;128;51;40;0.10;15;[];[];
distance.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 44;  3; 12;1;  30; 0;11;15;4;11;0.10;8;[];['    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    AvgPoolImpl(const AvgPoolOptions & options_)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    FractionalMaxPool2dImpl(const FractionalMaxPool2dOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    FractionalMaxPool3dImpl(const FractionalMaxPool3dOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward(const Tensor & input)', '    LPPoolImpl(const LPPoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    forward(const Tensor & input)', '    forward_with_indices(const Tensor & input)', '    MaxPoolImpl(const MaxPoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    forward(const Tensor & input,const Tensor & indices,const c10::optional)', '    MaxUnpoolImpl(const MaxUnpoolOptions & options_)', '    pretty_print(std::ostream & stream)', '    reset'];
dropout.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 79;  8; 20;7;  48; 0;23;15;10;13;0.17;10;[];['    _mkldnn_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode,ideep::algorithm algo)', '    mkldnn_adaptive_avg_pool2d(Tensor const & input,IntArrayRef output_size)', '    mkldnn_adaptive_avg_pool2d_out(Tensor & output,const Tensor & input,IntArrayRef output_size)', '    mkldnn_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    mkldnn_avg_pool2d_out(Tensor & output,const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    mkldnn_max_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)'];
fold.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 54;  3; 13;4;  36; 0;19;13;4;11;0.08;8;[];['    check1d(const char *function_name,const char *argument_name,IntArrayRef x)', '    adaptive_avg_pool1d(const Tensor & self,IntArrayRef output_size)', '    adaptive_max_pool1d(const Tensor & self,IntArrayRef output_size)', '    avg_pool1d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad)', '    max_pool1d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool1d_with_indices(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool2d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    max_pool3d(const Tensor & self,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)'];
instancenorm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 57;  3; 8;2;  47; 0;15;10;13;10;0.06;4;[];[];
linear.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 117;  8; 27;7;  80; 0;39;25;27;23;0.10;17;[];[];
normalization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 124;  11; 25;6;  90; 0;49;23;28;20;0.12;17;[];[];
padding.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 97;  5; 26;2;  66; 0;12;36;7;37;0.08;14;[];['    pow(const Tensor & base,const Tensor & exp)', '    pow(const Tensor & base,Scalar exp)', '    pow(Scalar base,const Tensor & exp)', '    pow_(Tensor & base,const Tensor & other)', '    pow_(Tensor & base,Scalar alpha)', '    pow_out(Tensor & result,const Tensor & base,const Tensor & exp)', '    pow_out(Tensor & result,const Tensor & base,Scalar exp)', '    pow_out(Tensor & result,Scalar base,const Tensor & exp)'];
pixelshuffle.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 25;  2; 7;1;  17; 0;3;12;2;7;0.12;4;[];['    operator=', '    pow_tensor_scalar_stub', '    pow_tensor_scalar_stub', '    operator=', '    pow_tensor_tensor_stub', '    pow_tensor_tensor_stub'];
rnn.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 783;  44; 107;16;  629; 0;305;301;151;389;0.07;41;['    GetPowGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPow', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Pow', '    vector', '    vector', '    vector', '    vector', '    Run(size_t n,const T1 *a,const T2 *b,T2 e,R *out,CPUContext *)', '    RunWithBroadcast(const T1 *a,const T2 *b,R *out,size_t pre,size_t n,CPUContext *)', '    RunWithBroadcast2(const T1 *a,const T2 *b,R *out,size_t pre,size_t n,size_t post,CPUContext *)', '    CopyArguments', '    GetGradientDefs', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector', '    vector'];
upsampling.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 49;  3; 9;2;  38; 0;24;10;17;7;0.08;4;['    PowOp'];['    DoRunWithType', '    PowOp(Args,...)', '    RunOnDevice'];
activation.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 55;  3; 17;1;  37; 0;0;37;0;17;0.08;14;[];['    assert_eq(T val,T act,T exp)', '    assert_eq(T val,T act,T exp)', '    doubles', '    floats', '    ints', '    longs', '    non_neg_ints', '    non_neg_longs', '    scalar_pow_tensor(const Vals vals,c10::ScalarType vals_dtype,const Pows pows,c10::ScalarType pows_dtype)', '    tensor_pow_scalar(const Vals vals,c10::ScalarType vals_dtype,const Pows pows,c10::ScalarType pows_dtype)', '    tensor_pow_tensor(const Vals vals,c10::ScalarType vals_dtype,Pows pows,c10::ScalarType pows_dtype)', '    TEST(PowTest,IntTensorPowAllScalars)', '    TEST(PowTest,DISABLED_LongTensorPowAllScalars)', '    TEST(PowTest,FloatTensorPowAllScalars)', '    TEST(PowTest,DoubleTensorPowAllScalars)', '    TEST(PowTest,IntScalarPowAllTensors)', '    TEST(PowTest,LongScalarPowAllTensors)', '    TEST(PowTest,FloatScalarPowAllTensors)', '    TEST(PowTest,DoubleScalarPowAllTensors)', '    TEST(PowTest,IntTensorPowIntTensor)', '    TEST(PowTest,LongTensorPowLongTensor)', '    TEST(PowTest,FloatTensorPowFloatTensor)', '    TEST(PowTest,DoubleTensorPowDoubleTensor)'];
batchnorm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];['    pow_tensor_scalar_kernel(TensorIterator & iter,Scalar exp_scalar)', '    pow_tensor_tensor_kernel(TensorIterator & iter)'];
conv.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 23;  3; 7;1;  15; 0;0;6;0;12;0.20;0;[];['    pytorch_qnnp_requantize_precise__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
dropout.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];[];
instancenorm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];['    pytorch_qnnp_requantize_precise__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
linear.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 13;  2; 4;1;  8; 0;0;8;0;4;0.25;2;[];[];
normalization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 22;  3; 9;1;  12; 0;0;12;0;8;0.25;5;[];[];
pooling.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 30;  2; 8;1;  21; 0;0;4;0;19;0.10;0;[];['    pytorch_qnnp_requantize_precise__scalar_signed64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned32(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
rnn.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 39;  4; 14;1;  24; 0;0;24;0;12;0.17;8;[];[];
vision.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_qnnp_requantize_precise__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
adam.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 169;  12; 22;8;  131; 0;87;60;106;67;0.09;10;[];['    pytorch_qnnp_requantize_precise__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
lbfgs.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 594;  93; 60;10;  448; 0;340;163;310;167;0.21;19;[];[];
optimizer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 176;  4; 31;7;  136; 0;51;44;59;42;0.03;28;[];['    pytorch_qnnp_requantize_precise__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
serialize.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 54;  2; 6;8;  40; 0;9;27;9;13;0.05;4;[];[];
sgd.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 126;  4; 15;9;  101; 0;61;46;72;50;0.04;10;[];['    enforceIsTensor(Workspace *ws,const std::string & name)', '    getBlob(Workspace *ws,const std::string & name)', '    getTensor(Workspace *ws,const std::string & name)', '    initialized', '    operator()(const TensorList & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorMap *outputs)', '    Predictor(PredictorConfig config)', '    Predictor(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)', '    run_map_workspace(const TensorMap & inputs)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/python; 75;  7; 10;22;  41; 0;25;15;17;29;0.17;6;[];['    loadModel(const std::string & path)', '    main(int argc,const char *[] argv)', '    output', '    no_autograd_guard', '    no_optimizer_guard', '    non_var_guard'];
input-archive.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/serialize; 172;  9; 19;11;  141; 0;52;58;46;36;0.06;18;['    Predictor'];['    def', '    input_names', '    operator()(const TensorList & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorList *outputs)', '    operator()(const TensorMap & inputs,TensorMap *outputs)', '    output_names', '    Predictor(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)', '    Predictor(PredictorConfig config)', '    run_map_workspace(const TensorMap & inputs)', '    ws', '    ~Predictor'];
output-archive.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/serialize; 51;  3; 11;9;  31; 0;6;19;6;9;0.10;7;[];['    warningEmitted', '    getBlobs(const MetaNetDef & def,const std::string & name)', '    getNet(const MetaNetDef & def,const std::string & name)', '    makePredictorConfig(const MetaNetDef & def,Workspace *parent,bool run_init)', '    makePredictorConfig(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)'];
anomaly_mode.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 9;  0; 4;1;  4; 0;2;4;0;4;0.00;0;[];['    makePredictorConfig(const MetaNetDef & net,Workspace *parent,bool run_init)', '    makePredictorConfig(const NetDef & init_net,const NetDef & run_net,Workspace *parent,bool run_init,int optimization)'];
autograd.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 145;  11; 8;5;  124; 0;57;50;47;29;0.09;4;['    PredictorTest'];['    parseMetaNetDef(const std::string & value)', '    parseNetDef(const std::string & value)', '    randomTensor(const std::vector & dims,CPUContext *ctx)', '    TEST_F(PredictorTest,SimpleBatchSized)', '    TEST_F(PredictorTest,SimpleBatchSizedMapInput)', '    SetUp'];
autograd.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 26;  4; 5;3;  16; 0;0;0;0;0;0.25;0;[];['    extractMetaNetDef(db::Cursor *cursor,const std::string & key)', '    getNet(const MetaNetDef & def,const std::string & name)', '    runGlobalInitialization(std::unique_ptr db,Workspace *master)'];
cpp_hook.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 43;  3; 5;3;  33; 0;15;15;14;12;0.09;3;[];['    extractMetaNetDef(db::Cursor *cursor,const std::string & key)', '    getBlobs(const MetaNetDef & def,const std::string & name)', '    getNet(const MetaNetDef & def,const std::string & name)', '    runGlobalInitialization(std::unique_ptr db,Workspace *master)'];
custom_function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 245;  32; 30;2;  183; 0;124;94;70;41;0.17;11;['    C10FlagParser_init_net', '    C10FlagParser_predict_net'];['    run', '    main(int argc,char **argv)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_predict_net(const std::string & content)'];
custom_function.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 316;  79; 44;6;  188; 0;0;0;0;0;0.42;0;['    PrefetchOperator'];['    CopyPrefetched', '    Finalize', '    Prefetch', '    PrefetchOperator(const OperatorDef & operator_def,Workspace *ws)', '    PrefetchWorker', '    Run(int)', '    ~PrefetchOperator'];
edge.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 56;  12; 12;5;  29; 0;6;17;6;19;0.41;6;[];['    add(const std::string & key,int64_t)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    joinKey(const std::string & key)', '    joinKeys(const std::vector & keys)', '    PrefixStore(const std::string & prefix,std::shared_ptr store)', '    set(const std::string & key,const std::vector & value)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)'];
engine.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 367;  111; 55;17;  188; 0;29;154;16;115;0.59;8;['    PrefixStore'];['    add(const std::string & key,int64_t)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    joinKey(const std::string & key)', '    joinKeys(const std::vector & keys)', '    PrefixStore(const std::string & prefix,std::shared_ptr store)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~PrefixStore'];
function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 92;  27; 14;11;  41; 0;20;14;17;13;0.66;6;['    GetPReluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUPRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
function.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 459;  173; 65;19;  205; 0;0;0;0;0;0.84;0;['    final', '    final'];['    PReluGradientOp(Args,...)', '    PReluOp(Args,...)', '    RunOnDevice'];
function_hook.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 26;  4; 7;4;  14; 0;4;10;2;12;0.29;0;[];['    PrePackingOpsFolder(script::Module & m,const PrePackingOpsFilterFn & is_foldable_op,const std::string & attr_prefix)'];
accumulate_grad.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 63;  17; 12;9;  28; 0;18;9;11;11;0.61;2;[];['    PrePackingOpsFolder(script::Module & m,const PrePackingOpsFilterFn & is_foldable_op,const std::string & attr_prefix)'];
accumulate_grad.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 123;  53; 10;5;  57; 0;32;18;16;9;0.93;2;[];['    PrepareDivisionForONNXOnBlock(Block *block)', '    PrepareDivisionForONNX(const std::shared_ptr & graph)'];
basic_ops.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 63;  4; 16;7;  36; 0;3;28;4;19;0.11;7;[];['    PrepareDivisionForONNX(const std::shared_ptr & graph)'];
comm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 132;  6; 19;12;  100; 0;44;41;28;90;0.06;6;[];['    PrepareListAppendAndInsertForONNX(Block *b)', '    PrepareListPopForONNX(Block *b)', '    FetchSliceAndSelect(const Node *index_put_node)', '    IsSameSource(const Node *n,const Node *m)', '    MergeSliceAndSelectToIndices(Graph *graph,Node *index_put_node,const std::vector & slice_and_select_nodes,Value *orig_data)', '    PrepareCopyForONNX(Block *block)', '    PrepareIndexPutForONNX(Block *block)', '    PrepareInplaceOpsForONNX(const std::shared_ptr & graph)', '    ReshapeToAdvancedIndexingFormat(Graph *graph,Node *index_put_node,std::unordered_map & dim_index_map)', '    SquashSliceAndSelect(Node *index_put_node)', '    CreateCompleteIndexTensor(Value *size,Node *insertBefore)', '    ConvertSelectToIndex(Value *index,Node *insertBefore)', '    ConvertSliceToIndex(Node *slice,Value *size,Node *insertBefore)', '    CreateSizeOfDim(Value *input,int64_t dim,Node *insertBefore)', '    ConvertedIndex(Value *index,c10::Symbol orig_node_kind)'];
comm.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 47;  2; 11;9;  27; 0;3;25;0;17;0.07;0;[];['    PrepareInplaceOpsForONNX(const std::shared_ptr & graph)'];
pybind.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 14;  1; 5;6;  3; 0;0;3;0;4;0.33;0;['    GetPrependDimGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUMergeDim', '    CAFFE_ANONYMOUS_VARIABLE_CPUPrependDim', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_MergeDim', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PrependDim', '    vector', '    CopyArguments', '    GetGradientDefs'];
tensor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 104;  14; 16;10;  68; 0;41;24;34;17;0.21;4;['    MergeDimOp', '    PrependDimOp'];['    MergeDimOp(Args,...)', '    RunOnDevice', '    GetSingleArgument', '    PrependDimOp(Args,...)', '    RunOnDevice'];
tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 44;  7; 10;9;  18; 0;1;16;0;13;0.39;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAMergeDim', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPrependDim'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 79;  6; 12;9;  52; 0;21;25;19;21;0.12;6;[];['    main(int,char **)'];
grad_mode.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 11;  0; 4;3;  4; 0;0;0;0;0;0.00;0;[];['    getPrintHandler', '    setPrintHandler(PrintHandler ph)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 163;  4; 26;8;  126; 0;95;46;172;72;0.03;11;[];['    getPrintHandler', '    setPrintHandler(PrintHandler ph)'];
input_buffer.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 45;  9; 11;8;  18; 0;4;16;1;12;0.50;2;['    C10FlagParser_schema'];['    HasDoc(const std::string & str)', '    HasSchema(const std::string & str)', '    main(int argc,char **argv)', '    C10FlagParser_schema(const std::string & content)'];
input_metadata.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 58;  8; 13;7;  31; 0;0;0;0;0;0.26;0;[];['    shouldUpdateMinEndTimePredicate', '    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    enqueueRecv(RecvWork work)', '    enqueueSend(SendWork work)', '    getMetrics', '    handleRecv(RecvWork & work)', '    handleSend(const SendWork & work)', '    hasPendingMessage', '    listenLoop', '    listenLoopInternal', '    markFutureWithError(Message & message)', '    markFutureWithError(int64_t id,std::string errorMsg)', '    pollTimedOutRPCs', '    processTimedOutFutures', '    send(const WorkerInfo & to,Message)', '    shutdown', '    start', '    sync', '    addData(uint64_t dataPoint)', '    AverageMetricsTracker(std::string key,uint64_t currentSum,uint64_t currentCount)', '    computeAverage', '    collectNames', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    join', '    increment(int dst)', '    MessageCounter(int worldSize)', '    snapshot', '    ProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout)', '    ~ProcessGroupAgent', '  Static Member Variables', '    kInfiniteTimeoutTimePoint'];
profiler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 338;  17; 34;8;  282; 0;195;65;116;50;0.06;15;['    ProcessGroupAgent', '    MessageCounter'];['    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    addData(uint64_t dataPoint)', '    AverageMetricsTracker(std::string key,uint64_t currentSum,uint64_t currentCount)', '    computeAverage', '    clientActiveCalls_', '    collectNames', '    enqueueRecv(RecvWork work)', '    enqueueSend(SendWork work)', '    FutureInfo(const std::shared_ptr & future,const steady_clock_time_point & endTime,int dstRank,const std::chrono::milliseconds timeout)', '    FutureInfo', '    getMetrics', '    getRPCRemainingTime(const std::chrono::milliseconds & rpcEndTime)', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    handleRecv(RecvWork & work)', '    handleSend(const SendWork & work)', '    hasPendingMessage', '    join', '    listenLoop', '    listenLoopInternal', '    markFutureWithError(Message & message)', '    markFutureWithError(int64_t id,std::string errorMsg)', '    increment(int dst)', '    MessageCounter(int worldSize)', '    snapshot', '    nextId', '    pollTimedOutRPCs', '    ProcessGroupAgent(std::string workerName,std::shared_ptr pg,int numSendRecvThreads,std::chrono::milliseconds rpcTimeout)', '    processTimedOutFutures', '    rpcRunning_', '    send(const WorkerInfo & to,Message)', '    serverActiveAsyncCalls_', '    serverActiveCalls_', '    shutdown', '    start', '    sync', '    ~ProcessGroupAgent', '    ProcessGroupRpcBackendOptions(int num_send_recv_threads,std::chrono::milliseconds rpc_timeout,std::string init_method)', '    RecvWork(const WorkerInfo & from,MessageType type,int64_t id,torch::Tensor)', '    SendWork(const WorkerInfo & to,Message)'];
profiler_cuda.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 86;  6; 8;5;  71; 0;34;25;25;23;0.08;10;[];['    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    ProcessGroup(int rank,int size)', '    abort', '    exception', '    finish(std::exception_ptr exception)', '    isCompleted', '    isSuccess', '    result', '    sourceRank', '    synchronize', '    wait', '    ~Work', '    ~ProcessGroup'];
python_anomaly_mode.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 63;  3; 11;9;  40; 0;22;9;18;9;0.07;2;['    ProcessGroup', '    Work'];['    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & data,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & data,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    getRank', '    getSize', '    ProcessGroup(int rank,int size)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    exception', '    finish(std::exception_ptr exception)', '    isCompleted', '    isSuccess', '    result', '    sourceRank', '    synchronize', '    wait', '    ~Work', '    ~ProcessGroup'];
python_anomaly_mode.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 32;  0; 7;5;  20; 0;6;10;5;10;0.00;3;['    AsyncAllgatherCoalescedWork', '    AsyncAllgatherWork', '    AsyncAllreduceCoalescedWork', '    AsyncAllreduceWork', '    AsyncBarrierWork', '    AsyncBroadcastWork', '    AsyncGatherWork', '    AsyncReduceWork', '    AsyncScatterWork', '    AsyncSparseAllreduceWork', '    SparseTensorMetadata', '    GlooStore'];['    band(void *c,const void *a,const void *b,size_t n)', '    bor(void *c,const void *a,const void *b,size_t n)', '    bxor(void *c,const void *a,const void *b,size_t n)', '    override', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    checkSingleTensor(std::vector & tensors)', '    checkTag(int32_t tag)', '    doesHostnameResolveToUsableAddress(const std::string & hostname)', '    setInput(O & opts,at::Tensor & tensor)', '    setInputs(O & opts,std::vector & tensors)', '    setOutput(O & opts,at::Tensor & tensor)', '    setOutput(O & opts,at::Tensor & tensor,std::vector & counts)', '    setOutputs(O & opts,std::vector & tensors)', '    toFunction(const ReduceOp & r)', '    allgather_coalesced', '    AsyncAllgatherCoalescedWork(const std::shared_ptr & context,std::vector,std::vector & input_list,uint32_t tag)', '    run', '    allgather(std::vector,std::vector & inputs)', '    AsyncAllgatherWork(const std::shared_ptr & context,std::vector,std::vector & inputs,uint32_t tag)', '    run', '    allreduceCoalesced(std::vector & tensors)', '    AsyncAllreduceCoalescedWork(const std::shared_ptr & context,std::vector & inputs,ReduceOp reduceOp,uint32_t tag)', '    run', '    allreduce(std::vector & tensors)', '    AsyncAllreduceWork(const std::shared_ptr & context,std::vector & inputs,ReduceOp reduceOp,uint32_t tag)', '    getFunction(gloo::AllreduceOptions::Func & fn,const ReduceOp op)', '    getFunction(const at::ScalarType & dtype,const ReduceOp op)', '    run', '    AsyncBarrierWork(const std::shared_ptr & context,std::vector,uint32_t tag)', '    run', '    AsyncBroadcastWork(const std::shared_ptr & context,std::vector & inputs,int rootRank,int rootTensor,uint32_t tag)', '    broadcast(at::Tensor & tensor)', '    run', '    AsyncGatherWork(const std::shared_ptr & context,std::vector,std::vector & inputs,int root,uint32_t tag)', '    gather(std::vector,std::vector & inputs)', '    run', '    AsyncReduceWork(const std::shared_ptr & context,std::vector & inputs,int rootRank,int rootTensor,ReduceOp reduceOp,uint32_t tag)', '    getFunction(gloo::ReduceOptions::Func & fn,const ReduceOp op)', '    getFunction(const at::ScalarType & dtype,const ReduceOp op)', '    reduce(std::vector & tensors)', '    run', '    AsyncScatterWork(const std::shared_ptr & context,std::vector & outputs,std::vector,int root,uint32_t tag)', '    run', '    scatter(std::vector & outputs,std::vector)', '    allgather_indices(const at::Tensor & tensor,const std::vector & metadata)', '    allgather_metadata(const at::Tensor & tensor)', '    allgather_values(const at::Tensor & tensor,const std::vector & metadata)', '    allreduce(std::vector & tensors)', '    AsyncSparseAllreduceWork(const std::shared_ptr & context,std::vector & inputs,uint32_t tag)', '    result', '    run', '    nnz', '    populate_from_sparse_tensor(const at::Tensor & tensor)', '    sizes', '    SparseTensorMetadata(at::Tensor metadata)', '    GlooStore(const std::shared_ptr & store)', '    Options', '    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector & input_list,const AllgatherOptions &)', '    allreduce(std::vector & inputs,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & inputs,const BroadcastOptions & opts)', '    enqueue(std::shared_ptr work)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    getContext(uint32_t tag)', '    nextTag', '    ProcessGroupGloo(const std::shared_ptr & store,int rank,int size,Options options)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & inputs,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    runLoop(int workerIndex)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupGloo', '    abort', '    RecvWork(at::Tensor & tensor,std::unique_ptr buffer)', '    sourceRank', '    wait', '    abort', '    SendWork(at::Tensor & tensor,std::unique_ptr buffer)', '    wait'];
python_cpp_function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 271;  5; 41;14;  213; 0;128;75;117;68;0.02;15;['    ProcessGroupGloo', '    AsyncWork', '    RecvWork', '    SendWork'];['    execute(std::shared_ptr work)', '    createDefaultDevice', '    createDeviceForHostname(const std::string & hostname)', '    createDeviceForInterface(const std::string & interface)', '    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & input_list,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    run', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    enqueue(std::shared_ptr work)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    getContext(uint32_t tag)', '    nextTag', '    Options', '    ProcessGroupGloo(const std::shared_ptr & store,int rank,int size,Options options)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    abort', '    RecvWork(at::Tensor & tensor,std::unique_ptr buffer)', '    sourceRank', '    wait', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    runLoop(int workerIndex)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    SendWork(at::Tensor & tensor,std::unique_ptr buffer)', '    wait', '    ~ProcessGroupGloo'];
python_cpp_function.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 66;  1; 13;15;  38; 0;11;25;22;24;0.03;2;['    AsyncAllreduceTest', '    AsyncBroadcastTest', '    AsyncInputIsOutputTest', '    AsyncTest'];['    initialize(const std::string & path,int N,Args,...)', '    main(int argc,char **argv)', '    runAsyncAllreduceTest(const std::string & path,size_t numProcesses,size_t numTensors)', '    runAsyncBroadcastTest(const std::string & path,size_t numProcesses,size_t numTensors)', '    AsyncAllreduceTest(const std::string & path,int numTensors)', '    run', '    AsyncBroadcastTest(const std::string & path,int numTensors)', '    run(int rootRank,int rootTensor)', '    AsyncInputIsOutputTest(const std::string & path,int numTensors)', '    getTensors', '    wait(std::shared_ptr & work)', '    AsyncTest(const std::string & path)', '    AsyncTest(AsyncTest)', '    getProcessGroup', '    start(int rank,int size)'];
python_engine.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 316;  50; 31;17;  254; 4;171;120;127;121;0.20;13;['    CollectiveTest', '    SignalTest'];['    TEST(ProcessGroupGlooTest,testSIGSTOPException)', '    TEST(ProcessGroupGlooTest,testSIGKILLException)', '    TEST(ProcessGroupGlooTest,testAllReduceCPU)', '    TEST(ProcessGroupGlooTest,testBroadcastCPU)', '    TEST(ProcessGroupGlooTest,testBarrier)', '    TEST(ProcessGroupGlooTest,testSend)', '    TEST(ProcessGroupGlooTest,testRecv)', '    testAllreduce(const std::string & path,const at::DeviceType b)', '    testBarrier(const std::string & path)', '    testBroadcast(const std::string & path,const at::DeviceType b)', '    testRecv(const std::string & path)', '    testSend(const std::string & path)', '    testSignal(const std::string & path,int signal)', '    initialize(const std::string & path,int num)', '    CollectiveTest(const std::string & path)', '    CollectiveTest(CollectiveTest)', '    getProcessGroup', '    start(int rank,int size)', '    arm(int pid,int signal)', '    run(int rank,int size)', '    SignalTest(const std::string & path)', '    ~SignalTest'];
python_function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 1052;  143; 112;32;  804; 0;527;307;515;261;0.18;39;[];['    checkSameSizeAndType(const at::Tensor & tensor,const std::vector & tensors)', '    checkSingleTensor(const std::vector & tensors)', '    checkSingleTensorHelper(const at::Tensor & tensor)', '    cudaAwareMpiCheck', '    initMPIOnce', '    mpiExit', '    abort', '    AsyncWork(at::Tensor tensor,MPI_Request request)', '    isCompleted', '    isSuccess', '    populateException', '    sourceRank', '    wait', '    ~AsyncWork', '    abort', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    createProcessGroupMPI(std::vector ranks)', '    destroy', '    enqueue(std::unique_ptr entry)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    ProcessGroupMPI(int rank,int size,MPI_Comm pgComm)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    runLoop', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupMPI', '  Static Member Variables', '    mpiThreadSupport_', '    onceFlagInitMPI', '    pgGlobalMutex_'];
python_function.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 119;  42; 20;13;  45; 0;10;31;10;31;0.93;4;['    ProcessGroupMPI', '    AsyncWork', '    WorkMPI'];['    createProcessGroupMPI(std::vector ranks)', '    initMPIOnce', '    mpiExit', '    abort', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputbuffer,at::Tensor & inputbuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    abort', '    AsyncWork(at::Tensor tensor,MPI_Request request)', '    isCompleted', '    isSuccess', '    populateException', '    sourceRank', '    wait', '    ~AsyncWork', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & data,const BroadcastOptions & opts)', '    destroy', '    enqueue(std::unique_ptr entry)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    ProcessGroupMPI(int rank,int size,MPI_Comm pgComm)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensor,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    runLoop', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupMPI', '    operator=', '    WorkEntry(std::vector *srcPtr,std::vector *dstPtr,std::function run)', '    WorkEntry'];
python_hook.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 172;  4; 31;8;  132; 0;67;50;69;46;0.03;11;[];['    main(int argc,char **argv)', '    testAllgather(int iter)', '    testAllreduce(int iter)', '    testBroadcast(int iter)', '    testGather(int iter)', '    testReduce(int iter)', '    testScatter(int iter)', '    testSendRecv(bool recvAnysource,int iter)', '    waitWork(std::shared_ptr pg,std::vector)'];
python_legacy_variable.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 142;  47; 16;7;  110; 0;89;61;45;24;0.43;2;[];['    buildNcclUniqueIdStr(const ncclUniqueId & ncclID)', '    getDeviceList(const std::vector & tensors)', '    getKeyFromDevices(const std::vector & devices)', '    getNcclAbortedCommStoreKey(const std::string ncclIdStr)', '    getNcclDataType(at::ScalarType type)', '    syncStreams(const std::vector & devices,std::vector & ncclEvents,std::vector & ncclStreams)', '    check_gpu_tensors(const std::vector & tensors)', '    flatten_for_scatter_gather(std::vector,std::vector & other,size_t world_size)', '    i', '    AutoNcclGroup', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector &,const AllgatherOptions &)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    broadcastUniqueNCCLID(ncclUniqueId *ncclID)', '    checkForNCCLErrors(const std::vector)', '    checkForNCCLErrorsInternal(const std::vector)', '    collective(std::vector & inputs,std::vector & outputs,Fn fn,PreProcess pre,PostProcess post)', '    collective(std::vector & inputs,std::vector & outputs,Fn fn)', '    gather(std::vector,std::vector &,const GatherOptions &)', '    initWork(std::vector devices)', '    ncclCommWatchdog', '    ncclCommWatchdogInternal', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::chrono::milliseconds & opTimeout)', '    recv(std::vector &,int,int)', '    recvAnysource(std::vector &,int)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector &,std::vector,const ScatterOptions &)', '    send(std::vector &,int,int)', '    abort', '    checkAndSetException', '    checkAndThrowException', '    checkForNCCLErrors(const std::vector)', '    finishedGPUExecution', '    finishedGPUExecutionInternal', '    isCompleted', '    isSuccess', '    synchronize', '    wait', '    WorkNCCL(const std::vector & devices)', '    ~WorkNCCL', '    ~ProcessGroupNCCL'];
python_legacy_variable.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 12;  3; 5;2;  3; 0;0;3;0;3;1.00;0;['    ProcessGroupNCCL', '    WorkNCCL'];['    checkForNCCLErrorsInternal(const std::vector)', '    allgather(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputbuffer,at::Tensor & inputbuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    broadcastUniqueNCCLID(ncclUniqueId *ncclID)', '    checkForNCCLErrors(const std::vector)', '    collective(std::vector & input,std::vector & output,Fn fn)', '    collective(std::vector & input,std::vector & output,Fn fn,PreProcess pre,PostProcess post)', '    gather(std::vector,std::vector & inputTensors,const GatherOptions & opts)', '    initWork(std::vector devices)', '    ncclCommCounter_', '    ncclCommWatchdog', '    ncclCommWatchdogInternal', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::chrono::milliseconds & opTimeout)', '    ProcessGroupNCCL(const std::shared_ptr & store,int rank,int size,const std::string & groupName,const std::chrono::milliseconds & opTimeout)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputTensors,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputTensors,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    abort', '    checkAndSetException', '    checkAndThrowException', '    checkForNCCLErrors(const std::vector)', '    finishedGPUExecution', '    finishedGPUExecutionInternal', '    isCompleted', '    isSuccess', '    synchronize', '    wait', '    WorkNCCL(const std::vector & devices)', '    ~WorkNCCL', '    ~ProcessGroupNCCL'];
python_nn_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 10;  1; 4;3;  3; 0;0;3;0;3;0.33;0;['    ProcessGroupNCCLErrorsTest', '    ProcessGroupNCCLSimulateErrors', '    ProcessGroupNCCLTimedOutErrors', '    WorkNCCLSimulateErrors', '    WorkNCCLTimedoutErrors'];['    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLErrorsBlocking)', '    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLTimedoutErrorsBlocking)', '    TEST_F(ProcessGroupNCCLErrorsTest,testNCCLErrorsNonBlocking)', '    SetUp', '    skipTest', '    TearDown', '    checkForNCCLErrors(const std::vector)', '    getNCCLCommCacheSize', '    getWatchdogSleepInterval', '    initWork(std::vector devices)', '    ProcessGroupNCCLSimulateErrors(const std::shared_ptr & store,int rank,int size,std::chrono::milliseconds timeout)', '    reset_error', '    simulate_error', '    initWork(std::vector devices)', '    ProcessGroupNCCLTimedOutErrors(const std::shared_ptr & store,int rank,int size,std::chrono::milliseconds timeout)', '    reset_timedout_error', '    set_timedout_error', '    checkForNCCLErrors(const std::vector)', '    WorkNCCLSimulateErrors(const std::vector & devices,bool simulate_error)', '    isCompleted', '    WorkNCCLTimedoutErrors(const std::vector & devices,bool set_timedout_error)'];
python_variable.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 38;  5; 8;6;  19; 0;5;11;3;9;0.26;3;['    AllgatherNCCLTest', '    AllreduceNCCLTest', '    BroadcastNCCLTest', '    NCCLTest', '    NCCLTestBase', '    ReduceNCCLTest'];['    main(int argc,char **argv)', '    numDevices', '    testAllgather(const std::string & path,int rank,int size)', '    testAllreduce(const std::string & path,int rank,int size)', '    testBroadcast(const std::string & path,int rank,int size)', '    testReduce(const std::string & path,int rank,int size)', '    testReduceScatter(const std::string & path,int rank,int size)', '    AllgatherNCCLTest(const std::string & path,int worldSize)', '    run', '    AllreduceNCCLTest(const std::string & path,int worldSize)', '    run', '    BroadcastNCCLTest(const std::string & path,int worldSize)', '    run(int rootRank,int rootTensor)', '    getTensors', '    NCCLTest(const std::string & path,int worldSize)', '    wait(std::shared_ptr & work)', '    getProcessGroup', '    initialize(int rank,int size)', '    NCCLTestBase(const std::string & path)', '    NCCLTestBase(NCCLTestBase)', '    ReduceNCCLTest(const std::string & path,int worldSize)', '    run(int rootRank,int rootTensor)', '    ReduceScatterNCCLTest(const std::string & path,int worldSize)', '    run'];
python_variable_indexing.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 405;  66; 37;21;  303; 0;162;84;129;268;0.22;13;[];['    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor &,at::Tensor &,const AllgatherOptions &)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions &)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    next', '    ProcessGroupRoundRobin(int rank,int size,std::vector)', '    recv(std::vector &,int,int)', '    recvAnysource(std::vector &,int)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector &,int,int)', '    ~ProcessGroupRoundRobin'];
python_variable_indexing.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 11;  1; 4;2;  5; 0;0;5;0;5;0.20;0;['    final'];['    allgather(std::vector,std::vector & inputs,const AllgatherOptions & opts)', '    allgather_base(at::Tensor & outputBuffer,at::Tensor & inputBuffer,const AllgatherOptions & opts)', '    allgather_coalesced(std::vector,std::vector & inputTensors,const AllgatherOptions & opts)', '    allreduce(std::vector & tensors,const AllreduceOptions & opts)', '    allreduce_coalesced(std::vector & tensors,const AllreduceCoalescedOptions & opts)', '    barrier(const BarrierOptions & opts)', '    broadcast(std::vector & tensors,const BroadcastOptions & opts)', '    gather(std::vector,std::vector & inputs,const GatherOptions & opts)', '    next', '    ProcessGroupRoundRobin(int rank,int size,std::vector)', '    recv(std::vector & tensors,int srcRank,int tag)', '    recvAnysource(std::vector & tensors,int tag)', '    reduce(std::vector & tensors,const ReduceOptions & opts)', '    reduce_scatter(std::vector & outputs,std::vector,const ReduceScatterOptions & opts)', '    scatter(std::vector & outputs,std::vector,const ScatterOptions & opts)', '    send(std::vector & tensors,int dstRank,int tag)', '    ~ProcessGroupRoundRobin'];
record_function.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 189;  29; 38;18;  106; 0;0;0;0;0;0.27;0;[];['    AddPerOpAsyncEndTime(size_t op_id)', '    AddPerOpEndTime(size_t op_id)', '    AddPerOpStartTime(size_t op_id)', '    GetReport', '    ProfDAGCounters(const std::shared_ptr & net_def)', '    ReportRunEnd', '    ReportRunStart', '    GetOperatorStats', '    GetPerOperatorCost', '    hasStats', '    operator+=(const ProfDAGReport & rhs)', '    PrintStats', '    statsProto(const std::string & name,const ProfDAGStats & stats,const std::vector & op_extra_info)'];
record_function_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 52;  13; 7;3;  33; 0;16;19;16;11;0.39;3;['    ProfDAGCounters', '    ProfDAGReport', '    ProfDAGStats'];['    AddPerOpAsyncEndTime(size_t op_id)', '    AddPerOpEndTime(size_t op_id)', '    AddPerOpStartTime(size_t op_id)', '    GetReport', '    ProfDAGCounters(const std::shared_ptr & net_def)', '    ReportRunEnd', '    ReportRunStart', '    GetOperatorStats', '    GetPerOperatorCost', '    hasStats', '    operator+=(const ProfDAGReport & rhs)', '    PrintStats', '    statsProto(const std::string & name,const ProfDAGStats & stats,const std::vector & op_extra_info)', '    cnt', '    computeMoments', '    operator+=(const ProfDAGStats & rhs)', '    ProfDAGStats', '    ProfDAGStats(float time_ms)', '    sqrsum', '    sum'];
saved_variable.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 108;  12; 13;10;  74; 0;55;11;40;8;0.16;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUGetProfDagStats', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetProfDagStats'];
symbolic.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 17;  1; 5;4;  8; 0;0;5;1;6;0.13;0;['    final'];['    GetProfDagStatsOp(const OperatorDef & operator_def,Workspace *ws)', '    getProtos(AsyncNetBase *net)', '    RunOnDevice', '    ~GetProfDagStatsOp'];
error_messages.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/utils; 18;  1; 4;2;  12; 0;7;3;5;4;0.08;1;[];['    Dump', '    Start', '    Stop'];
python_arg_parsing.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/utils; 42;  3; 4;4;  32; 0;6;21;0;65;0.09;0;['    final', '    final', '    ProfileCounter'];['    Dump', '    getId', '    ProfileObserver(NetBase *subject)', '    ProfileOperatorObserver', '    ProfileOperatorObserver(OperatorBase *subject,ProfileObserver *netObserver)', '    ProfileOperatorObserver(OperatorBase *subject,ProfileObserver *netObserver,int net_position,int rnn_order)', '    Start', '    Stop', '    ProfileCounter'];
variable.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 459;  49; 62;18;  339; 0;193;99;161;101;0.14;31;[];['    cuda_elapsed_us(const Event & e)', '    record(bool record_cuda)', '    disableProfiler', '    enableProfiler(ProfilerConfig config)', '    getEventList', '    mark(std::string name,bool include_cuda)', '    popRange', '    profilerEnabled', '    pushRange(const StringView & name,const char *msg,int64_t sequence_nr,std::vector)', '    registerCUDAMethods(CUDAStubs *stubs)', '    init', '    processEvents(const std::vector & events)', '    RecordProfile(std::ostream & out)', '    RecordProfile(const std::string & filename)', '    ~RecordProfile'];
variable.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 518;  286; 65;16;  160; 0;0;0;0;0;1.79;0;[];[];
VariableTypeManual.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 412;  57; 34;23;  305; 0;190;120;137;90;0.19;22;['    Profiler'];['    profile(std::function runnable)', '    ~Profiler'];
copy_utils.h;C++;pytorch-master/pytorch-master/torch/csrc; 82;  5; 10;4;  67; 0;37;35;18;15;0.07;4;[];['    cudaCheck(cudaError_t result,const char *file,int line)', '    elapsed(CUDAEventStub event,CUDAEventStub event2)', '    enabled', '    nvtxMarkA(const char *name)', '    nvtxRangePop', '    nvtxRangePushA(const char *name)', '    onEachDevice(std::function op)', '    record(int *device,CUDAEventStub *event,int64_t *cpu_ns)', '    synchronize', '    RegisterCUDAMethods'];
comm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 261;  46; 16;18;  179; 11;111;62;88;54;0.26;5;[];['    bailout_depth', '    executor_mode', '    needsGradientInProfilingMode(Block *b)', '    num_profiled_runs', '    profiling_mode', '    getBailoutDepth', '    getExecutorMode', '    getNumProfiledRuns', '    getProfilingMode', '    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    ProfilingGraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    runProfilingInsensitiveOptimizations(std::shared_ptr & copy)', '    runProfilingOptimizations(std::shared_ptr & copy)'];
comm.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 32;  0; 7;8;  17; 0;2;16;1;8;0.00;0;[];['    getDebugState', '    getPlanFor(Stack & stack,size_t remaining_bailout_depth)', '    ProfilingGraphExecutorImpl(const std::shared_ptr & graph,std::string function_name)', '    runProfilingInsensitiveOptimizations(std::shared_ptr & copy)', '    runProfilingOptimizations(std::shared_ptr & copy)', '    ~ProfilingGraphExecutorImpl'];
Event.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 219;  37; 29;10;  180; 0;137;114;183;92;0.21;12;[];['    unprofileBlock(Block *start_block)', '    unprofileGraphInputs(const std::shared_ptr & graph)', '    instrumentGraph(const std::shared_ptr & graph)', '    createProfileNode(const std::function & fp,at::ArrayRef inputs)', '    insertShapeProfile(Node *n,Value *i)', '    instrumentBlock(Block *block)', '    ProfilingRecord(std::shared_ptr g)'];
Event.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 20;  1; 5;6;  9; 0;1;6;1;4;0.11;1;[];['    instrumentGraph(const std::shared_ptr & graph)', '    createProfileNode(const std::function & fp,at::ArrayRef inputs)', '    graph', '    insertShapeProfile(Node *n,Value *i)', '    instrumentBlock(Block *block)', '    ProfilingRecord', '    ProfilingRecord(std::shared_ptr g)', '    ProfilingRecord', '    ready'];
Module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 565;  32; 72;38;  411; 19;299;203;442;220;0.08;32;[];['    fromMessage(const Message & message)', '    getAutogradMetadata', '    getGrads', '    PropagateGradientsReq(const AutogradMetadata & autogradMetadata,std::vector grads,bool retainGraph)', '    retainGraph', '    toMessageImpl'];
nccl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 323;  26; 35;25;  167; 76;80;69;70;44;0.16;14;['    PropagateGradientsReq'];['    fromMessage(const rpc::Message & message)', '    getAutogradMetadata', '    getGrads', '    PropagateGradientsReq(const AutogradMetadata & autogradMetadata,std::vector grads,bool retainGraph)', '    retainGraph', '    toMessageImpl'];
nccl.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 86;  6; 18;13;  51; 2;16;40;6;22;0.12;3;[];['    fromMessage(const rpc::Message & message)', '    toMessageImpl'];
override_macros.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 54;  0; 12;42;  0; 0;0;0;0;0;0.00;0;['    PropagateGradientsResp'];['    fromMessage(const rpc::Message & message)', '    PropagateGradientsResp', '    toMessageImpl'];
python_comm.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 7;  0; 3;1;  3; 0;0;3;0;4;0.00;0;[];[];
python_nccl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 389;  8; 50;17;  307; 7;213;113;202;157;0.03;12;[];[];
python_nccl.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 12;  0; 2;2;  8; 0;0;8;0;8;0.00;0;[];['    cpu_types', '    gpu_types', '    ArgumentHelper(const OperatorDef & def)', '    ArgumentHelper(const NetDef & netdef)', '    cleanupExternalInputsAndOutputs(NetDef *net)', '    DeviceId(const DeviceOption & option)', '    DeviceTypeName(const int32_t & d)', '    GetArgument(const OperatorDef & def,const string & name)', '    GetArgument(const NetDef & def,const string & name)', '    GetArgumentIndex(const google::protobuf::RepeatedPtrField & args,const string & name)', '    GetFlagArgument(const google::protobuf::RepeatedPtrField & args,const string & name,bool default_value)', '    GetFlagArgument(const OperatorDef & def,const string & name,bool default_value)', '    GetFlagArgument(const NetDef & def,const string & name,bool default_value)', '    GetMutableArgument(const string & name,const bool create_if_missing,OperatorDef *def)', '    GetMutableArgument(const string & name,const bool create_if_missing,NetDef *def)', '    GetMutableArgumentImpl(const string & name,const bool create_if_missing,Def *def)', '    HasInput(const OperatorDef & op,const std::string & input)', '    HasOutput(const OperatorDef & op,const std::string & output)', '    IsCPUDeviceType(int device_type)', '    IsGPUDeviceType(int device_type)', '    IsSameDevice(const DeviceOption & lhs,const DeviceOption & rhs)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const vector & value)', '    MakeArgument(const string & name,const bool & value)', '    MakeArgument(const string & name,const float & value)', '    MakeArgument(const string & name,const int & value)', '    MakeArgument(const string & name,const int64_t & value)', '    MakeArgument(const string & name,const string & value)', '    MakeArgument(const string & name,const MessageLite & value)', '    operator<<(std::ostream & output,const TensorProto & n)', '    operator<<(std::ostream & output,const QTensorProto & n)', '    operator<<(std::ostream & output,const NetDef & n)', '    operator==(const TensorProto & l,const TensorProto & r)', '    operator==(const QTensorProto & l,const QTensorProto & r)', '    operator==(const NetDef & l,const NetDef & r)', '    ParseProtoFromLargeString(const string & str,Message *proto)', '    ProtoDebugString(const Message & proto)', '    ReadProtoFromBinaryFile(const char *filename,MessageLite *proto)', '    ReadProtoFromTextFile(const char *filename,Message *proto)', '    ReadStringFromFile(const char *filename,string *str)', '    SupportsLosslessConversion(const InputType & value)', '    ParseFromString(const string & spec,Message *proto)', '    WriteProtoToBinaryFile(const MessageLite & proto,const char *filename)', '    WriteProtoToTextFile(const Message & proto,const char *filename)', '    WriteStringToFile(const string & str,const char *filename)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetRepeatedArgument(const string & name,const std::vector & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    GetSingleArgument(const string & name,const T & default_value)', '    HasArgument(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)', '    HasSingleArgumentOfType(const string & name)'];
serialization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 17;  0; 6;11;  0; 0;0;0;0;0;0.00;0;[];['    DeviceId(const DeviceOption & option)', '    DeviceTypeName(const int32_t & d)', '    IsCPUDeviceType(int device_type)', '    IsGPUDeviceType(int device_type)', '    IsSameDevice(const DeviceOption & lhs,const DeviceOption & rhs)', '    ParseProtoFromLargeString(const string & str,Message *proto)', '    ProtoDebugString(const Message & proto)', '    ReadProtoFromBinaryFile(const char *filename,MessageLite *proto)', '    ReadProtoFromBinaryFile(const string filename,MessageLite *proto)', '    ReadProtoFromFile(const char *filename,Message *proto)', '    ReadProtoFromFile(const string & filename,Message *proto)', '    ReadProtoFromTextFile(const char *filename,Message *proto)', '    ReadProtoFromTextFile(const string filename,Message *proto)', '    ReadStringFromFile(const char *filename,string *str)', '    ParseFromString(const string & spec,Message *proto)', '    WriteProtoToBinaryFile(const MessageLite & proto,const char *filename)', '    WriteProtoToBinaryFile(const MessageLite & proto,const string & filename)', '    WriteProtoToTextFile(const Message & proto,const char *filename)', '    WriteProtoToTextFile(const Message & proto,const string & filename)', '    WriteStringToFile(const string & str,const char *filename)'];
serialization.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 15;  0; 5;10;  0; 0;0;0;0;0;0.00;0;[];['    TEST(ProtoUtilsTest,IsSameDevice)', '    TEST(ProtoUtilsTest,SimpleReadWrite)', '    TEST(ProtoUtilsTest,CleanupExternalInputsAndOutputs)', '    expectedExternalInputs', '    expectedexternalOutputs'];
cudart.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda/shared; 37;  3; 7;12;  18; 2;12;7;7;6;0.17;1;[];['    GetEmptyStringAlreadyInited', '    ShutdownProtobufLibrary', '    GetEmptyStringAlreadyInited', '    GetEmptyStringAlreadyInited', '    ShutdownProtobufLibrary'];
nvtx.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda/shared; 17;  3; 4;2;  11; 0;5;7;3;6;0.27;1;[];['    ShutdownProtobufLibrary'];
Storage.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 26;  2; 6;18;  0; 0;0;0;0;1;0.00;0;['    ProtoDB', '    ProtoDBCursor', '    ProtoDBTransaction'];['    Close', '    NewCursor', '    NewTransaction', '    ProtoDB(const string & source,Mode mode)', '    ~ProtoDB', '    key', '    Next', '    ProtoDBCursor(const TensorProtos *proto)', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    ~ProtoDBCursor', '    Commit', '    ProtoDBTransaction(TensorProtos *proto)', '    Put(const string & key,const string & value)', '    ~ProtoDBTransaction'];
Storage.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 53;  0; 9;44;  0; 0;0;0;0;0;0.00;0;['    GetPSRoIPoolGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPSRoIPool', '    CAFFE_ANONYMOUS_VARIABLE_CPUPSRoIPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PSRoIPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PSRoIPoolGradient', '    vector', '    GetGradientDefs'];
Stream.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 21;  1; 5;6;  10; 0;1;7;1;5;0.10;1;['    final', '    final'];['    GetSingleArgument', '    PSRoIPoolGradientOp(const OperatorDef & def,Workspace *ws)', '    PSRoIPoolOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice'];
Tensor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 19;  1; 5;13;  0; 0;0;0;0;0;0.00;0;[];['    compute_1d_tiled(void *context_,size_t linear_index)', '    compute_2d(void *context_,size_t linear_index)', '    compute_2d_tiled(void *context_,size_t linear_index)', '    compute_3d_tiled(void *context_,size_t linear_index)', '    compute_4d_tiled(void *context_,size_t linear_index)', '    divide_round_up(size_t dividend,size_t divisor)', '    min(size_t a,size_t b)', '    pthreadpool_compute_1d_tiled(pthreadpool_t threadpool,pthreadpool_function_1d_tiled_t function,void *argument,size_t range,size_t tile)', '    pthreadpool_compute_2d(struct pthreadpool *threadpool,pthreadpool_function_2d_t function,void *argument,size_t range_i,size_t range_j)', '    pthreadpool_compute_2d_tiled(pthreadpool_t threadpool,pthreadpool_function_2d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j)', '    pthreadpool_compute_3d_tiled(pthreadpool_t threadpool,pthreadpool_function_3d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_i,size_t tile_j,size_t tile_k)', '    pthreadpool_compute_4d_tiled(pthreadpool_t threadpool,pthreadpool_function_4d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_i,size_t tile_j,size_t tile_k,size_t tile_l)'];
THCP.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 18;  0; 3;15;  0; 0;0;0;0;0;0.00;0;[];['    pthreadpool_compute_1d(pthreadpool_t threadpool,pthreadpool_function_1d_t function,void *argument,size_t range)', '    pthreadpool_compute_1d_tiled(pthreadpool_t threadpool,pthreadpool_function_1d_tiled_t function,void *argument,size_t range,size_t tile)', '    pthreadpool_compute_2d(struct pthreadpool *threadpool,pthreadpool_function_2d_t function,void *argument,size_t range_i,size_t range_j)', '    pthreadpool_compute_2d_tiled(pthreadpool_t threadpool,pthreadpool_function_2d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j)', '    pthreadpool_compute_3d_tiled(pthreadpool_t threadpool,pthreadpool_function_3d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_i,size_t tile_j,size_t tile_k)', '    pthreadpool_compute_4d_tiled(pthreadpool_t threadpool,pthreadpool_function_4d_tiled_t function,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_i,size_t tile_j,size_t tile_k,size_t tile_l)', '    pthreadpool_create(size_t threads_count)', '    pthreadpool_create_xnnpack(size_t threads_count)', '    pthreadpool_destroy(pthreadpool_t pthreadpool)', '    pthreadpool_destroy_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_get_threads_count(pthreadpool_t threadpool)', '    pthreadpool_get_threads_count_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_parallelize_1d(struct pthreadpool *threadpool,pthreadpool_task_1d_t task,void *argument,size_t range,uint32_t flags)', '    pthreadpool_parallelize_1d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_1d_tile_1d_t task,void *argument,size_t range,size_t tile,uint32_t flags)', '    pthreadpool_parallelize_2d(struct pthreadpool *threadpool,pthreadpool_task_2d_t task,void *argument,size_t range_i,size_t range_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_1d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_3d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_3d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_j,size_t tile_k,uint32_t flags)', '    pthreadpool_parallelize_4d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_4d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_k,size_t tile_l,uint32_t flags)', '    pthreadpool_parallelize_5d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_5d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t tile_l,size_t tile_m,uint32_t flags)', '    pthreadpool_parallelize_6d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_6d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t range_n,size_t tile_m,size_t tile_n,uint32_t flags)'];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 46;  0; 5;13;  0; 28;0;0;0;0;0.00;0;[];['    pthreadpool_compute_1d(pthreadpool_t threadpool,pthreadpool_function_1d_t function,void *argument,size_t range)', '    pthreadpool_create(size_t threads_count)', '    pthreadpool_destroy(pthreadpool_t pthreadpool)', '    pthreadpool_get_threads_count(pthreadpool_t threadpool)'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 24;  0; 7;17;  0; 0;0;0;0;0;0.00;0;[];['    atomic_decrement(atomic_size_t *value)', '    checkin_worker_thread(struct pthreadpool *threadpool)', '    compute_1d_tile_1d(const struct compute_1d_tile_1d_context *context,size_t linear_index)', '    compute_2d(const struct compute_2d_context *context,size_t linear_index)', '    compute_2d_tile_1d(const struct compute_2d_tile_1d_context *context,size_t linear_index)', '    compute_2d_tile_2d(const struct compute_2d_tile_2d_context *context,size_t linear_index)', '    compute_3d_tile_2d(const struct compute_3d_tile_2d_context *context,size_t linear_index)', '    compute_4d_tile_2d(const struct compute_4d_tile_2d_context *context,size_t linear_index)', '    compute_5d_tile_2d(const struct compute_5d_tile_2d_context *context,size_t linear_index)', '    compute_6d_tile_2d(const struct compute_6d_tile_2d_context *context,size_t linear_index)', '    divide_round_up(size_t dividend,size_t divisor)', '    min(size_t a,size_t b)', '    modulo_decrement(uint32_t i,uint32_t n)', '    multiply_divide(size_t a,size_t b,size_t d)', '    pthreadpool_allocate(size_t threads_count)', '    thread_main(void *arg)', '    thread_parallelize_1d(struct pthreadpool *threadpool,struct thread_info *thread)', '    wait_for_new_command(struct pthreadpool *threadpool,uint32_t last_command)', '    wait_worker_threads(struct pthreadpool *threadpool)', '    __aligned__', '    __aligned__', '    pthreadpool_create_xnnpack(size_t threads_count)', '    pthreadpool_destroy_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_get_threads_count_xnnpack(struct pthreadpool *threadpool)', '    pthreadpool_parallelize_1d(struct pthreadpool *threadpool,pthreadpool_task_1d_t task,void *argument,size_t range,uint32_t flags)', '    pthreadpool_parallelize_1d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_1d_tile_1d_t task,void *argument,size_t range,size_t tile,uint32_t flags)', '    pthreadpool_parallelize_2d(struct pthreadpool *threadpool,pthreadpool_task_2d_t task,void *argument,size_t range_i,size_t range_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_1d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_1d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_2d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_2d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t tile_i,size_t tile_j,uint32_t flags)', '    pthreadpool_parallelize_3d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_3d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t tile_j,size_t tile_k,uint32_t flags)', '    pthreadpool_parallelize_4d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_4d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t tile_k,size_t tile_l,uint32_t flags)', '    pthreadpool_parallelize_5d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_5d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t tile_l,size_t tile_m,uint32_t flags)', '    pthreadpool_parallelize_6d_tile_2d(pthreadpool_t threadpool,pthreadpool_task_6d_tile_2d_t task,void *argument,size_t range_i,size_t range_j,size_t range_k,size_t range_l,size_t range_m,size_t range_n,size_t tile_m,size_t tile_n,uint32_t flags)'];
CudaIPCTypes.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 240;  0; 0;21;  0; 238;0;0;0;0;0.00;0;[];['    disable_fpu_denormals', '    get_fpu_state', '    set_fpu_state(const struct fpu_state state)'];
DataLoader.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 222;  9; 9;27;  19; 181;11;11;4;5;0.47;4;[];['    THPWrapper_dealloc(THPWrapper *self)', '    THPWrapper_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPWrapper_check(PyObject *obj)', '    THPWrapper_get(PyObject *obj)', '    THPWrapper_init(PyObject *module)', '    THPWrapper_New(void *data,void (*) (void *) destructor)'];
DataLoader.h;C++;pytorch-master/pytorch-master/torch/csrc; 5;  0; 2;2;  1; 0;0;1;0;1;0.00;0;[];['    THPWrapper_check(PyObject *obj)', '    THPWrapper_get(PyObject *obj)', '    THPWrapper_init(PyObject *module)', '    THPWrapper_New(void *data,void (*) (void *) destructor)'];
Device.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 229;  42; 21;13;  192; 0;147;89;152;64;0.22;12;[];[];
autograd.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd; 13;  3; 4;2;  7; 0;0;7;0;4;0.43;0;[];['    PYBIND11_MODULE(python,m)'];
container.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/context; 266;  18; 41;3;  208; 0;118;70;77;44;0.09;22;[];['    PYBIND11_MODULE(python,m)'];
container.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/context; 139;  60; 34;4;  44; 0;5;41;0;38;1.36;0;[];['    fromPyTuple(const py::tuple & pyTuple)', '    toPyTuple(const RRefForkData & rrefForkData)', '    tryInferTypeWithTypeHint(const py::object & value,const py::object & type_hint)', '    unpickle(const py::tuple & pyTuple)', '    confirmedByOwner', '    isOwner', '    localValue', '    owner', '    ownerName', '    pickle', '    PyRRef(const py::object & value,const py::object & type_hint)', '    PyRRef(c10::intrusive_ptr rref)', '    str', '    toHere', '    toIValue'];
context.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/context; 135;  42; 32;7;  57; 0;5;51;1;43;0.74;0;['    PyRRef'];['    unpickle(const py::tuple & pyTuple)', '    confirmedByOwner', '    isOwner', '    localValue', '    owner', '    ownerName', '    pickle', '    PyRRef(const py::object & value,const py::object & type_hint)', '    PyRRef(c10::intrusive_ptr rref)', '    str', '    toHere', '    toIValue'];
dist_engine.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/engine; 421;  119; 60;5;  249; 0;161;81;93;59;0.48;10;[];['    PYBIND11_MODULE(dnnlowp_pybind11,m)'];
dist_engine.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/engine; 130;  44; 24;7;  58; 0;6;50;1;28;0.76;2;[];[];
recvrpc_backward.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/functions; 45;  14; 9;5;  20; 0;0;17;0;10;0.70;0;[];['    cast(const std::vector & src,return_value_policy,handle parent)', '    cast(const std::vector *src,return_value_policy pol,handle parent)', '    tuple_tail(const py::tuple & tup)', '    cast(torch::jit::IValue src,return_value_policy,handle)', '    cast(torch::jit::Symbol src,return_value_policy,handle)', '    cast(torch::jit::AttributeKind src,return_value_policy,handle)', '    load(handle src,bool)', '    load(handle src,bool)', '    load(handle src,bool)', '    PYBIND11_TYPE_CASTER(torch::jit::IValue,_)', '    PYBIND11_TYPE_CASTER(torch::jit::Symbol,_)', '    PYBIND11_TYPE_CASTER(torch::jit::AttributeKind,_)', '    fromQualString', '    toTypeInferredIValue'];
sendrpc_backward.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/functions; 28;  5; 6;1;  19; 0;5;10;7;6;0.26;2;[];[];
sendrpc_backward.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/functions; 34;  15; 6;2;  14; 0;0;11;0;7;1.07;0;['    BackgroundPlan', '    GetPythonGradient', '    StringFetcher'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPython', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUPythonGradient', '    addGlobalMethods(py::module & m)', '    addObjectMethods(py::module & m)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Python', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonDLPack', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonDLPackGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PythonGradient', '    CaffeToNumpyType(const TypeMeta & meta)', '    DefinitionGetter(const Registry *registry)', '    GetCurrentWorkspace', '    NumpyTypeToCaffe(int numpy_type)', '    deserializeBlob(const string & content)', '    feedBlob(Blob *blob,const py::object & arg,const py::object device_option)', '    fetchBlob(Workspace *ws,const std::string & name)', '    getGradientFunc(const std::string & token)', '    getOpFunc(const std::string & token)', '    gRegistry', '    RegistryName', '    RegistryName', '    switchWorkspaceInternal(const std::string & name,bool create_if_missing)', '    gRegistry', '    gRegistry', '    initialize', '    arg', '    PYBIND11_MODULE(caffe2_pybind11_state,m)', '    tensors_data', '    value_infos', '    vi', '    weight_names_overwrite', '    BackgroundPlan(Workspace *ws,PlanDef def)', '    isDone', '    isSucceeded', '    run', '    ~BlobFeederBase', '    ~BlobFetcherBase', '    GetGradientDefs', '    Fetch(const Blob & blob)'];
autograd_metadata.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 15;  3; 3;1;  11; 0;0;11;0;4;0.27;1;['    BlobFeederBase', '    BlobFetcherBase', '    PythonOpBase', '    TensorFeeder', '    TensorFetcher', '    PythonGradientOp', '    PythonOp'];['    CaffeToNumpyType(const TypeMeta & meta)', '    CreateFeeder(int device_type)', '    CreateFetcher(TypeIdentifier id)', '    GetCurrentWorkspace', '    NumpyTypeToCaffe(int numpy_type)', '    getGradientFunc(const std::string & token)', '    getOpFunc(const std::string & token)', '    RegistryName', '    static_assert(,)', '    Feed(const DeviceOption & option,PyArrayObject *array,Blob *blob,bool in_place)', '    ~BlobFeederBase', '    Fetch(const Blob & blob)', '    ~BlobFetcherBase', '    getFunc(const std::string & token)', '    PythonOpBase(const OperatorDef & operator_def,Workspace *ws,const std::string & pickled_builder_arg_name)', '    RunOnDevice', '    ~PythonOpBase', '    Feed(const DeviceOption & option,PyArrayObject *original_array,Blob *blob,bool in_place)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array,Tensor *out,bool in_place)', '    Fetch(const Blob & blob)', '    FetchTensor(const Tensor & tensor,bool force_copy)', '    NeedsCopy(const Tensor *tensor,const TypeMeta & dtype)', '    getFunc(const std::string & token)', '    PythonGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    getFunc(const std::string & token)', '    PythonOp(const OperatorDef & operator_def,Workspace *ws)', '    bytes', '    cast', '    len', '    getGradientFunc', '    getOpFunc'];
autograd_metadata.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 25;  9; 5;3;  11; 0;0;10;0;7;0.82;0;[];['    dl_device_type_map', '    dl_type_map', '    map', '    CaffeToDLDeviceType(int device_type)', '    CaffeToDLType(const TypeMeta & meta)', '    DLTypeToCaffe(const DLDataType & dl_type)'];
cleanup_autograd_context_req.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 45;  6; 7;3;  32; 0;14;23;3;13;0.19;4;['    DLPackWrapper'];['    CaffeToDLDeviceType(int device_type)', '    CaffeToDLType(const TypeMeta & meta)', '    DLTypeToCaffe(const DLDataType & dl_type)', '    data', '    DLPackWrapper(Tensor *tensor,DeviceOption device_option)', '    feed(py::object obj)', '    dim', '    id', '    raw_data', '    ShareExternalPointer', '    reinterpret_steal'];
cleanup_autograd_context_resp.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 23;  4; 4;1;  18; 0;5;11;2;7;0.22;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAPython', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_CUDAPythonGradient', '    addCUDAObjectMethods(py::module & m)', '    addCUDAGlobalMethods(py::module & m)', '    PYBIND11_MODULE(caffe2_pybind11_state_gpu,m)'];
cleanup_autograd_context_resp.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 24;  6; 4;4;  13; 0;1;11;0;7;0.46;0;[];['    CAFFE_ANONYMOUS_VARIABLE_HIPPython', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonDLPack', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonDLPackGradient', '    CAFFE_ANONYMOUS_VARIABLE_HIPPythonGradient', '    addHIPObjectMethods(py::module & m)', '    addHIPGlobalMethods(py::module & m)', '    PYBIND11_MODULE(caffe2_pybind11_state_hip,m)'];
propagate_gradients_req.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 99;  12; 19;3;  68; 0;31;38;23;25;0.18;6;['    IDeepFeeder', '    IDeepFetcher'];['    Feed(const DeviceOption & option,PyArrayObject *original_array,Blob *blob,bool in_place)', '    FeedTensor(const DeviceOption & option,PyArrayObject *original_array,itensor *tensor)', '    type_transform(const TypeMeta & meta)', '    ZeroDim(PyArrayObject *array)', '    Fetch(const Blob & blob)', '    FetchTensor(const itensor & atensor,bool force_copy)', '    type_transform(const itensor & atensor)'];
propagate_gradients_resp.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 18;  3; 4;1;  13; 0;2;9;2;5;0.23;2;['    Int8TensorFetcher'];['    Fetch(const Blob & blob)'];
propagate_gradients_resp.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 24;  7; 4;3;  13; 0;1;11;0;7;0.54;0;[];['    cast(const std::vector *src,return_value_policy pol,handle parent)', '    cast(const std::vector & src,return_value_policy,handle parent)', '    addNomnigraphMethods(pybind11::module & m)', '    GraphPrinter(Graph::NodeRef node)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    addNomnigraphMethodsImpl(py::module & m)'];
rpc_with_autograd.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 189;  13; 28;6;  145; 0;77;71;47;40;0.09;12;[];['    RegistryName'];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd; 145;  24; 19;6;  101; 0;54;51;28;29;0.24;4;[];['    RegistryName', '    PybindAddition', '    PybindAddition(py::module &)', '    ~PybindAddition'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd; 57;  23; 7;3;  27; 0;4;27;0;7;0.85;0;[];['    torch_warn_once_399', '    torch_warn_once_708', '    argumentToIValue(const FunctionSchema & schema,size_t argumentPosition,py::handle object)', '    deprecated_AT_ASSERT', '    deprecated_AT_ERROR', '    if_empty_then(::c10::str __VA_ARGS__,)', '    str(,,,,,::c10::str __VA_ARGS__)', '    createGenericDict(py::dict obj,const TypePtr & key_type,const TypePtr & value_type)', '    createGenericList(py::handle obj,const TypePtr & elem_type)', '    createPyObjectForStack(Stack)', '    createStackForSchema(const FunctionSchema & schema,const tuple_slice & args,const py::kwargs & kwargs,c10::optional self)', '    evilDeprecatedBadCreateStackDoNotUse(const py::tuple & tuple,at::ArrayRef inputs,size_t reserve_extra_space)', '    friendlyTypeName(py::handle obj)', '    guardAgainstNamedTensor(const T & var)', '    invokeOperatorFromPython(const std::vector,py::args args,py::kwargs kwargs)', '    invokeScriptFunctionFromPython(Function & callee,tuple_slice args,py::kwargs kwargs)', '    invokeScriptMethodFromPython(Method & callee,tuple_slice args,py::kwargs kwargs)', '    invokeScriptMethodFromPython(Object & object,const std::string & method_name,tuple_slice args,py::kwargs kwargs)', '    isTraceableType(TypePtr type)', '    setattr(pyObj,attrName,toPyObject)', '    tuple', '    returnToIValue(const TypePtr & type,py::handle object)', '    runAndInsertCall(Function & callee,tuple_slice args,py::kwargs kwargs,c10::optional self,std::function callInserter)', '    toIValue(py::handle obj,const TypePtr & type,c10::optional N)', '    toPyObject(IValue ivalue)', '    get_python_cu', '    toDictKeyIValue(py::handle key)', '    tryToInferContainerType(py::handle input)', '    tryToInferType(py::handle input)', '    unifyOrInitializeType(TypePtr accum,TypePtr unify)', '    toTraceableStack(const py::tuple & inputs)', '    toTypeInferredIValue(py::handle input)', '    create', '    at', '    findErrorInKwargs', '    formatTypeMismatchMsg', '    create', '    import', '    getOperation', '    schema', '    cast_error', '    getattr', '    hasattr', '    repr', '    toBool', '    toDouble', '    toGenericDict', '    toInt', '    toList', '    toObject', '    toStringRef', '    toTensor', '    toTuple', '    emplace_back', '    push_back', '    reserve', '    InferredType(TypePtr type)', '    InferredType(std::string reason)', '    reason', '    success', '    type', '    PythonFutureWrapper(c10::intrusive_ptr fut)', '    wait', '    ivalue', '    type', '    getPythonInterpreterSourceRange', '    getTracingState', '    getValueTrace', '    pauseTracing', '    setValueTrace', '    createNamed', '    begin', '    end', '    operator[](size_t index)', '    size', '    tuple_slice(py::tuple tup_)', '    tuple_slice(py::tuple tup_,int64_t b_)', '    tuple_slice(py::tuple tup_,int64_t b_,int64_t e_)'];
c10d.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 13;  3; 4;2;  7; 0;0;7;0;4;0.43;0;[];[];
comm.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 16;  2; 5;4;  6; 0;0;6;0;2;0.33;0;[];['    print_stack(const std::string & current_node_name)', '    store_stack'];
ddp.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 242;  45; 31;22;  146; 2;75;63;75;48;0.31;5;[];['    dict', '    print_stack(const std::string & current_node_name)', '    PyAnomalyMetadata', '    store_stack', '    ~PyAnomalyMetadata'];
ddp.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 44;  1; 10;8;  26; 0;1;26;0;7;0.04;0;[];['    sequence', '    sequence', '    cast_dict(std::vector objs)', '    cast_handle_sequence(std::vector objs)', '    cast_sequence(std::vector objs)', '    flatten(py::handle obj)', '    flatten_rec(PyObject *obj,ParsedArgs & args)', '    unflatten(ArrayRef vars,const IODescriptor & desc)', '    unflatten_rec(ArrayRef::iterator & var_it,ArrayRef::iterator & var_it_end,std::string::const_iterator & desc_it,std::vector::const_iterator & str_it,std::vector::const_iterator & str_it_end)'];
reducer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 853;  194; 98;10;  557; 0;288;189;219;292;0.35;18;[];['    operator<<(std::ostream & out,const IODescriptor::VariableMetadata & meta)', '    operator<<(std::ostream & out,const IODescriptor & desc)', '    unflatten(at::ArrayRef vars,const IODescriptor & structure)', '    hash(const IODescriptor & o)', '    hash(const VariableMetadata & m)', '    extend(const autograd::variable_list & list)', '    operator==(const IODescriptor & o)', '    operator==(const VariableMetadata & o)', '    VariableMetadata(const autograd::Variable & var)', '    extend(const autograd::variable_list & list)'];
reducer.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 196;  73; 39;10;  75; 0;1;66;0;62;0.97;0;[];['    find_param(FunctionSignature & signature,PyObject *name)', '    parse_as_integer(const std::string & s)', '    parse_intlist_args(const std::string & s,int64_t size)', '    should_allow_numbers_as_tensors(const std::string & name)', '    torch_warn_once_750', '    parse(PyObject *args,PyObject *kwargs,PyObject *[] dst,bool raise_exception)', '    append_overloaded_arg(std::vector & overloaded_args,PyObject *obj)', '    handle_torch_function(PythonArgs & r,PyObject *args,PyObject *kwargs,PyObject *torch_api,const char *module_name)', '    check_deprecated(const FunctionSignature & signature)', '    get_signatures', '    print_error(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    PythonArgParser(std::vector fmts,bool traceable)', '    raw_parse(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    scalar_slow(int i)', '    tensor_slow(int i)', '    check(PyObject *obj,std::vector & overloaded_args)', '    FunctionParameter(const std::string & fmt,bool keyword_only)', '    set_default_str(const std::string & str)', '    type_name', '    FunctionSignature(const std::string & fmt,int index)', '    toString'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 564;  39; 150;16;  366; 0;154;225;5;272;0.11;2;['    ParameterType'];['    _is_basic_python_type(PyTypeObject *tp)', '    check_has_torch_function(PyObject *obj)', '    PyObject_FastGetAttrString(PyObject *obj,char *name)', '    PyTorch_LookupSpecial(PyObject *obj,char *name)', '    handle_torch_function(PythonArgs & r,PyObject *args,PyObject *kwargs,PyObject *torch_api,const char *module_name)', '    parseDimnameList(PyObject *arg)', '    stashValue', '    get', '    dimnamelist(int i)', '    generator(int i)', '    isNone(int i)', '    memoryformat(int i)', '    memoryformatOptional(int i)', '    pyobject(int i)', '    storage(int i)', '    string(int i)', '    toBool(int i)', '    toBoolOptional(int i)', '    toBoolWithDefault(int i,bool default_bool)', '    toComplex(int i)', '    toComplexWithDefault(int i,std::complex default_value)', '    toDouble(int i)', '    toDoubleOptional(int i)', '    toDoubleWithDefault(int i,double default_double)', '    toInt64(int i)', '    toInt64Optional(int i)', '    toInt64WithDefault(int i,int64_t default_int)', '    toQScheme(int i)', '    empty', '    push_back', '    reserve', '    type_name', '    check(PyObject *obj,std::vector & overloaded_args)', '    FunctionParameter(const std::string & fmt,bool keyword_only)', '    set_default_str(const std::string & str)', '    type_name', '    FunctionSignature(const std::string & fmt,int index)', '    parse(PyObject *args,PyObject *kwargs,PyObject *[] dst,bool raise_exception)', '    toString', '    ParsedArgs', '    check_deprecated(const FunctionSignature & signature)', '    get_signatures', '    parse(PyObject *args,PyObject *kwargs,ParsedArgs & dst)', '    PythonArgParser(std::vector fmts,bool traceable)', '    raw_parse(PyObject *args,PyObject *kwargs,PyObject *[] parsed_args)', '    device(int i)', '    deviceOptional(int i)', '    deviceWithDefault(int i,const at::Device & default_device)', '    dimname(int i)', '    dimnamelist(int i)', '    generator(int i)', '    get_func_name', '    has_torch_function', '    intlist(int i)', '    intlistWithDefault(int i,std::vector default_intlist)', '    isNone(int i)', '    layout(int i)', '    layoutOptional(int i)', '    layoutWithDefault(int i,at::Layout default_layout)', '    memoryformat(int i)', '    memoryformatOptional(int i)', '    pyobject(int i)', '    PythonArgs(bool traceable,const FunctionSignature & signature,PyObject **args)', '    scalar(int i)', '    scalar_slow(int i)', '    scalarOptional(int i)', '    scalartype(int i)', '    scalartypeOptional(int i)', '    scalartypeWithDefault(int i,at::ScalarType default_scalartype)', '    scalarWithDefault(int i,at::Scalar default_scalar)', '    storage(int i)', '    string(int i)', '    tensor(int i)', '    tensor_slow(int i)', '    tensorlist(int i)', '    tensorlist_n(int i)', '    toBool(int i)', '    toBoolOptional(int i)', '    toBoolWithDefault(int i,bool default_bool)', '    toComplex(int i)', '    toComplexWithDefault(int i,std::complex default_complex)', '    toDouble(int i)', '    toDoubleOptional(int i)', '    toDoubleWithDefault(int i,double default_double)', '    toInt64(int i)', '    toInt64Optional(int i)', '    toInt64WithDefault(int i,int64_t default_int)', '    toQScheme(int i)', '    isTracing'];
message.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 135;  53; 23;4;  69; 0;2;64;0;35;0.77;0;[];[];
RpcMetricsHandler.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc/metrics; 25;  11; 2;2;  13; 0;3;11;0;8;0.85;1;[];['    THPAutograd_initExtension(PyObject *_unused,PyObject *unused)', '    THPAutograd_initFunctions', '    python_functions'];
process_group_agent.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 857;  119; 73;6;  667; 0;451;200;234;145;0.18;31;[];['    fromMessage(const Message & message)', '    PythonCall(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl'];
py_rref.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 210;  27; 25;6;  158; 0;86;61;46;38;0.17;15;['    final'];['    fromMessage(const Message & message)', '    PythonCall(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl'];
py_rref.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 35;  5; 6;4;  23; 0;0;20;0;17;0.22;0;[];['    initCommMethods(PyObject *module)'];
python_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 34;  3; 7;2;  25; 0;10;16;4;11;0.12;4;[];['    initCommMethods(PyObject *module)'];
python_functions.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 242;  20; 27;16;  185; 0;110;94;41;47;0.11;8;[];['    __PySlice_Unpack(PyObject *_r,Py_ssize_t *start,Py_ssize_t *stop,Py_ssize_t *step)', '    PyGILState_Check'];
python_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 42;  3; 8;5;  29; 0;0;29;0;8;0.10;0;[];['    _initFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    functionToPyObject(const std::shared_ptr & cdata)', '    registerCppFunction(const std::type_info & type,PyTypeObject *pytype)', '    registerFunctionHook(Node & fn,PyObject *hook)', '    THPCppFunction_call(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPCppFunction_clear(PyObject *self)', '    THPCppFunction_dealloc(PyObject *self)', '    THPCppFunction_metadata(THPCppFunction *self,void *_unused)', '    THPCppFunction_name(PyObject *self,PyObject *noargs)', '    THPCppFunction_next_functions(THPCppFunction *self,PyObject *hook)', '    THPCppFunction_register_hook(PyObject *self,PyObject *hook)', '    THPCppFunction_register_hook_dict(PyObject *self,PyObject *_var)', '    THPCppFunction_requires_grad(THPCppFunction *self,void *unused)', '    THPCppFunction_traverse(PyObject *self,visitproc visit,void *arg)', '    DefaultFunctionType'];
python_remote_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 57;  4; 10;3;  43; 0;24;31;6;16;0.09;3;[];['    _initFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    CppFunction_pynew(PyTypeObject *type,PyObject *args,PyObject *kwds)', '    createForwardFunctionPyTypeObject(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    functionToPyObject(const std::shared_ptr & cdata)', '    registerCppFunction(const std::type_info & type,PyTypeObject *pytype)', '    registerFunctionHook(Node & fn,PyObject *hook)', '    THPCppFunction_metadata(THPCppFunction *self,void *_unused)', '    THPCppFunction_name(PyObject *self,PyObject *noargs)', '    THPCppFunction_next_functions(THPCppFunction *self,PyObject *hook)', '    THPCppFunction_register_hook(PyObject *self,PyObject *hook)', '    THPCppFunction_register_hook_dict(PyObject *self,PyObject *_var)', '    THPCppFunction_requires_grad(THPCppFunction *self,void *unused)'];
python_resp.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 34;  3; 7;2;  25; 0;10;16;4;11;0.12;4;[];['    initPythonCustomClassBindings(PyObject *module)', '    __call__(py::args args,py::kwargs kwargs)'];
python_resp.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 27;  4; 8;3;  15; 0;0;12;0;9;0.27;0;[];['    initPythonCustomClassBindings(PyObject *module)', '    __call__(py::args args,py::kwargs kwargs)', '    ScriptClass(c10::StrongTypePtr class_type)'];
python_rpc_handler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 144;  26; 18;17;  92; 0;42;35;73;31;0.28;13;[];['    THPDimname_parse(PyObject *obj)', '    THPUtils_checkDimname(PyObject *obj)', '    THPUtils_checkDimnameList(PyObject *obj)', '    addMapping(PyObject *obj,at::Dimname dimname)', '    lookup(PyObject *obj)', '    ~InternedStringsTable'];
request_callback.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 24;  8; 5;3;  11; 0;1;8;2;5;0.73;1;[];['    THPDimname_parse(PyObject *obj)', '    THPUtils_checkDimname(PyObject *obj)', '    THPUtils_checkDimnameList(PyObject *obj)'];
request_callback.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 33;  14; 6;2;  14; 0;0;11;0;7;1.00;1;[];['    dispatch_str(const char *key,Func)', '    initDispatchBindings(PyObject *module)', '    parseAliasAnalysisKind(const std::string & k)', '    parseDispatchKey(const std::string & k)'];
request_callback_impl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 503;  82; 37;25;  373; 0;285;105;107;73;0.22;7;[];['    initDispatchBindings(PyObject *module)'];
rpc.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 13;  3; 4;2;  7; 0;0;7;0;4;0.43;0;[];['    child_atfork', '    py_outputs', '    THPEngine_initModule(PyObject *module)', '    THPEngine_is_checkpoint_valid(PyObject *self,PyObject *noargs)', '    THPEngine_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPEngine_queue_callback(PyObject *self,PyObject *_callback)', '    THPEngine_run_backward(THPEngine *self,PyObject *args,PyObject *kwargs)', '    get_python_engine', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    make_anomaly_metadata', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)'];
rpc_agent.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 236;  45; 31;1;  165; 0;95;66;62;37;0.27;15;[];['    THPEngine_initModule(PyObject *module)', '    get_python_engine', '    execute(const edge_list & roots,const variable_list & inputs,bool keep_graph,bool create_graph,const edge_list & outputs)', '    execute_with_graph_task(const std::shared_ptr & graph_task,std::shared_ptr graph_root,bool async_mode)', '    make_anomaly_metadata', '    PythonEngine', '    thread_init(int device,const std::shared_ptr & ready_queue)', '    thread_on_exception(std::shared_ptr graph_task,const std::shared_ptr & fn,std::exception & e)'];
rpc_agent.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 325;  107; 53;6;  163; 0;35;121;12;80;0.66;13;[];['    _assert_not_tracing(const char *name,const variable_list & input_vars)', '    _mark_dirty(THPFunction *self)', '    _parse_non_differentiable(THPFunction *self)', '    _prepare_grads(THPFunction *self,THPObjectPtr & raw_grads,bool is_grad_output)', '    _save_variables(const std::shared_ptr & cdata_ptr,THPFunction *self)', '    _trace_post_record(torch::jit::Node *node,PyObject *op_obj,const variable_list & input_vars,PyObject *output_objects,bool is_inplace,bool unpack_output)', '    _trace_pre_record(PyObject *op_obj,PyObject *input_objects,const variable_list & input_vars)', '    _trim_grad_input(const std::shared_ptr & cdata,THPFunction *self,THPObjectPtr & grad_input)', '    _wrap_outputs(const std::shared_ptr & cdata,THPFunction *self,const variable_list & input_vars,PyObject *raw_output,PyObject *outputs,bool is_executable)', '    THPFunction_clear(THPFunction *self)', '    THPFunction_dealloc(THPFunction *self)', '    THPFunction_traverse(THPFunction *self,visitproc visit,void *arg)', '    unpack_saved_variables(THPFunction *self,const std::function & unpack_fn)', '    as_variable', '    forward_class', '    getImplMember(PyObject *obj,void *_unused)', '    getMember(PyObject *obj,void *_unused)', '    getObject(PyObject *obj,void *_unused)', '    getRequiresGrad(PyObject *obj,void *_unused)', '    process_outputs(PyObject *op_obj,const std::shared_ptr & cdata,THPFunction *grad_fn,const UnpackedInput & unpacked,PyObject *inputs,THPObjectPtr,bool is_executable,torch::jit::Node *node)', '    setObject(PyObject *obj,PyObject *value,void *_unused)', '    THPFunction__register_hook_dict(THPFunction *self,PyObject *_var)', '    THPFunction_apply(PyObject *cls,PyObject *inputs)', '    THPFunction_do_backward(THPFunction *self,PyObject *args)', '    THPFunction_initModule(PyObject *module)', '    THPFunction_metadata(THPFunction *self,void *_unused)', '    THPFunction_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPFunction_next_functions(THPFunction *self,void *_unused)', '    THPFunction_register_hook(THPFunction *self,PyObject *hook)', '    THPFunction_saved_tensors(THPFunction *self,void *_unused)', '    THPFunction_saved_variables(THPFunction *self,void *_unused)', '    traceable_py_bool', '    unpack_input(PyObject *args)', '    apply(variable_list)', '    is_traceable', '    legacy_apply(const variable_list & inputs)', '    name', '    release_variables', '    throw_python_error'];
rref_context.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 668;  165; 51;3;  465; 0;251;148;162;181;0.35;30;[];['    THPFunction_Check(PyObject *obj)', '    THPFunction_initModule(PyObject *module)', '    ensure_tuple(THPObjectPtr & obj)', '    apply(variable_list)', '    is_traceable', '    legacy_apply(const variable_list & inputs)', '    name', '    PyNode(THPObjectPtr obj)', '    release_variables', '    throw_python_error', '    ~PyNode'];
rref_context.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 307;  144; 40;8;  119; 0;10;104;6;66;1.21;6;[];['    matchBuiltinOp(const std::string & opName,const py::args & args,const py::kwargs & kwargs,Stack & stack)', '    pyRemoteBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRemotePythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    pyRpcBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRpcPythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    sendPythonRemoteCall(const WorkerInfo & dst,SerializedPyObj serializedPyObj,const IValue & rrefId,const IValue & forkId,const std::shared_ptr & rf)', '    toPyObj(const Message & message)', '    toPyObjInternal(RpcCommandBase & rpc,MessageType messageType)'];
rref_impl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 243;  43; 27;6;  172; 0;78;59;55;34;0.25;15;[];['    addClass(PyTypeObject & type,const char *name,PyGetSetDef *function_properties,PyMethodDef *function_methods)', '    initialize_autogenerated_functions'];
rref_proto.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 208;  7; 37;4;  164; 0;70;72;50;49;0.04;24;[];['    pyRemoteBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRemotePythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    pyRpcBuiltin(const WorkerInfo & dst,const std::string & opName,const std::shared_ptr & rf,const py::args & args,const py::kwargs & kwargs)', '    pyRpcPythonUdf(const WorkerInfo & dst,std::string & pickledPythonUDF,std::vector & tensors,const std::shared_ptr & rf)', '    toPyObj(const Message & message)'];
rref_proto.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 168;  12; 39;7;  113; 0;1;81;1;60;0.11;13;[];['    initialize_autogenerated_functions'];
script_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 148;  15; 25;3;  108; 0;51;49;36;33;0.14;13;[];[];
script_remote_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 83;  4; 13;4;  65; 0;32;42;10;18;0.06;5;[];['    check_result(PyObject *prev,PyObject *result,PyObject *hook)', '    check_single_result(PyObject *_original,PyObject *_result,PyObject *hook)', '    hook_name(PyObject *hook)', '    unwrap_variables(PyObject *py_variables)', '    wrap_variables(const variable_list & c_variables)', '    operator()(const variable_list & _outputs,const variable_list & _inputs)', '    PyFunctionPostHook(PyObject *dict)', '    ~PyFunctionPostHook', '    operator()(const variable_list & values)', '    PyFunctionPreHook(PyObject *dict,int value_idx)', '    ~PyFunctionPreHook'];
script_remote_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 56;  9; 11;6;  33; 0;2;25;3;14;0.27;2;[];['    operator()(const variable_list & _outputs,const variable_list & _inputs)', '    PyFunctionPostHook(PyObject *dict)', '    ~PyFunctionPostHook', '    operator()(const variable_list & values)', '    PyFunctionPreHook(PyObject *dict,int value_idx)', '    ~PyFunctionPreHook'];
script_resp.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 45;  4; 10;5;  30; 0;12;21;5;15;0.13;4;[];['    aliasAnalysisIsSpecialCase', '    createPythonOperation(const Node *op_)'];
faulty_process_group_agent.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc/testing; 87;  14; 7;1;  68; 0;31;32;24;13;0.21;5;[];['    findAllNodes(c10::ArrayRef blocks,Symbol kind,bool recurse)', '    findAllNodes(Block *block,Symbol kind,bool recurse)', '    findNode(c10::ArrayRef blocks,Symbol kind,bool recurse)', '    findNode(Block *block,Symbol kind,bool recurse)', '    getPythonName(const PyObject *obj_)', '    initPythonIRBindings(PyObject *module_)', '    printPyObject(std::ostream & out,const THPObjectPtr & obj)', '    autogradFunction', '    cloneFrom(Node *other_)', '    lint_python', '    name', '    writeScalars(std::ostream & out)', '    createPythonOp(THPObjectPtr,const std::string & cconv,pyobj_list)', '  Static Member Variables', '    Kind'];
faulty_process_group_agent.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc/testing; 71;  13; 12;3;  46; 0;3;38;2;16;0.28;1;[];['    initPythonIRBindings(PyObject *module_)', '    allocNewInstance(Graph *g)', '    autogradFunction', '    cloneFrom(Node *other_)', '    ConcretePythonOp(Graph *graph)', '    init(THPObjectPtr,const std::string & cconv,pyobj_list)', '    lint_python', '    name', '    writeScalars(std::ostream & out)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc/testing; 118;  10; 15;6;  94; 0;77;23;7;11;0.11;2;[];['    create(py::object py_obj)', '    ConcretePyObjectHolder(py::object py_obj)', '    getPyObject', '    ~ConcretePyObjectHolder'];
torchscript_functions.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 118;  13; 16;7;  88; 0;61;56;13;22;0.15;2;[];['    THPVariable_pynew(PyTypeObject *type,PyObject *args,PyObject *kwds)', '    init_legacy_variable(PyObject *module)'];
torchscript_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 36;  13; 5;5;  16; 0;0;16;0;5;0.81;0;[];['    init_legacy_variable(PyObject *module)'];
types.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 104;  9; 19;1;  78; 0;28;35;24;25;0.12;11;[];['    destroy_nccl_comm(PyObject *capsule)', '    extract_tensors(PyObject *obj)', '    unpack_comms(PyObject *obj,size_t size)', '    unpack_nccl_comm(PyObject *capsule)', '    THCPModule_nccl_all_gather(PyObject *self,PyObject *args)', '    THCPModule_nccl_all_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_broadcast(PyObject *self,PyObject *args)', '    THCPModule_nccl_init_rank(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce_scatter(PyObject *self,PyObject *args)', '    THCPModule_nccl_unique_id(PyObject *self,PyObject *args)', '    THCPModule_nccl_version(PyObject *self,PyObject *args)'];
unpickled_python_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 28;  3; 6;3;  19; 0;5;11;5;7;0.16;3;[];['    THCPModule_nccl_all_gather(PyObject *self,PyObject *args)', '    THCPModule_nccl_all_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_broadcast(PyObject *self,PyObject *args)', '    THCPModule_nccl_init_rank(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce(PyObject *self,PyObject *args)', '    THCPModule_nccl_reduce_scatter(PyObject *self,PyObject *args)', '    THCPModule_nccl_unique_id(PyObject *self,PyObject *args)', '    THCPModule_nccl_version(PyObject *self,PyObject *args)'];
unpickled_python_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 33;  12; 6;4;  14; 0;0;11;0;8;0.86;0;[];['    THPVariable__parse_to(PyObject *module,PyObject *args,PyObject *kwargs)', '    $', '    $', '    initNNFunctions(PyObject *module)', '    tuple'];
unpickled_python_remote_call.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 28;  3; 6;3;  19; 0;2;15;2;6;0.16;3;[];['    initNNFunctions(PyObject *module)'];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 360;  33; 26;16;  293; 0;133;81;92;180;0.11;9;[];[];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 52;  21; 9;2;  23; 0;0;23;0;11;0.91;0;['    TaggedStringStream'];['    isValidIdentifier(const std::string & name)', '    isValidIdentifierChar(char c,size_t pos)', '    makeValidIdentifier(const std::string & candidate)', '    printFunction(const Function & func)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    PythonPrint(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    ranges', '    str', '    assignValue(Value *v,const std::string & s)', '    assignValue(Value *v,std::shared_ptr s)', '    assignValue(Value *v,Value *w)', '    assignValuesToTheirUniqueNames(at::ArrayRef values)', '    buildConstantList(Node *n,std::vector & constants)', '    buildConstantList(Block *b,std::vector & constants)', '    canInline(Value *v)', '    createBroadList(dtype value,const int64_t & N)', '    genName(const std::string & candidate)', '    genNameImpl(const std::string & candidate,std::unordered_set & used)', '    genUniqueNameFor(Value *v)', '    getOrAddTensorConstant(at::Tensor t)', '    indent', '    isLongInline(Node *node)', '    isLongLine(const std::string & str)', '    isNonConstantInline(Value *input)', '    previousNonConstant(Node *n)', '    printAnnotatedAssignment(at::ArrayRef lhs,at::ArrayRef rhs)', '    printAssignment(at::ArrayRef lhs,at::ArrayRef rhs)', '    printBlock(Block *root,bool block_has_other_statements)', '    printBody(Block *body)', '    printClass(const ClassTypePtr & classType)', '    printConstant(TaggedStringStream & stmt,const IValue & v)', '    printDefaultValue(const Argument & arg,TaggedStringStream & stmt,const IValue & value)', '    printDict(TaggedStringStream & stmt,at::ArrayRef key_value_pairs,const char *begin,const char *end)', '    printFunction(const Function & func,bool print_first_argument_type)', '    printIf(IfView stmt)', '    printLoop(LoopView stmt)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    printNode(Node *node,bool print_const)', '    printOpName(TaggedStringStream & stmt,Symbol kind)', '    printOutputDefinition(Node *node,const T & expr)', '    printRHS(TaggedStringStream & stmt,Node *node)', '    printValueIndex(TaggedStringStream & stmt,at::ArrayRef inputs)', '    printValueList(TaggedStringStream & stmt,at::ArrayRef list,const char *begin,const char *end)', '    PythonPrintImpl(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    registerClassDependencies(const TypePtr & type)', '    registerDependency(const c10::NamedTypePtr & type)', '    requiresAnnotation(Value *lhs,Value *rhs)', '    scanBlock(Block *b)', '    scanNode(Node *n)', '    scanTypeDependencies(Node *node)', '    scanValue(Node *block_point,Value *v)', '    splitLongInlines(at::ArrayRef inputs)', '    operator<<(const std::string & s)', '    operator<<(const TaggedStringStream & rhs)', '    operator<<(const std::shared_ptr & rhs)', '    operator<<(const T & t)', '    ranges', '    str', '    TaggedStringStream(const SourceRangeStack *srs)', '    useOf(Value *v)', '    WithIndented', '    WithSourceRange(SourceRangeStack *stack,Node *n)', '    ~WithSourceRange', '    zipWith(at::ArrayRef list_a,at::ArrayRef list_b,F action)', '    ~PythonPrintImpl'];
dl.c;C;pytorch-master/pytorch-master/torch/csrc; 48;  0; 8;19;  19; 3;15;12;9;4;0.00;1;[];['    printFunction(const Function & func)', '    printMethod(const Function & func)', '    printNamedType(const c10::NamedTypePtr & type)', '    PythonPrint(std::vector & tensor_table,std::vector & deps_table,bool enforce_importable)', '    ranges', '    str', '    ~PythonPrint'];
Dtype.h;C++;pytorch-master/pytorch-master/torch/csrc; 32;  0; 8;6;  17; 1;6;10;2;9;0.00;2;[];['    fromMessage(const Message & message)', '    PythonRemoteCall(SerializedPyObj,at::IValue retRRefId,at::IValue retForkId)', '    toMessageImpl'];
DynamicTypes.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 130;  3; 18;20;  92; 1;49;32;34;26;0.03;11;['    PythonRemoteCall'];['    fromMessage(const Message & message)', '    PythonRemoteCall(SerializedPyObj,at::IValue retRRefId,at::IValue retForkId)', '    retForkId', '    retRRefId', '    serializedPyObj', '    toMessageImpl'];
DynamicTypes.h;C++;pytorch-master/pytorch-master/torch/csrc; 35;  3; 10;7;  16; 0;0;16;0;13;0.19;0;[];['    fromMessage(const Message & message)', '    PythonResp(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl'];
Exceptions.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 201;  15; 23;8;  162; 0;101;41;24;81;0.09;9;['    final'];['    fromMessage(const Message & message)', '    PythonResp(SerializedPyObj)', '    serializedPyObj', '    toMessageImpl'];
Exceptions.h;C++;pytorch-master/pytorch-master/torch/csrc; 325;  61; 43;82;  142; 2;59;58;58;120;0.43;15;[];['    getFunction(const py::object & module,const char *name)', '    getInstance', '    cleanup', '    deserialize(const SerializedPyObj & serializedObj)', '    handleException(const py::object & obj)', '    handleExceptionGILHeld(const py::object & obj)', '    jitCompilationUnit', '    parseTypeFromStr(const std::string & type_str)', '    PythonRpcHandler', '    runPythonUdf(py::object)', '    serialize(const py::object & obj)', '    resolveType(const std::string & name,const jit::SourceRange &)', '    resolveValue(const std::string &,torch::jit::Function &,const jit::SourceRange &)'];
Generator.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 262;  41; 26;26;  194; 14;138;103;161;80;0.21;15;['    PythonRpcHandler'];['    getInstance', '    cleanup', '    deserialize(const SerializedPyObj & serializedObj)', '    handleException(const py::object & obj)', '    handleExceptionGILHeld(const py::object & obj)', '    jitCompilationUnit', '    operator=', '    operator=', '    parseTypeFromStr(const std::string & type_str)', '    PythonRpcHandler', '    PythonRpcHandler', '    PythonRpcHandler', '    runPythonUdf(py::object)', '    serialize(const py::object & obj)', '    ~PythonRpcHandler'];
serialization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/generic; 161;  7; 14;19;  112; 15;47;46;18;102;0.06;1;[];['    load_scalar(void *data,at::ScalarType scalarType)', '    store_scalar(void *data,at::ScalarType scalarType,PyObject *obj)', '    convert'];
serialization.h;C++;pytorch-master/pytorch-master/torch/csrc/generic; 11;  0; 3;4;  4; 1;0;4;0;3;0.00;0;[];['    THPUtils_checkString(PyObject *obj)', '    THPUtils_internString(const std::string & str)', '    THPUtils_internStringInPlace(PyObject **obj)', '    THPUtils_isInterned(PyObject *obj)', '    THPUtils_packString(const char *str)', '    THPUtils_packString(const std::string & str)', '    THPUtils_unpackString(PyObject *obj)'];
Storage.cpp;C++;pytorch-master/pytorch-master/torch/csrc/generic; 399;  49; 38;27;  289; 39;128;153;74;523;0.17;6;[];[];
StorageMethods.cpp;C++;pytorch-master/pytorch-master/torch/csrc/generic; 340;  6; 33;37;  234; 33;50;149;0;1109;0.03;0;[];[];
StorageSharing.cpp;C++;pytorch-master/pytorch-master/torch/csrc/generic; 549;  17; 27;30;  246; 244;57;164;4;1117;0.07;1;[];['    checkInterface(const SourceRange & loc,Function & m,std::shared_ptr self,const std::string & field)', '    isNamedTupleClass(const py::object & obj)', '    as_function(const py::object & obj)', '    typeString(py::handle h)', '    recurseThroughNestedModules(const SourceRange & loc,Function & m,std::vector & keys,std::vector & values,std::shared_ptr self,const std::string & prefix,const std::string & field)', '    registerNamedTuple(const py::object & obj,const SourceRange & loc)', '    toSugaredValue(const IValue & v,Function & m,const SourceRange & loc)', '    toSugaredValue(py::object obj,Function & m,SourceRange loc,bool is_constant)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getSugaredModuleDict(const SourceRange & loc,Function & m)', '    iter(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    checkForAddToConstantsError(std::stringstream & ss)', '    getattr(const SourceRange & loc,const std::string & name)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    getSchema(const size_t n_args,const size_t n_binders,const SourceRange & loc)', '    kind'];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/generic; 12;  0; 2;10;  0; 2;0;0;0;0;0.00;0;[];['    as_function(const py::object & obj)', '    isNamedTupleClass(const py::object & obj)', '    recurseThroughNestedModules(const SourceRange & loc,Function & m,std::vector & keys,std::vector & values,std::shared_ptr self,const std::string & prefix,const std::string & field)', '    registerNamedTuple(const py::object & obj,const SourceRange & loc)', '    toSimple(Value *v)', '    toSugaredValue(py::object obj,Function & m,SourceRange loc,bool is_constant)', '    BooleanDispatchValue(py::dict dispatched_fn)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    ConstantParameterList(Value *the_list)', '    kind', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    ModuleDictMethod(SugaredValuePtr iterable,const std::string & name)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & caller,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getSugaredModuleDict(const SourceRange & loc,Function & m)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    ModuleValue(Value *self,std::shared_ptr concreteType)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    PythonClassValue(ClassTypePtr type,py::object py_type)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    PythonModuleValue(py::object mod)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    checkForAddToConstantsError(std::stringstream & ss)', '    getattr(const SourceRange & loc,const std::string & name)', '    getSchema(const size_t n_args,const size_t n_binders,const SourceRange & loc)', '    kind', '    PythonValue(py::object the_self,c10::optional rcb,Value *module_self)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    getKeys', '    getModules', '    iter(const SourceRange & loc,Function & m)', '    kind', '    SugaredModuleDict(std::shared_ptr self,std::shared_ptr keys,std::shared_ptr modules)'];
compilation_unit.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 302;  65; 34;20;  187; 0;0;0;0;0;0.35;0;[];['    get_module(Backend backend)', '    get_name(Backend backend,ScalarType scalarType)', '    get_storage_obj(PyTensorType *type)', '    get_tensor_dict', '    initialize_aten_types(std::vector & tensor_types)', '    py_bind_tensor_types(const std::vector & tensor_types)', '    py_initialize_metaclass(PyTypeObject & metaclass)', '    py_initialize_tensor_type(PyTypeObject & type,const char *name,PyObject *tp_dict)', '    PyTensorType_Check(PyObject *obj)', '    set_name(PyTensorType & type_obj,const std::string & name)', '    set_type(PyTensorType & type_obj,Backend backend,ScalarType scalarType)', '    Tensor_instancecheck(PyTensorType *self,PyObject *arg)', '    Tensor_new(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    unavailable_type(const PyTensorType & type)', '    get_default_dispatch_key', '    get_default_scalar_type', '    initialize_python_bindings', '    py_set_default_dtype(PyObject *obj)', '    py_set_default_tensor_type(PyObject *obj)', '    set_default_tensor_type(PyTensorType *type)', '    Tensor_dtype(PyTensorType *self,void *unused)', '    Tensor_is_cuda(PyTensorType *self,void *unused)', '    Tensor_is_sparse(PyTensorType *self,void *unused)', '    Tensor_layout(PyTensorType *self,void *unused)', '    get_backend', '    get_dispatch_key', '    get_scalar_type'];
function_impl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 71;  5; 10;3;  56; 0;26;26;22;23;0.09;8;[];['    get_default_dispatch_key', '    get_default_scalar_type', '    initialize_python_bindings', '    py_set_default_dtype(PyObject *obj)', '    py_set_default_tensor_type(PyObject *obj)'];
function_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 132;  20; 26;5;  85; 0;0;0;0;0;0.24;0;[];['    check_out_type_matches(Tensor result,ScalarType scalarType,bool scalarType_is_none,c10::optional layout,const Device & device,bool device_is_none)', '    dispatch_nonzero(const Tensor & self)', '    dispatch_nonzero(const Tensor & self,Tensor out)', '    dispatch_nonzero_numpy(const Tensor & self)', '    THPVariable_arange(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_as_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_from_numpy(PyObject *module,PyObject *arg)', '    THPVariable_full(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_get_device(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_nonzero(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_numel(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_randint(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_range(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_sparse_coo_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    TypeError_to_NotImplemented_(PyObject *self,PyObject *args,PyObject *kwargs)', '    options', '    $', '    $', '    dispatch_arange(Scalar end,Tensor result)', '    dispatch_arange(Scalar end,const TensorOptions & options)', '    dispatch_arange(Scalar start,Scalar end,Scalar step,Tensor result)', '    dispatch_arange(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,c10::optional names,const TensorOptions & options)', '    dispatch_full(IntArrayRef size,Scalar fill_val,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,Generator generator,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    dispatch_randint(int64_t high,IntArrayRef size,Tensor result)', '    dispatch_randint(int64_t high,IntArrayRef size,const TensorOptions & options)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,Tensor result)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,Tensor result)', '    dispatch_randint(int64_t low,int64_t high,IntArrayRef size,const TensorOptions & options)', '    dispatch_range(Scalar start,Scalar end,Scalar step,Tensor result)', '    dispatch_range(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    initTorchFunctions(PyObject *module)'];
module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 404;  58; 44;10;  310; 0;163;139;115;87;0.19;36;[];['    lookup_fn_adapter', '    initPythonTracerBindings(PyObject *module)', '    preRecordPythonTrace(THPObjectPtr pyobj,const std::string & arg_types,at::ArrayRef inputs,pyobj_list scalar_args)', '    pythonRecordSourceLocation(Node *n)', '    pythonWarn(const std::string & reason)', '    createGraphByTracing(const py::function & func,Stack trace_inputs,const py::function & var_name_lookup_fn,bool force_outplace,Module *self)', '    getPythonInterpreterSourceRange'];
module.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 564;  109; 70;25;  372; 0;0;0;0;0;0.29;0;[];['    createGraphByTracing(const py::function & func,Stack inputs,const py::function & var_name_lookup_fn,bool force_outplace,Module *self)', '    getPythonInterpreterSourceRange', '    getPythonInterpreterStackTrace', '    initPythonTracerBindings(PyObject *module)', '    preRecordPythonTrace(THPObjectPtr pyobj,const std::string & arg_types,at::ArrayRef inputs,std::vector scalar_args)'];
module_save.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 29;  2; 6;2;  21; 0;4;13;4;6;0.10;4;[];['    initTreeViewBindings(PyObject *module)', '    maybeConvertToString(const py::object & obj)', '    wrap_list(const SourceRange & fallback_pos,std::vector)', '    wrap_maybe(const SourceRange & fallback_pos,T *val)', '    create(int line,int start_col,int end_col)', '    line_col_to_byte_offs(int line,int start_col,int end_col)', '    SourceRangeFactory(std::string text,py::object filename,size_t file_lineno,size_t leading_whitespace_chars)'];
object.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 138;  22; 19;4;  96; 0;0;0;0;0;0.23;0;[];['    initTreeViewBindings(PyObject *module)'];
arg_spec.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 59;  12; 9;8;  34; 0;8;20;5;24;0.35;8;[];[];
codegen.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 538;  74; 50;20;  404; 0;311;177;206;54;0.18;14;[];['    THPVariable_clear(THPVariable *self)', '    THPVariable_dealloc(THPVariable *self)', '    THPVariable_device(THPVariable *self,void *unused)', '    THPVariable_dtype(THPVariable *self,void *unused)', '    THPVariable_get_data(THPVariable *self,void *unused)', '    THPVariable_is_leaf(THPVariable *self,void *unused)', '    THPVariable_layout(THPVariable *self,void *unused)', '    THPVariable_make_subclass(PyObject *_ignored,PyObject *args,PyObject *kwargs)', '    THPVariable_NewWithVar(PyTypeObject *type,Variable var)', '    THPVariable_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPVariable_set_grad_fn(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_traverse(THPVariable *self,visitproc visit,void *arg)', '    parsed_args', '    THPVariable_get_backwards_hooks(THPVariable *self,void *unused)', '    THPVariable_get_base(THPVariable *self,void *unused)', '    THPVariable_get_cdata(THPVariable *self,void *unused)', '    THPVariable_get_grad(THPVariable *self,void *unused)', '    THPVariable_get_grad_fn(THPVariable *self,void *unused)', '    THPVariable_get_name(THPVariable *self,void *unused)', '    THPVariable_get_names(THPVariable *self,void *unused)', '    THPVariable_get_ndim(THPVariable *self,void *unused)', '    THPVariable_get_output_nr(THPVariable *self,void *unused)', '    THPVariable_get_requires_grad(THPVariable *self,void *unused)', '    THPVariable_get_shape(THPVariable *self,void *unused)', '    THPVariable_get_T(THPVariable *self,void *unused)', '    THPVariable_get_version(THPVariable *self,void *unused)', '    THPVariable_get_volatile(THPVariable *self,void *unused)', '    THPVariable_initModule(PyObject *module)', '    THPVariable_is_complex(THPVariable *self,void *unused)', '    THPVariable_is_cuda(THPVariable *self,void *unused)', '    THPVariable_is_mkldnn(THPVariable *self,void *unused)', '    THPVariable_is_quantized(THPVariable *self,void *unused)', '    THPVariable_is_sparse(THPVariable *self,void *unused)', '    THPVariable_set_backwards_hooks(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_set_data(THPVariable *self,PyObject *data,void *unused)', '    THPVariable_set_grad(THPVariable *self,PyObject *py_grad,void *unused)', '    THPVariable_set_names(THPVariable *self,PyObject *names)', '    THPVariable_set_requires_grad(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_set_volatile(THPVariable *self,PyObject *obj,void *unused)', '    THPVariable_Wrap(Variable var)', '    initTensorImplConversion(PyObject *module)'];
compiler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 302;  45; 33;22;  208; 0;129;81;82;64;0.22;18;[];['    THPVariable_CheckExact(PyObject *obj)', '    THPVariable_Check(PyObject *obj)', '    THPVariable_initModule(PyObject *module)', '    THPVariable_Unpack(PyObject *obj)', '    THPVariable_Wrap(Variable var)'];
compiler.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 60;  9; 10;10;  34; 0;10;22;2;16;0.26;1;[];['    applySlicing(const Variable & self,PyObject *index,variable_list & outIndices,bool is_tracing,const at::Device & self_device,const IntArrayRef & self_sizes)', '    count_specified_dimensions(PyObject *index)', '    checkUnpackSlice(PyObject *index,Py_ssize_t *start_ptr,Py_ssize_t *stop_ptr,Py_ssize_t *step_ptr)', '    recordSelectTrace(const Tensor & index_tensor)', '    recordSliceTrace(PyObject *obj)', '    sequenceToVariable(c10::DispatchKey dispatch_key,PyObject *seq)', '    valueToTensor(c10::TensorOptions options,PyObject *value,const at::Device & device)', '    treatSequenceAsTuple(PyObject *index)', '    wrapTuple(PyObject *index)', '    obj', '    THPVariable_getitem(PyObject *self,PyObject *index)', '    THPVariable_setitem(PyObject *self,PyObject *index,PyObject *py_value)', '    THPVariable_length(PyObject *self)'];
fused_kernel.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cpu; 343;  40; 29;37;  231; 20;134;101;89;64;0.17;13;[];['    THPVariable_getitem(PyObject *self,PyObject *index)', '    THPVariable_length(PyObject *self)', '    THPVariable_setitem(PyObject *self,PyObject *index,PyObject *value)'];
resource_strings.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cpu; 107;  8; 88;2;  13; 0;5;13;0;6;0.62;0;[];['    dispatch_contiguous(const Tensor & self,at::MemoryFormat memory_format)', '    dispatch_copy_(Tensor & self,const Tensor & other,bool non_blocking)', '    dispatch_invert(const Tensor & self)', '    dispatch_nonzero(const Tensor & self)', '    dispatch_nonzero_numpy(const Tensor & self)', '    dispatch_to(const Tensor & self,Device device,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to(const Tensor & self,Device device,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    dispatch_to_Bool(const Tensor & self)', '    dispatch_to_CComplexDouble(const Tensor & self)', '    dispatch_to_CDouble(const Tensor & self)', '    dispatch_to_CLong(const Tensor & self)', '    THPVariable__is_view(PyObject *self,PyObject *args)', '    THPVariable_apply_(PyObject *self,PyObject *arg)', '    THPVariable_bfloat16(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_bool(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_bool_scalar(PyObject *self,PyObject *args)', '    THPVariable_byte(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_char(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_contiguous(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_copy_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_cpu(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_cuda(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_data_ptr(PyObject *self_,PyObject *args)', '    THPVariable_dim(PyObject *self,PyObject *args)', '    THPVariable_double(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_element_size(PyObject *self,PyObject *args)', '    THPVariable_float(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_float_scalar(PyObject *self,PyObject *args)', '    THPVariable_get_device(PyObject *self_,PyObject *args)', '    THPVariable_half(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_has_names(PyObject *self_,PyObject *args)', '    THPVariable_index_scalar(PyObject *self,PyObject *args)', '    THPVariable_int(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_integral_scalar(PyObject *self,PyObject *args)', '    THPVariable_invert(PyObject *self,PyObject *args)', '    THPVariable_is_contiguous(PyObject *self_,PyObject *args,PyObject *kwargs)', '    THPVariable_item(PyObject *self,PyObject *args)', '    THPVariable_long(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_map2_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_map_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new_ones(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_new_tensor(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_nonzero(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_numel(PyObject *self,PyObject *args)', '    THPVariable_numpy(PyObject *self,PyObject *arg)', '    THPVariable_record_stream(PyObject *self,PyObject *arg)', '    THPVariable_requires_grad_(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_short(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_size(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_storage(PyObject *self,PyObject *arg)', '    THPVariable_storage_offset(PyObject *self_,PyObject *args)', '    THPVariable_storage_type(PyObject *self,PyObject *arg)', '    THPVariable_stride(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_to(PyObject *self,PyObject *args,PyObject *kwargs)', '    THPVariable_to_type(PyObject *self,ScalarType scalarType,c10::optional optional_memory_format)', '    THPVariable_tolist(PyObject *self,PyObject *args)', '    THPVariable_type(PyObject *self,PyObject *args,PyObject *kwargs)', '    TypeError_to_NotImplemented_(PyObject *self,PyObject *args,PyObject *kwargs)', '    $', '    dispatch_is_contiguous(Tensor & self,MemoryFormat memory_format)'];
temp_file.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cpu; 134;  8; 21;29;  73; 11;36;28;34;25;0.11;8;[];[];
fused_kernel.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cuda; 240;  29; 26;22;  165; 6;83;81;178;52;0.18;7;['    TensorHybrid'];['    newAtTensor(facebook::jni::alias_ref jbuffer,facebook::jni::alias_ref jshape,jint jdtype)', '    once', '    _s', '    _s', '    common_registerNatives', '    dict', '    dict', '    list', '    list', '    list', '    list', '    list', '    put(facebook::jni::alias_ref key,facebook::jni::alias_ref value)', '    shapeVec', '    init', '    initHybrid(facebook::jni::alias_ref jTensorThis)', '    newAtTensorFromJTensor(facebook::jni::alias_ref jtensor)', '    newJTensorFromAtTensor(const at::Tensor & input_tensor)', '    JIValueToAtIValue(facebook::jni::alias_ref jivalue)', '    newJIValueFromAtIValue(const at::IValue & ivalue)', '    tensor', '    TensorHybrid(at::Tensor tensor)', '  Static Member Variables', '    is_initialized_'];
resource_strings.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cuda; 236;  22; 167;9;  25; 20;15;25;2;12;0.88;2;['    JIValue', '    Trace'];['    common_registerNatives', '    JIValueToAtIValue(facebook::jni::alias_ref jivalue)', '    newJIValueFromAtIValue(const at::IValue & ivalue)', '    beginSection(const char *name)', '    endSection', '    ensureInit', '    init', '    Trace(const char *name)', '    ~Trace'];
executor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 409;  64; 40;17;  296; 0;178;126;132;161;0.22;8;['    final', '    PytorchJni'];['    once', '    _s', '    inputs', '    inputs', '    JNI_OnLoad(JavaVM *vm,void *)', '    output', '    output', '    initHybrid(facebook::jni::alias_ref,facebook::jni::alias_ref modelPath)', '    preModuleLoadSetupOnce', '    registerNatives', '    MemoryReadAdapter(const void *data,off_t size)', '    read(uint64_t pos,void *buf,size_t n,const char *what)', '    size', '    ~MemoryReadAdapter', '    no_autograd_guard', '    no_optimizer_guard', '    non_var_guard', '    forward(facebook::jni::alias_ref jinputs)', '    preModuleLoadSetup', '    PytorchJni(facebook::jni::alias_ref modelPath)', '    runMethod(facebook::jni::alias_ref jmethodName,facebook::jni::alias_ref jinputs)'];
executor.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 23;  5; 5;6;  10; 0;1;10;0;4;0.50;0;['    PytorchJni'];['    inputs', '    inputs', '    JNI_OnLoad(JavaVM *vm,void *)', '    output', '    output', '    initHybrid(facebook::jni::alias_ref,facebook::jni::alias_ref modelPath)', '    registerNatives', '    non_var_guard', '    forward(facebook::jni::alias_ref jinputs)', '    PytorchJni(facebook::jni::alias_ref modelPath)', '    runMethod(facebook::jni::alias_ref jmethodName,facebook::jni::alias_ref jinputs)'];
fallback.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 15;  3; 5;3;  7; 0;0;7;0;4;0.43;0;[];['    pytorch_qnnp_create_add_nc_q8(size_t channels,uint8_t a_zero_point,float a_scale,uint8_t b_zero_point,float b_scale,uint8_t sum_zero_point,float sum_scale,uint8_t sum_min,uint8_t sum_max,uint32_t flags,pytorch_qnnp_operator_t *add_out)', '    pytorch_qnnp_create_average_pooling2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *average_pooling_out)', '    pytorch_qnnp_create_channel_shuffle_nc_x8(size_t groups,size_t group_channels,uint32_t flags,pytorch_qnnp_operator_t *channel_shuffle_out)', '    pytorch_qnnp_create_clamp_nc_u8(size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *clamp_out)', '    pytorch_qnnp_create_convolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t kernel_height,uint32_t kernel_width,uint32_t subsampling_height,uint32_t subsampling_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *convolution_out)', '    pytorch_qnnp_create_deconvolution2d_nhwc_q8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t adjustment_height,uint32_t adjustment_width,uint32_t kernel_height,uint32_t kernel_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,uint32_t groups,size_t group_input_channels,size_t group_output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *deconvolution_out)', '    pytorch_qnnp_create_fully_connected_nc_q8(size_t input_channels,size_t output_channels,uint8_t input_zero_point,float input_scale,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *fully_connected_out)', '    pytorch_qnnp_create_global_average_pooling_nwc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *global_average_pooling_out)', '    pytorch_qnnp_create_leaky_relu_nc_q8(size_t channels,float negative_slope,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *leaky_relu_out)', '    pytorch_qnnp_create_max_pooling2d_nhwc_u8(uint32_t input_padding_top,uint32_t input_padding_right,uint32_t input_padding_bottom,uint32_t input_padding_left,uint32_t pooling_height,uint32_t pooling_width,uint32_t stride_height,uint32_t stride_width,uint32_t dilation_height,uint32_t dilation_width,size_t channels,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *max_pooling_out)', '    pytorch_qnnp_create_sigmoid_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *sigmoid_out)', '    pytorch_qnnp_create_softargmax_nc_q8(size_t channels,float input_scale,uint8_t output_zero_point,float output_scale,uint32_t flags,pytorch_qnnp_operator_t *softargmax_out)', '    pytorch_qnnp_create_tanh_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *tanh_out)', '    pytorch_qnnp_deinitialize', '    pytorch_qnnp_delete_operator(pytorch_qnnp_operator_t op)', '    pytorch_qnnp_initialize', '    pytorch_qnnp_run_operator(pytorch_qnnp_operator_t op,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_add_nc_q8(pytorch_qnnp_operator_t add_op,size_t batch_size,const uint8_t *a,size_t a_stride,const uint8_t *b,size_t b_stride,uint8_t *sum,size_t sum_stride)', '    pytorch_qnnp_setup_average_pooling2d_nhwc_q8(pytorch_qnnp_operator_t average_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_channel_shuffle_nc_x8(pytorch_qnnp_operator_t channel_shuffle_op,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_clamp_nc_u8(pytorch_qnnp_operator_t clamp,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_convolution2d_nhwc_q8(pytorch_qnnp_operator_t convolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_deconvolution2d_nhwc_q8(pytorch_qnnp_operator_t deconvolution,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_fully_connected_nc_q8(pytorch_qnnp_operator_t fully_connected,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_global_average_pooling_nwc_q8(pytorch_qnnp_operator_t global_average_pooling_op,size_t batch_size,size_t width,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_leaky_relu_nc_q8(pytorch_qnnp_operator_t leaky_relu,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_max_pooling2d_nhwc_u8(pytorch_qnnp_operator_t max_pooling,size_t batch_size,size_t input_height,size_t input_width,const uint8_t *input,size_t input_pixel_stride,uint8_t *output,size_t output_pixel_stride,pthreadpool_t threadpool)', '    pytorch_qnnp_setup_sigmoid_nc_q8(pytorch_qnnp_operator_t sigmoid,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_softargmax_nc_q8(pytorch_qnnp_operator_t softargmax,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)', '    pytorch_qnnp_setup_tanh_nc_q8(pytorch_qnnp_operator_t tanh,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
fused_kernel.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 95;  20; 13;8;  57; 0;9;41;7;24;0.35;8;[];['    imageYUV420CenterCropToFloatBuffer(JNIEnv *jniEnv,jclass,jobject yBuffer,jint yRowStride,jint yPixelStride,jobject uBuffer,jobject vBuffer,jint uRowStride,jint uvPixelStride,jint imageWidth,jint imageHeight,jint rotateCWDegrees,jint tensorWidth,jint tensorHeight,jfloatArray jnormMeanRGB,jfloatArray jnormStdRGB,jobject outBuffer,jint outOffset)'];
interface.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 106;  10; 21;6;  72; 0;38;37;27;28;0.14;9;[];['    pytorch_qnnp_requantize_q31__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
kernel_cache.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 92;  14; 15;6;  61; 0;32;32;14;26;0.23;8;[];[];
kernel_cache.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 36;  10; 10;7;  12; 0;0;12;0;8;0.83;0;[];[];
kernel_spec.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 148;  24; 14;15;  98; 0;25;57;11;79;0.24;23;[];['    pytorch_qnnp_requantize_q31__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
tensor_desc.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 102;  9; 17;9;  70; 0;23;41;18;34;0.13;12;[];[];
tensor_info.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 28;  5; 5;5;  16; 0;2;11;2;8;0.31;2;[];['    pytorch_qnnp_requantize_q31__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
builtin_functions.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 146;  14; 45;4;  86; 0;57;46;35;30;0.16;7;[];[];
canonicalize_modified_loop.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 70;  8; 8;7;  49; 0;24;24;11;49;0.16;3;[];['    pytorch_qnnp_requantize_q31__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
canonicalize_modified_loop.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 16;  4; 5;3;  6; 0;0;6;0;4;0.67;0;[];['    pytorch_qnnp_requantize_q31__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
code_template.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 238;  31; 14;5;  191; 0;100;58;87;69;0.16;15;[];[];
concrete_module_type.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 232;  79; 35;7;  114; 0;14;83;11;76;0.69;12;[];[];
convert_to_ssa.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 331;  46; 34;8;  245; 0;155;97;112;84;0.19;19;[];['    pytorch_q8avgpool_ukernel_mp8x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_mp8x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,int32_t *buffer,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8x9__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8x9__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8xm__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8avgpool_ukernel_up8xm__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
convert_to_ssa.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 16;  3; 4;6;  5; 0;0;5;0;3;0.60;0;[];[];
edit_distance.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 15;  2; 4;3;  8; 0;0;8;0;3;0.25;0;[];['    pytorch_q8conv_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8conv_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8conv_ukernel_4x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8conv_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8conv_ukernel_8x8__neon(size_t mr,size_t nr,size_t kc,size_t ks,const uint8_t **a,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
error_report.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 85;  6; 14;12;  50; 10;23;20;20;13;0.12;8;[];[];
error_report.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 54;  7; 13;3;  33; 0;2;26;2;24;0.21;3;[];['    pytorch_q8dwconv_ukernel_mp8x25__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_mp8x25__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,int32_t *outacc32,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__aarch32_neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8dwconv_ukernel_up8x9__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
exit_transforms.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 12;  2; 4;3;  5; 0;0;5;0;3;0.40;0;[];[];
function_schema_parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 315;  12; 16;9;  286; 0;161;90;122;106;0.04;13;[];['    pytorch_q8gavgpool_ukernel_mp8x7p7q__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_mp8x7p7q__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,int32_t *buffer,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8x7__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8x7__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8xm__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)', '    pytorch_q8gavgpool_ukernel_up8xm__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
function_schema_parser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 17;  2; 4;5;  8; 0;0;0;0;0;0.25;0;['    COMPUTE_ROW_SUM_Op', '    Q8GEMM', '    Q8GEMM_L1', '    Q8GEMM_Op', '    Q8GEMM_XZP', '    Q8GEMM_XZP_L1', '    Q8GEMM_XZP_Op'];['    GemmArguments(benchmark::internal::Benchmark *b)', '    MobileNetV1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G1GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4GemmArguments(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8GemmArguments(benchmark::internal::Benchmark *b)', '    SqueezeNetV10GemmArguments(benchmark::internal::Benchmark *b)', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)', '    COMPUTE_ROW_SUM_Op', '    SetUp(const benchmark::State & state)', '    TearDown(benchmark::State & state)', '    a', '    b', '    c', '    k', '    kc', '    kc_', '    kcStride', '    kr', '    kr_', '    mc', '    mc_', '    mr', '    mr_', '    nc', '    nc_', '    ncStride', '    np', '    np_', '    nr', '    nr_', '    Q8GEMM(uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    quantizationParams', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    w', '    w', '    Q8GEMM_L1', '    Q8GEMM_Op', '    SetUp(const benchmark::State & state)', '    aRowSums', '    aRowSums', '    Q8GEMM_XZP(uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    requantizationParams', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)', '    Q8GEMM_XZP_L1', '    Q8GEMM_XZP_Op', '    SetUp(const benchmark::State & state)'];
inline_loop_condition.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 16;  2; 4;6;  6; 0;0;6;0;4;0.33;0;[];[];
ir_emitter.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 3682;  516; 257;26;  2926; 0;1966;1160;1075;906;0.18;153;[];['    pytorch_q8gemm_dq_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)', '    pytorch_q8gemm_dq_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params *quantization_params)', '    pytorch_q8gemm_dq_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params [1] quantization_params)', '    pytorch_q8gemm_dq_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,const float *b,float *c,size_t c_stride,const struct pytorch_qnnp_conv_dynamic_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_2x4c8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_2x4c8__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_3x3c8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_4x4c2__sse2(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_4x8__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_4x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_6x4__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_ukernel_8x8__aarch64_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params *quantization_params)', '    pytorch_q8gemm_ukernel_8x8__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)', '    pytorch_q8gemm_xzp_ukernel_4x8c2__aarch32_neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params *requantization_params)', '    pytorch_q8gemm_xzp_ukernel_4x8c2__neon(size_t mr,size_t nr,size_t k,const uint8_t *a,size_t a_stride,const int32_t *a_sum,const void *w,uint8_t *c,size_t c_stride,const union pytorch_qnnp_q31_requantization_params [1] requantization_params)', '    pytorch_q8sumrows_ukernel_4x__neon(const uint8_t *a,size_t m,size_t k,size_t stride,const int32_t multiplier,int32_t *a_sum)'];
ir_emitter.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 21;  2; 5;10;  6; 0;0;6;0;5;0.33;0;[];[];
lexer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 520;  74; 28;103;  323; 0;178;96;308;107;0.23;22;[];['    pytorch_q8vadd_ukernel__neon(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)', '    pytorch_q8vadd_ukernel__sse2(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)'];
mini_environment.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 55;  5; 11;3;  38; 0;14;19;13;14;0.13;5;[];['    adaptive_avg_pool2d_single_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t sizeC,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideC,int64_t istrideH,int64_t istrideW)', '    end_index(int out_idx,int out_len,int in_len)', '    get_output_shape(const Tensor & input,IntArrayRef output_size)', '    q_adaptive_avg_pool2d(const Tensor & input,IntArrayRef output_size)', '    quantized_adaptive_avg_pool2d(const at::Tensor & input,IntArrayRef output_size)', '    start_index(int out_idx,int out_len,int in_len)'];
parse_string_literal.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 90;  7; 6;4;  76; 0;58;19;49;14;0.09;4;[];['    avg_pool2d_out_frame(const Tensor & input,Tensor & output,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    get_kernel(IntArrayRef kernel_size)', '    get_output_shape(const Tensor & input_,int kW,int kH,int dW,int dH,int padW,int padH,bool ceil_mode)', '    get_padding(IntArrayRef padding)', '    get_stride(IntArrayRef stride,int kW,int kH)', '    q_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    quantized_avg_pool2d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)'];
parser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 33;  2; 6;5;  22; 0;0;20;0;15;0.09;0;[];['    get_kernel(IntArrayRef kernel_size)', '    get_output_shape(const Tensor & input_,int kW,int kH,int kD,int dW,int dH,int dD,int padW,int padH,int padD,bool ceil_mode)', '    get_padding(IntArrayRef padding)', '    get_stride(IntArrayRef stride,int kW,int kH,int kD)', '    q_avg_pool3d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)', '    quantized_avg_pool3d(const Tensor & input,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,bool ceil_mode,bool count_include_pad,c10::optional divisor_override)'];
parser_constants.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 7;  2; 1;1;  5; 0;1;5;0;3;0.40;0;['    final', '    final', '    final', '    final'];['    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _add_scalar_out(Tensor & out,const Tensor & self,Scalar other)', '    check_inputs(const Tensor & qa,const Tensor & qb)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)', '    operator()(Tensor qa,Scalar b)', '    operator()(Tensor qa,Tensor qb,Tensor out)', '    operator()(Tensor qa,Scalar b,Tensor out)'];
resolver.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 68;  21; 9;4;  36; 0;8;20;8;15;0.58;6;['    final', '    final'];['    compute_fused_params(const int64_t channels,const float *weight_data,const float *bias_data,const float *mean_data,const float *var_data,double eps,double input_scale,double output_scale,float *alpha_data,float *beta_data)', '    q_batch_norm3d_impl(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    q_batch_norm_impl(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    quantized_batch_norm(const Tensor & qx,const Tensor & weight,const Tensor & bias,const Tensor & mean,const Tensor & var,double eps,double output_scale,int64_t output_zero_point)', '    operator()(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)', '    operator()(Tensor,Tensor weight,Tensor bias,Tensor mean,Tensor var,double eps,double output_scale,int64_t output_zero_point)'];
schema_matching.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 63;  7; 10;5;  43; 0;4;42;0;12;0.16;0;['    final'];['    quantized_clamp(const Tensor & qx,optional min,optional max)', '    quantized_clamp_impl(const Tensor & qx,optional min,optional max)', '    quantized_hardtanh(const Tensor & qx,Scalar min,Scalar max)', '    quantized_hardtanh_(Tensor & self,Scalar min,Scalar max)', '    quantized_hardtanh_out(Tensor & result,const Tensor & qx,Scalar min,Scalar max)', '    operator()(Tensor,optional min,optional max)'];
schema_type_parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 300;  24; 15;10;  258; 0;100;111;53;314;0.09;5;['    final', '    final'];['    is_cat_nhwc_fast_path(const c10::List & qxs,int dim)', '    is_valid_quantization_scheme(const Tensor & t)', '    quantized_cat(TensorList qxs,int64_t dim)', '    quantized_cat_impl(const c10::List & qxs,int64_t dim,double scale,int64_t zero_point)', '    quantized_cat_out(Tensor & out,TensorList qxs,int64_t dim)', '    operator()(const c10::List & qxs,int64_t dim,c10::optional scale,c10::optional zero_point)', '    operator()(const c10::List & qxs,int64_t dim,Tensor out)'];
schema_type_parser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 36;  2; 7;5;  24; 0;3;19;2;16;0.08;1;['    final'];['    ConvDimChecks(int64_t act_dims,int64_t stride_dims,int64_t padding_dims,int64_t dilation_dims)', '    operator()(Tensor act,Tensor packed_weight,torch::List stride,torch::List padding,torch::List dilation,int64_t groups,double output_scale,int64_t output_zero_point)'];
script_type_parser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 48;  8; 9;5;  28; 0;1;25;0;18;0.29;2;['    final'];['    operator()(Tensor weight,c10::optional bias,torch::List stride,torch::List padding,torch::List dilation,int64_t groups)'];
source_range.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 133;  15; 11;2;  111; 0;72;36;72;23;0.14;4;['    final'];['    Tensor'];
source_range.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 201;  22; 28;6;  147; 0;0;0;0;0;0.15;0;[];['    quantized_elu(const Tensor & qx,Scalar alpha,Scalar scale,Scalar input_scale)', '    quantized_elu_(Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)', '    quantized_elu_out(Tensor & result,const Tensor & self,Scalar alpha,Scalar scale,Scalar input_scale)'];
strtod.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 251;  16; 11;19;  13; 198;3;9;2;6;1.23;2;[];[];
strtod.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 12;  2; 4;2;  6; 0;0;6;0;4;0.33;0;[];['    quantized_hardsigmoid(const Tensor & qx)'];
sugared_value.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 626;  46; 57;5;  520; 0;325;232;177;153;0.09;27;[];['    quantized_hardswish(const Tensor & qx)', '    quantized_hardswish_(Tensor & qx)'];
tracer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 875;  59; 69;20;  734; 0;470;290;307;208;0.08;61;[];['    qint32(int32_t val)'];
tracer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 332;  20; 48;14;  253; 0;44;161;48;109;0.08;20;[];['    qint8(int8_t val)'];
tree.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 224;  21; 20;8;  178; 0;73;77;56;80;0.12;26;['    final'];['    operator()(at::Tensor input,at::Tensor packed_weight,double output_scale,int64_t output_zero_point)'];
alias_analysis.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 1366;  212; 163;4;  997; 0;601;270;525;244;0.21;79;['    final', '    final'];['    operator()(at::Tensor,at::Tensor)', '    operator()(at::Tensor input,at::Tensor packed_weight)'];
alias_analysis.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 229;  94; 33;6;  98; 0;2;95;0;84;0.96;0;['    final', '    final'];['    operator()(at::Tensor weight,c10::optional bias)', '    operator()(at::Tensor weight,c10::optional bias)'];
attributes.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 20;  2; 4;2;  14; 0;5;8;6;6;0.14;2;['    final', '    final'];['    Tensor', '    Tensor'];
constants.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 215;  5; 10;6;  198; 0;156;44;115;33;0.03;6;['    final', '    final', '    final', '    final'];['    _mul_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _mul_scalar_out(Tensor & out,const Tensor & self,Scalar other)', '    check_inputs(const Tensor & qa,const Tensor & qb)', '    operator()(at::Tensor qa,at::Tensor qb,Tensor out)', '    operator()(Tensor qa,Scalar b)', '    operator()(Tensor qa,Scalar b,Tensor out)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)'];
constants.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 60;  19; 9;6;  28; 0;0;0;0;0;0.68;0;['    final', '    final'];['    qnnpackConv(const conv_param_t & conv_p,void *packed_weights,const size_t batch_size,const size_t input_height,const size_t input_width,const float input_scale,const uint8_t input_zero_point,const uint8_t *input,const float output_scale,const uint8_t output_zero_point,uint8_t *output,pthreadpool_t threadpool)', '    qnnpackLinear(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t output_zero_point,const float output_scale,const uint8_t output_min,const uint8_t output_max,const uint8_t *input,const size_t input_stride,void *packed_weights,uint8_t *output,const size_t output_stride,pthreadpool_t threadpool)', '    qnnpackLinearDynamic(const size_t batch_size,const size_t input_channels,const size_t output_channels,const uint8_t input_zero_point,const float input_scale,const uint8_t kernel_zero_point,const float kernel_scale,const uint8_t *input,const size_t input_stride,void *packed_weights,const float *bias,float *output,const size_t output_stride,pthreadpool_t threadpool)', '    getInputChannels', '    getOutputChannels', '    getOutputChannels', '    getPackedWeights', '    getPackedWeights', '    operator=', '    operator=', '    PackBMatrix(size_t input_channels,size_t output_channels,uint8_t kernel_zero_point,float kernel_scale,const uint8_t *kernel,const int32_t *bias)', '    PackBMatrix', '    PackBMatrix', '    PrePackConvWeights(const conv_param_t & conv_param,const uint8_t *kernel,const int32_t *bias)', '    PrePackConvWeights', '    PrePackConvWeights', '    ~PackBMatrix', '    ~PrePackConvWeights'];
graph_node_list.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 201;  40; 21;2;  143; 0;0;0;0;0;0.28;0;[];[];
ir.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 1386;  322; 164;34;  871; 0;0;0;0;0;0.37;0;['    final'];['    check_maxpool2d_params(IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation)', '    q_maxpool_2d(Tensor,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,bool ceil_mode)', '    quantized_max_pool2d(const Tensor & qx,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding,IntArrayRef dilation,bool ceil_mode)', '    spatial_dilated_max_pooling(const T *iData,int64_t iC,int64_t iH,int64_t iW,int64_t oH,int64_t oW,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,T *oData)', '    operator()(Tensor,std::vector kernel_size,std::vector stride,std::vector padding,std::vector dilation,bool ceil_mode)'];
ir_views.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 162;  17; 14;2;  134; 0;55;54;50;45;0.13;29;[];['    quantized_mean_cpu(const Tensor & self,optional dtype)', '    quantized_mean_cpu(const Tensor & self,IntArrayRef dim,bool keepdim,optional dtype)', '    quantized_mean_cpu(const Tensor & self,DimnameList dim,bool keepdim,optional dtype)', '    quantized_mean_out_cpu(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    quantized_mean_out_cpu(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,c10::optional opt_dtype)'];
irparser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 476;  73; 48;7;  352; 0;190;115;155;138;0.21;22;['    final'];['    quantized_leaky_relu(const Tensor & self,Scalar negval)', '    quantized_leaky_relu_(Tensor & self,Scalar negval)', '    quantized_leaky_relu_out(Tensor & result,const Tensor & self,Scalar negval)', '    quantized_relu(const Tensor & qx)', '    quantized_relu6(const Tensor & qx)', '    quantized_relu6_(Tensor & qx)', '    quantized_relu_(Tensor & qx)', '    operator()(Tensor,bool inplace)'];
named_value.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 84;  12; 15;6;  56; 0;0;0;0;0;0.21;0;[];['    self', '    THPQScheme_init(PyObject *module)', '    THPQScheme_New(at::QScheme qscheme,const std::string & name)', '    THPQScheme_reduce(THPQScheme *self,PyObject *noargs)', '    THPQScheme_repr(THPQScheme *self)'];
node_hashing.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 249;  14; 32;15;  192; 0;133;41;151;33;0.07;11;[];['    THPQScheme_Check(PyObject *obj)', '    THPQScheme_init(PyObject *module)', '    THPQScheme_New(at::QScheme qscheme,const std::string & name)'];
node_hashing.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 17;  2; 5;2;  10; 0;0;8;0;6;0.20;0;['    QScheme'];['    toString(QScheme qscheme)'];
scope.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 110;  41; 21;7;  43; 0;0;0;0;0;0.95;0;[];['    quantized_sigmoid(const Tensor & qx)'];
subgraph_matcher.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 341;  63; 31;3;  247; 0;116;39;133;36;0.26;10;[];['    quantized_topk_cpu(const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    quantized_topk_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool largest,bool sorted)'];
subgraph_matcher.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 53;  34; 6;4;  11; 0;0;10;0;7;3.09;0;[];['    quantized_tanh(const Tensor & qx)'];
type_hashing.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 18;  2; 5;3;  10; 0;0;8;0;6;0.20;0;[];['    noexcept'];
jit_log.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit; 133;  7; 19;12;  97; 0;56;44;40;30;0.07;8;[];['    _choose_qparams_per_tensor(const Tensor & self,bool reduce_range)', '    dequantize_quant(const Tensor & self)', '    dequantize_tensors_quant(TensorList tensors)', '    int_repr_quant(const Tensor & self)', '    make_per_channel_quantized_tensor_cpu(const Tensor & self,const Tensor & scales,const Tensor & zero_points,int64_t axis)', '    make_per_tensor_quantized_tensor_cpu(const Tensor & self,double scale,int64_t zero_point)', '    q_per_channel_axis_quant(const Tensor & self)', '    q_per_channel_scales_quant(const Tensor & self)', '    q_per_channel_zero_points_quant(const Tensor & self)', '    q_scale_quant(const Tensor & self)', '    q_zero_point_quant(const Tensor & self)', '    qscheme_quant(const Tensor & self)', '    quantize_per_channel_cpu(const Tensor & self,const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType dtype)', '    quantize_per_tensor_cpu(const Tensor & self,double scale,int64_t zero_point,ScalarType dtype)', '    quantized_clone(const Tensor & self,c10::optional optional_memory_format)', '    quantized_equal(const Tensor & self,const Tensor & other)', '    set_quantizer_(Tensor & self,ConstQuantizerPtr quantizer)', '    set_storage_quantized_cpu_(Tensor & self,Storage storage,int64_t storage_offset,IntArrayRef sizes,IntArrayRef strides)'];
jit_log.h;C++;pytorch-master/pytorch-master/torch/csrc/jit; 90;  34; 19;15;  24; 0;1;20;0;13;1.42;0;['    QTensor'];['    aligned_size', '    alignment', '    bias', '    canonical_axis_index(int axis_index)', '    data', '    dim32(const int i)', '    dims', '    GetBitAtIndex(const unsigned char bit,const size_t index)', '    is_signed', '    mutable_data', '    nbytes', '    ndim', '    precision', '    QTensor', '    QTensor(at::ArrayRef dims,const unsigned char precision,const bool signbit)', '    Resize(at::ArrayRef dim_source)', '    scale', '    SetBias(const double bias)', '    SetBitAtIndex(const unsigned char bit,const size_t index,const bool value)', '    SetPrecision(const unsigned char precision)', '    SetScale(const double scale)', '    SetSigned(const bool make_signed)', '    size', '    size_from_dim(int k)', '    size_to_dim(int k)', '    sizes', '    ~QTensor'];
function.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 36;  4; 6;3;  26; 0;1;21;1;19;0.15;0;[];[];
import.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 287;  27; 34;12;  218; 0;123;131;62;80;0.12;12;['    QTensorDeserializer', '    QTensorSerializer'];['    context', '    Deserialize(const BlobProto & blob_proto,Blob *blob)', '    Deserialize(const QTensorProto & proto,QTensor *qtensor)', '    QTensorSerializer', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,BlobSerializerBase::SerializationAcceptor acceptor)', '    ~QTensorSerializer'];
import.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 27;  2; 6;5;  16; 0;3;13;3;8;0.13;0;[];['    QTensorImpl(Storage,DispatchKeySet key_set,QuantizerPtr quantizer)'];
interpreter.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 32;  4; 4;5;  23; 0;1;19;1;20;0.17;0;[];['    copy_tensor_metadata(const QTensorImpl *src_q_impl,QTensorImpl *dest_q_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    QTensorImpl(Storage,DispatchKeySet key_set,QuantizerPtr quantizer)', '    quantizer', '    set_quantizer_(QuantizerPtr quantizer)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    copy_tensor_metadata'];
module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 92;  4; 12;12;  57; 12;23;25;24;19;0.07;8;[];[];
module.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 48;  4; 5;2;  40; 0;4;28;4;25;0.10;5;['    GetQuantDecodeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUQuantDecode', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecode', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecodeGradient', '    GetGradientDefs'];
observer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 67;  1; 16;3;  48; 0;10;24;8;21;0.02;11;['    final', '    final', '    QuantDecodeRunTy'];['    Decode(const Tensor & codebook,const Tensor & codes,const Tensor *const decoded_grad,Tensor *const output,bool resizeOnly)', '    Decode(codebook_,codes_,gradient_,outDecoded_,resizeOnly_)', '    DecodeGeneral(const Tensor & codebook,const Tensor & codes,const Tensor *gradient,Tensor *outDecoded,bool resizeOnly)', '    Decode(codebook_,codes_,gradient_,outDecoded_,resizeOnly_)', '    ResizeLike', '    hasRun_', '    QuantDecodeGradientOp(Args,...)', '    QuantDecodeOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    ~QuantDecodeGradientOp', '    ~QuantDecodeOp', '    Id'];
register_mobile_autograd.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 147;  5; 7;5;  134; 0;73;107;27;44;0.04;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUQuantDecompZstd', '    GetMutableData(int type_index,TensorCPU *tensor)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_QuantDecompZstd', '    Decompress(const TensorProto & compressed,TensorCPU *outDecomp)', '    GetCompressedPtr(const TensorCPU & compressed,size_t *out_size)', '    GetTensorsProto(const TensorCPU & compressed)', '    RunOnDevice'];
register_mobile_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 536;  6; 28;23;  470; 10;117;109;63;551;0.01;20;['    final'];['    QuantDecompZstdOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~QuantDecompZstdOp'];
type_parser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 5;  1; 1;1;  3; 0;0;3;0;2;0.33;0;[];['    ChooseQuantizationParams(float min,float max,int32_t qmin,int32_t qmax,bool preserve_sparsity,bool force_scale_power_of_two,bool reduce_range)'];
bailout_graph.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 393;  80; 43;9;  263; 0;145;110;121;91;0.30;22;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUQuantile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Quantile'];
bailout_graph.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 34;  13; 5;9;  9; 0;0;9;0;4;1.44;0;['    final'];['    CountLowerEq(const T & thd)', '    DoRunWithType', '    GetRangeFromInputs(T *lo,T *hi)', '    GetSingleArgument', '    QuantileOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
batch_mm.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    FoldConvBatchNorm2dHelper', '    InsertQuantDeQuantHelper', '    ModuleUseDeduper', '    InsertObserversHelper', '    ModuleCloneHelper'];['    hastensor(Module & m,const char *name)', '    addBiasForConv2dIfNone(Module & module)', '    checkGetQParamsResult(const IValue & qparams)', '    DedupModuleUses(Module & module)', '    extractOptionalBNParams(const script::Module & bn,ConvBNParameters & r)', '    filter_fn', '    Finalize(script::Module & module)', '    findObserverName(Value *v)', '    FoldConvBatchNorm2d(const Module & module)', '    FoldPrepackedWeightIntoModule(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    FoldQuantizeCallIntoBuffer(Module & module,const std::string & method_name)', '    FoldQuantizedPrepackingOps(Module & module)', '    FoldQuantNodesIntoInputsOutputs(std::shared_ptr & graph)', '    insertDeQuantCall(Graph *graph,Value *quantized_val,Value *original_val,const std::vector & uses)', '    InsertObservers(Module & input_module,const std::string & method_name,const QConfigDict & qconfig_dict,bool inplace,bool is_dynamic)', '    InsertPrepackUnpack(std::shared_ptr & graph)', '    InsertPrepackUnpack(Module & module)', '    insertPrepackUnpackForConv(std::shared_ptr & graph)', '    insertPrepackUnpackForLinear(std::shared_ptr & graph)', '    InsertQuantDeQuant(Module & input_module,const std::string & method_name,bool inplace)', '    insertQuantDeQuantCall(Value *self,Node *observer,bool is_per_channel,const std::vector & qparam_names)', '    QuantFusion(std::shared_ptr & graph)', '    replaceConv2dBiasWithGetAttr(Module & module)', '    ReplicateDeQuant(std::shared_ptr & graph)', '    ReplicateQuant(std::shared_ptr & graph)', '    rv', '    swapDeQuant(Block *block)', '    SwapDeQuant(std::shared_ptr & graph)', '    SwapFunctionalLinear(Module & module)', '    SwapFunctionalLinear(std::shared_ptr & graph)', '    toAffine(c10::QScheme qscheme)', '    alwaysRaisesException(Block *block)', '    fillQConfigMap(const Module & module,const QConfigDict & qconfig_dict,ModuleQConfigMap & map,const std::string & key,const c10::optional & parent_qconfig)', '    findChildModule(const Module & module,const std::vector & path)', '    getCallFunctionGraph(Node *n)', '    getGeneralOpTensorInputs(Node *n)', '    getInvokedModule(Module & module,Node *n,Value *self)', '    getModuleAccessPath(Value *instance,Value *self)', '    getObserverModuleFor(Value *v,const QConfig & qconfig)', '    hitGraphInput(Value *value)', '    isAddScalar(Node *n)', '    isAtenFuncNthArg(Value *v,Node *use,const std::string & func_name,int n)', '    isBiasOfConvOrLinear(Value *v)', '    isCallFunctionNthArg(Value *v,Node *use,const std::string & func_name,int n)', '    isFunctionNode(Node *n,const std::vector & call_funcs,const std::vector & aten_funcs)', '    isPerChannel(at::QScheme qscheme)', '    isWeightOfConvOrLinear(Value *v)', '    matchArgPattern(Value *v,const AtenFuncArgs & aten_func_args,const CallFuncArgs & call_func_args)', '    mayRequireObservation(Value *v)', '    nodeQuantizable(Node *n)', '    userDefinedCallFunction(Node *n)', '    toTwoElementIntList(Value *v)', '    type_remap_fn', '    parse_from_str(std::string pattern_string)', '    analyze(Module & module)', '    computeUpdatedConvWeightAndBias(const ConvBNParameters & p)', '    transform', '    tryExtractingConvBNParameters(Module & conv,Module & bn,ConvBNParameters & r)', '    run(Module & module,const std::string & method_name,const Module & linear_params_module,const Module & conv_params_module)', '    run(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    addValuesToDelayObservation(const Module & module,const std::string & method_name)', '    delayObservingValuesInPattern(Graph & graph,const PatternInfo & pattern)', '    fillBoundaryValueMap(Module & module,const std::string & method_name)', '    fillPassThroughValueMap(const std::shared_ptr & graph)', '    fillValueObserverMap(Module & module,const std::string & method_name)', '    getObserverFor(Value *v)', '    preprocess(Module & module,const std::string & method_name)', '    propagateObservedProperty(Value *output,std::unordered_set & block_observed_values)', '    recordObserved(Value *v,Module observer_module,std::unordered_map & values_to_observe,std::unordered_set & block_observed_values)', '    setDynamicFlag(bool is_dynamic_)', '    valueNeedsToBeQuantized(Value *v)', '    checkQScheme(Graph *g,c10::QScheme qscheme)', '    cleanup(Module & module)', '    cleanup(Module & module,Graph *g)', '    collectObserverNodesAndValueToQuantize(Module & module,Value *v)', '    findChildModuleToQuantize(Module & module,Value *child_instance)', '    getInvokedMethods(Module & module,const std::string & method_name)', '    getQSchemeAndQParamVector(script::Module & module,Node *n)', '    InsertQuantDeQuantHelper', '    quantizeTensors(Module & module,Graph *g,Value *self)', '    run(Module & module,const std::string & method_name)', '    addChildModule(Module & module,const Module & child_module,const std::vector & path)', '    dedup', '    dedupModuleUses', '    findModuleUses(Graph *graph)', '    ModuleUseDeduper(Module & module)', '    getInvokedMethods(Module & module,const std::string & method_name)', '    insertObserverFor(Value *v,Module & module,const Module & observer_module,NameModuleVector & observer_name_and_modules)', '    InsertObserversHelper(const ModuleQConfigMap & map)', '    isObserved(Value *v,const std::unordered_set & block_observed_values)', '    clone(const Module & module,const ModuleQConfigMap & module_qconfig_map)', '    clone_impl(const Module & module,const ModuleQConfigMap & module_qconfig_map,std::unordered_map & type_remap)', '    clone_method(const Module & source,Module & target,const Function & method,const ModuleQConfigMap & module_qconfig_map,const std::unordered_map & type_remap)', '    remapTypes(Block *block,Value *self,const Module & source,Module & target,const ModuleQConfigMap & module_qconfig_map,const std::function & type_remap_fn)', '    remapTypes(Graph *graph,const Module & source,Module & target,const ModuleQConfigMap & module_qconfig_map,const std::function & type_remap_fn)'];
canonicalize.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 217;  40; 27;2;  150; 0;92;45;79;73;0.27;9;[];['    DedupModuleUses(Module & module)', '    FoldConvBatchNorm2d(const Module & module)', '    FoldPrepackedWeightIntoModule(Module & module,const Module & linear_params_module,const Module & conv_params_module)', '    FoldQuantizeCallIntoBuffer(Module & module,const std::string & method_name)', '    FoldQuantizedPrepackingOps(Module & module)', '    FoldQuantNodesIntoInputsOutputs(std::shared_ptr & graph)', '    InsertObservers(Module & module,const std::string & method_name,const QConfigDict & qconfig_dict,bool inplace,bool is_dynamic)', '    InsertPrepackUnpack(std::shared_ptr & graph)', '    InsertPrepackUnpack(Module & module)', '    InsertQuantDeQuant(Module & module,const std::string & method_name,bool inplace)', '    QuantFusion(std::shared_ptr & graph)', '    ReplicateDeQuant(std::shared_ptr & graph)', '    ReplicateQuant(std::shared_ptr & graph)', '    SwapDeQuant(std::shared_ptr & graph)', '    SwapFunctionalLinear(std::shared_ptr & graph)', '    SwapFunctionalLinear(Module & module)', '    has_value', '    operator()(const torch::jit::Module & arg)', '    _ivalue', '    operator()(const c10::optional & qconfig_opt)'];
canonicalize.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 14;  2; 4;2;  8; 0;1;8;0;4;0.25;0;['    L1ErrorMinimization', '    NormMinimization', '    P99', '    QuantizationErrorMinimization'];['    L1ErrorMinimization', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    NonlinearQuantizationParamsSearch(const Histogram & hist,bool preserve_sparsity,int precision)', '    NormMinimization(Kind kind)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    P99(float p99_threshold)', '    ChooseQuantizationParams(const Histogram & hist,bool preserve_sparsity,int precision)', '    ~QuantizationErrorMinimization'];
canonicalize_ops.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;[];['    quant_fusion_pattern_and_replacements'];
clear_undefinedness.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 38;  2; 5;2;  31; 0;16;11;14;9;0.06;3;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Quantize', '    QuantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
clear_undefinedness.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 24;  11; 4;6;  5; 0;0;5;0;3;2.20;0;['    final'];['    arguments_parsed_', '    QuantizeDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
common_subexpression_elimination.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 3;2;  6; 0;0;6;0;3;0.17;0;['    final'];['    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    _add_out(Tensor & out,const Tensor & self,const Tensor & other)', '    QHelper(Tensor qa)', '    operator()(Tensor qa,Tensor qb,double scale,int64_t zero_point)'];
constant_pooling.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 75;  12; 11;6;  49; 0;29;23;18;15;0.24;2;[];['    operator=', '    qadaptive_avg_pool2d_nhwc_stub', '    qadaptive_avg_pool2d_nhwc_stub', '    operator=', '    qadd_relu_stub', '    qadd_relu_stub', '    operator=', '    qadd_scalar_relu_stub', '    qadd_scalar_relu_stub', '    operator=', '    qadd_scalar_stub', '    qadd_scalar_stub', '    operator=', '    qadd_stub', '    qadd_stub', '    operator=', '    qavg_pool2d_nhwc_stub', '    qavg_pool2d_nhwc_stub', '    operator=', '    qavg_pool3d_nhwc_stub', '    qavg_pool3d_nhwc_stub', '    operator=', '    qbatch_norm_relu_stub', '    qbatch_norm_relu_stub', '    operator=', '    qbatch_norm_stub', '    qbatch_norm_stub', '    operator=', '    qcat_nhwc_stub', '    qcat_nhwc_stub', '    operator=', '    qcat_relu_nhwc_stub', '    qcat_relu_nhwc_stub', '    operator=', '    qclamp_stub', '    qclamp_stub', '    operator=', '    qelu_stub', '    qelu_stub', '    operator=', '    qhardsigmoid_stub', '    qhardsigmoid_stub', '    operator=', '    qhardswish_stub', '    qhardswish_stub', '    operator=', '    qmaxpool_2d_nhwc_stub', '    qmaxpool_2d_nhwc_stub', '    operator=', '    qmul_relu_stub', '    qmul_relu_stub', '    operator=', '    qmul_stub', '    qmul_stub', '    operator=', '    qrelu6_stub', '    qrelu6_stub', '    operator=', '    qrelu_leaky_stub', '    qrelu_leaky_stub', '    operator=', '    qrelu_stub', '    qrelu_stub', '    operator=', '    qsigmoid_stub', '    qsigmoid_stub', '    operator=', '    qtanh_stub', '    qtanh_stub', '    operator=', '    qtopk_stub', '    qtopk_stub', '    operator=', '    qupsample_bilinear2d_nhwc_stub', '    qupsample_bilinear2d_nhwc_stub'];
constant_pooling.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;[];['    callOp(const c10::OperatorHandle & op,Args,...)', '    callOp(const char *func_name,const char *overload_name,Args,...)', '    makeStack(Inputs,...)', '    has_value', '    value', '    singleton'];
constant_propagation.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 19;  6; 6;2;  7; 0;0;7;0;5;0.86;0;[];['    qx_expect', '    TEST(TestQTensor,QuantDequantAPIs)', '    TEST(TestQTensor,RoundingMode)', '    TEST(TestQTensor,Item)', '    TEST(TestQTensor,EmptyQuantized)', '    TEST(TestQTensor,EmptyPerchannelQuantized)', '    x_values'];
create_autodiff_subgraphs.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 178;  36; 20;7;  118; 0;56;49;51;31;0.31;8;[];['    fbgemm_is_cpu_supported', '    fbgemm_linear_fp16_weight(const Tensor & input,const Tensor & packed_weight,const Tensor & bias)', '    fbgemm_linear_fp16_weight_fp32_activation(const Tensor & input,const Tensor & packed_weight,const Tensor & bias)', '    fbgemm_linear_int8_weight(const Tensor &,const Tensor &,const Tensor &,const Tensor &,Scalar,Scalar,const Tensor &)', '    fbgemm_linear_int8_weight_fp32_activation(const Tensor &,const Tensor &,const Tensor &,const Tensor &,Scalar,Scalar,const Tensor &)', '    fbgemm_linear_quantize_weight(const Tensor &)', '    fbgemm_pack_gemm_matrix_fp16(const Tensor & weight)', '    fbgemm_pack_quantized_matrix(const Tensor &)', '    fbgemm_pack_quantized_matrix(const Tensor &,int64_t,int64_t)'];
create_autodiff_subgraphs.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 19;  6; 4;4;  7; 0;1;7;0;3;0.86;0;[];['    leaky_qrelu_out_kernel(Tensor & out,const Tensor & qx,Scalar negval_)', '    fake_quant_per_channel_cpu(TensorIterator & iter,int64_t quant_min,int64_t quant_max)', '    do_avg_pool_on_AVX2(T::underlying *i_p,T::underlying *o_p,int64_t & c,int64_t channel_size,int64_t channel_multiplier,int32_t input_zero_point_m_size,int32_t output_zero_point,float multiplier,int64_t dstart,int64_t dend,int64_t hstart,int64_t hend,int64_t wstart,int64_t wend,int64_t stride_C,int64_t stride_D,int64_t stride_H,int64_t stride_W)', '    do_quantized_bilinear_on_AVX2(const T::underlying *& pos1,T::underlying *& pos2,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t channels,int32_t output_zero_point,int32_t input_zero_point,float inverse_scale,const float h0lambda,const float h1lambda,const float w0lambda,const float w1lambda,const int64_t h1p,const int64_t w1p)', '    fake_quantize_grad_tensor_kernel(Tensor & input_grad,const Tensor & input,const Tensor & output_grad,float sc,int64_t z_point,int64_t quant_min,int64_t quant_max)', '    fake_quantize_tensor_kernel(Tensor & output,const Tensor & input,float sc,int64_t z_point,int64_t quant_min,int64_t quant_max)', '    q_batch_norm_kernel(int64_t N,int64_t C,int64_t HxW,int64_t in_zero_point,int64_t out_zero_point,const Tensor & input,const Tensor & a,const Tensor & b,Tensor & output)', '    qadaptive_avg_pool2d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t sizeC,int64_t isizeH,int64_t isizeW,int64_t osizeH,int64_t osizeW,int64_t istrideB,int64_t istrideC,int64_t istrideH,int64_t istrideW)', '    qadd_kernel(Tensor & out,const Tensor & self,const Tensor & other)', '    qadd_scalar_kernel(Tensor & out,const Tensor & self,Scalar other)', '    qavg_pool2d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t outputWidth,int64_t outputHeight,int kW,int kH,int dW,int dH,int padW,int padH,bool count_include_pad,c10::optional divisor_override)', '    qavg_pool3d_nhwc_kernel(const Tensor & qx,Tensor & qy,int64_t b,int64_t nInputPlane,int64_t inputWidth,int64_t inputHeight,int64_t inputDepth,int64_t outputWidth,int64_t outputHeight,int64_t outputDepth,int kW,int kH,int kD,int dW,int dH,int dD,int padW,int padH,int padD,bool count_include_pad,c10::optional divisor_override)', '    qcat_nhwc_kernel(const c10::List & qxs,int64_t dim,double scale,int64_t zero_point)', '    qclamp_kernel(const Tensor & qx,Scalar min_scalar,Scalar max_scalar,Tensor & qy)', '    qelu_kernel(const Tensor & qx,Scalar alpha,Tensor & qy)', '    qhardsigmoid_kernel(const Tensor & qx,Tensor & qy)', '    qhardswish_kernel(const Tensor & qx,Tensor & qy)', '    qmaxpool_2d_nhwc_kernel(const Tensor & qx,int64_t iC,int64_t iH,int64_t iW,int64_t oH,int64_t oW,int64_t kH,int64_t kW,int64_t sH,int64_t sW,int64_t pH,int64_t pW,int64_t dH,int64_t dW,Tensor & qy)', '    qmul_kernel(Tensor & out,const Tensor & self,const Tensor & other)', '    qrelu6_kernel(const Tensor & qx,Tensor & qy)', '    qrelu_kernel(const Tensor & qx,Tensor & qy)', '    qsigmoid_kernel(const Tensor & qx,Tensor & qy)', '    qtanh_kernel(const Tensor & qx,Tensor & qy)', '    qtopk_kernel(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    qupsample_bilinear2d_nhwc_kernel(Tensor & output,const Tensor & input,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    fake_quant_grad_per_channel_cpu(TensorIterator & iter,int64_t quant_min,int64_t quant_max)'];
create_functional_graphs.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 18;  4; 6;3;  7; 0;0;7;0;5;0.57;0;[];['    checkFloatCPUTensor(std::string fn_name,Tensor t)', '    checkQuantizedCPUTensor(std::string fn_name,Tensor t)', '    checkZeroPoint(std::string fn_name,int64_t zero_point)', '    checkZeroPoints(std::string fn_name,Tensor zero_points)', '    dequantize_tensor(Tensor qtensor,Tensor rtensor,double scale,int64_t zero_point)', '    dequantize_tensor_per_channel_affine(Tensor qtensor,Tensor rtensor,Tensor scales,Tensor zero_points,int64_t axis)', '    dequantize_val(double scale,int64_t zero_point,T value)', '    get_qtensorimpl(const Tensor & self)', '    make_per_channel_affine_quantizer(const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType scalar_type)', '    make_per_tensor_affine_quantizer(double scale,int64_t zero_point,ScalarType scalar_type)', '    new_qtensor_cpu(IntArrayRef sizes,const TensorOptions & options,QuantizerPtr quantizer)', '    quantize_tensor(Tensor rtensor,Tensor qtensor,double scale,int64_t zero_point)', '    quantize_tensor_per_channel_affine(Tensor rtensor,Tensor qtensor,Tensor scales,Tensor zero_points,int64_t axis)', '    quantize_val(double scale,int64_t zero_point,float value)', '    quantize_val_arm(const float scale,const int32_t zero_point,const float value)', '    quantize_vec(double scale,int64_t zero_point,const float *src,T *dst,size_t count)', '    requantize_from_int(double multiplier,int64_t zero_point,int64_t src)', '    requantize_val(double src_scale,int64_t src_zero_point,double dst_scale,int64_t dst_zero_point,SRC_T src)', '    Round(const T x)', '    dequantize(Tensor qtensor)', '    quantize(Tensor rtensor)', '    dequantize(Tensor qtensor)', '    quantize(Tensor rtensor)', '    ~Quantizer', '    quantizer'];
cuda_graph_fuser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 1231;  259; 103;15;  861; 0;617;405;432;325;0.30;46;[];['    dequantize_tensor(Tensor qtensor,Tensor rtensor,double scale,int64_t zero_point)', '    dequantize_val(double scale,int64_t zero_point,T value)', '    dequantize_vec(double scale,int64_t zero_point,const T *src,float *dst,size_t count)', '    get_qtensorimpl(const Tensor & self)', '    make_per_channel_affine_quantizer(const Tensor & scales,const Tensor & zero_points,int64_t axis,ScalarType scalar_type)', '    make_per_tensor_affine_quantizer(double scale,int64_t zero_point,ScalarType scalar_type)', '    new_qtensor_cpu(IntArrayRef sizes,const TensorOptions & options,QuantizerPtr quantizer)', '    quantize_tensor(Tensor rtensor,Tensor qtensor,double scale,int64_t zero_point)', '    quantize_val(double scale,int64_t zero_point,float value)', '    quantize_vec(double scale,int64_t zero_point,const float *src,T *dst,size_t count)', '    requantize_from_int(double multiplier,int64_t zero_point,int64_t src)', '    requantize_val(double src_scale,int64_t src_zero_point,double dst_scale,int64_t dst_zero_point,SRC_T src)', '    AffineQuantizer(ScalarType scalar_type)', '    NonUniformQuantizer(ScalarType scalar_type)', '    axis', '    dequantize(Tensor qtensor)', '    equalTo(QuantizerPtr other)', '    PerChannelAffineQuantizer(ScalarType scalar_type,Tensor scales,Tensor zero_points,int64_t axis)', '    qscheme', '    quantize(Tensor rtensor)', '    scales', '    zero_points', '    dequantize(Tensor qtensor)', '    equalTo(QuantizerPtr other)', '    PerTensorAffineQuantizer(ScalarType scalar_type,double scale,int64_t zero_point)', '    qscheme', '    quantize(Tensor rtensor)', '    scale', '    zero_point', '    dequantize(Tensor t)', '    equalTo(QuantizerPtr other)', '    intrusive_from_this', '    qscheme', '    quantize(Tensor t)', '    Quantizer(ScalarType scalar_type)', '    scalar_type', '    ~Quantizer', '    equal', '    UniformQuantizer(ScalarType scalar_type)', '    reclaim'];
cuda_graph_fuser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 17;  6; 5;2;  6; 0;0;6;0;4;1.00;0;['    Queue'];['    deprecated_AT_ASSERT', '    str(,,,,,::c10::str __VA_ARGS__)', '    clear', '    pop(optional timeout)', '    push(T)'];
dead_code_elimination.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 42;  15; 5;2;  22; 0;7;22;0;7;0.68;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCloseBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSafeDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSafeEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSampleDequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloseBlobsQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateBlobsQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnqueueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SafeDequeueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SafeEnqueueBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSampleDequeueBlobs', '    noexcept'];
decompose_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 232;  24; 42;8;  162; 0;108;77;57;42;0.15;9;['    final', '    final'];['    IDEEPCreateBlobsQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSafeEnqueueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ws_'];
decompose_ops.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    final', '    final', '    final', '    final', '    final', '    final', '    final'];['    CreateBlobsQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    DequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    dequeueMany(std::shared_ptr & queue)', '    dequeueOne(std::shared_ptr & queue)', '    Outputs', '    OutputSize', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    SafeDequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    WeightedSampleDequeueBlobsOp(const OperatorDef & operator_def,Workspace *ws)', '    ws_'];
erase_number_types.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 22;  13; 4;2;  5; 0;0;5;0;3;2.60;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDACloseBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CUDACreateBlobsQueue', '    CAFFE_ANONYMOUS_VARIABLE_CUDADequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDAEnqueueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDASafeDequeueBlobs', '    CAFFE_ANONYMOUS_VARIABLE_CUDASafeEnqueueBlobs'];
fixup_trace_scope_blocks.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 552;  156; 45;7;  353; 0;224;125;175;106;0.44;19;[];['    quint8(uint8_t val)'];
fixup_trace_scope_blocks.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 47;  35; 4;3;  7; 0;0;7;0;3;5.00;0;[];['    upsample_bilinear2d_out_frame(Tensor & output,const Tensor & input,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_bilinear2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)'];
freeze_module.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 25;  14; 5;3;  5; 0;0;5;0;3;2.80;0;[];['    upsample_nearest2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_frame_nhwc(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_nearest2d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)'];
fuse_linear.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 52;  5; 21;2;  26; 0;17;18;6;11;0.19;1;[];['    upsample_nearest3d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_frame_nhwc(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    quantized_upsample_nearest3d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)'];
fuse_linear.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 17;  9; 3;2;  5; 0;0;5;0;3;1.80;0;[];['    index', '    load(serialize::InputArchive & archive)', '    RandomSampler(int64_t size,Dtype index_dtype)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)'];
graph_fuser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 34;  17; 5;2;  12; 0;2;12;0;4;1.42;0;[];[];
graph_rewrite_helper.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 84;  4; 19;4;  60; 0;38;46;8;16;0.07;4;[];['    operator<<(std::ostream & out,const Range & range)'];
graph_rewrite_helper.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 22;  3; 4;2;  16; 0;0;16;0;7;0.19;0;[];['    operator<<(std::ostream & out,const Range & range)', '    operator/(int64_t divisor)', '    Range(int64_t begin,int64_t end)', '    size'];
guard_elimination.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 19;  2; 5;9;  5; 0;0;5;0;3;0.40;0;[];['    arange_cpu_out(Tensor & result,Scalar start,Scalar end,Scalar step)', '    linspace_cpu_out(Tensor & result,Scalar start,Scalar end,int64_t steps)', '    logspace_cpu_out(Tensor & result,Scalar start,Scalar end,int64_t steps,double base)', '    range_cpu_out(Tensor & result,Scalar start,Scalar end,Scalar step)'];
inline_autodiff_subgraphs.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 66;  6; 15;4;  44; 0;24;18;15;14;0.14;4;['    GetPairWiseLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUPairWiseLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUPairWiseLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PairWiseLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PairWiseLossGradient', '    logLogit(T x)', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
inline_autodiff_subgraphs.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 15;  2; 5;2;  8; 0;1;8;0;4;0.25;0;['    final', '    final'];['    PairWiseLossGradientOp(Args,...)', '    PairWiseLossOp(Args,...)', '    RunOnDevice', '    ~PairWiseLossGradientOp', '    ~PairWiseLossOp'];
inline_fork_wait.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 16;  7; 4;2;  5; 0;0;5;0;3;1.40;0;[];['    ~ReadAdapterInterface'];
inline_forked_closures.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 82;  13; 9;2;  60; 0;44;23;29;19;0.22;3;[];[];
inline_forked_closures.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 12;  2; 4;3;  5; 0;0;5;0;3;0.40;0;[];['    concat(CPUContext & context,const std::vector,const std::vector & outputs)', '    canRead', '    canWrite', '    capacity', '    close', '    dequeue(CPUContext & context,size_t numElements,const std::vector & outputs)', '    enqueue(std::vector)', '    enqueueMany(CPUContext & context,const std::vector & inputs)', '    enqueueOne(CPUContext &,const std::vector & inputs)', '    isClosed', '    numBlobs', '    RebatchingQueue(size_t capacity,size_t numBlobs)', '    ~RebatchingQueue'];
inliner.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 12;  3; 4;2;  5; 0;0;5;0;3;0.60;0;['    RebatchingQueue'];['    canRead', '    canWrite', '    capacity', '    close', '    dequeue(CPUContext & context,size_t numElements,const std::vector & outputs)', '    enqueue(std::vector)', '    enqueueMany(CPUContext & context,const std::vector & inputs)', '    enqueueOne(CPUContext & context,const std::vector & inputs)', '    head_', '    isClosed', '    isClosed_', '    numBlobs', '    RebatchingQueue(size_t capacity,size_t numBlobs)', '    tail_', '    ~RebatchingQueue'];
inplace_check.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 23;  2; 4;1;  18; 0;7;7;5;5;0.11;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUCloseRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUCreateRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUDequeueRebatchingQueue', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnqueueRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CloseRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_DequeueRebatchingQueue', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnqueueRebatchingQueue', '    _typeMetaDataInstance'];
inplace_check.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    CloseRebatchingQueueOp', '    CreateRebatchingQueueOp', '    DequeueRebatchingQueueOp', '    EnqueueRebatchingQueueOp'];['    CloseRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    CreateRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    DequeueRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    EnqueueRebatchingQueueOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
insert_guards.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 19;  2; 5;9;  5; 0;0;5;0;3;0.40;0;['    GetReciprocalGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReciprocalGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector'];
lift_closures.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 78;  12; 6;3;  59; 0;43;25;25;19;0.20;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUReciprocal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reciprocal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReciprocalGradient'];
lift_closures.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 12;  2; 4;3;  5; 0;0;5;0;3;0.40;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)'];
liveness.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 23;  4; 3;11;  7; 0;1;6;1;6;0.57;0;['    CallbackManager'];['    getSamplingProbability', '    hasCallbacks', '    hasNonSampledCallbacks', '    manager', '    needsInputs', '    popCallback', '    pushCallback(RecordFunctionCallback start,RecordFunctionCallback end,bool needs_inputs,bool sampled)', '    runBeforeCallbacks(RecordFunction *rf,const std::string & funcName)', '    setSamplingProbability(double prob)', '    shouldRunSampledCallbacks', '    sample_zero_one', '    _setCurrent', '    before(const char *name,int64_t sequence_nr)', '    before(std::string name,int64_t sequence_nr)', '    before(Node *fn,int64_t sequence_nr)', '    current', '    end', '    getCurrentThreadId', '    processCallbacks', '    ~RecordFunction', '    getSamplingProbability', '    hasCallbacks', '    hasNonSampledCallbacks', '    needsInputs', '    popCallback', '    pushCallback(RecordFunctionCallback start,RecordFunctionCallback end,bool needs_inputs,bool sampled)', '    setSamplingProbability(double prob)', '    shouldRunSampledCallbacks'];
loop_unrolling.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 236;  30; 32;5;  172; 0;120;85;74;67;0.17;14;[];[];
loop_unrolling.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;[];['    record_function_enter(const std::string & name)', '    record_function_exit(const at::Tensor & handle)', '    _typeMetaDataInstance'];
lower_grad_of.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 17;  8; 4;2;  5; 0;0;5;0;3;1.60;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetworkBlobFetcher', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetworkBlobFetcher'];
lower_graph.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 133;  10; 14;4;  108; 0;25;48;13;188;0.09;6;['    final'];['    copy(blob_names_vector,blob_names_vector,output)', '    GetSingleArgument', '    RecurrentNetworkBlobFetcherOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike', '    LocalBlobs'];
lower_graph.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 22;  9; 5;2;  8; 0;1;7;1;6;1.13;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDARecurrentNetworkBlobFetcher'];
lower_tuples.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 20;  7; 6;2;  7; 0;0;7;0;5;1.00;0;[];['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper rnn_args)', '    _Exec', '    Run(int T)', '    RunBackwards(int T)', '    RunOp(OpTask job,int)', '    WorkerFunction'];
onnx.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 375;  39; 24;11;  303; 0;248;175;116;51;0.13;9;['    RecurrentNetworkExecutorBase', '    ThreadedRecurrentNetworkExecutor'];['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper rnn_args)', '    add_race_conflict_dependencies(int opidx,std::vector & rnn_ops,std::unordered_set *dep_ops)', '    AnalyzeOps', '    CalculateInternalDependencies', '    EnsureTimestepInitialized(int t,Workspace *ws,const std::vector)', '    has_input(std::string x,int opidx)', '    ignoreLinkDependencies', '    infer_dependencies(int start_i,std::unordered_set outputs,std::vector & rnn_ops,std::unordered_set *dep_ops)', '    NumObserversStepNet', '    op_deps(int i)', '    PrintInfo(int t)', '    RecurrentNetworkExecutorBase(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    Run(int T)', '    RunBackwards(int T)', '    SetMaxParallelTimesteps(int p)', '    ~RecurrentNetworkExecutorBase', '    _Exec', '    _ExecRange(int from,int to)', '    ignoreLinkDependencies', '    Run(int T)', '    RunBackwards(int T)', '    RunOp(OpTask job,int)', '    setNumThreads(int n)', '    ThreadedRecurrentNetworkExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    WorkerFunction', '    ~ThreadedRecurrentNetworkExecutor', '    CreateBlob', '    GetBlob'];
onnx.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 21;  2; 4;3;  14; 0;0;14;0;6;0.14;0;[];['    createRNNExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob,ArgumentHelper arg_helper)', '    _ExecRange(int from,int to)', '    Run(int T)', '    RunBackwards(int T)', '    ~CUDARecurrentNetworkExecutor'];
cast_all_constant_to_floating.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 12;  3; 3;3;  5; 0;0;5;0;3;0.60;0;['    CUDARecurrentNetworkExecutor'];['    _ExecRange(int from,int to)', '    AnalyzeOps', '    CUDARecurrentNetworkExecutor(const NetDef & step_net_def,std::map & recurrent_input_map,std::string timestep_blob)', '    ignoreLinkDependencies', '    Run(int T)', '    RunBackwards(int T)', '    setMaxStreams(int n)', '    ~CUDARecurrentNetworkExecutor'];
constant_fold.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 424;  56; 21;5;  347; 0;247;94;176;63;0.16;11;[];['    backward', '    forward', '    OpTask', '    OpTask(int _timestep,int _op_idx,int _T,int _direction)', '    RNNNetOperator(const OperatorDef & def,int order)', '    RNNNetOperator(const RNNNetOperator & x)'];
constant_fold.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 18;  2; 4;2;  12; 0;4;12;0;7;0.17;0;['    C10FlagParser_caffe2_rnn_executor'];['    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetwork', '    CAFFE_ANONYMOUS_VARIABLE_CPURecurrentNetworkGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUrnn_internal_accumulate_gradient_input', '    CAFFE_ANONYMOUS_VARIABLE_CPUrnn_internal_apply_link', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetwork', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentNetworkGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_rnn_internal_accumulate_gradient_input', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_rnn_internal_apply_link', '    AddApplyLinkOps(const vector & links,std::string timestep,const DeviceOption & device_option,NetDef *netdef)', '    extractLinks(OperatorBase *op,const std::string & internalArg,const std::string & externalArg,const std::string & offsetArg,const std::string & windowArg,std::vector *links)', '    extractNetDef(const OperatorDef & op,const std::string & argName)', '    GetRecurrentMapping(const std::vector & links,bool backward)', '    PrependOps(std::vector ops,NetDef *netdef)', '    C10FlagParser_caffe2_rnn_executor(const std::string & content)', '    GetGradientDefs', '    _typeMetaDataInstance'];
fixup_onnx_conditionals.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    AccumulateInputGradientOp', '    final', '    final', '    RNNApplyLinkOp'];['    accumulateFinalInputGradients', '    AddApplyLinkOps(const vector & links,std::string timestep,const DeviceOption & device_option,NetDef *netdef)', '    applyOffsetAlias(const OffsetAlias & oc,Workspace *ws,Context *)', '    extractLinks(OperatorBase *op,const std::string & internalArg,const std::string & externalArg,const std::string & offsetArg,const std::string & windowArg,std::vector *links)', '    extractNetDef(const OperatorDef & op,const std::string & argName)', '    GetRecurrentMapping(const std::vector & links,bool backward)', '    initializeRecurrentInput(const RecurrentInput & rc,int32_t seqLen,int32_t batchSize,Workspace *ws,Context *context)', '    PrependOps(std::vector ops,NetDef *netdef)', '    repeatCopy(size_t repeat_n,size_t n,const T *src,T *dst,Context *context)', '    UpdateTimestepBlob(Workspace *ws,std::string blob_name,int t)', '    AccumulateInputGradientOp(Args,...)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    offset', '    window', '    offset', '    AddGradientInputAccumulationOps(const OperatorDef & operator_def)', '    AddParamGradientAccumulationOps(const OperatorDef & operator_def)', '    constructAliases', '    constructLinks', '    constructLinks', '    constructParams(const OperatorDef & operator_def)', '    constructRecurrentGradients(const OperatorDef & operator_def)', '    constructRecurrentInputs(const OperatorDef & operator_def,Workspace *sharedWs)', '    CreateSharedBlobs(const std::shared_ptr & step0Ws,Workspace *sharedBlobsWs)', '    debug_def', '    DoRunWithType', '    DoRunWithType', '    GetRepeatedArgument', '    GetSingleArgument', '    HasSingleArgumentOfType', '    initializeBlobsToRecomputeOnBackward(Workspace *sharedBlobsWs)', '    InitializeExecutor(const OperatorDef & operator_def)', '    InitializeExecutor(const OperatorDef & operator_def)', '    input', '    NumObservers', '    numSequences_', '    output', '    RecurrentNetworkGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentNetworkOp(const OperatorDef & operator_def,Workspace *ws)', '    remappedLink(const detail::Link & link)', '    remappedName(std::string blob_name)', '    renameOpInputOutput(std::string from_name,std::string to_name)', '    RunOnDevice', '    RunOnDevice', '    DoRunWithType', '    GetSingleArgument', '    RNNApplyLinkOp(Args,...)', '    RunOnDevice', '    Add'];
fixup_onnx_loop.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 252;  48; 39;3;  166; 0;117;63;86;52;0.29;8;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Recurrent', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentParamGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RecurrentParamSet', '    dim', '    array', '    stride', '    vector', '    TensorDescriptors(size_t n,const std::vector & dim,const std::vector & stride)', '    ~TensorDescriptors', '    initialize(const Tensor & input,Tensor *dropoutStates,Tensor *output,Tensor *hiddenOutput,Tensor *cellOutput)', '    ~RecurrentBaseOp', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice'];
fixup_onnx_loop.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    TensorDescriptors', '    RecurrentBaseOp', '    RecurrentGradientOp', '    RecurrentOp', '    RecurrentParamAccessOp'];['    descs', '    TensorDescriptors(size_t n,const std::vector & dim,const std::vector & stride)', '    ~TensorDescriptors', '    initialize(const Tensor & input,Tensor *dropoutStates,Tensor *output,Tensor *hiddenOutput,Tensor *cellOutput)', '    RecurrentBaseOp(Args,...)', '    ~RecurrentBaseOp', '    RecurrentGradientOp(Args,...)', '    RunOnDevice', '    RecurrentOp(Args,...)', '    RunOnDevice', '    RecurrentParamAccessOp(Args,...)', '    RunOnDevice'];
helper.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 19;  2; 6;4;  9; 0;3;9;2;8;0.22;0;['    TensorDescriptors', '    RecurrentBaseOp', '    RecurrentGradientOp', '    RecurrentOp', '    RecurrentParamAccessOp'];['    descs', '    RecurrentGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentOp(const OperatorDef & operator_def,Workspace *ws)', '    RecurrentParamAccessOp(const OperatorDef & operator_def,Workspace *ws)'];
peephole.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 881;  163; 85;6;  633; 0;437;207;354;167;0.26;29;[];['    apply(variable_list)', '    RecvRpcBackward(const AutogradMetadata & autogradMetadata,ContextPtr autogradContext,rpc::worker_id_t fromWorkerId)'];
peephole.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 14;  1; 4;2;  8; 0;0;8;0;3;0.13;0;['    RecvRpcBackward'];['    apply(torch::autograd::variable_list)', '    RecvRpcBackward(const AutogradMetadata & autogradMetadata,std::shared_ptr autogradContext,rpc::worker_id_t fromWorkerId)'];
prepare_division_for_onnx.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 19;  10; 4;2;  5; 0;0;5;0;3;2.00;0;[];['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    compoundKey(const std::string & name)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    RedisStoreHandler(std::string & host,int port,std::string & prefix)', '    set(const std::string & name,const std::string & data)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~RedisStoreHandler'];
prepare_inplace_ops_for_onnx.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 425;  92; 42;2;  292; 0;189;128;114;145;0.32;15;['    RedisStoreHandler'];['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    compoundKey(const std::string & name)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    RedisStoreHandler(std::string & host,int port,std::string & prefix)', '    set(const std::string & name,const std::string & data)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~RedisStoreHandler'];
prepare_inplace_ops_for_onnx.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 11;  2; 4;2;  5; 0;0;5;0;3;0.40;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURedisStoreHandlerCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RedisStoreHandlerCreate'];
scalar_type_analysis.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 11;  2; 4;2;  5; 0;0;5;0;3;0.40;0;['    final'];['    RedisStoreHandlerCreateOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
unpack_quantized_weights.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 313;  34; 37;7;  237; 0;154;105;88;78;0.14;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDARedisStoreHandlerCreate'];
unpack_quantized_weights.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 18;  2; 4;4;  10; 0;0;10;0;4;0.20;0;[];['    BothEndsMoments(const int M,const int N,const int K,const T *X,T *mean,T *var)', '    BothEndsReduceL1(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceL2(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *)', '    BothEndsReduceMax(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceMean(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceMin(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    BothEndsReduceSum(const int M,const int N,const int K,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseMoments(const int rows,const int cols,const T *X,T *mean,T *var)', '    ColwiseReduceL1(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceL2(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    ColwiseReduceMax(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceMean(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceMin(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    ColwiseReduceSum(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *context)', '    Moments(const int ndim,const int *X_dims,const int *Y_dims,const float *X,float *mean,float *var,CPUContext *context)', '    Moments(const int ndim,const int *X_dims,const int *Y_dims,const double *X,double *mean,double *var,CPUContext *context)', '    MomentsImpl(const int ndim,const int *X_dims,const int *Y_dims,const T *X,T *mean,T *var,CPUContext *)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceL1Impl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceL2Impl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMax(const int N,const float *X,float *Y,Tensor *,CPUContext *)', '    ReduceMax(const int N,const std::int32_t *X,std::int32_t *Y,Tensor *,CPUContext *)', '    ReduceMax(const int N,const std::int64_t *X,std::int64_t *Y,Tensor *,CPUContext *)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceMaxImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMeanImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceMin(const int N,const float *X,float *Y,Tensor *,CPUContext *)', '    ReduceMin(const int N,const std::int32_t *X,std::int32_t *Y,Tensor *,CPUContext *)', '    ReduceMin(const int N,const std::int64_t *X,std::int64_t *Y,Tensor *,CPUContext *)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceMinImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const float alpha,const float *X,float *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const double alpha,const double *X,double *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const std::int32_t alpha,const std::int32_t *X,std::int32_t *Y,CPUContext *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const std::int64_t alpha,const std::int64_t *X,std::int64_t *Y,CPUContext *context)', '    ReduceSumImpl(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,CPUContext *context)', '    ReduceTensorImpl(const int ndim,const int *X_dims,const int *Y_dims,const Reducer & reducer,const T init,const T *X,T *Y,CPUContext *context)', '    RowwiseMoments(const int rows,const int cols,const T *X,T *mean,T *var)', '    RowwiseReduceL1(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceL1(const int rows,const int cols,const float alpha,const float *X,float *Y,CPUContext *)', '    RowwiseReduceL1(const int rows,const int cols,const double alpha,const double *X,double *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const float alpha,const float *X,float *Y,CPUContext *)', '    RowwiseReduceL2(const int rows,const int cols,const double alpha,const double *X,double *Y,CPUContext *)', '    RowwiseReduceMax(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceMean(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceMin(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)', '    RowwiseReduceSum(const int rows,const int cols,const T alpha,const T *X,T *Y,CPUContext *)'];
pass_manager.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 40;  17; 9;2;  14; 0;2;10;2;12;1.21;0;[];['    for_each_in_tuple(const std::tuple & t,const TensorIterator & iter,const int num_outputs)', '    is_contiguous_reduction(const int64_t *strides)', '    is_outer_reduction(const int64_t *strides)', '    reduction128(char **data,int64_t n,int64_t stride,func_t op,vec_func_t vop,bool reduce)', '    set_result(const int index,const res_t result,const TensorIterator & iter,const int num_outputs)', '    set_results(const res_t result,const TensorIterator & iter,const int num_outputs)', '    UNARY_OUTER_LOOP(char *[2] data,const int64_t [2] strides,int64_t n,F f)', '    vectorized_inner_reduction(char **data,int64_t n,func_t op,vec_func_t vop)', '    vectorized_outer_reduction(char **data,int64_t inner_stride,int64_t size0,int64_t size1,func_t op,vec_func_t vop)', '    set_results(const std::tuple & result,const TensorIterator & iter,const int num_outputs)', '    set_result(i,std::get,iter,num_outputs)', '    UNARY_OUTER_LOOP(data,step,remaining,[],[0] data,[1] data,,inner_stride)', '    binary_kernel_reduce(TensorIterator & iter,ops_t ops,init_t init)', '    binary_kernel_reduce_vec(TensorIterator & iter,func_t op,vec_func_t vop,double ident)', '    UNARY_OUTER_LOOP(data,outer_strides,size1,[],data [0],data [1],strides [0],strides [1])', '    foreach_reduced_elt', '    noutputs', '    output', '    parallel_reduce'];
peephole.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 478;  91; 21;9;  365; 0;226;96;160;70;0.25;7;[];['    Moments(const int ndims,const int *X_dims,const int *Y_dims,const T *X,T *mean,T *var,Context *context)', '    ReduceL1(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceL2(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMax(const int N,const T *X,T *y,Tensor *scratch_ptr,Context *context)', '    ReduceMax(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMean(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceMin(const int N,const T *X,T *y,Tensor *scratch_ptr,Context *context)', '    ReduceMin(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)', '    ReduceSum(const int ndim,const int *X_dims,const int *Y_dims,const T alpha,const T *X,T *Y,Context *context)'];
peephole.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 16;  2; 4;2;  10; 0;2;10;0;4;0.20;0;['    GetReduceBackMaxGradient', '    GetReduceFrontMaxGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMaxGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    Compute(int rows,int cols,const float *data,const int32_t *lengths_data,float *out_data)'];
prepack_folding.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 17;  2; 5;3;  9; 0;1;8;1;5;0.22;0;['    final', '    final'];['    Compute(int rows,int cols,const float *data,const int32_t *lengths_data,float *out_data)', '    Compute(int rows,int cols,const float *dYdata,const float *Xdata,const float *Ydata,const int32_t *lengths_data,float *dXdata)', '    GetSingleArgument', '    MaxReduceDimsGradientOp(Args,...)', '    MaxReduceDimsOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
quantization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 2848;  363; 288;20;  2189; 0;1196;1012;707;1014;0.17;95;['    GetReduceBackMeanGradient', '    GetReduceFrontMeanGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontMeanGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)'];
quantization.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 200;  118; 25;3;  57; 0;14;48;8;34;2.07;2;['    final', '    final'];['    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    shape_', '    SumReduceDimsGradientOp(Args,...)', '    SumReduceDimsOp(Args,...)'];
remove_expands.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 24;  2; 5;1;  18; 0;8;8;8;6;0.11;2;['    GetReduceBackSumGradient', '    GetReduceFrontSumGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceBackSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceFrontSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceBackSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontSumGradient', '    GetGradientDefs', '    GetGradientDefs', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *dYdata,const int *lengths_data,T *dXdata)', '    Compute(int rows,int cols,const T *in_data,const int32_t *lengths_data,T *out_data)'];
remove_expands.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL1', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL1Gradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL2', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceL2Gradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMean', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMin', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceMinGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUReduceSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL1Gradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceL2Gradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMean', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceMinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceSumGradient', '    ComputeReduceMinMaxGradient(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data)', '    GetGradientDefs', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,CPUContext *)', '    vector'];
remove_inplace_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 82;  19; 9;1;  56; 0;38;28;21;17;0.34;3;['    final', '    final'];['    DoRunWithType', '    DoRunWithType', '    ReduceGradientOp(Args,...)', '    ReduceOp(Args,...)', '    reducer_', '    reducer_', '    RunOnDevice', '    RunOnDevice', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *,const T *,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *X_data,const T *Y_data,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)', '    Backward(const std::vector & dY_dims,const std::vector & dX_dims,const T *dY_data,const T *,const T *,T *dX_data,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & Y_dims,const T *X_data,T *Y_data,Context *context)'];
requires_grad_analysis.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 155;  4; 21;6;  127; 0;86;59;54;31;0.03;9;[];['    dtype', '    TEST(ReduceOpsTest,MaxValuesAndMinValues)'];
requires_grad_analysis.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 16;  2; 6;3;  7; 0;0;7;0;5;0.29;0;[];['    initializeHalvingDoubling'];
shape_analysis.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 2114;  282; 111;19;  1736; 0;1112;474;532;1088;0.16;64;['    final'];['    MessageLogger(,,ERROR)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    update(current_)', '    signalFailure(ws_,ioe)', '    initialize', '    initializeHalvingDoubling', '    ReduceScatterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    update(GlooParameters & params)', '    ~ReduceScatterOp'];
specialize_autogradzero.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 160;  25; 10;2;  125; 0;97;37;68;27;0.20;1;[];['    max(const Tensor & self)', '    min(const Tensor & self)'];
specialize_autogradzero.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 17;  8; 4;2;  5; 0;0;5;0;3;1.60;0;[];['    max_all_stub', '    max_all_stub', '    operator=', '    min_all_stub', '    min_all_stub', '    operator='];
subgraph_rewrite.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 142;  19; 22;3;  100; 0;50;45;44;31;0.19;7;[];['    min_all_kernel_impl(Tensor & result,const Tensor & input)', '    max_all_kernel_impl(Tensor & result,const Tensor & input)', '    reduce_all_impl(Tensor & output,const Tensor & input,const scalar_t ident_v,func_t op)', '    reduce_all_impl_vec(Tensor & output,const Tensor & input,const scalar_t ident_v,func_t op,vec_func_t vop)', '    result', '    result'];
tensorexpr_fuser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 348;  18; 43;17;  273; 0;196;57;215;38;0.07;12;[];['    _norm(const Tensor & self,Scalar p)', '    allocate_reduction_result(Tensor & result,const Tensor & self,DimMask mask,bool keepdim,ScalarType dtype)', '    check_scalar_type_device_layout_equal(const Tensor & out,const Tensor & self)', '    get_dtype(Tensor & result,const Tensor & self,optional dtype,bool promote_integers)', '    integer_upcast(const Tensor & self,optional dtype)', '    logsumexp_out_impl(Tensor & result,const Tensor & self,IntArrayRef dims,bool keepdim)', '    make_dim_mask(IntArrayRef dims,int64_t ndim)', '    make_reduction(const char *name,Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType in_dtype,ScalarType out_dtype)', '    make_reduction(const char *name,Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType out_dtype)', '    make_reduction(const char *name,Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    norm_out(Tensor & result,const Tensor & self,optional opt_p,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    prod_out_impl(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    review_reduce_result(const Tensor & result,int ndim,DimMask mask,bool keepdim)', '    squeeze_multiple(const Tensor & self,IntArrayRef dims)', '    std_var_mean_out(const char *fname,Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim,bool take_sqrt)', '    std_var_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim,bool take_sqrt)', '    _all(Tensor & result,TensorIterator & iter)', '    _any(Tensor & result,TensorIterator & iter)', '    _cumprod_cpu(const Tensor & self,int64_t dim)', '    _cumprod_out_cpu(Tensor & result,const Tensor & self,int64_t dim)', '    _cumsum_cpu(const Tensor & self,int64_t dim)', '    _cumsum_out_cpu(Tensor & result,const Tensor & self,int64_t dim)', '    all(const Tensor & self)', '    all(const Tensor & self,int64_t dim,bool keepdim)', '    all(const Tensor & self,Dimname dim,bool keepdim)', '    all_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim)', '    all_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim)', '    any(const Tensor & self)', '    any(const Tensor & self,int64_t dim,bool keepdim)', '    any(const Tensor & self,Dimname dim,bool keepdim)', '    any_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim)', '    any_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim)', '    argmax(const Tensor & self,c10::optional dim,bool keepdims)', '    argmax_out(Tensor & result,const Tensor & self,c10::optional dim,bool keepdim)', '    argmin(const Tensor & self,c10::optional dim,bool keepdims)', '    argmin_out(Tensor & result,const Tensor & self,c10::optional dim,bool keepdim)', '    cummax(const Tensor & self,int64_t dim)', '    cummax(const Tensor & self,Dimname dim)', '    cummax_cummin_helper(const T1 *self_data,T1 *values_data,T2 *indices_data,int self_dim_size,int self_stride,int values_stride,int indices_stride)', '    cummax_helper_cpu(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim)', '    cummax_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim)', '    cummax_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim)', '    cummin(const Tensor & self,int64_t dim)', '    cummin(const Tensor & self,Dimname dim)', '    cummin_helper_cpu(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim)', '    cummin_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim)', '    cummin_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim)', '    cumprod(const Tensor & self,int64_t dim,c10::optional dtype)', '    cumprod(const Tensor & self,Dimname dim,c10::optional dtype)', '    cumprod_out(Tensor & result,const Tensor & self,int64_t dim,c10::optional dtype)', '    cumprod_out(Tensor & result,const Tensor & self,Dimname dim,c10::optional dtype)', '    cumsum(const Tensor & self,int64_t dim,c10::optional dtype)', '    cumsum(const Tensor & self,Dimname dim,c10::optional dtype)', '    cumsum_out(Tensor & result,const Tensor & self,int64_t dim,c10::optional dtype)', '    cumsum_out(Tensor & result,const Tensor & self,Dimname dim,c10::optional dtype)', '    dist(const Tensor & self,const Tensor & other,Scalar p)', '    isnan_(T x)', '    isnan_(T x)', '    logsumexp(const Tensor & self,IntArrayRef dims,bool keepdim)', '    logsumexp(const Tensor & self,DimnameList dims,bool keepdim)', '    logsumexp_out(Tensor & result,const Tensor & self,IntArrayRef dims,bool keepdim)', '    logsumexp_out(Tensor & result,const Tensor & self,DimnameList dims,bool keepdim)', '    max_values(const Tensor & self,IntArrayRef dims,bool keepdim)', '    max_values(const Tensor & self,DimnameList dims,bool keepdim)', '    mean(const Tensor & self,DimnameList dim,bool keepdim,optional dtype)', '    mean_cpu_gpu(const Tensor & self,optional dtype)', '    mean_cpu_gpu(const Tensor & self,IntArrayRef dim,bool keepdim,optional dtype)', '    mean_out(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,c10::optional opt_dtype)', '    mean_out_cpu_gpu(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional opt_dtype)', '    min_values(const Tensor & self,IntArrayRef dims,bool keepdim)', '    min_values(const Tensor & self,DimnameList dims,bool keepdim)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,ScalarType dtype)', '    norm(const Tensor & self,optional p,IntArrayRef dim,bool keepdim)', '    norm(const Tensor & self,Scalar p)', '    norm(const Tensor & self,optional p,DimnameList dim,bool keepdim,ScalarType dtype)', '    norm(const Tensor & self,optional p,DimnameList dim,bool keepdim)', '    norm_out(Tensor & result,const Tensor & self,optional p,IntArrayRef dim,bool keepdim,ScalarType dtype)', '    norm_out(Tensor & result,const Tensor & self,optional p,IntArrayRef dim,bool keepdim)', '    norm_out(Tensor & result,const Tensor & self,optional p,DimnameList dim,bool keepdim,ScalarType dtype)', '    norm_out(Tensor & result,const Tensor & self,optional p,DimnameList dim,bool keepdim)', '    prod(const Tensor & self,int64_t dim,bool keepdim,c10::optional dtype)', '    prod(const Tensor & self,c10::optional dtype)', '    prod(const Tensor & self,Dimname dim,bool keepdim,c10::optional dtype)', '    prod_out(Tensor & result,const Tensor & self,int64_t dim,bool keepdim,c10::optional dtype)', '    prod_out(Tensor & result,const Tensor & self,Dimname dim,bool keepdim,optional opt_dtype)', '    std(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    std(const Tensor & self,bool unbiased)', '    std_mean(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_mean(const Tensor & self,bool unbiased)', '    std_mean(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    std_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,bool unbiased)', '    std_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    std_out(Tensor & result,const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    sum(const Tensor & self,c10::optional dtype)', '    sum(const Tensor & self,IntArrayRef dim,bool keepdim,c10::optional dtype)', '    sum(const Tensor & self,DimnameList dim,bool keepdim,c10::optional dtype)', '    sum_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool keepdim,optional opt_dtype)', '    sum_out(Tensor & result,const Tensor & self,DimnameList dim,bool keepdim,optional opt_dtype)', '    var(const Tensor & self,bool unbiased)', '    var(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    var_mean(const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_mean(const Tensor & self,bool unbiased)', '    var_mean(const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    var_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_mean_out(Tensor & result1,Tensor & result2,const Tensor & self,bool unbiased)', '    var_out(Tensor & result,const Tensor & self,IntArrayRef dim,bool unbiased,bool keepdim)', '    var_out(Tensor & result,const Tensor & self,DimnameList dim,bool unbiased,bool keepdim)', '    result', '    result', '    t'];
tensorexpr_fuser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 20;  4; 7;3;  8; 0;0;8;0;6;0.50;0;[];['    and_stub', '    and_stub', '    operator=', '    argmax_stub', '    argmax_stub', '    operator=', '    argmin_stub', '    argmin_stub', '    operator=', '    cumprod_stub', '    cumprod_stub', '    operator=', '    cumsum_stub', '    cumsum_stub', '    operator=', '    max_values_stub', '    max_values_stub', '    operator=', '    mean_stub', '    mean_stub', '    operator=', '    min_values_stub', '    min_values_stub', '    operator=', '    norm_kernel', '    norm_kernel', '    operator=', '    norm_stub', '    norm_stub', '    operator=', '    operator=', '    or_stub', '    or_stub', '    operator=', '    prod_stub', '    prod_stub', '    operator=', '    std_var_stub', '    std_var_stub', '    operator=', '    sum_stub', '    sum_stub'];
check_alias_annotation.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 257;  30; 31;3;  196; 0;119;67;122;52;0.15;10;[];['    and_kernel_impl(TensorIterator & iter)', '    argmax_kernel_impl(TensorIterator & iter)', '    argmin_kernel_impl(TensorIterator & iter)', '    cpu_cum_base_kernel(Tensor & result,const Tensor & self,int64_t dim,const func_t & f,scalar_t init_val)', '    cumprod_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim)', '    cumsum_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim)', '    max_values_kernel_impl(TensorIterator & iter)', '    mean_kernel_impl(TensorIterator & iter)', '    min_values_kernel_impl(TensorIterator & iter)', '    norm_kernel_tensor_iterator_impl(TensorIterator & iter,Scalar p)', '    or_kernel_impl(TensorIterator & iter)', '    prod_kernel_impl(TensorIterator & iter)', '    std_var_kernel_impl(TensorIterator & iter,bool unbiased,bool take_sqrt)', '    sum_kernel_impl(TensorIterator & iter)'];
memory_dag.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 163;  7; 30;5;  123; 0;63;41;60;34;0.06;16;[];['    ensure_nonempty_dim(int64_t dim)', '    ensure_nonempty_size(const Tensor & t,int64_t dim)', '    ensure_nonempty_stride(const Tensor & t,int64_t dim)', '    ensure_nonempty_vec(IdxVec vec)', '    restride_dim(const Tensor & src,int64_t dim,IntArrayRef replacement_shape)', '    _allreduce_return_trivial(const Tensor & self,Scalar ident)', '    _dimreduce_return_trivial(Tensor & result,const Tensor & self,Scalar ident,int64_t dim,bool keepdim)', '    _dimreduce_return_trivial_no_ident(Tensor & result,const Tensor & self,int64_t dim,bool keepdim,const char *fn_name)', '    _dimreduce_setup(Tensor & result,const Tensor & self,int64_t dim)', '    lower_bound', '    upper_bound', '    scalar_tensor', '    infinity', '    lowest', '    max'];
memory_dag.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 124;  44; 23;8;  51; 0;3;43;0;38;0.86;1;['    LambdaPostHook'];['    current_time_in_nanos', '    index', '    operator==(const BucketKey & lhs,const BucketKey & rhs)', '    hash(const BucketKey & key)', '    BucketKey(c10::ScalarType type,c10::Device device)', '    LambdaPostHook(std::function fn)', '    operator()(const variable_list & outputs,const variable_list &)', '    Reducer(std::vector,std::vector,std::shared_ptr process_group,std::vector)', '    autograd_hook(VariableIndex index)', '    finalize_backward', '    finalize_bucket_dense(Bucket & bucket)', '    finalize_bucket_sparse(Bucket & bucket)', '    initialize_buckets(std::vector)', '    mark_bucket_ready(size_t bucket_index)', '    mark_variable_ready(VariableIndex index)', '    mark_variable_ready_dense(VariableIndex index)', '    mark_variable_ready_sparse(VariableIndex index)', '    prepare_for_backward(const std::vector & outputs)'];
subgraph_utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 211;  28; 21;1;  166; 0;106;69;90;53;0.17;8;['    Reducer'];['    autograd_hook(VariableIndex index)', '    finalize_backward', '    finalize_bucket_dense(Bucket & replica)', '    finalize_bucket_sparse(Bucket & replica)', '    mark_bucket_ready(size_t bucket_index)', '    mark_variable_ready(VariableIndex index)', '    mark_variable_ready_dense(VariableIndex index)', '    mark_variable_ready_sparse(VariableIndex index)', '    initialize_buckets(std::vector)', '    prepare_for_backward(const std::vector & outputs)', '    Reducer(std::vector,std::vector,std::shared_ptr process_group,std::vector)', '    ~Reducer'];
xnnpack_rewrite.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 148;  2; 8;13;  21; 106;4;8;8;6;0.10;4;['    BaseReducer', '    BaseReducerGradient', '    LogMeanExpRangeReducer', '    LogMeanExpRangeReducerGradient', '    LogSumExpRangeReducer', '    LogSumExpRangeReducerGradient', '    MaxRangeReducer', '    MaxRangeReducerGradient', '    MaxReducer', '    MaxReducerGradient', '    MeanRangeReducer', '    MeanRangeReducerGradient', '    MeanReducer', '    MeanReducerGradient', '    SumRangeReducer', '    SumRangeReducerGradient', '    SumReducer', '    SumReducerGradient', '    WeightedSumReducer', '    WeightedSumReducerGradient'];['    computeLength', '    numAuxInputsWithGrads(const OperatorDef &)', '    originalInputs', '    requiresDataInput(const OperatorDef &)', '    requiresForwardOutput', '    PopulateSchema(OpSchema &)', '    requiresDataInput(const OperatorDef &)', '    requiresForwardOutput', '    PopulateSchema(OpSchema &)', '    computeLength', '    PopulateSchema(OpSchema &)', '    PopulateSchema(OpSchema & schema)', '    numAuxInputsWithGrads(const OperatorDef & def)', '    originalInputs', '    requiresDataInput(const OperatorDef & def)', '    finish(const Meta &,CPUContext *)', '    appendOutputShape(vector *output_shape)', '    computeMeta(at::IntArrayRef dims,size_t skip_dims)', '    getOutputShape(const TensorShape & in,int skip_dims)', '    Meta(bool first)', '    observeInput(int input,const Tensor & value,int skip_dims)', '    appendGradShape(vector *output_shape)', '    Meta(const Tensor & out_grad,int skip_dims,bool first_dim)', '    observeOriginalInput(int,const Tensor &,Tensor *,int)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    r', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *data_in,const T *data_out,Context *)', '    MaxReducer(const Meta & meta,T *out,CPUContext *)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    fillGradWithMainInputAndForwardOutput(const Meta & meta,const T *data,T *data_grad,const T *forward_output,int64_t,Context *,const int)', '    MaxReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *,const T *,Context *)', '    finish(const Meta & meta,CPUContext *context)', '    MeanReducer(const Meta & meta,T *out,CPUContext *)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int length)', '    MeanReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *in,T *out,CPUContext *)', '    operator()(const int64_t block_size,const int64_t blocks,const T *segment_grad,T *data_grad,const T *,const T *,Context *context)', '    process(const Meta & meta,const T *in,int64_t,CPUContext *context)', '    SumReducer(const Meta & meta,T *out,CPUContext *)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int length)', '    SumReducerGradient(const Meta &,const T *s_grad,CPUContext *)', '    dim', '    ResizeLike', '    size_from_dim', '    Meta(bool first)', '    observeInput(int input,const Tensor & value,int skip_dims)', '    process(const Meta & meta,const T *in,int64_t offset,CPUContext *context)', '    WeightedSumReducer(const Meta & meta,T *out,CPUContext *)', '    fillGrad(const Meta & meta,T *data_grad,int64_t offset,Context *context,const int)', '    fillGradWithMainInput(const Meta & meta,const T *data,T *data_grad,int64_t offset,Context *context,const int)', '    observeOriginalInput(int original_input,const Tensor & value,Tensor *input_grad,int)', '    WeightedSumReducerGradient(const Meta &,const T *s_grad,CPUContext *)'];
xnnpack_rewrite.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 13;  2; 2;3;  8; 0;0;8;0;6;0.25;0;[];[];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 861;  39; 51;82;  672; 26;98;187;32;1027;0.06;6;['    Function'];['    arg(int index)', '    args', '    bodies', '    body(size_t index)', '    dim(int index)', '    dims', '    func_var(size_t index)', '    func_vars', '    Function(const std::vector & func_names,const std::vector & dims,const std::vector & args,const std::vector & bodies)', '    Function(const std::string & func_name,const std::vector & dims,const std::vector & args,const Expr *body)', '    ndim'];
module_python.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 20;  2; 4;4;  12; 0;4;6;3;4;0.17;1;['    GetSumElementsGradient', '    GetColwiseMaxGradient', '    GetRowwiseMaxGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUColwiseMax', '    CAFFE_ANONYMOUS_VARIABLE_CPUColwiseMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwiseMax', '    CAFFE_ANONYMOUS_VARIABLE_CPURowwiseMaxGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElements', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElementsGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumElementsInt', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumSqrElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElementsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumElementsInt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumSqrElements', '    vector', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColumnMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColwiseMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ColwiseMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowwiseMax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowwiseMaxGradient', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
pybind.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 126;  13; 19;13;  91; 0;27;48;17;30;0.14;9;['    MaxReductionGradientOp', '    MaxReductionOp', '    SumElementsGradientOp', '    SumElementsIntOp', '    SumElementsOp', '    SumSqrElementsOp'];['    MaxReductionGradientOp(Args,...)', '    RunOnDevice', '    ~MaxReductionGradientOp', '    MaxReductionOp(Args,...)', '    RunOnDevice', '    ~MaxReductionOp', '    RunOnDevice', '    SumElementsGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    SumElementsGradientOp(const OperatorDef & operator_def,Workspace *ws,bool average)', '    SumElementsGradientOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs)', '    SumElementsGradientOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs,bool average)', '    ~SumElementsGradientOp', '    RunOnDevice', '    scratch_', '    SumElementsIntOp(Args,...)', '    ~SumElementsIntOp', '    RunOnDevice', '    scratch_', '    SumElementsOp(const OperatorDef & operator_def,Workspace *ws)', '    SumElementsOp(const OperatorDef & operator_def,Workspace *ws,bool average)', '    SumElementsOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs)', '    SumElementsOp(const c10::FunctionSchema & schema,std::vector inputs,std::vector outputs,bool average)', '    ~SumElementsOp', '    DoRunWithType', '    RunOnDevice', '    scratch_', '    SumSqrElementsOp(Args,...)', '    ~SumSqrElementsOp'];
pybind_utils.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 1086;  74; 80;49;  876; 15;516;259;336;514;0.08;43;[];['    reflection_pad1d_backward_out_frame(scalar_t *grad_input,scalar_t *grad_output,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad2d_backward_out_frame(scalar_t *grad_input,scalar_t *grad_output,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad1d_backward_cpu(const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_backward_out_loop(scalar_t *grad_input,scalar_t *grad_output,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_backward_out_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_cpu(const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef padding)', '    reflection_pad1d_out_loop(scalar_t *input_p,scalar_t *output_p,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t output_w,int64_t pad_l)', '    reflection_pad1d_out_template(Tensor & output,const Tensor & input_,IntArrayRef padding)', '    reflection_pad2d_backward_cpu(const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_backward_out_loop(scalar_t *grad_input,scalar_t *grad_output,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_backward_out_template(Tensor & grad_input,const Tensor & grad_output_,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_cpu(const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef padding)', '    reflection_pad2d_out_loop(scalar_t *input_p,scalar_t *output_p,int64_t nbatch,int64_t nplane,int64_t input_w,int64_t input_h,int64_t output_w,int64_t output_h,int64_t pad_l,int64_t pad_t)', '    reflection_pad2d_out_template(Tensor & output,const Tensor & input_,IntArrayRef padding)'];
python_arg_flatten.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 122;  13; 17;8;  87; 0;34;46;31;32;0.15;9;[];['    $', '    as_bool_array(const c10::List & list)', '    atenOperatorOptions', '    DUMMY_OPERATION', '    toListOfOptionalTensor(const IValue & v)', '    toOptionalTensor(const IValue & v)'];
python_custom_class.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 51;  11; 7;2;  34; 0;24;11;3;8;0.32;2;['    final'];['    createOperatorFromC10(const c10::OperatorHandle & op)', '    ensure_c10_registerer_defined', '    registerer', '    onOperatorDeregistered(const c10::OperatorHandle & op)', '    onOperatorRegistered(const c10::OperatorHandle & op)', '    Registerer'];
python_custom_class.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 22;  2; 7;4;  11; 0;0;10;0;7;0.18;1;[];['    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase', '    optional_to_tensor(c10::optional v)', '    toOptionalTensor(const c10::IValue & v)'];
python_ir.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 779;  35; 32;33;  681; 0;151;191;86;1200;0.05;13;[];['    conv2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    log_softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    toOptionalTensor(const c10::IValue & v)', '    view_kernel(const c10::OperatorHandle & op,Stack *stack)'];
python_ir.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 52;  15; 7;3;  29; 0;5;21;5;16;0.52;3;[];['    __is__kernel(const c10::OperatorHandle & op,Stack *stack)', '    __isnot__kernel(const c10::OperatorHandle & op,Stack *stack)', '    _convolution_kernel(const c10::OperatorHandle & op,Stack *stack)', '    cat_kernel(const c10::OperatorHandle & op,Stack *stack)', '    conv2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    format_kernel(const c10::OperatorHandle & op,Stack *stack)', '    listAppend(const c10::OperatorHandle & op,Stack *stack)', '    log_softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    normalizeIndex(int64_t idx,int64_t list_size)', '    optional_to_tensor(c10::optional v)', '    permute_kernel(const c10::OperatorHandle & op,Stack *stack)', '    pop_kernel(const c10::OperatorHandle & op,Stack *stack)', '    softmax_kernel(const c10::OperatorHandle & op,Stack *stack)', '    to_dtype_kernel(const c10::OperatorHandle & op,Stack *stack)', '    toOptionalTensor(const c10::IValue & v)', '    TupleIndex_kernel(const c10::OperatorHandle & op,Stack *stack)', '    tupleunpack_kernel(const c10::OperatorHandle & op,Stack *stack)', '    upsample_nearest2d_kernel(const c10::OperatorHandle & op,Stack *stack)', '    view_kernel(const c10::OperatorHandle & op,Stack *stack)', '    warn_kernel(const c10::OperatorHandle & op,Stack *stack)'];
python_ivalue.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 31;  5; 7;3;  18; 0;2;11;2;9;0.28;4;[];['    ceil(double a)', '    floor(double a)', '    floordiv(int64_t a,int64_t b)', '    gcd(int64_t a,int64_t b)', '    to_dispatch(at::Tensor self,c10::optional device,c10::optional scalarType,bool non_blocking,bool copy)', '    _is_floating_value(double v)', '    _output_size(const at::Tensor & input,size_t dim,const IValue & size,const IValue & scale_factors)', '    cat(const c10::List & tensors)', '    checkSortSchema(const c10::TypePtr & list_element_type)', '    convert_scale_factor_to_double(const IValue & int_ivalue)', '    get_first(const c10::List)', '    interpolate(const at::Tensor & input,const IValue & size,const IValue & scale_factors,const std::string & mode,c10::optional align_corners,c10::optional recompute_scale_factor)', '    interpolate_op(Stack & stack)', '    leaky_relu(const at::Tensor & tensor,double scalar)', '    simpleClassTypeArg(const Argument & arg,const ClassTypePtr & type)', '    sort_op(Stack & stack)', '    dictClear(Stack & stack)', '    dictConstructFromList(Stack & stack)', '    dictContains(Stack & stack)', '    dictCopy(Stack & stack)', '    dictDelete(Stack & stack)', '    dictGet(Stack & stack)', '    dictIndex(Stack & stack)', '    dictItems(Stack & stack)', '    dictKeys(Stack & stack)', '    dictLen(Stack & stack)', '    dictPop(Stack & stack)', '    dictPopItem(Stack & stack)', '    dictSetDefault(Stack & stack)', '    dictSetItem(Stack & stack)', '    dictUpdate(Stack & stack)', '    dictValues(Stack & stack)', '    hashValue(Stack & stack)', '    aliasAnalysisConservative', '    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase', '    checkDoubleInRange(double a)', '    checkImplicitTensorToNum(at::Tensor t,bool toInt)', '    degrees(double x)', '    factorial(int n)', '    getItem(const c10::List & list,int64_t idx)', '    listAdd(Stack & stack)', '    listAppend(Stack & stack)', '    listClear(Stack & stack)', '    listContains(Stack & stack)', '    listCopy(Stack & stack)', '    listCount(Stack & stack)', '    listCount(Stack & stack)', '    listDelete(Stack & stack)', '    listEq(Stack & stack)', '    listEq(Stack & stack)', '    listExtend(Stack & stack)', '    listIndex(Stack & stack)', '    listIndex(Stack & stack)', '    listInplaceAdd(Stack & stack)', '    listInsert(Stack & stack)', '    listLen(Stack & stack)', '    listList(Stack & stack)', '    listMax(Stack & stack)', '    listMin(Stack & stack)', '    listMulIntLeft(Stack & stack)', '    listMulIntLeftInPlace(Stack & stack)', '    listMulIntRight(Stack & stack)', '    listNe(Stack & stack)', '    listNe(Stack & stack)', '    listPop(Stack & stack)', '    listPopImpl(Stack & stack,const char *empty_message)', '    listRemove(Stack & stack)', '    listRemove(Stack & stack)', '    listReverse(Stack & stack)', '    listSelect(Stack & stack)', '    listSlice(Stack & stack)', '    listSort(Stack & stack)', '    listSort(Stack & stack)', '    loop(int n,int64_t & p,int64_t & r)', '    make_result_list(const TypePtr & elemType)', '    make_result_list(const TypePtr & elemType)', '    maxList(Stack & stack)', '    minList(Stack & stack)', '    nminussumofbits(int v)', '    noop(Stack & n)', '    normalizeIndex(int64_t idx,int64_t list_size)', '    partProduct(int n,int m)', '    radians(double x)', '    setItem(const c10::List & list,int64_t idx,T)', '    tensor_list_equal(const c10::List & a,const c10::List & b)', '    tensorToListRecursive(char *data,int64_t cur_dim,int64_t num_tensor_dims,TypePtr ty,at::IntArrayRef sizes,at::IntArrayRef strides,size_t element_size)', '    listCopyAndSort(Stack & stack)', '    listCopyAndSort(Stack & stack)', '    listSetItem(Stack & stack)', '    upsample_bilinear_op(Stack & stack)', '    upsample_nearest_op(Stack & stack)', '    upsample_op(Stack & stack)'];
python_sugared_value.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 273;  16; 53;9;  197; 0;24;149;18;70;0.08;21;[];[];
python_tracer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 197;  6; 24;11;  159; 0;66;62;35;175;0.04;7;[];['    aliasAnalysisConservative', '    aliasAnalysisFromSchema', '    aliasAnalysisSpecialCase'];
python_tracer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 36;  3; 8;7;  21; 0;1;21;0;9;0.14;0;[];['    aliasAnalysisFromSchema', '    castTensorTo(at::Tensor self,const IValue & dtype,const IValue & device)', '    checkListInputType(const c10::TypePtr & elem_type,bool empty_list)', '    checkSequenceSize(int64_t n,int64_t dim,int64_t seq_size)', '    compute_sizes(const IValue & seq)', '    createTensorFromList(Stack & stack)', '    recursiveStore(char *data,const std::vector & sizes,const c10::ArrayRef & strides,int64_t dim,int elementSize,const IValue & obj)', '    storeLastDimension(char *data,const std::vector & sizes,const c10::ArrayRef & strides,int64_t dim,int elementSize,at::ArrayRef obj)'];
python_tree_views.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 11;  2; 4;2;  5; 0;0;5;0;3;0.40;0;[];['    aliasAnalysisFromSchema', '    normalizeIndex(int64_t idx,int64_t list_size)', '    stringFindImpl(std::string string,std::string substr,int64_t start,int64_t end,bool reverse)', '    stringSlice(std::string string,int64_t start,int64_t end,int64_t step)'];
script_init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 1391;  71; 90;39;  1199; 0;362;410;191;1436;0.06;36;[];['    InternedStrings'];
script_init.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 9;  2; 2;2;  5; 0;0;5;0;3;0.40;0;[];[];
update_graph_executor_opt.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 8;  2; 0;2;  6; 0;0;0;0;0;0.33;0;[];['    $'];
resource_guard.h;C++;pytorch-master/pytorch-master/torch/csrc/jit; 26;  2; 6;2;  18; 0;3;11;3;8;0.11;3;[];[];
argument_spec.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 281;  38; 11;1;  237; 0;178;81;142;88;0.16;6;['    Registerer', '    Registry'];['    KeyStrRepr(const KeyType &)', '    KeyStrRepr(const std::string & key)', '    DefaultCreator(Args,...)', '    Registerer(const SrcType & key,Registry *registry,Registry::Creator creator,const std::string & help_msg)', '    Registerer(const SrcType & key,const RegistryPriority priority,Registry *registry,Registry::Creator creator,const std::string & help_msg)', '    Create(const SrcType & key,Args,...)', '    Has(const SrcType & key)', '    HelpMessage', '    HelpMessage(const SrcType & key)', '    Keys', '    operator=', '    Register(const SrcType & key,Creator creator,const RegistryPriority priority)', '    Register(const SrcType & key,Creator creator,const std::string & help_msg,const RegistryPriority priority)', '    Registry(bool warning)', '    Registry', '    SetTerminate(bool terminate)', '    exit'];
autodiff.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 844;  206; 75;14;  555; 0;351;237;194;303;0.37;28;['    AnotherBar', '    Bar', '    Foo'];['    RegisterFooBarFallback', '    RegisterFooBarPreferred', '    RegisterFooDefault', '    RegisterFooDefaultAgain', '    RegistryName', '    TEST(RegistryTest,CanRunCreator)', '    TEST(RegistryTest,ReturnNullOnNonExistingCreator)', '    TEST(RegistryTest,RegistryPriorities)', '    AnotherBar(int x)', '    Bar(int x)', '    Foo(int x)', '    ~Foo'];
autodiff.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 98;  65; 13;6;  21; 0;3;17;2;17;3.10;1;[];['    mkldnn_relu(const Tensor & input)', '    mkldnn_relu_(Tensor & input)'];
custom_operator.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 28;  9; 5;4;  12; 0;0;0;0;0;0.75;0;[];['    relu_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)'];
graph_executor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 767;  106; 88;47;  535; 0;288;195;228;157;0.20;50;[];['    RunOnDevice'];
graph_executor.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 109;  24; 21;8;  60; 0;0;0;0;0;0.40;0;['    final'];['    ReluAVX2(const int N,const int zero_point,const T *X,T *Y)', '    ReluDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
graph_executor_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 96;  17; 15;24;  42; 0;10;37;2;24;0.40;2;[];['    ReluAVX2(const int N,const int zero_point,const uint8_t *X,uint8_t *Y)', '    ReluAVX2(const int N,const int zero_point,const uint16_t *X,uint16_t *Y)'];
instruction.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 74;  46; 6;39;  16; 0;0;12;0;13;2.88;1;['    GetReluNGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReluN', '    CAFFE_ANONYMOUS_VARIABLE_CPUReluNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluNGradient', '    CostInferenceForReluN(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector'];
interpreter.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 1458;  228; 129;31;  1082; 0;687;321;552;269;0.21;95;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    ReluNFunctor(OperatorBase & op)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)', '    ReluNGradientFunctor(OperatorBase & op)'];
interpreter.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 120;  17; 19;7;  80; 0;0;0;0;0;0.21;0;['    GetReluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPURelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Relu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluGradient', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector'];
jit_exception.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 15;  2; 5;3;  7; 0;0;6;0;5;0.29;0;['    final', '    final'];['    IDEEPReluGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPReluOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPReluGradientOp', '    ~IDEEPReluOp'];
logging.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 72;  5; 12;4;  54; 0;29;23;21;18;0.09;8;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)'];
logging.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 87;  12; 15;6;  58; 0;13;44;1;35;0.21;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURemoveDataBlocks', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RemoveDataBlocks'];
operator.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 196;  56; 26;17;  101; 0;0;0;0;0;0.55;0;['    final'];['    DoRunWithType', '    RemoveDataBlocksOp(Args,...)', '    RunOnDevice', '    ~RemoveDataBlocksOp'];
operator_options.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 11;  2; 4;2;  5; 0;0;0;0;0;0.40;0;[];['    RemoveExpands(Block *block)', '    RemoveExpands(const std::shared_ptr & graph)'];
print_handler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 22;  2; 6;3;  13; 0;2;9;2;5;0.15;2;[];['    RemoveExpands(const std::shared_ptr & graph)'];
profiling_graph_executor_impl.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 195;  12; 24;25;  134; 2;90;40;78;29;0.09;14;[];['    isInplaceOp(const Node *node)', '    RemoveInplaceOps(Block *block)', '    RemoveInplaceOps(const std::shared_ptr & graph)'];
profiling_graph_executor_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 27;  3; 5;2;  20; 0;0;18;0;12;0.15;0;[];['    RemoveInplaceOps(const std::shared_ptr & graph)'];
profiling_record.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 135;  8; 19;4;  106; 0;63;37;48;30;0.08;7;[];['    compute_cpu(int64_t *repeat_ptr,int64_t *cumsum_ptr,int64_t *result_ptr,int64_t size)', '    repeat_interleave(const Tensor & self,const Tensor & repeats,c10::optional dim)', '    repeat_interleave(const Tensor & self,int64_t repeats,c10::optional dim)', '    repeat_interleave_cpu(const Tensor & repeat)'];
register_c10_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 193;  20; 17;10;  146; 4;122;19;9;14;0.14;6;[];['    repeat_interleave_common(const Tensor & repeats)'];
register_distributed_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 237;  22; 18;9;  191; 0;169;177;10;16;0.12;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUReplaceNaN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReplaceNaN', '    ReplaceNaN(const T & value,const int64_t size,const T *X,T *Y)'];
register_prim_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 3297;  126; 235;478;  2471; 0;1795;1088;515;331;0.05;93;['    final'];['    DoRunWithType', '    GetSingleArgument', '    ReplaceNaN(const T & value,const int64_t size,const T *X,T *Y)', '    ReplaceNaNOp(Args,...)', '    RunOnDevice'];
register_prim_ops_fulljit.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 309;  23; 19;46;  228; 0;49;222;5;8;0.10;3;[];['    replication_pad1d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,long nslices,long iwidth,long owidth,int pad_l,int pad_r,int nbatch)', '    replication_pad1d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,long nslices,long iwidth,long owidth,int pad_l,int pad_r)', '    replication_pad1d_out_batch(scalar_t *input_data,scalar_t *output_data,long nslices,long iwidth,long owidth,int pad_l,int pad_r,int nbatch)', '    replication_pad1d_out_frame(scalar_t *input_p,scalar_t *output_p,long nslices,long iwidth,long owidth,int pad_l,int pad_r)', '    replication_pad2d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b,int nbatch)', '    replication_pad2d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b)', '    replication_pad2d_out_batch(scalar_t *input_data,scalar_t *output_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b,int nbatch)', '    replication_pad2d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t owidth,int64_t oheight,int pad_l,int pad_r,int pad_t,int pad_b)', '    replication_pad3d_backward_out_batch(scalar_t *ginput_data,scalar_t *goutput_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback,int nbatch)', '    replication_pad3d_backward_out_frame(scalar_t *ginput_p,scalar_t *goutput_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    replication_pad3d_out_batch(scalar_t *input_data,scalar_t *output_data,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback,int nbatch)', '    replication_pad3d_out_frame(scalar_t *input_p,scalar_t *output_p,int64_t nslices,int64_t iwidth,int64_t iheight,int64_t idepth,int64_t owidth,int64_t oheight,int64_t odepth,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    shapeCheck3d(const Tensor & input,int pleft,int pright,int ptop,int pbottom,int pfront,int pback)', '    replication_pad1d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad1d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)', '    replication_pad2d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)', '    replication_pad3d_backward_cpu(const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_backward_out_cpu(Tensor & gradInput,const Tensor & gradOutput,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_backward_out_cpu_template(Tensor & gradInput,const Tensor & gradOutput_,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_cpu(const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef paddingSize)', '    replication_pad3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef paddingSize)'];
register_special_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 443;  19; 39;46;  343; 0;275;243;57;31;0.06;8;[];['    pytorch_qnnp_requantize_fp32__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_lrintf(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__scalar_magic(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_fp32__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_gemmlowp__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_signed64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned32(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__scalar_unsigned64(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_precise__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__neon(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__psimd(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__scalar(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__sse2(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__sse4(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)', '    pytorch_qnnp_requantize_q31__ssse3(size_t n,const int32_t *input,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax,uint8_t *output)'];
register_string_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 728;  18; 63;29;  621; 0;574;584;27;17;0.03;4;['    RequantizationTester'];['    requantizeApproximate(int32_t value,float scale,uint8_t zeroPoint,uint8_t qmin,uint8_t qmax)', '    shiftLeft(int64_t w,uint32_t n)', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    s(uint32_t s)', '    s', '    s_', '    scale', '    testDivideByPO2WithRoundingAway(pytorch_requantization_function requantize)', '    testDivideByPO2WithRoundingDown(pytorch_requantization_function requantize)', '    testDivideByPO2WithRoundingUp(pytorch_requantization_function requantize)', '    testExactDivideByPO2(pytorch_requantization_function requantize)', '    testRandomCasesAgainstReference(pytorch_requantization_function requantize,pytorch_requantization_function requantizeReference)', '    testRandomCasesApproximate(pytorch_requantization_function requantize)', '    testRandomCasesPrecise(pytorch_requantization_function requantize)', '    testSpecialCases(pytorch_requantization_function requantize)', '    zeroPoint(int32_t zeroPoint)', '    zeroPoint', '    zeroPoint_'];
symbolic_script.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 20;  4; 3;4;  11; 0;0;10;0;7;0.36;0;[];['    TEST(PRECISE__SCALAR_UNSIGNED32,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_UNSIGNED32,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_UNSIGNED32,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_UNSIGNED32,special_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED32,random_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED64,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_UNSIGNED64,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_UNSIGNED64,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_UNSIGNED64,special_cases)', '    TEST(PRECISE__SCALAR_UNSIGNED64,random_cases)', '    TEST(PRECISE__SCALAR_SIGNED64,exact_divide_by_po2)', '    TEST(PRECISE__SCALAR_SIGNED64,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__SCALAR_SIGNED64,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__SCALAR_SIGNED64,special_cases)', '    TEST(PRECISE__SCALAR_SIGNED64,random_cases)', '    TEST(FP32__SCALAR_LRINTF,random_cases)', '    TEST(FP32__SCALAR_MAGIC,random_cases)', '    TEST(Q31__SCALAR,exact_divide_by_po2)', '    TEST(Q31__SCALAR,exact_divide_by_po2_with_zero_point)', '    TEST(Q31__SCALAR,divide_by_po2_with_rounding_up)', '    TEST(Q31__SCALAR,divide_by_po2_with_rounding_away)', '    TEST(Q31__SCALAR,special_cases)', '    TEST(Q31__SCALAR,random_cases)', '    TEST(Q31__SCALAR,random_match_gemmlowp)', '    TEST(GEMMLOWP__SCALAR,random_cases)', '    TEST(PRECISE__PSIMD,exact_divide_by_po2)', '    TEST(PRECISE__PSIMD,exact_divide_by_po2_with_zero_point)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_up)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_down)', '    TEST(PRECISE__PSIMD,divide_by_po2_with_rounding_away)', '    TEST(PRECISE__PSIMD,special_cases)', '    TEST(PRECISE__PSIMD,random_cases)', '    TEST(FP32__PSIMD,random_cases)'];
vararg_functions.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 124;  9; 15;1;  101; 0;59;38;49;31;0.09;12;['    Requantization'];['    divideRoundUp(uint32_t x,uint32_t q)', '    min(uint32_t a,uint32_t b)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    Requantization(benchmark::State & state)', '    roundUp(uint32_t x,uint32_t q)', '    input', '    n', '    output', '    Requantization', '    SetUp(const benchmark::State &)', '    TearDown(benchmark::State & state)'];
vararg_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 34;  2; 12;5;  17; 0;0;17;0;12;0.12;0;[];['    pytorch_qnnp_add_quantize(uint8_t a,uint8_t b,union pytorch_qnnp_add_quantization_params params)', '    pytorch_qnnp_avgpool_quantize(int32_t n,union pytorch_qnnp_avgpool_quantization_params params)', '    pytorch_qnnp_compute_add_quantization_params(uint8_t a_zero_point,uint8_t b_zero_point,uint8_t output_zero_point,float a_output_scale,float b_output_scale,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_avgpool_quantization_params(int32_t bias,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_conv_quantization_params(uint8_t input_zero_point,uint8_t kernel_zero_point,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_requantization_params(float scale,uint8_t zero_point,uint8_t min,uint8_t max)', '    pytorch_qnnp_compute_scalar_add_quantization_params(uint8_t a_zero_point,uint8_t b_zero_point,uint8_t output_zero_point,float a_output_scale,float b_output_scale,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_scalar_avgpool_quantization_params(int32_t bias,float scale,uint8_t output_zero_point,uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_compute_scalar_requantization_params(float scale,uint8_t zero_point,uint8_t min,uint8_t max)', '    pytorch_qnnp_compute_u8_clamping_params(uint8_t output_min,uint8_t output_max)', '    pytorch_qnnp_q31_requantize(int32_t n,union pytorch_qnnp_q31_requantization_params params)'];
export.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 1004;  61; 66;28;  856; 0;515;364;405;158;0.07;37;[];['    TEST(Requantization,BatchRequantizationUnitTest)', '    TEST(Requantization,RequantizationUnitTest)'];
export.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 92;  16; 14;7;  57; 0;23;56;2;15;0.28;0;[];['    operator()(Message & request)'];
export_module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 336;  41; 43;12;  246; 0;126;128;78;89;0.17;19;['    RequestCallback'];['    operator()(Message & request)', '    processMessage(Message & request)', '    ~RequestCallback'];
import.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 76;  18; 13;6;  43; 0;0;0;0;0;0.42;0;[];['    deserializePythonRpcCommand(std::unique_ptr,const MessageType & messageType)', '    deserializePythonRpcCommandReference(RpcCommandBase & rpc,const MessageType & messageType)', '    clear', '    ~ClearAutogradContextGuard', '    handleError(const std::exception & e,const MessageType messageType,int64_t messageId)', '    processMessage(Message & request)', '    processRpc(RpcCommandBase & rpc,const MessageType & messageType,const int64_t messageId,const std::shared_ptr & responseFuture)'];
import_export_constants.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 10;  2; 1;1;  8; 0;4;8;0;6;0.25;0;['    RequestCallbackImpl'];['    handleError(const std::exception & e,const MessageType messageType,int64_t messageId)', '    processMessage(Message & request)', '    processRpc(RpcCommandBase & rpc,const MessageType & messageType,const int64_t messageId,const std::shared_ptr & responseFuture)'];
import_export_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 11;  3; 1;1;  8; 0;0;8;0;4;0.38;0;[];['    bitwiseOr(std::vector a,const std::vector & b)', '    getRequiresGrad(Value *value)', '    PropagateRequiresGrad(std::shared_ptr & graph)', '    PropagateRequiresGrad(Block *block)', '    PropagateRequiresGrad(Node *node)', '    PropagateRequiresGradSimpleNode(Node *node)', '    setRequiresGrad(Value *value,bool req_value)', '    setRequiresGrad(at::ArrayRef outputs,const std::vector & values)', '    setRequiresGrad(Node *node,const std::vector & values)'];
import_export_helpers.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 32;  8; 7;3;  17; 0;0;17;0;8;0.47;0;[];['    PropagateRequiresGrad(std::shared_ptr & graph)'];
import_legacy.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 381;  24; 40;15;  308; 0;175;144;122;85;0.08;10;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReservoirSampling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReservoirSampling', '    countNewEntries(const std::set & unique_object_ids)', '    ReservoirSamplingOp(const OperatorDef operator_def,Workspace *ws)', '    RunOnDevice'];
import_legacy.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 23;  5; 6;2;  14; 0;0;14;0;7;0.36;0;['    GetReshapeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Reshape', '    vector', '    CopyArguments', '    GetGradientDefs'];
import_source.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 43;  9; 9;7;  20; 0;1;17;1;11;0.45;0;['    final'];['    IDEEPReshapeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
pickle.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 152;  14; 18;14;  107; 8;47;48;18;30;0.13;9;['    ReshapeOp'];['    DoRunWithType', '    DoRunWithTypeImpl(const Tensor & input,Tensor *output)', '    GetRepeatedArgument', '    InputIsTensorType', '    ReshapeOp(Args,...)', '    RunOnDevice', '    begin', '    dim', '    end', '    raw_data', '    size'];
pickle.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 86;  51; 9;6;  22; 0;0;0;0;0;2.32;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAReshape'];
pickler.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 270;  40; 40;9;  182; 1;0;0;0;0;0.22;0;[];['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(ReshapeOpGPUTest,testReshapeWithScalar)'];
python_print.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 1372;  202; 106;10;  1064; 0;740;328;562;215;0.19;67;[];['    resize_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    resize_as_(Tensor & self,const Tensor & the_template,c10::optional optional_memory_format)'];
python_print.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 35;  2; 8;5;  22; 0;1;20;0;15;0.09;0;[];['    checkInBoundsForStorage(IntArrayRef size,IntArrayRef stride,int64_t storage_offset,const Storage & new_storage)', '    checkSetStorage(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)', '    maybe_resize_storage_cpu(TensorImpl *self,int64_t new_size)', '    resize_impl_cpu_(TensorImpl *self,IntArrayRef size,c10::optional stride)', '    setStrided(const Tensor & self,IntArrayRef size,IntArrayRef stride,int64_t storage_offset)', '    computeStorageSize', '    value'];
source_range_serialization.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 39;  2; 11;5;  23; 0;1;18;0;14;0.09;1;['    GetResizeNearest3DGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeNearest3D', '    schema_OperatorName', '    resizeNearest3DNCHW2x(int batch_size,int num_channels,int temporal_scale,int input_frames,int input_height,int input_width,const float *input,float *output)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest3D', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest3DGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNCHW'];
source_range_serialization_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 29;  4; 9;2;  16; 0;0;13;0;10;0.25;0;['    final', '    final'];['    schema_ResizeNearest3D', '    GetSingleArgument', '    ResizeNearest3DGradientOp(Args,...)', '    ResizeNearest3DOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW'];
unpickler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 816;  84; 28;20;  651; 40;427;168;346;504;0.13;19;[];['    RunOnDevice'];
analysis.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 33;  3; 4;4;  25; 0;7;12;5;9;0.12;3;['    final'];['    ResizeNearest3DDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
buffer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 1;  0; 1;0;  0; 0;0;0;0;0;0.00;0;[];['    RunOnDevice'];
buffer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 134;  5; 12;2;  118; 0;42;53;38;34;0.04;14;['    final'];['    ResizeNearestDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
codegen.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 185;  4; 34;20;  130; 0;35;79;27;114;0.03;44;['    GetResizeNearestGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeNearest', '    schema_OperatorName', '    resizeNearestNCHW2x(int batch_size,int num_channels,int input_height,int input_width,const float *input,float *output)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeNearestGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW'];
cuda_codegen.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 687;  52; 70;22;  530; 21;349;191;385;185;0.10;29;['    final', '    final'];['    schema_ResizeNearest', '    GetSingleArgument', '    ResizeNearestGradientOp(Args,...)', '    ResizeNearestOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW', '    RunOnDeviceWithOrderNHWC'];
cuda_codegen.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 130;  6; 24;14;  89; 0;23;49;20;38;0.07;11;[];['    AddNoiseInput(const vector & shape,const string & name,Workspace *ws)', '    compareResizeNeareast(int N,int C,int H,int W,float wscale,float hscale)', '    randInt(int a,int b)', '    TEST(ResizeNearestOp,ResizeNearest2x)'];
cuda_random.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 104;  3; 95;1;  8; 0;2;8;0;4;0.38;0;[];['    resize_named_tensor_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    has_value'];
eval.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 13;  3; 4;1;  8; 0;0;8;0;5;0.38;0;[];['    nativeResolver', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)', '    ~Resolver'];
eval.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 958;  15; 96;122;  728; 0;444;230;789;380;0.02;107;['    ResourceGuard'];['    release', '    ResourceGuard(std::function destructor)', '    ~ResourceGuard'];
execution_counter.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 118;  33; 19;7;  62; 0;19;32;11;32;0.53;9;[];[];
expr.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 208;  4; 51;5;  151; 0;47;57;47;59;0.03;56;[];['    half_support_literal', '    n'];
expr.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 235;  23; 28;7;  180; 0;24;125;22;105;0.13;28;[];[];
function.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 94;  3; 13;5;  76; 0;21;40;20;21;0.04;11;['    reverse_iterator'];['    __make_reverse_iterator(_Iterator __i)', '    __niter_base(reverse_iterator __it)', '    operator!=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator!=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator-(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator<=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator==(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator==(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>=(const reverse_iterator & __x,const reverse_iterator & __y)', '    operator>=(const reverse_iterator & __x,const reverse_iterator & __y)', '    make_reverse_iterator(_Iterator __i)', '    operator+(reverse_iterator::difference_type __n,const reverse_iterator & __x)', '    _S_to_pointer(_Tp *__p)', '    _S_to_pointer(_Tp __t)', '    base', '    operator*', '    operator+(difference_type __n)', '    operator++', '    operator++(int)', '    operator+=(difference_type __n)', '    operator-(difference_type __n)', '    operator--', '    operator--(int)', '    operator-=(difference_type __n)', '    operator->', '    operator=(const reverse_iterator & rhs)', '    operator[](difference_type __n)', '    reverse_iterator', '    reverse_iterator(iterator_type __x)', '    reverse_iterator(const reverse_iterator & __x)', '    reverse_iterator(const reverse_iterator & __x)'];
hash_provider.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 331;  3; 51;2;  278; 0;192;61;176;56;0.01;35;['    GetReversePackedSegsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReversePackedSegs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReversePackedSegs', '    vector', '    GetGradientDefs'];
hash_provider.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 272;  21; 44;15;  199; 0;69;117;77;111;0.11;36;['    final'];['    DoRunWithLengthType', '    DoRunWithType', '    ReversePackedSegsOp(Args,...)', '    RunOnDevice', '    ~ReversePackedSegsOp'];
ir.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 878;  18; 93;44;  727; 0;244;332;314;244;0.02;114;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURMACRegions', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RMACRegions', '    RunOnDevice'];
ir_mutator.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 465;  8; 64;9;  387; 0;244;176;140;173;0.02;51;['    final'];['    RMACRegionsOp(Args,...)', '    RunOnDevice'];
ir_mutator.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 109;  9; 11;9;  83; 0;0;80;0;93;0.11;1;['    RMaxMicrokernelTester'];['    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_u8rmax_ukernel_function u8rmax)'];
ir_printer.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 102;  4; 17;7;  78; 0;5;63;5;69;0.05;5;[];['    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)', '    operator==(const RMSpropOptions & lhs,const RMSpropOptions & rhs)', '    operator==(const RMSpropParamState & lhs,const RMSpropParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    RMSpropOptions(double lr)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)'];
ir_simplifier.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 1093;  118; 176;1;  802; 0;556;240;372;177;0.15;26;[];[];
ir_simplifier.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 392;  57; 69;7;  264; 0;79;145;64;102;0.22;37;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURmsProp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RmsProp', '    rmsprop_update(int N,const float *g,const float *ms,const float *mom,float *ng,float *nms,float *nmom,float decay,float momentum,float epsilon,const float *lr,CPUContext *)'];
ir_visitor.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 100;  9; 11;7;  76; 0;0;74;0;87;0.12;1;['    final'];['    rmsprop_update(int N,const float *g,const float *ms,const float *mom,float *ng,float *nms,float *nmom,float decay,float momentum,float epsilon,const float *lr,Context *context)', '    decay_', '    epsilon_', '    GetSingleArgument', '    momentum_', '    RmsPropOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ResizeLike'];
kernel.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 1548;  49; 167;21;  1305; 15;1003;268;573;189;0.04;35;[];['    createTestCPUGenerator(uint64_t value)', '    getInstanceCount', '    identity(Generator g)', '    PYBIND11_MODULE(TORCH_EXTENSION_NAME,m)', '    random_(Tensor & self,Generator generator)', '    random_from_to(Tensor & self,int64_t from,optional to,Generator generator)', '    random_to(Tensor & self,int64_t to,Generator generator)', '    device_type', '    clone_impl', '    current_seed', '    random', '    random64', '    seed', '    set_current_seed(uint64_t seed)', '    TestCPUGenerator(uint64_t value)', '    ~TestCPUGenerator'];
kernel.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 231;  3; 42;5;  184; 0;42;134;28;73;0.02;15;[];[];
llvm_codegen.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 56;  1; 1;9;  0; 52;0;0;0;0;0.00;0;[];['    GRUCellOptions(int64_t input_size,int64_t hidden_size)', '    GRUOptions(int64_t input_size,int64_t hidden_size)', '    LSTMCellOptions(int64_t input_size,int64_t hidden_size)', '    LSTMOptions(int64_t input_size,int64_t hidden_size)', '    RNNCellOptions(int64_t input_size,int64_t hidden_size)', '    RNNCellOptionsBase(int64_t input_size,int64_t hidden_size,bool bias,int64_t num_chunks)', '    RNNOptions(int64_t input_size,int64_t hidden_size)', '    RNNOptionsBase(rnn_options_base_mode_t mode,int64_t input_size,int64_t hidden_size)'];
llvm_jit.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 457;  1; 0;13;  0; 455;0;0;0;0;0.00;0;[];['    _quantized_params_dynamic(TensorList params,std::string qengine)', '    gather_params(TensorList params,bool has_biases)', '    gather_quantized_params(TensorList params)', '    gather_quantized_params_dynamic(TensorList params)', '    gather_quantized_params_fp16(TensorList params)', '    unpair_vec(std::vector)', '    _lstm_impl(const io_type & input,const std::vector & params,const Tensor & hx,const Tensor & cx,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _rnn_impl_with_concat(const io_type & input,const std::vector & params,const std::vector & hiddens,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _thnn_differentiable_gru_cell_backward(const Tensor & grad_hy,const Tensor & input_gates,const Tensor & hidden_gates,const Tensor & hx,const Tensor & input_bias,const Tensor & hidden_bias)', '    _thnn_differentiable_lstm_cell_backward(const Tensor & grad_hy,const Tensor & grad_cy,const Tensor & input_gates,const Tensor & hidden_gates,const Tensor & input_bias,const Tensor & hidden_bias,const Tensor & cx,const Tensor & cy)', '    _use_cudnn_rnn_flatten_weight', '    use_miopen(const at::Tensor & input,const double dropout_state)', '    CellParams', '    dropout(const Tensor & input,double p)', '    dropout(const PackedSequence & input,double p)', '    grad_bias', '    grad_hidden_bias', '    grad_input_bias', '    gru(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    gru_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    hidden_as_output(const Tensor & t)', '    hidden_as_output(const tpair_of & t)', '    hidden_concat(at::ArrayRef)', '    hidden_concat(at::ArrayRef hiddens)', '    hidden_slice(const Tensor & t,int64_t start,int64_t end)', '    hidden_slice(const tpair_of & t,int64_t start,int64_t end)', '    input', '    input', '    input', '    input', '    input', '    input', '    lstm(const Tensor & _input,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm(const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_cell(const Tensor & input,TensorList hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    output', '    PackedSequence', '    PackedSequence', '    prepare_quantized_hx(simple_hx_type hx)', '    prepare_quantized_lstm_hx(TensorList hx)', '    project(at::ArrayRef)', '    quantized_gru(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    quantized_gru(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    quantized_gru_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_lstm(const Tensor & _input,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first,c10::optional dtype,bool use_dynamic)', '    quantized_lstm(const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,c10::optional dtype,bool use_dynamic)', '    quantized_lstm_cell(const Tensor & input,TensorList hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_rnn_relu_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    quantized_rnn_tanh_cell(const Tensor & input,simple_hx_type hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh,const Tensor & packed_ih,const Tensor & packed_hh,const Tensor & col_offsets_ih,const Tensor & col_offsets_hh,const Scalar scale_ih,const Scalar scale_hh,const Scalar zero_point_ih,const Scalar zero_point_hh)', '    rnn_relu(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_relu_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    rnn_tanh(const Tensor & _input,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh(const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList _params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_cell(const Tensor & input,const Tensor & hx,const Tensor & w_ih,const Tensor & w_hh,const Tensor & b_ih,const Tensor & b_hh)', '    CellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    linear_hh(Tensor h)', '    linear_ih(Tensor input)', '    matmul_hh(Tensor h)', '    matmul_ih(Tensor input)', '    PackedSequence(Tensor _data,Tensor _batch_sizes)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    matmul_hh(const Tensor & h)', '    matmul_ih(const Tensor & input)', '    QuantizedCellParams(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh,const Tensor & _packed_ih,const Tensor & _packed_hh,const Tensor & _col_offsets_ih,const Tensor & _col_offsets_hh,const Scalar & _scale_ih,const Scalar & _scale_hh,const Scalar & _zero_point_ih,const Scalar & _zero_point_hh)', '    linear_hh(const Tensor & input_hh)', '    linear_ih(const Tensor & input_ih)', '    matmul_hh(const Tensor & h)', '    matmul_ih(const Tensor & input)', '    QuantizedCellParamsDynamic(const Tensor & _w_ih,const Tensor & _w_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    linear_hh(const Tensor & h)', '    linear_ih(const Tensor & input)', '    matmul_hh(const Tensor &)', '    matmul_ih(const Tensor &)', '    QuantizedCellParamsFP16(const Tensor & _packed_ih,const Tensor & _packed_hh,const Tensor & _b_ih,const Tensor & _b_hh)', '    operator()(const Tensor & t)', '    operator()(const Tensor & t)', '    ~Cell', '    FullBidirectionalLayer(Cell & cell)', '    operator()(const Tensor & input,const hidden_type & input_hidden,const param_type & params)', '    reverse(std::vector)', '    FullLayer(Cell & cell)', '    operator()(const std::vector & step_inputs,const hidden_type & input_hidden,const cell_params & params,bool pre_compute_input)', '    operator()(const Tensor & inputs,const hidden_type & input_hidden,const cell_params & params)', '    operator()(const Tensor & input,const hidden_type & hidden,const cell_params & params,bool pre_compute_input)', '    ~Layer', '    operator()(const Tensor & input,const hidden_type & hidden,const cell_params & params,bool pre_compute_input)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const param_type & params)', '    PackedBidirectionalLayer(Cell & cell)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const cell_params & params)', '    PackedLayer(Cell & cell)', '    operator()(const PackedSequence & input,const hidden_type & input_hidden,const cell_params & params)', '    ReversedPackedLayer(Cell & cell)', '    operator()(const Tensor & input,const Tensor & hidden,const cell_params & params,bool pre_compute_input)'];
llvm_jit.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 39;  1; 1;10;  0; 35;0;0;0;0;0.00;0;['    CuDNNMode'];['    compute_rnn_options_base_mode(RNNOptions::nonlinearity_t nonlinearity)', '    apply_permutation(const Tensor & tensor,const Tensor & permutation,int64_t dim)', '    get_cudnn_mode_for_rnn(detail::RNNOptionsBase::rnn_options_base_mode_t mode)', '    forward(const Tensor & input,Tensor hx)', '    GRUCellImpl(const GRUCellOptions & options_)', '    forward(const Tensor & input,Tensor hx)', '    forward_helper(const Tensor & input,const Tensor & batch_sizes,const Tensor & sorted_indices,int64_t max_batch_size,Tensor hx)', '    forward_with_packed_input(const PackedSequence & packed_input,Tensor hx)', '    GRUImpl(const GRUOptions & options_)', '    forward(const Tensor & input,torch::optional,Tensor)', '    LSTMCellImpl(const LSTMCellOptions & options_)', '    check_forward_args(const Tensor & input,std::tuple hidden,const Tensor & batch_sizes)', '    LSTMImpl(const LSTMOptions & options_)', '    permute_hidden(std::tuple hx,const Tensor & permutation)', '    forward(const Tensor & input,Tensor hx)', '    get_nonlinearity_str', '    RNNCellImpl(const RNNCellOptions & options_)', '    check_forward_hidden(const Tensor & input,const Tensor & hx,std::string hidden_label)', '    check_forward_input(const Tensor & input)', '    get_nonlinearity_str', '    pretty_print(std::ostream & stream)', '    reset_parameters', '    RNNCellImplBase(const RNNCellOptionsBase & options_)', '    forward(const Tensor & input,Tensor hx)', '    forward_helper(const Tensor & input,const Tensor & batch_sizes,const Tensor & sorted_indices,int64_t max_batch_size,Tensor hx)', '    forward_with_packed_input(const PackedSequence & packed_input,Tensor hx)', '    RNNImpl(const RNNOptions & options_)', '    all_weights', '    check_forward_args(Tensor input,Tensor hidden,Tensor batch_sizes)', '    check_hidden_size(const Tensor & hx,std::tuple expected_hidden_size,std::string msg)', '    check_input(const Tensor & input,const Tensor & batch_sizes)', '    flatten_parameters', '    get_expected_hidden_size(const Tensor & input,const Tensor & batch_sizes)', '    permute_hidden(Tensor hx,const Tensor & permutation)', '    pretty_print(std::ostream & stream)', '    reset_flat_weights', '    reset_parameters', '    RNNImplBase(const RNNOptionsBase & options_)', '    to(torch::Device device,torch::Dtype dtype,bool non_blocking)', '    to(torch::Dtype dtype,bool non_blocking)', '    to(torch::Device device,bool non_blocking)'];
loopnest.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 79;  4; 14;5;  59; 0;3;47;3;43;0.07;5;[];['    bi_grus', '    bi_lstm', '    BidirectionalGRUReverseForward(bool cuda)', '    BidirectionalLSTMReverseForwardTest(bool cuda)', '    check_lstm_sizes(std::tuple,std::tuple,torch::Tensor)', '    copyParameters(torch::nn::ModuleHolder & target,std::string t_suffix,const torch::nn::ModuleHolder & source,std::string s_suffix)', '    forward_op', '    gru_cpu', '    gru_cuda', '    gru_output_to_device(std::tuple gru_output,torch::Device device)', '    lstm_cpu', '    lstm_cuda', '    reverse_gru', '    reverse_lstm', '    TEST_F(RNNTest,CheckOutputSizes)', '    TEST_F(RNNTest,CheckOutputValuesMatchPyTorch)', '    TEST_F(RNNTest,EndToEndLSTM)', '    TEST_F(RNNTest,EndToEndGRU)', '    TEST_F(RNNTest,EndToEndRNNRelu)', '    TEST_F(RNNTest,EndToEndRNNTanh)', '    TEST_F(RNNTest,Sizes_CUDA)', '    TEST_F(RNNTest,EndToEndLSTM_CUDA)', '    TEST_F(RNNTest,EndToEndGRU_CUDA)', '    TEST_F(RNNTest,EndToEndRNNRelu_CUDA)', '    TEST_F(RNNTest,EndToEndRNNTanh_CUDA)', '    TEST_F(RNNTest,PrettyPrintRNNs)', '    TEST_F(RNNTest,BidirectionalFlattenParameters)', '    TEST_F(RNNTest,BidirectionalGRUReverseForward)', '    TEST_F(RNNTest,BidirectionalGRUReverseForward_CUDA)', '    TEST_F(RNNTest,BidirectionalLSTMReverseForward)', '    TEST_F(RNNTest,BidirectionalLSTMReverseForward_CUDA)', '    TEST_F(RNNTest,BidirectionalMultilayerGRU_CPU_vs_CUDA)', '    TEST_F(RNNTest,BidirectionalMultilayerLSTM_CPU_vs_CUDA)', '    TEST_F(RNNTest,UsePackedSequenceAsInput)', '    test_RNN_xor(Func,bool cuda)'];
mem_arena.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 56;  6; 11;1;  42; 0;15;20;13;16;0.14;8;[];['    dropout_state_cache', '    _copyParams(MatrixRef params_from,MatrixRef params_to)', '    _cudnn_impl(const Tensor & input,const Tensor & _batch_sizes,const hidden_type & hidden,TensorList params,bool has_biases,cudnnRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _cudnn_impl(const Tensor & input,const hidden_type & hidden,TensorList params,bool has_biases,cudnnRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    _cudnn_init_dropout_state(double dropout,bool train,int64_t dropout_seed,const TensorOptions & options)', '    _cudnn_rnn(const Tensor & input_r,TensorList weight,int64_t weight_stride0,const Tensor & weight_buf_r,const Tensor & hx,const Tensor & cx,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state)', '    _cudnn_rnn_backward_input(const Tensor & input_r,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,const Tensor & grad_output_r,const Tensor & grad_hy,const Tensor & grad_cy,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,std::array output_mask)', '    _cudnn_rnn_backward_weight(const Tensor & input_r,TensorList weight_arr,int64_t weight_stride0,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve)', '    _cudnn_rnn_flatten_weight(TensorList weight_arr,int64_t weight_stride0,int64_t input_size,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,bool fn_bidirectional)', '    _hidden_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _input_size(const TensorDescriptorListParams & tensors)', '    _num_linear_layers(cudnnRNNMode_t mode)', '    _output_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _viewOrCopyParams(MatrixRef params_from,MatrixRef params_to,bool copy)', '    _viewParams(MatrixRef params_from,MatrixRef params_to)', '    batch_sizes', '    get_algo(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors,const Tensor input)', '    get_dropout_state(double dropout_p,bool train,TensorOptions options)', '    get_expected_data_ptrs(const Tensor & weight_buf,cudnnHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,cudnnDataType_t datatype)', '    get_num_weights(cudnnHandle_t handle,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,cudnnDataType_t datatype)', '    get_parameters(cudnnHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,const FilterDescriptor & w_desc,const Tensor & weight_buf)', '    gru_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_cudnn(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & input,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm_packed_cudnn(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    promote_rnn_math_type(cudnnDataType_t dtype)', '    rnn_descriptor(const Tensor & tensor,int64_t N)', '    rnn_descriptor_sequence(const Tensor & tensor,IntArrayRef batch_sizes)', '    rnn_relu_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_cudnn(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh_packed_cudnn(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    try_get_weight_buf(const Tensor & input,TensorList parameters,bool has_biases,cudnnRNNMode_t mode,int64_t hidden_size,int64_t num_layers,bool bidirectional)', '    unpack_hidden(const std::tuple & hidden)', '    unpack_hidden(const Tensor & hidden)', '    weight', '    weight', '    DropoutDescriptorParams', '    lock', '    unlock', '    descriptor(cudnnHandle_t handle,DropoutDescriptor)', '    descriptor(cudnnHandle_t handle)', '    int64_t', '    num_directions', '    set_algo(cudnnRNNAlgo_t algo)', '    set_bidirectional(bool fn_bidirectional)', '    set_mode(int64_t fn_mode)', '    get_descs(const std::vector & descs)', '    get_x_descs', '    get_y_descs', '    RNNDescriptors(const RNNParams & fn,cudnnHandle_t handle,Tensor x,Tensor y,Tensor hx,Tensor cx)', '    descriptors(Tensor x)', '    IntArrayRef', '    is_input_packed'];
mem_arena.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 61;  16; 9;3;  40; 0;11;31;0;27;0.40;1;[];[];
stmt.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 537;  20; 75;5;  440; 0;170;175;145;117;0.05;59;[];[];
tensor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 7;  3; 1;1;  5; 0;0;5;0;3;0.60;0;[];['    check_device(const Tensor & input,const TensorList & params,const TensorList & hiddens)', '    gru_cudnn_stub', '    gru_cudnn_stub', '    operator=', '    gru_miopen_stub', '    gru_miopen_stub', '    operator=', '    gru_packed_cudnn_stub', '    gru_packed_cudnn_stub', '    operator=', '    gru_packed_miopen_stub', '    gru_packed_miopen_stub', '    operator=', '    lstm_cudnn_stub', '    lstm_cudnn_stub', '    operator=', '    lstm_miopen_stub', '    lstm_miopen_stub', '    operator=', '    lstm_packed_cudnn_stub', '    lstm_packed_cudnn_stub', '    operator=', '    lstm_packed_miopen_stub', '    lstm_packed_miopen_stub', '    operator=', '    operator=', '    rnn_relu_cudnn_stub', '    rnn_relu_cudnn_stub', '    operator=', '    rnn_relu_miopen_stub', '    rnn_relu_miopen_stub', '    operator=', '    rnn_relu_packed_cudnn_stub', '    rnn_relu_packed_cudnn_stub', '    operator=', '    rnn_relu_packed_miopen_stub', '    rnn_relu_packed_miopen_stub', '    operator=', '    rnn_tanh_cudnn_stub', '    rnn_tanh_cudnn_stub', '    operator=', '    rnn_tanh_miopen_stub', '    rnn_tanh_miopen_stub', '    operator=', '    rnn_tanh_packed_cudnn_stub', '    rnn_tanh_packed_cudnn_stub', '    operator=', '    rnn_tanh_packed_miopen_stub', '    rnn_tanh_packed_miopen_stub'];
tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 169;  11; 18;5;  138; 0;24;88;23;49;0.08;23;[];[];
types.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 163;  10; 29;17;  112; 0;33;61;35;62;0.09;23;[];['    _miopen_impl(const Tensor & input,const Tensor & _batch_sizes,const hidden_type & hidden,TensorList params,bool has_biases,miopenRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    _miopen_impl(const Tensor & input,const hidden_type & hidden,TensorList params,bool has_biases,miopenRNNMode_t mode,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    MatrixRef', '    _copyParams(MatrixRef params_from,MatrixRef params_to)', '    _copyParams_and_permute(MatrixRef params_from,MatrixRef params_to,int64_t mode)', '    _hidden_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _input_size(const TensorDescriptorListParams & tensors)', '    _num_linear_layers(miopenRNNMode_t mode)', '    _output_size(const RNNDescriptorParams & rnn,const TensorDescriptorListParams & tensors)', '    _viewOrCopyParams(MatrixRef params_from,MatrixRef params_to,bool copy)', '    _viewParams(MatrixRef params_from,MatrixRef params_to)', '    get_num_weights(miopenHandle_t handle,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,miopenDataType_t datatype)', '    get_parameters(miopenHandle_t handle,const RNNDescriptorParams & rnn,const RNNDescriptor & rnn_desc,const TensorDescriptor & x_desc,const FilterDescriptor & w_desc,const Tensor & weight_buf)', '    MatrixRef', '    miopen_rnn(const Tensor & input_r,TensorList weight,int64_t weight_stride0,const Tensor & hx,const Tensor & cx,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state)', '    permute_wei_for_miopen(Tensor wei,int64_t mode)', '    rnn_descriptor(const Tensor & tensor,int64_t N)', '    rnn_descriptor_sequence(const Tensor & tensor,IntArrayRef batch_sizes)', '    batch_sizes', '    gru_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    gru_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    lstm_miopen(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & input,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    lstm_packed_miopen(Tensor & output,Tensor & hy,Tensor & cy,const Tensor & data,const Tensor & batch_sizes,TensorList hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    miopen_rnn_backward_input(const Tensor & input_r,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,const Tensor & grad_output_r,const Tensor & grad_hy,const Tensor & grad_cy,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,std::array output_mask)', '    miopen_rnn_backward_weight(const Tensor & input_r,TensorList weight_arr,int64_t weight_stride0,const Tensor & weight_buf,const Tensor & hx,const Tensor & cx,const Tensor & output_r,int64_t fn_mode,int64_t fn_hidden_size,int64_t fn_num_layers,bool batch_first,double fn_dropout,bool fn_train,bool fn_bidirectional,IntArrayRef fn_batch_sizes,const Tensor & fn_dropout_state,const Tensor & fn_reserve,const Tensor & fn_workspace)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    pack_hidden(const Tensor & hx,const Tensor & cx)', '    rnn_relu_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_relu_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    rnn_tanh_miopen(Tensor & output,Tensor & hy,const Tensor & input,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional,bool batch_first)', '    rnn_tanh_packed_miopen(Tensor & output,Tensor & hy,const Tensor & data,const Tensor & batch_sizes,const Tensor & hx,TensorList params,bool has_biases,int64_t num_layers,double dropout_p,bool train,bool bidirectional)', '    unpack_hidden(const std::tuple & hidden)', '    unpack_hidden(const Tensor & hidden)', '    descriptor', '    int64_t', '    num_directions', '    set_algo(miopenRNNAlgo_t algo)', '    set_bidirectional(bool fn_bidirectional)', '    set_mode(int64_t fn_mode)', '    get_descs(const std::vector & descs)', '    get_x_descs', '    get_y_descs', '    RNNDescriptors(const RNNParams & fn,miopenHandle_t handle,Tensor x,Tensor y,Tensor hx,Tensor cx)', '    descriptors(Tensor x)', '    IntArrayRef', '    is_input_packed'];
unique_name_manager.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 48;  8; 6;3;  34; 0;19;14;13;11;0.24;2;['    C10FlagParser_caffe2_rocksdb_block_size', '    RocksDB', '    RocksDBCursor', '    RocksDBTransaction'];['    gCaffe2ModuleSanityCheckcaffe2_rocksdb', '    C10FlagParser_caffe2_rocksdb_block_size(const std::string & content)', '    Close', '    NewCursor', '    NewTransaction', '    RocksDB(const string & source,Mode mode)', '    key', '    Next', '    RocksDBCursor(rocksdb::DB *db)', '    Seek(const string & key)', '    SeekToFirst', '    SupportsSeek', '    Valid', '    value', '    ~RocksDBCursor', '    Commit', '    Put(const string & key,const string & value)', '    RocksDBTransaction(rocksdb::DB *db)', '    ~RocksDBTransaction'];
unique_name_manager.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 36;  6; 9;5;  19; 0;1;16;1;14;0.32;0;['    GetRoIAlignGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlignGradient', '    schema_OperatorName', '    add(const T & val,T *address)', '    bilinear_interpolate_gradient(const int height,const int width,T y,T x,T & w1,T & w2,T & w3,T & w4,int & x_low,int & x_high,int & y_low,int & y_high,const int)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignGradient', '    ROIAlignBackwardFeature(const int nthreads,const T *top_diff,const int,const T & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,T *bottom_diff,const T *bottom_rois,int rois_cols,bool continuous_coordinate)', '    vector', '    GetGradientDefs', '    RunOnDevice'];
file_check.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/testing; 478;  19; 52;11;  405; 0;236;164;204;100;0.05;30;['    final'];['    schema_RoIAlignGradient', '    GetSingleArgument', '    RoIAlignGradientOp(Args,...)', '    RunOnDevice'];
file_check.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/testing; 74;  22; 17;4;  34; 0;2;31;0;21;0.65;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlign', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlign', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const float *X,const float *R,float *Y)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const float *X,const float *R,float *Y)'];
hooks_for_testing.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/testing; 31;  2; 6;2;  23; 0;7;10;7;8;0.09;4;['    final'];['    schema_RoIAlign', '    Y_sizes', '    RoIAlignOp(Args,...)', '    RunOnDevice', '    RunOnDeviceWithOrderNCHW(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const T *X,const T *R,T *Y)', '    RunOnDeviceWithOrderNHWC(int64_t N,int64_t C,int64_t H,int64_t W,int64_t roi_cols,const T *X,const T *R,T *Y)'];
Layout.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 80;  37; 7;8;  65; 0;54;46;12;7;0.57;4;[];['    AddConstInput(const vector & shape,const float value,const string & name,Context *context,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    AddInput(const vector & shape,const vector & values,const string & name,Workspace *ws)', '    CreateAndRun(TensorCPU *outResult,const string & order,const TestParams & test_params,bool random_test)', '    GetDeviceType', '    randInt(int a,int b)', '    rois', '    TEST(RoiAlignTest,DISABLED_CheckCPUGPUEqual)', '    test_params'];
Layout.h;C++;pytorch-master/pytorch-master/torch/csrc; 25;  0; 9;4;  12; 0;2;9;1;8;0.00;1;['    GetRoIAlignRotatedGradient'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignRotatedGradient', '    vector', '    GetGradientDefs'];
MemoryFormat.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 80;  37; 7;8;  65; 0;54;46;12;7;0.57;4;['    final'];['    GetSingleArgument', '    RoIAlignRotatedGradientOp(Args,...)', '    RunOnDevice'];
Module.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 800;  53; 87;90;  537; 49;350;201;460;247;0.10;43;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURoIAlignRotated', '    schema_OperatorName', '    schema_OperatorName', '    pre_calc_for_bilinear_interpolate(const int height,const int width,const int pooled_height,const int pooled_width,const int iy_upper,const int ix_upper,T roi_start_h,T roi_start_w,T bin_size_h,T bin_size_w,int roi_bin_grid_h,int roi_bin_grid_w,T roi_center_h,T roi_center_w,T theta,std::vector)', '    ROIAlignRotatedForward(const int nthreads,const T *bottom_data,const T & spatial_scale,const int channels,const int height,const int width,const int pooled_height,const int pooled_width,const int sampling_ratio,const T *bottom_rois,int roi_cols,T *top_data,StorageOrder order,bool continuous_coordinate)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIAlignRotated', '    RunOnDevice'];
Module.h;C++;pytorch-master/pytorch-master/torch/csrc; 6;  0; 2;4;  0; 0;0;0;0;0;0.00;0;['    final'];['    schema_RoIAlignRotated', '    RoIAlignRotatedOp(Args,...)', '    RunOnDevice'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/multiprocessing; 58;  4; 13;13;  29; 3;20;20;5;8;0.14;2;['    GetRoIPoolFGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolF', '    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolFGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolF', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolFGradient', '    vector', '    GetGradientDefs'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/onnx; 47;  1; 5;6;  35; 1;31;5;6;5;0.03;1;['    final', '    final'];['    GetSingleArgument', '    RoIPoolFGradientOp(const OperatorDef & def,Workspace *ws)', '    RoIPoolFOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice'];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/onnx; 9;  1; 4;2;  3; 0;0;3;0;3;0.33;0;['    GetRoIPoolGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPURoIPool', '    CAFFE_ANONYMOUS_VARIABLE_CPURoIPoolGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPool', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RoIPoolGradient', '    vector', '    GetGradientDefs', '    RunOnDevice'];
onnx.h;C++;pytorch-master/pytorch-master/torch/csrc/onnx; 23;  11; 4;1;  15; 0;2;6;0;8;0.73;0;['    final', '    final'];['    RoIPoolGradientOp(Args,...)', '    RoIPoolOp(Args,...)', '    RunOnDevice', '    RunOnDevice'];
PtrWrapper.h;C++;pytorch-master/pytorch-master/torch/csrc; 16;  3; 5;4;  4; 0;0;4;0;4;0.75;0;['    GetRowMulGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUReduceTailSum', '    CAFFE_ANONYMOUS_VARIABLE_CPURowMul', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceTailSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowMul', '    vector', '    GetGradientDefs'];
python_dimname.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 100;  12; 17;4;  68; 0;38;27;26;26;0.18;6;['    ReduceTailSumOp', '    RowMulOp'];['    ReduceTailSumOp(Args,...)', '    RunOnDevice', '    ~ReduceTailSumOp', '    RowMulOp(Args,...)', '    RunOnDevice', '    ~RowMulOp'];
python_dimname.h;C++;pytorch-master/pytorch-master/torch/csrc; 8;  0; 2;3;  3; 0;0;3;0;3;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApprox'];
PythonTypes.h;C++;pytorch-master/pytorch-master/torch/csrc; 20;  1; 5;3;  12; 0;0;10;0;7;0.08;0;['    final', '    final', '    final'];['    compute_square_average_inlined_(const float *a,int len)', '    compute(int64_t block_size,const SIndex *indices,int64_t n,const TLengths *lengths,int64_t numSegments,const T *gradIn,const Tdata *paramIn,int64_t numParams,const T *momentIn,Tdata *paramOut,T *momentOut,float epsilon,T lr,rowWiseAdagradT & kernel)', '    compute(int64_t block_size,const SIndex *indices,int64_t n,const TLengths *lengths,int64_t numSegments,const T *gradIn,const Tdata *paramIn,int64_t numParams,const T *momentIn,const T *auxParamIn,Tdata *paramOut,T *momentOut,T *auxGrad,float epsilon,T lr,rowWiseAdagradT & kernel,CPUContext *context)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GetSingleArgument', '    RowWiseSparseAdagradFusedWithSparseLengthsSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp(const OperatorDef & operator_def,Workspace *ws)', '    RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    operator()(int N,float *w,float *w_n,const float *g,float g_sq_avg,float *h,float *h_n,float epsilon,float lr)', '    Resize', '    ResizeLike'];
QScheme.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 90;  38; 9;8;  73; 0;60;52;13;10;0.52;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPURowWiseCounter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RowWiseCounter'];
QScheme.h;C++;pytorch-master/pytorch-master/torch/csrc; 25;  0; 9;4;  12; 0;2;9;1;8;0.00;1;['    final'];['    DoRunWithType', '    GetSingleArgument', '    RowWiseCounterOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
serialization.h;C++;pytorch-master/pytorch-master/torch/csrc; 25;  0; 8;13;  4; 0;0;4;0;2;0.00;0;[];[];
Size.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 234;  47; 26;12;  191; 2;138;109;122;66;0.25;10;[];['    getCurrentRpcAgent', '    isCurrentRpcAgentSet', '    setCurrentRpcAgent(std::shared_ptr rpcAgent)', '    cleanup', '    enableGILProfiling(bool flag)', '    getDebugInfo', '    getTypeResolver', '    getWorkerInfo', '    isGILProfilingEnabled', '    retryExpiredRpcs', '    RpcAgent(WorkerInfo workerId,std::unique_ptr cb,std::chrono::milliseconds rpcTimeout)', '    rpcRetryCallback(const rpc::Message & message,const c10::optional & futErr,steady_clock_time_point newTime,std::shared_ptr earliestRpc)', '    sendWithRetries(const WorkerInfo & to,Message,RpcRetryOptions retryOptions)', '    setTypeResolver(std::shared_ptr typeResolver)', '    ~RpcAgent', '  Static Member Variables', '    currentRpcAgent_', '    MAX_NAME_LEN'];
Size.h;C++;pytorch-master/pytorch-master/torch/csrc; 14;  0; 5;5;  4; 0;0;4;0;4;0.00;0;['    RpcAgent'];['    getCurrentRpcAgent', '    isCurrentRpcAgentSet', '    setCurrentRpcAgent(std::shared_ptr rpcAgent)', '    time_point_cast', '    operator()(const torch::distributed::rpc::WorkerInfo & worker_info)', '    isalnum', '    now', '    addGilWaitTime(const std::chrono::microseconds gilWaitTime)', '    cleanup', '    computeNewRpcRetryTime(RpcRetryOptions & options,int retryCount)', '    enableGILProfiling(bool flag)', '    getDebugInfo', '    getMetrics', '    getRpcTimeout', '    getTypeResolver', '    getWorkerInfo', '    getWorkerInfo(const std::string & workerName)', '    getWorkerInfo(worker_id_t id)', '    getWorkerInfos', '    isGILProfilingEnabled', '    join', '    retryExpiredRpcs', '    RpcAgent(WorkerInfo workerId,std::unique_ptr cb,std::chrono::milliseconds rpcTimeout)', '    rpcRetryCallback(const rpc::Message & message,const c10::optional & futErr,steady_clock_time_point newTime,std::shared_ptr earliestRpc)', '    send(const WorkerInfo & to,Message)', '    sendWithRetries(const WorkerInfo & to,Message,RpcRetryOptions retryOptions)', '    setRpcTimeout(const std::chrono::milliseconds & rpcTimeout)', '    setTypeResolver(std::shared_ptr typeResolver)', '    shutdown', '    start', '    sync', '    ~RpcAgent', '    RpcBackendOptions', '    RpcBackendOptions(std::chrono::milliseconds rpcTimeout,std::string initMethod)', '    RpcRetryInfo(const WorkerInfo & to,Message,std::shared_ptr originalFuture,int retryCount,RpcRetryOptions options)', '    maxRetries', '    retryBackoff', '    rpcRetryDuration', '    RpcRetryOptions', '    operator==(const WorkerInfo & rhs)', '    WorkerInfo(std::string name,int64_t id)', '    WorkerInfo(std::string name,worker_id_t id)'];
Storage.h;C++;pytorch-master/pytorch-master/torch/csrc; 68;  0; 11;57;  0; 0;0;0;0;0;0.00;0;['    RpcCommandBase'];['    toMessageImpl', '    toMessage', '    toMessageImpl', '    ~RpcCommandBase'];
StorageDefs.h;C++;pytorch-master/pytorch-master/torch/csrc; 5;  0; 0;1;  4; 0;0;3;0;2;0.00;0;[];['    ivalues', '    autogradMetadata', '    fromMessage(const Message & message)', '    fromWorkerId', '    moveWrappedRpc', '    RpcWithAutograd(worker_id_t fromWorkerId,MessageType messageType,const AutogradMetadata & autogradMetadata,rpc::Message)', '    RpcWithAutograd(worker_id_t fromWorkerId,MessageType messageType,const AutogradMetadata & autogradMetadata,std::unique_ptr wrappedRpc,MessageType wrappedMessageType,std::vector tensors)', '    setWrappedRpc(std::unique_ptr wrappedRpc)', '    tensors', '    toMessageImpl', '    wrappedMessageType', '    wrappedRpc'];
stub.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 18;  0; 2;6;  6; 4;1;2;1;2;0.00;1;['    final'];['    fromMessage(const rpc::Message & message)', '    autogradMetadata', '    fromWorkerId', '    moveWrappedRpc', '    RpcWithAutograd(rpc::worker_id_t fromWorkerId,rpc::MessageType messageType,const AutogradMetadata & autogradMetadata,rpc::Message)', '    RpcWithAutograd(rpc::worker_id_t fromWorkerId,rpc::MessageType messageType,const AutogradMetadata & autogradMetadata,std::unique_ptr wrappedRpc,rpc::MessageType wrappedMessageType,std::vector tensors)', '    setWrappedRpc(std::unique_ptr wrappedRpc)', '    tensors', '    toMessageImpl', '    wrappedMessageType', '    wrappedRpc'];
python_tensor.h;C++;pytorch-master/pytorch-master/torch/csrc/tensor; 36;  12; 9;4;  13; 0;0;13;0;11;0.92;0;['    RpcMetricsHandler'];['    ~RpcMetricsHandler'];
THP.h;C++;pytorch-master/pytorch-master/torch/csrc; 45;  5; 9;32;  0; 0;0;0;0;0;0.00;0;[];['    confirmPendingUser(const rpc::Message & message,const c10::optional & futErr)', '    finishCreatingOwnerRRef(const Message & message,const c10::optional & futErr)', '    getInstance', '    addConfirmedUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    addForkOfOwnerIfNotPresent(const RRefId & rrefId,const ForkId & forkId)', '    addPendingChild(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addPendingUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addSelfAsFork(c10::intrusive_ptr & rref)', '    checkRRefLeaks(bool ignoreRRefLeak)', '    clearRecordedPendingRRefsOnError', '    createOwnerRRef(const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,const TypePtr & type)', '    delAllUsers(std::chrono::milliseconds timeoutMillis)', '    delForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    delPendingChild(const ForkId & forkId)', '    delPendingUser(const ForkId & forkId)', '    delUser(const worker_id_t owner,const RRefId & rrefId,const ForkId & forkId)', '    finishForkRequest(const ForkId & forkId,worker_id_t parent)', '    getDebugInfo', '    getOrCreateOwnerRRef(const RRefId & rrefId,const TypePtr & type)', '    getOrCreateRRef(const RRefForkData & rrefForkData,const TypePtr & type)', '    getOwnerRRef(const RRefId & rrefId)', '    handleException(const c10::optional & futErr)', '    notifyOwnerAndParentOfFork(const ForkId & forkId,worker_id_t parent,const c10::intrusive_ptr & rref)', '    prepareChildFork(const c10::intrusive_ptr & rref)', '    recordThreadLocalPendingRRefs', '    RRefContext(std::shared_ptr agent)', '    ~RRefContext', '  Static Member Variables', '    recording'];
THP_export.h;C++;pytorch-master/pytorch-master/torch/csrc; 17;  0; 2;15;  0; 5;0;0;0;0;0.00;0;['    RRefContext'];['    confirmPendingUser(const rpc::Message & message,const c10::optional & futErr)', '    finishCreatingOwnerRRef(const Message & message,const c10::optional & futErr)', '    getInstance', '    handleException(const c10::optional & futErr)', '    static_intrusive_pointer_cast', '    addConfirmedUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    addForkOfOwnerIfNotPresent(const RRefId & rrefId,const ForkId & forkId)', '    addPendingChild(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addPendingUser(const ForkId & forkId,const c10::intrusive_ptr & rref)', '    addSelfAsFork(c10::intrusive_ptr & rref)', '    agent', '    checkRRefLeaks(bool ignoreRRefLeak)', '    clearRecordedPendingRRefsOnError', '    createOwnerRRef(const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const TypePtr & type)', '    createUserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,const TypePtr & type)', '    delAllUsers(std::chrono::milliseconds timeoutMillis)', '    delForkOfOwner(const RRefId & rrefId,const ForkId & forkId)', '    delPendingChild(const ForkId & forkId)', '    delPendingUser(const ForkId & forkId)', '    delUser(const worker_id_t owner,const RRefId & rrefId,const ForkId & forkId)', '    finishForkRequest(const ForkId & forkId,worker_id_t parent)', '    genGloballyUniqueId', '    getDebugInfo', '    getOrCreateOwnerRRef(const RRefId & rrefId,const TypePtr & type)', '    getOrCreateRRef(const RRefForkData & rfd,const TypePtr & type)', '    getOwnerRRef(const RRefId & rrefId)', '    getWorkerId', '    getWorkerName', '    notifyOwnerAndParentOfFork(const ForkId & forkId,worker_id_t parent,const c10::intrusive_ptr & rref)', '    operator=', '    operator=', '    confirm', '    PendingUserState(c10::intrusive_ptr rref)', '    prepareChildFork(const c10::intrusive_ptr & rref)', '    recordThreadLocalPendingRRefs', '    RRefContext', '    RRefContext', '    RRefContext(std::shared_ptr)', '    ~RRefContext'];
ThreadLocalState.h;C++;pytorch-master/pytorch-master/torch/csrc; 39;  5; 9;3;  22; 1;0;0;0;0;0.23;0;[];['    getFuture', '    getTypeStr(const c10::TypePtr & type)', '    getValue', '    hasValue', '    setValue(IValue)', '    nextLocalId_', '    fork', '    RRef(worker_id_t ownerId,const RRefId & rrefId,TypePtr type)', '    RRefForkData(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,worker_id_t parent,std::string typeStr)', '    fork', '    forkId', '    release_resources', '    toHere', '    tryDel', '    UserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,TypePtr type)'];
TypeInfo.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 296;  82; 26;12;  255; 0;190;135;262;202;0.32;17;['    final', '    final', '    RRef'];['    confirm', '    confirmedByOwner', '    confirmedByOwner', '    deletedOnOwner_', '    fork', '    forkId', '    getFuture', '    getValue', '    hasValue', '    isOwner', '    isOwner', '    operator=', '    operator=', '    operator=', '    operator=', '    release_resources', '    setValue(IValue)', '    toHere', '    tryDel', '    UserRRef', '    UserRRef', '    UserRRef(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,TypePtr type)', '    worker_id_t', '    worker_id_t', '    ~UserRRef', '    fork', '    isPyObj', '    operator=', '    owner', '    ownerName', '    RRef', '    RRef', '    RRef(worker_id_t ownerId,const RRefId & rrefId,TypePtr type)', '    rrefId', '    tryDel', '    type', '    ~RRef', '    RRefForkData(worker_id_t ownerId,const RRefId & rrefId,const ForkId & forkId,worker_id_t parent,std::string typeStr)'];
TypeInfo.h;C++;pytorch-master/pytorch-master/torch/csrc; 26;  0; 9;3;  14; 0;2;9;2;9;0.00;2;[];[];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 251;  2; 32;21;  196; 0;110;56;91;53;0.01;20;[];['    fromIValues(std::vector ivalues,MessageType type)', '    toIValues(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    toMessageImpl', '    forkId', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    fromMessage(const Message & message)', '    toMessageImpl', '    fromMessage(const Message & message)', '    forkId', '    toMessageImpl', '    toMessageImpl', '    values', '    rrefId', '    toMessageImpl'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc; 194;  4; 36;120;  31; 20;2;29;2;24;0.13;2;['    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    final', '    ForkMessageBase', '    RRefFetchRet', '    RRefMessageBase'];['    fromMessage(const Message & message)', '    fromMessage(const Message & message,MessageType type)', '    fromMessage(const Message & message,MessageType type)', '    forkId', '    fromWorkerId', '    PythonRRefFetchCall(worker_id_t fromWorkerId,const RRefId & rrefId)', '    PythonRRefFetchRet(std::vector values)', '    RemoteRet(const RRefId & rrefId,const ForkId & forkId)', '    RRefAck', '    RRefChildAccept(const ForkId & forkId)', '    RRefForkRequest(const RRefId & rrefId,const ForkId & forkId)', '    RRefUserDelete(const RRefId & rrefId,const ForkId & forkId)', '    ScriptRRefFetchCall(worker_id_t fromWorkerId,const RRefId & rrefId)', '    ScriptRRefFetchRet(std::vector values)', '    toMessageImpl', '    forkId', '    ForkMessageBase(const RRefId & rrefId,const ForkId & forkId,MessageType type)', '    toMessageImpl', '    ~ForkMessageBase', '    RRefFetchRet(std::vector values,MessageType type)', '    toMessageImpl', '    values', '    rrefId', '    RRefMessageBase(const RRefId & rrefId,MessageType type)', '    toMessageImpl', '    ~RRefMessageBase'];
auto_gil.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 40;  13; 8;3;  21; 0;3;11;3;10;0.62;5;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPURsqrt', '    CAFFE_ANONYMOUS_VARIABLE_CPURsqrtGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Rsqrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RsqrtGradient', '    GetGradientDefs', '    Forward(const std::vector & dY_dims,const std::vector &,const T *dY,const T *Y,T *dX,CPUContext *)', '    vector'];
byte_order.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 87;  2; 7;6;  74; 0;0;74;0;17;0.03;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & Y_dims,const T *dY,const T *Y,T *dX,Context *context)'];
cuda_enabled.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 15;  0; 3;4;  7; 1;1;5;1;3;0.00;1;['    C10FlagParser_plan'];['    main(int argc,char **argv)', '    C10FlagParser_plan(const std::string & content)'];
cuda_lazy_init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 33;  4; 6;5;  18; 0;9;9;8;7;0.22;2;['    C10FlagParser_plan'];['    main(int argc,char **argv)', '    C10FlagParser_plan(const std::string & content)'];
disallow_copy.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 5;  0; 2;3;  0; 0;0;0;0;0;0.00;0;[];['    debugInfo', '    Start', '    Stop', '    RunCountOperatorObserver(OperatorBase *op,RunCountNetObserver *netObserver)', '    Start', '    Stop'];
future.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 152;  23; 26;2;  104; 0;44;36;41;50;0.22;14;['    final', '    final'];['    debugInfo', '    RunCountNetObserver(NetBase *subject_)', '    RunCountOperatorObserver', '    RunCountOperatorObserver(OperatorBase *op,RunCountNetObserver *netObserver)', '    Start', '    Stop', '    ~RunCountNetObserver', '    ~RunCountOperatorObserver'];
hash.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 138;  47; 22;3;  69; 0;14;39;13;42;0.68;9;[];[];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 11;  2; 4;2;  5; 0;0;5;0;3;0.40;0;[];['    sub_zero_point(const uint8x8_t va,const uint8x8_t vzp)'];
invalid_arguments.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 401;  6; 51;6;  340; 0;211;135;163;112;0.02;23;[];['    sub_zero_point(const __m128i va,const __m128i vzp)'];
invalid_arguments.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 15;  1; 4;4;  7; 0;0;7;0;2;0.14;0;['    GetSampleAsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSampleAs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSampleAsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SampleAs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SampleAsGradient', '    vector', '    GetGradientDefs'];
numpy_stub.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 21;  1; 2;14;  0; 15;0;0;0;0;0.00;0;['    final', '    final'];['    RunOnDevice', '    RunOnDevice', '    SampleAsGradientOp(const OperatorDef & def,Workspace *ws)', '    SampleAsOp(const OperatorDef & operator_def,Workspace *ws)'];
object_ptr.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 11;  0; 3;2;  6; 0;2;2;2;2;0.00;1;[];[];
object_ptr.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 38;  11; 5;2;  20; 0;12;16;19;19;0.55;12;[];['    SavedVariable(const Variable & variable,bool is_output,bool is_inplace_view)', '    unpack(std::shared_ptr saved_for)'];
python_arg_parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 864;  120; 74;12;  662; 0;442;169;372;186;0.18;21;[];[];
python_arg_parser.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 729;  130; 85;34;  480; 2;221;203;191;200;0.27;48;[];['    asr_s32(int32_t x,uint32_t n)', '    asr_s64(int64_t x,uint32_t n)', '    pytorch_scalar_requantize_precise(int32_t value,float scale,uint8_t zero_point,uint8_t qmin,uint8_t qmax)'];
python_compat.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 82;  14; 12;18;  38; 5;23;7;20;3;0.37;2;[];['    compute_sum(size_t n,const uint8_t *x,const uint32_t *t)', '    pytorch_u8lut32norm_ukernel__scalar(size_t n,const uint8_t *x,const uint32_t *t,uint8_t *y)'];
python_dispatch.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 9;  1; 3;1;  5; 0;0;5;0;4;0.20;0;[];[];
python_numbers.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 168;  3; 16;31;  92; 26;0;0;0;0;0.03;0;[];['    pytorch_x8lut_ukernel__scalar(size_t n,const uint8_t *x,const uint8_t [256] t,uint8_t *y)'];
python_scalars.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 54;  1; 6;5;  43; 0;34;4;65;4;0.02;2;[];[];
python_stub.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 4;  0; 1;1;  2; 0;1;1;1;3;0.00;0;[];['    _local_scalar_dense_cpu(const Tensor & self)', '    item(const Tensor & self)'];
python_tuples.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 23;  0; 3;5;  15; 0;0;0;0;0;0.00;0;[];['    operator-'];
six.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 58;  10; 10;10;  27; 2;12;8;12;8;0.37;6;[];[];
structseq.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 13;  0; 5;4;  3; 1;0;3;0;3;0.00;0;[];[];
tensor_apply.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 99;  1; 13;6;  80; 0;44;30;39;26;0.01;6;[];[];
tensor_apply.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 13;  1; 4;3;  6; 0;0;6;0;5;0.17;0;[];['    require_equal_size_dim(const Tensor & lhs,const Tensor & rhs)', '    should_expand(const IntArrayRef & from_size,const IntArrayRef & to_size)', '    TEST(TestScalarTensor,TestScalarTensorCPU)', '    TEST(TestScalarTensor,TestScalarTensorCUDA)', '    test(DeprecatedTypeProperties & T)'];
tensor_dtypes.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 11;  1; 4;4;  3; 0;0;3;0;3;0.33;0;[];['    TEST(TestScalar,TestScalar)', '    test_overflow', '    apply(Tensor a,Tensor b)', '    apply(Tensor a,Tensor b)'];
tensor_flatten.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 120;  4; 19;3;  94; 0;58;40;47;35;0.04;6;['    ScalarTypeHashFunction'];['    CreateProfiledTensorTypeWithScalarType(const TensorTypePtr & typePtr,const c10::ScalarType & scalar_type)', '    ImplicitCastForONNX(Block *block)', '    InferExpectedScalarType(const Node *n)', '    IsComparisonOp(const NodeKind & nkind)', '    IsImplicitCastSupported(const NodeKind & nodeKind)', '    IsStandardOp(const NodeKind & nkind)', '    PromoteScalarTypes(const std::vector & types)', '    ScalarTypeToONNXType(const c10::ScalarType & st)', '    UpdateScalarTypeForInputs(Node *n,const c10::ScalarType & scalar_type)', '    UpdateScalarTypeForOutput(Node *n,const c10::ScalarType & scalar_type)', '    ImplicitCastForONNX(const std::shared_ptr & graph)', '    ScalarTypeAnalysisForONNX(const std::shared_ptr & graph)', '    operator()(const c10::ScalarType & type)'];
tensor_flatten.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 76;  22; 12;5;  37; 0;15;23;13;17;0.59;3;[];['    ScalarTypeAnalysisForONNX(const std::shared_ptr & graph)'];
tensor_layouts.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 7;  1; 3;1;  3; 0;0;3;0;3;0.33;0;[];[];
tensor_list.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 42;  1; 6;4;  32; 0;19;12;16;11;0.03;2;['    ScalarType'];['    canCast(const ScalarType from,const ScalarType to)', '    elementSize(ScalarType t)', '    isComplexType(ScalarType t)', '    isFloatingType(ScalarType t)', '    isIntegralType(ScalarType t)', '    isIntegralType(ScalarType t,bool includeBool)', '    isQIntType(ScalarType t)', '    isSignedType(ScalarType t)', '    isUnderlying(ScalarType type,ScalarType qtype)', '    operator==(ScalarType t,caffe2::TypeMeta m)', '    operator==(caffe2::TypeMeta m,ScalarType t)', '    promoteTypes(ScalarType a,ScalarType b)', '    scalarTypeToTypeMeta(ScalarType scalar_type)', '    toQIntType(ScalarType t)', '    toString(ScalarType t)', '    toUnderlying(ScalarType t)', '    toValueType(ScalarType t)', '    tryTypeMetaToScalarType(caffe2::TypeMeta dtype)', '    typeMetaToScalarType(caffe2::TypeMeta dtype)', '    operator<<(std::ostream & stream,at::ScalarType scalar_type)', '    TypeMeta'];
tensor_list.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 10;  1; 4;3;  3; 0;0;3;0;3;0.33;0;[];[];
tensor_memoryformats.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 7;  1; 3;1;  3; 0;0;3;0;3;0.33;0;[];[];
tensor_new.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 717;  48; 54;28;  570; 26;384;209;272;149;0.08;30;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUScaleBlobs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScaleBlobs'];
tensor_new.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 22;  1; 5;3;  14; 0;0;14;0;10;0.07;0;['    final'];['    DoRunWithType', '    RunOnDevice', '    ScaleBlobsOp(Args,...)'];
tensor_numpy.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 19;  1; 7;3;  9; 0;0;0;0;0;0.11;0;['    GetScaleGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUScale', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Scale', '    vector', '    GetGradientDefs'];
tensor_qschemes.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 44;  2; 9;7;  28; 0;15;12;11;10;0.07;2;['    final'];['    DoRunWithType', '    RunOnDevice', '    ScaleOp(Args,...)'];
tensor_qschemes.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 9;  1; 3;2;  4; 0;0;4;0;4;0.25;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAScale', '    RunOnDevice'];
tensor_types.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 16;  2; 5;4;  6; 0;0;6;0;7;0.33;0;[];['    gather_cpu_kernel(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index)', '    gather_shape_check(const Tensor & self,int64_t dim,const Tensor & index)', '    scatter_add_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_fill_cpu_kernel(Tensor & self,int64_t dim,const Tensor & index,Scalar src)', '    scatter_shape_check(const Tensor & self,int64_t dim,const Tensor & index,const c10::optional & src_opt)', '    operator()(scalar_t *self_data,int64_t self_dim_stride,int64_t *index_data,int64_t index_dim_stride,scalar_t *src_data,int64_t src_dim_stride,int64_t dim,int64_t index_dim_size,int64_t index_upper_bound,const func_t & f)', '    operator()(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src,const std::string & method_name,const func_t & f,bool serial_exec)'];
throughput_benchmark-inl.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 133;  14; 16;5;  101; 0;49;31;40;59;0.14;4;[];['    gather_shape_check(const Tensor & self,int64_t dim,const Tensor & index)', '    scatter_shape_check(const Tensor & self,int64_t dim,const Tensor & index,const c10::optional & src_opt)'];
throughput_benchmark.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 129;  7; 18;3;  104; 0;51;44;36;20;0.07;13;['    PyTorchSchemasRegisterer'];['    registerer', '    PyTorchSchemasRegisterer'];
variadic.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 1;  1; 0;0;  0; 0;0;0;0;0;0.00;0;[];[];
variadic.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 139;  21; 28;8;  84; 0;0;0;0;0;0.25;0;[];['    emitBuiltinNode(const MatchedSchema & matched_schema,const SourceRange & loc,Graph & graph,Symbol name)', '    packOutputs(Graph & g,at::ArrayRef values,c10::OptNameList field_names)', '    prefixLine(const std::string & str,const std::string & prefix)', '    isIntOrFloatUsedAsList(const Value *value,const Argument & arg)', '    tryCreateList(const TypePtr & elem_type,Graph & graph,const SourceRange & loc,at::ArrayRef varargs,std::ostream *failure_messages,const std::function & err,bool convert_tensor_to_num,TypeEnv & type_env)', '    tryMatchArgument(const Argument & arg,Graph & graph,const SourceRange & loc,const NamedValue & named_value,std::ostream *failure_messages,const std::function & err,bool allow_conversions,TypeEnv & type_env)', '    tryMatchSchema(const FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,c10::optional self,std::ostream *failure_messages,bool allow_conversions)', '    unwrapOptional(TypePtr opt_type)', '    varargsCanBeUsedAsList(const FunctionSchema & schema,size_t arg_index,const Argument & arg)', '    allow_conversions', '    emitBuiltinCall(const SourceRange & loc,Graph & graph,Symbol name,at::ArrayRef inputs,at::ArrayRef attributes,const c10::optional & self)', '    err', '    matchSchemas(const std::vector & schemas,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & self,bool render_errors)', '    convertibleToList(const TypePtr & type,const TypePtr & list_type_)', '    findInputWithName(const std::string & name,at::ArrayRef kwargs)', '    tryConvertToType(const SourceRange & loc,Graph & graph,const TypePtr & concrete_type,Value *value,bool allow_conversions)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs,const c10::optional & self)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwargs)'];
WindowsTorchApiMacro.h;C++;pytorch-master/pytorch-master/torch/csrc; 7;  2; 2;3;  0; 0;0;0;0;0;0.00;0;[];['    convertibleToList(const TypePtr & type,const TypePtr & list_type_)', '    emitBuiltinCall(const SourceRange & loc,Graph & graph,Symbol name,at::ArrayRef inputs,at::ArrayRef attributes,const c10::optional & self)', '    findInputWithName(const std::string & name,at::ArrayRef kwargs)', '    matchSchema(const ::c10::FunctionSchema & schema,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwarg,const c10::optional & self)', '    matchSchemas(const std::vector & schemas,const SourceRange & loc,Graph & graph,at::ArrayRef args,at::ArrayRef kwarg,const c10::optional & self,bool render_errors)', '    tryConvertToType(const SourceRange & loc,Graph & graph,const TypePtr & concrete_type,Value *value,bool allow_conversions)'];
custom_class_detail.h;C++;pytorch-master/pytorch-master/torch; 155;  11; 28;5;  114; 0;0;0;0;0;0.10;0;[];['    parseList(int begin,int sep,int end,const std::function & callback)', '    parseRefinedTensor', '    parseTensorDType(const std::string & dtype)', '    parseAliasAnnotation', '    parseBaseType'];
extension.h;C++;pytorch-master/pytorch-master/torch; 6;  2; 1;3;  0; 0;0;0;0;0;0.00;0;[];['    parseAliasAnnotation', '    parseBaseType', '    parseList(int begin,int sep,int end,const std::function & callback)', '    parseRefinedTensor', '    parseTensorDType(const std::string & dtype)', '    SchemaTypeParser(Lexer & L,bool parse_complete_tensor_types)'];
allreduce.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/example; 32;  3; 5;2;  22; 0;13;14;9;14;0.14;1;[];['    TEST(SCONV_6x8__PSIMD,k_eq_1)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_strided_c)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_qmin128)', '    TEST(SCONV_6x8__PSIMD,k_eq_1_qmax128)', '    TEST(SCONV_6x8__PSIMD,k_gt_1)', '    TEST(SCONV_6x8__PSIMD,k_gt_1_strided_c)', '    TEST(SCONV_6x8__PSIMD,k_gt_1_subtile)'];
FileStore.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 47;  1; 18;5;  24; 0;0;20;0;18;0.04;0;[];['    pytorch_sconv_ukernel_6x8__psimd(size_t mr,size_t nr,size_t kc,size_t ks,const float **a,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
GlooDeviceFactory.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 123;  5; 20;31;  22; 56;8;8;7;6;0.23;3;[];['    callee', '    InlinedCallStack(Function *fn,SourceRange source_range)', '    InlinedCallStack(InlinedCallStackPtr callee,Function *fn,SourceRange source_range)', '    intrusive_from_this', '    vec', '    getDepth', '    getRoot', '    intrusive_from_this', '    isBlank', '    isRoot', '    name', '    namesFromRoot(const std::string & separator)', '    parent', '    push(Symbol name)', '    Scope', '    Scope(ScopePtr parent,Symbol name)'];
GlooDeviceFactory.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 28;  5; 7;5;  14; 0;0;12;0;6;0.36;0;[];[];
HashStore.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 39;  1; 13;6;  20; 0;1;14;1;12;0.05;2;['    ScopeGuardImplBase', '    ScopeGuardImpl'];['    makeFailsafe(std::true_type,const void *)', '    ScopeGuardImpl(const FunctionType & fn)', '    execute', '    function_(std::forward fn)', '    MakeGuard(F)', '    ScopeGuardImpl(FunctionType)', '    ScopeGuardImpl(ScopeGuardImpl)', '    ScopeGuardImpl(Fn,ScopeGuardImplBase)', '    ref(*fn)', '    ~ScopeGuardImpl', '    asConst(const T & t)', '    makeEmptyScopeGuard', '    dismiss', '    ScopeGuardImplBase', '    ScopeGuardImpl(FunctionType & fn)'];
NCCLUtils.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 34;  3; 6;2;  24; 0;13;9;5;11;0.13;2;[];[];
NCCLUtils.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 166;  16; 22;44;  63; 24;25;30;26;27;0.25;10;[];['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    matchOperator(const std::string & str_schema)', '    hasOp', '    hasQualifiedName', '    op', '    qualifiedName', '    ScriptCall(std::shared_ptr op,std::vector)', '    ScriptCall(const c10::QualifiedName & qualifiedName,std::vector)', '    stack', '    stackRef', '    toIValues(std::vector & ivalues)', '    toMessageImpl', '  Static Member Variables', '    ATEN_PREFIX_', '    BUILTIN_OP_NAMESPACE_'];
PrefixStore.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 36;  1; 13;3;  20; 0;0;16;0;14;0.05;1;['    ScriptCall'];['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    matchOperator(const std::string & str_schema)', '    hasOp', '    hasQualifiedName', '    op', '    qualifiedName', '    ScriptCall(std::shared_ptr op,std::vector)', '    ScriptCall(const c10::QualifiedName & qualifiedName,std::vector)', '    stack', '    stackRef', '    toIValues(std::vector & ivalues)', '    toMessageImpl', '    ~ScriptCall'];
ProcessGroup.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 75;  7; 16;2;  54; 0;25;19;22;15;0.13;13;[];['    _jit_debug_module_iterators(Module & module)', '    bind(const py::module & m,const char *name)', '    mergeDefaultsAndExtraParametersToOverloadDecl(const Decl & overload_decl,const Decl & impl_decl,const FunctionDefaults & defaults)', '    script_compile_function(const c10::QualifiedName & name,const Def & def,const FunctionDefaults & defaults,ResolutionCallback rcb)', '    script_compile_overloaded_function(const c10::QualifiedName & name,const Decl & overload_decl,const Def & implementation_def,ResolutionCallback rcb,const FunctionDefaults & implementation_defaults,const py::object & signature)', '    _assign_output_shapes(Graph & graph,std::vector outputs)', '    _propagate_and_assign_input_shapes(Graph & graph,const std::vector & inputs,bool with_grad,bool propagate)', '    _propagate_shapes(Graph & graph,std::vector inputs,bool with_grad)', '    getTensorType(const at::Tensor & t,bool complete)', '    getTupleTensorType(const Stack::const_iterator & s_iter,const Stack::const_iterator & s_iter_end,const TypePtr & tupleType,bool complete)', '    setInputTensorTypes(Graph & g,const Stack & stack,bool complete)', '    debugMakeList(const T & list)', '    debugMakeNamedList(const T & list)', '    getattr(const std::string & name)', '    getSchemaWithNameAndDefaults(const SourceRange & range,const FunctionSchema & schema,const at::optional & new_name,const FunctionDefaults & default_args)', '    initJitScriptBindings(PyObject *module)', '    setattr(const std::string & name,py::object value)', '    addFunctionToModule(Module & module,const StrongFunctionPtr & func)', '    calcOverloadedFunctionDefaults(const FunctionSchema & schema,const FunctionDefaults & defaults)', '    checkMutableFunctionDefault(const py::object & def_arg)', '    checkOverloadDecl(const Decl & new_decl,const Decl & old_decl)', '    ivalue_tags_match(const Module & lhs,const Module & rhs)', '    pythonResolver(ResolutionCallback rcb)', '    pythonResolver(ResolutionCallback rcb,std::string classname,ClassTypePtr classType)', '    tryCalculateDefaultParam(const Argument & arg,const py::object & def_value)', '    isNamedTupleClass(py::object obj)', '    contains(const std::string & name)', '    slot_dict_impl(ModulePtr)', '    getClassType', '    makeSugared(Value *v)', '    ModuleSelf(std::shared_ptr concreteType)', '    PythonResolver(ResolutionCallback rcb)', '    PythonResolver(ResolutionCallback rcb,std::string classname,ClassTypePtr classType)', '    resolveType(const std::string & name,const SourceRange & loc)', '    resolveTypeFromObject(const py::object & obj,const SourceRange & loc)', '    resolveValue(const std::string & name,Function & m,const SourceRange & loc)'];
ProcessGroup.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 187;  62; 34;9;  83; 0;18;73;2;37;0.75;2;[];['    initJitScriptBindings(PyObject *module)'];
ProcessGroupGloo.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 267;  72; 49;21;  126; 2;20;105;4;58;0.57;1;['    final', '    final', '    ScriptModuleDeserializer', '    ScriptModuleSerializer'];['    CAFFE_ANONYMOUS_VARIABLE_CPUScriptModule', '    CAFFE_ANONYMOUS_VARIABLE_CPUScriptModuleLoad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScriptModule', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScriptModuleLoad', '    noexcept', '    castIValueToTensor(IValue)', '    RunOnDevice', '    RunOnDevice', '    ScriptModuleLoadOp(const OperatorDef & operator_def,Workspace *ws)', '    ScriptModuleOp(const OperatorDef & operator_def,Workspace *ws)', '    Deserialize(const BlobProto & proto,Blob *blob)', '    Serialize(const void *pointer,TypeMeta typeMeta,const string & name,SerializationAcceptor acceptor)'];
ProcessGroupMPI.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 685;  34; 96;19;  541; 6;288;178;226;160;0.06;35;[];['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    ScriptRemoteCall(std::shared_ptr op,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    ScriptRemoteCall(const c10::QualifiedName & qualifiedName,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    toMessageImpl'];
ProcessGroupMPI.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 209;  38; 43;12;  117; 0;22;101;5;59;0.32;1;['    final'];['    fromIValues(std::vector & ivalues)', '    fromMessage(const Message & message)', '    retForkId', '    retRRefId', '    ScriptRemoteCall(std::shared_ptr op,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    ScriptRemoteCall(const c10::QualifiedName & qualifiedName,std::vector,const RRefId & retRRefId,const ForkId & retForkId)', '    toMessageImpl'];
ProcessGroupNCCL.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 382;  157; 70;9;  147; 0;20;138;0;71;1.07;2;[];['    fromMessage(const Message & message)', '    ScriptResp(at::IValue)', '    toMessageImpl', '    value'];
ProcessGroupRoundRobin.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 121;  13; 19;1;  101; 0;25;60;26;20;0.13;17;['    final'];['    fromMessage(const Message & message)', '    ScriptResp(at::IValue)', '    toMessageImpl', '    value'];
ProcessGroupRoundRobin.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 100;  12; 22;3;  64; 0;12;61;0;21;0.19;0;[];['    collectQualname(const Select & select)', '    isTorch(const Expr & expr)', '    evaluateDefaults(const SourceRange & r,const std::vector & default_types,const std::vector & default_exprs)', '    parseArgsFromDecl(const Decl & decl,bool skip_self)', '    parseBaseTypeName(const Expr & expr)', '    parseClassConstant(const Assign & assign)', '    parseReturnFromDecl(const Decl & decl)', '    parseSchemaFromDef(const Def & def,bool skip_self)', '    parseType(const std::string & str)', '    parseTypeFromExpr(const Expr & expr)', '    subscriptToType(const std::string & typeName,const Subscript & subscript)'];
Store.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 47;  1; 15;6;  26; 0;10;20;0;15;0.04;2;['    ScriptTypeParser'];['    evaluateDefaults(const SourceRange & r,const std::vector & default_types,const std::vector & default_exprs)', '    parseArgsFromDecl(const Decl & decl,bool skip_self)', '    parseBaseTypeName(const Expr & expr)', '    parseClassConstant(const Assign & assign)', '    parseReturnFromDecl(const Decl & decl)', '    parseSchemaFromDef(const Def & def,bool skip_self)', '    parseType(const std::string & str)', '    parseTypeFromExpr(const Expr & expr)', '    ScriptTypeParser', '    ScriptTypeParser(ResolverPtr resolver)', '    subscriptToType(const std::string & typeName,const Subscript & subscript)'];
TCPStore.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 430;  48; 48;5;  332; 0;199;103;169;84;0.14;26;[];['    pytorch_sdwconv_ukernel_up4x9__psimd(size_t channels,size_t output_width,const float **input,const float *weights,float *output,size_t input_stride,size_t output_increment,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
TCPStore.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 100;  6; 27;6;  62; 0;7;55;0;46;0.10;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPULengthsIndicesInGradientMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsIndicesInGradientSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientMeanGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseLengthsIndicesInGradientWeightedSumWithMainInputGradient', '    schema_OperatorName', '    schema_OperatorName', '    schema_OperatorName', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_gradient_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsIndicesInGradientMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsIndicesInGradientSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReduceFrontWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_segment_name', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeLogMeanExpGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeLogSumExpGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeMaxGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentRangeSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsIndicesInGradientWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseLengthsWeightedSumWithMainInputGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseSortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseUnsortedSegmentWeightedSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentMeanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentSumGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UnsortedSegmentWeightedSumGradient', '    CostInferenceForSparseLengths(const OperatorDef & def,const vector & inputs,bool use_weight)', '    equal(char const *lhs,char const *rhs1,char const *rhs2,char const *rhs3)', '    FormatDoc'];
FileStoreTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 91;  6; 13;6;  66; 0;40;21;29;34;0.09;3;['    AbstractSortedSegmentRangeGradientOp', '    BaseInputAccessor'];['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    schema_LengthsMax', '    schema_LengthsMean', '    schema_LengthsSum', '    RangeReducer', '    PopulateSchema(OpSchema & schema)', '    GetGradientDefs', '    vector', '    AbstractSortedSegmentRangeGradientOp(Args,...)', '    RunOnDevice', '    ~AbstractSortedSegmentRangeGradientOp', '    BaseInputAccessor', '    getBlockPtr(int64_t in_block_size,int64_t idx,int64_t)', '    observeInput(const Tensor & dataInput)', '    raw_data'];
HashStoreTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 62;  4; 7;6;  46; 0;19;16;13;48;0.09;2;['    GetSelectSmoothL1LossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSelectSmoothL1Loss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSelectSmoothL1LossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SelectSmoothL1Loss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SelectSmoothL1LossGradient', '    vector', '    GetGradientDefs'];
ProcessGroupGlooAsyncTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 261;  22; 41;6;  192; 0;92;82;101;72;0.11;15;['    final', '    final'];['    buff_', '    buff_', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SelectSmoothL1LossGradientOp(const OperatorDef & def,Workspace *ws)', '    SelectSmoothL1LossOp(const OperatorDef & operator_def,Workspace *ws)'];
ProcessGroupMPITest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 357;  28; 42;12;  259; 16;183;106;153;104;0.11;9;['    GetSeluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUSeluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Selu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SeluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
ProcessGroupNCCLErrorsTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 248;  9; 46;10;  180; 3;72;73;70;49;0.05;21;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    SeluGradientOp(Args,...)', '    SeluOp(Args,...)'];
ProcessGroupNCCLTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 445;  45; 68;8;  324; 0;178;165;164;161;0.14;24;[];['    apply(torch::autograd::variable_list)', '    setGrads(const torch::autograd::variable_list & grads)'];
TCPStoreTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 118;  13; 20;7;  79; 0;30;41;8;105;0.16;3;[];['    apply(torch::autograd::variable_list)', '    setGrads(const torch::autograd::variable_list & grads)'];
TestUtils.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 106;  6; 18;11;  73; 0;35;26;27;24;0.08;9;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAddPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUGatherPadding', '    CAFFE_ANONYMOUS_VARIABLE_CPUPadEmptySamples', '    CAFFE_ANONYMOUS_VARIABLE_CPURemovePadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AddPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherPadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PadEmptySamples', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_RemovePadding', '    g_inputs', '    g_inputs', '    padding_grads', '    zero', '    MakePadding(const T *in_ptr,T *out_ptr,const int32_t *lengths_ptr,int32_t lengths_size,int32_t outer_size,const T *padding_start_ptr,const T *padding_end_ptr,int64_t block_size)', '    RunOnDevice', '    GatherPadding(const int outer_size,const int lengths_size,const int block_size,const int pad_width,const T *in_ptr,const int *lengths_ptr,T *padding_start_ptr,T *padding_end_ptr)', '    GetGradientDefs', '    GetGradientDefs', '    DoRunWithType'];
Types.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 64;  4; 14;3;  47; 0;19;30;0;30;0.09;0;['    final', '    final', '    final', '    PadEmptySamplesOp'];['    AddPaddingOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    DoRunWithType', '    GatherPadding(const int outer_size,const int lengths_size,const int block_size,const int pad_width,const T *in_ptr,const int *lengths_ptr,T *padding_start_ptr,T *padding_end_ptr)', '    GatherPaddingOp(Args,...)', '    GetSingleArgument', '    lengths_prefix_sum_', '    lengths_prefix_sum_', '    lengths_prefix_sum_', '    lengths_prefix_sum_buffer_', '    lengths_prefix_sum_buffer_', '    lengths_prefix_sum_buffer_', '    MakePadding(const T *in_ptr,T *out_ptr,const int32_t *lengths_ptr,int32_t lengths_size,int32_t outer_size,const T *padding_start_ptr,const T *padding_end_ptr,int64_t block_size)', '    RemovePaddingOp(Args,...)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    PadEmptySamplesOp(Args,...)', '    RunOnDevice'];
Utils.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 540;  31; 67;33;  408; 3;174;194;148;145;0.08;41;[];['    buffer_contains_result(const std::vector)', '    next(ResultProducer next_result)', '    buffer(size_t index)', '    next(ResultProducer next_result)', '    OrderedSequencer(size_t max_jobs)', '    next(ResultProducer next_result)', '    ~Sequencer'];
alloc_info.h;C++;pytorch-master/pytorch-master/torch/lib/libshm; 9;  0; 2;2;  5; 0;0;4;0;4;0.00;0;[];['    forward', '    forward', '    forward', '    forward', '    forward', '    M(const M & other)', '    TEST_F(SequentialTest,CanContainThings)', '    TEST_F(SequentialTest,ConstructsFromSharedPointer)', '    TEST_F(SequentialTest,ConstructsFromConcreteType)', '    TEST_F(SequentialTest,ConstructsFromModuleHolder)', '    TEST_F(SequentialTest,PushBackAddsAnElement)', '    TEST_F(SequentialTest,AccessWithAt)', '    TEST_F(SequentialTest,AccessWithPtr)', '    TEST_F(SequentialTest,CallingForwardOnEmptySequentialIsDisallowed)', '    TEST_F(SequentialTest,CallingForwardChainsCorrectly)', '    TEST_F(SequentialTest,CallingForwardWithTheWrongReturnTypeThrows)', '    TEST_F(SequentialTest,TheReturnTypeOfForwardDefaultsToTensor)', '    TEST_F(SequentialTest,ForwardReturnsTheLastValue)', '    TEST_F(SequentialTest,SanityCheckForHoldingStandardModules)', '    TEST_F(SequentialTest,ExtendPushesModulesFromOtherSequential)', '    TEST_F(SequentialTest,HasReferenceSemantics)', '    TEST_F(SequentialTest,IsCloneable)', '    TEST_F(SequentialTest,RegistersElementsAsSubmodules)', '    TEST_F(SequentialTest,CloneToDevice_CUDA)', '    TEST_F(SequentialTest,PrettyPrintSequential)', '    TEST_F(SequentialTest,ModuleForwardMethodOptionalArg)', '    forward(int x)', '    forward(int x)', '    forward(int x)', '    forward(int x)', '    forward(torch::Tensor v)', '    forward', '    forward', '    MImpl(int value_)', '    forward(int value)', '    MockModule(int value)'];
core.cpp;C++;pytorch-master/pytorch-master/torch/lib/libshm; 126;  3; 16;7;  102; 0;63;32;88;30;0.03;11;[];['    index', '    load(serialize::InputArchive & archive)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    SequentialSampler(size_t size)'];
libshm.h;C++;pytorch-master/pytorch-master/torch/lib/libshm; 33;  4; 10;4;  15; 0;2;11;2;11;0.27;2;[];[];
manager.cpp;C++;pytorch-master/pytorch-master/torch/lib/libshm; 168;  9; 24;21;  117; 4;83;33;66;31;0.08;7;[];[];
socket.h;C++;pytorch-master/pytorch-master/torch/lib/libshm; 154;  0; 24;13;  117; 0;60;44;93;42;0.00;17;[];['    doRead(file,& size,)', '    doRead(file,data,)', '    doRead(file,le_buffer,)', '    THP(THStorage *self,io fd,bool save_size)', '    THPUtils_setError(__VA_ARGS__)', '    THP_decodeInt16Buffer(int16_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)', '    THP_decodeInt32Buffer(int32_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)', '    THP_decodeInt64Buffer(& size,,torch::utils::THP_nativeByteOrder,)', '    THP_decodeInt64Buffer(int64_t *,le_buffer,torch::utils::THP_nativeByteOrder,to_convert)'];
libshm.h;C++;pytorch-master/pytorch-master/torch/lib/libshm_windows; 26;  0; 8;9;  9; 1;1;7;1;6;0.00;2;[];[];
script.h;C++;pytorch-master/pytorch-master/torch; 12;  0; 2;10;  0; 0;0;0;0;0;0.00;0;;[];['    doPartialPythonIO(PyObject *fildes,void *buf,size_t nbytes,bool is_read)', '    doPartialPythonReadBuffered(PyObject *fildes,void *buf,size_t raw_nbytes)', '    doPartialPythonReadInto(PyObject *fildes,void *buf,size_t nbytes)', '    doPartialPythonWrite(PyObject *fildes,void *buf,size_t nbytes)', '    isUnsupportedOperation', '    doPartialRead(int fildes,void *buf,size_t nbytes)', '    doPartialRead(PyObject *fildes,void *buf,size_t nbytes)', '    doPartialWrite(int fildes,void *buf,size_t nbytes)', '    doPartialWrite(PyObject *fildes,void *buf,size_t nbytes)', '    doRead(io fildes,void *raw_buf,size_t nbytes)', '    doWrite(io fildes,void *raw_buf,size_t nbytes)'];
pytorch_jni_common.cpp;C++;pytorch-master/pytorch-master/android/pytorch_android/src/main/cpp; 623;  6; 41;19;  533; 27;383;314;111;397;0.01;22;[];[];
pytorch_vision_jni.cpp;C++;pytorch-master/pytorch-master/android/pytorch_android_torchvision/src/main/cpp; 144;  1; 18;5;  121; 0;76;67;39;70;0.01;1;[];['    doRead(io fildes,void *raw_buf,size_t nbytes)', '    doWrite(io fildes,void *raw_buf,size_t nbytes)'];
autocast_mode.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 506;  147; 46;29;  294; 5;187;178;67;72;0.50;24;[];['    THP(THStorage *self,io fd,bool save_size)'];
Backtrace.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];['    pickle_load(const std::vector & data)', '    pickle_save(const at::IValue & ivalue)'];
Array.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 38;  3; 7;5;  20; 3;7;13;5;13;0.15;3;[];['    serialize(serialize::InputArchive & archive,const std::string & key,int64_t & value)', '    serialize(serialize::OutputArchive & archive,const std::string & key,const std::vector & steps)', '    serialize(serialize::InputArchive & archive,const std::string & key,std::vector & steps)', '    serialize(serialize::OutputArchive & archive,const std::string & key,const int64_t & value)'];
BackendSelectFallbackKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 14;  0; 4;1;  9; 0;4;6;3;5;0.00;0;[];['    closure', '    closure', '    is_optimizer_param_group_equal(const OptimizerParamGroup & lhs,const OptimizerParamGroup & rhs)', '    is_optimizer_state_equal(const ska::flat_hash_map,std::unique_ptr,const ska::flat_hash_map,std::unique_ptr)', '    iteration_', '    save_and_load(torch::Tensor input)', '    step', '    step', '    step', '    step', '    step', '    step', '    step', '    TEST(SerializeTest,KeysFunc)', '    TEST(SerializeTest,TryReadFunc)', '    TEST(SerializeTest,Basic)', '    TEST(SerializeTest,BasicToFile)', '    TEST(SerializeTest,BasicViaFunc)', '    TEST(SerializeTest,Resized)', '    TEST(SerializeTest,Sliced)', '    TEST(SerializeTest,NonContiguous)', '    TEST(SerializeTest,ErrorOnMissingKey)', '    TEST(SerializeTest,XOR)', '    TEST(SerializeTest,Optim)', '    TEST(SerializeTest,Optim_Adagrad)', '    TEST(SerializeTest,Optim_SGD)', '    TEST(SerializeTest,Optim_Adam)', '    TEST(SerializeTest,Optim_RMSprop)', '    TEST(SerializeTest,Optim_LBFGS)', '    TEST(SerializeTest,XOR_CUDA)', '    TEST(SerializeTest,CanSerializeModulesWithIntermediateModulesWithoutParametersOrBuffers)', '    TEST(SerializeTest,VectorOfTensors)', '    TEST(SerializeTest,IValue)', '    TEST(SerializeTest,UnserializableSubmoduleIsSkippedWhenSavingModule)', '    TEST(SerializeTest,UnserializableSubmoduleIsIgnoredWhenLoadingModule)', '    test_serialize_optimizer(DerivedOptimizerOptions options,bool only_has_global_state)', '    write_int_value(torch::serialize::OutputArchive & archive,const std::string & key,const int64_t & value)', '    write_step_buffers(torch::serialize::OutputArchive & archive,const std::string & key,const std::vector & steps)', '    write_tensors_to_archive(torch::serialize::OutputArchive & archive,const std::string & key,const BufferContainer & buffers)', '    xor_model', '    A', '    A', '    A', '    A(const std::string & name_b,const std::string & name_c)', '    B(const std::string & name_c)', '    B', '    C', '    M'];
boxing.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 71;  11; 15;4;  41; 0;0;0;0;0;0.27;0;[];[];
kernel_functor.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 318;  38; 49;3;  230; 0;0;0;0;0;0.17;0;[];[];
kernel_lambda_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 754;  30; 139;5;  580; 0;384;320;203;264;0.05;40;[];[];
KernelFunction_impl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/boxing; 190;  19; 34;1;  146; 0;0;0;0;0;0.13;0;[];['    serialize(torch::serialize::InputArchive & archive)', '    serialize(torch::serialize::OutputArchive & archive)', '    operator==(const SGDOptions & lhs,const SGDOptions & rhs)', '    operator==(const SGDParamState & lhs,const SGDParamState & rhs)', '    load(serialize::InputArchive & archive)', '    save(serialize::OutputArchive & archive)', '    step(LossClosure closure)', '    serialize(torch::serialize::OutputArchive & archive)', '    serialize(torch::serialize::InputArchive & archive)', '    SGDOptions(double lr)'];
custom_class.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 44;  2; 10;4;  29; 0;11;11;11;14;0.07;5;[];[];
DeprecatedTypePropertiesRegistry.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 31;  3; 10;3;  16; 0;0;0;0;0;0.19;0;[];['    MobileNetV1(benchmark::internal::Benchmark *b)', '    MobileNetV2(benchmark::internal::Benchmark *b)', '    ResNet18(benchmark::internal::Benchmark *b)', '    ResNet50(benchmark::internal::Benchmark *b)', '    sgemm(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    sgemm_6x8__psimd(benchmark::State & state,const char *net)', '    sgemm_in_l1(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    sgemmBenchmark(benchmark::State & state,pytorch_sgemm_ukernel_function sgemm,uint32_t mc,uint32_t nc,uint32_t kc,uint32_t mr,uint32_t nr,uint32_t np,uint32_t kr)', '    ShuffleNetV1G1(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G2(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G3(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G4(benchmark::internal::Benchmark *b)', '    ShuffleNetV1G8(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X05(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X10(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X15(benchmark::internal::Benchmark *b)', '    ShuffleNetV2X20(benchmark::internal::Benchmark *b)', '    SqueezeNetV10(benchmark::internal::Benchmark *b)', '    SqueezeNetV11(benchmark::internal::Benchmark *b)', '    VGG(benchmark::internal::Benchmark *b)', '    clampingParams', '    divideRoundUp(uint32_t x,uint32_t q)', '    roundUp(uint32_t x,uint32_t q)'];
Dimname.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 48;  1; 14;5;  29; 0;0;0;0;0;0.03;0;[];['    TEST(SGEMM_6x8__PSIMD,k_eq_2)', '    TEST(SGEMM_6x8__PSIMD,k_eq_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_eq_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_eq_8_qmin128)', '    TEST(SGEMM_6x8__PSIMD,k_eq_8_qmax128)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_gt_2_subtile)', '    TEST(SGEMM_6x8__PSIMD,k_div_2)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_strided_a)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_strided_c)', '    TEST(SGEMM_6x8__PSIMD,k_div_2_subtile)'];
DispatchKeyExtractor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 25;  1; 6;2;  17; 0;8;5;8;4;0.06;3;[];['    pytorch_sgemm_ukernel_5x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)', '    pytorch_sgemm_ukernel_6x8__neon(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)', '    pytorch_sgemm_ukernel_6x8__psimd(size_t mr,size_t nr,size_t k,const float *a,size_t a_stride,const float *w,float *c,size_t c_stride,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
OperatorEntry.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core/dispatch; 192;  11; 21;1;  159; 0;89;63;78;30;0.07;13;['    ShapePropagator'];['    all_reduce_ops', '    all_reduce_ops_with_integer_upcast_and_dtype', '    any_tensor_type', '    argminmax', '    binary_ops_strict_match', '    broadcast', '    broadcasting_ops', '    broadcasting_ops_arithmetic', '    broadcasting_tensor_scalar_ops', '    broadcasting_tensor_scalar_ops_arithmetic', '    cast_ops', '    comparison_ops', '    determineListSize(Value *list)', '    dim_reduce_ops', '    dim_reduce_ops_dtype', '    dim_reduce_ops_with_integer_upcast', '    factory_with_ndim', '    fused_accum_binary_ops', '    get_cast_scalar_type', '    like_factories_with_options', '    multidim_reduce_with_keepdim', '    nn_ops_first_input_preserving', '    propagate', '    propagate_complete', '    reduce_op_handler', '    reduce_ops_with_opt_dtype', '    register_softmax', '    reshape_prop', '    resize_ops', '    simple_unary_ops', '    size_factories_with_options', '    where_op', '    broadcastBinary(Node *node,std::vector & types,size_t idx1,size_t idx2)', '    canPropagateShapeByRunningIt(Node *node)', '    dependsOnMutation(Node *node)', '    DoesntRefineOutputs(Node *node)', '    EraseShapeInformation(at::ArrayRef vals)', '    EraseShapeInformation(Block *b)', '    EraseShapeInformation(const std::shared_ptr & graph)', '    getPromotedTypeForArithmeticOp(Node *node)', '    getSingleOutputType', '    mergeTypes(ArrayRef lhs,ArrayRef rhs,ArrayRef outputs)', '    PropagateCatShape(Node *cat_node)', '    PropagateCompleteShapeOnNode(Node *node,bool insert_expands,std::vector tensor_types)', '    PropagateInputShapes(const std::shared_ptr & graph)', '    PropagateShapeOnNode(Node *node,bool insert_expands)', '    PropagateShapeOnNodeByRunningIt(Node *node)', '    PropagateTensorShapeOnNode(Node *node,bool insert_expands)', '    propagateTorchTensorShape(Node *node)', '    setUnshapedTypeIfAliasResizedSet(at::ArrayRef vs)', '    containsTensorType(const TypePtr & t)', '    isValidArgumentForRunning(Value *v)', '    isValidReturnForRunning(Value *v)', '    unionScalarTypes(c10::ScalarType original,c10::ScalarType next)', '    jitDeviceIndexToDevice(int device)', '    register_formula_for(OperatorSet operators,formula_t formula)', '    collectResizeSet(Block *block)', '    PropagateShapeOnBlock(Block *block,bool insert_expands)', '    representativeValue(Value *v)', '    resizesInput(Node *n)', '    setUnshapedType(Value *o)', '    setUnshapedType(Node *node)', '    ShapePropagator(std::shared_ptr graph)', '    wrapDim(int64_t dim,at::IntArrayRef sizes)'];
DistributionsHelper.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 278;  57; 42;17;  161; 3;63;82;54;76;0.35;14;[];[];
function_schema.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 9;  0; 3;1;  5; 0;1;3;1;2;0.00;1;[];['    constructShapeInfoWithDefaultDimType(TensorShape shape,TensorBoundShape_DimType defaultFirstDimType)', '    getShapeInfoFromBlob(const Blob *blob)', '    operator==(const ShapeInfo & lhs,const ShapeInfo & rhs)', '    parseShapeInfoMapFromString(const std::string & input,ShapeInfoMap & shape_hints)'];
Generator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 98;  34; 18;14;  33; 0;9;17;9;13;1.03;10;[];['    constructShapeInfoWithDefaultDimType(TensorShape shape,TensorBoundShape_DimType defaultFirstDimType)', '    getShapeInfoFromBlob(const Blob *blob)', '    operator==(const ShapeInfo & lhs,const ShapeInfo & rhs)', '    parseShapeInfoMapFromString(const std::string & input,ShapeInfoMap & shape_hints)', '    QShapeInfo(float o,float s,uint32_t a)', '    dimTypeIsSet', '    getDimType', '    getDimType(int idx)', '    setDimType(const std::vector & dim_types)', '    setDimType(int idx,TensorBoundShape_DimType type)', '    ShapeInfo(bool q)', '    ShapeInfo(std::vector,TensorShape,bool q)', '    ShapeInfo(const std::vector & t,TensorShape,bool q)', '    ShapeInfo(const std::vector & t,const TensorShape & s,bool q)', '    ShapeInfo(bool q,const QShapeInfo & info)', '    ShapeInfo(const std::vector & t,TensorShape,bool q,const QShapeInfo & info)', '    ShapeInfo(const std::vector & t,const TensorShape & s,bool q,const QShapeInfo & info)'];
interned_strings.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 426;  64; 31;272;  68; 11;0;0;0;0;0.94;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUShape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Shape'];
ivalue_inl.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 938;  105; 103;21;  718; 0;0;0;0;0;0.15;0;['    IDEEPShapeOp'];['    IDEEPShapeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
LegacyTypeDispatch.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 12;  2; 3;1;  6; 0;1;4;1;3;0.33;1;['    ShapeOp'];['    RunOnDevice', '    ShapeOp(Args,...)'];
List_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1084;  4; 200;2;  882; 0;601;177;564;178;0.00;135;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAShape'];
NamedTensor.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 123;  31; 27;4;  63; 0;0;0;0;0;0.49;0;[];[];
op_registration.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core/op_registration; 918;  411; 90;11;  411; 1;0;0;0;0;1.00;0;[];['    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    combine(arg_t a,arg_t b)', '    project(arg_t)', '    reduce(arg_t arg,scalar_t val,int64_t idx)', '    translate_idx(arg_t a,int64_t base_idx)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    translate_idx(acc_t acc,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    operator()(scalar_t a,scalar_t b)', '    operator()(scalar_t a,scalar_t b)', '    combine(acc_t a,acc_t b)', '    MeanOps(factor_t factor)', '    project(acc_t a)', '    reduce(acc_t a,acc_t b,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    NormOps(acc_t norm_)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    combine(acc_t a,acc_t b)', '    project(acc_t a)', '    reduce(acc_t acc,acc_t data,int64_t)', '    WelfordData', '    WelfordData(scalar_t mean,scalar_t m2,index_t n,combine_t nf)', '    combine(acc_t a,acc_t b)', '    project(acc_t acc)', '    reduce(acc_t acc,scalar_t data,index_t)', '    WelfordOps(bool unbiased,bool take_sqrt)'];
OpsAlreadyMovedToC10.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 14;  1; 5;2;  6; 0;0;0;0;0;0.17;0;[];['    available', '    convolution2d(const Tensor &,const Tensor &,const Tensor &,const IntArrayRef,const IntArrayRef,const IntArrayRef,const int64_t,const bool)', '    linear(const Tensor &,const Tensor &,const Tensor &)', '    use_convolution2d(const Tensor &,const Tensor &,const Tensor &,const IntArrayRef,const IntArrayRef,const IntArrayRef,const int64_t,const bool)', '    use_linear(const Tensor &,const Tensor &,const Tensor &)'];
Range.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 25;  1; 8;3;  14; 0;2;11;2;8;0.07;3;[];['    getInstance', '    addLock(const std::string & name)', '    removeLock(const std::string & name)'];
Scalar.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;['    ShmProcessMutex', '    ShmProcessMutexCheck', '    ShmTicketMutex', '    ShmTTSetMutex'];['    getInstance', '    internalDestroy', '    lock', '    operator=(ShmProcessMutex)', '    ShmProcessMutex(ShmProcessMutex)', '    ShmProcessMutex(const char *name)', '    try_lock', '    unlock', '    ~ShmProcessMutex', '    addLock(const std::string & name)', '    operator=', '    removeLock(const std::string & name)', '    ShmProcessMutexCheck', '    ShmProcessMutexCheck', '    ShmTicketMutex(const char *name,int delay)', '    subUnlock', '    waitForLock', '    ShmTTSetMutex(const char *name,int timeout)', '    subUnlock', '    waitForLock'];
Tensor.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 12;  8; 1;3;  0; 0;0;0;0;0;0.00;0;['    SigmoidOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8'];
typeid.h;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_qnnp_create_sigmoid_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *sigmoid_out)', '    pytorch_qnnp_setup_sigmoid_nc_q8(pytorch_qnnp_operator_t sigmoid,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
VariableHooksInterface.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/core; 17;  1; 4;1;  12; 0;4;7;2;6;0.08;2;[];['    Compute(T x)', '    Sigmoid(double max_abs_err)'];
FlushDenormal.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu; 32;  2; 5;5;  7; 14;3;5;1;5;0.29;1;[];['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    sigmoid_q8(benchmark::State & state)'];
vec256.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 228;  10; 9;28;  18; 176;0;0;0;0;0.56;0;[];['    TEST(SIGMOID_OP,zero_batch)', '    TEST(SIGMOID_OP,unit_batch)', '    TEST(SIGMOID_OP,unit_batch_with_qmin)', '    TEST(SIGMOID_OP,unit_batch_with_qmax)', '    TEST(SIGMOID_OP,unit_batch_with_input_scale)', '    TEST(SIGMOID_OP,unit_batch_with_input_zero_point)', '    TEST(SIGMOID_OP,small_batch)', '    TEST(SIGMOID_OP,small_batch_with_input_stride)', '    TEST(SIGMOID_OP,small_batch_with_output_stride)', '    TEST(SIGMOID_OP,small_batch_with_qmin)', '    TEST(SIGMOID_OP,small_batch_with_qmax)', '    TEST(SIGMOID_OP,small_batch_with_input_scale)', '    TEST(SIGMOID_OP,small_batch_with_input_zero_point)', '    TEST(SIGMOID_OP,strided_batch)', '    TEST(SIGMOID_OP,strided_batch_with_qmin)', '    TEST(SIGMOID_OP,strided_batch_with_qmax)', '    TEST(SIGMOID_OP,strided_batch_with_input_scale)', '    TEST(SIGMOID_OP,strided_batch_with_input_zero_point)'];
vec256_double.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu/vec256; 335;  1; 4;12;  4; 319;0;0;0;0;0.25;0;['    Sigmoid'];['    Compute(T x)', '    GetInputQuantizationParams', '    GetOutputQuantizationParams', '    Sigmoid(double max_abs_err)'];
vml.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cpu; 200;  29; 19;76;  45; 70;35;34;28;31;0.64;27;[];['    sigmoid_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)'];
CPUGenerator.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 44;  3; 9;5;  28; 0;0;0;0;0;0.11;0;['    GetSigmoidCrossEntropyLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidCrossEntropyLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidCrossEntropyLossGradient', '    vector', '    GetGradientDefs'];
CUDABlas.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 68;  16; 11;14;  26; 4;2;22;8;11;0.62;2;['    final', '    final'];['    counts_', '    counts_', '    GetSingleArgument', '    losses_', '    RunOnDevice', '    RunOnDevice', '    SigmoidCrossEntropyLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SigmoidCrossEntropyLossOp(const OperatorDef & operator_def,Workspace *ws)'];
CUDAEvent.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 185;  28; 29;16;  113; 4;60;50;75;58;0.25;22;[];['    sigmoid_cross_entropy_with_logits_op_cpu_impl(const at::Tensor & logits_,const at::Tensor & targets_,const at::Tensor & out_,bool log_D_trick,bool unjoined_lr_loss)', '    sigmoid_partition(float lgt)', '    sigmoid_xent_forward(float lgt,float tgt)', '    sigmoid_xent_forward_with_log_d_trick(float lgt,float tgt)', '    unjoined_sigmoid_xent_forward(float lgt,float tgt)'];
CuSparseHandlePool.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 47;  13; 10;5;  21; 0;8;13;12;13;0.62;3;['    SigmoidFunctor'];['    GetOutputQuantizationParams', '    operator()(const int n,const T *x,T *y)', '    SigmoidFunctor'];
KernelUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda/detail; 31;  12; 7;5;  8; 0;3;4;5;5;1.50;1;['    GetSigmoidFocalLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFocalLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFocalLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFocalLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFocalLossGradient', '    GetGradientDefs'];
PinnedMemoryAllocator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cuda; 17;  1; 5;6;  6; 0;2;4;1;4;0.17;1;['    final', '    final'];['    counts_', '    counts_', '    GetSingleArgument', '    losses_', '    RunOnDevice', '    RunOnDevice', '    SigmoidFocalLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SigmoidFocalLossOp(const OperatorDef & operator_def,Workspace *ws)', '    weights_'];
Descriptors.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 147;  6; 16;15;  107; 4;71;34;71;33;0.06;10;['    GetSigmoidGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const T *Y,const T *dY,T *dX,CPUContext *)', '    vector'];
Handle.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 10;  1; 4;3;  3; 0;0;3;0;3;0.33;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sigmoid', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidGradient', '    operator()(const int N,const T *X,T *Y,CPUContext *)'];
Utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/cudnn; 22;  4; 4;6;  8; 0;3;4;4;4;0.50;1;['    final', '    final'];['    IDEEPSigmoidGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSigmoidOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPSigmoidGradientOp', '    ~IDEEPSigmoidOp'];
CUDAHooksInterface.h;C++;pytorch-master/pytorch-master/aten/src/ATen/detail; 171;  27; 35;11;  101; 0;0;0;0;0;0.27;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)'];
Device.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 2;  0; 0;2;  0; 0;0;0;0;0;0.00;0;[];[];
Dispatch.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 482;  70; 36;372;  17; 2;0;0;0;0;4.12;0;[];['    TEST(Sigmoid,SigmoidUnitTest)'];
dlpack.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 141;  70; 10;24;  39; 5;0;39;0;21;1.79;0;[];['    CheckForSignals', '    GotSIGHUP', '    GotSIGINT', '    SignalHandler(SignalHandler::Action SIGINT_action,SignalHandler::Action SIGHUP_action)', '    ~SignalHandler'];
ExpandUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 193;  18; 27;6;  153; 0;0;0;0;0;0.12;0;[];[];
HIPCachingAllocatorMasqueradingAsCUDA.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 17;  2; 4;2;  11; 0;2;7;2;6;0.18;2;[];['    detectHostSIMDExtensions'];
HIPStreamMasqueradingAsCUDA.h;C++;pytorch-master/pytorch-master/aten/src/ATen/hip/impl; 119;  15; 28;2;  77; 0;27;45;25;34;0.19;25;[];['    AA_op(const Tensor & self)', '    BB_op(const Tensor & self)', '    CC_op(const Tensor & self)', '    DD_op(const Tensor & self)', '    EE_op(const Tensor & self)', '    FF_op(const Tensor & self)'];
MatrixRef.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 100;  39; 18;4;  42; 0;12;22;13;15;0.93;8;[];['    call_AA_op(const Tensor & self)', '    call_BB_op(const Tensor & self)', '    call_CC_op(const Tensor & self)', '    call_DD_op(const Tensor & self)', '    call_EE_op(const Tensor & self)', '    call_FF_op(const Tensor & self)', '    singleton'];
Descriptors.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 157;  21; 20;5;  113; 0;31;36;32;35;0.19;14;[];[];
miopen-wrapper.h;C++;pytorch-master/pytorch-master/aten/src/ATen/miopen; 3;  0; 1;2;  0; 0;0;0;0;0;0.00;0;[];['    ConsumerFunction(int thread_idx)', '    ProducerFunction(int thread_idx,int start,int count)', '    TEST(SimpleQueueTest,SingleProducerSingleConsumer)', '    TEST(SimpleQueueTest,SingleProducerDoubleConsumer)', '    TEST(SimpleQueueTest,DoubleProducerDoubleConsumer)', '    TEST(SimpleQueueDeathTest,CannotAddAfterQueueFinished)'];
Descriptors.h;C++;pytorch-master/pytorch-master/aten/src/ATen/mkl; 44;  1; 8;4;  32; 0;12;9;11;9;0.03;3;['    GetSinGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSin', '    CAFFE_ANONYMOUS_VARIABLE_CPUSinGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinGradient', '    GetGradientDefs', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector'];
NamedTensorUtils.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 541;  45; 56;5;  437; 0;216;155;184;97;0.10;37;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
AdaptiveAveragePooling.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 364;  20; 37;4;  306; 0;191;101;109;53;0.07;13;[];['    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)'];
AffineGridGenerator.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 134;  1; 15;2;  117; 0;49;66;36;22;0.01;9;['    SingleOpTransform'];['    MatchOperator(const OperatorDef & op)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceOperator(OperatorDef *op)', '    ReplaceRule(const std::vector & subgraph,Graph *g_ptr)', '    ValidatorRule(const Graph &,const std::vector & subgraph)'];
BatchLinearAlgebra.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1145;  37; 81;47;  410; 585;240;127;451;152;0.09;39;['    GetSinhGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSinh', '    CAFFE_ANONYMOUS_VARIABLE_CPUSinhGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sinh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinhGradient', '    GetGradientDefs', '    Forward(const std::vector &,const std::vector & X_dims,const T *dY,const T *X,T *dX,CPUContext *)', '    vector'];
c10_utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 28;  0; 4;2;  22; 0;8;14;5;4;0.00;3;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & dY_dims,const std::vector & X_dims,const T *dY,const T *X,T *dX,Context *context)'];
Convolution.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1049;  66; 106;23;  821; 52;531;230;396;177;0.08;35;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSinusoidPositionEncoding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SinusoidPositionEncoding'];
ConvUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 97;  17; 11;1;  71; 0;44;40;23;30;0.24;5;['    SinusoidPositionEncodingOp'];['    DoRunWithType', '    GetSingleArgument', '    Input', '    RunOnDevice', '    SinusoidPositionEncodingOp(Args,...)'];
AtomicAddFloat.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 33;  0; 7;9;  17; 1;7;7;6;5;0.00;1;[];['    isStructSeq(pybind11::handle input)', '    isStructSeq(PyObject *obj)', '    isTuple(pybind11::handle input)', '    isTuple(PyObject *obj)', '    maybeAsTuple(PyStructSequence *obj)', '    maybeAsTuple(PyObject *obj)', '    handle'];
CatKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 75;  2; 11;8;  56; 1;31;30;36;29;0.04;3;[];['    isTracedZeroDimVar(PyObject *item)', '    THPSize_numel(THPSize *self,PyObject *noargs)', '    THPSize_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPSize_reduce(THPSize *self,PyObject *noargs)', '    THPSize_repr(THPSize *self)', '    wrap_tuple_fn(Args,...)', '    ret', '    THPSize_init(PyObject *module)', '    THPSize_New(const torch::autograd::Variable & var)', '    THPSize_NewFromSizes(int dim,const int64_t *sizes)'];
DepthwiseConvKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 305;  14; 20;45;  82; 193;42;50;3;26;0.17;4;[];['    THPSize_init(PyObject *module)', '    THPSize_New(const torch::autograd::Variable & var)', '    THPSize_NewFromSizes(int dim,const int64_t *sizes)'];
FillKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 47;  5; 8;7;  31; 0;19;11;54;19;0.16;2;[];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSlice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Slice', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SliceGradient', '    GetGradientDefs'];
Intrinsics.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 28;  1; 1;20;  0; 18;0;0;0;0;0.00;0;['    SliceOp', '    SliceGradientOp'];['    SliceImpl(Tensor *output,const Tensor & data,const Tensor & starts,const Tensor & ends,Context *context,Tensor *gdata,const Tensor *go)', '    DoRunWithType', '    operator=', '    RunOnDevice', '    SliceOp(Args,...)', '    SliceOp', '    itemsize', '    nbytes', '    ResizeLike', '    DoRunWithType', '    operator=', '    RunOnDevice', '    SliceGradientOp(Args,...)', '    SliceGradientOp'];
Loops.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 271;  34; 30;14;  194; 3;0;0;0;0;0.18;0;[];['    grow_pod(void *FirstEl,size_t MinSizeInBytes,size_t TSize)'];
Reduce.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 278;  38; 24;10;  210; 0;134;69;88;77;0.18;12;['    SmallVector', '    SmallVectorBase', '    SmallVectorImpl', '    SmallVectorTemplateBase', '    SmallVectorTemplateBase', '    SmallVectorTemplateCommon'];['    NextPowerOf2(uint64_t A)', '    capacity_in_bytes(const SmallVector & X)', '    operator<<(std::ostream & out,const SmallVector & list)', '    swap(c10::SmallVectorImpl & LHS,c10::SmallVectorImpl & RHS)', '    swap(c10::SmallVector & LHS,c10::SmallVector & RHS)', '    destroy_range(T *,T *)', '    destroy_range(T *S,T *E)', '    uninitialized_copy(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_copy(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_copy(T1 *Iit,T1 *Eit,T2 *Dest,std::enable_if::type *)', '    uninitialized_move(It1 Iit,It1 Eit,It2 Dest)', '    uninitialized_move(It1 Iit,It1 Eit,It2 Dest)', '    operator=(const SmallVector & RHS)', '    operator=(const Container & RHS)', '    operator=(SmallVector)', '    operator=(SmallVectorImpl)', '    operator=(Container)', '    operator=(std::initializer_list IL)', '    SmallVector', '    SmallVector(size_t Size,const T & Value)', '    SmallVector(ItTy S,ItTy E)', '    SmallVector(Container)', '    SmallVector(std::initializer_list IL)', '    SmallVector(const SmallVector & RHS)', '    SmallVector(SmallVector)', '    SmallVector(SmallVectorImpl)', '    capacity_in_bytes', '    empty', '    grow_pod(void *FirstEl,size_t MinSizeInBytes,size_t TSize)', '    size_in_bytes', '    SmallVectorBase(void *FirstEl,size_t Size)', '    append(in_iter in_start,in_iter in_end)', '    append(size_type NumInputs,const T & Elt)', '    append(std::initializer_list IL)', '    assign(size_type NumElts,const T & Elt)', '    assign(in_iter in_start,in_iter in_end)', '    assign(std::initializer_list IL)', '    clear', '    emplace_back(ArgTypes,...)', '    erase(const_iterator CIit)', '    erase(const_iterator CSit,const_iterator CEit)', '    insert(iterator Iit,T)', '    insert(iterator Iit,const T & Elt)', '    insert(iterator Iit,size_type NumToInsert,const T & Elt)', '    insert(iterator Iit,ItTy From,ItTy To)', '    insert(iterator Iit,std::initializer_list IL)', '    operator!=(const SmallVectorImpl & RHS)', '    operator<(const SmallVectorImpl & RHS)', '    operator=(const SmallVectorImpl & RHS)', '    operator=(SmallVectorImpl)', '    operator==(const SmallVectorImpl & RHS)', '    pop_back_val', '    reserve(size_type N)', '    resize(size_type N)', '    resize(size_type N,const T & NV)', '    set_size(size_type N)', '    SmallVectorImpl(unsigned N)', '    SmallVectorImpl', '    swap(SmallVectorImpl & RHS)', '    ~SmallVectorImpl', '    grow(size_t MinSize)', '    grow(size_t MinSize)', '    pop_back', '    pop_back', '    push_back(const T & Elt)', '    push_back(T)', '    push_back(const T & Elt)', '    SmallVectorTemplateBase(size_t Size)', '    SmallVectorTemplateBase(size_t Size)', '    at(size_type idx)', '    at(size_type idx)', '    back', '    back', '    begin', '    begin', '    capacity', '    capacity_ptr', '    capacity_ptr', '    data', '    data', '    end', '    end', '    front', '    front', '    grow_pod(size_t MinSizeInBytes,size_t TSize)', '    isSmall', '    max_size', '    operator[](size_type idx)', '    operator[](size_type idx)', '    rbegin', '    rbegin', '    rend', '    rend', '    resetToSmall', '    setEnd(T *P)', '    size', '    SmallVectorTemplateCommon(size_t Size)', '    bad_alloc', '    copy', '    distance', '    equal', '    fill_n', '    lexicographical_compare', '    make_move_iterator', '    move_backward', '    move_iterator', '    swap', '    uninitialized_copy', '    uninitialized_fill', '    uninitialized_fill_n'];
SoftMaxKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 275;  17; 20;9;  231; 0;169;69;93;50;0.07;9;[];[];
UnaryOpsKernel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cpu; 511;  17; 54;85;  353; 6;246;119;857;1759;0.05;33;[];['    DefaultTensorPrinter', '    PrintTensor(const Tensor & tensor)', '    DoRunWithType', '    Print', '    Print(const Tensor & tensor)', '    SmartTensorPrinter(const std::string & tensor_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)'];
Cross.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 54;  1; 10;4;  40; 0;28;12;34;12;0.03;2;['    SmartTensorPrinter'];['    DefaultTensorPrinter', '    PrintTensor(const Tensor & tensor)', '    Print(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    PrintTensorMeta(const Tensor & tensor)', '    SmartTensorPrinter(const std::string & tensor_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name)', '    SmartTensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    SmartTensorPrinter'];
CuFFTUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 74;  3; 7;10;  55; 0;44;5;45;5;0.05;2;[];['    expect_stderr_contains(const std::vector & values)', '    my_to_string(const T & value)', '    my_to_string(const std::string & value)', '    printTensorAndCheck(const std::vector & values)'];
MiscUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cuda; 69;  6; 5;8;  15; 41;8;8;1;5;0.40;1;['    GetSmoothL1LossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSmoothL1Loss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSmoothL1LossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SmoothL1Loss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SmoothL1LossGradient', '    vector', '    GetGradientDefs'];
Conv.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/cudnn; 1288;  242; 143;31;  818; 63;425;347;273;229;0.30;60;['    final', '    final'];['    buff_', '    buff_', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SmoothL1LossGradientOp(const OperatorDef & def,Workspace *ws)', '    SmoothL1LossOp(const OperatorDef & operator_def,Workspace *ws)'];
DilatedConvolutionUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 232;  31; 17;16;  172; 0;47;44;54;16;0.18;5;[];['    copyOutputTo(float *outputData)', '    snpe_copy_output_to(void *ctx,float *outputData)', '    snpe_create(const uint8_t *container,size_t size,const char *input_name)', '    snpe_destroy(void *ctx)', '    snpe_get_input_dims(void *ctx,size_t const **dims,size_t *size)', '    snpe_has_gpu', '    snpe_run(void *ctx,const float *inputData,size_t inputSize,size_t const **outputDims,size_t *outputSize)', '    getInputDims', '    SNPEContext(const std::vector & buffer,const char *input_name,bool enable_logging)'];
DispatchStub.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 204;  44; 27;58;  61; 24;30;33;29;25;0.72;5;[];['    gSNPELocation', '    snpe_copy_output_to(void *ctx,float *outputData)', '    snpe_create(const uint8_t *container,size_t size,const char *input_name)', '    snpe_destroy(void *ctx)', '    snpe_get_input_dims(void *ctx,size_t const **dims,size_t *size)', '    snpe_has_gpu', '    snpe_run(void *ctx,const float *inputData,size_t inputSize,size_t const **outputDims,size_t *outputSize)'];
Distributions.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 390;  68; 29;31;  263; 14;182;169;73;110;0.26;10;[];['    gSNPELocation'];
EmbeddingBag.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 779;  84; 88;12;  633; 0;418;327;263;188;0.13;23;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSNPE', '    RunOnDevice', '    SNPEOp(const OperatorDef & def,Workspace *ws)'];
FractionalMaxPool3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 423;  17; 50;5;  355; 0;238;127;86;57;0.05;11;[];['    main'];
Im2Col.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 213;  4; 27;7;  178; 0;107;76;44;33;0.02;6;[];['    _sobol_engine_draw(const Tensor & quasi,int64_t n,const Tensor & sobolstate,int64_t dimension,int64_t num_generated,optional dtype)', '    _sobol_engine_ff_(Tensor & quasi,int64_t n,const Tensor & sobolstate,int64_t dimension,int64_t num_generated)', '    _sobol_engine_initialize_state_(Tensor & sobolstate,int64_t dimension)', '    _sobol_engine_scramble_(Tensor & sobolstate,const Tensor & ltm,int64_t dimension)'];
Integration.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 72;  14; 10;5;  44; 0;24;18;18;16;0.32;5;[];['    bit_length(const int64_t n)', '    bitsubseq(const int64_t n,const int64_t pos,const int64_t length)', '    cdot_pow2(const at::Tensor & bmat)', '    rightmost_zero(const int64_t n)', '    options', '    size'];
LegacyBridge.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1;  0; 1;0;  0; 0;0;0;0;0;0.00;0;['    ClientSocket', '    ManagerServerSocket', '    ManagerSocket', '    Socket'];['    ClientSocket(const std::string & path)', '    register_allocation(AllocInfo & info)', '    register_deallocation(AllocInfo & info)', '    accept', '    ManagerServerSocket(const std::string & path)', '    ~ManagerServerSocket', '    confirm', '    ManagerSocket(int fd)', '    receive', '    address_length(struct sockaddr_un address)', '    prepare_address(const char *path)', '    recv(void *_buffer,size_t num_bytes)', '    send(const void *_buffer,size_t num_bytes)', '    Socket', '    Socket', '    Socket(Socket)', '    Socket(int fd)', '    ~Socket'];
Lerp.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 25;  2; 6;3;  16; 0;12;6;2;16;0.13;0;['    SoftArgMaxOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    testQ8'];
Loss.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 391;  11; 47;14;  320; 0;208;122;150;117;0.03;30;[];['    pytorch_qnnp_create_softargmax_nc_q8(size_t channels,float input_scale,uint8_t output_zero_point,float output_scale,uint32_t flags,pytorch_qnnp_operator_t *softargmax_out)', '    pytorch_qnnp_setup_softargmax_nc_q8(pytorch_qnnp_operator_t softargmax,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
LossNLL.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 397;  11; 52;5;  332; 0;180;122;122;63;0.03;10;[];['    TEST(SOFTARGMAX_OP,zero_batch)', '    TEST(SOFTARGMAX_OP,single_class)', '    TEST(SOFTARGMAX_OP,two_classes)', '    TEST(SOFTARGMAX_OP,many_classes)', '    TEST(SOFTARGMAX_OP,cifar_classes)', '    TEST(SOFTARGMAX_OP,imagenet_classes)', '    TEST(SOFTARGMAX_OP,many_channels_with_input_scale)', '    TEST(SOFTARGMAX_OP,many_channels_with_input_zero_point)', '    TEST(SOFTARGMAX_OP,small_batch)', '    TEST(SOFTARGMAX_OP,small_batch_with_input_stride)', '    TEST(SOFTARGMAX_OP,small_batch_with_output_stride)', '    TEST(SOFTARGMAX_OP,strided_batch_with_input_and_output_stride)'];
Memory.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 41;  2; 5;7;  28; 0;16;15;11;8;0.07;3;[];['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    softargmax_q8(benchmark::State & state)'];
LinearAlgebra.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkl; 101;  3; 21;19;  51; 9;30;35;24;28;0.06;4;[];['    host_softmax(Tensor output,const Tensor & input,const int64_t dim)', '    host_softmax_backward(Tensor & gI,const Tensor & grad,const Tensor & output,int64_t dim)', '    log_softmax(const Tensor & input_,const int64_t dim_)', '    log_softmax(const Tensor & input_,const int64_t dim_,c10::optional dtype)', '    log_softmax(const Tensor & self,Dimname dim,optional dtype)', '    log_softmax_backward_cpu(const Tensor & grad_,const Tensor & output_,int64_t dim_,const Tensor & input_)', '    log_softmax_cpu(const Tensor & input_,const int64_t dim_,const bool half_to_float)', '    softmax(const Tensor & input_,const int64_t dim_)', '    softmax(const Tensor & input_,const int64_t dim_,c10::optional dtype)', '    softmax(const Tensor & self,Dimname dim,optional dtype)', '    softmax_backward_cpu(const Tensor & grad_,const Tensor & output_,int64_t dim_,const Tensor & input_)', '    softmax_cpu(const Tensor & input_,const int64_t dim_,const bool half_to_float)', '    grad_arg', '    grad_arg', '    result', '    result', '    result', '    result'];
IDeepRegistration.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 21;  1; 1;5;  0; 16;0;0;0;0;0.00;0;[];['    mkldnn_softmax(const Tensor & self,const int64_t dim,const bool half_to_float)'];
MKLDNNConversions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 110;  1; 7;8;  16; 79;3;10;12;5;0.06;3;['    GetSoftmaxFocalLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxFocalLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxFocalLossGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxFocalLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxFocalLossGradient', '    vector', '    GetGradientDefs'];
Relu.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 43;  4; 8;7;  15; 13;8;7;4;7;0.27;2;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SoftmaxFocalLossGradientOp(const OperatorDef & def,Workspace *ws)', '    SoftmaxFocalLossOp(const OperatorDef & operator_def,Workspace *ws)'];
TensorShape.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/mkldnn; 13;  2; 5;2;  6; 0;0;6;0;4;0.33;0;['    GetSoftmaxGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softmax', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
NaiveConvolutionTranspose2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 914;  62; 109;5;  744; 0;508;205;202;109;0.08;8;['    final', '    final'];['    RunOnDevice', '    SoftmaxGradientOp(Args,...)', '    SoftmaxOp(Args,...)'];
NNPACK.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 602;  52; 70;14;  424; 53;318;142;129;79;0.12;15;['    final', '    final'];['    CuDNNSoftmaxGradientOp(Args,...)', '    CuDNNSoftmaxOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    ~CuDNNSoftmaxGradientOp', '    ~CuDNNSoftmaxOp'];
PixelShuffle.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 34;  2; 6;5;  23; 0;13;13;9;12;0.09;1;[];['    SoftmaxCPU(const int N,const int D,const bool logarithmic,const float *X,float *Y,float *scratch,CPUContext *context)'];
Pooling.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 152;  2; 22;6;  124; 0;62;63;37;18;0.02;8;[];['    SoftmaxCPU(int N,int D,bool logarithmic,const T *X,T *Y,T *scratch,CPUContext *context)'];
Copy.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;['    GetSoftmaxWithLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxWithLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftmaxWithLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxWithLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftmaxWithLossGradient', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
init_qnnpack.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 13;  0; 1;3;  0; 9;0;0;0;0;0.00;0;['    final', '    final'];['    RunOnDevice', '    scratch_', '    scratch_', '    SoftmaxWithLossGradientOp(Args,...)', '    SoftmaxWithLossOp(Args,...)', '    sum_multiplier_'];
q_avgpool3d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 212;  4; 17;13;  181; 0;101;112;45;51;0.02;6;[];['    log_softmax_backward_lastdim_kernel_impl(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    log_softmax_lastdim_kernel_impl(Tensor & result,const Tensor & self)', '    softmax_backward_lastdim_kernel_impl(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    softmax_lastdim_kernel_impl(Tensor & result,const Tensor & self)', '    _vec_host_softmax_backward_lastdim(scalar_t *grad_input_data_base,scalar_t *grad_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    _vec_log_softmax_lastdim(scalar_t *input_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    _vec_softmax_lastdim(scalar_t *input_data_base,scalar_t *output_data_base,int64_t outer_size,int64_t dim_size)', '    apply(Tensor & grad_input,const Tensor & grad,const Tensor & output)', '    apply(Tensor & output,const Tensor & input)'];
qconcat.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 154;  9; 15;9;  126; 0;74;69;61;41;0.07;7;[];['    log_softmax_backward_lastdim_kernel', '    log_softmax_backward_lastdim_kernel', '    operator=', '    log_softmax_lastdim_kernel', '    log_softmax_lastdim_kernel', '    operator=', '    operator=', '    softmax_backward_lastdim_kernel', '    softmax_backward_lastdim_kernel', '    operator=', '    softmax_lastdim_kernel', '    softmax_lastdim_kernel'];
qelu.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 36;  2; 6;5;  24; 0;4;17;4;12;0.08;3;['    GetSoftplusGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSoftplus', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftplusGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softplus', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftplusGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
qlinear_dynamic.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 415;  12; 7;21;  41; 343;17;29;4;9;0.29;2;['    final', '    final'];['    RunOnDevice', '    SoftplusGradientOp(Args,...)', '    SoftplusOp(Args,...)', '    ~SoftplusGradientOp', '    ~SoftplusOp'];
add.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 172;  33; 27;9;  129; 0;107;27;49;30;0.26;3;['    GetSoftsignGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPU__VA_ARGS__', '    CAFFE_ANONYMOUS_VARIABLE_CPUSoftsign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Softsign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SoftsignGradient', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector'];
global-average-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 99;  14; 17;12;  62; 0;51;15;22;16;0.23;2;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
requantization.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 379;  39; 25;18;  149; 180;97;38;33;35;0.26;17;[];['    kthvalue_out_impl_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool keepdim)', '    kthvalue(const Tensor & self,int64_t k,int64_t dim,bool keepdim)', '    kthvalue(const Tensor & self,int64_t k,Dimname dim,bool keepdim)', '    kthvalue_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,Dimname dim,bool keepdim)', '    kthvalue_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool keepdim)', '    median(const Tensor & self,int64_t dim,bool keepdim)', '    median(const Tensor & self,Dimname dim,bool keepdim)', '    median_cpu(const Tensor & self)', '    median_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim,bool keepdim)', '    median_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    quick_select_template(TensorAccessor arr,int64_t k,Comp gt_or_nan,Fn swap_fn)', '    topk(const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)', '    topk_out_cpu(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim_,bool largest,bool sorted)', '    result'];
tanh.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/bench; 99;  17; 17;9;  66; 0;53;16;27;17;0.26;2;[];['    operator=', '    topk_stub', '    topk_stub'];
conv_utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/include; 194;  10; 19;8;  163; 0;110;49;32;25;0.06;1;[];['    topk_kernel(Tensor & values,Tensor & indices,const Tensor & self,int64_t k,int64_t dim,bool largest,bool sorted)'];
average-pooling.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 298;  9; 37;14;  238; 0;182;59;96;24;0.04;3;[];['    _allocate_or_resize_output_with_indices(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim_,int64_t k)', '    _reduction_with_indices_allocate_or_resize_output(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim_,bool keepdim)', '    dim_apply(TensorList tensors,int64_t dim,Fn f)'];
conv-run.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 690;  9; 36;11;  640; 2;465;356;98;186;0.01;10;[];['    highlight(std::ostream & out)', '    print_with_context(std::ostream & out,size_t context,bool highlight,const std::string & funcname)', '    format_stack_trace(std::ostream & out,const std::vector & entries)', '    findSourceRangeThatGenerated(const SourceRange & range)'];
fc-prepack.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 54;  1; 5;5;  44; 0;32;13;11;6;0.02;1;[];[];
8x8-neonfp16arith.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/hgemm; 370;  7; 24;2;  337; 0;292;73;206;54;0.02;1;['    SourceRangeDeserializer', '    SourceRangeSerializer'];['    row_elems', '    ConcreteSourceRangeUnpickler(at::DataPtr,size_t size)', '    findSourceRangeThatGenerated(const SourceRange & range)', '    unpickle', '    deserialize(const c10::IValue & iv)', '    deserialize_source(const c10::IValue & iv)', '    pickle(const SourceRangeRecords & ranges)', '    SourceRangePickler', '    serialize(const SourceRange & sr)', '    serialize_source(const std::shared_ptr & s)'];
max-pooling.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 243;  9; 31;14;  189; 0;141;54;75;18;0.05;3;['    SourceRangePickler', '    SourceRangeUnpickler'];['    pickle(const SourceRangeRecords & ranges)', '    SourceRangePickler', '    findSourceRangeThatGenerated(const SourceRange & range)', '    ~SourceRangeUnpickler'];
mp8x9p8q-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 562;  7; 67;3;  485; 0;451;324;122;240;0.01;1;['    ConcreteSourceRangeUnpickler'];['    ConcreteSourceRangeUnpickler(at::DataPtr,size_t size)', '    findSourceRangeThatGenerated(const SourceRange & range)', '    unpickle'];
up8xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool; 148;  7; 19;3;  119; 0;101;67;35;34;0.06;1;['    GetSpaceToBatchGradient', '    GetBatchToSpaceGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBatchToSpace', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpaceToBatch', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BatchToSpace', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpaceToBatch', '    vector', '    vector', '    GetGradientDefs', '    GetGradientDefs'];
mp8x25-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv; 908;  7; 79;8;  810; 4;783;451;255;295;0.01;1;['    final', '    final', '    SpaceBatchOpBase'];['    batchToSpace(const Tensor & input,int pad_t,int pad_l,int block_size,Tensor *output,Context *)', '    spaceToBatch(const Tensor & input,int pad_t,int pad_l,int block_size,Tensor *output,Context *)', '    RunOnDevice', '    RunOnDevice', '    GetSingleArgument', '    SpaceBatchOpBase(Args,...)', '    dim', '    dim32'];
mp8x7p7q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 395;  9; 36;18;  282; 50;258;150;121;101;0.03;1;['    SparseBitVector', '    SparseBitVectorIterator'];['    begin', '    count', '    find_first', '    find_last', '    find_next(unsigned Curr)', '    intersects(const SparseBitVectorElement & RHS)', '    intersectWith(const SparseBitVectorElement & RHS,bool & BecameZero)', '    intersectWithComplement(const SparseBitVectorElement & RHS,bool & BecameZero)', '    intersectWithComplement(const SparseBitVectorElement & RHS1,const SparseBitVectorElement & RHS2,bool & BecameZero)', '    reset(unsigned Idx)', '    test(unsigned Idx)', '    test_and_set(unsigned Idx)', '    unionWith(const SparseBitVectorElement & RHS)', '    contains(const SparseBitVector & RHS)', '    count', '    empty', '    end', '    find_first', '    find_last', '    intersects(const SparseBitVector *RHS)', '    intersects(const SparseBitVector & RHS)', '    intersectWithComplement(const SparseBitVector & RHS)', '    intersectWithComplement(const SparseBitVector *RHS)', '    intersectWithComplement(const SparseBitVector & RHS1,const SparseBitVector & RHS2)', '    intersectWithComplement(const SparseBitVector *RHS1,const SparseBitVector *RHS2)', '    operator!=(const SparseBitVector & RHS)', '    operator&(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator&=(const SparseBitVector & RHS)', '    operator&=(SparseBitVector *LHS,const SparseBitVector & RHS)', '    operator&=(SparseBitVector & LHS,const SparseBitVector *RHS)', '    operator-(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator-=(const SparseBitVector & RHS)', '    operator<<(std::ostream & stream,const SparseBitVector & vec)', '    operator==(const SparseBitVector & RHS)', '    operator|(const SparseBitVector & LHS,const SparseBitVector & RHS)', '    operator|=(const SparseBitVector & RHS)', '    operator|=(SparseBitVector & LHS,const SparseBitVector *RHS)', '    operator|=(SparseBitVector *LHS,const SparseBitVector & RHS)', '    test_and_set(unsigned Idx)', '    empty', '    index', '    operator!=(const SparseBitVectorElement & RHS)', '    operator==(const SparseBitVectorElement & RHS)', '    SparseBitVectorElement', '    SparseBitVectorElement(unsigned Idx)', '    word(unsigned Idx)', '    clear', '    FindLowerBound(unsigned ElementIndex)', '    FindLowerBoundConst(unsigned ElementIndex)', '    FindLowerBoundImpl(unsigned ElementIndex)', '    intersectWithComplement', '    operator&=', '    operator=(const SparseBitVector & RHS)', '    operator=(SparseBitVector)', '    operator|=', '    reset(unsigned Idx)', '    SparseBitVector', '    SparseBitVector(const SparseBitVector & RHS)', '    SparseBitVector(SparseBitVector)', '    AdvanceToFirstNonZero', '    AdvanceToNextNonZero', '    operator!=(const SparseBitVectorIterator & RHS)', '    operator*', '    operator++', '    operator++(int)', '    operator==(const SparseBitVectorIterator & RHS)', '    SparseBitVectorIterator', '    SparseBitVectorIterator(const SparseBitVector *RHS,bool end)', '    test(unsigned Idx)', '    find_first', '    find_last', '    index'];
up8xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool; 161;  7; 16;12;  100; 26;82;50;37;29;0.07;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseDropoutWithReplacement', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseDropoutWithReplacement', '    RunOnDevice'];
4x4c2-dq-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 304;  7; 30;3;  264; 0;237;89;84;56;0.03;1;['    final'];['    GetSingleArgument', '    RunOnDevice', '    SparseDropoutWithReplacementOp(Args,...)'];
4x8c2-xzp-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm; 543;  15; 38;5;  472; 13;445;102;191;65;0.03;1;['    GetSparseFunHashGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFunHash', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseFunHashGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFunHash', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseFunHashGradient', '    vector', '    GetGradientDefs'];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8vadd; 224;  18; 30;4;  172; 0;157;106;35;56;0.10;1;['    SparseFunHashGradientOp', '    SparseFunHashOp'];['    RunOnDevice', '    SparseFunHashGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    SparseFunHashOp(const OperatorDef & operator_def,Workspace *ws)'];
hgemm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 37;  8; 7;19;  4; 0;0;4;0;2;2.00;0;[];['    sparse_lengths_sum_op_cpu(const at::Tensor & dataInput,const at::Tensor & indicesInput,const at::Tensor & lengthsInput,const at::Tensor & output)', '    sparse_lengths_sum_op_cpu_impl(const at::Tensor & dataInput,const at::Tensor & indicesInput,const at::Tensor & lengthsInput,const at::Tensor & output)', '    sparse_lengths_sum_op_cpu_impl_(const at::Tensor & dataInput_,const at::Tensor & indicesInput_,const at::Tensor & lengthsInput_,const at::Tensor & output_)'];
math.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 35;  7; 7;6;  15; 0;5;5;5;5;0.47;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseMatrixReshape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseMatrixReshape'];
q8avgpool.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 58;  7; 9;34;  6; 2;0;6;0;6;1.17;0;['    SparseMatrixReshapeOp'];['    RunOnDevice', '    SparseMatrixReshapeOp(const OperatorDef & operator_def,Workspace *ws)'];
q8gemm.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 90;  8; 14;45;  24; 0;0;24;0;16;0.33;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseNormalize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseNormalize', '    RunOnDevice'];
scalar-utils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 119;  23; 15;37;  40; 24;25;22;11;15;0.57;3;['    final'];['    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SparseNormalizeOp(Args,...)'];
u8clamp.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 33;  7; 7;15;  2; 2;0;2;0;2;3.50;0;['    GetSparseToDenseMaskGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDenseMask', '    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDenseMaskGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDenseMask', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDenseMaskGradient', '    GetGradientDefs'];
x8lut.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/qnnpack; 29;  7; 7;12;  1; 2;0;1;0;1;7.00;0;['    SparseToDenseMaskBase', '    SparseToDenseMaskGradientOp', '    SparseToDenseMaskOp'];['    getFeatureIdx(int64_t id)', '    GetRepeatedArgument', '    SparseToDenseMaskBase(Args,...)', '    DoRunWithType', '    RunOnDevice', '    SparseToDenseMaskGradientOp(Args,...)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SparseToDenseMaskOp(Args,...)'];
fp32-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 121;  7; 15;5;  94; 0;74;70;22;44;0.07;2;['    GetSparseToDenseGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseToDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseToDense', '    vector', '    GetGradientDefs'];
gemmlowp-scalar.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 48;  25; 6;3;  14; 0;10;10;2;8;1.79;2;['    final'];['    DoRunWithOtherType2', '    DoRunWithType', '    DoRunWithType2', '    GetOutputFirstDim(const TInd *sparse_indices_vec,const int32_t sparse_indices_len)', '    GetSingleArgument', '    max_element_host_', '    RunOnDevice', '    scratch_', '    SparseToDenseOp(Args,...)'];
gemmlowp-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 73;  9; 12;6;  47; 0;37;38;8;25;0.19;1;[];['    sparse_mask_cuda(const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cuda(SparseTensor & r,const Tensor & t,const SparseTensor & mask)'];
precise-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 164;  24; 18;5;  117; 0;107;106;10;59;0.21;1;[];['    expand_values_if_needed(const Tensor & values)', '    _coalesced_sparse_(SparseTensor & self,bool coalesced)', '    _indices_sparse(const SparseTensor & self)', '    _is_same_size_as_sparse(const SparseTensor & self,const SparseTensor & src)', '    _nnz_sparse(const SparseTensor & self)', '    _sparse_coo_tensor_unsafe(const Tensor & indices,const Tensor & values_,ArrayRef size,const TensorOptions & options)', '    _values_sparse(const SparseTensor & self)', '    clone_sparse(const SparseTensor & self,c10::optional optional_memory_format)', '    coalesce_sparse_cpu(const SparseTensor & self)', '    copy_sparse_(SparseTensor & self,const SparseTensor & src,bool non_blocking)', '    dense_dim_sparse(const SparseTensor & self)', '    dense_to_sparse(const Tensor & self)', '    dense_to_sparse(const Tensor & self,int64_t sparse_dim)', '    empty_sparse(IntArrayRef size,const TensorOptions & options,c10::optional optional_memory_format)', '    indices_sparse(const Tensor & self)', '    is_coalesced_sparse(const SparseTensor & self)', '    new_sparse(const TensorOptions & options)', '    new_with_dims_and_tensor_sparse(int64_t sparse_dim,int64_t dense_dim,ArrayRef size,const LongTensor & indices,const Tensor & values,const TensorOptions & options)', '    new_with_dims_sparse(int64_t sparse_dim,int64_t dense_dim,ArrayRef size,const TensorOptions & options)', '    resize_as_sparse_(SparseTensor & self,const SparseTensor & src)', '    sparse_coo_tensor(const Tensor & indices,const Tensor & values_,const TensorOptions & options)', '    sparse_coo_tensor(const Tensor & indices,const Tensor & values_,ArrayRef size,const TensorOptions & options)', '    sparse_coo_tensor(ArrayRef size,const TensorOptions & options)', '    sparse_dim_sparse(const SparseTensor & self)', '    sparse_mask_cpu(const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cpu(SparseTensor & r,const Tensor & t,const SparseTensor & mask)', '    sparse_mask_out_cpu_kernel(Tensor & r_values,const Tensor & t,const int64_t r_nnz,const int64_t sparse_dim,const LongTensor & mask_indices)', '    sparse_resize_(SparseTensor & self,ArrayRef size,int64_t sparse_dim,int64_t dense_dim)', '    sparse_resize_and_clear_(SparseTensor & self,ArrayRef size,int64_t sparse_dim,int64_t dense_dim)', '    sparse_to_dense(const SparseTensor & self)', '    values_sparse(const Tensor & self)'];
q31-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 163;  66; 14;5;  78; 0;68;62;15;37;0.85;1;[];['    sparseTensorSetToDeviceType(DispatchKeySet key_set)', '    dim', '    has_storage', '    is_contiguous(at::MemoryFormat memory_format)', '    set_indices_and_values_unsafe(const Tensor & indices,const Tensor & values)', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,at::Tensor indices,at::Tensor values)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides'];
runtime-assembly.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization; 29;  8; 3;9;  3; 10;0;0;0;1;2.67;0;[];['    copy_tensor_metadata(const SparseTensorImpl *src_sparse_impl,SparseTensorImpl *dest_sparse_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    coalesced', '    dense_dim', '    dim', '    has_storage', '    indices', '    is_contiguous(at::MemoryFormat memory_format)', '    nnz', '    raw_resize_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    resize_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    resize_and_clear_(int64_t sparse_dim,int64_t dense_dim,IntArrayRef size)', '    set_coalesced(bool coalesced)', '    set_indices_and_values_unsafe(const Tensor & indices,const Tensor & values)', '    set_nnz_and_narrow(int64_t new_nnz)', '    set_size(int64_t dim,int64_t new_size)', '    set_storage_offset(int64_t storage_offset)', '    set_stride(int64_t dim,int64_t new_stride)', '    shallow_copy_and_detach(const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    shallow_copy_from(const c10::intrusive_ptr & impl)', '    sparse_dim', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type)', '    SparseTensorImpl(at::DispatchKeySet key_set,const caffe2::TypeMeta & data_type,at::Tensor indices,at::Tensor values)', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    values', '    narrow', '    options', '    resize_', '    size', '    copy_tensor_metadata'];
up4x9-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/sdwconv; 156;  7; 30;2;  117; 0;104;63;51;54;0.06;1;[];['    coalesce_(SparseTensor & tensor)', '    wrapped_scalar_tensor(Scalar s)', '    _sparse_addmm(const Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    _sparse_mm(const SparseTensor & sparse,const Tensor & dense)', '    _sparse_mm_out(SparseTensor & result,const SparseTensor & sparse,const Tensor & dense)', '    _sparse_sum(const SparseTensor & input)', '    _sparse_sum(const SparseTensor & input,ScalarType dtype)', '    _sparse_sum(const SparseTensor & input,IntArrayRef dims_to_sum,ScalarType dtype)', '    _sparse_sum(const SparseTensor & input,IntArrayRef dims_to_sum)', '    _sparse_sum_backward_cpu(const Tensor & grad_,const SparseTensor & input_,IntArrayRef dims_to_sum)', '    _sspaddmm_out_cpu(SparseTensor & r,const SparseTensor & t,const SparseTensor & sparse_,const Tensor & dense,Scalar beta,Scalar alpha)', '    _sspaddmm_out_only_sparse(Tensor & result,const Tensor & self,const Tensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    any_sparse(const Tensor & self)', '    addmm_sparse_dense_cpu(const Tensor & self,const SparseTensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    _to_csr(const int64_t *indices,int64_t dim,int64_t nnz)', '    add_dense_sparse_worker_cpu(Tensor & r,Scalar value,const SparseTensor & sparse,const Tensor & indices,const Tensor & values)', '    add_out_dense_sparse_cpu(Tensor & r,const Tensor & dense,const SparseTensor & sparse_,Scalar value)', '    add_out_sparse_contiguous(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value,ScalarType commonDtype)', '    add_out_sparse_cpu(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value)', '    add_out_sparse_non_contiguous(SparseTensor & r,const SparseTensor & t,const SparseTensor & src,Scalar value,ScalarType commonDtype)', '    add_sparse(const Tensor & self,const Tensor & other,Scalar alpha)', '    add_sparse_(Tensor & self,const Tensor & other,Scalar alpha)', '    addmm_out_sparse_dense_cpu(Tensor & result,const Tensor & self,const SparseTensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)', '    div_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    div_out_sparse_zerodim(SparseTensor & r,const SparseTensor & t,const Tensor & value)', '    div_sparse(const Tensor & self,const Tensor & value)', '    div_sparse_(Tensor & self,const Tensor & value)', '    floor_divide_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    floor_divide_out_sparse_zerodim(SparseTensor & result,const SparseTensor & dividend,const Tensor & divisor)', '    floor_divide_sparse(const Tensor & self,const Tensor & value)', '    floor_divide_sparse_(Tensor & self,const Tensor & value)', '    log1p_out_sparse(SparseTensor & r,const SparseTensor & t)', '    log1p_sparse_(SparseTensor & t)', '    mul_out_sparse_cpu(SparseTensor & r,const Tensor & t_,const Tensor & src_)', '    mul_out_sparse_scalar(SparseTensor & r,const SparseTensor & t,Scalar value)', '    mul_out_sparse_zerodim(SparseTensor & r,const SparseTensor & t,const Tensor & value)', '    mul_sparse(const Tensor & self,const Tensor & other)', '    mul_sparse_(Tensor & self,const Tensor & other)', '    norm_sparse(const SparseTensor & self,Scalar value)', '    pow_out_sparse_scalar(SparseTensor & r,const SparseTensor & t_,Scalar value)', '    pow_sparse_scalar(const SparseTensor & t,Scalar value)', '    s_addmm_out_sparse_dense_cpu(Tensor & r,const Tensor & t,const SparseTensor & sparse_,const Tensor & dense,Scalar beta,Scalar alpha)', '    s_addmm_out_sparse_dense_worker(int64_t nnz,int64_t dim_i,int64_t dim_j,int64_t dim_k,Tensor & r,Scalar beta,const Tensor & t,Scalar alpha,const Tensor & indices,const Tensor & values,const Tensor & dense)', '    sub_out_sparse(Tensor & r,const Tensor & self,const Tensor & other,Scalar alpha)', '    sub_sparse(const Tensor & self,const Tensor & other,Scalar alpha)', '    sub_sparse_(Tensor & self,const Tensor & other,Scalar alpha)', '    true_divide_out_sparse_scalar(SparseTensor & result,const SparseTensor & dividend,Scalar divisor)', '    true_divide_out_sparse_zerodim(SparseTensor & result,const SparseTensor & dividend,const Tensor & divisor)', '    true_divide_sparse(const Tensor & self,const Tensor & value)', '    true_divide_sparse_(Tensor & self,const Tensor & divisor)', '    zero_sparse_(SparseTensor & self)', '    s_addmm_sparse_dense_cpu(const Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    hspmm_out_sparse_cpu(SparseTensor & r,const SparseTensor & sparse_,const Tensor & dense)', '    hspmm_sparse_cpu(const SparseTensor & sparse,const Tensor & dense)', '    index_preamble', '    isnan_sparse(const Tensor & self)', '    s_addmm_sparse_dense_cpu_(Tensor & t,const SparseTensor & sparse,const Tensor & dense,Scalar beta,Scalar alpha)', '    smm(const Tensor & self,const Tensor & mat2)', '    sspaddmm(const Tensor & self,const Tensor & mat1,const Tensor & mat2,Scalar beta,Scalar alpha)'];
sigmoid.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src; 159;  8; 24;8;  119; 0;85;28;58;10;0.07;2;[];['    mul_out_sparse_scalar(sparse::SparseTensor & r,const sparse::SparseTensor & t,Scalar value)', '    mul_out_sparse_zerodim(sparse::SparseTensor & r,const sparse::SparseTensor & t,const Tensor & value)'];
sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8clamp; 81;  7; 9;3;  62; 0;51;27;28;17;0.11;1;[];['    alias_into_sparse(const SparseTensor & self,const LongTensor & indices,const Tensor & values)', '    copy_into_sparse(const SparseTensor & self,const LongTensor & indices,const Tensor & values,bool non_blocking)', '    flatten_indices(const Tensor & indices,IntArrayRef full_size,bool force_clone)', '    flatten_indices_by_dims(const LongTensor & indices,const IntArrayRef & sizes,const IntArrayRef & dims_to_flatten)', '    get_sparse_impl(const SparseTensor & self)', '    is_same_density(const SparseTensor & self,const SparseTensor & src)', '    is_same_tensor(const Tensor & lhs,const Tensor & rhs)', '    new_values_with_size_of(const Tensor & values,int64_t nnz)', '    variable_excluded_from_dispatch', '    device', '    mul', '    sizes', '    squeeze', '    to', '    unsafeGetTensorImpl'];
sub16-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool; 91;  7; 9;3;  72; 0;54;16;41;8;0.10;1;[];['    registerer', '    $extra_cuda_headers', '    $'];
scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8lut; 47;  7; 8;2;  30; 0;22;15;12;11;0.23;1;[];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SpatialBN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Int8SpatialBNRelu', '    RunOnDevice', '    SpatialBNDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)'];
x3-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 205;  67; 14;2;  122; 0;118;96;20;41;0.55;1;['    final'];['    SpatialBNNHWCAVX2(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const T *X,const float *alpha,const float *beta,T *Y,bool relu_fused)', '    ComputeFusedParam_(const int C,const float *scale,const float *bias,const float *mean,const float *var,float *alpha,float *beta)', '    RunOnDevice', '    SpatialBNDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ~SpatialBNDNNLowPOp'];
xm-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip; 208;  7; 13;2;  186; 0;170;54;120;46;0.04;1;[];['    SpatialBNNHWCAVX2(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const uint8_t *X,const float *alpha,const float *beta,uint8_t *Y,bool relu_fused)', '    SpatialBNNHWCAVX2_uint8(const int N,const int C,const int HxW,const int in_zero_point,const int out_zero_point,const uint8_t *X,const float *alpha,const float *beta,uint8_t *Y)'];
average-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1512;  7; 60;3;  1442; 0;1172;213;405;185;0.00;57;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNFakeFp16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNFakeLoweredFp16NNPI'];
clamp-microkernel-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 118;  11; 20;10;  77; 0;47;25;35;24;0.14;16;['    SpatialBNFakeFp16Op', '    SpatialBNFakeLoweredFp16Op'];['    GetDeviceType', '    AffineChannel_NCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,float *Y)', '    ComputeFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *alpha,T *beta)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNFakeFp16Op(Args,...)', '    ~SpatialBNFakeFp16Op', '    AffineChannel_NCHW(const int N,const int C,const int HxW,const float *X,const float *scale,const float *bias,const float *mean,float *Y)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    SpatialBNFakeLoweredFp16Op(Args,...)', '    ~SpatialBNFakeLoweredFp16Op'];
convolution.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 648;  7; 58;3;  580; 0;462;55;71;55;0.01;55;['    GetSpatialBNGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBNGradient', '    GetGradientDefs', '    ComputeMultiBatchScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *scale,const T *mean,const T *rstd,const T *dscale_sum,const T *dbias_sum,T *dscale,T *dbias,T *alpha,T *beta,T *gamma)', '    ComputeScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *dY,const T *X,const T *scale,const T *mean,const T *rstd,T *dscale,T *dbias,T *alpha,T *beta,T *gamma,T *)', '    ComputeXGradient(const int N,const int C,const int HxW,const T *dY,const T *X,const T *alpha,const T *beta,const T *gamma,T *dX)'];
fully-connected-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 357;  32; 43;12;  289; 0;222;117;96;56;0.11;25;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBN', '    CostInferenceForSpatialBN(const OperatorDef & def,const vector & in)'];
global-average-pooling-operator-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 253;  11; 37;9;  197; 0;133;52;82;49;0.06;37;['    final', '    final'];['    IDEEPSpatialBNGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPSpatialBNOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    ~IDEEPSpatialBNGradientOp', '    ~IDEEPSpatialBNOp'];
leaky-relu.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 161;  7; 15;2;  137; 0;94;30;47;30;0.05;13;['    SpatialBNGradientOp', '    SpatialBNOp'];['    ComputeMultiBatchScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *scale,const T *mean,const T *rstd,const T *dscale_sum,const T *dbias_sum,T *dscale,T *dbias,T *alpha,T *beta,T *gamma)', '    ComputeScaleBiasGradientsAndFusedParams(const int N,const int C,const int HxW,const T *dY,const T *X,const T *scale,const T *mean,const T *rstd,T *dscale,T *dbias,T *alpha,T *beta,T *gamma,T *)', '    ComputeXGradient(const int N,const int C,const int HxW,const T *dY,const T *X,const T *alpha,const T *beta,const T *gamma,T *dX)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNGradientOp(Args,...)', '    ~SpatialBNGradientOp', '    ComputeBatchMoments(const int N,const int C,const int HxW,const T *batch_mean_sum,const T *batch_var_sum,T *mean,T *var)', '    ComputeFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *alpha,T *beta)', '    ComputeRunningMomentsAndFusedParam(const int C,const T *scale,const T *bias,const T *mean,const T *var,T *running_mean,T *running_var,T *rstd,T *alpha,T *beta)', '    DoRunWithType', '    RunOnDevice', '    SpatialBNOp(Args,...)', '    ~SpatialBNOp'];
max-pooling.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1215;  7; 54;3;  1151; 0;947;153;329;153;0.01;51;['    SpatialBNReluOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialBNRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialBNRelu', '    RunOnDevice', '    SpatialBNReluOp(const OperatorDef & operator_def,Workspace *ws)'];
q8dwconv.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 1267;  10; 6;11;  0; 1243;0;0;0;0;0.00;0;['    SpatialNarrowAsGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialNarrowAs', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialNarrowAsGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialNarrowAs', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialNarrowAsGradient', '    vector', '    GetGradientDefs'];
requantization-tester.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 470;  47; 56;12;  359; 0;280;107;146;76;0.13;26;['    final', '    final'];['    DoRunWithType', '    RunOnDevice', '    RunOnDevice', '    SpatialNarrowAsGradientOp(const OperatorDef & def,Workspace *ws)', '    SpatialNarrowAsOp(const OperatorDef & operator_def,Workspace *ws)'];
sgemm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 502;  7; 17;7;  140; 331;102;25;37;25;0.05;13;['    GetSoftmaxWithLossGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialSoftmaxWithLoss', '    CAFFE_ANONYMOUS_VARIABLE_CPUSpatialSoftmaxWithLossGradient', '    blob_names', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialSoftmaxWithLoss', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SpatialSoftmaxWithLossGradient', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
softargmax.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 135;  12; 15;3;  105; 0;72;21;33;21;0.11;12;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    scratch_', '    scratch_', '    SpatialSoftmaxWithLossGradientOp(Args,...)', '    SpatialSoftmaxWithLossOp(Args,...)'];
u8lut32norm.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 48;  7; 9;3;  29; 0;13;10;14;10;0.24;6;['    State'];['    specializeAutogradZero(Graph & g)'];
x8lut.cc;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/test; 45;  7; 9;3;  26; 0;10;10;14;10;0.27;6;[];['    specializeAutogradZero(Graph & g)'];
mp8x9p8q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    _fft_fill_with_conjugate_symmetry_(Tensor & input,int64_t signal_ndim,int64_t size_last_dim,int64_t last_dim_start_slice)', '    _fft_fill_with_conjugate_symmetry_slice(Tensor & output,int64_t signal_ndim,int64_t size_last_dim,int64_t start_last_dim_idx,int64_t i,int64_t num)', '    _fft_mkl(const Tensor & self,int64_t signal_ndim,bool complex_input,bool complex_output,bool inverse,IntArrayRef checked_signal_sizes,bool normalized,bool onesided,IntArrayRef output_sizes)'];
up8xm-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    _fft(const Tensor & self,const int64_t signal_ndim,const bool complex_input,const bool complex_output,const bool inverse,IntArrayRef signal_sizes,const bool normalized,const bool onesided)', '    _cufft_clear_plan_cache(int64_t device_index)', '    _cufft_get_plan_cache_max_size(int64_t device_index)', '    _cufft_get_plan_cache_size(int64_t device_index)', '    _cufft_set_plan_cache_max_size(int64_t device_index,int64_t max_size)', '    fft(const Tensor & self,const int64_t signal_ndim,const bool normalized)', '    ifft(const Tensor & self,const int64_t signal_ndim,const bool normalized)', '    irfft(const Tensor & self,const int64_t signal_ndim,const bool normalized,const bool onesided,IntArrayRef signal_sizes)', '    rfft(const Tensor & self,const int64_t signal_ndim,const bool normalized,const bool onesided)', '    stft(const Tensor & self,const int64_t n_fft,const optional hop_lengthOpt,const optional win_lengthOpt,const Tensor & window,const bool normalized,const bool onesided)'];
8x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    infer_ft_complex_to_real_onesided_size(int64_t complex_size,int64_t expected_size)', '    infer_ft_real_to_complex_onesided_size(int64_t real_size)'];
up8x9-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    C10FlagParser_algo', '    C10FlagParser_engine', '    C10FlagParser_force_algo', '    C10FlagParser_force_engine', '    C10FlagParser_init_net', '    C10FlagParser_input', '    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_net', '    C10FlagParser_opt', '    C10FlagParser_output', '    C10FlagParser_output_folder', '    C10FlagParser_run_individual', '    C10FlagParser_warmup'];['    main(int argc,char **argv)', '    C10FlagParser_algo(const std::string & content)', '    C10FlagParser_engine(const std::string & content)', '    C10FlagParser_force_algo(const std::string & content)', '    C10FlagParser_force_engine(const std::string & content)', '    C10FlagParser_init_net(const std::string & content)', '    C10FlagParser_input(const std::string & content)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_net(const std::string & content)', '    C10FlagParser_opt(const std::string & content)', '    C10FlagParser_output(const std::string & content)', '    C10FlagParser_output_folder(const std::string & content)', '    C10FlagParser_run_individual(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)'];
up8x7-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    C10FlagParser_input_dims', '    C10FlagParser_input_file', '    C10FlagParser_input_type', '    C10FlagParser_iter', '    C10FlagParser_model', '    C10FlagParser_print_output', '    C10FlagParser_pytext_len', '    C10FlagParser_report_pep', '    C10FlagParser_warmup'];['    main(int argc,char **argv)', '    split(char separator,const std::string & string,bool ignore_empty)', '    C10FlagParser_input_dims(const std::string & content)', '    C10FlagParser_input_file(const std::string & content)', '    C10FlagParser_input_type(const std::string & content)', '    C10FlagParser_iter(const std::string & content)', '    C10FlagParser_model(const std::string & content)', '    C10FlagParser_print_output(const std::string & content)', '    C10FlagParser_pytext_len(const std::string & content)', '    C10FlagParser_report_pep(const std::string & content)', '    C10FlagParser_warmup(const std::string & content)'];
4x-sumrows-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    C10FlagParser_batch_size', '    C10FlagParser_db_type', '    C10FlagParser_input_db', '    C10FlagParser_splits'];['    Split(int argc,char **argv)', '    main(int argc,char **argv)', '    C10FlagParser_batch_size(const std::string & content)', '    C10FlagParser_db_type(const std::string & content)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_splits(const std::string & content)'];
4x8-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    GetSqrGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSqr', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sqr', '    GetGradientDefs', '    vector', '    vector'];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8vadd; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)'];
fp32-scalar.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDASqr'];
gemmlowp-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    GetSqrtGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSqrt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Sqrt', '    GetGradientDefs', '    vector', '    vector'];
precise-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)'];
precise-ssse3.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDASqrt'];
q31-sse4.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;['    GetSquareRootDivideGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSquareRootDivide', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SquareRootDivide', '    vector', '    GetGradientDefs'];
6x8-psimd.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm; 3;  1; 1;1;  0; 0;0;0;0;0;0.00;0;['    final'];['    DoRunWithType', '    DoRunWithType2', '    RunOnDevice', '    SquareRootDivideOp(Args,...)'];
16x9p8q-neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    TEST(SsaTest,ConvReluInplace)', '    TEST(SsaTest,FC_FC_FC_InPlace_Output)'];
neon.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8rmax; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
x2-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];['    pytorch_q8vadd_ukernel__sse2(size_t n,const uint8_t *a,const uint8_t *b,uint8_t *y,const union pytorch_qnnp_add_quantization_params [1] quantization_params)'];
x4-sse2.c;C;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip; 5;  2; 1;3;  0; 1;0;0;0;0;0.00;0;[];[];
qpool.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 427;  36; 19;18;  248; 127;144;102;66;44;0.15;5;[];['    pytorch_u8clamp_ukernel__sse2(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)'];
qsort.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 63;  9; 8;9;  39; 0;13;27;7;10;0.23;2;[];[];
qupsample_bilinear2d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized/cpu; 169;  8; 23;8;  135; 0;83;88;48;49;0.06;2;[];['    pytorch_u8rmax_ukernel__sse2(size_t n,const uint8_t *x)'];
fake_quant_affine.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 41;  2; 10;3;  28; 0;23;9;3;29;0.07;0;[];[];
TensorCompare.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/quantized; 38;  5; 6;8;  23; 0;8;12;4;7;0.22;3;[];[];
ReduceAllOps.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 26;  1; 6;3;  17; 0;6;11;6;10;0.06;2;[];[];
ReduceOpsUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 100;  4; 14;2;  81; 0;39;26;43;22;0.05;11;[];[];
ReplicationPadding.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1042;  25; 94;4;  922; 0;619;323;305;194;0.03;31;[];[];
RNN.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1333;  132; 134;170;  894; 20;444;519;329;653;0.15;96;[];[];
SharedReduceOps.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 380;  26; 65;60;  213; 47;68;104;46;88;0.12;43;[];[];
Sorting.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 309;  34; 29;8;  245; 0;132;100;146;52;0.14;14;[];[];
SparseTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/sparse; 522;  83; 76;8;  370; 0;248;132;249;128;0.22;31;[];[];
SpectralOpsUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 58;  28; 6;4;  21; 0;14;6;13;5;1.33;2;[];['    toMap(const ExportedStatList & stats)', '    get', '    add(const std::string & name)', '    publish(ExportedStatList & exported,bool reset)', '    update(const ExportedStatList & data)', '    ~StatRegistry'];
TensorCompare.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 316;  17; 33;9;  258; 0;142;72;188;73;0.07;33;['    AvgExportedStat', '    DetailedExportedStat', '    ExportedStat', '    StaticStat', '    StatRegistry', '    StatValue', '    StdDevExportedStat'];['    ScopeGuard(T f)', '    toMap(const ExportedStatList & stats)', '    get', '    AvgExportedStat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    _ScopeGuard(T)', '    operator bool', '    ~_ScopeGuard', '    DetailedExportedStat(const std::string & gn,const std::string & n)', '    increment(T value,size_t detailIndex,Unused,...)', '    setDetails(const std::vector & detailNames)', '    ExportedStat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    increment(Unused,...)', '    Stat(const std::string & gn,const std::string & n)', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    StaticStat(const std::string & groupName,const std::string & name)', '    add(const std::string & name)', '    publish(ExportedStatList & exported,bool reset)', '    publish(bool reset)', '    update(const ExportedStatList & data)', '    ~StatRegistry', '    exchange', '    get', '    increment(int64_t inc)', '    load', '    reset(int64_t value)', '    v_', '    compare_exchange_strong', '    const_min_', '    first_', '    increment(int64_t value)', '    increment(T value,Unused1,Unused,...)', '    load', '    StdDevExportedStat(const std::string & gn,const std::string & n)', '    now'];
TensorFactories.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 1060;  119; 164;42;  761; 0;400;298;492;200;0.16;86;['    StatRegistryCreateOp', '    StatRegistryExportOp', '    StatRegistryUpdateOp', '    TimerInstance'];['    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryCreate', '    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryExport', '    CAFFE_ANONYMOUS_VARIABLE_CPUStatRegistryUpdate', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerBegin', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerEnd', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUTimerGetAndEnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryCreate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryExport', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StatRegistryUpdate', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerBegin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerEnd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TimerGetAndEnd', '    noexcept', '    RunOnDevice', '    StatRegistryCreateOp(Args,...)', '    RunOnDevice', '    StatRegistryExportOp(Args,...)', '    RunOnDevice', '    StatRegistryUpdateOp(Args,...)', '    RunOnDevice', '    TimerBeginOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    TimerEndOp(Args,...)', '    RunOnDevice', '    TimerGetAndEndOp(Args,...)', '    RunOnDevice', '    TimerGetOp(Args,...)', '    begin', '    end', '    get_ns', '    TimerInstance(const std::string & name)', '    time_ns', '    TimerStat(std::string name)', '    _typeMetaDataInstance'];
TensorIteratorReduce.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 172;  18; 26;4;  126; 0;94;40;57;40;0.14;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUAveragePut', '    CAFFE_ANONYMOUS_VARIABLE_CPUIncrementPut', '    CAFFE_ANONYMOUS_VARIABLE_CPUStdDevPut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AveragePut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IncrementPut', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StdDevPut', '    AveragePutStat(std::string name)', '    stat_value', '    IncrementPutStat(std::string name)', '    stat_value', '    stat_value', '    StdDevPutStat(std::string name)'];
TensorTransformations.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 56;  4; 11;5;  37; 0;21;11;24;10;0.11;2;[];['    DoRunWithType', '    isNan(V input)', '    RunOnDevice', '    TemplatePutOp(const OperatorDef & operator_def,Workspace *ws)'];
TypeProperties.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 15;  0; 4;1;  10; 0;3;9;0;11;0.00;0;[];['    filterMap(const ExportedStatMap & map,const ExportedStatMap & keys)', '    TEST(StatsTest,StatsTestClass)', '    TEST(StatsTest,StatsTestDuration)', '    TEST(StatsTest,StatsTestSimple)', '    TEST(StatsTest,StatsTestStatic)', '    MyCaffeClass(const std::string & name)', '    MyStats(std::string name)', '    num_failures', '    num_runs', '    num_successes', '    usdt_only', '    run(int numRuns)', '    tryRun(int)', '    count', '    cpuUsage', '    memUsage', '    s1', '    s2', '    s3', '    TestStats(std::string name)', '    TestStats(std::string name)', '    TestStats(std::string name)', '    time_ns'];
Unfold2d.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 28;  1; 5;3;  20; 0;18;4;1;14;0.05;0;['    StdOutputFormatter'];['    get_mean(const std::vector & values)', '    get_stdev(const std::vector & values)', '    format(const std::vector & durations_ms,uint64_t threads,uint64_t iterations)', '    inner_product'];
UpSample.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 302;  59; 25;4;  216; 0;70;101;52;64;0.27;13;['    Allocate', '    Block', '    Cond', '    For', '    Free', '    LetStmt', '    LoopOptions', '    Stmt', '    StmtNode', '    Store'];['    make(const VarHandle & buffer_var,Dtype dtype,const std::vector & dims)', '    make(const std::vector & stmts)', '    make(const ExprHandle & condition,Stmt *true_stmt,Stmt *false_stmt)', '    make(const VarHandle & var,const ExprHandle & start,const ExprHandle & stop,Stmt *body)', '    make(const VarHandle & var,const ExprHandle & start,const ExprHandle & stop,Stmt *body,const LoopOptions & loop_options)', '    make(const VarHandle & buffer_var)', '    make(const VarHandle & var,const ExprHandle & value,Stmt *body)', '    clone(Stmt *s)', '    set_parent(Stmt *s,Stmt *new_parent)', '    make(const Buffer & buffer,const ExprHandle & index,const ExprHandle & value,const ExprHandle & mask)', '    make(const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & value,const ExprHandle & mask)', '    make(const VarHandle & base_handle,const ExprHandle & index,const ExprHandle & value)', '    empty', '    node', '    push_back', '    size', '    Allocate(const Var *buffer_var,Dtype dtype,const std::vector & dims)', '    buffer_var', '    dims', '    dtype', '    append_stmt(Stmt *s)', '    Block(const std::vector & stmts)', '    nstmts', '    prepend_stmt(Stmt *s)', '    replace_stmt(Stmt *old_stmt,Stmt *new_stmt)', '    stmts', '    Cond(const Expr *condition,Stmt *true_stmt,Stmt *false_stmt)', '    condition', '    false_stmt', '    true_stmt', '    body', '    For(const Var *var,const Expr *start,const Expr *stop,Stmt *body)', '    For(const Var *var,const Expr *start,const Expr *stop,Stmt *body,const LoopOptions & loop_options)', '    loop_options', '    set_gpu_block_index(int block_index)', '    set_gpu_thread_index(int thread_index)', '    start', '    stop', '    var', '    buffer_var', '    Free(const Var *buffer_var)', '    body', '    LetStmt(const Var *var,const Expr *value,Stmt *body)', '    value', '    var', '    gpu_block_index', '    gpu_block_index_str', '    gpu_thread_index', '    gpu_thread_index_str', '    is_gpu_block_index', '    is_gpu_thread_index', '    set_gpu_block_index(int index)', '    set_gpu_thread_index(int index)', '    ToString', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    get_parent', '    Stmt', '    accept(IRVisitor *visitor)', '    accept_mutator(IRMutator *mutator)', '    StmtNode', '    base_handle', '    index', '    mask', '    Store(const Buffer & buffer,const Expr *index,const Expr *value,const Expr *mask)', '    Store(const Var *base_handle,const Expr *index,const Expr *value,const Expr *mask)', '    value', '    dtype'];
UpSampleNearest1d.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 117;  3; 20;3;  94; 0;41;48;23;23;0.03;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUStopGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StopGradient'];
Allocator.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/utils; 55;  10; 11;2;  34; 0;13;18;4;16;0.29;5;['    StopGradientOp'];['    RunOnDevice', '    StopGradientOp(Args,...)', '    ~StopGradientOp'];
vol2col.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native; 115;  2; 5;5;  105; 0;43;71;30;25;0.02;2;[];['    stop_gradient_op_cpu_impl(const at::Tensor & input_,const at::Tensor & output_)'];
Convolution.h;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 50;  1; 1;6;  0; 46;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAStopGradient'];
Linear.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 198;  1; 0;5;  0; 196;0;0;0;0;0.00;0;[];['    free'];
RegisterOpContextClass.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/native/xnnpack; 103;  1; 0;8;  0; 101;0;0;0;0;0.00;0;[];['    THP(THPStorage *self)', '    THP(THPStorage *self)', '    THP(THPStorage *self,PyObject *index,PyObject *value)', '    deprecated_AT_ASSERT', '    incref(old_storage)', '    str(,,,,,::c10::str __VA_ARGS__)', '    PyDict_DelItemString(kwargs,)', '    PyErr_Format(PyExc_IndexError,,int64_t,int64_t)', '    PyErr_Format(PyExc_TypeError,,Py_TYPE)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    TH(ptr)', '    TH_CONCAT_4(THP,Real,Storage_,New)', '    TH_CONCAT_4(TH,Real,Storage_,copy_functions)', '    THP(PyObject *module)', '    THP', '    THP(PyObject *module)', '    THPUtils_invalidArguments(args,kwargs,TH_CONCAT_STRING_3,,,,,,,)', '    THPUtils_setError(__VA_ARGS__)', '    THPUtils_setError', '    THPUtils_setError(,Py_TYPE,Py_TYPE,THPUtils_typeTraits::python_type_str)', '    THPUtils_setError(,int64_t)', '    data'];
Parallel.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 136;  75; 18;10;  35; 3;2;33;1;18;2.14;1;[];[];
ParallelNativeTBB.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 105;  0; 0;19;  0; 103;0;0;0;0;0.00;0;[];[];
ParallelThreadPoolNative.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 88;  0; 0;9;  0; 86;0;0;0;0;0.00;0;[];[];
Quantizer.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/quantized; 638;  26; 45;33;  359; 183;176;135;235;178;0.07;25;[];[];
ScalarType.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 4;  1; 0;4;  0; 0;0;0;0;0;0.00;0;[];[];
SparseTensorUtils.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 132;  59; 12;3;  63; 0;41;22;32;27;0.94;8;[];[];
LegacyTHFunctions.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 50;  5; 9;6;  34; 0;13;20;5;16;0.15;6;[];[];
PerOpRegistration.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 17;  2; 4;5;  7; 0;2;4;0;5;0.29;1;[];['    TH_CONCAT_3(THP,Real,StorageClass)', '    TH_CONCAT_3(THP,Real,StorageType)', '    TH_CONCAT_4(THP,Real,Storage_,New)', '    THP(PyObject *module)'];
TypeDefault.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/templates; 39;  3; 8;15;  15; 0;7;15;0;7;0.20;2;[];[];
Tensor.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 12;  8; 1;3;  0; 0;0;0;0;0;0.00;0;[];[];
TensorIndexing.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 90;  5; 13;2;  72; 0;39;20;42;18;0.07;10;[];[];
TensorOperators.h;C++;pytorch-master/pytorch-master/aten/src/ATen; 99;  3; 9;29;  58; 0;0;0;0;0;0.05;0;[];['    _lseeki64(fd,THPUtils_unpackLong,SEEK_SET)', '    _lseeki64(fd,fd_original_pos,SEEK_SET)', '    Py_DECREF(seek_return)', '    Py_INCREF(self)', '    PyBuffer_Release(& buffer)', '    PyErr_Format(PyExc_ValueError,,byte_order_str)', '    PyErr_Format(PyExc_ValueError,,int64_t,int64_t)', '    PyErr_Format(PyExc_ValueError,,int64_t,int64_t,int64_t)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    TH(ptr)', '    TH(self,newsize)', '    TH(self,TH_CONCAT_4 THP)', '    TH(self)', '    THP(self,file,save_size)', '    THP(self,fd,save_size)', '    THPUtils_setError(__VA_ARGS__)'];
apply_utils_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 143;  14; 16;5;  108; 0;88;23;87;34;0.13;8;[];['    THP', '    deprecated_AT_ASSERT', '    decref(weak_storage)', '    str(,,,,,::c10::str __VA_ARGS__)', '    Py_INCREF(self)', '    PyErr_SetString(PyExc_IndexError,msg)', '    PyErr_SetString(PyExc_ValueError,msg)', '    PyErr_SetString(PyExc_RuntimeError,msg)', '    PyErr_SetString(e,msg)', '    PyTuple_SET_ITEM(tuple,,manager_handle)', '    PyTuple_SET_ITEM(tuple,,storage_handle)', '    PyTuple_SET_ITEM(tuple,,size)', '    TH_CONCAT_4(THP,Real,Storage_,newFilenameStorage)', '    TH_CONCAT_4(TH,Real,Storage_,newWithDataAndAllocator)', '    TH_CONCAT_4(THP,Real,Storage_,newFdStorage)', '    THPUtils_invalidArguments(args,nullptr,,,)', '    THPUtils_setError(__VA_ARGS__)', '    THPUtils_setError', '    move(sptr)', '    makeDataPtr(,handle,flags,size *)'];
broadcast_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 186;  18; 28;2;  138; 0;99;72;38;73;0.13;19;[];['    setTimeout(const std::chrono::milliseconds & timeout)', '    ~Store', '  Static Member Variables', '    kDefaultTimeout', '    kNoTimeout'];
cuda_apply_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 146;  3; 2;12;  0; 129;0;0;0;0;0.00;0;['    Store'];['    add(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    setTimeout(const std::chrono::milliseconds & timeout)', '    Store', '    Store(const std::chrono::milliseconds & timeout)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~Store', '    zero'];
Dict_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 520;  0; 81;6;  433; 0;285;129;251;131;0.00;47;[];['    noexcept', '    ~StoreHandler', '  Static Member Variables', '    kDefaultTimeout', '    kNoTimeout'];
half_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 166;  2; 13;17;  127; 7;86;38;78;40;0.02;8;[];['    get(const std::string & key)', '    set(const std::string & key,const std::vector & data)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)'];
NamedTensor_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 249;  11; 40;6;  192; 0;132;89;68;91;0.06;17;['    StoreHandlerWrapper'];['    get(const std::string & key)', '    StoreHandlerWrapper(StoreHandler & handler)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~StoreHandlerWrapper'];
reduce_ops_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 24;  0; 3;3;  18; 0;13;5;5;6;0.00;2;['    StoreHandler'];['    add(const std::string & name,int64_t value)', '    check(const std::vector & names)', '    get(const std::string & name,const std::chrono::milliseconds & timeout)', '    wait(const std::vector & names,const std::chrono::milliseconds & timeout)', '    ~StoreHandler', '    StoreHandlerNotAvailableException(const std::string & msg)', '    StoreHandlerTimeoutException(const std::string & msg)', '    seconds', '    zero'];
tensor_interop_test.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 299;  30; 48;4;  217; 0;139;84;116;83;0.14;16;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUStoreAdd', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreGet', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreSet', '    CAFFE_ANONYMOUS_VARIABLE_CPUStoreWait', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreAdd', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreGet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreSet', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StoreWait', '    RunOnDevice', '    StoreAddOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreGetOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreSetOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    StoreWaitOp(const OperatorDef & operator_def,Workspace *ws)'];
test_parallel.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 71;  3; 13;7;  48; 0;39;16;16;13;0.06;4;['    final', '    final', '    final', '    final'];['    RunOnDevice', '    StoreAddOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreGetOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreSetOp(const OperatorDef & operator_def,Workspace *ws)', '    StoreWaitOp(const OperatorDef & operator_def,Workspace *ws)'];
verify_api_visibility.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen/test; 19;  0; 5;13;  1; 4;0;1;0;1;0.00;1;[];['    check(Store & store,const std::string & key,const std::string & expected)', '    set(Store & store,const std::string & key,const std::string & value)', '    set'];
ThreadLocalDebugInfo.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 20;  1; 5;1;  14; 0;4;9;3;6;0.07;2;[];['    operator<<(std::ostream & stream,const Stream & s)'];
Version.cpp;C++;pytorch-master/pytorch-master/aten/src/ATen; 188;  7; 27;39;  58; 61;37;10;35;9;0.12;5;[];['    THCPStream_dealloc(THCPStream *self)', '    THCPStream_eq(THCPStream *self,THCPStream *other)', '    THCPStream_get_cuda_stream(THCPStream *self,void *unused)', '    THCPStream_get_device(THCPStream *self,void *unused)', '    THCPStream_get_priority(THCPStream *self,void *unused)', '    THCPStream_priority_range', '    THCPStream_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THCPStream_query(THCPStream *self,PyObject *noargs)', '    THCPStream_synchronize(THCPStream *self,PyObject *noargs)', '    THCPStream_init(PyObject *module)'];
THBlas.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 542;  0; 0;60;  0; 539;0;0;0;0;0.00;0;[];['    BatchSize(size_t size)', '    operator size_t', '    size', '    load(serialize::InputArchive & archive)', '    next(size_t batch_size)', '    reset(optional new_size)', '    save(serialize::OutputArchive & archive)', '    StreamSampler(size_t epoch_size)'];
THStorage.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 146;  1; 21;20;  100; 6;43;50;14;63;0.01;9;[];['    THCPStream_Check(PyObject *obj)', '    THCPStream_init(PyObject *module)'];
THTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 521;  11; 83;11;  418; 1;196;105;179;161;0.03;41;[];[];
THTensorEvenMoreMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 452;  15; 51;29;  358; 6;172;78;1695;193;0.04;17;[];[];
THTensorLapack.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 496;  109; 65;4;  322; 1;192;77;190;125;0.34;9;[];['    current_stream', '    operator=', '    operator=', '    OptionalStreamGuard', '    OptionalStreamGuard(Stream stream)', '    OptionalStreamGuard(optional stream_opt)', '    OptionalStreamGuard', '    OptionalStreamGuard', '    original_stream', '    reset', '    reset_stream(Stream stream)', '    current_device', '    current_stream', '    operator=', '    operator=', '    original_device', '    original_stream', '    reset_stream(Stream stream)', '    StreamGuard', '    StreamGuard(Stream stream)', '    StreamGuard', '    StreamGuard'];
THTensorMoreMath.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 774;  87; 84;84;  408; 129;279;53;792;103;0.21;13;[];[];
THVectorDefault.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/generic; 42;  0; 0;7;  0; 39;0;0;0;0;0.00;0;[];[];
THAllocator.h;C++;pytorch-master/pytorch-master/aten/src/TH; 100;  13; 18;16;  52; 4;13;41;9;41;0.25;6;[];['    ForEach(OperatorBase & op)', '    operator()(int n,const In *in,Out *out,Context *)'];
THDiskFile.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 801;  22; 92;119;  562; 21;351;153;569;173;0.04;39;['    StringJoinOpTest'];['    TEST_F(StringJoinOpTest,testString1DJoin)', '    TEST_F(StringJoinOpTest,testString2DJoin)', '    TEST_F(StringJoinOpTest,testFloat1DJoin)', '    TEST_F(StringJoinOpTest,testFloat2DJoin)', '    TEST_F(StringJoinOpTest,testLong2DJoin)', '    checkAndGetOutput(int outputSize)', '    runOp(const Tensor & input)'];
THFilePrivate.h;C++;pytorch-master/pytorch-master/aten/src/TH; 50;  1; 9;2;  38; 0;0;34;0;34;0.03;0;[];['    string_to_type_lut'];
THGenerateBoolType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 0;0;0;0;0;0.00;0;[];['    editDistance(const std::string & s1,const std::string & s2,size_t max_distance)', '    editDistanceHelper(const char *s1,size_t s1_len,const char *s2,size_t s2_len,std::vector & current,std::vector & previous,std::vector & previous1,size_t max_distance)', '    split(char separator,const std::string & string,bool ignore_empty)', '    trim(const std::string & str)'];
THGenerateFloatType.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 2;16;  0; 2;0;0;0;0;0.00;0;[];['    editDistance(const std::string & s1,const std::string & s2,size_t max_distance)', '    editDistanceHelper(const char *s1,size_t s1_len,const char *s2,size_t s2_len,std::vector & current,std::vector & previous,std::vector & previous1,size_t max_distance)', '    EndsWith(const std::string & full,const std::string & ending)', '    split(char separator,const std::string & string,bool ignore_empty)', '    StartsWith(const std::string & str,const std::string & prefix)', '    trim(const std::string & str)', '    mismatch'];
THGenerateIntTypes.h;C++;pytorch-master/pytorch-master/aten/src/TH; 20;  0; 3;17;  0; 6;0;0;0;0;0.00;0;[];[];
THGenerateQTypes.h;C++;pytorch-master/pytorch-master/aten/src/TH; 18;  0; 3;15;  0; 1;0;0;0;0;0.00;0;['    final'];['    begin(basic_string_view sv)', '    end(basic_string_view sv)', '    operator!=(basic_string_view lhs,basic_string_view rhs)', '    operator<(basic_string_view lhs,basic_string_view rhs)', '    operator<<(std::basic_ostream & stream,basic_string_view sv)', '    operator<=(basic_string_view lhs,basic_string_view rhs)', '    operator==(basic_string_view lhs,basic_string_view rhs)', '    operator>(basic_string_view lhs,basic_string_view rhs)', '    operator>=(basic_string_view lhs,basic_string_view rhs)', '    operator()(::c10::basic_string_view x)', '    swap(basic_string_view & lhs,basic_string_view & rhs)', '    strlen_(const_pointer str)', '    swap', '    at(size_type pos)', '    at_(size_type pos)', '    back', '    basic_string_view', '    basic_string_view(const_pointer str,size_type count)', '    basic_string_view(const_pointer str)', '    basic_string_view(const ::std::basic_string & str)', '    basic_string_view', '    begin', '    cbegin', '    cend', '    compare(basic_string_view rhs)', '    compare(size_type pos1,size_type count1,basic_string_view v)', '    compare(size_type pos1,size_type count1,basic_string_view v,size_type pos2,size_type count2)', '    compare(const_pointer s)', '    compare(size_type pos1,size_type count1,const_pointer s)', '    compare(size_type pos1,size_type count1,const_pointer s,size_type count2)', '    copy(pointer dest,size_type count,size_type pos)', '    crbegin', '    crend', '    data', '    empty', '    end', '    ends_with(basic_string_view suffix)', '    ends_with(CharT suffix)', '    ends_with(const_pointer suffix)', '    equals_(basic_string_view rhs)', '    operator()(CharT actual)', '    operator()(CharT ch)', '    operator()(CharT ch)', '    operator()(CharT actual)', '    find(basic_string_view v,size_type pos)', '    find(CharT ch,size_type pos)', '    find(const_pointer s,size_type pos,size_type count)', '    find(const_pointer s,size_type pos)', '    find_first_if_(size_type pos,Condition)', '    find_first_not_of(basic_string_view v,size_type pos)', '    find_first_not_of(CharT ch,size_type pos)', '    find_first_not_of(const_pointer s,size_type pos,size_type count)', '    find_first_not_of(const_pointer s,size_type pos)', '    find_first_of(basic_string_view v,size_type pos)', '    find_first_of(CharT ch,size_type pos)', '    find_first_of(const_pointer s,size_type pos,size_type count)', '    find_first_of(const_pointer s,size_type pos)', '    find_last_if_(size_type pos,Condition)', '    find_last_not_of(basic_string_view v,size_type pos)', '    find_last_not_of(CharT ch,size_type pos)', '    find_last_not_of(const_pointer s,size_type pos,size_type count)', '    find_last_not_of(const_pointer s,size_type pos)', '    find_last_of(basic_string_view v,size_type pos)', '    find_last_of(CharT ch,size_type pos)', '    find_last_of(const_pointer s,size_type pos,size_type count)', '    find_last_of(const_pointer s,size_type pos)', '    front', '    length', '    max_size', '    operator ::std::basic_string', '    operator=(const basic_string_view & rhs)', '    operator[](size_type pos)', '    rbegin', '    remove_prefix(size_type n)', '    remove_suffix(size_type n)', '    rend', '    rfind(basic_string_view v,size_type pos)', '    rfind(CharT ch,size_type pos)', '    rfind(const_pointer s,size_type pos,size_type count)', '    rfind(const_pointer s,size_type pos)', '    size', '    starts_with(basic_string_view prefix)', '    starts_with(CharT prefix)', '    starts_with(const_pointer prefix)', '    substr(size_type pos,size_type count)', '    substr_(size_type pos,size_type count)', '    swap(basic_string_view & sv)', '    min', '    to_string', '    max', '    out_of_range'];
THHalf.h;C++;pytorch-master/pytorch-master/aten/src/TH; 8;  0; 3;5;  0; 0;0;0;0;0;0.00;0;[];['    TEST(StringViewTest,testConversionToString)', '    TEST(StringViewTest,whenCopyingFullStringView_thenDestinationHasCorrectData)', '    TEST(StringViewTest,whenCopyingSubstr_thenDestinationHasCorrectData)', '    TEST(StringViewTest,whenCopyingTooMuch_thenJustCopiesLess)', '    TEST(StringViewTest,whenCopyingJustAtRange_thenDoesntCrash)', '    TEST(StringViewTest,whenCopyingOutOfRange_thenThrows)', '    assign(string_view value)', '    TEST(StringViewTest,testCopyAssignment)', '    TEST(StringViewTest,testHash)', '    TEST(StringViewTest,testOutputOperator)', '    testOutputIterator(const std::string & str)', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    expectThrows', '    TEST(StringViewTest,whenCallingAccessOperatorOutOfRange_thenThrows)', '    remove_prefix(string_view input,size_t len)', '    TEST(StringViewTest,whenRemovingValidPrefix_thenWorks)', '    TEST(StringViewTest,whenRemovingTooLargePrefix_thenThrows)', '    remove_suffix(string_view input,size_t len)', '    TEST(StringViewTest,whenRemovingValidSuffix_thenWorks)', '    TEST(StringViewTest,whenRemovingTooLargeSuffix_thenThrows)', '    TEST(StringViewTest,testStringConstructor)', '    test_conversion_is_implicit(string_view a)', '    TEST(StringViewTest,whenCallingSubstrWithPosOutOfRange_thenThrows)', '    get', '    TEST(StringViewTest,testSwapFunction)', '    get', '    TEST(StringViewTest,testSwapMethod)', '    expectThrows(Functor,const char *expectMessageContains)', '    string_equal(const char *lhs,const char *rhs,size_t size)'];
THMemoryFile.h;C++;pytorch-master/pytorch-master/aten/src/TH; 13;  0; 4;5;  4; 0;0;4;0;4;0.00;0;[];['    StripBasename(const std::string & full_path)', '    operator<<(std::ostream & out,const SourceLocation & loc)', '    ReplaceAll(std::string & s,const char *from,const char *to)'];
THStorageFunctions.hpp;C++;pytorch-master/pytorch-master/aten/src/TH; 38;  23; 6;5;  4; 0;0;4;0;4;5.75;0;[];['    isPrint(char s)', '    _str(std::ostream & ss)', '    _str(std::ostream & ss,const T & t)', '    _str(std::ostream & ss,const T & t,const Args &,...)', '    _str_wrapper(const Args &,...)', '    StripBasename(const std::string & full_path)', '    Join(const std::string & delimiter,const Container & v)', '    operator<<(std::ostream & out,const SourceLocation & loc)', '    printQuotedString(std::ostream & stmt,const std::string & str)', '    ReplaceAll(std::string & s,const char *from,const char *to)', '    str(const Args &,...)', '    str(const std::string & str)', '    str(const char *c_str)'];
THTensorApply.h;C++;pytorch-master/pytorch-master/aten/src/TH; 309;  81; 13;238;  1; 0;0;0;0;0;81.00;0;[];['    strtod_c(const char *nptr,char **endptr)', '    strtof_c(const char *nptr,char **endptr)'];
THTensorLapack.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 5;  0; 1;4;  0; 0;0;0;0;1;0.00;0;[];['    strtod_c(const char *nptr,char **endptr)', '    strtof_c(const char *nptr,char **endptr)'];
THVector.cpp;C++;pytorch-master/pytorch-master/aten/src/TH; 39;  0; 12;27;  0; 3;0;0;0;0;0.00;0;[];['    returned_structseq_repr(PyStructSequence *obj)'];
NEON.cpp;C++;pytorch-master/pytorch-master/aten/src/TH/vector; 30;  0; 6;0;  24; 0;16;4;18;4;0.00;2;[];[];
THCStorage.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 50;  0; 0;15;  0; 47;0;0;0;0;0.00;0;[];['    PyInit__C'];
THCTensor.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 104;  12; 21;15;  56; 1;0;56;0;67;0.21;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUStumpFunc', '    CAFFE_ANONYMOUS_VARIABLE_CPUStumpFuncIndex', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StumpFunc', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_StumpFuncIndex', '    RunOnDevice', '    RunOnDevice'];
THCTensorMasked.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 54;  3; 11;4;  36; 1;0;36;0;9;0.08;0;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    StumpFuncIndexOp(Args,...)', '    StumpFuncOp(Args,...)'];
THCTensorMathPairwise.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 14;  0; 5;6;  3; 1;0;3;0;3;0.00;0;['    BRGNCHWCToPackedInt8BGRAStylizerDeprocessOp', '    PackedInt8BGRANHWCToNCHWCStylizerPreprocessOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUBRGNCHWCToPackedInt8BGRAStylizerDeprocess', '    CAFFE_ANONYMOUS_VARIABLE_CPUPackedInt8BGRANHWCToNCHWCStylizerPreprocess', '    clamped_cast(float f)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_BRGNCHWCToPackedInt8BGRAStylizerDeprocess', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_PackedInt8BGRANHWCToNCHWCStylizerPreprocess', '    runBatch(int N,int,int H,int W,const float *input,const float *meanChannel,uint8_t *output)', '    runCPU(int H,int W,const float *input,const float *meanChannel,uint8_t *output)', '    RunOnDevice', '    initNoiseCPU(Tensor *noise,int size)', '    PackedInt8BGRANHWCToNCHWCStylizerPreprocessOp(const OperatorDef & operator_def,Workspace *ws)', '    runBatch(int N,int,int H,int W,int noiseCycle,const uint8_t *input,const float *meanChannel,const float *noise,float *output)', '    runCPU(int H,int W,int noiseCycle,const uint8_t *input,const float *meanChannel,const float *noise,float *output)', '    RunOnDevice'];
THCTensorMode.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 14;  3; 2;4;  6; 1;0;6;0;1;0.50;0;[];['    pytorch_u8maxpool_ukernel_sub16__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)'];
THCTensorTopK.h;C++;pytorch-master/pytorch-master/aten/src/THC/generic; 13;  3; 2;4;  5; 1;0;5;0;1;0.60;0;[];[];
THCBlas.h;C++;pytorch-master/pytorch-master/aten/src/THC; 55;  3; 9;14;  16; 13;0;16;0;12;0.19;0;[];[];
THCGeneral.hpp;C++;pytorch-master/pytorch-master/aten/src/THC; 21;  9; 4;2;  6; 0;0;5;0;5;1.50;0;[];['    pytorch_u8maxpool_ukernel_sub16__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)'];
THCGenerateByteType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 20;  0; 2;18;  0; 2;0;0;0;0;0.00;0;['    SubgraphMatcher'];['    endsWith(const std::string & str,const std::string & suffix)', '    findPatternMatches(const Graph & pattern,Graph & graph)', '    patternGraphIsValid(const Graph & pattern)', '    matchAttributes(const Node *n1,Node *n2)', '    matchesSubgraphFromAnchorNode(Node *anchor)', '    matchNodes(const Node *n1,Node *n2)', '    matchValues(const Value *v1,Value *v2)', '    nodes_map', '    SubgraphMatcher(const Graph & pattern)', '    values_map'];
THCGenerateFloatTypes.h;C++;pytorch-master/pytorch-master/aten/src/THC; 32;  0; 5;27;  0; 0;0;0;0;0;0.00;0;[];['    findPatternMatches(const Graph & pattern,Graph & graph)'];
THCGenerateShortType.h;C++;pytorch-master/pytorch-master/aten/src/THC; 20;  0; 2;18;  0; 2;0;0;0;0;0.00;0;[];['    PatternBasedRewrite(const Module & module)', '    overlapsWithPreviousMatches(const Match *match)', '    RegisterDefaultPatterns', '    RegisterRewritePattern(const std::string & pattern,const std::string & replacement)', '    rewriteSinglePatternOnGraph(std::shared_ptr & graph,const RewritePatternDescr & pattern,const std::function & filter)', '    runOnGraph(std::shared_ptr & graph,const std::function & filter)', '    runOnModule(const Module & module)'];
THCStorage.hpp;C++;pytorch-master/pytorch-master/aten/src/THC; 26;  3; 8;7;  8; 0;0;8;0;6;0.38;0;['    SubgraphRewriter'];['    PatternBasedRewrite(const Module & module)', '    overlapsWithPreviousMatches(const Match *match)', '    RegisterDefaultPatterns', '    RegisterRewritePattern(const std::string & pattern,const std::string & replacement)', '    rewriteSinglePatternOnGraph(std::shared_ptr & graph,const RewritePatternDescr & pattern,const std::function & filter)', '    runOnGraph(std::shared_ptr & graph,const std::function & filter)', '    runOnModule(const Module & module)'];
THCTensor.cpp;C++;pytorch-master/pytorch-master/aten/src/THC; 369;  28; 61;14;  268; 1;159;58;156;54;0.10;26;[];['    closedOverValues(Node *toMerge,std::unordered_map & inputsMap)', '    collectNestedUses(std::unordered_set & closed_over_values,std::unordered_set & new_values,std::unordered_map & inputsMap,Node *input_node)', '    createSingletonSubgraph(Node *n,Symbol subgraphKind)', '    getSubgraph(Node *n)', '    hasSubgraph(Node *n)', '    mergeNodeIntoSubgraph(Node *toMerge,Node *subgraphNode)', '    mergeSubgraph(Node *mergeTo,Node *mergeFrom)', '    unmergeSubgraph(Node *subgraphNode)'];
THCTensorCopy.hpp;C++;pytorch-master/pytorch-master/aten/src/THC; 18;  0; 6;2;  10; 0;0;10;0;5;0.00;0;[];['    createSingletonSubgraph(Node *n,Symbol subgraphKind)', '    getSubgraph(Node *n)', '    mergeNodeIntoSubgraph(Node *toMerge,Node *subgraphNode)', '    unmergeSubgraph(Node *subgraphNode)'];
THCUNN.h;C++;pytorch-master/pytorch-master/aten/src/THCUNN/generic; 204;  0; 0;6;  0; 201;0;0;0;0;0.00;0;['    MatchGraph', '    MatchPredicate', '    SubgraphMatchResult'];['    matched(bool ownSubgraph)', '    notMatched(const std::string & debugMessage)', '    notMatched', '    debugString(MatchGraph::NodeRef rootCriteriaRef,bool invertGraphTraversal)', '    isNodeMatch(GraphType::NodeRef node,const MatchPredicate & matchPredicate)', '    isSubgraphMatch(GraphType::NodeRef root,const MatchGraph::NodeRef & rootCriteriaRef,bool invertGraphTraversal,bool debug)', '    isSubgraphMatchInternal(std::shared_ptr matchedNodes,std::shared_ptr matchedSubgraph,GraphType::NodeRef root,const MatchGraph::NodeRef & rootCriteriaRef,bool includeInSubgraph,bool invertGraphTraversal,bool debug)', '    replaceSubgraph(GraphType & graph,const MatchGraph::NodeRef & criteria,const ReplaceGraphOperation & replaceFunction,bool invertGraphTraversal)', '    count(int count)', '    excludeFromSubgraph', '    getCount', '    getCriteria', '    getDebugString', '    isNonTerminal', '    MatchPredicate(const Predicate & criteria)', '    MatchPredicate', '    MatchPredicate', '    MatchPredicate', '    nonTerminal', '    operator=', '    setDebugString(const std::string & debugString)', '    shouldIncludeInSubgraph', '    starCount', '    getDebugMessage', '    getMatchedSubgraph', '    getMatchNodeMap', '    isMatch', '    SubgraphMatchResult(bool isMatch,const std::string & debugMessage,bool ownSubgraph)'];
benchmark_args.h;C++;pytorch-master/pytorch-master/binaries; 95;  15; 3;2;  75; 0;18;18;18;125;0.20;18;[];['    any', '    getInNode(TestGraph::NodeRef node,int index)', '    isSubgraphMatch(TestGraph::NodeRef nodeRef,const TestMatchGraph::NodeRef & criteria,bool invertGraphTraversal)', '    reset', '    testMatchPredicate(const Criteria & criteria)', '    NonTerminal(const Criteria & root,int count)', '    TestGraphNodePrinter(TestGraph::NodeRef node)', '    Tree(const Criteria & root,const std::vector & children,int count)', '    TEST(SubgraphMatcher,IsNodeMatch)', '    TEST(SubgraphMatcher,IsSubtreeMatch)', '    TEST(SubgraphMatcher,IsSubtreeMatchRepeated)', '    TEST(SubgraphMatcher,DagMatching)', '    TEST(SubgraphMatcher,DagMatchingMultiEdges)', '    TEST(SubgraphMatcher,DagMatchingRandomLargeGraph)', '    TEST(SubgraphMatcher,IsSubtreeMatchRealistic)', '    TEST(SubgraphMatcher,ReplaceGraphRealistic)', '    DataFlowTestGraph', '    DataFlowTestGraphCriteria'];
convert_and_benchmark.cc;C++;pytorch-master/pytorch-master/binaries; 770;  41; 56;26;  636; 13;394;208;322;193;0.06;28;[];['    isRecursive(const TypePtr & classType,const TypePtr & attrType)', '    builtin_cast_methods', '    make_simple_value', '    base_iters', '    tryCreate(Symbol symbol,c10::optional self)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    addChild(const SourceRange & range,Function & m,const SugaredValuePtr iter_value)', '    get_base_iterables', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    len(const SourceRange & loc,Function & m)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    RangeValue(const SourceRange & loc,Function & m,std::vector inputs,c10::optional static_len)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    operator()(T t)', '    kind'];
convert_image_to_tensor.cc;C++;pytorch-master/pytorch-master/binaries; 450;  29; 33;14;  374; 2;243;129;175;192;0.08;25;[];['    toValues(Graph & g,at::ArrayRef nvs)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs_,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    len(const SourceRange & loc,Function & m)', '    shouldEmitUnrolled', '    staticLen', '    ~SugaredValue', '    tryCreate(Symbol symbol,c10::optional self)', '    create(Symbol form)', '    BuiltinFunction(Symbol symbol,c10::optional self)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    BuiltinModule(std::string name,c10::optional version)', '    kind', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    CastValue(TypePtr type,c10::Symbol method)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    ClassValue(ClassTypePtr type)', '    kind', '    asValue(const SourceRange & range,Function & m)', '    ClosureValue(Value *value)', '    kind', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    callees', '    FunctionValue(Function *callee)', '    FunctionValue(const StrongFunctionPtr & p)', '    FunctionValue(const std::vector & callees)', '    kind', '    createTuple', '    insertNode', '    addChild(const SourceRange & range,Function & m,const SugaredValuePtr iter_value)', '    get_base_iterables', '    get_children', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    IterableTree', '    IterableTree(const SourceRange & range,Function & m,at::ArrayRef children)', '    kind', '    len(const SourceRange & loc,Function & m)', '    staticLen', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    MagicMethod(std::string desugared_name,SugaredValuePtr base)', '    call(const SourceRange & loc,Function & f,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    MethodValue(Value *self,std::vector method_names)', '    MethodValue(Value *self,std::string method_name)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    NamedTupleConstructor(TupleTypePtr type)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    kind', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    len(const SourceRange & loc,Function & m)', '    RangeValue(const SourceRange & loc,Function & m,std::vector inputs,c10::optional static_len)', '    staticLen', '    getClassType', '    makeSugared(Value *v)', '    SimpleSelf(ClassTypePtr classType)', '    asValue(const SourceRange & range,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    call(const SourceRange & loc,Function & m,at::ArrayRef inputs,at::ArrayRef attributes,size_t n_binders)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    getValue', '    iter(const SourceRange & loc,Function & m)', '    kind', '    len(const SourceRange & loc,Function & m)', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)', '    SimpleValue(Value *value)', '    form', '    kind', '    SpecialFormValue(Symbol form)', '    end', '    push_back', '    asValue(const SourceRange & loc,Function & m)', '    getitem(const SourceRange & loc,Function & m,Value *idx)', '    iter(const SourceRange & loc,Function & m)', '    kind', '    override', '    staticLen', '    SugaredTupleValue(std::vector)', '    asValue(const SourceRange & loc,Function & m)', '    attr(const SourceRange & loc,Function & m,const std::string & field)', '    kind', '    setAttr(const SourceRange & loc,Function & m,const std::string & field,Value *newValue)'];
dump_operator_names.cc;C++;pytorch-master/pytorch-master/binaries; 83;  15; 8;6;  54; 0;40;21;35;34;0.28;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSummarize', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Summarize', '    RunOnDevice'];
make_cifar_db.cc;C++;pytorch-master/pytorch-master/binaries; 146;  29; 15;9;  95; 0;65;34;56;63;0.31;9;['    final'];['    GetSingleArgument', '    RunOnDevice', '    SummarizeOp(const OperatorDef & def,Workspace *ws)', '    ~SummarizeOp', '    RootFolder'];
predictor_verifier.cc;C++;pytorch-master/pytorch-master/binaries; 57;  17; 5;4;  31; 0;20;8;31;20;0.55;4;[];['    _bincount_cpu(const Tensor & self,const Tensor & weights,int64_t minlength)', '    _bincount_cpu_template(const Tensor & self,const Tensor & weights,int64_t minlength)'];
run_plan_mpi.cc;C++;pytorch-master/pytorch-master/binaries; 49;  16; 5;7;  21; 0;17;3;18;9;0.76;2;[];[];
tsv_2_proto.cc;C++;pytorch-master/pytorch-master/binaries; 49;  15; 4;8;  22; 0;17;5;17;21;0.68;3;[];[];
Allocator.cpp;C++;pytorch-master/pytorch-master/c10/core; 31;  1; 7;1;  23; 0;9;11;8;7;0.04;4;['    SimpleContainer'];['    assert_tensor_equal(at::Tensor a,at::Tensor b,bool allow_inf)', '    assert_tensor_not_equal(at::Tensor x,at::Tensor y)', '    count_substr_occurrences(const std::string & str,const std::string & substr)', '    pointer_equal(at::Tensor first,at::Tensor second)', '    cpu', '    data_ptr', '    device', '    get_device', '    is_cuda', '    is_floating_point', '    numel', '    scalar_type', '    sizes', '    to', '    type', '    type_as', '    equal', '    get_default_dtype', '    isinf', '    isnan', '    manual_seed', '    scalarTypeToTypeMeta', '    set_default_dtype', '    AutoDefaultDtypeMode(c10::ScalarType default_dtype)', '    ~AutoDefaultDtypeMode', '    CerrRedirect(std::streambuf *new_buffer)', '    ~CerrRedirect', '    SeedingFixture', '    add(ModuleHolder module_holder,std::string name)', '    reset', '    typeMetaToScalarType'];
CopyBytes.h;C++;pytorch-master/pytorch-master/c10/core; 44;  10; 6;7;  22; 0;0;0;0;0;0.45;0;['    GetSwishGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSwish', '    CAFFE_ANONYMOUS_VARIABLE_CPUSwishGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Swish', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SwishGradient', '    GetGradientDefs', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    vector', '    DoRunWithType'];
DefaultDtype.h;C++;pytorch-master/pytorch-master/c10/core; 13;  2; 3;2;  8; 0;0;0;0;0;0.25;0;['    final'];['    DoRunWithType', '    RunOnDevice', '    SwishGradientOp(Args,...)', '    ~SwishGradientOp', '    operator()(const int N,const T *X,T *Y,Context *context)'];
DeviceGuard.h;C++;pytorch-master/pytorch-master/c10/core; 184;  103; 26;2;  54; 0;0;0;0;0;1.91;0;[];[];
DispatchKey.h;C++;pytorch-master/pytorch-master/c10/core; 221;  141; 38;4;  53; 0;3;16;2;13;2.66;2;[];['    gradientInfoForSchema(const FunctionSchema & schema)', '    hasGradientInfoForSchema(const FunctionSchema & schema)', '    extractClosure(Value *closure)', '    isHelperFunction(const std::string & method_name)', '    loadModule(const CompilationUnit & module)', '    originalReturnType(const TupleTypePtr & tup)', '    overloadedSchemaString(const FunctionSchema & schema)', '    loadFunctions'];
GeneratorImpl.cpp;C++;pytorch-master/pytorch-master/c10/core; 84;  33; 9;12;  22; 14;9;10;7;8;1.50;5;[];['    gradientInfoForSchema(const FunctionSchema & schema)', '    hasGradientInfoForSchema(const FunctionSchema & schema)'];
FakeGuardImpl.h;C++;pytorch-master/pytorch-master/c10/core/impl; 105;  11; 12;3;  80; 0;28;43;44;30;0.14;18;['    GetTanGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTan', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tan', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanGradient', '    GetGradientDefs', '    Forward(const std::vector & X_dims,const std::vector &,const T *X,const T *dY,T *dX,CPUContext *)', '    vector'];
LocalDispatchKeySet.cpp;C++;pytorch-master/pytorch-master/c10/core/impl; 125;  29; 21;5;  69; 4;30;26;22;24;0.42;10;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & X_dims,const std::vector & dY_dims,const T *X,const T *dY,T *dX,Context *context)'];
MemoryFormat.h;C++;pytorch-master/pytorch-master/c10/core; 239;  94; 16;6;  124; 0;0;0;0;0;0.76;0;['    TanHOperatorTester'];['    batchSize(size_t batchSize)', '    batchSize', '    batchSize_', '    channels(size_t channels)', '    channels', '    channels_', '    inputScale(float inputScale)', '    inputScale', '    inputScale_', '    inputStride(size_t inputStride)', '    inputStride', '    inputStride_', '    inputZeroPoint(uint8_t inputZeroPoint)', '    inputZeroPoint', '    inputZeroPoint_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    outputScale', '    outputStride(size_t outputStride)', '    outputStride', '    outputStride_', '    outputZeroPoint', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    testQ8'];
Scalar.h;C++;pytorch-master/pytorch-master/c10/core; 158;  21; 25;39;  75; 0;0;0;0;0;0.28;0;[];['    pytorch_qnnp_create_tanh_nc_q8(size_t channels,uint8_t input_zero_point,float input_scale,uint8_t output_zero_point,float output_scale,uint8_t output_min,uint8_t output_max,uint32_t flags,pytorch_qnnp_operator_t *tanh_out)', '    pytorch_qnnp_setup_tanh_nc_q8(pytorch_qnnp_operator_t tanh,size_t batch_size,const uint8_t *input,size_t input_stride,uint8_t *output,size_t output_stride)'];
StorageImpl.cpp;C++;pytorch-master/pytorch-master/c10/core; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    CharacteristicArguments(benchmark::internal::Benchmark *b)', '    tanh_q8(benchmark::State & state)'];
StreamGuard.h;C++;pytorch-master/pytorch-master/c10/core; 126;  65; 24;2;  36; 0;18;28;9;27;1.81;13;[];['    GetPassRegionEnd_(TensorQuantizationParams in_qparams,TensorQuantizationParams out_qparams,double max_abs_err,int num_in_bits)', '    GetSaturationRegionBegin_(double max_abs_err)', '    sgn(T val)', '    Compute(T x)', '    Tanh(double max_abs_err)'];
TensorOptions.h;C++;pytorch-master/pytorch-master/c10/core; 650;  217; 78;14;  352; 0;0;0;0;0;0.62;0;[];['    TEST(TANH_OP,zero_batch)', '    TEST(TANH_OP,unit_batch)', '    TEST(TANH_OP,unit_batch_with_qmin)', '    TEST(TANH_OP,unit_batch_with_qmax)', '    TEST(TANH_OP,unit_batch_with_input_scale)', '    TEST(TANH_OP,unit_batch_with_input_zero_point)', '    TEST(TANH_OP,small_batch)', '    TEST(TANH_OP,small_batch_with_input_stride)', '    TEST(TANH_OP,small_batch_with_output_stride)', '    TEST(TANH_OP,small_batch_with_qmin)', '    TEST(TANH_OP,small_batch_with_qmax)', '    TEST(TANH_OP,small_batch_with_input_scale)', '    TEST(TANH_OP,small_batch_with_input_zero_point)', '    TEST(TANH_OP,strided_batch)', '    TEST(TANH_OP,strided_batch_with_qmin)', '    TEST(TANH_OP,strided_batch_with_qmax)', '    TEST(TANH_OP,strided_batch_with_input_scale)', '    TEST(TANH_OP,strided_batch_with_input_zero_point)'];
UndefinedTensorImpl.h;C++;pytorch-master/pytorch-master/c10/core; 35;  5; 4;5;  21; 2;0;0;0;0;0.24;0;['    Tanh'];['    Compute(T x)', '    GetInputQuantizationParams', '    GetOutputQuantizationParams', '    GetPassRegionEnd', '    GetPassRegionEndDequantized', '    GetSaturationRegionBegin', '    Tanh(double max_abs_err)'];
CUDAException.h;C++;pytorch-master/pytorch-master/c10/cuda; 31;  7; 4;20;  0; 0;0;0;0;0;0.00;0;['    TanhFunctor'];['    GetOutputQuantizationParams', '    operator()(const int n,const T *x,T *y)', '    TanhFunctor'];
CUDAMathCompat.h;C++;pytorch-master/pytorch-master/c10/cuda; 119;  3; 1;13;  0; 112;0;0;0;0;0.00;0;['    GetTanhGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTanhGradient', '    GetGradientDefs', '    Forward(const std::vector & Y_dims,const std::vector &,const float *Y,const float *dY,float *dX,CPUContext *)', '    vector'];
CUDAGuardImpl.h;C++;pytorch-master/pytorch-master/c10/cuda/impl; 154;  10; 17;8;  121; 0;60;59;86;60;0.08;18;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUTanh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tanh', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanhGradient'];
Export.h;C++;pytorch-master/pytorch-master/c10/macros; 116;  56; 14;49;  0; 17;0;0;0;0;0.00;0;[];['    operator()(const int N,const T *X,T *Y,Context *context)', '    Forward(const std::vector & Y_dims,const std::vector & dY_dims,const T *Y,const T *dY,T *dX,Context *context)'];
InlineDeviceGuard_test.cpp;C++;pytorch-master/pytorch-master/c10/test/core/impl; 192;  19; 17;3;  153; 0;100;45;80;53;0.12;15;[];[];
bfloat16_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 162;  22; 34;2;  106; 0;55;52;45;41;0.21;10;[];['    TEST(Tanh,TanhUnitTest)'];
exception_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 20;  1; 2;6;  9; 3;2;6;1;10;0.11;2;['    Tarjans'];['    NodeWrapper(NodeRef n)', '    NodeWrapper', '    connect(WrappedGraph::NodeRef n)', '    connect(n)', '    Tarjans(Graph *g)', '    unwrapSubgraph(const WrappedSubgraph & wrappedSubgraph)'];
LeftRight_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 243;  24; 48;3;  172; 0;69;85;37;105;0.14;12;[];['    TEST(Tarjans,Simple)', '    TEST(Tarjans,WithEdgeStorage)', '    TEST(Tarjans,DAG)', '    TEST(Tarjans,Cycle)', '    TEST(Tarjans,Random)'];
ordered_preserving_dict_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 421;  23; 94;8;  296; 0;208;90;247;99;0.08;22;['    CheckResponseType', '    QueryType', '    WaitResponseType'];['    add(const std::string & key,int64_t value)', '    addHelper_(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    getHelper_(const std::string & key)', '    getPort', '    set(const std::string & key,const std::vector & data)', '    TCPStore(const std::string & masterAddr,PortType masterPort,int numWorkers,bool isServer,const std::chrono::milliseconds & timeout,bool waitWorkers)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    waitForWorkers', '    waitHelper_(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~TCPStore', '    addHandler(int socket)', '    checkHandler(int socket)', '    checkKeys(const std::vector & keys)', '    getHandler(int socket)', '    join', '    query(int socket)', '    run', '    setHandler(int socket)', '    stop', '    TCPStoreDaemon(int storeListenSocket)', '    waitHandler(int socket)', '    wakeupWaitingClients(const std::string & key)', '    ~TCPStoreDaemon'];
typeid_test.cpp;C++;pytorch-master/pytorch-master/c10/test/util; 130;  5; 21;4;  102; 0;67;43;54;44;0.05;12;['    TCPStore', '    TCPStoreDaemon'];['    add(const std::string & key,int64_t value)', '    addHelper_(const std::string & key,int64_t value)', '    check(const std::vector & keys)', '    get(const std::string & key)', '    getHelper_(const std::string & key)', '    getPort', '    TCPStore(const std::string & masterAddr,PortType masterPort,int numWorkers,bool isServer,const std::chrono::milliseconds & timeout,bool waitWorkers)', '    wait(const std::vector & keys)', '    wait(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    waitForWorkers', '    waitHelper_(const std::vector & keys,const std::chrono::milliseconds & timeout)', '    ~TCPStore', '    addHandler(int socket)', '    checkHandler(int socket)', '    checkKeys(const std::vector & keys)', '    controlPipeFd_', '    getHandler(int socket)', '    join', '    query(int socket)', '    run', '    setHandler(int socket)', '    stop', '    TCPStoreDaemon(int storeListenSocket)', '    waitHandler(int socket)', '    wakeupWaitingClients(const std::string & key)', '    ~TCPStoreDaemon'];
AlignOf.h;C++;pytorch-master/pytorch-master/c10/util; 173;  45; 21;11;  94; 6;1;80;0;42;0.48;0;[];['    TEST(TCPStoreTest,testHelper)', '    TEST(TCPStoreTest,testHelperPrefix)', '    testHelper(const std::string & prefix)'];
Backtrace.cpp;C++;pytorch-master/pytorch-master/c10/util; 202;  10; 6;28;  8; 163;1;6;1;2;1.25;1;[];['    mkstemps(char *tmpl,int suffix_len)', '    begin', '    end', '    close', '    file', '    name', '    operator=', '    sync', '    TempFile', '    TempFile(const std::string & t,int suffix)', '    write(const std::string & str)', '    ~TempFile'];
C++17.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    try_make_tempfile(std::string name_prefix)', '    make_tempfile(std::string name_prefix)'];
Deprecated.h;C++;pytorch-master/pytorch-master/c10/util; 101;  33; 9;46;  0; 35;0;0;0;0;0.00;0;[];[];
Flags.h;C++;pytorch-master/pytorch-master/c10/util; 228;  66; 24;84;  20; 78;1;15;1;13;3.30;2;[];['    tensor_info_call_registry_', '    type_call_registry_', '    empty(at::IntArrayRef dims,at::TensorOptions options)', '    GetInt8TensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetInt8TensorType(const void *c)', '    GetTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetTensorInfoFunction(TypeIdentifier id)', '    GetTensorType(const void *c)', '    GetTypeCallFunction(TypeIdentifier id)', '    RegisterTensorInfoFunction(TypeIdentifier id,TensorInfoCall c)', '    RegisterTypeCallFunction(TypeIdentifier id,TypeCall c)', '    ReinitializeAndCopyFrom(Tensor *t,at::TensorOptions options,const Tensor & src,bool async)', '    ReinitializeTensor(Tensor *tensor,at::IntArrayRef dims,at::TensorOptions options)', '    TensorVectorResize(std::vector & tensors,int size,DeviceType type)', '    CopyFrom(const Tensor & src,bool async)', '    enforce_invariants', '    operator at::Tensor', '    operator at::Tensor', '    Tensor(at::Tensor tensor)', '    MetaStr(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    TensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    ~TensorPrinter', '    sizeBytes(const Blob & blob)', '    _typeMetaDataInstance'];
FunctionRef.h;C++;pytorch-master/pytorch-master/c10/util; 65;  22; 11;1;  31; 0;8;24;3;11;0.71;5;[];['    apply(variable_list)', '    apply(variable_list)', '    CopySlices(const Variable & base_var,at::TensorGeometry view_,std::shared_ptr fn_)', '    release_variables'];
IdWrapper.h;C++;pytorch-master/pytorch-master/c10/util; 77;  23; 11;13;  31; 0;6;21;6;21;0.74;4;[];[];
LeftRight.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];['    _base', '    _register_hook(std::function hook)', '    enforce_invariants', '    grad_fn', '    is_view', '    name', '    print', '    remove_hook(unsigned pos)', '    tensor_data', '    toString', '    variable_data'];
Logging.h;C++;pytorch-master/pytorch-master/c10/util; 310;  73; 39;135;  70; 7;23;36;28;39;1.04;12;[];['    almost_equal(at::Tensor left,T right,T tolerance)', '    exactly_equal(at::Tensor left,T right)', '    TEST(TensorTest,ToDtype)', '    TEST(TensorTest,ToTensorAndTensorAttributes)', '    TEST(TensorTest,ToOptionsWithRequiresGrad)', '    TEST(TensorTest,ToDoesNotCopyWhenOptionsAreAllTheSame)', '    TEST(TensorTest,AtTensorCtorScalar)', '    TEST(TensorTest,AtTensorCtorSingleDim)', '    TEST(TensorTest,TorchTensorCtorScalarIntegralType)', '    TEST(TensorTest,TorchTensorCtorScalarFloatingType)', '    TEST(TensorTest,TorchTensorCtorScalarBoolType)', '    TEST(TensorTest,TorchTensorCtorSingleDimIntegralType)', '    TEST(TensorTest,TorchTensorCtorSingleDimFloatingType)', '    TEST(TensorTest,TorchTensorCtorSingleDimBoolType)', '    TEST(TensorTest,TorchTensorCtorMultiDimIntegralType)', '    TEST(TensorTest,TorchTensorCtorMultiDimFloatingType)', '    TEST(TensorTest,TorchTensorCtorMultiDimBoolType)', '    TEST(TensorTest,TorchTensorCtorMultiDimWithOptions)', '    TEST(TensorTest,TorchTensorCtorMultiDimErrorChecks)', '    TEST(TensorTest,TorchTensorCtorMultiDim_CUDA)', '    TEST(TensorTest,TorchTensorCtorZeroSizedDim)', '    TEST(TensorTest,TorchTensorCtorWithoutSpecifyingDtype)', '    TEST(TensorTest,TorchTensorCtorWithNonDtypeOptions)', '    TEST(TensorTest,Arange)', '    TEST(TensorTest,PrettyPrintTensorDataContainer)', '    TEST(TensorTest,TensorDataContainerCallingAccessorOfWrongType)', '    TEST(TensorTest,FromBlob)', '    TEST(TensorTest,FromBlobUsesDeleter)', '    TEST(TensorTest,FromBlobWithStrides)', '    TEST(TensorTest,Item)', '    TEST(TensorTest,Item_CUDA)', '    TEST(TensorTest,DataPtr)', '    TEST(TensorTest,Data)', '    TEST(TensorTest,BackwardAndGrad)', '    TEST(TensorTest,BackwardCreatesOnesGrad)', '    TEST(TensorTest,BackwardNonScalarOutputs)', '    TEST(TensorTest,IsLeaf)', '    TEST(TensorTest,OutputNr)', '    TEST(TensorTest,Version)', '    TEST(TensorTest,Detach)', '    TEST(TensorTest,DetachInplace)', '    TEST(TensorTest,SetData)', '    TEST(TensorTest,RequiresGradInplace)', '    test_Arange_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorMultiDim_CUDA_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorMultiDimFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorScalarFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorSingleDimFloatingType_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorWithNonDtypeOptions_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorWithoutSpecifyingDtype_expected_dtype(c10::ScalarType default_dtype)', '    test_TorchTensorCtorZeroSizedDim_expected_dtype(c10::ScalarType default_dtype)'];
Metaprogramming.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;[];[];
Optional.cpp;C++;pytorch-master/pytorch-master/c10/util; 1;  0; 0;1;  0; 0;0;0;0;0;0.00;0;['    final', '    TensorPrinter'];['    GetTensorInfo(const void *c,size_t *capacity,DeviceOption *device)', '    GetTensorInfoFunction(TypeIdentifier id)', '    GetTypeCallFunction(TypeIdentifier id)', '    RegisterTensorInfoFunction(TypeIdentifier id,TensorInfoCall c)', '    RegisterTypeCallFunction(TypeIdentifier id,TypeCall c)', '    ReinitializeAndCopyFrom(Tensor *t,at::TensorOptions options,const Tensor & src,bool async)', '    ReinitializeTensor(Tensor *tensor,at::IntArrayRef dims,at::TensorOptions options)', '    TensorCPUFromValues(at::IntArrayRef dims,at::ArrayRef values)', '    TensorVectorResize(std::vector & tensors,int size,DeviceType type)', '    device', '    computeDispatchKey', '    CopyItemsFromCPU', '    Alias', '    canonical_axis_index(int axis_index)', '    Clone', '    CopyFrom(const Tensor & src,bool async)', '    data', '    DebugString', '    defined', '    dim', '    dim(const int i)', '    dim32(const int i)', '    dtype', '    dtype_initialized', '    enforce_invariants', '    Extend(int64_t num,float growthPct)', '    ExtendTo(int64_t num,float growthPct)', '    FreeMemory', '    GetDevice', '    GetDeviceType', '    getIntrusivePtr', '    is_contiguous(at::MemoryFormat memory_format)', '    is_same(const Tensor & other)', '    IsType', '    itemsize', '    meta', '    mutable_data', '    nbytes', '    ndim', '    numel', '    operator at::Tensor', '    operator at::Tensor', '    operator bool', '    operator=', '    operator=', '    raw_data', '    raw_mutable_data(const TypeMeta & meta)', '    raw_mutable_data', '    ReserveSpace(const T & outer_dim)', '    Reshape(const vector & dims)', '    Reshape(const vector & dims)', '    Resize(Ts,...)', '    ResizeLike(const Tensor & src_tensor)', '    ShareData(const Tensor & src)', '    ShareExternalPointer(T *src,size_t capacity,MemoryDeleter d)', '    ShareExternalPointer(at::DataPtr,size_t capacity)', '    ShareExternalPointer(void *src,const TypeMeta & data_type,size_t capacity,MemoryDeleter d)', '    ShareExternalPointer(at::DataPtr,const TypeMeta & data_type,size_t capacity)', '    ShrinkTo(int64_t outer_dim)', '    size', '    size(const int i)', '    size_between_dim(int k,int l)', '    size_from_dim(int k)', '    size_to_dim(int k)', '    sizes', '    storage', '    storage', '    storage_initialized', '    stride(int64_t dim)', '    strides', '    Tensor(const Tensor & other,Unsafe _)', '    Tensor', '    Tensor', '    Tensor', '    Tensor(at::Device device)', '    Tensor(at::IntArrayRef dims,DeviceType type)', '    Tensor(at::IntArrayRef dims,at::Device device)', '    Tensor(const vector & dims,DeviceType type)', '    Tensor(const Tensor & src,DeviceType type)', '    Tensor(at::Tensor tensor)', '    unsafeGetTensorImpl', '    UnsafeSharedInstance', '    CopyFrom', '    dtype', '    getIntrusivePtr', '    is_contiguous', '    numel', '    sizes', '    MetaStr(const Tensor & tensor)', '    Print(const Tensor & tensor)', '    PrintMeta(const Tensor & tensor)', '    TensorPrinter(const std::string & tensor_name,const std::string & file_name,int limit)', '    ~TensorPrinter', '    uninitialized', '    Make'];
qint32.h;C++;pytorch-master/pytorch-master/c10/util; 15;  4; 3;2;  7; 0;1;5;1;9;0.57;1;['    DimArg', '    FunctionCall', '    Tensor'];['    params(,...)', '    Compute(const std::string & func_name,const std::vector & dim_args,const std::function & body_func)', '    make(Tensor *tensor,const std::vector & params)', '    dim', '    DimArg(const ExprHandle & dim)', '    DimArg(const ExprHandle & dim,const std::string & name_hint)', '    name_hint', '    DefaultMutator(const std::vector & new_params)', '    func_name', '    FunctionCall(Tensor *tensor,const std::vector & params)', '    tensor', '    tensor', '    arg(int index)', '    args', '    body', '    call(const std::vector & args)', '    call(const Ts &,...)', '    call(const Ts &,...)', '    dim(int index)', '    dims', '    func_var', '    function', '    ndim', '    operator()(const Ts &,...)', '    operator()(const Ts &,...)', '    output_index', '    Tensor(Function *function,int output_index)'];
reverse_iterator.h;C++;pytorch-master/pytorch-master/c10/util; 296;  52; 48;9;  184; 4;44;98;42;71;0.28;34;[];[];
string_utils.h;C++;pytorch-master/pytorch-master/c10/util; 103;  5; 5;11;  7; 79;0;2;5;6;0.71;0;[];[];
tempfile.h;C++;pytorch-master/pytorch-master/c10/util; 105;  20; 8;20;  17; 47;6;10;7;6;1.18;2;[];['    apply(variable_list)', '    apply(variable_list)', '    CopySlices(const Variable & base_var,at::TensorGeometry view_,std::shared_ptr fn_)', '    release_variables'];
Type.h;C++;pytorch-master/pytorch-master/c10/util; 28;  6; 7;10;  7; 2;1;5;1;3;0.86;1;[];[];
TypeIndex.h;C++;pytorch-master/pytorch-master/c10/util; 170;  16; 19;64;  47; 60;16;26;8;18;0.34;9;[];[];
TypeTraits.h;C++;pytorch-master/pytorch-master/c10/util; 133;  48; 25;3;  58; 0;2;50;2;64;0.83;0;[];[];
aten_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/aten; 37;  4; 9;2;  26; 0;3;20;3;7;0.15;3;[];['    recursive_apply(IntArrayRef sizes,ScalarType scalarType,int64_t dim,PyObject *fn,std::array strided_data)', '    apply_(Tensor & self,PyObject *fn)', '    map2_(Tensor & self,const Tensor & x_,const Tensor & y_,PyObject *fn)', '    map_(Tensor & self,const Tensor & other_,PyObject *fn)', '    step(int dim)', '    StridedData(const Tensor & tensor)'];
common.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 5;  0; 2;1;  2; 0;2;2;2;14;0.00;2;[];['    apply_(at::Tensor & self,PyObject *fn)', '    map2_(at::Tensor & self,const at::Tensor & x_,const at::Tensor & y_,PyObject *fn)', '    map_(at::Tensor & self,const at::Tensor & other_,PyObject *fn)'];
fp16_fma_slow.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 541;  55; 64;9;  421; 0;264;120;211;73;0.13;21;[];['    TEST(TensorTest,AllocatesTensorOnTheCorrectDevice_MultiCUDA)', '    TEST(TensorTest,ToDevice_MultiCUDA)', '    TEST(TensorTest,ToTensorAndTensorAttributes_MultiCUDA)', '    TEST(TensorTest,ToDoesNotCopyWhenOptionsAreAllTheSame_CUDA)', '    TEST(TensorTest,ToDeviceAndDtype_MultiCUDA)', '    TEST(TensorTest,MagmaInitializesCorrectly_CUDA)'];
lengths_reducer_fused_8bit_rowwise_fp16_fake_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 722;  57; 66;1;  655; 0;544;560;14;113;0.09;28;[];['    findContiguous(const at::IntArrayRef & sizes,const at::IntArrayRef & strides)', '    hash(const TensorDesc & spec)', '    operator<<(std::ostream & out,const TensorDesc & d)', '    lastIsContiguous', '    nDim', '    operator!=(const TensorDesc & desc)', '    operator==(const TensorDesc & desc)', '    TensorDesc(const at::ScalarType & type,const at::IntArrayRef & sizes,const at::IntArrayRef & strides)', '    TensorDesc(const at::Tensor & t)', '    TensorDesc(const c10::TensorTypePtr & type)', '    scalar_type', '    sizes', '    strides', '    findContiguous', '    contiguity', '    TensorDesc(const at::ScalarType & type,const std::vector & contiguity)'];
spatial_batch_norm_fp16_fake_op.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/fakelowp; 12;  1; 5;3;  4; 0;2;4;2;9;0.25;2;[];['    getDtypeNames(at::ScalarType scalarType)', '    initializeDtypes'];
allgather_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 61;  18; 7;2;  37; 0;26;9;11;8;0.49;1;[];['    initializeDtypes'];
allreduce_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 168;  17; 15;8;  132; 0;83;43;35;56;0.13;8;[];['    flatten_sparse_tensors(at::TensorList tensors)', '    get_indices(const at::Tensor & t)', '    get_values(const at::Tensor & t)', '    reorder_tensors_like(std::vector & tensors,TensorList order)', '    take_tensors(TensorList tensors,size_t size_limit,bool fine_grained)', '    unflatten_sparse_tensors(const at::Tensor & flat_indices,const at::Tensor & flat_values,at::TensorList tensors)'];
broadcast_ops.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 112;  13; 20;8;  73; 0;22;35;52;90;0.18;5;[];['    flatten_dense_tensors(at::TensorList tensors)', '    reorder_tensors_like(std::vector & tensors,at::TensorList order)', '    take_tensors(at::TensorList tensors,size_t size_limit,bool fine_grained)', '    unflatten_dense_tensors(const at::Tensor & flat,at::TensorList tensors)', '    unflatten_sparse_tensors(const at::Tensor & flat_indices,const at::Tensor & flat_values,at::TensorList tensors)', '    narrow', '    push_back', '    reserve', '    type', '    type'];
common_world_ops.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 29;  4; 8;2;  18; 0;0;11;0;11;0.22;1;[];[];
context.h;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 3;  0; 1;2;  0; 0;0;0;0;0;0.00;0;[];['    f', '    runner', '    tensor_sizes', '    TEST(TensorIndexingTest,Slice)', '    TEST(TensorIndexingTest,TensorIndex)', '    TEST(TensorIndexingTest,TestNoIndices)', '    TEST(TensorIndexingTest,TestAdvancedIndexingWithArrayRefOfTensor)', '    TEST(TensorIndexingTest,TestSingleInt)', '    TEST(TensorIndexingTest,TestMultipleInt)', '    TEST(TensorIndexingTest,TestNone)', '    TEST(TensorIndexingTest,TestStep)', '    TEST(TensorIndexingTest,TestStepAssignment)', '    TEST(TensorIndexingTest,TestBoolIndices)', '    TEST(TensorIndexingTest,TestBoolIndicesAccumulate)', '    TEST(TensorIndexingTest,TestMultipleBoolIndices)', '    TEST(TensorIndexingTest,TestByteMask)', '    TEST(TensorIndexingTest,TestByteMaskAccumulate)', '    TEST(TensorIndexingTest,TestMultipleByteMask)', '    TEST(TensorIndexingTest,TestByteMask2d)', '    TEST(TensorIndexingTest,TestIntIndices)', '    TEST(TensorIndexingTest,TestIntIndices2d)', '    TEST(TensorIndexingTest,TestIntIndicesBroadcast)', '    TEST(TensorIndexingTest,TestEmptyIndex)', '    TEST(TensorIndexingTest,TestEmptyNdimIndex)', '    TEST(TensorIndexingTest,TestEmptyNdimIndex_CUDA)', '    TEST(TensorIndexingTest,TestEmptyNdimIndexBool)', '    TEST(TensorIndexingTest,TestEmptyNdimIndexBool_CUDA)', '    TEST(TensorIndexingTest,TestEmptySlice)', '    TEST(TensorIndexingTest,TestEmptySlice_CUDA)', '    TEST(TensorIndexingTest,TestIndexGetitemCopyBoolsSlices)', '    TEST(TensorIndexingTest,TestIndexSetitemBoolsSlices)', '    TEST(TensorIndexingTest,TestIndexScalarWithBoolMask)', '    TEST(TensorIndexingTest,TestIndexScalarWithBoolMask_CUDA)', '    TEST(TensorIndexingTest,TestSetitemExpansionError)', '    TEST(TensorIndexingTest,TestGetitemScalars)', '    TEST(TensorIndexingTest,TestSetitemScalars)', '    TEST(TensorIndexingTest,TestBasicAdvancedCombined)', '    TEST(TensorIndexingTest,TestIntAssignment)', '    TEST(TensorIndexingTest,TestByteTensorAssignment)', '    TEST(TensorIndexingTest,TestVariableSlicing)', '    TEST(TensorIndexingTest,TestEllipsisTensor)', '    TEST(TensorIndexingTest,TestOutOfBoundIndex)', '    TEST(TensorIndexingTest,TestZeroDimIndex)', '    TEST(NumpyTests,TestNoneIndex)', '    TEST(NumpyTests,TestEmptyFancyIndex)', '    TEST(NumpyTests,TestEllipsisIndex)', '    TEST(NumpyTests,TestSingleIntIndex)', '    TEST(NumpyTests,TestSingleBoolIndex)', '    TEST(NumpyTests,TestBooleanShapeMismatch)', '    TEST(NumpyTests,TestBooleanIndexingOnedim)', '    TEST(NumpyTests,TestBooleanAssignmentValueMismatch)', '    TEST(NumpyTests,TestBooleanIndexingTwodim)', '    TEST(NumpyTests,TestBooleanIndexingWeirdness)', '    TEST(NumpyTests,TestBooleanIndexingWeirdnessTensors)', '    TEST(NumpyTests,TestBooleanIndexingAlldims)', '    TEST(NumpyTests,TestBooleanListIndexing)', '    TEST(NumpyTests,TestEverythingReturnsViews)', '    TEST(NumpyTests,TestBroaderrorsIndexing)', '    TEST(NumpyTests,TestTrivialFancyOutOfBounds)', '    TEST(NumpyTests,TestIndexIsLarger)', '    TEST(NumpyTests,TestBroadcastSubspace)'];
store_handler.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/gloo; 25;  2; 5;1;  19; 0;5;11;5;5;0.11;3;[];['    sizes(size_t nDim)', '    strides(size_t nDim)'];
cuda_nccl_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/nccl; 275;  11; 37;3;  228; 0;127;93;106;110;0.05;21;[];['    _typeMetaDataInstance'];
context_test.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/opencl; 12;  2; 5;1;  6; 0;0;5;0;3;0.33;1;[];['    scale', '    Tensor', '    zero_point'];
prof_dag_stats_op.h;C++;pytorch-master/pytorch-master/caffe2/contrib/prof; 88;  5; 11;7;  67; 0;24;24;49;39;0.07;4;[];['    TEST(Caffe2ToPytorch,SimpleLegacy)', '    TEST(Caffe2ToPytorch,Simple)', '    TEST(Caffe2ToPytorch,ExternalData)', '    TEST(Caffe2ToPytorch,Op)', '    TEST(Caffe2ToPytorch,PartiallyInitialized)', '    TEST(Caffe2ToPytorch,MutualResizes)', '    TEST(PytorchToCaffe2,Op)', '    TEST(PytorchToCaffe2,SharedStorageRead)', '    TEST(PytorchToCaffe2,SharedStorageWrite)', '    TEST(PytorchToCaffe2,MutualResizes)', '    TEST(PytorchToCaffe2,Strided)', '    TEST(PytorchToCaffe2,InplaceStrided)', '    TEST(PytorchToCaffe2,NonRegularTensor)', '    TEST(Caffe2ToPytorch,NonPOD)', '    TEST(Caffe2ToPytorch,Nullptr)', '    TEST(PytorchToCaffe2,Nullptr)'];
tensorrt_op_trt.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 258;  24; 24;6;  206; 0;150;95;100;65;0.12;6;[];['    random_tensor_for_type(at::ScalarType scalar_type)', '    TEST(TensorIteratorTest,CPUScalar)', '    TEST(TensorIteratorTest,CPUScalarInputs)', '    TEST(TensorIteratorTest,MixedDevices)', '    TEST(TensorIteratorTest,SerialLoopUnary_Byte)', '    TEST(TensorIteratorTest,SerialLoopUnary_Char)', '    TEST(TensorIteratorTest,SerialLoopUnary_Short)', '    TEST(TensorIteratorTest,SerialLoopUnary_Int)', '    TEST(TensorIteratorTest,SerialLoopUnary_Long)', '    TEST(TensorIteratorTest,SerialLoopUnary_Float)', '    TEST(TensorIteratorTest,SerialLoopUnary_Double)', '    TEST(TensorIteratorTest,SerialLoopBinary_Byte)', '    TEST(TensorIteratorTest,SerialLoopBinary_Char)', '    TEST(TensorIteratorTest,SerialLoopBinary_Short)', '    TEST(TensorIteratorTest,SerialLoopBinary_Int)', '    TEST(TensorIteratorTest,SerialLoopBinary_Long)', '    TEST(TensorIteratorTest,SerialLoopBinary_Float)', '    TEST(TensorIteratorTest,SerialLoopBinary_Double)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Byte)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Char)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Short)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Int)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Long)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Float)', '    TEST(TensorIteratorTest,SerialLoopPointwise_Double)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopUnaryNoOutput_Double)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopBinaryNoOutput_Double)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Byte)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Char)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Short)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Int)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Long)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Float)', '    TEST(TensorIteratorTest,SerialLoopPoinwiseNoOutput_Double)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Byte)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Char)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Short)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Int)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Long)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Float)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Double)', '    TEST(TensorIteratorTest,ComparisonLoopBinary_Bool)', '    TEST(TensorIteratorTest,SerialLoopSingleThread)', '    TEST(TensorIteratorTest,InputDType)', '    TEST(TensorIteratorTest,ComputeCommonDTypeInputOnly)', '    TEST(TensorIteratorTest,DoNotComputeCommonDTypeInputOnly)', '    TEST(TensorIteratorTest,DoNotComputeCommonDTypeIfOutputIsUndefined)', '    TEST(TensorIteratorTest,FailNonPromotingBinaryOp)'];
trt_utils.cc;C++;pytorch-master/pytorch-master/caffe2/contrib/tensorrt; 62;  2; 2;8;  40; 12;27;17;8;9;0.05;1;[];['    initializeLayouts'];
ctc_op_gpu.cpp;C++;pytorch-master/pytorch-master/caffe2/contrib/warpctc; 18;  0; 3;3;  12; 0;4;8;4;8;0.00;2;[];['    initializeLayouts'];
blob.h;C++;pytorch-master/pytorch-master/caffe2/core; 133;  13; 16;14;  92; 0;52;22;41;16;0.14;9;[];['    recursive_to_list(char *data,IntArrayRef sizes,IntArrayRef strides,int64_t dim,ScalarType scalarType,int64_t elementSize)', '    tensor_to_list(const Tensor & tensor)'];
blob_serialization_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/core; 10;  1; 2;3;  5; 0;0;5;0;4;0.20;0;[];['    tensor_to_list(const at::Tensor & tensor)'];
blob_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 1253;  67; 109;77;  1010; 0;668;383;858;513;0.07;102;[];['    initializeMemoryFormats'];
common_cudnn.h;C++;pytorch-master/pytorch-master/caffe2/core; 321;  36; 29;41;  205; 15;88;87;97;77;0.18;19;[];['    initializeMemoryFormats'];
common_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 45;  7; 11;7;  22; 0;16;10;10;9;0.32;2;[];['    as_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    backendToBackendOfDeviceType(Backend b,DeviceType d)', '    check_base_legacy_new(c10::DispatchKey dispatch_key,at::Layout expected_layout)', '    check_legacy_ctor_device(c10::DispatchKey dispatch_key,c10::optional device)', '    compute_sizes(PyObject *seq)', '    denseTypeIdWithDefault(PythonArgs & r,int64_t device_idx,c10::DispatchKey dispatch_key)', '    dispatch_full(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,Scalar fill_value,const optional & device,IntArrayRef sizes)', '    dispatch_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    dispatch_zeros(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    indexing_tensor_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    infer_scalar_type(PyObject *obj)', '    internal_new_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device_opt,PyObject *data,bool copy_variables,bool copy_numpy,bool type_inference,bool pin_memory)', '    legacy_new_from_sequence(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    legacy_sparse_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_sparse_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    maybe_initialize_cuda(c10::DispatchKey dispatch_key)', '    maybe_initialize_cuda(const Device device)', '    new_from_data_copy(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    new_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_with_sizes(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const optional & device,IntArrayRef sizes)', '    new_with_storage(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,Storage storage)', '    new_with_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const Tensor & other)', '    options(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,const c10::optional & device)', '    recursive_store(char *data,IntArrayRef sizes,IntArrayRef strides,int64_t dim,ScalarType scalarType,int elementSize,PyObject *obj)', '    sparse_coo_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    typeIdWithDefault(PythonArgs & r,int64_t device_idx,c10::DispatchKey dispatch_key)'];
context_base.h;C++;pytorch-master/pytorch-master/caffe2/core; 168;  18; 31;17;  106; 0;40;50;27;30;0.17;11;[];['    as_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    indexing_tensor_from_data(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,c10::optional device,PyObject *data)', '    legacy_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    legacy_tensor_new(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_ones(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    new_tensor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    sparse_coo_tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)', '    tensor_ctor(c10::DispatchKey dispatch_key,at::ScalarType scalar_type,PyObject *args,PyObject *kwargs)'];
cudnn_wrappers.h;C++;pytorch-master/pytorch-master/caffe2/core; 199;  75; 27;5;  93; 0;42;57;75;74;0.81;18;[];['    is_numpy_int(PyObject *obj)', '    is_numpy_scalar(PyObject *obj)', '    tensor_from_cuda_array_interface(PyObject *obj)', '    tensor_from_numpy(PyObject *obj)', '    tensor_to_numpy(const at::Tensor & tensor)'];
event.h;C++;pytorch-master/pytorch-master/caffe2/core; 382;  39; 52;60;  223; 16;69;126;77;92;0.17;30;[];[];
event_test.cc;C++;pytorch-master/pytorch-master/caffe2/core; 40;  1; 9;3;  28; 0;17;9;17;8;0.04;2;[];['    eq_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    eq_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    eq_quantized_cpu(const Tensor & self,Scalar other)', '    eq_quantized_cpu(const Tensor & self,const Tensor & other)', '    ge_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    ge_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    ge_quantized_cpu(const Tensor & self,Scalar other)', '    ge_quantized_cpu(const Tensor & self,const Tensor & other)', '    gt_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    gt_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    gt_quantized_cpu(const Tensor & self,Scalar other)', '    gt_quantized_cpu(const Tensor & self,const Tensor & other)', '    le_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    le_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    le_quantized_cpu(const Tensor & self,Scalar other)', '    le_quantized_cpu(const Tensor & self,const Tensor & other)', '    lt_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar other)', '    lt_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    lt_quantized_cpu(const Tensor & self,Scalar other)', '    lt_quantized_cpu(const Tensor & self,const Tensor & other)', '    ne_out_quantized_cpu(Tensor & out,const Tensor & self,Scalar)', '    ne_out_quantized_cpu(Tensor & out,const Tensor & self,const Tensor & other)', '    ne_quantized_cpu(const Tensor & self,Scalar other)', '    ne_quantized_cpu(const Tensor & self,const Tensor & other)', '    quantized_resize_cpu_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)'];
flags.h;C++;pytorch-master/pytorch-master/caffe2/core; 4;  0; 1;3;  0; 0;0;0;0;0;0.00;0;[];['    TEST(TensorOptionsTest,DefaultsToTheRightValues)', '    TEST(TensorOptionsTest,UtilityFunctionsReturnTheRightTensorOptions)', '    TEST(TensorOptionsTest,ConstructsWellFromCPUTypes)', '    TEST(TensorOptionsTest,ConstructsWellFromCPUTensors)', '    TEST(TensorOptionsTest,ConstructsWellFromVariables)', '    TEST(DeviceTest,ParsesCorrectlyFromString)', '    TEST(DefaultDtypeTest,CanSetAndGetDefaultDtype)', '    TEST(DefaultDtypeTest,NewTensorOptionsHasCorrectDefault)', '    TEST(DefaultDtypeTest,NewTensorsHaveCorrectDefaultDtype)'];
common_miopen.h;C++;pytorch-master/pytorch-master/caffe2/core/hip; 178;  37; 18;31;  95; 0;37;41;50;42;0.39;12;[];['    CPUDevice', '    CUDADevice(DeviceIndex index)', '    TEST(TensorOptionsTest,ConstructsWellFromCUDATypes_CUDA)', '    TEST(TensorOptionsTest,ConstructsWellFromCUDATensors_MultiCUDA)'];
init_denormals.cc;C++;pytorch-master/pytorch-master/caffe2/core; 38;  0; 0;5;  0; 36;0;0;0;0;0.00;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUTensorProtosDBInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorProtosDBInput'];
int8_serialization.cc;C++;pytorch-master/pytorch-master/caffe2/core; 107;  3; 10;6;  91; 0;57;27;41;21;0.03;2;['    final'];['    BlobSetTensor(& [i] prefetched_blobs_,deserializer)', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    CopyPrefetched', '    device', '    Prefetch', '    TensorProtosDBInput(const OperatorDef & operator_def,Workspace *ws)', '    ~TensorProtosDBInput', '    CopyPrefetched', '    TensorProtosDBInput(const OperatorDef & operator_def,Workspace *ws)'];
memonger.h;C++;pytorch-master/pytorch-master/caffe2/core; 29;  2; 7;7;  15; 0;0;15;0;4;0.13;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDATensorProtosDBInput'];
net.cc;C++;pytorch-master/pytorch-master/caffe2/core; 238;  18; 27;11;  188; 0;95;65;94;48;0.10;16;[];['    getTHPQScheme(at::QScheme qscheme)', '    initializeQSchemes'];
net_async_scheduling.cc;C++;pytorch-master/pytorch-master/caffe2/core; 297;  39; 30;2;  227; 0;156;45;116;41;0.17;13;[];['    initializeQSchemes'];
net_async_task_future.cc;C++;pytorch-master/pytorch-master/caffe2/core; 110;  4; 18;3;  86; 0;57;18;36;16;0.05;10;[];['    backend_to_string(const at::Backend & backend)', '    options_from_string(const std::string & str)', '    options_to_string(const at::TensorOptions options)', '    type_to_string(const at::DeprecatedTypeProperties & type)'];
net_async_tracing.cc;C++;pytorch-master/pytorch-master/caffe2/core; 501;  35; 57;3;  410; 0;258;102;213;113;0.09;35;[];['    options_from_string(const std::string & str)', '    options_to_string(const at::TensorOptions options)', '    type_to_string(const at::DeprecatedTypeProperties & type)'];
net_dag_utils.h;C++;pytorch-master/pytorch-master/caffe2/core; 69;  10; 13;22;  28; 0;4;26;1;21;0.36;0;[];[];
net_parallel.h;C++;pytorch-master/pytorch-master/caffe2/core; 85;  2; 22;5;  58; 0;4;39;3;37;0.03;4;['    GenericPackedTensorAccessor', '    GenericPackedTensorAccessor', '    GenericPackedTensorAccessorBase', '    TensorAccessor', '    TensorAccessor', '    TensorAccessorBase'];['    GenericPackedTensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessor(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    data', '    data', '    GenericPackedTensorAccessorBase(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    GenericPackedTensorAccessorBase(PtrType data_,const source_index_t *sizes_,const source_index_t *strides_)', '    size(index_t i)', '    stride(index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    operator[](index_t i)', '    TensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    TensorAccessor(PtrType data_,const index_t *sizes_,const index_t *strides_)', '    data', '    data', '    size(index_t i)', '    sizes', '    stride(index_t i)', '    strides', '    TensorAccessorBase(PtrType data_,const index_t *sizes_,const index_t *strides_)'];
net_simple_refcount.h;C++;pytorch-master/pytorch-master/caffe2/core; 59;  25; 10;12;  14; 0;1;9;1;8;1.79;0;[];['    all_strides_match(TensorList tensors)', '    make_index_iterator(const AdvancedIndex & info)', '    make_index_put_iterator(const AdvancedIndex & info,const Tensor & value)', '    make_info(Tensor self,TensorList orig)', '    masked_fill_impl_cpu(Tensor & self,const Tensor & mask,Scalar value)', '    reshape_indexer(const Tensor & index,int64_t dims_before,int64_t dims_after)', '    restride_src(const Tensor & src,int64_t dims_before,int64_t dims_indexed,IntArrayRef replacement_shape)', '    shapes_as_str(TensorList tensors)', '    _gather_sparse_backward(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & grad)', '    _index_put_impl_(Tensor & self,TensorList indices,const Tensor & value,const bool accumulate,const bool unsafe)', '    gather_cpu(const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    gather_out_cpu(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index,bool sparse_grad)', '    index(const Tensor & self,TensorList indices)', '    index_add(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_add_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_copy(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_copy_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_fill(const Tensor & self,int64_t dim,const Tensor & index,Scalar source)', '    index_fill(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_fill_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    index_put(const Tensor & self,TensorList indices,const Tensor & value,bool accumulate)', '    index_put_(Tensor & self,TensorList indices,const Tensor & value,const bool accumulate)', '    index_select_cpu_(const Tensor & self,int64_t dim,const Tensor & index)', '    index_select_out_cpu_(Tensor & result,const Tensor & self,int64_t dim,const Tensor & index)', '    masked_fill(const Tensor & self,const Tensor & mask,Scalar source)', '    masked_fill(const Tensor & self,const Tensor & mask,const Tensor & source)', '    masked_fill__cpu(Tensor & self,const Tensor & mask,Scalar value)', '    masked_fill__cpu(Tensor & self,const Tensor & mask,const Tensor & value)', '    masked_scatter(const Tensor & self,const Tensor & mask,const Tensor & source)', '    nonzero_numpy(const Tensor & self)', '    scatter(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    scatter(const Tensor & self,int64_t dim,const Tensor & index,Scalar source)', '    scatter_add(const Tensor & self,int64_t dim,const Tensor & index,const Tensor & source)', '    scatter_add_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_cpu_(Tensor & self,int64_t dim,const Tensor & index,const Tensor & src)', '    scatter_fill_cpu_(Tensor & self,int64_t dim,const Tensor & index,Scalar src)', '    AdvancedIndex(const Tensor & src,TensorList indices_list)'];
OpClasses.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Generated; 767;  0; 196;1;  570; 0;135;326;192;264;0.00;196;[];['    gather_stub', '    gather_stub', '    operator=', '    index_put_accum_stub', '    index_put_accum_stub', '    operator=', '    index_put_stub', '    index_put_stub', '    operator=', '    index_stub', '    index_stub', '    operator=', '    masked_fill_stub', '    masked_fill_stub', '    operator=', '    operator=', '    scatter_add_stub', '    scatter_add_stub', '    operator=', '    scatter_fill_stub', '    scatter_fill_stub', '    operator=', '    scatter_stub', '    scatter_stub'];
BinaryMatchImpl.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Graph; 108;  16; 19;4;  72; 0;18;30;1;116;0.22;0;['    Tensor'];['    legacyExtractDispatchKey(const Tensor & t)', '    variable_excluded_from_dispatch', '    make_tensor(Args,...)', '    wrap_tensor_impl(c10::intrusive_ptr tensor_impl)', '    $', '    accessor', '    data', '    data_ptr', '    defined', '    dim', '    element_size', '    generic_packed_accessor', '    getIntrusivePtr', '    grad', '    grad', '    has_storage', '    is_alias_of(const at::Tensor & other)', '    is_contiguous(at::MemoryFormat memory_format)', '    is_non_overlapping_and_dense', '    is_same(const Tensor & other)', '    is_variable', '    itemsize', '    key_set', '    names', '    nbytes', '    ndimension', '    numel', '    operator=(const Tensor & x)', '    operator=(Tensor)', '    opt_names', '    packed_accessor', '    packed_accessor32', '    packed_accessor64', '    requires_grad', '    reset', '    scalar_type', '    set_requires_grad(bool requires_grad)', '    sizes', '    storage', '    storage_offset', '    strides', '    suggest_memory_format(bool channels_last_strides_exact_match)', '    Tensor', '    Tensor(c10::intrusive_ptr tensor_impl)', '    to(caffe2::TypeMeta type_meta,bool non_blocking,bool copy)', '    to(Device device,caffe2::TypeMeta type_meta,bool non_blocking,bool copy)', '    type', '    unsafeGetTensorImpl', '    unsafeReleaseTensorImpl', '    use_count', '    weak_use_count'];
Compiler.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Representations; 101;  6; 16;6;  78; 0;13;43;8;37;0.08;17;[];['    max_out_impl(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    min_out_impl(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _max_cpu(const Tensor & self,int64_t dim,bool keepdim)', '    _max_out_cpu(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _min_cpu(const Tensor & self,int64_t dim,bool keepdim)', '    _min_out_cpu(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    _s_where(const Tensor & condition,const Tensor & self,const Tensor & other)', '    argmax(const Tensor & self,Dimname dim,bool keepdim)', '    argmin(const Tensor & self,Dimname dim,bool keepdim)', '    argsort(const Tensor & self,Dimname dim,bool keepdim)', '    isfinite(const Tensor & self)', '    allclose(const Tensor & self,const Tensor & other,double rtol,double atol,bool equal_nan)', '    isclose(const Tensor & self,const Tensor & other,double rtol,double atol,bool equal_nan)', '    isinf(const Tensor & self)', '    isnan(const Tensor & self)', '    is_nonzero(const Tensor & self)', '    max(const Tensor & self,int64_t dim,bool keepdim)', '    max(const Tensor & self,Dimname dim,bool keepdim)', '    max_out(Tensor & max,Tensor & max_indices,const Tensor & self,int64_t dim,bool keepdim)', '    max_out(Tensor & max,Tensor & max_indices,const Tensor & self,Dimname dim,bool keepdim)', '    min(const Tensor & self,int64_t dim,bool keepdim)', '    min(const Tensor & self,Dimname dim,bool keepdim)', '    min_out(Tensor & min,Tensor & min_indices,const Tensor & self,int64_t dim,bool keepdim)', '    min_out(Tensor & min,Tensor & min_indices,const Tensor & self,Dimname dim,bool keepdim)', '    mode(const Tensor & self,int64_t dim,bool keepdim)', '    mode(const Tensor & self,Dimname dim,bool keepdim)', '    mode_out(Tensor & values,Tensor & indices,const Tensor & self,int64_t dim,bool keepdim)', '    mode_out(Tensor & values,Tensor & indices,const Tensor & self,Dimname dim,bool keepdim)', '    result', '    result', '    result', '    where(const Tensor & condition,const Tensor & self,const Tensor & other)', '    where(const Tensor & condition)'];
Common.h;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/include/nomnigraph/Support; 121;  27; 19;15;  61; 0;19;26;19;25;0.44;13;[];['    max_quant(const Tensor & self)', '    min_quant(const Tensor & self)', '    sort_quant(const Tensor & self,int64_t dim,bool descending)'];
NeuralNet.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/Representations; 363;  11; 39;3;  313; 0;196;109;146;95;0.04;27;[];['    max_stub', '    max_stub', '    operator=', '    min_stub', '    min_stub', '    operator=', '    operator=', '    where_kernel', '    where_kernel'];
MatchTest.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 37;  0; 5;3;  29; 0;0;0;0;1;0.00;0;[];['    compare_base_kernel(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim,const func_t & f)', '    max_kernel_impl(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim)', '    min_kernel_impl(Tensor & result,Tensor & indice,const Tensor & self,int64_t dim,bool keepdim)', '    where_kernel_impl(TensorIterator & iter,ScalarType condition_type)'];
test_util.cc;C++;pytorch-master/pytorch-master/caffe2/core/nomnigraph/tests; 129;  2; 11;3;  115; 0;87;44;58;39;0.02;8;[];['    ensure_has_index(Device device)', '    to_impl(const Tensor & self,const TensorOptions & options,bool non_blocking,bool copy)', '    to(const Tensor & self,const TensorOptions & options_,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,Device device,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,ScalarType dtype,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to(const Tensor & self,const Tensor & other,bool non_blocking,bool copy,c10::optional optional_memory_format)', '    to_dense_backward(const Tensor & grad,const Tensor & input_)', '    to_mkldnn_backward(const Tensor & grad,const Tensor & input_)'];
numa.h;C++;pytorch-master/pytorch-master/caffe2/core; 3;  0; 0;3;  0; 0;0;0;0;0;0.00;0;['    TensorDataContainerType'];['    str(,,,,,::c10::str __VA_ARGS__)', '    operator<<(std::ostream & stream,const TensorDataContainer & tensor_data_container)', '    compute_desired_dtype(c10::ScalarType scalar_type)', '    operator<<(std::ostream & stream,const TensorDataContainer & tensor_data_container)', '    operator<<(std::ostream & stream,c10::BFloat16 value)', '    fill_', '    device', '    begin', '    end', '    insert', '    push_back', '    reserve', '    size', '    convert_to_tensor(at::TensorOptions options)', '    fill_tensor(at::Tensor & tensor)', '    init_list', '    is_init_list', '    is_scalar', '    is_tensor', '    pretty_print_recursive(std::ostream & stream)', '    scalar', '    scalar_type', '    sizes', '    tensor', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer', '    TensorDataContainer(uint8_t value)', '    TensorDataContainer(int8_t value)', '    TensorDataContainer(int16_t value)', '    TensorDataContainer(int value)', '    TensorDataContainer(int64_t value)', '    TensorDataContainer(float value)', '    TensorDataContainer(double value)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(std::initializer_list init_list)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer((*) () decltype)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(at::ArrayRef values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)', '    TensorDataContainer(const std::vector & values)'];
operator.h;C++;pytorch-master/pytorch-master/caffe2/core; 1658;  285; 172;262;  933; 49;0;0;0;0;0.31;0;[];['    tensor_dim_apply3(const Tensor & self,Tensor & values,Tensor & indices,int64_t dim,Function func)'];
operator_schema.h;C++;pytorch-master/pytorch-master/caffe2/core; 631;  175; 87;41;  321; 26;0;0;0;0;0.55;0;[];['    tensorExprFuserEnabled', '    canHandle(Node *node,AliasDb & aliasDb)', '    canMerge(Node *consumer,Node *producer,AliasDb & aliasDb)', '    createTensorExprOp(const Node *node)', '    fuseTensorExprs(std::shared_ptr & graph)', '    getOrCreateTensorExprSubgraph(Node *n)', '    getTensorExprSymbol', '    isSupported(Node *node)', '    scanNode(Node *consumer,AliasDb & aliasDb)', '    setTensorExprFuserEnabled(bool val)', '    sortReverseTopological(ArrayRef inputs,torch::jit::Block *block)', '    tryMerge(Node *consumer,Node *producer,AliasDb & aliasDb)'];
plan_executor.cc;C++;pytorch-master/pytorch-master/caffe2/core; 522;  51; 52;17;  407; 0;176;155;131;335;0.13;25;[];['    registerTensorExprFuser', '    setTensorExprFuserEnabled(bool val)'];
qtensor.cc;C++;pytorch-master/pytorch-master/caffe2/core; 5;  0; 1;1;  3; 0;1;3;1;5;0.00;1;[];['    empty_mkldnn(IntArrayRef sizes,const TensorOptions & options,c10::optional optional_memory_format)'];
scope_guard.h;C++;pytorch-master/pytorch-master/caffe2/core; 158;  52; 25;6;  77; 0;10;44;8;62;0.68;9;[];['    allIntegral(std::initializer_list)', '    torch_warn_once_356', '    _cast_BFloat16(const Tensor & self,bool non_blocking)', '    _cast_Bool(const Tensor & self,bool non_blocking)', '    _cast_Byte(const Tensor & self,bool non_blocking)', '    _cast_Char(const Tensor & self,bool non_blocking)', '    _cast_Double(const Tensor & self,bool non_blocking)', '    _cast_Float(const Tensor & self,bool non_blocking)', '    _cast_Half(const Tensor & self,bool non_blocking)', '    _cast_Int(const Tensor & self,bool non_blocking)', '    _cast_Long(const Tensor & self,bool non_blocking)', '    _cast_Short(const Tensor & self,bool non_blocking)', '    _dim_arange(const Tensor & like,int64_t dim)', '    arange(Scalar start,Scalar end,const TensorOptions & options)', '    arange(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    window_function_checks(const char *function_name,const TensorOptions & options,int64_t window_length)', '    bartlett_window(int64_t window_length,const TensorOptions & options)', '    bartlett_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    blackman_window(int64_t window_length,const TensorOptions & options)', '    blackman_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    clone(const Tensor & src,c10::optional optional_memory_format)', '    empty(IntArrayRef size,at::optional names,const TensorOptions & options,optional optional_memory_format)', '    empty_cpu(IntArrayRef size,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_like(const Tensor & self,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_strided_cpu(IntArrayRef size,IntArrayRef stride,const TensorOptions & options)', '    eye(int64_t n,const TensorOptions & options)', '    eye(int64_t n,int64_t m,const TensorOptions & options)', '    from_file(std::string filename,c10::optional shared,c10::optional size,const TensorOptions & options)', '    full(IntArrayRef size,Scalar fill_value,const TensorOptions & options)', '    full(IntArrayRef size,Scalar fill_value,optional names,const TensorOptions & options)', '    full_like(const Tensor & self,Scalar fill_value,const TensorOptions & options,c10::optional optional_memory_format)', '    hamming_window(int64_t window_length,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,double alpha,const TensorOptions & options)', '    hamming_window(int64_t window_length,bool periodic,double alpha,double beta,const TensorOptions & options)', '    hann_window(int64_t window_length,const TensorOptions & options)', '    hann_window(int64_t window_length,bool periodic,const TensorOptions & options)', '    infer_full_options(Scalar fill_value,const TensorOptions & options)', '    linspace(Scalar start,Scalar end,int64_t steps,const TensorOptions & options)', '    logspace(Scalar start,Scalar end,int64_t steps,double base,const TensorOptions & options)', '    new_empty(const Tensor & self,IntArrayRef size,const TensorOptions & options)', '    new_full(const Tensor & self,IntArrayRef size,Scalar fill_value,const TensorOptions & options)', '    new_zeros(const Tensor & self,IntArrayRef size,const TensorOptions & options)', '    normal(double mean,double std,IntArrayRef size,Generator generator,const TensorOptions & options)', '    ones(IntArrayRef size,const TensorOptions & options)', '    ones(IntArrayRef size,optional names,const TensorOptions & options)', '    ones_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    rand(IntArrayRef size,const TensorOptions & options)', '    rand(IntArrayRef size,Generator generator,const TensorOptions & options)', '    rand(IntArrayRef size,optional names,const TensorOptions & options)', '    rand(IntArrayRef size,Generator generator,optional names,const TensorOptions & options)', '    rand_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    randint(int64_t high,IntArrayRef size,const TensorOptions & options)', '    randint(int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    randint(int64_t low,int64_t high,IntArrayRef size,const TensorOptions & options)', '    randint(int64_t low,int64_t high,IntArrayRef size,Generator generator,const TensorOptions & options)', '    randint_like(const Tensor & self,int64_t high,const TensorOptions & options,c10::optional optional_memory_format)', '    randint_like(const Tensor & self,int64_t low,int64_t high,const TensorOptions & options,c10::optional optional_memory_format)', '    randn(IntArrayRef size,const TensorOptions & options)', '    randn(IntArrayRef size,Generator generator,const TensorOptions & options)', '    randn(IntArrayRef size,optional names,const TensorOptions & options)', '    randn(IntArrayRef size,Generator generator,optional names,const TensorOptions & options)', '    randn_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)', '    randperm(int64_t n,const TensorOptions & options)', '    randperm(int64_t n,Generator generator,const TensorOptions & options)', '    randperm_cpu(Tensor & result,int64_t n,CPUGenerator *generator)', '    range(Scalar start,Scalar end,Scalar step,const TensorOptions & options)', '    range(Scalar start,Scalar end,const TensorOptions & options)', '    scalar_tensor(Scalar s,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor(ArrayRef values,const TensorOptions & options)', '    tensor_backend(ArrayRef values,const TensorOptions & options)', '    tensor_cpu(ArrayRef values,const TensorOptions & options)', '    tril_indices_cpu(int64_t row,int64_t col,int64_t offset,const TensorOptions & options)', '    triu_indices_cpu(int64_t row,int64_t col,int64_t offset,const TensorOptions & options)', '    zeros(IntArrayRef size,const TensorOptions & options)', '    zeros(IntArrayRef size,optional names,const TensorOptions & options)', '    zeros_like(const Tensor & self,const TensorOptions & options,c10::optional optional_memory_format)'];
stats.h;C++;pytorch-master/pytorch-master/caffe2/core; 357;  99; 52;49;  160; 0;45;89;32;73;0.62;28;[];['    empty_affine_quantized_cpu(IntArrayRef size,const TensorOptions & options_,double scale,int64_t zero_point,c10::optional optional_memory_format)', '    empty_affine_quantized_other_backends_stub(IntArrayRef,const TensorOptions &,double,int64_t,c10::optional)', '    empty_per_channel_affine_quantized_cpu(IntArrayRef size,const Tensor & scales,const Tensor & zero_points,int64_t axis,const TensorOptions & options_,c10::optional optional_memory_format)', '    empty_per_channel_affine_quantized_other_backends_stub(IntArrayRef,const Tensor &,const Tensor &,int64_t,const TensorOptions &,c10::optional)'];
tensor.h;C++;pytorch-master/pytorch-master/caffe2/core; 641;  190; 92;16;  345; 0;122;158;136;130;0.55;63;[];['    check_args(int64_t row,int64_t col,const TensorOptions & options)', '    check_size_nonnegative(IntArrayRef size)', '    check_supported_max_int_with_precision(int64_t n,const Tensor & tensor)', '    get_tril_size(int64_t row,int64_t col,int64_t offset)'];
test_utils.cc;C++;pytorch-master/pytorch-master/caffe2/core; 137;  7; 15;3;  116; 0;45;62;79;39;0.06;12;[];['    is_contiguous'];
transform.cc;C++;pytorch-master/pytorch-master/caffe2/core; 259;  41; 27;6;  187; 0;92;68;84;81;0.22;9;[];[];
types.h;C++;pytorch-master/pytorch-master/caffe2/core; 83;  14; 15;11;  46; 0;19;23;17;13;0.30;5;['    C10FlagParser_caffe2_keep_on_shrink', '    C10FlagParser_caffe2_max_keep_on_shrink_memory'];['    deletePlacementDeleteContext(void *ptr)', '    GetAutogradMetaFactory', '    SetAutogradMetaFactory(AutogradMetaFactory *factory)', '    key_set_(key_set)', '    d', '    d', '    makeDataPtr(at::DataPtr,PlacementDtor placement_dtor,size_t size,at::Device device)', '    ~AutogradMetaInterface', '    C10FlagParser_caffe2_keep_on_shrink(const std::string & content)', '    C10FlagParser_caffe2_max_keep_on_shrink_memory(const std::string & content)', '    autograd_meta', '    compute_channels_last_contiguous_2d', '    compute_channels_last_contiguous_3d', '    compute_contiguous', '    compute_non_overlapping_and_dense', '    compute_strides_like_channels_last_2d', '    compute_strides_like_channels_last_3d', '    copy_tensor_metadata(const TensorImpl *src_impl,TensorImpl *dest_impl,const c10::VariableVersion & version_counter,bool allow_tensor_metadata_change)', '    dim', '    grad', '    grad', '    has_storage', '    is_contiguous(at::MemoryFormat memory_format)', '    release_resources', '    requires_grad', '    set_autograd_meta(std::unique_ptr autograd_meta)', '    set_requires_grad(bool requires_grad)', '    size(int64_t d)', '    sizes', '    storage', '    stride(int64_t d)', '    strides', '    TensorImpl(Storage,DispatchKeySet key_set)', '    TensorImpl(DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::optional device_opt)', '    TensorImpl(Storage,DispatchKeySet key_set,const caffe2::TypeMeta & data_type,c10::optional device_opt)'];
common_rtc.h;C++;pytorch-master/pytorch-master/caffe2/cuda_rtc; 120;  11; 13;15;  83; 0;37;50;69;43;0.13;6;[];[];
create_db_op.h;C++;pytorch-master/pytorch-master/caffe2/db; 42;  2; 7;6;  29; 0;5;21;6;12;0.07;2;[];['    TEST(TensorImplTest,Caffe2Constructor)'];
lmdb.cc;C++;pytorch-master/pytorch-master/caffe2/db; 175;  6; 26;11;  134; 3;63;52;61;52;0.04;20;[];['    set_item(Tensor & self,ArrayRef indices,Scalar)', '    operator<<(std::ostream & stream,const Slice & slice)', '    operator<<(std::ostream & stream,const TensorIndex & tensor_index)', '    operator<<(std::ostream & stream,const std::vector & tensor_indices)', '    index(ArrayRef indices)', '    index(std::initializer_list indices)', '    index_put_(ArrayRef indices,Tensor const & rhs)', '    index_put_(std::initializer_list indices,Tensor const & rhs)', '    index_put_(ArrayRef indices,Scalar v)', '    index_put_(std::initializer_list indices,Scalar v)'];
file_store_handler.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 36;  1; 13;2;  21; 0;2;18;0;13;0.05;0;[];[];
py_export.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 21;  2; 7;2;  12; 0;5;6;3;5;0.17;1;[];['    compute_common_type_(at::ArrayRef operands)', '    maybe_copy_casting_to_common_dtype(OperandInfo & op,ScalarType common_dtype)', '    validate_dtype(OperandInfo & op,ScalarType common_dtype,CommonDTypeStrategy strategy)', '    compute_device(at::ArrayRef operands)', '    binary_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    comparison_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    nullary_op(Tensor & out)', '    reduce_op(Tensor & out,const Tensor & a)', '    reduce_op(Tensor & out1,Tensor & out2,const Tensor & a)', '    unary_op(Tensor & out,const Tensor & a,bool check_mem_overlap)', '    DimCounter(IntArrayRef shape,Range range)', '    increment(const std::array & step)', '    is_done', '    max_2d_step', '    begin', '    end', '    iterator(const TensorIterator & iter)', '    operator*', '    operator++', '    allocate_outputs', '    analyze_memory_format', '    apply_perm_and_mul(IntArrayRef input,int mul)', '    build', '    can_use_32bit_indexing', '    check_mem_overlaps', '    coalesce_dimensions', '    compatible_stride(int element_size)', '    compute_common_type', '    compute_fast_setup_type', '    compute_names', '    compute_shape', '    compute_strides', '    compute_types', '    data_ptr(int arg)', '    fast_set_up', '    for_each(loop_t loop,int64_t grain_size)', '    for_each(loop2d_t loop,int64_t grain_size)', '    get_base_ptrs', '    get_data_ptrs(ArrayRef base,IntArrayRef counter)', '    get_dim_strides(int dim)', '    get_dim_to_split', '    get_strides', '    invert_perm(IntArrayRef input)', '    is_contiguous', '    is_cpu_scalar(int arg)', '    is_dim_reduced(int dim)', '    is_scalar(int arg)', '    is_trivial_1d', '    mark_outputs', '    narrow(int dim,int64_t start,int64_t size)', '    num_output_elements', '    num_reduce_dims', '    numel', '    permute_dimensions(IntArrayRef perm)', '    propagate_names_to_outputs', '    remove_dimension(int dim)', '    remove_operand(int arg)', '    reorder_dimensions', '    select_all_keeping_dim(int start_dim,IntArrayRef indices)', '    serial_for_each(loop_t loop,Range range)', '    serial_for_each(loop2d_t loop,Range range)', '    split(int dim)', '    unsafe_replace_operand(int arg,void *data)', '    with_32bit_indexing'];
redis_store_handler_op.h;C++;pytorch-master/pytorch-master/caffe2/distributed; 44;  1; 9;4;  31; 0;7;23;10;13;0.03;2;['    CommonDTypeStrategy', '    FastSetupType'];['    binary_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    comparison_op(Tensor & out,const Tensor & a,const Tensor & b,bool check_mem_overlap)', '    nullary_op(Tensor & out)', '    reduce_op(Tensor & out,const Tensor & a)', '    reduce_op(Tensor & out1,Tensor & out2,const Tensor & a)', '    unary_op(Tensor & out,const Tensor & a,bool check_mem_overlap)', '    DimCounter(IntArrayRef shape,Range range)', '    increment(const std::array & step)', '    is_done', '    max_2d_step', '    is_type_defined', '    OperandInfo', '    OperandInfo(const Tensor & t)', '    OperandInfo(const Tensor & t,Device device,ScalarType dtype)', '    options', '    validate', '    begin', '    end', '    iterator', '    iterator(const TensorIterator & iter)', '    iterator', '    operator!=(const iterator & other)', '    operator*', '    operator++', '    operator==(const iterator & other)', '    SplitUntil32Bit(const TensorIterator & iter)', '    defined', '    device', '    layout', '    scalar_type', '    add_input(const Tensor & input)', '    add_input(const Tensor & input,Device device,ScalarType dtype)', '    add_output(const Tensor & output)', '    add_output(const Tensor & input,Device device,ScalarType dtype)', '    allocate_outputs', '    analyze_memory_format', '    apply_perm_and_mul(IntArrayRef input,int mul)', '    build', '    can_use_32bit_indexing', '    cast_outputs', '    check_mem_overlaps', '    coalesce_dimensions', '    common_dtype', '    compatible_stride(int element_size)', '    compute_common_dtype_only_for_inputs', '    compute_common_type', '    compute_fast_setup_type', '    compute_names', '    compute_shape', '    compute_strides', '    compute_types', '    data_ptr(int arg)', '    device(int arg)', '    device_type(int arg)', '    dont_compute_common_dtype', '    dont_resize_outputs', '    dtype(int arg)', '    element_size(int arg)', '    fast_set_up', '    for_each(loop_t loop,int64_t grain_size)', '    for_each(loop2d_t loop,int64_t grain_size)', '    foreach_reduced_elt(loop_subiter_t loop,bool parallelize)', '    get_base_ptrs', '    get_data_ptrs(ArrayRef base,IntArrayRef counter)', '    get_dim_strides(int dim)', '    get_dim_to_split', '    get_inner_strides', '    get_strides', '    has_contiguous_first_dim', '    input(int arg)', '    input_dtype(int arg)', '    invert_perm(IntArrayRef input)', '    is_contiguous', '    is_cpu_scalar(int arg)', '    is_dim_reduced(int dim)', '    is_final_output', '    is_scalar(int arg)', '    is_trivial_1d', '    mark_outputs', '    narrow(int dim,int64_t start,int64_t size)', '    ndim', '    ninputs', '    noutputs', '    ntensors', '    num_output_elements', '    num_reduce_dims', '    numel', '    output(int arg)', '    parallel_reduce(loop2d_t loop)', '    permute_dimensions(IntArrayRef perm)', '    promote_common_dtype', '    propagate_names_to_outputs', '    remove_dimension(int dim)', '    remove_operand(int arg)', '    reorder_dimensions', '    scalar_value(int arg)', '    select_all_keeping_dim(int start_dim,IntArrayRef indices)', '    serial_for_each(loop_t loop,Range range)', '    serial_for_each(loop2d_t loop,Range range)', '    set_check_mem_overlap(bool check_mem_overlap)', '    shape', '    should_accumulate', '    split(int dim)', '    strides(int arg)', '    tensor(int arg)', '    tensor(int arg)', '    TensorIterator', '    unsafe_replace_operand(int arg,void *data)', '    view_offsets', '    with_32bit_indexing', '    fetch_and_cast'];
store_ops.cc;C++;pytorch-master/pytorch-master/caffe2/distributed; 126;  2; 25;2;  97; 0;65;72;24;42;0.02;16;[];['    find_split_dim(TensorIterator & iter)', '    parallel_dim_reduction(TensorIterator & iter,loop2d_t loop)', '    round_columns(TensorIterator & iter,int dim,int multiple,int64_t begin,int64_t end)', '    two_pass_reduction(TensorIterator & iter,loop2d_t loop)', '    use_two_pass_reduction(TensorIterator & iter)', '    dims', '    foreach_reduced_elt(loop_subiter_t loop,bool parallelize)', '    parallel_reduce(loop2d_t loop)'];
fully_connected_op_decomposition_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 26;  16; 4;2;  5; 0;2;4;2;9;3.20;2;[];['    $', '    get_device(Tensor self)', '    is_cuda(Tensor self)', '    is_hip(Tensor self)', '    is_mkldnn(Tensor self)', '    is_quantized(Tensor self)', '    is_sparse(Tensor self)', '    cpu', '    cuda', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    data_ptr', '    device', '    dtype', '    get_device', '    get_named_tensor_meta', '    get_named_tensor_meta', '    has_names', '    hip', '    is_cuda', '    is_hip', '    is_mkldnn', '    is_quantized', '    is_sparse', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    item', '    layout', '    options', '    register_hook(T)', '    register_hook(T)', '    toBackend(Backend b)', '    toType(ScalarType)'];
fully_connected_op_sparse.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 149;  33; 20;9;  93; 1;39;58;47;59;0.35;9;[];['    operator<<(std::ostream & out,const TensorName & tensorname)', '    toDimname', '    unify(const TensorName & other,const char *op_name)', '    append(TensorName)', '    checkUnique(const char *op_name)', '    TensorNames(ArrayRef names)', '    TensorNames(ArrayRef names,int64_t start,int64_t end)', '    toDimnameVec', '    unifyFromRightInplace(const TensorNames & other,const char *op_name)'];
sparse_funhash_op.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 241;  24; 39;16;  161; 5;103;92;91;124;0.15;4;[];[];
tt_contraction_op.h;C++;pytorch-master/pytorch-master/caffe2/experiments/operators; 163;  17; 30;6;  112; 0;70;55;68;90;0.15;4;[];[];
ideep_utils.h;C++;pytorch-master/pytorch-master/caffe2/ideep; 48;  13; 7;26;  14; 0;0;14;0;3;0.93;0;[];['    operator<<(std::ostream & stream,const TensorOptions & options)'];
conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 343;  1; 45;1;  297; 0;140;177;139;221;0.00;10;[];[];
dropout_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 90;  1; 20;1;  69; 0;24;38;79;110;0.01;6;[];[];
local_response_normalization_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 91;  1; 19;1;  71; 0;20;44;63;108;0.01;6;[];['    contiguous(const Tensor & self)', '    contiguous(const Tensor & self,MemoryFormat memory_format)', '    cudnn_is_acceptable(const Tensor & self)', '    detach(const Tensor & self)', '    detach_(Tensor & self)', '    is_same_size(const Tensor & self,const Tensor & other)', '    is_set_to(const Tensor & self,const Tensor & src)', '    size(const Tensor & self,int64_t dim)', '    size(const Tensor & self,Dimname dim)', '    stride(const Tensor & self,int64_t dim)', '    stride(const Tensor & self,Dimname dim)'];
order_switch_ops.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 62;  5; 14;1;  43; 0;18;20;77;100;0.12;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDATensorRT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TensorRT', '    CheckDims(const nvinfer1::Dims & nv_dims,at::ArrayRef c2_dims)', '    MaybeAdjustOutputShape(int output_idx,std::vector *dims)', '    RunOnDevice', '    TensorRTOp(const OperatorDef & operator_def,Workspace *ws)'];
int8_dequantize_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 42;  1; 10;1;  31; 0;14;11;33;48;0.03;4;['    final'];['    batch_warning_issued_', '    MaybeAdjustOutputShape(int output_idx,std::vector *dims)', '    RunOnDevice', '    TensorRTOp(const OperatorDef & operator_def,Workspace *ws)', '    trt_engine_', '    trt_executor_', '    ~TensorRTOp'];
int8_quantize_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators/quantization; 60;  1; 13;1;  46; 0;19;20;42;54;0.02;4;[];['    BlobToTensorProto(const std::string & name,Workspace *ws,CUDAContext *context,::ONNX_NAMESPACE::TensorProto *t)', '    BuildInitializationList(Workspace *ws,::ONNX_NAMESPACE::GraphProto *g,std::unordered_set *initialization_list)', '    ConvertToValueInfo(const std::vector & names,const std::unordered_map & shape_hints)', '    CPUTensorToTensorProto(const TensorCPU & cpu_tensor,::ONNX_NAMESPACE::TensorProto *t)', '    DumpModel(const ::ONNX_NAMESPACE::ModelProto & model,const std::string & fname)', '    FillModelInfo(::ONNX_NAMESPACE::ModelProto *model)', '    InferShapes(Workspace *ws,NetDef *pred_net,CaffeMap *shape_hints_ordered)', '    trt_converter', '    AddTrtOptions(OperatorDef *op,const std::unordered_map,std::vector)', '    BuildTrtOp(const std::string & onnx_model_str,const std::unordered_map,std::vector)', '    BuildTrtOpLazy(const std::string & onnx_model_str,const std::unordered_map,std::vector,const std::unordered_set & initialization_list,const caffe2::NetDef & net)', '    PruneUnusedWeights(Workspace *ws,const NetDef & pred_net)', '    SsaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    SubnetToTrtOp(const caffe2::NetDef & net,Workspace *ws,onnx::OnnxExporter *exporter,std::unordered_map *shape_hints)', '    Transform(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)'];
reshape_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 132;  10; 15;1;  107; 0;55;27;80;65;0.09;2;['    TensorRTTransformer'];['    BuildInitializationList(Workspace *ws,::ONNX_NAMESPACE::GraphProto *g,std::unordered_set *initialization_list)', '    AddTrtOptions(caffe2::OperatorDef *op,const std::unordered_map,std::vector)', '    build_serializable_op_', '    BuildTrtOp(const std::string & onnx_model_str,const std::unordered_map,std::vector)', '    BuildTrtOpLazy(const std::string & onnx_model_str,const std::unordered_map,std::vector,const std::unordered_set & initialization_list,const caffe2::NetDef & net)', '    debug_builder_', '    max_batch_size_', '    max_workspace_size_', '    PruneUnusedWeights(Workspace *ws,const NetDef & pred_net)', '    SsaRewriteAndMapNames(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    SubnetToTrtOp(const caffe2::NetDef & net,Workspace *ws,onnx::OnnxExporter *exporter,std::unordered_map *shape_hints)', '    TensorRTTransformer(size_t max_batch_size,size_t max_workspace_size,int verbosity,bool debug_builder,bool build_serializable_op)', '    Transform(Workspace *ws,NetDef *pred_net,const std::unordered_map & input_shape_hints)', '    verbosity_'];
transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/operators; 35;  1; 11;1;  23; 0;5;14;28;50;0.04;3;[];['    cat_sparse(TensorList tensors,int64_t dim)', '    check_cat_no_zero_dim(TensorList tensors)', '    check_cat_shape_except_dim(const Tensor & first,const Tensor & second,int64_t dimension)', '    check_cat_sparse_dims(Tensor const & t,int64_t pos,IntArrayRef sizes,int64_t wrapped,int64_t sparse_dim,int64_t dense_dim)', '    check_t(const Tensor & self,const char *fn)', '    get_stack_inputs(TensorList tensors,int64_t dim)', '    propagate_transposed_names(Tensor & result,const Tensor & other,int64_t dim0,int64_t dim1)', '    select_sparse(const Tensor & self,int64_t dim,int64_t index)', '    sizes_match_except(IntArrayRef s1,IntArrayRef s2,int64_t dim_except)', '    sparse_transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    unsqueeze_sparse(Tensor const & self,int64_t dim)', '    _unsafe_view(const Tensor & self,IntArrayRef size)', '    alias(const Tensor & self)', '    apply_diag(Tensor & result,const Tensor & self,int64_t dimension)', '    diag(const Tensor & self,int64_t dimension)', '    diag_out(Tensor & result,const Tensor & self,int64_t dimension)', '    flatten(const Tensor & self,int64_t start_dim,int64_t end_dim)', '    flatten(const Tensor & self,int64_t start_dim,int64_t end_dim,Dimname out_dim)', '    flatten(const Tensor & self,Dimname start_dim,Dimname end_dim,Dimname out_dim)', '    flatten(const Tensor & self,DimnameList dims,Dimname out_dim)', '    inferSqueezeGeometry(const Tensor & tensor)', '    inferSqueezeGeometry(const Tensor & tensor,int64_t dim)', '    inferUnsqueezeGeometry(const Tensor & tensor,int64_t dim)', '    meshgrid(TensorList tensors)', '    _cat_cpu(TensorList tensors,int64_t dim)', '    _cat_out_cpu(Tensor & result,TensorList tensors,int64_t dim)', '    _reshape_from_tensor(const Tensor & self,const Tensor & shape_tensor)', '    _shape_as_tensor(const Tensor & self)', '    alias_with_sizes_and_strides(const Tensor & self,const c10::IntArrayRef sizes,const c10::IntArrayRef strides)', '    as_strided_(Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    as_strided_qtensorimpl(const Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    as_strided_tensorimpl(const Tensor & self,IntArrayRef size,IntArrayRef stride,optional storage_offset_)', '    broadcast_tensors(TensorList tensors)', '    cat(TensorList tensors,Dimname dim)', '    cat(TensorList tensors,int64_t dim)', '    cat_out(Tensor & result,TensorList tensors,int64_t dim)', '    cat_out(Tensor & result,TensorList tensors,Dimname dim)', '    chunk(const Tensor & self,int64_t chunks,int64_t dim)', '    diag_embed(const Tensor & self,int64_t offset,int64_t dim1_,int64_t dim2_)', '    diagflat(const Tensor & self,int64_t offset)', '    diagonal(const Tensor & self,int64_t offset,int64_t dim1_,int64_t dim2_)', '    diagonal(const Tensor & self,Dimname outdim,Dimname dim1,Dimname dim2,int64_t offset)', '    expand(const Tensor & self,IntArrayRef size,bool implicit)', '    expand_as(const Tensor & self,const Tensor & other)', '    index_select_sparse(const Tensor & self,int64_t dim,const Tensor & index)', '    narrow(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    narrow(const Tensor & self,int64_t dim,const Tensor & start,int64_t length)', '    narrow_copy_dense(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    narrow_copy_sparse(const Tensor & self,int64_t dim,int64_t start,int64_t length)', '    permute(const Tensor & self,IntArrayRef dims)', '    repeat(const Tensor & self,IntArrayRef repeats)', '    reshape(const Tensor & self,IntArrayRef proposed_shape)', '    reshape_as(const Tensor & self,const Tensor & other)', '    select(const Tensor & self,int64_t dim,int64_t index)', '    select(const Tensor & self,Dimname dim,int64_t index)', '    set_(Tensor & result,Storage source)', '    set_cpu_(Tensor & result)', '    set_storage_cpu_(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)', '    set_tensor_(Tensor & result,const Tensor & source)', '    slice(const Tensor & self,int64_t dim,int64_t start,int64_t end,int64_t step)', '    split(const Tensor & self,int64_t split_size,int64_t dim)', '    split_with_sizes(const Tensor & self,IntArrayRef split_sizes,int64_t dim)', '    stack(TensorList tensors,int64_t dim)', '    stack_out(Tensor & result,TensorList tensors,int64_t dim)', '    sum_to_size(const Tensor & self,IntArrayRef size)', '    transpose(const Tensor & self,Dimname dim0,Dimname dim1)', '    transpose(const Tensor & self,int64_t dim0,int64_t dim1)', '    transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    numel(const Tensor & self)', '    numpy_T(const Tensor & self)', '    squeeze(const Tensor & self)', '    squeeze(const Tensor & self,int64_t dim)', '    squeeze_(Tensor & self)', '    squeeze_(Tensor & self,int64_t dim)', '    t_(Tensor & self)', '    unbind(const Tensor & self,int64_t dim)', '    unbind(const Tensor & self,Dimname dim)', '    unfold(const Tensor & self,int64_t dimension,int64_t size,int64_t step)', '    unsqueeze(const Tensor & self,int64_t dim)', '    unsqueeze_(Tensor & self,int64_t dim)', '    view(const Tensor & self,IntArrayRef size)', '    view_as(const Tensor & self,const Tensor & other)'];
ideep_register.cc;C++;pytorch-master/pytorch-master/caffe2/ideep/utils; 63;  3; 9;5;  49; 0;7;29;11;52;0.06;3;[];['    mkldnn_clone(const Tensor & self,c10::optional optional_memory_format)', '    mkldnn_reshape(const Tensor & self,IntArrayRef size)', '    mkldnn_transpose(const Tensor & self,int64_t dim0,int64_t dim1)', '    mkldnn_transpose_(Tensor & self,int64_t dim0,int64_t dim1)', '    mkldnn_view(const Tensor & self,IntArrayRef size)', '    y'];
transform_gpu.h;C++;pytorch-master/pytorch-master/caffe2/image; 43;  25; 6;4;  9; 0;0;9;0;2;2.78;0;[];[];
ios_caffe_predictor.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 72;  0; 6;10;  40; 17;25;16;14;9;0.00;3;[];['    set_cuda_(Tensor & result)', '    set_storage_cuda_(Tensor & result,Storage storage,int64_t storage_offset,IntArrayRef size,IntArrayRef stride)'];
mpscnn_graph_mask.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios/mpscnn; 16;  6; 2;3;  6; 0;0;6;0;3;1.00;0;[];['    flip_cpu(const Tensor & self,IntArrayRef dims)', '    flip_cpu_kernel(const int64_t total_dims,const std::vector & stride_contiguous_v,const std::bitset & flip_dims_b,const Tensor & in_tensor,Tensor & out_tensor)', '    roll_cpu(const Tensor & self,IntArrayRef shifts,IntArrayRef dims)', '    rot90(const Tensor & self,int64_t k,IntArrayRef dims)'];
resize_test.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ios; 96;  3; 17;8;  70; 0;41;40;30;33;0.04;4;[];['    flip_check_errors(int64_t total_dims,int64_t flip_dims_size,IntArrayRef dims)', '    roll_common(const Tensor & self,IntArrayRef shifts,IntArrayRef dims)', '    roll', '    minmax_element', '    unique'];
cl_gl.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include/CL; 162;  81; 27;32;  74; 1;0;74;0;17;1.09;0;[];['    check_dim_size(const Tensor & tensor,int64_t dim,int64_t dim_size,int64_t size)', '    checkAllContiguous(CheckedFrom c,at::ArrayRef ts)', '    checkAllDefined(CheckedFrom c,ArrayRef ts)', '    checkAllSame(CheckedFrom c,ArrayRef tensors,void (*) (CheckedFrom, const TensorArg &, const TensorArg &) fn)', '    checkAllSameGPU(CheckedFrom c,ArrayRef tensors)', '    checkAllSameNumel(CheckedFrom c,ArrayRef tensors)', '    checkAllSameSize(CheckedFrom c,ArrayRef tensors)', '    checkAllSameType(CheckedFrom c,ArrayRef tensors)', '    checkBackend(CheckedFrom c,at::ArrayRef tensors,at::Backend backend)', '    checkBackend(CheckedFrom c,const Tensor & t,Backend backend)', '    checkContiguous(CheckedFrom c,const TensorGeometryArg & t)', '    checkDefined(CheckedFrom c,const TensorArg & t)', '    checkDeviceType(CheckedFrom c,at::ArrayRef tensors,at::DeviceType device_type)', '    checkDeviceType(CheckedFrom c,const Tensor & t,DeviceType device_type)', '    checkDim(CheckedFrom,const TensorGeometryArg & t,int64_t dim)', '    checkDimRange(CheckedFrom c,const TensorGeometryArg & t,int64_t dim_start,int64_t dim_end)', '    checkLayout(CheckedFrom c,const Tensor & t,Layout layout)', '    checkLayout(CheckedFrom c,at::ArrayRef tensors,at::Layout layout)', '    checkNumel(CheckedFrom c,const TensorGeometryArg & t,int64_t numel)', '    checkSameDim(CheckedFrom c,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameGPU(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameNumel(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameSize(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameType(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkScalarType(CheckedFrom c,const TensorArg & t,ScalarType ty)', '    checkScalarTypes(CheckedFrom c,const TensorArg & t,at::ArrayRef l)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,IntArrayRef sizes)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,int64_t dim,int64_t size)', '    computeStorageSize(IntArrayRef sizes,IntArrayRef strides)', '    defaultStrides(IntArrayRef sizes)', '    geometry_is_contiguous(IntArrayRef sizes,IntArrayRef strides)', '    maybe_data_ptr(const Tensor & tensor)', '    maybe_data_ptr(const TensorArg & tensor)', '    operator<<(std::ostream & out,TensorGeometryArg t)'];
libopencl.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libopencl-stub/include; 249;  5; 105;13;  125; 2;0;125;0;102;0.04;0;[];['    check_dim_size(const Tensor & tensor,int64_t dim,int64_t dim_size,int64_t size)', '    checkAllContiguous(CheckedFrom c,at::ArrayRef ts)', '    checkAllDefined(CheckedFrom,at::ArrayRef t)', '    checkAllSameGPU(CheckedFrom c,ArrayRef tensors)', '    checkAllSameNumel(CheckedFrom c,ArrayRef tensors)', '    checkAllSameType(CheckedFrom c,ArrayRef tensors)', '    checkBackend(CheckedFrom c,at::ArrayRef tensors,at::Backend backend)', '    checkContiguous(CheckedFrom c,const TensorGeometryArg & t)', '    checkDefined(CheckedFrom c,const TensorArg & t)', '    checkDeviceType(CheckedFrom c,at::ArrayRef tensors,at::DeviceType device_type)', '    checkDim(CheckedFrom,const TensorGeometryArg & t,int64_t dim)', '    checkDimRange(CheckedFrom c,const TensorGeometryArg & t,int64_t dim_start,int64_t dim_end)', '    checkLayout(CheckedFrom c,const Tensor & t,Layout layout)', '    checkLayout(CheckedFrom c,at::ArrayRef tensors,at::Layout layout)', '    checkNumel(CheckedFrom c,const TensorGeometryArg & t,int64_t numel)', '    checkSameDim(CheckedFrom c,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameGPU(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameNumel(CheckedFrom,const TensorGeometryArg & t1,const TensorGeometryArg & t2)', '    checkSameSize(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkSameType(CheckedFrom c,const TensorArg & t1,const TensorArg & t2)', '    checkScalarType(CheckedFrom,const TensorArg & t,ScalarType s)', '    checkScalarTypes(CheckedFrom c,const TensorArg & t,at::ArrayRef l)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,IntArrayRef sizes)', '    checkSize(CheckedFrom c,const TensorGeometryArg & t,int64_t dim,int64_t size)', '    computeStorageSize(IntArrayRef sizes,IntArrayRef strides)', '    defaultStrides(IntArrayRef sizes)', '    geometry_is_contiguous(IntArrayRef sizes,IntArrayRef strides)', '    maybe_data_ptr(const Tensor & tensor)', '    maybe_data_ptr(const TensorArg & tensor)', '    operator<<(std::ostream & out,TensorGeometryArg t)', '    operator*', '    operator->', '    TensorArg(Tensor tensor,const char *name,int pos)', '    operator*', '    operator->', '    TensorGeometryArg(TensorArg arg)', '    TensorGeometryArg(TensorGeometry tensor,const char *name,int pos)'];
vulkan.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/libvulkan-stub/include/vulkan; 4161;  31; 328;186;  2474; 1195;0;2474;0;1363;0.01;0;[];['    elem', '    testAliasRegistration', '    testContainerAliasing', '    testMemoryDAG', '    testWildcards', '    testWriteTracking', '    aliasAnalysisFromSchema', '    expectThrows(Functor,const char *expectMessageContains)', '    insertIf(Graph & g,Value *condValue,std::function trueInst,std::function falseInst)', '    testAliasAnalysis', '    testTopologicalMove', '    ValueSet', '    checkPostCondition(const std::string & toInsert,const std::string & insertPoint,bool after)', '    createGraph', '    createNode(const std::string & name,const std::vector & inputNames,const std::vector & blockInputNames)', '    moveAfterTopologicallyValid(const std::string & toInsert,const std::string & insertPoint)', '    moveBeforeTopologicallyValid(const std::string & toInsert,const std::string & insertPoint)', '    moveWithChecks(const std::string & toInsert,const std::string & insertPoint,std::function func)', '    TopoMoveTestFixture'];
NeuralNetworks.h;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 1925;  1712; 79;6;  129; 0;7;122;0;43;13.27;1;[];['    device(const autograd::Variable & v)', '    hashCode(const TensorTypePtr & ptr)', '    isEqual(at::IntArrayRef lhs,at::IntArrayRef rhs)', '    isEqual(const CompleteArgumentInfo & ti,const autograd::Variable & v)', '    isEqual(const ArgumentInfo & ti,const autograd::Variable & v)', '    testArgumentSpec', '    testCompleteArgumentSpec', '    testProfiledTensorTypeHashing', '    undef', '    var(at::TensorOptions t,at::IntArrayRef sizes,bool requires_grad)'];
nnapi_test.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/nnapi; 642;  24; 38;8;  579; 0;326;183;249;146;0.04;33;[];['    barf(const char *fmt,...)'];
snpe_op.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/snpe; 130;  2; 20;16;  92; 0;60;35;84;36;0.02;3;[];['    testATen_cast_Float', '    testATen_sigmoid_backward', '    testATen_tanh_backward', '    testATenaddcmulFloat', '    testATenaddcmulInt', '    testATenaddFloat', '    testATenaddInt', '    testATencosFloat', '    testATendivFloat', '    testATendivInt', '    testATeneqInt', '    testATenerfFloat', '    testATenexpFloat', '    testATenlerp', '    testATenlog10Float', '    testATenlog2Float', '    testATenlogFloat', '    testATenmaxFloat', '    testATenmaxInt', '    testATenminFloat', '    testATenminInt', '    testATenmulFloat', '    testATenmulInt', '    testATennegFloat', '    testATennegInt', '    testATenreciprocal', '    testATenreluFloat', '    testATenreluInt', '    testATensubFloat', '    testATensubInt', '    testATengeInt', '    testATengtInt', '    testATenleInt', '    testATenltInt'];
ulp_neon.cc;C++;pytorch-master/pytorch-master/caffe2/mobile/contrib/ulp2; 555;  3; 4;6;  3; 540;1;3;0;2;1.00;0;[];['    graph', '    testDifferentiate', '    testDifferentiateWithRequiresGrad', '    grad(const variable_list & outputs,const variable_list & inputs,const variable_list & grad_outputs)', '    get_grad_outputs(const variable_list & vars)', '    testADFormulas', '    ADTestSpec(const char *name,var_meta_list input_meta,test_fn_type test_fn,float clampMax)', '    make_vars', '    operator()(const variable_list & inputs)'];
mpi_common.h;C++;pytorch-master/pytorch-master/caffe2/mpi; 155;  55; 19;26;  57; 0;21;35;40;31;0.96;9;[];['    aliasAnalysisFromSchema'];
mpi_ops_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/mpi; 86;  9; 8;40;  21; 36;7;9;7;29;0.43;7;[];['    assertAllEqual(const std::vector & vec,const T & val)', '    ExpectAllNear(const std::vector & v1,const std::vector & v2,V threshold,const std::string & name)'];
profile_observer.h;C++;pytorch-master/pytorch-master/caffe2/observers; 113;  23; 17;9;  66; 0;12;39;8;27;0.35;7;[];['    isSandcastle'];
time_observer.h;C++;pytorch-master/pytorch-master/caffe2/observers; 72;  3; 13;10;  49; 0;9;31;4;24;0.06;5;[];['    import_libs(std::shared_ptr cu,const std::string & class_name,const std::shared_ptr & src,const std::vector & tensor_table)', '    testClassDerive', '    testClassImport', '    testSaveLoadTorchbind', '    testScriptObject'];
backend_rep.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 31;  0; 6;3;  22; 0;9;9;8;5;0.00;3;[];['    testClassParser'];
helper.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 57;  0; 6;3;  48; 0;23;22;19;16;0.00;4;[];['    testClassTypeAddRemoveAttr', '    testClassTypeAddRemoveConstant'];
onnx_exporter.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 1370;  63; 123;14;  1177; 0;848;439;660;392;0.05;35;[];['    testCodeTemplate'];
onnxifi_init.cc;C++;pytorch-master/pytorch-master/caffe2/onnx; 22;  2; 4;3;  15; 0;4;7;3;8;0.13;2;[];['    testConstantPooling'];
defs.cc;C++;pytorch-master/pytorch-master/caffe2/onnx/torch_ops; 160;  3; 11;1;  146; 0;0;10;0;9;0.02;0;[];['    testCreateAutodiffSubgraphs'];
abs_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 108;  4; 44;4;  60; 0;33;45;8;24;0.07;7;[];[];
accuracy_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 81;  4; 14;1;  63; 0;52;50;28;33;0.06;3;[];['    testPickle', '    register_take_instance', '    take_an_instance(const c10::intrusive_ptr & instance)', '    test_with_obj', '    testTorchbindIValueAPI', '    add(int64_t z)', '    combine(c10::intrusive_ptr b)', '    Foo', '    Foo(int x_,int y_)', '    increment(int64_t z)', '    info', '    ~Foo', '    clone', '    merge(const c10::intrusive_ptr & c)', '    MyStackClass(std::vector init)', '    pop', '    push(T)', '    return_a_tuple', '    PickleTester(std::vector vals)'];
activation_ops_cudnn.h;C++;pytorch-master/pytorch-master/caffe2/operators; 140;  5; 20;8;  110; 0;29;45;110;118;0.05;9;[];['    testIValueKWargs', '    testCustomOperatorAliasing', '    testCustomOperators'];
alias_with_name.h;C++;pytorch-master/pytorch-master/caffe2/operators; 46;  4; 10;6;  28; 0;5;18;26;35;0.14;2;[];['    get_autograd_operator_from_registry_and_execute', '    get_autograd_operator_from_registry_and_execute_in_nograd_mode', '    get_operator_from_registry_and_execute', '    check_all_parameters(const torch::jit::Module & module,Predicate predicate)', '    get_operator_from_registry_and_execute(const char *op_name,Args,...)', '    load_serialized_module_with_custom_op_and_execute(const std::string & path_to_exported_script_module)', '    main(int argc,const char *[] argv)', '    test_argument_checking_for_serialized_modules(const std::string & path_to_exported_script_module)', '    test_move_to_device(const std::string & path_to_exported_script_module)', '    test_move_to_dtype(const std::string & path_to_exported_script_module)'];
arg_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 100;  2; 13;9;  78; 0;29;47;40;49;0.03;4;[];['    testDCE'];
assert_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 51;  3; 10;5;  35; 0;7;16;25;32;0.09;4;['    DistAutogradTest'];['    tensors', '    TEST_F(DistAutogradTest,TestSendFunctionInvalidInputs)', '    TEST_F(DistAutogradTest,TestInitializedContextCleanup)', '    TEST_F(DistAutogradTest,TestInitializedContextCleanupSendFunction)', '    SetUpTestCase', '  Static Member Variables', '    autogradContainer_'];
batch_box_cox_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 342;  7; 23;43;  63; 244;35;51;17;56;0.11;3;[];['    test_01(const ExprHandle & expr)', '    testCond01', '    testExprBinaryMath01', '    testExprBitwiseOps', '    testExprDynamicShapeAdd', '    testExprMath01', '    testExprSubstitute01', '    testExprUnaryMath01', '    testIfThenElse01', '    testIfThenElse02', '    testStmtClone', '    testExprBasicValueTest', '    testExprBasicValueTest02', '    testExprByteTest', '    testExprCharTest', '    testExprCompareSelectEQ', '    testExprDoubleTest', '    testExprFloatTest', '    testExprHalfTest', '    testExprIntTest', '    testExprLetStmtTest01', '    testExprLetTest01', '    testExprLetTest02', '    testExprLongTest', '    testExprShortTest', '    testExprVectorAdd01'];
batch_gather_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  1; 26;1;  38; 0;30;36;6;22;0.03;6;[];['    graph_strings', '    i', '    testSimple', '    testFusion', '    testRegisterFusionCachesKernel'];
batch_matmul_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 91;  2; 10;5;  76; 0;46;25;39;20;0.03;5;[];['    testGraphExecutor'];
batch_permutation_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 169;  3; 53;16;  95; 10;56;51;34;51;0.03;10;[];['    extractDispatchKey(const at::Tensor & t)', '    callOp(const c10::OperatorHandle & op,Args,...)', '    callOpUnboxed(const c10::OperatorHandle & op,Args,...)', '    callOpUnboxedWithDispatchKey(const c10::OperatorHandle & op,c10::DispatchKey dispatchKey,Args,...)', '    dummyTensor(c10::DispatchKeySet ks)', '    dummyTensor(c10::DispatchKey dispatch_key)', '    expectDoesntFindKernel(const char *op_name,c10::DispatchKey dispatch_key)', '    expectDoesntFindOperator(const char *op_name)', '    expectListEquals(c10::ArrayRef expected,c10::List actual)', '    expectListEquals(c10::ArrayRef expected,std::vector actual)', '    expectThrows(Functor,const char *expectMessageContains)', '    makeStack(Inputs,...)', '    make_tensor', '    DispatchKeySet', '    make_intrusive', '    singleton', '    HasSubstr'];
batch_sparse_to_dense_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 151;  7; 24;6;  116; 0;65;70;82;101;0.06;8;[];['    testInliner', '    InlinerGuard(bool shouldInline)', '    ~InlinerGuard'];
bisect_percentile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 168;  10; 18;8;  135; 0;58;69;75;69;0.07;4;[];['    import_libs(std::shared_ptr cu,const std::string & class_name,const std::shared_ptr & src,const std::vector & tensor_table)', '    testModuleInterfaceSerialization'];
boolean_unmask_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  1; 6;5;  9; 0;0;6;17;28;0.11;2;[];['    testInterp'];
bucketize_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 77;  3; 28;3;  45; 0;35;36;12;27;0.07;4;[];['    testAttributes', '    testBlocks', '    testCommonAncestor', '    value_names'];
cast_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 240;  8; 88;1;  144; 0;100;65;50;58;0.06;10;[];['    testIRPrinterBasicValueTest', '    testIRPrinterBasicValueTest02', '    testIRPrinterCastTest', '    testIRPrinterLetTest01', '    testIRPrinterLetTest02'];
cc_bmm_bg_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 13;  1; 4;1;  8; 0;4;6;1;7;0.13;2;[];['    checkRoundtrip(const std::string & s)', '    testIRParser'];
channel_backprop_stats_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 82;  1; 18;2;  62; 0;55;41;19;22;0.02;3;[];['    testUnifyTypes'];
channel_stats_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 78;  1; 13;2;  63; 0;29;48;13;36;0.02;3;['    TorchBindLiteInterpreterTestStruct'];['    reg', '    testLiteInterpreterAdd', '    testLiteInterpreterBuiltinFunction', '    testLiteInterpreterConv', '    testLiteInterpreterInline', '    testLiteInterpreterLoadOrigJit', '    testLiteInterpreterParams', '    testLiteInterpreterPrim', '    testLiteInterpreterPrimOverload', '    testLiteInterpreterSetState', '    testLiteInterpreterTuple', '    testLiteInterpreterUpsampleNearest2d', '    testLiteInterpreterWrongMethodName', '    train_inputs', '    train_inputs', '    vector', '    get(at::Tensor t)'];
collect_and_distribute_fpn_rpn_proposals_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 675;  118; 70;1;  489; 0;350;360;103;183;0.24;17;[];[];
concat_split_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 513;  11; 156;1;  348; 0;230;213;119;172;0.03;16;[];['    remove_space(const std::string & str)', '    b', '    c', '    c', '    c', '    d', '    tensor', '    tensor', '    tensor', '    testScheduleDynamicShape2D', '    e', '    f', '    g', '    InlineFunc01Helper(const std::vector & inline_order)', '    testExprLower01', '    testExprSimple01', '    testExprSimple02', '    testExprSplitWithMask01', '    testExprSplitWithTailNone', '    testScheduleBroadcastAddBuffer', '    testScheduleFunctionCall01', '    testScheduleFuserStyle', '    testScheduleFuserThreeArg', '    testScheduleInlineFunc01', '    x', '    y', '    z', '    z2'];
conditional_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 24;  1; 7;6;  11; 0;0;8;17;27;0.09;1;['    TestThreadLocalDebugInfo'];['    checkShape(Node *n,std::vector expected,bool prev)', '    checkDebugInfo', '    checkTracedInputs(const TracedTestInputs & inputs)', '    eltwise', '    expected', '    expectedAfter', '    expectedBefore', '    fakePass(std::shared_ptr & g)', '    invokeTestRecordFunction(at::Tensor & t)', '    invokeTestRecordFunctionJIT(at::Tensor & t)', '    is', '    is', '    is', '    mm_expected', '    run', '    run_test_function', '    testAutogradProfiler', '    testAutogradSymbols', '    testCallStack', '    testCallStackCaching', '    testInsertAndEliminateRedundantGuards', '    testInsertBailOuts', '    testModuleConversion', '    testModuleDefine', '    testNoneSchemaMatch', '    testPassManagement', '    testProfiler', '    testRecordFunction', '    testThreadLocalDebugInfo', '    testTopologicalIndex', '    aliasAnalysisFromSchema', '    operator<<(std::ostream & out,const std::vector & list)', '    testATenNativeBatchNorm', '    testControlFlow', '    testCustomFusion', '    testCustomFusionNestedBlocks', '    testEvalModeForLoadedModule', '    testFromQualString', '    testInternedStrings', '    testProto', '    testSchemaParser', '    testSerializationInterop', '    testTHNNConv', '    testTorchSaveError', '    getModelId', '    setModelId(int model_id)', '    ~TestThreadLocalDebugInfo'];
conv_op_cache_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 14;  2; 4;4;  6; 0;0;2;0;5;0.33;0;[];['    testMobileTypeParser'];
conv_op_eigen.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 221;  0; 1;8;  0; 216;0;0;0;0;0.00;0;[];['    testModuleClone', '    testModuleCloneInstance', '    testModuleConstant', '    testModuleParameter'];
conv_op_shared.h;C++;pytorch-master/pytorch-master/caffe2/operators; 25;  10; 5;6;  6; 0;0;6;0;3;1.67;0;[];['    TEST(TestParallel,TestParallel)', '    TEST(TestParallel,NestedParallel)', '    TEST(TestParallel,Exceptions)', '    TEST(TestParallel,IntraOpLaunchFuture)'];
conv_transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 126;  1; 71;2;  53; 0;51;53;1;7;0.02;2;[];['    testPeepholeOptimize'];
conv_transpose_op_impl.h;C++;pytorch-master/pytorch-master/caffe2/operators; 646;  22; 40;16;  565; 7;314;450;125;364;0.04;3;[];['    testQualifiedName'];
conv_transpose_op_mobile_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 200;  5; 26;10;  132; 28;97;47;61;32;0.04;5;[];['    testSaveExtraFilesHook', '    testTypeTags'];
copy_rows_to_tensor_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 69;  3; 16;1;  52; 0;28;38;6;27;0.06;5;[];['    testSchemaMatching'];
cosh_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 115;  4; 46;3;  66; 0;36;49;8;24;0.06;7;[];['    testSimplifyAdd', '    testSimplifyAdds', '    testSimplifyCasts', '    testSimplifyDeeperDifference', '    testSimplifyDeeperTerms', '    testSimplifyEliminatesNoOps', '    testSimplifyEliminatesVar', '    testSimplifyFactorization', '    testSimplifyFactorizeUneven', '    testSimplifyFoldComplexDifference', '    testSimplifyIfComponents', '    testSimplifyManyOps', '    testSimplifyMuls', '    testSimplifyMultiLayer', '    testSimplifyMultiOp', '    testSimplifyMultiTerm', '    testSimplifyMultiVar', '    testSimplifyOpaqueTerms', '    testSimplifyReorderings', '    testSimplifySub', '    testSimplifySubs', '    testSimplifyWontReorderFloat', '    testConstantFoldBitwise', '    testConstantFoldIntrinsics', '    testConstantFoldMinMax', '    testConstantFoldMultiOp', '    testConstantFoldShifts', '    testConstantFoldSimple', '    testConstantFoldTwoLayer', '    testConstantFoldWithVar', '    testHashDifferenceTypes', '    testHashEquivalence', '    testHashEquivalenceAfterFolding', '    testHashLargeExpression', '    testHashSimple', '    testUnFoldableExpr'];
counter_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 307;  15; 118;2;  173; 0;127;143;34;80;0.09;18;[];['    testBadPattern', '    testDiamond1', '    testDiamond2', '    testLinear1', '    testLinear2', '    testMatchesAttributes', '    testMatchInBasicBlocks1', '    testMatchInBasicBlocks2', '    testMultipleMatches', '    testOverlappingMatches', '    testSubgraphMatching', '    testTrivial1', '    testTrivial2', '    testTrivial3', '    testTrivial4', '    testXPattern'];
create_scope_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 45;  1; 15;1;  29; 0;16;20;9;32;0.03;8;[];['    testFilterMatch', '    testFilterNoMatch', '    testSubgraphRewriter'];
cross_entropy_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 159;  16; 24;7;  114; 0;5;62;177;277;0.14;22;[];['    testSubgraphUtils'];
ctc_greedy_decoder_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 31;  3; 7;5;  18; 0;2;11;18;30;0.17;1;[];['    testTypePropagation', '    testTypeTest01'];
data_couple.h;C++;pytorch-master/pytorch-master/caffe2/operators; 22;  3; 6;5;  10; 0;1;6;1;5;0.30;3;[];['    BBPrinter(nom::repr::NNCFGraph::NodeRef node)', '    cfgEdgePrinter(nom::repr::NNCFGraph::EdgeRef edge)', '    createGraph', '    createGraphWithCycle', '    createTestNode(nom::Graph & g)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    TestNodePrinter(nom::Graph::NodeRef)', '    to_string(T value)'];
deform_conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 56;  1; 12;3;  41; 0;39;41;0;3;0.02;1;['    TestClass', '    TestRandom'];['    BBPrinter(nom::repr::NNCFGraph::NodeRef node)', '    cfgEdgePrinter(nom::repr::NNCFGraph::EdgeRef edge)', '    createGraph', '    createGraphWithCycle', '    createTestNode(nom::Graph & g)', '    NNPrinter(nom::repr::NNGraph::NodeRef node)', '    TestNodePrinter(nom::Graph::NodeRef)', '    equal(const nom::repr::NNGraph::NodeRef & a,const nom::repr::NNGraph::NodeRef & b)', '    TestClass', '    ~TestClass', '    nextInt', '    TestRandom(unsigned int seed)'];
dense_vector_to_id_list_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  2; 13;7;  45; 0;28;22;37;44;0.04;4;[];['    assertTensorEqualsWithType(const caffe2::TensorCPU & tensor1,const caffe2::TensorCPU & tensor2,float)', '    assertTensorEqualsWithType(const caffe2::TensorCPU & tensor1,const caffe2::TensorCPU & tensor2,float eps)', '    assertNear(float value1,float value2,float epsilon)', '    assertTensorEquals(const TensorCPU & tensor1,const TensorCPU & tensor2,float eps)', '    assertTensorListEquals(const std::vector & tensorNames,const Workspace & workspace1,const Workspace & workspace2)', '    createOperator(const std::string & type,const std::vector & inputs,const std::vector & outputs,caffe2::NetDef *net)', '    createTensor(const std::string & name,caffe2::Workspace *workspace)', '    getTensor(const caffe2::Workspace & workspace,const std::string & name)', '    externalInputs(const std::vector & externalInputs)', '    externalOutputs(const std::vector & externalOutputs)', '    newOp(const std::string & type,const std::vector & inputs,const std::vector & outputs)', '    setDeviceOptionName(const std::string & name)'];
do_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 183;  9; 19;12;  146; 0;79;45;107;64;0.06;5;[];['    unpackReturnTuple(Stack & stack)', '    f_code', '    f_interpreter', '    almostEqual(const at::Tensor & a,const at::Tensor & b)', '    assertAllClose(const tensor_list & a,const tensor_list & b)', '    build_lstm', '    checkRtol(const at::Tensor & diff,const std::vector inputs)', '    createStack(std::vector)', '    exactlyEqual(const at::Tensor & a,const at::Tensor & b)', '    lstm(at::Tensor input,at::Tensor hx,at::Tensor cx,at::Tensor w_ih,at::Tensor w_hh)', '    run(InterpreterState & interp,const std::vector & inputs)', '    runGradient(Gradient & grad_spec,tensor_list & tensors_in,tensor_list & tensor_grads_in)', '    t_def(at::Tensor x)', '    t_use(at::Tensor x)'];
dropout_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 298;  3; 3;6;  2; 285;0;2;0;2;1.50;0;[];['    almostEqual(const at::Tensor & a,const at::Tensor & b)', '    assertAllClose(const tensor_list & a,const tensor_list & b)', '    build_lstm', '    checkRtol(const at::Tensor & diff,const std::vector inputs)', '    createStack(std::vector)', '    exactlyEqual(const at::Tensor & a,const at::Tensor & b)', '    lstm(at::Tensor input,at::Tensor hx,at::Tensor cx,at::Tensor w_ih,at::Tensor w_hh)', '    run(InterpreterState & interp,const std::vector & inputs)', '    runGradient(Gradient & grad_spec,tensor_list & tensors_in,tensor_list & tensor_grads_in)', '    t_def(at::Tensor x)', '    t_use(at::Tensor x)'];
elementwise_add_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 4;2;  11; 0;2;4;2;9;0.09;2;[];[];
elementwise_linear_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 198;  1; 79;1;  118; 0;93;93;46;67;0.01;8;['    NetMutator', '    WorkspaceMutator'];['    assertNear(float value1,float value2,float epsilon)', '    assertTensor(const TensorCPU & tensor,const std::vector & sizes,const std::vector & data,float epsilon)', '    assertTensorEquals(const TensorCPU & tensor1,const TensorCPU & tensor2,float eps)', '    assertTensorEquals(const TensorCPU & tensor,const std::vector & data,float epsilon)', '    assertTensorListEquals(const std::vector & tensorNames,const Workspace & workspace1,const Workspace & workspace2)', '    constantFillTensor(const vector & shape,const T & data,TensorCPU *tensor)', '    createOperator(const std::string & type,const std::vector & inputs,const std::vector & outputs,caffe2::NetDef *net)', '    createTensor(const std::string & name,caffe2::Workspace *workspace)', '    createTensorAndConstantFill(const std::string & name,const std::vector & shape,const T & data,Workspace *workspace)', '    createTensorAndFill(const std::string & name,const std::vector & shape,const std::vector & data,Workspace *workspace)', '    createTensorAndFill(const std::vector & shape,const std::vector & data)', '    fillTensor(const std::vector & shape,const std::vector & data,TensorCPU *tensor)', '    getTensor(const caffe2::Workspace & workspace,const std::string & name)', '    randomFill(RealType *data,size_t size,const double min,const double max)', '    addArgument(const std::string & name,const T & value)', '    externalInputs(const std::vector & externalInputs)', '    externalOutputs(const std::vector & externalOutputs)', '    NetMutator(caffe2::NetDef *net)', '    newOp(const std::string & type,const std::vector & inputs,const std::vector & outputs)', '    setDeviceOptionName(const std::string & name)', '    newTensor(const std::string & name,const std::vector & shape,const std::vector & data)', '    newTensorConst(const std::string & name,const std::vector & shape,const T & data)', '    WorkspaceMutator(caffe2::Workspace *workspace)'];
elementwise_mul_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 248;  17; 24;5;  206; 0;128;95;51;45;0.08;7;[];['    TEST(WireSerialize,Base)', '    TEST(WireSerialize,RecopySparseTensors)', '    TEST(WireSerialize,CloneSparseTensors)', '    TEST(WireSerialize,DISABLED_Sparse)'];
elementwise_op_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 38;  0; 9;2;  27; 0;7;13;7;8;0.00;7;[];[];
elementwise_ops_schema.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 991;  2; 579;44;  368; 0;302;273;10;102;0.01;28;[];['    testADFormulas', '    testAliasAnalysis', '    testAliasRegistration', '    testArgumentSpec', '    testATenNativeBatchNorm', '    testAttributes', '    testAutogradSymbols', '    testBlocks', '    testCallStack', '    testCallStackCaching', '    testClassDerive', '    testClassImport', '    testClassParser', '    testClassTypeAddRemoveAttr', '    testCodeTemplate', '    testCommonAncestor', '    testCompleteArgumentSpec', '    testConstantPooling', '    testContainerAliasing', '    testControlFlow', '    testCreateAutodiffSubgraphs', '    testCustomFusion', '    testCustomFusionNestedBlocks', '    testCustomOperatorAliasing', '    testCustomOperators', '    testDCE', '    testDifferentiate', '    testDifferentiateWithRequiresGrad', '    testEvalModeForLoadedModule', '    testFromQualString', '    testFusion', '    testGraphExecutor', '    testInliner', '    testInsertAndEliminateRedundantGuards', '    testInsertBailOuts', '    testInternedStrings', '    testInterp', '    testIRParser', '    testIValueKWargs', '    testLiteInterpreterAdd', '    testLiteInterpreterBuiltinFunction', '    testLiteInterpreterConv', '    testLiteInterpreterInline', '    testLiteInterpreterLoadOrigJit', '    testLiteInterpreterParams', '    testLiteInterpreterPrim', '    testLiteInterpreterSetState', '    testLiteInterpreterTuple', '    testLiteInterpreterUpsampleNearest2d', '    testLiteInterpreterWrongMethodName', '    testMemoryDAG', '    testMobileTypeParser', '    testModuleClone', '    testModuleCloneInstance', '    testModuleConstant', '    testModuleConversion', '    testModuleDefine', '    testModuleInterfaceSerialization', '    testModuleParameter', '    testNoneSchemaMatch', '    testPassManagement', '    testPeepholeOptimize', '    testProfiledTensorTypeHashing', '    testProfiler', '    testProto', '    testQualifiedName', '    testRecordFunction', '    testRegisterFusionCachesKernel', '    testSaveExtraFilesHook', '    testSaveLoadTorchbind', '    testSchemaMatching', '    testSchemaParser', '    testScriptObject', '    testSerializationInterop', '    testSubgraphMatching', '    testSubgraphRewriter', '    testSubgraphUtils', '    testTHNNConv', '    testThreadLocalDebugInfo', '    testTopologicalIndex', '    testTopologicalMove', '    testTorchbindIValueAPI', '    testTorchSaveError', '    testTypeTags', '    testUnifyTypes', '    testWildcards', '    testWriteTracking'];
elementwise_sub_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;1;  5; 0;1;3;1;5;0.20;1;[];['    testATen_cast_Float', '    testATen_sigmoid_backward', '    testATen_tanh_backward', '    testATenaddcmulFloat', '    testATenaddcmulInt', '    testATenaddFloat', '    testATenaddInt', '    testATencosFloat', '    testATendivFloat', '    testATendivInt', '    testATeneqInt', '    testATenerfFloat', '    testATenexpFloat', '    testATengeInt', '    testATengtInt', '    testATenleInt', '    testATenlerp', '    testATenlog10Float', '    testATenlog2Float', '    testATenlogFloat', '    testATenltInt', '    testATenmaxFloat', '    testATenmaxInt', '    testATenminFloat', '    testATenminInt', '    testATenmulFloat', '    testATenmulInt', '    testATennegFloat', '    testATennegInt', '    testATenreciprocal', '    testATenreluFloat', '    testATenreluInt', '    testATensubFloat', '    testATensubInt', '    testCond01', '    testConstantFoldBitwise', '    testConstantFoldIntrinsics', '    testConstantFoldMinMax', '    testConstantFoldMultiOp', '    testConstantFoldShifts', '    testConstantFoldSimple', '    testConstantFoldTwoLayer', '    testConstantFoldWithVar', '    testExprBasicValueTest', '    testExprBasicValueTest02', '    testExprBinaryMath01', '    testExprBitwiseOps', '    testExprByteTest', '    testExprCharTest', '    testExprCompareSelectEQ', '    testExprDoubleTest', '    testExprDynamicShapeAdd', '    testExprFloatTest', '    testExprHalfTest', '    testExprIntTest', '    testExprLetStmtTest01', '    testExprLetTest01', '    testExprLetTest02', '    testExprLongTest', '    testExprLower01', '    testExprMath01', '    testExprShortTest', '    testExprSimple01', '    testExprSimple02', '    testExprSplitWithMask01', '    testExprSplitWithTailNone', '    testExprSubstitute01', '    testExprUnaryMath01', '    testExprVectorAdd01', '    testHashDifferenceTypes', '    testHashEquivalence', '    testHashEquivalenceAfterFolding', '    testHashLargeExpression', '    testHashSimple', '    testIfThenElse01', '    testIfThenElse02', '    testIRPrinterBasicValueTest', '    testIRPrinterBasicValueTest02', '    testIRPrinterCastTest', '    testIRPrinterLetTest01', '    testIRPrinterLetTest02', '    testScheduleBroadcastAddBuffer', '    testScheduleDynamicShape2D', '    testScheduleFunctionCall01', '    testScheduleFuserStyle', '    testScheduleFuserThreeArg', '    testScheduleInlineFunc01', '    testSimplifyAdd', '    testSimplifyAdds', '    testSimplifyCasts', '    testSimplifyDeeperDifference', '    testSimplifyDeeperTerms', '    testSimplifyEliminatesNoOps', '    testSimplifyEliminatesVar', '    testSimplifyFactorization', '    testSimplifyFactorizeUneven', '    testSimplifyFoldComplexDifference', '    testSimplifyIfComponents', '    testSimplifyManyOps', '    testSimplifyMuls', '    testSimplifyMultiLayer', '    testSimplifyMultiOp', '    testSimplifyMultiTerm', '    testSimplifyMultiVar', '    testSimplifyOpaqueTerms', '    testSimplifySub', '    testSimplifySubs', '    testSimplifyWontReorderFloat', '    testStmtClone', '    testTypePropagation', '    testTypeTest01', '    testUnFoldableExpr'];
elu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 145;  7; 60;5;  78; 0;43;55;11;25;0.09;8;['    Semaphore'];['    isTSANEnabled', '    tmppath', '    Fork', '    isChild', '    ~Fork', '    post(int n)', '    wait(int n)', '    TemporaryFile', '    ~TemporaryFile'];
enforce_finite_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 47;  2; 10;7;  30; 0;6;16;23;33;0.07;4;['    CreateTextFileReaderOp', '    TextFileReaderReadOp'];['    CAFFE_ANONYMOUS_VARIABLE_CPUCreateTextFileReader', '    CAFFE_ANONYMOUS_VARIABLE_CPUTextFileReaderRead', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CreateTextFileReader', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TextFileReaderRead', '    convert(TensorProto_DataType dst_type,const char *src_start,const char *src_end,void *dst)', '    noexcept', '    CreateTextFileReaderOp(Args,...)', '    RunOnDevice', '    rowsRead', '    TextFileReaderInstance(const std::vector & delims,char escape,const std::string & filename,int numPasses,const std::vector & types)', '    RunOnDevice', '    TextFileReaderReadOp(Args,...)'];
ensure_cpu_output_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 51;  4; 7;6;  36; 0;19;12;27;30;0.11;3;[];['    FileReader(const std::string & path,size_t bufferSize)', '    operator()(CharRange & range)', '    reset', '    ~FileReader', '    next(char *start,char *end,TokenizedString & tokenized)', '    reset', '    Tokenizer(const std::vector & delims,char escape)'];
exp_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  2; 5;5;  10; 0;2;6;2;3;0.20;1;['    BufferedTokenizer', '    FileReader', '    TokenizedString', '    Tokenizer'];['    BufferedTokenizer(const Tokenizer & t,StringProvider *p,int numPasses)', '    endDelim', '    next(Token & token)', '    pass_', '    FileReader(const std::string & path,size_t bufferSize)', '    operator()(CharRange & range)', '    reset', '    ~FileReader', '    operator()(CharRange &)', '    reset', '    ~StringProvider', '    lastDelim', '    tokens', '    next(char *start,char *end,TokenizedString & tokenized)', '    reset', '    Tokenizer(const std::vector & delims,char escape)'];
expand_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 17;  1; 3;2;  12; 0;2;4;2;9;0.08;2;[];['    TEST(TextFileReaderUtilsTest,TokenizeTest)', '    charIdx', '    ChunkProvider(const std::string & str)', '    operator()(CharRange & range)', '    reset'];
add_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 84;  2; 9;4;  71; 0;41;31;23;22;0.03;1;[];[];
cast_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 100;  5; 9;6;  82; 0;53;27;68;17;0.06;3;[];['    deleteTHMapAllocator(void *ptr)', '    deleteTHRefcountedMapAllocator(void *ptr)', '    WaitForReleaseHandle(PVOID lpParam,BOOLEAN TimerOrWaitFired)', '    getTHDefaultAllocator', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    close', '    THMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THMapAllocator(const char *filename,int flags,size_t size)', '    close', '    data', '    initializeAlloc', '    THRefcountedMapAllocator(const char *filename,int flags,size_t size)', '    THRefcountedMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THRefcountedMapAllocatorArgCheck(int flags)'];
fc_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 142;  9; 16;7;  112; 0;80;33;37;22;0.08;2;['    THMapAllocator', '    THRefcountedMapAllocator'];['    getTHDefaultAllocator', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    fromDataPtr(const at::DataPtr & dptr)', '    makeDataPtr(const char *filename,int flags,size_t size,size_t *actual_size_out)', '    makeDataPtr(WithFd,const char *filename,int fd,int flags,size_t size,size_t *actual_size_out)', '    close', '    data', '    fd', '    filename', '    operator=', '    operator=', '    size', '    THMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    THMapAllocator(const char *filename,int flags,size_t size)', '    THMapAllocator', '    THMapAllocator', '    ~THMapAllocator', '    checkFlags', '    close', '    data', '    decref', '    incref', '    initializeAlloc', '    THRefcountedMapAllocator(const char *filename,int flags,size_t size)', '    THRefcountedMapAllocator(WithFd,const char *filename,int fd,int flags,size_t size)', '    ~THRefcountedMapAllocator', '    THRefcountedMapAllocatorArgCheck(int flags)'];
relu_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 54;  9; 8;8;  23; 8;8;15;3;8;0.39;1;[];[];
stop_gradient_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/experimental/c10/cpu; 35;  2; 6;4;  25; 0;8;17;4;9;0.08;1;[];[];
feature_maps_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 785;  3; 85;5;  695; 0;447;351;422;496;0.00;42;[];[];
filler_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 566;  24; 52;7;  486; 0;284;157;392;343;0.05;29;[];[];
find_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 78;  7; 13;7;  53; 0;26;29;35;45;0.13;3;[];['    THBlas_axpy(int64_t n,T a,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_axpy(int64_t n,uint8_t a,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int8_t a,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int16_t a,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,int a,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_axpy(int64_t n,int64_t a,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_axpy(int64_t n,float a,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_axpy(int64_t n,double a,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_copy(int64_t n,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_copy(int64_t n,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_copy(int64_t n,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_copy(int64_t n,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_copy(int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_copy(int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_dot(int64_t n,T *x,int64_t incx,T *y,int64_t incy)', '    THBlas_dot(int64_t n,uint8_t *x,int64_t incx,uint8_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int8_t *x,int64_t incx,int8_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int16_t *x,int64_t incx,int16_t *y,int64_t incy)', '    THBlas_dot(int64_t n,int *x,int64_t incx,int *y,int64_t incy)', '    THBlas_dot(int64_t n,int64_t *x,int64_t incx,int64_t *y,int64_t incy)', '    THBlas_dot(int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THBlas_dot(int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,T alpha,T *a,int64_t lda,T *b,int64_t ldb,T beta,T *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,uint8_t alpha,uint8_t *a,int64_t lda,uint8_t *b,int64_t ldb,uint8_t beta,uint8_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int8_t alpha,int8_t *a,int64_t lda,int8_t *b,int64_t ldb,int8_t beta,int8_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int16_t alpha,int16_t *a,int64_t lda,int16_t *b,int64_t ldb,int16_t beta,int16_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int alpha,int *a,int64_t lda,int *b,int64_t ldb,int beta,int *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,int64_t alpha,int64_t *a,int64_t lda,int64_t *b,int64_t ldb,int64_t beta,int64_t *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,float *a,int64_t lda,float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    THBlas_gemm(char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,double *a,int64_t lda,double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    THBlas_gemv(char transa,int64_t m,int64_t n,T alpha,T *a,int64_t lda,T *x,int64_t incx,T beta,T *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,uint8_t alpha,uint8_t *a,int64_t lda,uint8_t *x,int64_t incx,uint8_t beta,uint8_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int8_t alpha,int8_t *a,int64_t lda,int8_t *x,int64_t incx,int8_t beta,int8_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int16_t alpha,int16_t *a,int64_t lda,int16_t *x,int64_t incx,int16_t beta,int16_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int alpha,int *a,int64_t lda,int *x,int64_t incx,int beta,int *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,int64_t alpha,int64_t *a,int64_t lda,int64_t *x,int64_t incx,int64_t beta,int64_t *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,float alpha,float *a,int64_t lda,float *x,int64_t incx,float beta,float *y,int64_t incy)', '    THBlas_gemv(char transa,int64_t m,int64_t n,double alpha,double *a,int64_t lda,double *x,int64_t incx,double beta,double *y,int64_t incy)'];
flexible_top_k.h;C++;pytorch-master/pytorch-master/caffe2/operators; 38;  3; 11;6;  20; 0;0;14;34;53;0.15;2;[];[];
free_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 29;  5; 6;5;  15; 0;3;9;3;5;0.33;2;[];['    deleteTHCIpcDeleter(void *ptr)', '    makeDataPtr(std::shared_ptr basePtr,void *data)', '    THCIpcDeleter(std::shared_ptr basePtr)', '    ~THCIpcDeleter'];
fully_connected_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 219;  60; 14;7;  140; 56;91;32;31;31;0.43;9;['    THCIpcDeleter'];['    makeDataPtr(std::shared_ptr basePtr,void *data)', '    THCIpcDeleter(std::shared_ptr basePtr)', '    ~THCIpcDeleter'];
fused_rowwise_nbit_conversion_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 203;  20; 32;16;  132; 5;82;66;55;51;0.15;6;[];['    THCudaBlas_Ddot(THCState *state,int64_t n,double *x,int64_t incx,double *y,int64_t incy)', '    THCudaBlas_Dgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,double *a,int64_t lda,double *b,int64_t ldb,double beta,double *c,int64_t ldc)', '    THCudaBlas_DgemmBatched(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,double alpha,const double *[] a,int64_t lda,const double *[] b,int64_t ldb,double beta,double *[] c,int64_t ldc,int64_t batchCount)', '    THCudaBlas_Dgemv(THCState *state,char trans,int64_t m,int64_t n,double alpha,double *a,int64_t lda,double *x,int64_t incx,double beta,double *y,int64_t incy)', '    THCudaBlas_Dger(THCState *state,int64_t m,int64_t n,double alpha,double *x,int64_t incx,double *y,int64_t incy,double *a,int64_t lda)', '    THCudaBlas_Hdot(THCState *state,int64_t n,at::Half *x,int64_t incx,at::Half *y,int64_t incy)', '    THCudaBlas_Hgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,at::Half alpha,at::Half *a,int64_t lda,at::Half *b,int64_t ldb,at::Half beta,at::Half *c,int64_t ldc)', '    THCudaBlas_Sdot(THCState *state,int64_t n,float *x,int64_t incx,float *y,int64_t incy)', '    THCudaBlas_Sgemm(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,float *a,int64_t lda,float *b,int64_t ldb,float beta,float *c,int64_t ldc)', '    THCudaBlas_SgemmBatched(THCState *state,char transa,char transb,int64_t m,int64_t n,int64_t k,float alpha,const float *[] a,int64_t lda,const float *[] b,int64_t ldb,float beta,float *[] c,int64_t ldc,int64_t batchCount)', '    THCudaBlas_Sgemv(THCState *state,char trans,int64_t m,int64_t n,float alpha,float *a,int64_t lda,float *x,int64_t incx,float beta,float *y,int64_t incy)', '    THCudaBlas_Sger(THCState *state,int64_t m,int64_t n,float alpha,float *x,int64_t incx,float *y,int64_t incy,float *a,int64_t lda)'];
fused_rowwise_random_quantization_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 93;  2; 15;22;  44; 14;7;24;41;64;0.05;6;[];['    BlockComparator(const BlockSize & a,const BlockSize & b)', '    THCCachingHostDeleter(void *ptr)', '    getTHCCachingHostAllocator', '    THCCachingHostAllocator_emptyCache', '    THCCachingHostAllocator_recordEvent(void *ptr,at::cuda::CUDAStream stream)', '    Block(size_t size,void *ptr,bool allocated)', '    BlockSize(size_t size,void *ptr)', '    allocate(size_t size)', '    raw_deleter', '    emptyCache', '    free(void *ptr)', '    HostAllocator', '    insertEvents(Block & block)', '    malloc(void **ptr,size_t size)', '    processEvents', '    recordEvent(void *ptr,at::cuda::CUDAStream stream)'];
gather_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 218;  32; 27;5;  157; 0;80;78;86;78;0.20;7;[];['    getTHCCachingHostAllocator', '    THCCachingHostAllocator_emptyCache', '    THCCachingHostAllocator_recordEvent(void *ptr,at::cuda::CUDAStream stream)'];
gelu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 62;  3; 16;8;  38; 0;1;30;0;17;0.08;2;[];['    __THCublasCheck(cublasStatus_t status,const char *file,const int line)', '    __THCudaCheck(cudaError_t err,const char *file,const int line)', '    __THCudaCheckWarn(cudaError_t err,const char *file,const int line)', '    __THCusparseCheck(cusparseStatus_t status,const char *file,const int line)', '    THCState_alloc', '    THCState_free(THCState *state)', '    THCState_getCudaHostAllocator(THCState *state)', '    THCState_getCurrentDeviceScratchSpaceSize(THCState *state)', '    THCState_getDeviceResourcePtr(THCState *state,int device)', '    THCState_getPeerToPeerAccess(THCState *state,int dev,int devToAccess)', '    THCudaFree(THCState *state,void *ptr)', '    THCudaHostAlloc(THCState *state,size_t size)', '    THCudaHostRecord(THCState *state,void *ptr)', '    THCudaInit(THCState *state)', '    THCudaMalloc(THCState *state,size_t size)', '    THCudaMemGetInfo(THCState *state,size_t *freeBytes,size_t *totalBytes,size_t *largestBlock)', '    THCudaShutdown(THCState *state)'];
generate_proposals_op_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 727;  43; 70;5;  615; 0;492;210;174;187;0.07;18;[];[];
generate_proposals_op_util_nms_gpu.h;C++;pytorch-master/pytorch-master/caffe2/operators; 70;  22; 9;5;  37; 0;0;36;0;7;0.59;0;[];[];
given_tensor_byte_string_to_uint8_fill_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 65;  1; 7;7;  51; 0;29;48;31;48;0.02;3;[];[];
glu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 56;  2; 8;5;  43; 0;16;23;24;36;0.05;2;[];[];
gru_unit_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 240;  15; 35;6;  190; 0;103;108;96;113;0.08;8;[];[];
half_float_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 96;  2; 18;5;  73; 0;11;41;83;120;0.03;8;[];[];
heatmap_max_keypoint_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 183;  30; 23;2;  133; 0;89;58;78;77;0.23;5;[];[];
if_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 61;  2; 12;6;  43; 0;19;16;41;35;0.05;2;[];[];
im2col_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 9;  1; 3;2;  4; 0;2;4;2;9;0.25;2;[];[];
index_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 123;  6; 18;11;  92; 0;42;37;41;37;0.07;15;[];[];
instance_norm_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 216;  2; 74;2;  140; 0;72;107;26;64;0.01;5;[];[];
is_empty_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 75;  1; 51;1;  23; 0;21;23;1;7;0.04;2;[];[];
key_split_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 11;  1; 3;3;  5; 0;2;5;1;9;0.20;2;[];[];
layer_norm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 277;  2; 28;10;  239; 0;124;151;80;132;0.01;8;[];[];
length_split_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 75;  4; 14;8;  51; 0;22;23;43;41;0.08;3;[];['    THC_sleep(THCState *state,int64_t cycles)'];
lengths_reducer_fused_8bit_rowwise_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 178;  4; 16;18;  61; 82;35;35;43;54;0.07;4;[];[];
lengths_reducer_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 256;  19; 18;11;  84; 135;45;44;46;54;0.23;5;[];['    THCStorage_getDevice(THCState *state,const THCStorage *storage)', '    THCStorage_new(THCState *state,caffe2::TypeMeta data_type)', '    THCStorage_resize(THCState *state,THCStorage *self,ptrdiff_t size)'];
lengths_tile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 29;  2; 8;5;  16; 0;2;10;18;32;0.13;4;[];[];
listwise_l2r_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 63;  2; 9;5;  48; 0;0;40;34;70;0.04;3;[];[];
load_save_op_util.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 128;  10; 6;1;  114; 0;51;25;62;14;0.09;3;[];['    THCStorage_getDevice(THCState *state,const THCStorage *storage)', '    THCStorage_new(THCState *state,caffe2::TypeMeta data_type)', '    THCStorage_newWithDataAndAllocator(THCState *state,at::ScalarType scalar_type,at::DataPtr,ptrdiff_t size,at::Allocator *allocator)', '    THCStorage_resize(THCState *state,THCStorage *self,ptrdiff_t size)', '    THCStorage_retain(THCState *state,THCStorage *storage)'];
local_response_normalization_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 219;  11; 35;4;  170; 0;58;82;134;139;0.06;8;[];[];
locally_connected_op_impl.h;C++;pytorch-master/pytorch-master/caffe2/operators; 864;  10; 46;11;  799; 0;638;212;228;296;0.01;7;[];['    TH(THCState *state,THCStorage *self,struct THStorage *src)', '    TH(THCState *state,THCStorage *self,struct THByteStorage *src)', '    TH(THCState *state,THCStorage *self,struct THCharStorage *src)', '    TH(THCState *state,THCStorage *self,struct THShortStorage *src)', '    TH(THCState *state,THCStorage *self,struct THIntStorage *src)', '    TH(THCState *state,THCStorage *self,struct THLongStorage *src)', '    TH(THCState *state,THCStorage *self,struct THFloatStorage *src)', '    TH(THCState *state,THCStorage *self,struct THHalfStorage *src)', '    TH(THCState *state,THCStorage *self,struct THDoubleStorage *src)', '    TH(THCState *state,THCStorage *self,struct THBoolStorage *src)', '    TH(THCState *state,THCStorage *self,struct THBFloat16Storage *src)', '    TH(THCState *state,THStorage *self,struct THCStorage *src)', '    TH(THCState *state,THByteStorage *self,struct THCStorage *src)', '    TH(THCState *state,THCharStorage *self,struct THCStorage *src)', '    TH(THCState *state,THShortStorage *self,struct THCStorage *src)', '    TH(THCState *state,THIntStorage *self,struct THCStorage *src)', '    TH(THCState *state,THLongStorage *self,struct THCStorage *src)', '    TH(THCState *state,THFloatStorage *self,struct THCStorage *src)', '    TH(THCState *state,THHalfStorage *self,struct THCStorage *src)', '    TH(THCState *state,THDoubleStorage *self,struct THCStorage *src)', '    TH(THCState *state,THBoolStorage *self,struct THCStorage *src)', '    TH(THCState *state,THBFloat16Storage *self,struct THCStorage *src)', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel', '    numel'];
log_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  2; 5;5;  10; 0;2;6;2;3;0.20;1;[];[];
loss_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 77;  1; 46;1;  30; 0;21;27;4;21;0.03;6;[];[];
lpnorm_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 50;  2; 10;6;  34; 0;2;22;40;57;0.06;2;[];[];
map_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 80;  1; 18;1;  61; 0;33;41;11;53;0.02;10;[];['    compareSizeAndStride(const void *a,const void *b)', '    THCTensor_all32BitIndexable(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allContiguous(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allSameDevice(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_canUse32BitIndexMath(THCState *state,const at::TensorImpl *t,ptrdiff_t max_elem)', '    THCTensor_free(THCState *state,at::TensorImpl *self)', '    THCTensor_getDevice(THCState *state,const at::TensorImpl *tensor)', '    THCTensor_maybeOverlappingIndices(THCState *state,const at::TensorImpl *t)', '    THCTensor_nDimension(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyAll(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyNoScalars(THCState *state,const at::TensorImpl *self)', '    THCTensor_nElement(THCState *state,const at::TensorImpl *self)', '    THCTensor_new(THCState *state,caffe2::TypeMeta type_meta)', '    THCTensor_preserveReduceDimSemantics(THCState *state,at::TensorImpl *tensor,int in_dims,int64_t dimension,int keepdim)', '    THCTensor_resize(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THCTensor_resizeAs(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_resizeNd(THCState *state,at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THCTensor_retain(THCState *state,at::TensorImpl *self)', '    THCTensor_set(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_setStorage(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THCTensor_size(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_sizeLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_squeeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    THCTensor_stride(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_strideLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_unsqueeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)'];
matmul_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 225;  9; 54;1;  162; 0;95;115;17;45;0.06;4;[];[];
mean_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 98;  1; 57;1;  40; 0;31;38;7;23;0.03;5;[];[];
minmax_gradient_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 66;  2; 12;4;  50; 0;26;28;22;37;0.04;7;[];['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim)', '    TH(THCState *state,at::TensorImpl *self,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim,int keepdim)', '    TH(THCState *state,const at::TensorImpl *self)', '    TH(THCState *state,const at::TensorImpl *self,int dim)', '    TH(THCState *state,at::TensorImpl *self,const char flag)', '    TH(THCState *state,at::TensorImpl *tensor,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_,int64_t size3_)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t size0_,int64_t size1_,int64_t size2_,int64_t size3_,int64_t size4_)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension_,int64_t firstIndex_,int64_t size_)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension_,int64_t sliceIndex_)', '    TH(THCState *state,const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(THCState *state,const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(THCState *state,unsigned int nTensors,...)'];
mod_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 40;  2; 9;6;  25; 0;5;14;24;33;0.08;2;[];['    THCTensor_all32BitIndexable(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allContiguous(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_allSameDevice(THCState *state,at::TensorImpl **inputs,int numInputs)', '    THCTensor_canUse32BitIndexMath(THCState *state,const at::TensorImpl *t,ptrdiff_t max_elem)', '    THCTensor_free(THCState *state,at::TensorImpl *self)', '    THCTensor_getDevice(THCState *state,const at::TensorImpl *tensor)', '    THCTensor_maybeOverlappingIndices(THCState *state,const at::TensorImpl *t)', '    THCTensor_nDimension(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyAll(THCState *state,const at::TensorImpl *self)', '    THCTensor_nDimensionLegacyNoScalars(THCState *state,const at::TensorImpl *self)', '    THCTensor_nElement(THCState *state,const at::TensorImpl *self)', '    THCTensor_new(THCState *state,caffe2::TypeMeta type_meta)', '    THCTensor_preserveReduceDimSemantics(THCState *state,at::TensorImpl *tensor,int in_dims,int64_t dimension,int keepdim)', '    THCTensor_resize(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THCTensor_resizeAs(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_resizeNd(THCState *state,at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THCTensor_retain(THCState *state,at::TensorImpl *self)', '    THCTensor_set(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    THCTensor_setStorage(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THCTensor_size(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_sizeLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_squeeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    THCTensor_stride(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_strideLegacyNoScalars(THCState *state,const at::TensorImpl *self,int dim)', '    THCTensor_unsqueeze1d(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dimension)'];
multi_class_accuracy_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 22;  2; 6;5;  11; 0;0;7;17;29;0.18;2;[];['    TH(THCState *state,at::TensorImpl *self,THCStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    TH(THCState *state,at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)'];
negative_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 81;  3; 43;3;  34; 0;22;30;3;16;0.09;4;[];[];
ngram_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 83;  6; 8;5;  65; 0;35;42;57;62;0.09;2;[];['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)'];
normalize_l1_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 39;  2; 9;6;  24; 0;11;17;19;37;0.08;3;[];[];
numpy_tile_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 116;  21; 18;8;  71; 0;38;35;51;50;0.30;5;[];['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *res_,int dim,at::TensorImpl *indices,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *src,int dim,at::TensorImpl *index)', '    TH(THCState *state,at::TensorImpl *res_,at::TensorImpl *indices,at::TensorImpl *src,int accumulate)'];
onnx_while_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 314;  27; 45;7;  238; 0;137;102;120;95;0.11;13;[];['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)'];
order_switch_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 89;  4; 21;2;  66; 0;50;62;6;30;0.06;8;[];[];
pack_rnn_sequence_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 107;  2; 58;1;  48; 0;30;42;14;34;0.04;8;[];['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int64_t k)'];
pad_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 464;  35; 30;11;  389; 0;147;126;102;136;0.09;11;[];['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)'];
percentile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 139;  1; 31;1;  107; 0;93;72;43;44;0.01;3;[];[];
piecewise_linear_transform_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 100;  3; 27;1;  70; 0;56;57;3;17;0.04;3;[];['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src)'];
pool_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 315;  3; 27;9;  279; 0;131;172;120;224;0.01;9;[];['    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,scalar_t value)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *res_,at::TensorImpl *indices,at::TensorImpl *src,int accumulate)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,scalar_t min_value,scalar_t max_value)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src1,scalar_t value,at::TensorImpl *src2)'];
pow_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 377;  78; 54;5;  244; 0;100;124;34;231;0.32;24;[];['    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)', '    TH(THCState *state,at::TensorImpl *self)', '    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim,int keepdim)'];
prelu_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 43;  1; 10;5;  28; 0;0;20;34;55;0.04;2;[];['    TH(THCState *state,at::TensorImpl *self,at::TensorImpl *src,int dim)'];
quant_decode_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 67;  1; 24;6;  34; 3;23;25;14;27;0.03;5;[];['    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)'];
init_qnnpack.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 17;  1; 5;3;  9; 0;2;5;1;18;0.11;1;[];['    THCRandom_getRNGState(at::Generator gen_,at::TensorImpl *rng_state)', '    THCRandom_setRNGState(at::Generator gen_,at::TensorImpl *rng_state)'];
int8_average_pool_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 152;  8; 18;15;  112; 5;77;63;41;24;0.07;5;[];[];
int8_concat_op.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 91;  6; 9;7;  72; 0;51;25;31;21;0.08;2;[];['    TH(THCState *state,at::TensorImpl *res_,int dim,at::TensorImpl *indices,at::TensorImpl *src)', '    TH(THCState *state,at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(THCState *state,at::TensorImpl *tensor,at::TensorImpl *src,int dim,at::TensorImpl *index)'];
int8_conv_transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 49;  1; 15;1;  33; 0;31;33;1;9;0.03;2;[];['    TH(THCState *state,at::TensorImpl *keys,at::TensorImpl *values,int dim,bool dir)', '    TH(THCState *state,at::TensorImpl *sorted,at::TensorImpl *indices,at::TensorImpl *input,int dim,int order)'];
int8_fc_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 48;  1; 20;3;  25; 0;22;24;2;10;0.04;2;[];['    TH(THCState *state,at::TensorImpl *topK,at::TensorImpl *indices,at::TensorImpl *input,int64_t k,int dim,int dir,int sorted)'];
int8_given_tensor_fill_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 34;  1; 7;1;  26; 0;24;26;2;15;0.04;4;[];[];
int8_max_pool_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 62;  1; 12;1;  49; 0;42;23;3;15;0.02;5;[];[];
int8_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 37;  3; 10;1;  25; 0;17;22;3;10;0.12;3;[];['    THDiskFile_close(THFile *self)', '    THDiskFile_free(THFile *self)', '    THDiskFile_isOpened(THFile *self)', '    THDiskFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THDiskFile_position(THFile *self)', '    THDiskFile_readByte(THFile *self,uint8_t *data,ssize_t n)', '    THDiskFile_readChar(THFile *self,int8_t *data,ssize_t n)', '    THDiskFile_readDouble(THFile *self,double *data,ssize_t n)', '    THDiskFile_readFloat(THFile *self,float *data,ssize_t n)', '    THDiskFile_readHalf(THFile *self,at::Half *data,ssize_t n)', '    THDiskFile_readInt(THFile *self,int32_t *data,ssize_t n)', '    THDiskFile_readLong(THFile *self,int64_t *data,ssize_t n)', '    THDiskFile_readShort(THFile *self,int16_t *data,ssize_t n)', '    THDiskFile_readString(THFile *self,const char *format,char **str_)', '    THDiskFile_reverseMemory(void *dst,const void *src,ssize_t blockSize,ssize_t numBlocks)', '    THDiskFile_seek(THFile *self,ssize_t position)', '    THDiskFile_seekEnd(THFile *self)', '    THDiskFile_synchronize(THFile *self)', '    THDiskFile_writeByte(THFile *self,uint8_t *data,ssize_t n)', '    THDiskFile_writeChar(THFile *self,int8_t *data,ssize_t n)', '    THDiskFile_writeDouble(THFile *self,double *data,ssize_t n)', '    THDiskFile_writeFloat(THFile *self,float *data,ssize_t n)', '    THDiskFile_writeHalf(THFile *self,at::Half *data,ssize_t n)', '    THDiskFile_writeInt(THFile *self,int32_t *data,ssize_t n)', '    THDiskFile_writeLong(THFile *self,int64_t *data,ssize_t n)', '    THDiskFile_writeShort(THFile *self,int16_t *data,ssize_t n)', '    THDiskFile_writeString(THFile *self,const char *str,ssize_t size)', '    THPipeFile_free(THFile *self)', '    THPipeFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THDiskFile_bigEndianEncoding(THFile *self)', '    THDiskFile_isBigEndianCPU', '    THDiskFile_isLittleEndianCPU', '    THDiskFile_littleEndianEncoding(THFile *self)', '    THDiskFile_longSize(THFile *self,int size)', '    THDiskFile_name(THFile *self)', '    THDiskFile_nativeEndianEncoding(THFile *self)', '    THDiskFile_new(const char *name,const char *mode,int isQuiet)', '    THDiskFile_noBuffer(THFile *self)', '    THPipeFile_new(const char *name,const char *mode,int isQuiet)'];
int8_resize_nearest_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 26;  2; 9;1;  15; 0;13;15;1;7;0.13;2;[];['    THDiskFile_bigEndianEncoding(THFile *self)', '    THDiskFile_isBigEndianCPU', '    THDiskFile_isLittleEndianCPU', '    THDiskFile_littleEndianEncoding(THFile *self)', '    THDiskFile_longSize(THFile *self,int size)', '    THDiskFile_name(THFile *self)', '    THDiskFile_nativeEndianEncoding(THFile *self)', '    THDiskFile_new(const char *name,const char *mode,int isQuiet)', '    THDiskFile_noBuffer(THFile *self)', '    THPipeFile_new(const char *name,const char *mode,int isQuiet)'];
int8_roi_align_op_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 62;  2; 3;2;  56; 0;35;43;10;49;0.04;1;[];['    THFile_ascii(THFile *self)', '    THFile_autoSpacing(THFile *self)', '    THFile_binary(THFile *self)', '    THFile_clearError(THFile *self)', '    THFile_close(THFile *self)', '    THFile_free(THFile *self)', '    THFile_hasError(THFile *self)', '    THFile_isAutoSpacing(THFile *self)', '    THFile_isBinary(THFile *self)', '    THFile_isOpened(THFile *self)', '    THFile_isQuiet(THFile *self)', '    THFile_isReadable(THFile *self)', '    THFile_isWritable(THFile *self)', '    THFile_noAutoSpacing(THFile *self)', '    THFile_pedantic(THFile *self)', '    THFile_position(THFile *self)', '    THFile_quiet(THFile *self)', '    THFile_readByte(THFile *self,THByteStorage *storage)', '    THFile_readByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_readByteScalar(THFile *self)', '    THFile_readChar(THFile *self,THCharStorage *storage)', '    THFile_readCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_readCharScalar(THFile *self)', '    THFile_readDouble(THFile *self,THDoubleStorage *storage)', '    THFile_readDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_readDoubleScalar(THFile *self)', '    THFile_readFloat(THFile *self,THFloatStorage *storage)', '    THFile_readFloatRaw(THFile *self,float *data,size_t n)', '    THFile_readFloatScalar(THFile *self)', '    THFile_readHalf(THFile *self,THHalfStorage *storage)', '    THFile_readHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_readHalfScalar(THFile *self)', '    THFile_readInt(THFile *self,THIntStorage *storage)', '    THFile_readIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_readIntScalar(THFile *self)', '    THFile_readLong(THFile *self,THLongStorage *storage)', '    THFile_readLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_readLongScalar(THFile *self)', '    THFile_readShort(THFile *self,THShortStorage *storage)', '    THFile_readShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_readShortScalar(THFile *self)', '    THFile_readStringRaw(THFile *self,const char *format,char **str_)', '    THFile_seek(THFile *self,size_t position)', '    THFile_seekEnd(THFile *self)', '    THFile_synchronize(THFile *self)', '    THFile_writeByte(THFile *self,THByteStorage *storage)', '    THFile_writeByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_writeByteScalar(THFile *self,uint8_t scalar)', '    THFile_writeChar(THFile *self,THCharStorage *storage)', '    THFile_writeCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_writeCharScalar(THFile *self,int8_t scalar)', '    THFile_writeDouble(THFile *self,THDoubleStorage *storage)', '    THFile_writeDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_writeDoubleScalar(THFile *self,double scalar)', '    THFile_writeFloat(THFile *self,THFloatStorage *storage)', '    THFile_writeFloatRaw(THFile *self,float *data,size_t n)', '    THFile_writeFloatScalar(THFile *self,float scalar)', '    THFile_writeHalf(THFile *self,THHalfStorage *storage)', '    THFile_writeHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_writeHalfScalar(THFile *self,at::Half scalar)', '    THFile_writeInt(THFile *self,THIntStorage *storage)', '    THFile_writeIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_writeIntScalar(THFile *self,int32_t scalar)', '    THFile_writeLong(THFile *self,THLongStorage *storage)', '    THFile_writeLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_writeLongScalar(THFile *self,int64_t scalar)', '    THFile_writeShort(THFile *self,THShortStorage *storage)', '    THFile_writeShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_writeShortScalar(THFile *self,int16_t scalar)', '    THFile_writeStringRaw(THFile *self,const char *str,size_t size)'];
int8_slice_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 49;  1; 26;1;  22; 0;20;22;1;9;0.05;2;[];['    THFile_ascii(THFile *self)', '    THFile_autoSpacing(THFile *self)', '    THFile_binary(THFile *self)', '    THFile_clearError(THFile *self)', '    THFile_close(THFile *self)', '    THFile_free(THFile *self)', '    THFile_hasError(THFile *self)', '    THFile_isAutoSpacing(THFile *self)', '    THFile_isBinary(THFile *self)', '    THFile_isOpened(THFile *self)', '    THFile_isQuiet(THFile *self)', '    THFile_isReadable(THFile *self)', '    THFile_isWritable(THFile *self)', '    THFile_noAutoSpacing(THFile *self)', '    THFile_pedantic(THFile *self)', '    THFile_position(THFile *self)', '    THFile_quiet(THFile *self)', '    THFile_readBool(THFile *self,THBoolStorage *storage)', '    THFile_readByte(THFile *self,THByteStorage *storage)', '    THFile_readByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_readByteScalar(THFile *self)', '    THFile_readChar(THFile *self,THCharStorage *storage)', '    THFile_readCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_readCharScalar(THFile *self)', '    THFile_readDouble(THFile *self,THDoubleStorage *storage)', '    THFile_readDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_readDoubleScalar(THFile *self)', '    THFile_readFloat(THFile *self,THFloatStorage *storage)', '    THFile_readFloatRaw(THFile *self,float *data,size_t n)', '    THFile_readFloatScalar(THFile *self)', '    THFile_readHalf(THFile *self,THHalfStorage *storage)', '    THFile_readHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_readHalfScalar(THFile *self)', '    THFile_readInt(THFile *self,THIntStorage *storage)', '    THFile_readIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_readIntScalar(THFile *self)', '    THFile_readLong(THFile *self,THLongStorage *storage)', '    THFile_readLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_readLongScalar(THFile *self)', '    THFile_readShort(THFile *self,THShortStorage *storage)', '    THFile_readShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_readShortScalar(THFile *self)', '    THFile_readStringRaw(THFile *self,const char *format,char **str_)', '    THFile_seek(THFile *self,size_t position)', '    THFile_seekEnd(THFile *self)', '    THFile_synchronize(THFile *self)', '    THFile_writeBool(THFile *self,THBoolStorage *storage)', '    THFile_writeByte(THFile *self,THByteStorage *storage)', '    THFile_writeByteRaw(THFile *self,uint8_t *data,size_t n)', '    THFile_writeByteScalar(THFile *self,uint8_t scalar)', '    THFile_writeChar(THFile *self,THCharStorage *storage)', '    THFile_writeCharRaw(THFile *self,int8_t *data,size_t n)', '    THFile_writeCharScalar(THFile *self,int8_t scalar)', '    THFile_writeDouble(THFile *self,THDoubleStorage *storage)', '    THFile_writeDoubleRaw(THFile *self,double *data,size_t n)', '    THFile_writeDoubleScalar(THFile *self,double scalar)', '    THFile_writeFloat(THFile *self,THFloatStorage *storage)', '    THFile_writeFloatRaw(THFile *self,float *data,size_t n)', '    THFile_writeFloatScalar(THFile *self,float scalar)', '    THFile_writeHalf(THFile *self,THHalfStorage *storage)', '    THFile_writeHalfRaw(THFile *self,at::Half *data,size_t n)', '    THFile_writeHalfScalar(THFile *self,at::Half scalar)', '    THFile_writeInt(THFile *self,THIntStorage *storage)', '    THFile_writeIntRaw(THFile *self,int32_t *data,size_t n)', '    THFile_writeIntScalar(THFile *self,int32_t scalar)', '    THFile_writeLong(THFile *self,THLongStorage *storage)', '    THFile_writeLongRaw(THFile *self,int64_t *data,size_t n)', '    THFile_writeLongScalar(THFile *self,int64_t scalar)', '    THFile_writeShort(THFile *self,THShortStorage *storage)', '    THFile_writeShortRaw(THFile *self,int16_t *data,size_t n)', '    THFile_writeShortScalar(THFile *self,int16_t scalar)', '    THFile_writeStringRaw(THFile *self,const char *str,size_t size)'];
int8_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 1024;  22; 45;5;  956; 0;570;696;67;1276;0.02;28;[];[];
int8_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators/quantized; 157;  27; 20;12;  93; 9;51;37;39;25;0.29;8;[];['    defaultArgErrorHandlerFunction(int argNumber,const char *msg,void *data)', '    defaultErrorHandlerFunction(const char *msg,void *data)', '    _THArgCheck(const char *file,int line,int condition,int argNumber,const char *fmt,...)', '    _THAssertionFailed(const char *file,const int line,const char *exp,const char *fmt,...)', '    _THError(const char *file,const int line,const char *fmt,...)', '    _THSizeDesc(const int64_t *size,const int64_t ndim)', '    THAlloc(ptrdiff_t size)', '    THFree(void *ptr)', '    THRealloc(void *ptr,ptrdiff_t size)', '    THSetArgErrorHandler(THArgErrorHandlerFunction new_handler,void *data)', '    THSetDefaultArgErrorHandler(THArgErrorHandlerFunction new_handler,void *data)', '    THSetDefaultErrorHandler(THErrorHandlerFunction new_handler,void *data)', '    THSetErrorHandler(THErrorHandlerFunction new_handler,void *data)', '    THSetGCHandler(void (*) (void *) torchGCFunction_,void *data)'];
reciprocal_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 72;  2; 44;3;  24; 0;17;19;1;9;0.08;3;[];[];
reduce_front_back_mean_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 295;  8; 114;17;  157; 0;90;110;32;75;0.05;13;[];[];
reduce_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 353;  6; 30;10;  313; 0;135;160;95;106;0.02;16;[];[];
relu_n_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 107;  8; 21;5;  79; 0;38;54;11;28;0.10;9;[];[];
remove_data_blocks_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 24;  2; 6;1;  17; 0;12;17;1;10;0.12;2;[];[];
reservoir_sampling.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 277;  18; 39;6;  217; 0;164;117;115;92;0.08;5;[];[];
reshape_op_gpu_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 52;  2; 6;7;  38; 0;23;17;18;12;0.05;2;[];[];
resize_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 81;  1; 16;4;  61; 0;16;37;62;75;0.02;2;[];[];
rmac_regions_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 30;  2; 9;4;  17; 0;0;13;17;30;0.12;1;[];[];
recurrent_network_blob_fetcher_op_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 8;  1; 1;2;  5; 0;1;3;1;5;0.20;1;[];[];
recurrent_network_executor_gpu.h;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 82;  9; 15;6;  52; 0;23;27;16;17;0.17;4;[];[];
recurrent_op_cudnn.cc;C++;pytorch-master/pytorch-master/caffe2/operators/rnn; 589;  62; 56;9;  492; 12;213;189;194;411;0.13;16;[];[];
roi_align_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 328;  11; 28;10;  283; 2;137;191;53;156;0.04;6;[];[];
roi_align_rotated_gradient_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 46;  3; 8;6;  31; 0;5;20;22;32;0.10;2;[];[];
roi_pool_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 79;  2; 10;7;  62; 0;10;45;70;78;0.03;3;[];[];
rsqrt_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];[];
scale_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 43;  2; 9;6;  28; 0;10;14;20;31;0.07;3;[];[];
selu_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 147;  3; 65;3;  77; 0;63;62;17;31;0.04;8;[];[];
shape_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 78;  1; 42;1;  35; 0;32;35;1;9;0.03;2;[];[];
sigmoid_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 90;  4; 48;2;  38; 0;26;29;3;10;0.11;4;[];[];
sin_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 34;  2; 7;6;  21; 0;2;16;2;5;0.10;1;[];['    dgeev_(char *jobvl,char *jobvr,int *n,double *a,int *lda,double *wr,double *wi,double *vl,int *ldvl,double *vr,int *ldvr,double *work,int *lwork,int *info)', '    dgels_(char *trans,int *m,int *n,int *nrhs,double *a,int *lda,double *b,int *ldb,double *work,int *lwork,int *info)', '    dgeqrf_(int *m,int *n,double *a,int *lda,double *tau,double *work,int *lwork,int *info)', '    dorgqr_(int *m,int *n,int *k,double *a,int *lda,double *tau,double *work,int *lwork,int *info)', '    dormqr_(char *side,char *trans,int *m,int *n,int *k,double *a,int *lda,double *tau,double *c,int *ldc,double *work,int *lwork,int *info)', '    dpotri_(char *uplo,int *n,double *a,int *lda,int *info)', '    sgeev_(char *jobvl,char *jobvr,int *n,float *a,int *lda,float *wr,float *wi,float *vl,int *ldvl,float *vr,int *ldvr,float *work,int *lwork,int *info)', '    sgels_(char *trans,int *m,int *n,int *nrhs,float *a,int *lda,float *b,int *ldb,float *work,int *lwork,int *info)', '    sgeqrf_(int *m,int *n,float *a,int *lda,float *tau,float *work,int *lwork,int *info)', '    sorgqr_(int *m,int *n,int *k,float *a,int *lda,float *tau,float *work,int *lwork,int *info)', '    sormqr_(char *side,char *trans,int *m,int *n,int *k,float *a,int *lda,float *tau,float *c,int *ldc,float *work,int *lwork,int *info)', '    spotri_(char *uplo,int *n,float *a,int *lda,int *info)', '    TH(char trans,int m,int n,int nrhs,scalar_t *a,int lda,scalar_t *b,int ldb,scalar_t *work,int lwork,int *info)', '    TH(char jobvl,char jobvr,int n,scalar_t *a,int lda,scalar_t *wr,scalar_t *wi,scalar_t *vl,int ldvl,scalar_t *vr,int ldvr,scalar_t *work,int lwork,int *info)', '    TH(char uplo,int n,scalar_t *a,int lda,int *info)', '    TH(int m,int n,scalar_t *a,int lda,scalar_t *tau,scalar_t *work,int lwork,int *info)', '    TH(int m,int n,int k,scalar_t *a,int lda,scalar_t *tau,scalar_t *work,int lwork,int *info)', '    TH(char side,char trans,int m,int n,int k,scalar_t *a,int lda,scalar_t *tau,scalar_t *c,int ldc,scalar_t *work,int lwork,int *info)'];
sinusoid_position_encoding_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 94;  7; 19;12;  59; 0;33;36;36;50;0.12;3;[];[];
softmax_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 47;  2; 9;7;  31; 0;0;23;34;61;0.06;2;[];[];
softmax_with_loss_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 391;  24; 114;4;  263; 0;204;140;129;99;0.09;8;[];['    THMemoryFile_cloneString(const int8_t *str,ssize_t size)', '    THMemoryFile_close(THFile *self)', '    THMemoryFile_free(THFile *self)', '    THMemoryFile_grow(THMemoryFile *self,ssize_t size)', '    THMemoryFile_isOpened(THFile *self)', '    THMemoryFile_mode(const char *mode,int *isReadable,int *isWritable)', '    THMemoryFile_position(THFile *self)', '    THMemoryFile_readByte(THFile *self,uint8_t *data,ssize_t n)', '    THMemoryFile_readChar(THFile *self,int8_t *data,ssize_t n)', '    THMemoryFile_readDouble(THFile *self,double *data,ssize_t n)', '    THMemoryFile_readFloat(THFile *self,float *data,ssize_t n)', '    THMemoryFile_readHalf(THFile *self,at::Half *data,ssize_t n)', '    THMemoryFile_readInt(THFile *self,int32_t *data,ssize_t n)', '    THMemoryFile_readLong(THFile *self,int64_t *data,ssize_t n)', '    THMemoryFile_readShort(THFile *self,int16_t *data,ssize_t n)', '    THMemoryFile_readString(THFile *self,const char *format,char **str_)', '    THMemoryFile_seek(THFile *self,ssize_t position)', '    THMemoryFile_seekEnd(THFile *self)', '    THMemoryFile_strnextspace(int8_t *str_,int8_t *c_)', '    THMemoryFile_synchronize(THFile *self)', '    THMemoryFile_writeByte(THFile *self,uint8_t *data,ssize_t n)', '    THMemoryFile_writeChar(THFile *self,int8_t *data,ssize_t n)', '    THMemoryFile_writeDouble(THFile *self,double *data,ssize_t n)', '    THMemoryFile_writeFloat(THFile *self,float *data,ssize_t n)', '    THMemoryFile_writeHalf(THFile *self,at::Half *data,ssize_t n)', '    THMemoryFile_writeInt(THFile *self,int32_t *data,ssize_t n)', '    THMemoryFile_writeLong(THFile *self,int64_t *data,ssize_t n)', '    THMemoryFile_writeShort(THFile *self,int16_t *data,ssize_t n)', '    THMemoryFile_writeString(THFile *self,const char *str,ssize_t size)', '    THMemoryFile_longSize(THFile *self,int size)', '    THMemoryFile_new(const char *mode)', '    THMemoryFile_newWithStorage(THCharStorage *storage,const char *mode)', '    THMemoryFile_storage(THFile *self)'];
softsign_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 149;  5; 60;4;  85; 0;47;63;14;25;0.06;8;[];['    THMemoryFile_longSize(THFile *self,int size)', '    THMemoryFile_new(const char *mode)', '    THMemoryFile_newWithStorage(THCharStorage *storage,const char *mode)', '    THMemoryFile_storage(THFile *self)'];
sparse_dropout_with_replacement_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 131;  4; 44;3;  81; 0;64;54;35;33;0.05;3;[];[];
sparse_to_dense_mask_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 119;  5; 29;1;  88; 0;75;78;6;23;0.06;6;[];[];
spatial_batch_norm_gradient_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 191;  12; 13;3;  166; 0;99;83;83;45;0.07;6;[];['    main', '    test(int given_num_threads)'];
spatial_softmax_with_loss_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 70;  7; 11;7;  52; 0;6;38;48;72;0.13;4;[];['    setThreadName(std::string name)'];
sqrt_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 96;  3; 47;3;  45; 0;24;37;5;21;0.07;5;[];['    setThreadName(std::string name)'];
square_root_divide_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 62;  2; 11;6;  45; 0;23;25;29;42;0.04;4;[];['    RegistryName', '    ThreadPool(int pool_size,int numa_node_id,std::function init_thread)', '    inThreadPool', '    main_loop(std::size_t index)', '    numAvailable', '    run(const std::function & func)', '    size', '    waitWorkComplete', '    ~ThreadPool'];
stop_gradient.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 19;  2; 6;1;  11; 0;8;11;1;9;0.18;2;['    TaskThreadPoolBase', '    ThreadPool'];['    defaultNumThreads', '    inThreadPool', '    numAvailable', '    run(const std::function & func)', '    size', '    ~TaskThreadPoolBase', '    inThreadPool', '    main_loop(std::size_t index)', '    numAvailable', '    run(const std::function & func)', '    runTaskWithID(Task task)', '    size', '    task_element_t(const std::function & f)', '    task_element_t(const std::function & f)', '    ThreadPool(int pool_size,int numa_node_id,std::function init_thread)', '    ThreadPool', '    waitWorkComplete', '    ~ThreadPool', '    hardware_concurrency'];
string_ops.h;C++;pytorch-master/pytorch-master/caffe2/operators; 77;  11; 13;5;  51; 0;3;8;4;5;0.22;2;[];['    getThreadLocalDebugInfo', '    setThreadLocalDebugInfo(std::shared_ptr info)'];
stylizer_ops.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 596;  26; 46;32;  172; 337;91;92;75;86;0.15;13;['    DebugInfoGuard', '    ThreadLocalDebugInfoBase'];['    getThreadLocalDebugInfo', '    DebugInfoGuard(std::shared_ptr info)', '    ~DebugInfoGuard', '    ThreadLocalDebugInfoBase', '    ~ThreadLocalDebugInfoBase', '    move'];
swish_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 35;  2; 9;5;  21; 0;1;14;18;33;0.10;3;[];['    getAllThreadLocalHelperVector', '    getThreadLocalHelper', '    erase(ThreadLocalHelper *helper)', '    erase_tlp(ThreadLocalPtrImpl *ptr)', '    push_back(ThreadLocalHelper *helper)', '    erase(ThreadLocalPtrImpl *key)', '    get(ThreadLocalPtrImpl *key)', '    insert(ThreadLocalPtrImpl *tl_ptr,std::shared_ptr ptr)', '    ThreadLocalHelper', '    ~ThreadLocalHelper', '    ~ThreadLocalPtrImpl'];
tanh_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 95;  2; 52;4;  29; 10;22;24;1;9;0.07;3;['    AllThreadLocalHelperVector', '    ThreadLocalHelper', '    ThreadLocalPtr', '    ThreadLocalPtrImpl'];['    getThreadLocalHelper', '    AllThreadLocalHelperVector', '    erase(ThreadLocalHelper *helper)', '    erase_tlp(ThreadLocalPtrImpl *ptr)', '    push_back(ThreadLocalHelper *helper)', '    erase(ThreadLocalPtrImpl *key)', '    get(ThreadLocalPtrImpl *key)', '    insert(ThreadLocalPtrImpl *tl_ptr,std::shared_ptr ptr)', '    ThreadLocalHelper', '    ~ThreadLocalHelper', '    get', '    get', '    operator*', '    operator*', '    operator->', '    operator->', '    reset(unique_ptr ptr)', '    get', '    operator=', '    operator=', '    reset(T *newPtr)', '    ThreadLocalPtrImpl', '    ThreadLocalPtrImpl', '    ThreadLocalPtrImpl', '    ~ThreadLocalPtrImpl'];
tensor_protos_db_input.h;C++;pytorch-master/pytorch-master/caffe2/operators; 107;  11; 11;7;  81; 0;11;50;7;173;0.14;3;[];['    getThreadLocalState', '    setThreadLocalState(const ThreadLocalState & state)', '    ThreadLocalState(bool grad_mode_enabled,int64_t dist_autograd_context_id)'];
text_file_reader_utils.h;C++;pytorch-master/pytorch-master/caffe2/operators; 122;  6; 18;7;  93; 0;25;49;20;47;0.06;7;[];[];
tile_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 202;  18; 61;2;  123; 0;71;81;9;165;0.15;6;['    C10FlagParser_caffe2_threadpool_android_cap', '    C10FlagParser_caffe2_threadpool_force_inline', '    C10FlagParser_caffe2_threadpool_ios_cap'];['    getDefaultNumThreads', '    C10FlagParser_caffe2_threadpool_android_cap(const std::string & content)', '    C10FlagParser_caffe2_threadpool_force_inline(const std::string & content)', '    C10FlagParser_caffe2_threadpool_ios_cap(const std::string & content)', '    defaultThreadPool', '    getNumThreads', '    run(const std::function & fn,size_t range)', '    setMinWorkSize(size_t size)', '    setNumThreads(size_t numThreads)', '    ThreadPool(int numThreads)', '    withPool(const std::function & f)', '    ~ThreadPool', '    FnTask', '    Run', '    ~FnTask'];
transpose_op.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 120;  3; 48;1;  69; 0;44;56;3;53;0.04;5;[];[];
tt_linear_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 195;  24; 26;12;  139; 1;58;69;67;111;0.17;7;[];[];
upsample_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 76;  16; 10;3;  48; 0;14;26;56;65;0.33;2;[];['    mobile_pthreadpool', '    mobile_threadpool'];
utility_ops_test.cc;C++;pytorch-master/pytorch-master/caffe2/operators; 45;  2; 6;4;  34; 0;19;17;14;12;0.06;2;[];['    getDefaultNumThreads', '    mobile_pthreadpool', '    mobile_threadpool'];
weighted_multi_sampling_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 26;  1; 6;3;  17; 0;1;12;21;30;0.06;1;[];['    xnnpack_threadpool'];
while_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 72;  2; 13;6;  53; 0;24;15;47;35;0.04;2;[];['    xnnpack_threadpool'];
zero_gradient_op.h;C++;pytorch-master/pytorch-master/caffe2/operators; 20;  1; 6;3;  11; 0;1;6;18;28;0.09;3;['    GetThresholdedReluGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUThresholdedRelu', '    CAFFE_ANONYMOUS_VARIABLE_CPUThresholdedReluGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThresholdedRelu', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThresholdedReluGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
backend_cutting.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 445;  29; 46;8;  365; 0;230;171;153;102;0.08;21;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    ThresholdedReluGradientOp(Args,...)', '    ThresholdedReluOp(Args,...)'];
backend_transformer_base.h;C++;pytorch-master/pytorch-master/caffe2/opt; 99;  17; 21;8;  55; 0;7;47;2;25;0.31;7;[];['    MessageLogger(,,INFO)', '    finished', '    initialized', '    start', '    lock(m)', '    lock(m)', '    now', '    now', '    empty', '    size', '    benchmark(const BenchmarkConfig & config)'];
converter.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 646;  42; 97;7;  504; 0;313;180;269;177;0.08;42;[];['    cloneInput(const ModuleInput & input)', '    cloneInput(const ScriptModuleInput & input)', '    addInput(py::args,py::kwargs)', '    runOnce(ModuleInput)', '    runOnce(py::args,py::kwargs)', '    addInput(py::args,py::kwargs)', '    runOnce(ScriptModuleInput)', '    runOnce(py::args,py::kwargs)', '    addInput(py::args args,py::kwargs kwargs)', '    benchmark(const BenchmarkConfig & config)', '    runOnce(py::args,py::kwargs)', '    ThroughputBenchmark(jit::Module script_module)', '    ThroughputBenchmark(py::object module)'];
cc_amrc.h;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 176;  4; 17;6;  151; 0;94;60;73;77;0.03;2;['    BenchmarkHelper', '    ThroughputBenchmark'];['    cloneInput(const Input & input)', '    num_calling_threads', '    num_iters', '    num_warmup_iters', '    num_worker_threads', '    latency_avg_ms', '    num_iters', '    addInput(py::args,py::kwargs)', '    benchmark(const BenchmarkConfig & config)', '    BenchmarkHelper', '    BenchmarkHelper', '    BenchmarkHelper(Model model)', '    initialized', '    initialized_', '    runOnce(Input)', '    runOnce(py::args,py::kwargs)', '    runOnce(ModuleInput)', '    ModuleInput', '    ModuleInput', '    ModuleInput(py::args,py::kwargs)', '    operator=', '    operator=', '    runOnce(ScriptModuleInput)', '    addInput(py::args args,py::kwargs kwargs)', '    benchmark(const BenchmarkConfig & config)', '    runOnce(py::args,py::kwargs)', '    ThroughputBenchmark(jit::Module script_module)', '    ThroughputBenchmark(py::object module)'];
converter.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 310;  7; 35;3;  267; 0;146;105;112;104;0.03;27;[];['    TH(THStorage *storage1,THStorage *storage2)', '    TH(THStorage *storage)', '    TH(const THStorage *self)', '    TH', '    TH(THStorage *storage,ptrdiff_t size)', '    TH(THStorage *storage,scalar_t value)', '    TH(THStorage *self,ptrdiff_t idx,scalar_t value)', '    TH(const THStorage *self,ptrdiff_t idx)', '    TH(THStorage *storage)', '    Make'];
glow_net_transform.cc;C++;pytorch-master/pytorch-master/caffe2/opt/custom; 217;  23; 25;5;  166; 0;93;55;77;94;0.14;12;[];[];
dead_code_elim.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 43;  4; 8;3;  30; 0;18;11;20;15;0.13;2;[];[];
device_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 77;  6; 8;10;  53; 0;46;7;34;8;0.11;1;[];['    TH(THStorage *storage,THByteStorage *src)', '    TH(THStorage *storage,THCharStorage *src)', '    TH(THStorage *storage,THShortStorage *src)', '    TH(THStorage *storage,THIntStorage *src)', '    TH(THStorage *storage,THLongStorage *src)', '    TH(THStorage *storage,THFloatStorage *src)', '    TH(THStorage *storage,THDoubleStorage *src)', '    TH(THStorage *storage,THHalfStorage *src)', '    TH(THStorage *storage,THBoolStorage *src)', '    TH(THStorage *storage,THBFloat16Storage *src)', '    TH(THStorage *storage,THStorage *src)'];
distributed_test.cc;C++;pytorch-master/pytorch-master/caffe2/opt; 173;  17; 25;3;  129; 0;100;44;65;44;0.13;9;[];[];
mobile.h;C++;pytorch-master/pytorch-master/caffe2/opt; 16;  3; 5;5;  6; 0;1;6;0;4;0.50;0;[];['    THStorage_free(THStorage *storage)', '    THStorage_new(caffe2::TypeMeta data_type)', '    THStorage_resize(THStorage *storage,ptrdiff_t size)', '    THStorage_retain(THStorage *storage)', '    THStorage_size(const THStorage *self)'];
graphmatcher.h;C++;pytorch-master/pytorch-master/caffe2/opt/nql; 132;  33; 16;3;  82; 0;30;43;23;45;0.40;8;[];[];
onnxifi_op.h;C++;pytorch-master/pytorch-master/caffe2/opt; 399;  47; 52;20;  250; 34;132;124;122;120;0.19;21;[];['    THStorage_resize(THStorage *storage,ptrdiff_t size)', '    THStorage_retain(THStorage *storage)', '    THStorage_size(const THStorage *self)'];
optimize_ideep.h;C++;pytorch-master/pytorch-master/caffe2/opt; 16;  1; 3;5;  8; 0;1;8;0;3;0.13;0;[];['    copy_(tensor_wrap,self_wrap,)', '    incref(storage)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(const at::TensorImpl *self,int dim)', '    TH(const at::TensorImpl *self,int dim)', '    TH(at::TensorImpl *self,at::TensorImpl *dst)', '    TH(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    TH(at::TensorImpl *self,at::TensorImpl *src)', '    TH(at::TensorImpl *self,at::TensorImpl *src)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,scalar_t value)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *tensor)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    TH(at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(at::TensorImpl *tensor,int64_t size0)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1,int64_t size2)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3,int64_t size4)', '    TH(at::TensorImpl *self)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t firstIndex,int64_t size)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t sliceIndex)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension1,int dimension2)', '    TH(const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(const at::TensorImpl *self)', '    TH(const at::TensorImpl *self)', '    reclaim'];
passes.h;C++;pytorch-master/pytorch-master/caffe2/opt; 75;  11; 13;29;  24; 0;1;13;1;15;0.46;4;[];['    THTensor_free(at::TensorImpl *self)', '    THTensor_resize(at::TensorImpl *self,at::IntArrayRef size,at::IntArrayRef stride)', '    THTensor_resizeNd(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THTensor_setStorage(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THTensor_stealAndSetStoragePtr(at::TensorImpl *tensor,THStorage *storage)'];
tvm_transformer.h;C++;pytorch-master/pytorch-master/caffe2/opt; 91;  18; 19;3;  52; 0;2;48;0;18;0.35;5;[];['    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension)', '    TH(const at::TensorImpl *self,int dim)', '    TH(at::TensorImpl *tensor,scalar_t value)', '    TH(const at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,int64_t size0)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1)', '    TH(at::TensorImpl *tensor,int64_t size0,int64_t size1,int64_t size2)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3)', '    TH(at::TensorImpl *self,int64_t size0,int64_t size1,int64_t size2,int64_t size3,int64_t size4)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t firstIndex,int64_t size)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension,int64_t sliceIndex)', '    TH(at::TensorImpl *self,at::TensorImpl *src,int dimension1,int dimension2)', '    TH(const at::TensorImpl *self,const at::TensorImpl *src)', '    TH(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    TH(at::TensorImpl *tensor,int64_t x0,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(const at::TensorImpl *tensor,int64_t x0,int64_t x1,int64_t x2,int64_t x3)'];
common.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 108;  68; 8;38;  0; 21;0;0;0;0;0.00;0;[];[];
cvtsh_ss_bugfix.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 73;  14; 10;17;  21; 25;12;7;12;5;0.67;2;[];['    THTensor_getSizePtr(at::TensorImpl *tensor)', '    THTensor_getStoragePtr(const at::TensorImpl *tensor)', '    THTensor_getStridePtr(at::TensorImpl *tensor)', '    THTensor_nDimension(const at::TensorImpl *tensor)', '    THTensor_nDimensionLegacyAll(const at::TensorImpl *tensor)', '    THTensor_nDimensionLegacyNoScalars(const at::TensorImpl *tensor)', '    THTensor_resizeNd(at::TensorImpl *self,int nDimension,const int64_t *size,const int64_t *stride)', '    THTensor_setStorage(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)', '    THTensor_sizeLegacyNoScalars(const at::TensorImpl *self,int dim)', '    THTensor_sizesLegacyNoScalars(const at::TensorImpl *self)', '    THTensor_stealAndSetStoragePtr(at::TensorImpl *tensor,THStorage *storage)', '    THTensor_strideLegacyNoScalars(const at::TensorImpl *self,int dim)', '    THTensor_stridesLegacyNoScalars(const at::TensorImpl *self)', '    THTensor_wrap(at::TensorImpl *tensor)', '    reclaim'];
embedding_lookup_fused_8bit_rowwise_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 3070;  161; 8;2;  2900; 0;2414;850;1176;591;0.06;18;[];['    TH(at::TensorImpl *self,THStorage *storage_,ptrdiff_t storageOffset_,at::IntArrayRef size_,at::IntArrayRef stride_)'];
embedding_lookup_idx_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 3140;  161; 8;2;  2970; 0;2466;908;1176;641;0.05;18;[];[];
fused_8bit_rowwise_embedding_lookup.cc;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 207;  10; 11;129;  56; 4;29;34;69;47;0.18;7;[];[];
math.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 35;  13; 7;2;  15; 0;0;15;0;4;0.87;0;[];[];
typed_axpy.h;C++;pytorch-master/pytorch-master/caffe2/perfkernels; 12;  5; 3;1;  4; 0;0;4;0;2;1.25;0;[];[];
benchmark.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 44;  7; 8;5;  26; 0;0;22;0;20;0.27;3;[];['    TH(at::TensorImpl *tensor,ptrdiff_t linearIndex)', '    TH(int64_t linearIndex,int64_t numel)', '    TH(int64_t linearIndex,int64_t numel)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,scalar_t value)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *index,at::TensorImpl *src,int accumulate)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src,at::TensorImpl *mask)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src)', '    TH(at::TensorImpl *subscript,at::TensorImpl *tensor)', '    TH(at::TensorImpl *tensor)', '    TH(at::TensorImpl *r_,at::TensorImpl *src,at::TensorImpl *index)', '    TH(at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *mask,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *src,at::TensorImpl *mask)'];
emulator.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 20;  5; 5;2;  10; 0;2;8;0;6;0.50;1;[];['    TH(at::TensorImpl *self,int64_t x0,int64_t x1)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,int64_t x4)', '    TH(at::TensorImpl *self,int64_t x0,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0,int64_t x1,int64_t x2,int64_t x3,int64_t x4,scalar_t value)', '    TH(at::TensorImpl *self,int64_t x0)', '    TH(at::TensorImpl *self,int64_t x0)'];
std_output_formatter.h;C++;pytorch-master/pytorch-master/caffe2/predictor/emulator; 45;  5; 6;2;  34; 0;15;20;3;12;0.15;3;[];['    TH(at::TensorImpl *r_,scalar_t value)', '    TH(at::TensorImpl *r_)'];
predictor.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 126;  4; 16;3;  105; 0;53;37;55;25;0.04;10;[];[];
predictor_test.cc;C++;pytorch-master/pytorch-master/caffe2/predictor; 208;  1; 75;6;  127; 0;94;83;32;24;0.01;6;[];['    TH(at::TensorImpl *r_,scalar_t value)'];
ThreadLocalPtr.h;C++;pytorch-master/pytorch-master/caffe2/predictor; 158;  47; 30;5;  79; 0;20;44;14;40;0.59;11;[];['    TH(at::TensorImpl *self)', '    TH(at::TensorImpl *self)', '    copy_(result_wrap,src_wrap)', '    copy_(view_wrap,src_wrap)', '    decref(view)', '    TH(at::TensorImpl *rb_,at::TensorImpl *ra_,at::TensorImpl *b,at::TensorImpl *a)', '    TH(at::TensorImpl *re_,at::TensorImpl *rv_,at::TensorImpl *a_,bool eigenvectors)', '    TH(at::TensorImpl *a,char uplo)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,bool upper)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau,at::TensorImpl *c,bool left,bool transpose)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau)', '    TH(at::TensorImpl *ra_,at::TensorImpl *rtau_,at::TensorImpl *a)', '    unsqueeze'];
torch_pb.h;C++;pytorch-master/pytorch-master/caffe2/proto; 8;  1; 2;6;  0; 0;0;0;0;0;0.00;0;[];[];
pybind_state.cc;C++;pytorch-master/pytorch-master/caffe2/python; 1882;  84; 116;90;  1498; 118;284;565;103;3289;0.06;40;[];['    TH(at::TensorImpl *re_,at::TensorImpl *rv_,at::TensorImpl *a_,bool eigenvectors)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,bool upper)', '    TH(at::TensorImpl *ra_,at::TensorImpl *a,at::TensorImpl *tau,at::TensorImpl *c,bool left,bool transpose)'];
pybind_state_gpu.cc;C++;pytorch-master/pytorch-master/caffe2/python; 177;  10; 16;23;  103; 33;29;27;18;148;0.10;7;[];[];
pybind_state_nomni.cc;C++;pytorch-master/pytorch-master/caffe2/python; 551;  12; 28;14;  502; 0;134;183;25;692;0.02;6;[];['    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *m1,at::TensorImpl *m2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *result,at::TensorImpl *t,at::TensorImpl *batch1,at::TensorImpl *batch2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *mat,at::TensorImpl *vec,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *m1,at::TensorImpl *m2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *r_,at::TensorImpl *t,at::TensorImpl *vec1,at::TensorImpl *vec2,scalar_t beta,scalar_t alpha)'];
activation_distribution_observer.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 234;  35; 32;10;  161; 0;31;120;9;74;0.22;5;[];['    TH(at::TensorImpl *r_,at::TensorImpl *t,scalar_t value)', '    TH(at::TensorImpl *r_,int in_dims,int reduce_dimension,int keepdim)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,at::TensorImpl *src)', '    TH(at::TensorImpl *tensor,at::TensorImpl *index,at::TensorImpl *src,int accumulate)', '    TH(at::TensorImpl *tensor,int dim,at::TensorImpl *index,scalar_t val)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int64_t k,int dimension,int keepdim)', '    TH(at::TensorImpl *result,at::TensorImpl *t,at::TensorImpl *batch1,at::TensorImpl *batch2,scalar_t beta,scalar_t alpha)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int dimension,int keepdim)'];
batch_permutation_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 28;  2; 8;3;  16; 0;2;9;32;47;0.13;1;[];['    TH(scalar_t *arr,int64_t *idx,int64_t elements,int64_t stride)', '    TH(scalar_t *arr,int64_t *idx,int64_t elements,int64_t stride)', '    TH(at::TensorImpl *result,at::TensorImpl *src)', '    TH(at::TensorImpl *ta,at::TensorImpl *tb)', '    TH(scalar_t *arr,int64_t *idx,int64_t k,int64_t elements,int64_t stride)', '    TH(at::TensorImpl *ta,at::TensorImpl *tb)', '    TH(at::TensorImpl *r_,int in_dims,int reduce_dimension,int keepdim)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int64_t k,int dimension,int keepdim)', '    TH(at::TensorImpl *values_,at::TensorImpl *indices_,at::TensorImpl *t,int dimension,int keepdim)', '    TH(at::TensorImpl *rt_,at::TensorImpl *ri_,at::TensorImpl *t,int dimension,int descendingOrder)', '    TH(at::TensorImpl *t)', '    TH(at::TensorImpl *result,scalar_t beta,at::TensorImpl *t,scalar_t alpha,at::TensorImpl *batch1,at::TensorImpl *batch2)', '    TH(at::TensorImpl *t)'];
channel_shuffle_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 37;  2; 11;6;  20; 0;1;15;31;49;0.10;0;[];[];
conv_dnnlowp_acc16_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 74;  15; 14;3;  44; 0;4;25;56;102;0.34;3;[];[];
conv_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 76;  5; 14;7;  51; 2;29;33;10;54;0.10;3;[];[];
dnnlowp.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 327;  7; 25;10;  286; 1;151;89;111;122;0.02;23;[];[];
dnnlowp_partition.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 31;  9; 5;4;  14; 0;2;14;0;3;0.64;0;[];[];
elementwise_add_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 199;  9; 30;24;  140; 6;95;47;90;88;0.06;3;[];[];
elementwise_mul_dnnlowp_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 117;  4; 18;13;  84; 3;49;37;70;77;0.05;3;[];[];
elementwise_sum_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 58;  16; 8;1;  34; 0;17;13;29;35;0.47;4;[];[];
fbgemm_pack_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 887;  65; 99;4;  733; 0;480;266;298;184;0.09;30;[];['    TH_CONCAT_4(TH,Real,Vector_,startup)', '    TH', '    TH(scalar_t *x,const scalar_t,const ptrdiff_t n)', '    TH(scalar_t *y,const scalar_t *x,const scalar_t c,const ptrdiff_t n)'];
fully_connected_dnnlowp_acc16_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 37;  7; 8;2;  22; 0;1;10;24;39;0.32;0;['    GetTileGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTile', '    CAFFE_ANONYMOUS_VARIABLE_CPUTileGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Tile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TileGradient', '    GetGradientDefs', '    RunOnDevice'];
fully_connected_fake_lowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 137;  37; 19;6;  89; 0;19;64;36;72;0.42;10;['    final', '    final'];['    DoRunWithType', '    DoRunWithType', '    DoTile(const int outer_size,const int inner_size,const T *X,T *Y)', '    DoTileGradient(const int outer_size,const int inner_size,const T *dY,T *dX)', '    GetArgFromTensor(const Tensor & tensor)', '    GetArgFromTensor(const Tensor & tensor)', '    RunOnDevice', '    RunOnDevice', '    TileGradientOp(Args,...)', '    TileOp(Args,...)'];
group_norm_dnnlowp_op_avx2.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 296;  2; 19;87;  190; 4;88;136;60;98;0.01;5;[];['    Start', '    Stop', '    Start', '    Stop'];
kl_minimization_example.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 52;  0; 11;5;  36; 0;20;16;15;16;0.00;1;['    final', '    final', '    TimeCounter'];['    average_time_children', '    Start', '    Stop', '    TimeObserver(NetBase *subject)', '    TimeOperatorObserver', '    TimeOperatorObserver(OperatorBase *subject,TimeObserver *)', '    average_time', '    TimeCounter', '    GetOperators'];
l2_minimization_example.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 67;  0; 14;5;  48; 0;30;16;27;18;0.00;1;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUSleepOp', '    CAFFE_ANONYMOUS_VARIABLE_CUDASleepOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SleepOp', '    CreateNetTestHelper(Workspace *ws)', '    TEST(TimeObserverTest,Test3Seconds)', '    Run(int)'];
mmio.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 53;  2; 8;5;  39; 0;20;13;20;8;0.05;1;['    TimeProfiler'];['    profile(std::function runnable)'];
p99.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 63;  2; 7;4;  52; 0;36;26;29;21;0.04;1;['    Timer'];['    MicroSeconds', '    MilliSeconds', '    NanoSeconds', '    operator=', '    Seconds', '    Start', '    Timer', '    Timer', '    duration_cast'];
pool_dnnlowp_op_avx2.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 75;  4; 6;2;  64; 0;0;64;0;4;0.06;0;[];['    TEST(TimerTest,Test)', '    TEST(TimerTest,TestLatency)'];
quantize_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 21;  2; 6;3;  12; 0;1;8;17;29;0.17;1;['    GetTopKGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTopK', '    CAFFE_ANONYMOUS_VARIABLE_CPUTopKGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TopK', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TopKGradient', '    GetTopK(const T *input,const int64_t n,const int64_t k,const int64_t src_offset,const int64_t dst_offset,const int64_t stride,T *values,int64_t *indices,int64_t *flatten_indices)', '    SetTopKGradient(const T *values,const int64_t *indices,const int k,const int64_t src_offset,const int64_t dst_offset,const int64_t stride,T *gradient)', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice', '    operator()(const std::pair & lhs,const std::pair & rhs)'];
requantization_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 151;  21; 25;6;  100; 0;81;36;52;34;0.21;2;['    TopKGradientOp', '    TopKOp'];['    RunOnDevice', '    TopKGradientOp(Args,...)', '    ~TopKGradientOp', '    RunOnDevice', '    TopKOp(Args,...)', '    ~TopKOp'];
resize_nearest_dnnlowp_op.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 36;  1; 9;3;  24; 0;7;18;44;54;0.04;1;['    TopoSort'];['    topoSort(GraphT *g)', '    dfs(NodeRefT node,std::unordered_map & status,std::vector & nodes)', '    run', '    TopoSort(GraphT *graph)'];
sigmoid_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 42;  0; 5;5;  32; 0;24;14;18;14;0.00;1;[];['    TEST(TopoSort,Simple)', '    TEST(TopoSort,DAG)', '    TEST(TopoSort,Cycle1)', '    TEST(TopoSort,Cycle2)'];
spatial_batch_norm_relu_op.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 52;  17; 10;1;  26; 0;13;17;7;14;0.65;4;[];[];
tanh_test.cc;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 45;  2; 5;5;  33; 0;25;13;18;13;0.06;1;[];['    TEST(TorchIncludeTest,GetSetNumThreads)'];
utility_dnnlowp_ops.h;C++;pytorch-master/pytorch-master/caffe2/quantization/server; 110;  5; 24;5;  79; 0;27;52;64;99;0.06;5;[];[];
blobs_queue_db.h;C++;pytorch-master/pytorch-master/caffe2/queue; 145;  4; 21;7;  116; 0;39;58;39;34;0.03;16;[];['    runJITCPPTests(bool runCuda)', '    runTENSOREXPRCPPTests(bool runCuda)'];
rebatching_queue.cc;C++;pytorch-master/pytorch-master/caffe2/queue; 234;  14; 50;2;  175; 0;84;65;88;143;0.08;13;[];['    remoteTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)', '    rpcTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)'];
file_adapter.cc;C++;pytorch-master/pytorch-master/caffe2/serialize; 28;  2; 6;3;  19; 0;6;9;9;6;0.11;4;[];['    remoteTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)', '    rpcTorchscript(const std::string & dstWorkerName,const c10::QualifiedName & qualifiedName,const c10::FunctionSchema & functionSchema,std::vector & stack)'];
inline_container_test.cc;C++;pytorch-master/pytorch-master/caffe2/serialize; 68;  5; 13;5;  48; 0;32;19;30;13;0.10;1;[];['    addInput(const std::shared_ptr & state,const IValue & input,const TypePtr & type,Value *value)', '    gatherParametersAndBuffers(const std::shared_ptr & state,Value *self_value,const Module & self,const std::string & prefix)', '    kind', '    reason', '    _do_warn(const char *_reason,const char *_kind)', '    defaultRecordSourceLocation(Node *n)', '    defaultWarn(const std::string & str)', '    ensureUniqueIfOutOfPlaced(const char *name,const at::Tensor & tensor)', '    getSizeOf(const autograd::Variable & var,int64_t dim)', '    abandon', '    addInputs(Node *n,const char *name,int64_t value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,bool value)', '    addInputs(Node *n,const char *name,double value)', '    addInputs(Node *n,const char *name,const at::Scalar & value)', '    addInputs(Node *n,const char *name,const std::string & value)', '    addInputs(Node *n,const char *name,const at::Tensor & value)', '    addInputs(Node *n,const char *name,const at::Generator & value)', '    addInputs(Node *n,const char *name,at::Device value)', '    addInputs(Node *n,const char *name,at::Layout value)', '    addInputs(Node *n,const char *name,at::ScalarType value)', '    addInputs(Node *n,const char *name,at::MemoryFormat value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,at::TensorList value,bool allow_undefined)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,const at::TensorOptions & options)', '    addInputs(Node *n,const char *name,at::IntArrayRef value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,const c10::intrusive_ptr & obj)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,c10::optional opt_dtype)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addOutput(Node *node,const at::Tensor & output)', '    addOutput(Node *node,const std::vector & outputs)', '    addOutput(Node *node,const c10::List & outputs)', '    delValueTrace(const IValue & var)', '    getTracingState', '    getValueTrace(const IValue & var)', '    setOutput(Value *value,const at::Tensor & output)', '    setTracingState(std::shared_ptr state)', '    setValueTrace(const IValue & v,Value *value)', '    trace(Stack inputs,const std::function & traced_fn,std::function var_name_lookup_fn,bool force_outplace,Module *self)', '    badArgType(const T & v)', '    genericAddInput(Node *n,T value)', '    pauseTracing', '    recordSourceLocation(Node *n)', '    setRecordSourceLocation(void (*) (Node *) v)', '    setWarn(warn_fn_type fn)', '    warn_callback', '    stashIntArrayRefElem(const std::string & arg_name,size_t size,size_t idx,const Variable & var)', '    stashValue(const std::string & arg_name,size_t idx,const Variable & var,const TypePtr & type)', '    delValue(const IValue & var)', '    getOutput(const IValue & iv,size_t i)', '    getValue(const IValue & var)', '    hasValue(const IValue & var)', '    setValue(const IValue & v,Value *value)', '    TracingState'];
read_adapter_interface.h;C++;pytorch-master/pytorch-master/caffe2/serialize; 23;  5; 5;4;  11; 0;0;0;0;0;0.45;0;[];['    _do_warn(const char *_reason,const char *_kind)', '    abandon', '    addInputs(Node *n,const char *name,int64_t value)', '    addInputs(Node *n,const char *name,c10::optional value)', '    addInputs(Node *n,const char *name,bool value)', '    addInputs(Node *n,const char *name,const c10::optional & value)', '    addInputs(Node *n,const char *name,double value)', '    addInputs(Node *n,const char *name,const at::Scalar & value)', '    addInputs(Node *n,const char *name,const at::Tensor & value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,ArrayRef value,bool allow_undefined)', '    addInputs(Node *n,const char *name,const std::string & value)', '    addInputs(Node *n,const char *name,const at::TensorOptions & value)', '    addInputs(Node *n,const char *name,at::Device value)', '    addInputs(Node *n,const char *name,at::Layout value)', '    addInputs(Node *n,const char *name,at::ScalarType value)', '    addInputs(Node *n,const char *name,at::MemoryFormat value)', '    addInputs(Node *n,const char *name,const at::Generator & value)', '    addInputs(Node *n,const char *name,const std::vector & value)', '    addInputs(Node *n,const char *name,ArrayRef value)', '    addInputs(Node *n,const char *name,const std::unordered_map & value)', '    addInputs(Node *n,const char *name,std::array value)', '    addInputs(Node *n,const char *name,const c10::intrusive_ptr & obj)', '    delValueTrace(const IValue & var)', '    ensureUniqueIfOutOfPlaced(const char *name,const at::Tensor & tensor)', '    getTracingState', '    getValueTrace(const IValue & var)', '    isTracing', '    pauseTracing', '    recordSourceLocation(Node *n)', '    setTracingState(std::shared_ptr state)', '    setValueTrace(const IValue & v,Value *value)', '    setWarn(warn_fn_type fn)', '    trace(Stack inputs,const std::function & traced_fn,std::function var_name_lookup_fn,bool force_outplace,Module *self)', '    warn(const char *_reason,const char *_kind)', '    empty', '    hasIntArrayRef(const std::string & arg_name)', '    hasValue(const std::string & arg_name)', '    popIntArrayRef(const std::string & arg_name)', '    popValue(const std::string & arg_name)', '    stashIntArrayRefElem(const std::string & arg_name,size_t size,size_t idx,const Variable & var)', '    stashValue(const std::string & arg_name,size_t idx,const Variable & var,const c10::TypePtr & type)', '    ArrayRef', '    IValue', '    IntArrayRefTrace(int size)', '    NoWarn', '    ~NoWarn', '    delValue(const IValue & var)', '    enterFrame', '    getOutput(const IValue & var,size_t i)', '    getValue(const IValue & var)', '    hasValue(const IValue & var)', '    leaveFrame', '    setValue(const IValue & v,Value *value)', '    TracingState', '    operator()(const WeakIValue & t1,const WeakIValue & t2)', '    operator()(const WeakIValue & t)', '    ~TracingState', '    WithNestedTracingFrame', '    ~WithNestedTracingFrame'];
adagrad_fused.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 456;  31; 76;3;  352; 0;205;161;145;151;0.09;9;[];['    ApplyTransform(const string & key,const NetDef & netdef)', '    ApplyTransformIfFaster(const string & key,const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs,const double improvement_threshold)', '    average_net_run_duration(const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs)', '    RegistryName', '    CreateTransform(string)', '    ApplyTo(const NetDef & orig_net)', '    PatternMatchHelper(const Graph & graph,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    ReplacePattern(const std::vector,Graph *graph)', '    TryNeighbors(const Graph & graph,const std::map,std::vector,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)'];
adam_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 690;  17; 52;10;  618; 0;345;321;214;262;0.03;17;['    Transform'];['    ApplyTransform(const string & key,const NetDef & netdef)', '    ApplyTransformIfFaster(const string & key,const NetDef & netdef,const NetDef & init_netdef,const int warmup_runs,const int main_runs,const double improvement_threshold)', '    CreateTransform(string key)', '    RegistryName', '    ApplyTo(const NetDef & orig_net_def)', '    PatternMatchHelper(const transform::Graph & graph,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    PatternRule(const transform::Graph & g,const std::vector & subgraph,int)', '    ReplacePattern(const std::vector,transform::Graph *graph)', '    ReplaceRule(const std::vector & subgraph,transform::Graph *g_ptr)', '    SetPatternMatchType(PatternMatchType type)', '    Transform', '    TryNeighbors(const transform::Graph & graph,const std::map,std::vector,const std::vector & matched,std::vector *subgraph_ptr,std::vector *best_subgraph_ptr)', '    ValidatorRule(const transform::Graph & g,const std::vector & subgraph)', '    ~Transform'];
fp32_momentum_sgd_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 66;  2; 8;3;  54; 0;22;30;33;34;0.04;5;[];['    TransformOnGPU(Tensor & X,Tensor *Y,Tensor & mean,Tensor & std,Context *context)'];
gftrl_op.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 38;  1; 6;2;  30; 0;1;21;20;36;0.03;2;['    DummyTransform', '    FastToSlowTransform', '    final', '    final', '    final', '    GeneralDummyTransform', '    SlowToFastTransform', '    SortedDummyTransform', '    TypeSwapTransform'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp1', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp2', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformDummyOp3', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformSleepFastOp', '    CAFFE_ANONYMOUS_VARIABLE_CPUTransformSleepSlowOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp1', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp2', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformDummyOp3', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformSleepFastOp', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TransformSleepSlowOp', '    TEST(TransformTest,TestPatternMatch)', '    TEST(TransformTest,TestReplacePattern)', '    TEST(TransformTest,TestTransformApply)', '    TEST(TransformTest,TestPatternMatchTypeSortedOrder)', '    TEST(TransformTest,TestPatternMatchTypeGeneral)', '    TEST(TransformTest,TestApplyTransformIfFasterIsFaster)', '    TEST(TransformTest,TestApplyTransformIfFasterButSlower)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    FastToSlowTransform', '    Run(int)', '    Run(int)', '    Run(int)', '    GeneralDummyTransform', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    SlowToFastTransform', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    SortedDummyTransform', '    ValidatorRule(const Graph & g,const std::vector & subgraph)', '    PatternRule(const Graph & g,const std::vector & subgraph,int idx)', '    ReplaceRule(const std::vector & match,Graph *g_ptr)', '    TypeSwapTransform(string old_type,string new_type)', '    ValidatorRule(const Graph & g,const std::vector & subgraph)'];
lars_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 55;  1; 21;1;  33; 0;18;28;4;11;0.03;3;[];['    CanRenameBackwards(const string & from,const string & to,const std::shared_ptr & net,const std::set & netInputs,const std::set & netOutputs,const std::set & ignoreTypes,int end)', '    CanRenameForwards(const string & from,const string & to,const std::shared_ptr & net,const std::set & netOutputs,const std::set & ignoreTypes,int start)', '    HasInput(const string & blob,const OperatorDef & op)', '    HasOutput(const string & blob,const OperatorDef & op)', '    InPlaceOps(const InferenceGraph & graph,const std::string & op_type)', '    NextBlob(const Workspace & ws,const string & prefix,int max_tries)', '    RemoveOpsByType(const InferenceGraph & graph,const std::string & op_type)', '    RenameInputs(const string & from,const string & to,OperatorDef *def)', '    RenameInputsInChildren(const string & from,const string & to,std::shared_ptr net,int pidx)', '    RenameOutputs(const string & from,const string & to,OperatorDef *def)'];
learning_rate_functors.h;C++;pytorch-master/pytorch-master/caffe2/sgd; 455;  37; 36;14;  372; 0;78;237;57;116;0.10;35;[];[];
math_lp.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 41;  2; 5;7;  27; 3;5;21;5;7;0.07;2;[];[];
rmsprop_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 53;  4; 14;3;  33; 0;15;24;9;10;0.12;3;[];['    transpose_4rows(int N,const std::uint8_t *src,std::uint8_t *dst)'];
rowwise_counter.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 25;  1; 7;1;  17; 0;14;17;1;9;0.06;2;[];['    NCHW2NHWC(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *)', '    NHWC2NCHW(const int N,const int C,const int HxW,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const float *X,float *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const double *X,double *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const double *X,double *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::int32_t *X,std::int32_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::int64_t *X,std::int64_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::uint8_t *X,std::uint8_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::uint8_t *X,std::uint8_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int32_t *dims,const int *axes,const std::uint16_t *X,std::uint16_t *Y,CPUContext *)', '    Transpose(const int ndim,const std::int64_t *dims,const int *axes,const std::uint16_t *X,std::uint16_t *Y,CPUContext *)', '    Transpose2D(const TIndex rows,const TIndex cols,const TData *X,TData *Y)', '    TransposeImpl(const int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y)', '    TransposeND(const int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y)'];
wngrad_op.cc;C++;pytorch-master/pytorch-master/caffe2/sgd; 63;  1; 27;1;  35; 0;31;35;2;17;0.03;4;[];['    transpose_4rows(int N,const std::uint8_t *src,std::uint8_t *dst)'];
depthwise3x3_conv_op.cc;C++;pytorch-master/pytorch-master/caffe2/share/contrib/depthwise; 545;  9; 38;57;  262; 218;155;152;144;222;0.03;17;[];['    NCHW2NHWC(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    NHWC2NCHW(int N,int C,int HxW,const T *X,T *Y,Context *context)', '    Transpose(int ndim,const TIndex *dims,const int *axes,const TData *X,TData *Y,Context *context)'];
quant_decomp_zstd_op.cc;C++;pytorch-master/pytorch-master/caffe2/share/contrib/zstd; 139;  21; 27;11;  82; 0;49;46;48;91;0.26;7;['    final'];['    IDEEPTransposeOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    ~IDEEPTransposeOp'];
common_subexpression_elimination.h;C++;pytorch-master/pytorch-master/caffe2/transforms; 52;  18; 7;5;  23; 0;3;15;2;8;0.78;2;['    GetTransposeGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTranspose', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Transpose', '    vector', '    CopyArguments', '    GetGradientDefs'];
conv_to_nnpack_transform_test.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 42;  5; 8;4;  30; 0;19;11;17;10;0.17;1;['    TransposeOp'];['    dim', '    vec', '    DoRunWithType', '    GetRepeatedArgument', '    RunOnDevice', '    TransposeImpl(const Tensor & X,Tensor *Y)', '    TransposeOp(Args,...)'];
single_op_transform.cc;C++;pytorch-master/pytorch-master/caffe2/transforms; 40;  2; 7;5;  28; 0;10;13;10;6;0.07;3;['    final'];['    CuDNNTransposeOp(Args,...)', '    DoRunWithType', '    IsCuDNNValidTensor(const Tensor & X)', '    IsFloatType', '    RunOnDevice', '    SetTensorDescriptor(const cudnnDataType_t data_type,const std::vector & X_dims,const std::vector & Y_dims)', '    ~CuDNNTransposeOp', '    DoRunWithType'];
cast.h;C++;pytorch-master/pytorch-master/caffe2/utils; 49;  2; 6;10;  16; 23;8;7;7;6;0.13;1;[];['    mergeRanges(SourceRange c,const TreeList & others)', '    operator<<(std::ostream & out,pretty_tree t_)', '    operator<<(std::ostream & out,const TreeRef & t)', '    incref(this)', '    matchD(k,,,args,...)', '    matchD(int k,const char *filename,int lineno,Args &,...)', '    matchNumSubtrees(int k,size_t expected_subtrees)', '    matchNumSubtreesD(int k,const char *filename,int lineno,size_t expected_subtrees,bool allow_more)', '    ~Tree', '    create(int kind,const SourceRange & range_,TreeList)', '    create(Args,...)', '    Compound(int kind,SourceRange range)', '    Compound(int kind,const SourceRange & range_,TreeList)', '    isAtom', '    override', '    range', '    trees', '    get_flat(const TreeRef & t)', '    pretty_tree(const TreeRef & tree,size_t col)', '    print(std::ostream & out,const TreeRef & t,int indent)', '    String(std::string value)', '    stringValue', '    isAtom', '    kind', '    range', '    stringValue', '    Tree(int kind_)', '    tree(size_t i)', '    trees'];
cpu_neon.h;C++;pytorch-master/pytorch-master/caffe2/utils; 53;  3; 2;6;  0; 45;0;0;0;0;0.00;0;[];['    create(const SourceRange & range)', '    create(const SourceRange & range,const T & value)', '    create(const Expr & value)', '    create(const SourceRange & range,const std::vector & subtrees)', '    unsafeCreate(const SourceRange & range,TreeList)', '    size', '    type_erased_sub', '    create(const SourceRange & range,const Expr & callee,const List & inputs,const List & attributes)', '    create(const SourceRange & range,const Expr & test,const Maybe & msg)', '    create(const SourceRange & range,const List & lhs,const Maybe & rhs,const Maybe & type)', '    create(const SourceRange & range,const Ident & name,const TreeRef & value)', '    create(const SourceRange & range,const Expr & lhs,const AugAssignKind & aug_op,const Expr & rhs)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Ident & name,const Maybe & superclass,const List & body)', '    create(const SourceRange & range,const std::string & value)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Ident & name,const Decl & decl,const List & stmts)', '    create(const SourceRange & range,const List & keys,const List & values)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Expr & list)', '    create(const SourceRange & range,const List & targets,const List & itrs,const List & body)', '    create(const SourceRange & range,const List & names)', '    create(const SourceRange & range,const std::string & name)', '    create(const SourceRange & range,const Expr & cond,const List & true_branch,const List & false_branch)', '    create(const SourceRange & range,const Expr & elt,const Expr & target,const Expr & iter)', '    create(const SourceRange & range,const List & inputs)', '    create(const SourceRange & range,const Ident & ident,const Maybe & type,const Maybe & def,bool kwarg_only)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Maybe & expr)', '    create(const SourceRange & range)', '    create(const SourceRange & range,const Expr & value)', '    create(const SourceRange & range,const Expr & value,const Ident & selector)', '    create(const SourceRange & range,const Maybe & start,const Maybe & end,const Maybe & step)', '    create(const SourceRange & range,const Expr & expr)', '    create(const SourceRange & range,const std::string & value)', '    create(const SourceRange & range,const Expr & value,const List & subscript_exprs)', '    create(const SourceRange & range,const Expr & cond,const Expr & true_expr,const Expr & false_expr)', '    create(const SourceRange & range,const List & inputs)', '    create(const SourceRange & range,int kind,const Expr & expr)', '    create(const SourceRange & range,const Ident & name)', '    create(const SourceRange & range,const Expr & cond,const List & body)', '    Apply(const TreeRef & tree)', '    attributes', '    callee', '    inputs', '    Assert(const TreeRef & tree)', '    msg', '    test', '    Assign(const TreeRef & tree)', '    lhs', '    lhs_list', '    Attribute(const TreeRef & tree)', '    name', '    value', '    aug_op', '    AugAssign(const TreeRef & tree)', '    lhs', '    AugAssignKind(const TreeRef & tree)', '    BinOp(const TreeRef & tree)', '    lhs', '    Break(const TreeRef & tree)', '    stoll', '    body', '    ClassDef(const TreeRef & tree)', '    name', '    superclass', '    withName(std::string new_name)', '    asFloatingPoint', '    asIntegral', '    Const(const TreeRef & tree)', '    isFloatingPoint', '    isIntegral', '    text', '    Continue(const TreeRef & tree)', '    Decl(const TreeRef & tree)', '    params', '    decl', '    Def(const TreeRef & tree)', '    name', '    statements', '    withDecl(Decl decl)', '    withName(std::string new_name)', '    DictLiteral(const TreeRef & tree)', '    key_inputs', '    value_inputs', '    Dots(const TreeRef & tree)', '    Expr(const TreeRef & tree)', '    range', '    expr', '    ExprStmt(const TreeRef & tree)', '    body', '    For(const TreeRef & tree)', '    itrs', '    targets', '    Global(const TreeRef & tree)', '    names', '    Ident(const TreeRef & tree)', '    name', '    range', '    cond', '    falseBranch', '    If(const TreeRef & tree)', '    trueBranch', '    withNewBranches(const List & true_branch,const List & false_branch)', '    elt', '    iter', '    ListComp(const TreeRef & tree)', '    target', '    inputs', '    ListLiteral(const TreeRef & tree)', '    get', '    Maybe(const TreeRef & tree)', '    Maybe(const T & tree)', '    present', '    defaultValue', '    ident', '    kwarg_only', '    Param(const TreeRef & tree)', '    type', '    withType(const Maybe & typ)', '    Pass(const TreeRef & tree)', '    expr', '    Raise(const TreeRef & tree)', '    expr', '    Return(const TreeRef & tree)', '    Select(const TreeRef & tree)', '    selector', '    value', '    createInt(int value)', '    end', '    endOr(int alternative)', '    SliceExpr(const TreeRef & tree)', '    start', '    startOr(int alternative)', '    step', '    stepOr(int alternative)', '    expr', '    Starred(const TreeRef & tree)', '    Stmt(const TreeRef & tree)', '    StringLiteral(const TreeRef & tree)', '    text', '    Subscript(const TreeRef & tree)', '    subscript_exprs', '    value', '    cond', '    false_expr', '    TernaryIf(const TreeRef & tree)', '    true_expr', '    begin', '    empty', '    end', '    List(const TreeRef & tree)', '    operator[](size_t i)', '    ListIterator(TreeList::const_iterator it)', '    operator!=(const ListIterator & rhs)', '    operator*', '    operator++', '    operator+=(std::ptrdiff_t n)', '    operator--', '    operator==(const ListIterator & rhs)', '    dump', '    get', '    kind', '    operator TreeRef', '    range', '    subtree(size_t i)', '    tree', '    TreeView(TreeRef tree)', '    inputs', '    TupleLiteral(const TreeRef & tree)', '    UnaryOp(const TreeRef & tree)', '    name', '    Var(const TreeRef & tree)', '    body', '    cond', '    While(const TreeRef & tree)'];
eigen_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils; 187;  17; 24;6;  142; 0;35;78;41;94;0.12;5;[];['    apply_triu_tril_single(scalar_t *result,scalar_t *self,bool inplace,int64_t k,int64_t n,int64_t m,int64_t res_row_stride,int64_t res_col_stride,int64_t self_row_stride,int64_t self_col_stride)', '    apply_triu_tril(Tensor & result,const Tensor & self,bool inplace,int64_t k)', '    tril(const Tensor & self,int64_t k)', '    tril_cpu_(Tensor & self,int64_t k)', '    tril_cpu_out(Tensor & result,const Tensor & self,int64_t k)', '    triu(const Tensor & self,int64_t k)', '    triu_cpu_(Tensor & self,int64_t k)', '    triu_cpu_out(Tensor & result,const Tensor & self,int64_t k)'];
fixed_divisor_test.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 80;  7; 19;5;  51; 0;42;17;29;15;0.14;2;[];['    batchCountTrilTriu(const Tensor & batched_matrices)', '    checkTrilTriuBatchContiguous(const Tensor & tensor,bool allow_zero_stride)'];
math.h;C++;pytorch-master/pytorch-master/caffe2/utils; 466;  56; 46;75;  293; 1;11;292;0;81;0.19;0;[];['    BuildTrtEngine(const std::string & onnx_model_str,TrtLogger *logger,size_t max_batch_size,size_t max_workspace_size,bool debug_builder)'];
elementwise.h;C++;pytorch-master/pytorch-master/caffe2/utils/math; 154;  8; 17;5;  127; 0;0;127;0;52;0.06;0;['    TrtLogger'];['    BuildTrtEngine(const std::string & onnx_model_str,TrtLogger *logger,size_t max_batch_size,size_t max_workspace_size,bool debug_builder)', '    TrtObject(T *obj)', '    operator()(T *obj)', '    log(Severity severity,const char *msg)', '    TrtLogger(Severity verbosity)'];
transpose.cc;C++;pytorch-master/pytorch-master/caffe2/utils/math; 267;  12; 17;101;  95; 94;55;60;44;38;0.13;17;['    C10FlagParser_f_in', '    C10FlagParser_f_out'];['    main(int argc,char **argv)', '    C10FlagParser_f_in(const std::string & content)', '    C10FlagParser_f_out(const std::string & content)'];
math_cpu.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 2701;  216; 136;693;  1446; 352;797;831;2617;1699;0.15;382;['    GetTTContractionGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTTContraction', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTContractionGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTContraction', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTContractionGradient', '    vector', '    GetGradientDefs'];
murmur_hash3.h;C++;pytorch-master/pytorch-master/caffe2/utils; 34;  9; 12;5;  8; 4;0;8;0;7;1.13;0;['    final', '    final'];['    RunOnDevice', '    RunOnDevice', '    TTContractionGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    TTContractionOp(const OperatorDef & operator_def,Workspace *ws)'];
proto_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils; 361;  43; 47;14;  217; 49;7;24;9;24;0.20;6;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDATTContraction', '    CAFFE_ANONYMOUS_VARIABLE_CUDATTContractionGradient'];
signal_handler.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 463;  5; 3;35;  20; 433;7;9;7;6;0.25;5;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUTT', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTLinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TT', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTLinearGradient'];
smart_tensor_printer.cc;C++;pytorch-master/pytorch-master/caffe2/utils; 77;  8; 13;5;  51; 2;8;38;8;16;0.16;8;['    final', '    TTLinearGradientOp'];['    dtype', '    ThrowEnforceNotMet(,,,::c10::str __VA_ARGS__)', '    ReinitializeTensor(& bias_multiplier_,,at::dtype)', '    GetRepeatedArgument', '    RunOnDevice', '    TTLinearOp(Args,...)', '    ~TTLinearOp', '    dim32', '    Gemm(CblasNoTrans,CblasNoTrans,Y,Y,,,bias_multiplier_,b,,Y,& context_)', '    Set(batch_size,,bias_multiplier_,& context_)', '    RunOnDevice', '    Tensor', '    TTLinearGradientOp(Args,...)', '    ~TTLinearGradientOp'];
string_utils.h;C++;pytorch-master/pytorch-master/caffe2/utils; 45;  1; 9;6;  30; 0;10;19;4;7;0.03;2;['    GetTTPadGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUTTPad', '    CAFFE_ANONYMOUS_VARIABLE_CPUTTPadGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTPad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TTPadGradient', '    vector', '    GetGradientDefs'];
pthreadpool_new_if_impl.c;C;pytorch-master/pytorch-master/caffe2/utils/threadpool; 1209;  139; 92;97;  804; 102;462;432;265;289;0.17;33;['    final', '    final'];['    RunOnDevice', '    RunOnDevice', '    TTPadGradientOp(const OperatorDef & operator_def,Workspace *ws)', '    TTPadOp(const OperatorDef & operator_def,Workspace *ws)'];
ThreadPoolCommon.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 23;  6; 4;15;  0; 4;0;0;0;0;0.00;0;[];['    main(int argc,char **argv)'];
ThreadPoolXNNPACK.h;C++;pytorch-master/pytorch-master/caffe2/utils/threadpool; 7;  4; 0;1;  3; 0;0;3;0;2;1.33;0;['    C10FlagParser_caffe2_tvm_min_ops', '    C10FlagParser_caffe2_tvm_profiling_based_jit'];['    supported_ops', '    cleanUpPredictNet(NetDef *net,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names)', '    tvmTransform(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,size_t max_batch_size,size_t max_seq_size,bool debug)', '    C10FlagParser_caffe2_tvm_min_ops(const std::string & content)', '    C10FlagParser_caffe2_tvm_profiling_based_jit(const std::string & content)', '    applyTvmTransform(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    buildTvmOp(const caffe2::NetDef & net,const std::unordered_set & weights,const ShapeInfoMap & shape_hints)', '    canConvertFullGraph(const caffe2::NetDef & net,const std::unordered_set & blacklisted_ops)', '    getSupportedOps', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & input_shape_hints,const std::unordered_set & blacklisted_ops)'];
optical_flow.h;C++;pytorch-master/pytorch-master/caffe2/video; 50;  10; 10;8;  24; 0;0;24;0;6;0.42;0;['    final'];['    cleanUpPredictNet(NetDef *net,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names)', '    tvmTransform(NetDef *net,Workspace *ws,const std::vector & input_names,const std::vector & output_names,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops,size_t max_batch_size,size_t max_seq_size,bool debug)', '    canConvertFullGraph(const caffe2::NetDef & net,const std::unordered_set & blacklisted_ops)', '    getSupportedOps', '    applyTvmTransform(NetDef *pred_net,const std::unordered_set & weights,const std::unordered_set & blacklisted_ops,const ShapeInfoMap & shape_hints)', '    buildTvmOp(const caffe2::NetDef & net,const std::unordered_set & weights,const ShapeInfoMap & shape_hints)', '    profiling_based_jit', '    transform(Workspace *ws,NetDef *pred_net,const std::vector & weight_names,const ShapeInfoMap & shape_hints,const std::unordered_set & blacklisted_ops)', '    tvm_op_id_', '    TvmTransformer(const TvmTransformOptions & opts)', '    TvmTransformOptions', '    ~TvmTransformer'];
video_input_op.h;C++;pytorch-master/pytorch-master/caffe2/video; 1021;  56; 93;15;  864; 0;496;320;437;253;0.06;13;[];['    demangle(const char *name)'];
LibTorch.h;C++;pytorch-master/pytorch-master/ios; 6;  0; 2;4;  0; 0;0;0;0;0;0.00;0;[];['    compatible_optional(c10::optional e,T a)', '    compatible_varying_shape(const VaryingShape & e,at::IntArrayRef a)', '    containsAny(const TypePtr & type)', '    operator<<(std::ostream & out,const Type & t)', '    VaryingShape', '    checkNoAny(const Type & base,const char *what,const std::string & attrname,const TypePtr & attrtype)', '    elementTypeCanBeInferredFromMembers(const TypePtr & elem_type)', '    is_module', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    matchTypeVariables(TypePtr formal,TypePtr actual,TypeEnv & type_env)', '    merge(const VaryingShape & other)', '    operator<<(std::ostream & out,const VaryingShape & vs)', '    tryEvalTypeVariables(TypePtr type,std::unordered_map & type_env)', '    typeKindToString(TypeKind kind)', '    unifyTypeList(at::ArrayRef elements,std::ostream & why_not)', '    unifyTypes(const TypePtr & t1,const TypePtr & t2)', '    get', '    get', '    get', '    get', '    get', '    get', '    addAttribute(const std::string & name,const TypePtr & type,bool is_parameter)', '    addConstant(const std::string & name,const IValue & value)', '    addMethod(torch::jit::Function *method)', '    checkNotExist(const std::string & name,const std::string & what)', '    ClassType(c10::optional name,std::weak_ptr cu,bool is_module)', '    compilation_unit', '    compilation_unit', '    create(c10::optional qualifiedName,std::weak_ptr cu,bool is_module)', '    findConstant(const std::string & name)', '    getConstant(const std::string & name)', '    getConstant(size_t slot)', '    getMethod(const std::string & name)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    methods', '    refine(at::ArrayRef refined_slots)', '    unsafeRemoveAttribute(const std::string & name)', '    unsafeRemoveConstant(const std::string & name)', '    unsafeRemoveMethod(const std::string & name)', '    get', '    get', '    FunctionType(torch::jit::Function *function)', '    get', '    addMethod(FunctionSchema schema)', '    create(QualifiedName qualifiedName,bool is_module)', '    getMethod(const std::string & name)', '    InterfaceType(QualifiedName name,bool is_module)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    get', '    get', '    isSubtypeOfExt(const TypePtr rhs_,std::ostream *why_not)', '    ofBools', '    ofFloats', '    ofInts', '    ofStrings', '    ofTensors', '    get', '    get', '    ofTensor', '    get', '    get', '    get', '    get', '    get', '    isCompatibleWithInCurrentExecutionContext(at::Tensor & t)', '    isSubtypeOfExt(const TypePtr rhs,std::ostream *why_not)', '    merge(TensorTypePtr other)', '    str', '    createNamed(const c10::optional & qualName,const std::vector & field_names,const std::vector & field_types)', '    isSubtypeOfExt(const TypePtr rhs_,std::ostream *why_not)', '    operator==(const Type & rhs)', '    python_str', '    str', '    TupleType(std::vector elements,c10::optional name,std::shared_ptr schema)'];
group_spatial_softmax_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 83;  16; 18;2;  48; 0;36;42;4;21;0.33;6;[];['    demangle(const char *name)', '    demangle_type'];
roi_pool_f_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 99;  16; 9;1;  74; 0;66;72;4;21;0.22;6;[];['    operator()(const TypePtr & a,const TypePtr & b)', '    operator()(const TypePtr & type)'];
select_smooth_l1_loss_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 107;  16; 10;1;  81; 0;69;75;4;21;0.20;6;[];['    operator()(const TypePtr & a,const TypePtr & b)', '    operator()(const TypePtr & type)'];
sigmoid_focal_loss_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 119;  16; 26;1;  77; 0;66;68;4;22;0.21;6;['    TypeParser'];['    isSpecialChar(char a)', '    parseType(const std::string & pythonStr)', '    CreateSingleElementType', '    cur', '    expect(const std::string & s)', '    lex', '    next', '    parse', '    TypeParser(std::string pythonStr)'];
softmax_focal_loss_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 104;  16; 23;2;  64; 0;54;60;4;21;0.25;6;[];['    parseType(const std::string & pythonStr)'];
upsample_nearest_op.cc;C++;pytorch-master/pytorch-master/modules/detectron; 83;  16; 9;7;  49; 5;39;45;4;21;0.33;6;[];[];
net_observer_reporter.h;C++;pytorch-master/pytorch-master/modules/observers; 38;  9; 6;5;  20; 0;11;17;0;14;0.45;0;[];['    TypedAxpy(int N,const float a,const float *x,float *y)', '    TypedAxpy(int N,const float a,const at::Half *x,float *y)', '    TypedAxpy(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpy__base(int N,const float a,const float *x,float *y)', '    TypedAxpy_uint8_float__base(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpyHalffloat__base(int N,const float a,const at::Half *x,float *y)'];
observer_config.h;C++;pytorch-master/pytorch-master/modules/observers; 99;  28; 12;4;  55; 0;17;25;23;19;0.51;10;[];['    TypedAxpy(int N,const OUT a,const IN *x,OUT *y)'];
any.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 428;  18; 46;11;  353; 4;124;157;202;162;0.05;57;[];['    TypedAxpy__avx_f16c(int N,const float a,const float *x,float *y)', '    TypedAxpyHalffloat__avx_f16c(int N,const float a,const at::Half *x,float *y)'];
enum.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 87;  0; 5;10;  72; 0;70;35;69;69;0.00;1;[];['    TypedAxpy__avx2_fma(int N,const float a,const float *x,float *y)', '    TypedAxpy_uint8_float__avx2_fma(int N,const float a,const std::uint8_t *x,float *y)', '    TypedAxpyHalffloat__avx2_fma(int N,const float a,const at::Half *x,float *y)'];
init_baseline.h;C++;pytorch-master/pytorch-master/test/cpp/api; 181;  2; 8;2;  170; 0;128;6;0;75;0.01;0;[];['    registerer', '    $'];
misc.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 83;  1; 18;4;  60; 0;29;21;36;22;0.02;11;[];['    $'];
namespace.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 19;  8; 4;2;  5; 0;1;3;1;3;1.60;2;[];['    $legacy_th_headers', '    $', '    registerer'];
ordered_dict.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 234;  0; 31;3;  200; 0;138;46;166;43;0.00;29;[];['    $'];
serialize.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 934;  70; 132;22;  718; 0;519;339;323;354;0.10;48;['    final'];['    _ThrowRuntimeTypeLogicError(const string & msg)', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    noexcept', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
tensor.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 917;  36; 106;14;  778; 0;533;175;534;159;0.05;51;['    final', '    final', '    final'];['    _typeMetaDataInstance', '    Id', '    ItemSize', '    Make', '    TypeName', '    _typeMetaDataInstance', '    copy', '    deleteFn', '    _Copy(const void *src,void *dst,size_t n)', '    _CopyNotAllowed(const void *,void *,size_t)', '    _Delete(void *ptr)', '    _makeTypeMetaDataInstance', '    _New', '    _NewNotDefault', '    _PickCopy', '    _PickCopy', '    _PickDelete', '    _PickNew', '    _PickNew', '    _PickPlacementDelete', '    _PickPlacementNew', '    _PickPlacementNew', '    _PlacementDelete(void *ptr,size_t n)', '    _PlacementNew(void *ptr,size_t n)', '    _PlacementNewNotDefault(void *,size_t)', '    id', '    itemsize', '    Match', '    name', '    newFn', '    placementDelete', '    placementNew', '    operator!=(const TypeMeta & lhs,const TypeMeta & rhs)', '    operator<(TypeIdentifier lhs,TypeIdentifier rhs)', '    operator<<(std::ostream & stream,caffe2::TypeIdentifier typeId)', '    operator<<(std::ostream & stream,caffe2::TypeMeta typeMeta)', '    operator==(const TypeMeta & lhs,const TypeMeta & rhs)', '    TypeMeta', '    Get', '    uninitialized', '    get_fully_qualified_type_name', '    TypeMetaData', '    TypeMetaData(size_t itemsize,New *newFn,PlacementNew *placementNew,Copy *copy,PlacementDelete *placementDelete,Delete *deleteFn,TypeIdentifier id,c10::string_view name)', '    operator=', '    TypeMeta', '    operator()(caffe2::TypeIdentifier x)'];
tensor_options_cuda.cpp;C++;pytorch-master/pytorch-master/test/cpp/api; 78;  6; 17;14;  43; 0;26;9;54;10;0.14;4;[];[];
test_dist_autograd.cpp;C++;pytorch-master/pytorch-master/test/cpp/dist_autograd; 104;  17; 20;9;  63; 0;45;31;22;29;0.27;5;['    ClassAllowAssignment', '    ClassNoAssignment', '    TypeMetaTestBar', '    TypeMetaTestFoo'];['    TEST(TypeMetaTest,TypeMetaStatic)', '    TEST(TypeMetaTest,Names)', '    TEST(TypeMetaTest,TypeMeta)', '    TEST(TypeMetaTest,CtorDtorAndCopy)', '    TEST(TypeMetaTest,Float16IsNotUint16)', '    ClassAllowAssignment', '    ClassAllowAssignment(const ClassAllowAssignment & src)', '    ClassNoAssignment', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance', '    _typeMetaDataInstance'];
test_autodiff.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 275;  27; 37;18;  202; 0;156;113;62;68;0.13;9;[];['    get_fully_qualified_type_name', '    extract(string_view prefix,string_view suffix,string_view str)', '    fully_qualified_type_name_impl', '    type_index_impl', '    get_type_index', '    operator<(type_index lhs,type_index rhs)', '    operator<<(std::ostream & stream,type_index typeId)', '    fully_qualified_type_name_impl', '    type_index(uint64_t checksum)', '    operator()(c10::util::type_index x)', '    logic_error'];
test_class_parser.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 36;  2; 12;3;  21; 0;11;11;15;8;0.10;1;['    final'];['    TEST(TypeIndex,FunctionArgumentsAndReturns)', '    TEST(TypeIndex,NestedName)', '    TEST(TypeIndex,NonTypeTemplateParameter)', '    TEST(TypeIndex,TopLevelName)', '    TEST(TypeIndex,TypeComputationsAreResolved)', '    TEST(TypeIndex,FunctionTypeComputationsAreResolved)', '    TEST(TypeIndex,TypeTemplateParameter)'];
test_create_autodiff_subgraphs.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 24;  4; 4;3;  16; 0;10;6;2;4;0.25;1;[];['    THPDTypeInfo_bits(THPDTypeInfo *self,void *)', '    THPFInfo_eps(THPFInfo *self,void *)', '    THPFInfo_max(THPFInfo *self,void *)', '    THPFInfo_min(THPFInfo *self,void *)', '    THPFInfo_tiny(THPFInfo *self,void *)', '    THPIInfo_max(THPFInfo *self,void *)', '    THPIInfo_min(THPFInfo *self,void *)', '    self', '    self', '    THPDTypeInfo_compare(THPDTypeInfo *a,THPDTypeInfo *b,int op)', '    THPDTypeInfo_init(PyObject *module)', '    THPFInfo_New(const at::ScalarType & type)', '    THPFInfo_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPFInfo_str(THPFInfo *self)', '    THPIInfo_New(const at::ScalarType & type)', '    THPIInfo_pynew(PyTypeObject *type,PyObject *args,PyObject *kwargs)', '    THPIInfo_str(THPIInfo *self)'];
test_fuser.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 228;  12; 65;48;  105; 0;92;80;27;36;0.11;5;[];['    THPDTypeInfo_init(PyObject *module)', '    THPFInfo_Check(PyObject *obj)', '    THPIInfo_Check(PyObject *obj)'];
test_interpreter.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 31;  3; 6;2;  22; 0;14;18;5;16;0.14;1;[];[];
test_lite_interpreter.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 361;  32; 77;9;  246; 0;160;119;140;162;0.13;17;[];[];
test_peephole_optimize.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 118;  6; 40;5;  69; 0;51;11;18;9;0.09;1;['    MyClass', '    final', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass', '    MyClass'];['    TEST(TypeListTest,MapTypesToValues_members)', '    TEST(TypeListTest,MapTypesToValues_empty)', '    TEST(TypeListTest,MapTypesToValues_sametype)', '    TEST(TypeListTest,MapTypesToValues_differenttypes)', '    func', '    func', '    operator()(T)', '    operator()(T)'];
test_subgraph_matcher.cpp;C++;pytorch-master/pytorch-master/test/cpp/jit; 521;  45; 156;3;  331; 0;250;91;240;81;0.14;16;[];['    combine_categories(ScalarType higher,ScalarType lower)', '    promote_skip_undefined(ScalarType a,ScalarType b)', '    _has_compatible_shallow_copy_type(const Tensor & self,const Tensor & from)', '    is_complex(const Tensor & self)', '    is_cuda(const Tensor & self)', '    is_distributed(const Tensor & self)', '    is_floating_point(const Tensor & self)', '    is_quantized(const Tensor & self)', '    is_signed(const Tensor & self)', '    is_sparse(const Tensor & self)', '    type_as(const Tensor & self,const Tensor & other)', '    update_result_type_state(const Tensor & tensor,const ResultTypeState & in_state)', '    can_cast(const at::ScalarType from,const at::ScalarType to)', '    promote_types(ScalarType type1,ScalarType type2)', '    tensors', '    tensors'];
test_utils.h;C++;pytorch-master/pytorch-master/test/cpp/jit; 52;  8; 13;6;  27; 0;1;25;2;16;0.30;0;[];['    update_result_type_state(const Tensor & tensor,const ResultTypeState & in_state)'];
gtest.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 34;  2; 6;21;  5; 12;1;5;112;114;0.40;112;[];['    data_type_map', '    type_meta_map', '    DataTypeToTypeMeta(const TensorProto::DataType & dt)', '    TypeMetaToDataType(const TypeMeta & meta)'];
test_aten.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 1096;  3; 198;7;  891; 0;488;622;377;559;0.00;34;[];['    fromIValue(const at::IValue & ivalue)', '    fromIValues(std::vector values)', '    GloballyUniqueId(worker_id_t createdOn,local_id_t localId)', '    toIValue', '    toIValues', '    getAllowJitRRefPickle', '    operator!=(const GloballyUniqueId & other)', '    operator<<(std::ostream & os,GloballyUniqueId const & globalId)', '    operator==(const GloballyUniqueId & other)', '    JitRRefPickleGuard', '    ~JitRRefPickleGuard'];
test_ir_printer.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 82;  2; 13;6;  63; 0;28;44;20;41;0.03;5;[];['    getMiopenDataType(const at::Tensor & tensor)', '    miopen_version'];
test_type.cpp;C++;pytorch-master/pytorch-master/test/cpp/tensorexpr; 124;  9; 3;3;  111; 0;60;62;56;54;0.08;2;[];['    cudnn_version', '    getCudnnDataType(const at::Tensor & tensor)'];
cuda_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 19;  3; 3;1;  12; 0;7;4;7;5;0.25;2;[];['    to_string(const Dtype & dtype)', '    to_string(const ScalarType & type)', '    is_floating_point(const ScalarType & type)', '    is_integral(const ScalarType & type)', '    operator<<(std::ostream & stream,const Dtype & dtype)', '    operator<<(std::ostream & stream,const ScalarType & type)', '    ToDtype(ScalarType type)', '    byte_size', '    scalar_dtype', '    ToCppString'];
jit_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 20;  0; 5;2;  13; 0;7;3;5;6;0.00;2;[];[];
rng_extension.cpp;C++;pytorch-master/pytorch-master/test/cpp_extensions; 71;  0; 13;7;  51; 0;29;29;19;26;0.00;17;[];['    DataTypeToTypeMeta(const TensorProto::DataType & dt)', '    fp16_type', '    fp16_type', '    GetDimFromOrderString(const std::string & str)', '    NameScopeSeparator', '    StringToStorageOrder(const string & str)', '    TypeMetaToDataType(const TypeMeta & meta)', '    static_assert(,)'];
predictor.cpp;C++;pytorch-master/pytorch-master/test/mobile/custom_build; 53;  12; 8;3;  31; 0;18;15;13;15;0.39;6;[];['    cudnn_version', '    getCudnnDataType(const at::Tensor & tensor)'];
simple_ops.cpp;C++;pytorch-master/pytorch-master/test/mobile/op_deps; 88;  8; 14;5;  63; 0;38;26;22;17;0.13;6;[];[];
example1.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 126;  10; 19;3;  95; 0;67;22;50;16;0.11;1;[];['    getAllowJitRRefPickle', '    operator<<(std::ostream & os,GloballyUniqueId const & globalId)', '    fromIValue(const at::IValue &)', '    fromIValues(std::vector)', '    GloballyUniqueId(worker_id_t createdOn,local_id_t localId)', '    GloballyUniqueId', '    operator()(const GloballyUniqueId & key)', '    operator!=(const GloballyUniqueId & other)', '    operator=', '    operator==(const GloballyUniqueId & other)', '    SerializedPyObj(std::string,std::vector)', '    toIValue', '    toIValues', '    JitRRefPickleGuard', '    ~JitRRefPickleGuard'];
example5.c;C;pytorch-master/pytorch-master/third_party/miniz-2.0.8/examples; 327;  35; 50;13;  229; 0;145;33;126;33;0.15;1;['    Dtype', '    ScalarType'];['    to_string(const Dtype & dtype)', '    to_string(const ScalarType & type)', '    BinaryOpDtype(Dtype op1_dtype,Dtype op2_dtype,ScalarType ret_type)', '    is_floating_point(const ScalarType & type)', '    is_integral(const ScalarType & type)', '    operator<<(std::ostream & stream,const Dtype & dtype)', '    operator<<(std::ostream & stream,const ScalarType & type)', '    promoteTypes(ScalarType a,ScalarType b)', '    promoteTypes(Dtype a,Dtype b)', '    ToDtype', '    ToDtype(ScalarType type)', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    ToDtype', '    promoteTypes', '    byte_size', '    Dtype(int8_t type)', '    Dtype(ScalarType type)', '    Dtype(int8_t type,int lanes)', '    Dtype(ScalarType type,int lanes)', '    Dtype(Dtype type,int lanes)', '    is_floating_point', '    is_integral', '    lanes', '    operator!=(const Dtype & other)', '    operator==(const Dtype & other)', '    scalar_dtype', '    scalar_type', '    ToCppString'];
Functions.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 2583;  769; 244;18;  1602; 0;1068;558;702;507;0.48;119;[];['    getMiopenDataType(const at::Tensor & tensor)', '    miopen_version'];
python_nn_functions.cpp;C++;pytorch-master/pytorch-master/tools/autograd/templates; 96;  6; 13;12;  65; 2;47;28;41;32;0.09;5;['    ReduceOp'];[];
variable_factories.h;C++;pytorch-master/pytorch-master/tools/autograd/templates; 121;  44; 12;12;  54; 0;22;32;7;40;0.81;6;[];[];
op_dependency.cpp;C++;pytorch-master/pytorch-master/tools/code_analyzer; 772;  227; 52;17;  480; 0;273;158;218;124;0.47;24;[];['    declval', '    static_assert(,LambdaType,)'];
abi-check.cpp;C++;pytorch-master/pytorch-master/torch; 9;  0; 1;4;  3; 1;1;1;1;1;0.00;1;['    final', '    EqualityComparable', '    NotEqualityComparable', '    MyClass', '    Hashable', '    NotHashable', '    Double', '    Multiple', '    MyClass', '    Single', '    NotATypeCondition'];['    final', '    operator==(const EqualityComparable &,const EqualityComparable &)', '    func', '    lambda', '    func', '    operator()', '    operator()(Args,...)', '    operator()(Args,...)'];
cuda.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 18;  5; 5;3;  7; 0;0;7;0;5;0.71;0;[];[];
stateful.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/dataloader; 64;  21; 7;5;  33; 0;0;0;0;0;0.64;0;[];['    pytorch_u8clamp_ukernel__neon(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8clamp_ukernel__sse2(size_t n,const uint8_t *x,uint8_t *y,const union pytorch_qnnp_u8_clamping_params [1] params)'];
base.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 103;  27; 15;9;  61; 0;0;0;0;0;0.44;0;[];['    TEST(U8LUT32NORM__SCALAR,n_eq_1)', '    TEST(U8LUT32NORM__SCALAR,small_n)', '    TEST(U8LUT32NORM__SCALAR,large_n)', '    TEST(U8LUT32NORM__SCALAR,n_eq_1_inplace)', '    TEST(U8LUT32NORM__SCALAR,small_n_inplace)', '    TEST(U8LUT32NORM__SCALAR,large_n_inplace)'];
shared.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/datasets; 83;  24; 14;4;  45; 0;0;0;0;0;0.53;0;[];['    pytorch_u8lut32norm_ukernel__scalar(size_t n,const uint8_t *x,const uint32_t *t,uint8_t *y)'];
queue.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/detail; 84;  24; 8;8;  47; 0;15;17;13;48;0.51;3;[];[];
samplers.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 9;  0; 1;8;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_u8maxpool_ukernel_16x9p8q__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_16x9p8q__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_sub16__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)', '    pytorch_u8maxpool_ukernel_sub16__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_u8_clamping_params [1] params)'];
random.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/samplers; 56;  16; 12;6;  27; 0;0;0;0;0;0.59;0;[];[];
transforms.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data; 7;  0; 1;6;  0; 0;0;0;0;0;0.00;0;[];['    pytorch_u8rmax_ukernel__neon(size_t n,const uint8_t *x)', '    pytorch_u8rmax_ukernel__sse2(size_t n,const uint8_t *x)'];
stack.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/data/transforms; 49;  7; 6;6;  33; 0;0;0;0;0;0.21;0;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUQConv', '    create2b1bConvState(Workspace *ws,const TensorCPU & W,const TensorCPU *b)', '    filterNormalization11(const TensorCPU & WQ,TensorCPU *WQN)', '    filterNormalizationL1(const TensorCPU & W,TensorCPU *WL1)', '    qconv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    qim2col(const ConvArgs & args,const TensorCPU & XQ,const TensorCPU & WQ,TensorCPU *XQcol)', '    qpad_zero(const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bConvGeneric(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bUnification(QConvState *state,size_t N,size_t C,const float *WQNVdata,const float *YQs0Vdata,const float *YQs1Vdata,size_t YQstride,float *Ydata,size_t Ystride,const float *bias)', '    signQuantize(const TensorCPU & X,TensorCPU *XQ)', '    uniformQuantize2b1b(const TensorCPU & X,const std::vector,float offset,float inter_center_distance)', '    QConvOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDeviceWithOrderNHWC'];
TensorDataContainer.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/detail; 315;  82; 27;26;  182; 0;87;49;207;107;0.45;45;[];['    create2b1bConvState(Workspace *ws,const TensorCPU & W,const TensorCPU *b)', '    divRoundUp(size_t x,size_t d)', '    filterNormalization11(const TensorCPU & WQ,TensorCPU *WQN)', '    filterNormalizationL1(const TensorCPU & W,TensorCPU *WL1)', '    qconv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    qim2col(const ConvArgs & args,const TensorCPU & XQ,const TensorCPU & WQ,TensorCPU *XQcol)', '    qpad_zero(const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bConvGeneric(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)', '    run2b1bUnification(QConvState *state,size_t N,size_t C,const float *WQNVdata,const float *YQs0Vdata,const float *YQs1Vdata,size_t YQstride,float *Ydata,size_t Ystride,const float *bias)', '    signQuantize(const TensorCPU & X,TensorCPU *XQ)', '    uniformQuantize2b1b(const TensorCPU & X,const std::vector,float offset,float inter_center_distance)', '    pad_b', '    pad_l', '    pad_r', '    pad_t', '    stride_h', '    stride_w', '    parallelFor'];
nn.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 10;  0; 1;9;  0; 0;0;0;0;0;0.00;0;[];[];
batchnorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 70;  16; 6;5;  48; 0;0;0;0;0;0.33;0;[];['    run2b1bConvNeon(QConvState *state,const ConvArgs & args,const TensorCPU & X,TensorCPU *Y)'];
embedding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 173;  29; 15;6;  130; 0;0;0;0;0;0.22;0;[];['    ca(size_t pad,size_t stride)', '    conv(const ConvArgs & args,const TensorCPU & X,const TensorCPU & W,const TensorCPU *b,TensorCPU *Y)', '    ConvTest2b1b(int IC,int KH,int KW,int H,int W,int OC,int N,ConvArgs args)', '    gemmNT(int M,int N,int K,const float *A,const float *B,float *C)', '    gemmTest(int64_t M,int64_t N,int64_t)', '    genTensor0123(std::vector shape)', '    genTensor11(std::vector shape)', '    genTensorUniform11(std::vector shape)', '    qgemmNT(int M,int N,int K,const uint8_t *A,const uint8_t *B,float *C)', '    randInt(int a,int b)', '    TEST(QConv)', '    TEST(QConv)', '    TEST(QConv)', '    TEST(ULP,QPadZero)', '    TEST(QConv,GemmTest)', '    TEST(QConv,ConvTest)', '    rca'];
loss.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 857;  258; 75;40;  524; 0;0;0;0;0;0.49;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUReluFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUSigmoidFakeFp16NNPI', '    CAFFE_ANONYMOUS_VARIABLE_CPUSqrFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanhFakeFp16', '    CAFFE_ANONYMOUS_VARIABLE_CPUTanhFakeFp16NNPI', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ReluFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SigmoidFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SqrFakeFp16', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_TanhFakeFp16', '    CalcSigmoidByLUT(at::Half x)', '    CalcTanhByLUT(at::Half input)', '    CalcTanhByPolynomial(at::Half input)', '    CostInferenceForRelu(const OperatorDef & def,const vector & in)', '    sig_lut', '    operator()(const int N,const float *X,float *Y,CPUContext *)', '    operator()(const int N,const float *X,float *Y,CPUContext *)'];
pooling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/functional; 1001;  334; 72;56;  600; 0;0;0;0;0;0.56;0;[];['    operator()(const int N,const T *X,T *Y,Context *)', '    operator()(const int N,const T *X,T *Y,CPUContext *)', '    operator()(const int N,const T *X,T *Y,Context *context)', '    operator()(const int N,const T *X,T *Y,CPUContext *context)'];
module.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn; 691;  398; 78;14;  205; 0;0;0;0;0;1.94;0;[];['    mkldnn_sigmoid(const Tensor & self)', '    mkldnn_sigmoid_(Tensor & self)'];
adaptive.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 94;  34; 24;8;  30; 0;0;0;0;0;1.13;0;[];['    mvlgamma_check(const Tensor & self,int64_t p)', '    unary_op_impl(const Tensor & self,OutImpl & out_impl)', '    unary_op_impl_(Tensor & self,OutImpl & out_impl)', '    unary_op_impl_out(Tensor & result,const Tensor & self,Stub & stub)', '    _atan__cpu(Tensor & self)', '    _atan_out_cpu(Tensor & result,const Tensor & self)', '    _clamp__cpu(Tensor & self,optional min,optional max)', '    _clamp_max__cpu(Tensor & self,Scalar max)', '    _clamp_max_out_cpu(Tensor & result,const Tensor & self,Scalar max)', '    _clamp_min__cpu(Tensor & self,Scalar min)', '    _clamp_min_out_cpu(Tensor & result,const Tensor & self,Scalar min)', '    _clamp_out_cpu(Tensor & result,const Tensor & self,optional min,optional max)', '    _cos__cpu(Tensor & self)', '    _cos_out_cpu(Tensor & result,const Tensor & self)', '    _cosh__cpu(Tensor & self)', '    _cosh_out_cpu(Tensor & result,const Tensor & self)', '    _erf__cpu(Tensor & self)', '    _erf_out_cpu(Tensor & result,const Tensor & self)', '    _erfc__cpu(Tensor & self)', '    _erfc_out_cpu(Tensor & result,const Tensor & self)', '    _erfinv__cpu(Tensor & self)', '    _erfinv__cuda(Tensor & self)', '    _erfinv_out_cpu(Tensor & result,const Tensor & self)', '    _erfinv_out_cuda(Tensor & result,const Tensor & self)', '    _exp__cpu(Tensor & self)', '    _exp_out_cpu(Tensor & result,const Tensor & self)', '    _lgamma__cpu(Tensor & self)', '    _lgamma__cuda(Tensor & self)', '    _lgamma_out_cpu(Tensor & result,const Tensor & self)', '    _lgamma_out_cuda(Tensor & result,const Tensor & self)', '    _tan__cpu(Tensor & self)', '    _tan_out_cpu(Tensor & result,const Tensor & self)', '    _tanh__cpu(Tensor & self)', '    _tanh_out_cpu(Tensor & result,const Tensor & self)', '    abs(const Tensor & self)', '    abs_(Tensor & self)', '    abs_out(Tensor & result,const Tensor & self)', '    acos(const Tensor & self)', '    acos_(Tensor & self)', '    acos_out(Tensor & result,const Tensor & self)', '    angle(const Tensor & self)', '    angle_out(Tensor & result,const Tensor & self)', '    asin(const Tensor & self)', '    asin_(Tensor & self)', '    asin_out(Tensor & result,const Tensor & self)', '    atan(const Tensor & self)', '    bitwise_not(const Tensor & self)', '    bitwise_not_(Tensor & self)', '    bitwise_not_out(Tensor & result,const Tensor & self)', '    ceil(const Tensor & self)', '    ceil_(Tensor & self)', '    ceil_out(Tensor & result,const Tensor & self)', '    clamp(const Tensor & self,optional min,optional max)', '    clamp_max(const Tensor & self,Scalar max)', '    clamp_min(const Tensor & self,Scalar min)', '    conj(const Tensor & self)', '    conj_out(Tensor & result,const Tensor & self)', '    cos(const Tensor & self)', '    cosh(const Tensor & self)', '    digamma(const Tensor & self)', '    digamma_(Tensor & self)', '    digamma_out(Tensor & result,const Tensor & self)', '    erf(const Tensor & self)', '    erfc(const Tensor & self)', '    erfinv(const Tensor & self)', '    exp(const Tensor & self)', '    expm1(const Tensor & self)', '    expm1_(Tensor & self)', '    expm1_out(Tensor & result,const Tensor & self)', '    floor(const Tensor & self)', '    floor_(Tensor & self)', '    floor_out(Tensor & result,const Tensor & self)', '    frac(const Tensor & self)', '    frac_(Tensor & self)', '    frac_out(Tensor & result,const Tensor & self)', '    imag(const Tensor & self)', '    lgamma(const Tensor & self)', '    log(const Tensor & self)', '    log10(const Tensor & self)', '    log10_(Tensor & self)', '    log10_out(Tensor & result,const Tensor & self)', '    log1p(const Tensor & self)', '    log1p_(Tensor & self)', '    log1p_out(Tensor & result,const Tensor & self)', '    log2(const Tensor & self)', '    log2_(Tensor & self)', '    log2_out(Tensor & result,const Tensor & self)', '    log_(Tensor & self)', '    log_out(Tensor & result,const Tensor & self)', '    logical_not(const Tensor & self)', '    logical_not_(Tensor & self)', '    logical_not_out(Tensor & result,const Tensor & self)', '    mvlgamma(const Tensor & self,int64_t p)', '    mvlgamma_(Tensor & self,int64_t p)', '    neg(const Tensor & self)', '    neg_(Tensor & self)', '    neg_out(Tensor & result,const Tensor & self)', '    polygamma(int64_t n,const Tensor & self)', '    polygamma_(Tensor & self,int64_t n)', '    polygamma_out(Tensor & result,int64_t n,const Tensor & self)', '    real(const Tensor & self)', '    reciprocal(const Tensor & self)', '    reciprocal_(Tensor & self)', '    reciprocal_out(Tensor & result,const Tensor & self)', '    round(const Tensor & self)', '    round_(Tensor & self)', '    round_out(Tensor & result,const Tensor & self)', '    rsqrt(const Tensor & self)', '    rsqrt_(Tensor & self)', '    rsqrt_out(Tensor & result,const Tensor & self)', '    sigmoid(const Tensor & self)', '    sigmoid_(Tensor & self)', '    sigmoid_out(Tensor & result,const Tensor & self)', '    sign(const Tensor & self)', '    sign_(Tensor & self)', '    sign_out(Tensor & result,const Tensor & self)', '    sin(const Tensor & self)', '    sin_(Tensor & self)', '    sin_out(Tensor & result,const Tensor & self)', '    sinh(const Tensor & self)', '    sinh_(Tensor & self)', '    sinh_out(Tensor & result,const Tensor & self)', '    sqrt(const Tensor & self)', '    sqrt_(Tensor & self)', '    sqrt_out(Tensor & result,const Tensor & self)', '    square(const Tensor & self)', '    square_(Tensor & self)', '    tan(const Tensor & self)', '    tanh(const Tensor & self)', '    trunc(const Tensor & self)', '    trunc_(Tensor & self)', '    trunc_out(Tensor & result,const Tensor & self)'];
any_module_holder.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 128;  23; 20;2;  85; 0;0;0;0;0;0.27;0;[];['    abs_stub', '    abs_stub', '    operator=', '    acos_stub', '    acos_stub', '    operator=', '    angle_stub', '    angle_stub', '    operator=', '    asin_stub', '    asin_stub', '    operator=', '    atan_stub', '    atan_stub', '    operator=', '    bernoulli_mkl_stub', '    bernoulli_mkl_stub', '    operator=', '    bitwise_not_stub', '    bitwise_not_stub', '    operator=', '    cauchy_stub', '    cauchy_stub', '    operator=', '    ceil_stub', '    ceil_stub', '    operator=', '    clamp_max_stub', '    clamp_max_stub', '    operator=', '    clamp_min_stub', '    clamp_min_stub', '    operator=', '    clamp_stub', '    clamp_stub', '    operator=', '    conj_stub', '    conj_stub', '    operator=', '    cos_stub', '    cos_stub', '    operator=', '    cosh_stub', '    cosh_stub', '    operator=', '    digamma_stub', '    digamma_stub', '    operator=', '    erf_stub', '    erf_stub', '    operator=', '    erfc_stub', '    erfc_stub', '    operator=', '    erfinv_stub', '    erfinv_stub', '    operator=', '    exp_stub', '    exp_stub', '    operator=', '    expm1_stub', '    expm1_stub', '    operator=', '    exponential_stub', '    exponential_stub', '    operator=', '    floor_stub', '    floor_stub', '    operator=', '    frac_stub', '    frac_stub', '    operator=', '    geometric_stub', '    geometric_stub', '    operator=', '    imag_stub', '    imag_stub', '    operator=', '    lgamma_stub', '    lgamma_stub', '    operator=', '    log10_stub', '    log10_stub', '    operator=', '    log1p_stub', '    log1p_stub', '    operator=', '    log2_stub', '    log2_stub', '    operator=', '    log_normal_stub', '    log_normal_stub', '    operator=', '    log_stub', '    log_stub', '    operator=', '    logical_not_stub', '    logical_not_stub', '    operator=', '    multinomial_stub', '    multinomial_stub', '    operator=', '    neg_stub', '    neg_stub', '    operator=', '    normal_stub', '    normal_stub', '    operator=', '    operator=', '    polygamma_stub', '    polygamma_stub', '    operator=', '    random_from_to_stub', '    random_from_to_stub', '    operator=', '    random_full_64_bits_range_stub', '    random_full_64_bits_range_stub', '    operator=', '    random_stub', '    random_stub', '    operator=', '    real_stub', '    real_stub', '    operator=', '    reciprocal_stub', '    reciprocal_stub', '    operator=', '    round_stub', '    round_stub', '    operator=', '    rsqrt_stub', '    rsqrt_stub', '    operator=', '    sigmoid_stub', '    sigmoid_stub', '    operator=', '    sign_stub', '    sign_stub', '    operator=', '    sin_stub', '    sin_stub', '    operator=', '    sinh_stub', '    sinh_stub', '    operator=', '    sqrt_stub', '    sqrt_stub', '    operator=', '    tan_stub', '    tan_stub', '    operator=', '    tanh_stub', '    tanh_stub', '    operator=', '    trigamma_stub', '    trigamma_stub', '    operator=', '    trunc_stub', '    trunc_stub'];
named_any.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules/container; 95;  34; 14;16;  33; 0;0;0;0;0;1.03;0;[];['    abs_kernel(TensorIterator & iter)', '    acos_kernel(TensorIterator & iter)', '    angle_kernel(TensorIterator & iter)', '    bitwise_not_kernel(TensorIterator & iter)', '    cauchy_kernel(TensorIterator & iter,double median,double sigma,Generator gen)', '    clamp_kernel(TensorIterator & iter,Scalar min_scalar,Scalar max_scalar)', '    clamp_max_kernel(TensorIterator & iter,Scalar max_scalar)', '    clamp_min_kernel(TensorIterator & iter,Scalar min_scalar)', '    conj_kernel(TensorIterator & iter)', '    cosh_kernel(TensorIterator & iter)', '    digamma_kernel(TensorIterator & iter)', '    exponential_kernel(TensorIterator & iter,double lambda,Generator gen)', '    frac_kernel(TensorIterator & iter)', '    geometric_kernel(TensorIterator & iter,double p,Generator gen)', '    imag_kernel(TensorIterator & iter)', '    log_normal_kernel(TensorIterator & iter,double mean,double std,Generator gen)', '    logical_not_kernel(TensorIterator & iter)', '    neg_kernel(TensorIterator & iter)', '    polygamma_kernel(TensorIterator & iter,int64_t n)', '    random_from_to_kernel(TensorIterator & iter,uint64_t range,int64_t base,Generator gen)', '    random_full_64_bits_range_kernel(TensorIterator & iter,Generator gen)', '    random_kernel(TensorIterator & iter,Generator gen)', '    real_kernel(TensorIterator & iter)', '    reciprocal_kernel(TensorIterator & iter)', '    rsqrt_kernel(TensorIterator & iter)', '    sigmoid_kernel(TensorIterator & iter)', '    sign_kernel(TensorIterator & iter)', '    sinh_kernel(TensorIterator & iter)', '    trigamma_kernel(TensorIterator & iter)', '    abs_impl(T v)', '    abs_impl(uint8_t v)', '    bernoulli_mkl_kernel(Tensor & self,const double p,Generator gen)', '    normal_kernel(Tensor & self,double mean,double std,Generator gen)'];
dropout.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 190;  89; 36;8;  59; 0;0;0;0;0;1.51;0;[];[];
linear.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 170;  80; 36;9;  47; 0;0;0;0;0;1.70;0;[];['    TEST(TestUndefined,UndefinedTest)'];
pixelshuffle.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 48;  22; 11;5;  12; 0;0;0;0;0;1.83;0;[];['    dim', '    has_storage', '    size(int64_t d)', '    sizes', '    storage', '    storage_offset', '    stride(int64_t d)', '    strides', '    UndefinedTensorImpl'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/modules; 46;  9; 6;4;  31; 0;0;0;0;0;0.29;0;[];[];
batchnorm.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 91;  47; 20;4;  24; 0;0;0;0;0;1.96;0;[];[];
embedding.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 188;  100; 21;5;  66; 0;0;0;0;0;1.52;0;[];[];
loss.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 630;  406; 80;5;  159; 0;0;0;0;0;2.55;0;[];['    cadd(scalar_t *z,const scalar_t *x,const scalar_t *y,int64_t n)', '    unfolded2d_acc(scalar_t *finput_data,scalar_t *input_data,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_copy(scalar_t *input_data,scalar_t *finput_data,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_acc_kernel(Tensor & finput,Tensor & input,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    unfolded2d_copy_kernel(Tensor & finput,Tensor & input,int64_t kH,int64_t kW,int64_t dH,int64_t dW,int64_t padH,int64_t padW,int64_t n_input_plane,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)'];
pooling.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/options; 549;  332; 86;5;  145; 0;0;0;0;0;2.29;0;[];['    operator=', '    unfolded2d_acc_stub', '    unfolded2d_acc_stub', '    operator=', '    unfolded2d_copy_stub', '    unfolded2d_copy_stub'];
data_parallel.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/parallel; 284;  86; 37;17;  154; 0;75;60;52;54;0.56;6;[];['    IsAGeZeroAndALtB(int64_t a,int64_t b)', '    MatAdd(int64_t M,int64_t N,int64_t ldx,int64_t ldy,const T *X,T *Y)', '    MatAdd(int64_t M,int64_t N,int64_t ldx,int64_t stridex,int64_t ldy,int64_t stridey,const T *X,T *Y)', '    MatCopy(int64_t M,int64_t N,int64_t lda,int64_t ldb,const T *A,T *B)', '    MatCopy(int64_t M,int64_t N,int64_t lda,int64_t stridea,int64_t ldb,int64_t strideb,const T *A,T *B)', '    Unfold3dAccCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dAccKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,const T *src,T *dst)', '    Unfold3dCopyCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dCopyKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,const T *src,T *dst)', '    Unfold3dZeroPaddingAccKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,const T *src,T *dst)', '    Unfold3dZeroPaddingCopyKernelImpl(int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,const T *src,T *dst)'];
clip_grad.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/nn/utils; 99;  19; 12;2;  69; 0;0;0;0;0;0.28;0;[];['    Unfold3dAccCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)', '    Unfold3dCopyCPU(const Tensor & src,int64_t C,int64_t X_D,int64_t X_H,int64_t X_W,int64_t Y_D,int64_t Y_H,int64_t Y_W,int64_t kernel_d,int64_t kernel_h,int64_t kernel_w,int64_t stride_d,int64_t stride_h,int64_t stride_w,int64_t pad_d,int64_t pad_h,int64_t pad_w,Tensor *dst)'];
adagrad.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 82;  4; 12;8;  62; 0;0;0;0;0;0.06;0;[];['    _unique2_cpu(const Tensor & self,const bool sorted,const bool return_inverse,const bool return_counts)', '    _unique_cpu(const Tensor & self,const bool sorted,const bool return_inverse)', '    _unique_dim_cpu_impl(ForwardIt first,ForwardIt last,std::vector & indices,Tensor inverse_indices_vec,Tensor counts)', '    _unique_dim_cpu_template(const Tensor & self,const int64_t dim,const bool consecutive,const bool return_inverse,const bool return_counts)', '    unique_consecutive_cpu_template(const Tensor & self,const bool return_inverse,const bool return_counts)', '    unique_cpu_template(const Tensor & self,const bool sorted,const bool return_inverse,const bool return_counts)', '    unique_consecutive_cpu(const Tensor & self,const bool return_inverse,const bool return_counts,c10::optional dim)', '    unique_dim_consecutive_cpu(const Tensor & self,const int64_t dim,const bool return_inverse,const bool return_counts)', '    unique_dim_cpu(const Tensor & self,const int64_t dim,const bool sorted,const bool return_inverse,const bool return_counts)'];
rmsprop.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/optim; 79;  4; 12;11;  56; 0;0;0;0;0;0.07;0;[];['    get_unique_name(const VarHandle & v)', '    get_unique_name(const Var *v)'];
python.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 262;  84; 16;18;  150; 2;0;0;0;0;0.56;0;['    UniqueNameManager'];['    get_unique_name(const VarHandle & v)', '    get_unique_name(const Var *v)'];
input-archive.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch/serialize; 113;  39; 22;10;  47; 0;0;0;0;0;0.83;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUUnique', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Unique', '    DoRunWithType'];
types.h;C++;pytorch-master/pytorch-master/torch/csrc/api/include/torch; 57;  23; 9;5;  22; 0;0;0;0;0;1.05;0;['    UniqueOp'];['    cuda_order_buffer_', '    DoRunWithType', '    RunOnDevice', '    second_order_buffer_', '    UniqueOp(Args,...)', '    ~UniqueOp'];
distributed.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/data/samplers; 166;  13; 23;7;  132; 0;58;57;35;68;0.10;12;[];['    deleteNothing(void *)'];
enum.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src; 36;  0; 1;1;  34; 0;0;34;0;68;0.00;0;['    UniqueVoidPtr'];['    cast_context(DeleterFnPtr expected_deleter)', '    compare_exchange_deleter(DeleterFnPtr expected_deleter,DeleterFnPtr new_deleter)', '    deleteNothing(void *)', '    get_deleter', '    operator bool', '    operator!=(const UniqueVoidPtr & sp,std::nullptr_t)', '    operator!=(std::nullptr_t,const UniqueVoidPtr & sp)', '    operator==(const UniqueVoidPtr & sp,std::nullptr_t)', '    operator==(std::nullptr_t,const UniqueVoidPtr & sp)', '    clear', '    get', '    get_context', '    operator->', '    release_context', '    UniqueVoidPtr', '    UniqueVoidPtr(void *data)', '    UniqueVoidPtr(void *data,void *ctx,DeleterFnPtr ctx_deleter)', '    unique_ptr'];
_functions.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 122;  7; 27;1;  90; 0;70;38;48;32;0.08;2;[];['    insertPermutes(std::shared_ptr & graph,std::map & paramsDict)', '    callOpUnboxed(const c10::OperatorHandle & op,Args,...)', '    CreateQuantizedBias(std::vector data,std::shared_ptr & graph,std::vector shapes,double scale,int64_t zero_point)', '    CreateQuantizedWeights(std::string data,std::shared_ptr & graph,std::vector shapes,double scale,int64_t zero_point)', '    getScaleFromInput(Node *input_node)', '    insertPermutesHelper(std::shared_ptr & graph,std::map & paramsDict,const std::string & pattern)', '    UnpackQuantizedWeights(std::shared_ptr & graph,std::map & paramsDict)', '    unpackQuantizedWeightsHelper(std::shared_ptr & graph,std::map & paramsDict,const std::string & pattern,const std::string & unpack_fn)'];
functional.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules/container; 31;  2; 8;4;  19; 0;4;11;4;8;0.11;6;[];['    insertPermutes(std::shared_ptr & graph,std::map & paramsDict)', '    UnpackQuantizedWeights(std::shared_ptr & graph,std::map & paramsDict)'];
embedding.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 140;  4; 14;8;  118; 0;74;15;55;13;0.03;10;[];['    movePythonUdf', '    toMessageImpl', '    UnpickledPythonCall(const SerializedPyObj & serializedPyObj)'];
loss.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 360;  24; 92;1;  250; 0;83;117;53;75;0.10;72;['    UnpickledPythonCall'];['    movePythonUdf', '    toMessageImpl', '    UnpickledPythonCall(const SerializedPyObj & serializedPyObj)'];
pooling.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/modules; 375;  10; 62;2;  305; 0;162;70;58;79;0.03;43;[];['    forkId', '    rrefId', '    UnpickledPythonRemoteCall(const SerializedPyObj & serializedPyObj,const at::IValue & rrefId,const at::IValue & forkId)'];
adaptive.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 11;  2; 3;1;  7; 0;0;7;0;3;0.29;1;['    final'];['    forkId', '    rrefId', '    UnpickledPythonRemoteCall(const SerializedPyObj & serializedPyObj,const at::IValue & retRRefId,const at::IValue & retForkId)'];
embedding.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 11;  2; 2;1;  8; 0;0;8;0;4;0.25;2;[];['    convertList(const IValue & v)', '    restoreAccurateTypeTagsIfPossible(const IValue & root)', '    tupleToIntList(const IValue & v)', '    is_valid_python_id_char(char c)', '    append(std::vector & a,T)', '    append(std::vector & a,bool)', '    restoreAccurateTypeTags(const IValue & root,const TypePtr & type_tag)', '    restoreContainerTypeTags(IValue & ivalue,TypePtr type)', '    parse_ivalue', '    readBytes(size_t length)', '    readFloat', '    readGlobal(const std::string & module_name,const std::string & class_name)', '    readInstruction', '    readList(IValue list_ivalue)', '    readSlowWithBuffer(char *dest,size_t sz)', '    readString', '    rebuildTensor(bool quantized)', '    run', '    setInput(size_t memo_id)'];
padding.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/nn/options; 24;  3; 8;1;  15; 0;0;7;0;12;0.20;1;[];[];
adagrad.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 140;  6; 19;7;  111; 0;70;52;84;56;0.05;11;[];[];
rmsprop.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src/optim; 168;  9; 21;6;  135; 0;89;57;115;65;0.07;10;[];['    pytorch_sdwconv_ukernel_up4x9__psimd(size_t channels,size_t output_width,const float **input,const float *weights,float *output,size_t input_stride,size_t output_increment,const struct pytorch_qnnp_fp32_clamping_params [1] clamping_params)'];
serialize.cpp;C++;pytorch-master/pytorch-master/torch/csrc/api/src; 18;  1; 6;4;  8; 0;2;4;2;3;0.13;2;[];['    pytorch_q8gavgpool_ukernel_up8x7__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
anomaly_mode.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 27;  0; 7;3;  17; 0;0;0;0;0;0.00;0;[];[];
cpp_hook.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 17;  1; 4;4;  9; 0;1;7;1;9;0.11;0;[];['    pytorch_q8gavgpool_ukernel_up8x7__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
engine.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 1180;  353; 117;35;  688; 0;422;213;337;229;0.51;54;[];[];
function_hook.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 8;  1; 3;1;  4; 0;2;4;0;4;0.25;0;[];[];
basic_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 30;  2; 7;7;  15; 0;6;7;5;8;0.13;2;[];['    pytorch_q8dwconv_ukernel_up8x9__neon(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 127;  0; 20;16;  88; 4;49;45;63;44;0.00;7;[];['    pytorch_q8avgpool_ukernel_up8x9__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
utils.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd/functions; 58;  3; 5;6;  47; 0;28;13;24;12;0.06;2;[];[];
input_buffer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 144;  35; 11;8;  91; 0;62;26;42;19;0.38;8;[];['    pytorch_q8dwconv_ukernel_up8x9__sse2(size_t channels,size_t output_width,const uint8_t **input,const void *weights,uint8_t *output,size_t input_stride,size_t output_increment,const union pytorch_qnnp_conv_quantization_params [1] quantization_params)'];
profiler.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 264;  24; 29;30;  174; 19;0;0;0;0;0.14;0;[];['    pytorch_q8avgpool_ukernel_up8x9__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
python_autograd.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 17;  0; 6;6;  5; 0;0;5;0;5;0.00;0;[];[];
python_engine.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 36;  1; 8;4;  24; 0;2;22;0;12;0.04;0;[];[];
python_hook.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 24;  1; 5;4;  15; 0;0;13;0;13;0.07;0;[];['    pytorch_q8gavgpool_ukernel_up8xm__neon(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
python_variable.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 623;  91; 61;32;  477; 0;317;234;580;275;0.19;41;[];[];
record_function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 253;  8; 37;6;  206; 0;104;62;102;49;0.04;28;[];['    pytorch_q8avgpool_ukernel_up8xm__neon(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
saved_variable.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 60;  12; 13;5;  31; 0;0;0;0;0;0.39;0;[];[];
wrap_outputs.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd/utils; 197;  4; 29;12;  153; 0;100;42;100;43;0.03;37;[];['    pytorch_q8avgpool_ukernel_up8xm__sse2(size_t n,size_t ks,size_t kc,const uint8_t **input,const uint8_t *zero,uint8_t *output,size_t input_increment,size_t output_increment,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
VariableTypeUtils.h;C++;pytorch-master/pytorch-master/torch/csrc/autograd; 172;  10; 22;30;  113; 1;55;36;51;46;0.09;14;[];[];
device_set.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 10;  0; 4;2;  4; 0;2;3;1;4;0.00;0;[];['    pytorch_q8gavgpool_ukernel_up8xm__sse2(size_t m,size_t n,const uint8_t *input,size_t input_stride,const uint8_t *zero,uint8_t *output,const union pytorch_qnnp_avgpool_quantization_params [1] quantization_params)'];
Module.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 14;  0; 3;3;  8; 0;0;8;0;9;0.00;0;[];[];
python_comm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 68;  1; 4;10;  53; 0;9;26;1;41;0.02;1;[];['    getGraphExecutorOptimize', '    setGraphExecutorOptimize(bool o)'];
restore_macros.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 17;  0; 4;13;  0; 0;0;0;0;0;0.00;0;[];[];
cudnn.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda/shared; 95;  2; 0;17;  0; 91;0;0;0;0;0.00;0;[];['    area_pixel_compute_scale(int64_t input_size,int64_t output_size,bool align_corners,const c10::optional scale)', '    area_pixel_compute_source_index(scalar_t scale,int64_t dst_index,bool align_corners,bool cubic)', '    compute_scales_value(const c10::optional scale,int64_t input_size,int64_t output_size)', '    cubic_convolution1(scalar_t x,scalar_t A)', '    cubic_convolution2(scalar_t x,scalar_t A)', '    cubic_interp1d(scalar_t x0,scalar_t x1,scalar_t x2,scalar_t x3,scalar_t)', '    get_cubic_upsample_coefficients(scalar_t [4] coeffs,scalar_t)', '    nearest_neighbor_compute_source_index(const float scale,int64_t dst_index,int64_t input_size)', '    upsample_1d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_width,int64_t output_width)', '    upsample_2d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width)', '    upsample_3d_shape_check(const Tensor & input,const Tensor & grad_output,int64_t nbatch,int64_t nchannels,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width)', '    upsample_get_value_bounded(scalar_t *data,int64_t width,int64_t height,int64_t x,int64_t y)', '    upsample_increment_value_bounded(scalar_t *data,int64_t width,int64_t height,int64_t x,int64_t y,scalar_t value)', '    operator=', '    upsample_nearest1d_backward_kernel', '    upsample_nearest1d_backward_kernel', '    operator=', '    upsample_nearest1d_kernel', '    upsample_nearest1d_kernel', '    operator=', '    upsample_nearest2d_backward_kernel', '    upsample_nearest2d_backward_kernel', '    operator=', '    upsample_nearest2d_kernel', '    upsample_nearest2d_kernel', '    operator=', '    upsample_nearest3d_backward_kernel', '    upsample_nearest3d_backward_kernel', '    operator=', '    upsample_nearest3d_kernel', '    upsample_nearest3d_kernel', '    has_value', '    value'];
Stream.cpp;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 180;  38; 25;8;  147; 0;117;96;140;70;0.26;10;['    GetUpsampleNearestGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleNearest', '    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleNearestGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleNearest', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleNearestGradient', '    vector', '    GetGradientDefs'];
undef_macros.h;C++;pytorch-master/pytorch-master/torch/csrc/cuda; 52;  0; 11;41;  0; 0;0;0;0;0;0.00;0;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    UpsampleNearestGradientOp(const OperatorDef & def,Workspace *ws)', '    UpsampleNearestOp(const OperatorDef & operator_def,Workspace *ws)'];
CudaIPCTypes.h;C++;pytorch-master/pytorch-master/torch/csrc; 146;  0; 0;11;  0; 143;0;0;0;0;0.00;0;['    GetUpsampleBilinearGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleBilinear', '    CAFFE_ANONYMOUS_VARIABLE_CPUUpsampleBilinearGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleBilinear', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_UpsampleBilinearGradient', '    vector', '    GetGradientDefs', '    RunOnDevice', '    RunOnDevice'];
Device.h;C++;pytorch-master/pytorch-master/torch/csrc; 22;  1; 7;4;  10; 0;1;7;1;6;0.10;1;['    final', '    final'];['    GetSingleArgument', '    RunOnDevice', '    UpsampleBilinearGradientOp(Args,...)', '    UpsampleBilinearOp(Args,...)'];
context.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/context; 218;  20; 29;4;  170; 0;88;56;54;48;0.12;17;[];['    upsample_bicubic2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bicubic2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)'];
recvrpc_backward.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/functions; 63;  10; 10;4;  42; 0;13;25;11;14;0.24;2;[];['    upsample_bilinear2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_height,int64_t input_width,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)', '    upsample_bilinear2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_h,c10::optional scales_w)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd; 230;  7; 81;9;  139; 0;55;86;4;159;0.05;2;[];['    nearest_idx(int64_t output_index,int64_t input_size,int64_t output_size,c10::optional scales)', '    cpu_upsample_nearest(Tensor & output_,const Tensor & input_,const scale_type & scales)', '    cpu_upsample_nearest_backward(Tensor & grad_input_,const Tensor & grad_output_,const scale_type & scales)', '    cpu_upsample_nearest_channels_last(Tensor & output_,const Tensor & input_,const scale_type & scales)', '    data_index_init(T offset)', '    data_index_init(T offset,T & x,const T & X,Args,...)', '    data_index_step', '    data_index_step(T & x,const T & X,Args,...)', '    upsample_nearest1d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_w)', '    upsample_nearest1d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_w)', '    upsample_nearest2d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_kernel_impl(Tensor & grad_input,const Tensor & grad_output,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_kernel_impl(Tensor & output,const Tensor & input,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)'];
cleanup_autograd_context_req.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 30;  6; 6;5;  16; 0;0;13;0;9;0.38;0;[];['    upsample_linear1d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_width,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_width,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales)', '    upsample_linear1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales)'];
propagate_gradients_req.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 42;  8; 9;5;  23; 0;1;20;0;13;0.35;0;[];['    upsample_nearest1d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales)', '    upsample_nearest1d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales)', '    upsample_nearest1d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales)', '    upsample_nearest1d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales)'];
rpc_with_autograd.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/autograd/rpc_messages; 90;  28; 22;4;  39; 0;0;36;0;22;0.72;0;[];['    upsample_nearest2d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest2d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_h,c10::optional scales_w)'];
comm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 82;  17; 16;5;  47; 0;20;27;15;16;0.36;3;[];['    upsample_nearest3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_cpu_template(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_cpu(const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_nearest3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/c10d; 756;  32; 80;33;  484; 134;257;321;17;331;0.07;8;[];['    upsample_trilinear3d_backward_out_cpu_template(Tensor & grad_input,const Tensor & grad_output_,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_cpu_template(Tensor & output,const Tensor & input_,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_frame(scalar_t *odata,scalar_t *idata,int64_t input_depth,int64_t input_height,int64_t input_width,int64_t output_depth,int64_t output_height,int64_t output_width,int64_t nbatch,int64_t channels,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_cpu(const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_backward_out_cpu(Tensor & grad_input,const Tensor & grad_output,IntArrayRef output_size,IntArrayRef input_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_cpu(const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)', '    upsample_trilinear3d_out_cpu(Tensor & output,const Tensor & input,IntArrayRef output_size,bool align_corners,c10::optional scales_d,c10::optional scales_h,c10::optional scales_w)'];
message.cpp;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 130;  19; 22;1;  102; 0;48;39;18;38;0.19;15;[];['    forward(const Tensor & input)', '    pretty_print(std::ostream & stream)', '    reset', '    UpsampleImpl(const UpsampleOptions & options_)'];
process_group_agent.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 291;  96; 38;7;  153; 0;12;131;4;95;0.63;9;[];[];
python_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 27;  4; 8;3;  15; 0;0;12;0;9;0.27;0;[];[];
python_remote_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 43;  3; 9;6;  28; 0;3;19;3;13;0.11;3;[];[];
python_rpc_handler.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 99;  47; 19;5;  31; 0;5;28;0;25;1.52;0;[];['    GatherDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
request_callback_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 31;  3; 6;4;  21; 0;0;18;0;7;0.14;0;['    final', '    final'];['    ElementWiseSumAVX2(const T *input0,const T *input1,T *output,int len,float a_scale,int32_t a_zero_point,float b_scale,int32_t b_zero_point,float c_scale,int32_t c_zero_point)', '    arguments_parsed_', '    dequantize_output_', '    DoRunWithType', '    Fp32Op_', '    GatherDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    GetQuantizationParameters_', '    measure_quantization_error_', '    RunOnDevice', '    static_assert(std::is_integral,)', '    SumDNNLowPOp(const OperatorDef & operator_def,Workspace *ws)', '    ~GatherDNNLowPOp'];
rpc_command_base.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 27;  6; 5;3;  16; 0;2;12;1;9;0.38;2;['    final', '    final', '    final', '    IDEEPWeightedSumOp'];['    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyCPUToIDEEP', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_CopyIDEEPToCPU', '    CopyCPUToIDEEPOp(const OperatorDef & operator_def,Workspace *ws)', '    CopyIDEEPToCPUOp(const OperatorDef & operator_def,Workspace *ws)', '    IDEEPCopyOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    ~CopyCPUToIDEEPOp', '    ~CopyIDEEPToCPUOp', '    ~IDEEPCopyOp', '    IDEEPWeightedSumOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
rref_impl.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 364;  197; 44;8;  126; 0;33;92;11;76;1.56;14;['    GetEnsureDenseGradient', '    GetAliasGradient', '    GetSumGradient', '    GetWeightedSumGradient'];['    CAFFE_ANONYMOUS_VARIABLE_CPUAccumulateHistogram', '    CAFFE_ANONYMOUS_VARIABLE_CPUAlias', '    CAFFE_ANONYMOUS_VARIABLE_CPUEnsureDense', '    CAFFE_ANONYMOUS_VARIABLE_CPUFlattenToVec', '    CAFFE_ANONYMOUS_VARIABLE_CPUGatherRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPUHasElements', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsGather', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToSegmentIds', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToShape', '    CAFFE_ANONYMOUS_VARIABLE_CPULengthsToWeights', '    CAFFE_ANONYMOUS_VARIABLE_CPUPrint', '    CAFFE_ANONYMOUS_VARIABLE_CPUResizeLike', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatter', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatterAssign', '    CAFFE_ANONYMOUS_VARIABLE_CPUScatterWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentIdsToLengths', '    CAFFE_ANONYMOUS_VARIABLE_CPUSegmentIdsToRanges', '    CAFFE_ANONYMOUS_VARIABLE_CPUSumInt', '    CAFFE_ANONYMOUS_VARIABLE_CPUWallClockTime', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSum', '    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSumGradient', '    CAFFE_ANONYMOUS_VARIABLE_CPUFail', '    CAFFE_ANONYMOUS_VARIABLE_CPUIsNaN', '    CAFFE_ANONYMOUS_VARIABLE_CPULogFatal', '    CAFFE_ANONYMOUS_VARIABLE_CPUNanCheck', '    CAFFE_ANONYMOUS_VARIABLE_CPURange', '    CAFFE_ANONYMOUS_VARIABLE_CPUSize', '    CAFFE_ANONYMOUS_VARIABLE_CPUThrowChildThreadException', '    CAFFE_ANONYMOUS_VARIABLE_CPUThrowException', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_AccumulateHistogram', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Alias', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_EnsureDense', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_FlattenToVec', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GatherRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_HasElements', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsGather', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToSegmentIds', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToShape', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LengthsToWeights', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Print', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ResizeLike', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Scatter', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScatterAssign', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ScatterWeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentIdsToLengths', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SegmentIdsToRanges', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SumInt', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WallClockTime', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSum', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSumGradient', '    CostInferenceForWeightedSum(const OperatorDef &,const vector & in)', '    WeightedSumShapeInference(const OperatorDef &,const vector & in)', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Fail', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_IsNaN', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_LogFatal', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_NanCheck', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Range', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Size', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThrowChildThreadException', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ThrowException', '    inputs', '    vector', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    GetGradientDefs', '    RunOnDevice', '    DoRunOnDevice(const T & start,const T & step,Tensor *output)', '    RunOnDevice', '    RunOnDevice'];
script_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 66;  16; 12;7;  34; 0;1;29;1;24;0.47;0;['    AccumulateHistogramOp', '    final', '    FailOp', '    final', '    final', '    final', '    final', '    final', '    FlattenToVecOp', '    GatherRangesOp', '    HasElementsOp', '    LengthsGatherOp', '    LengthsToRangesOp', '    LengthsToSegmentIdsOp', '    LengthsToShapeOp', '    LengthsToWeightsOp', '    LogFatalOp', '    RangeOp', '    ResizeLikeOp', '    ScatterAssignOp', '    ScatterOp', '    ScatterWeightedSumOp', '    SegmentIdsToLengthsOp', '    SegmentIdsToRangesOp', '    SizeOp', '    SumOp', '    ThrowChildThreadExceptionOp', '    ThrowExceptionOp', '    WeightedSumGradientOp', '    WeightedSumOp'];['    CostInferenceForSum(const OperatorDef & def,const std::vector & in)', '    check_indexarray_range(const IndexType *indices,int64_t n,IndexType indexing_axis_dim)', '    AccumulateHistogramOp(Args,...)', '    RunOnDevice', '    NanCheckOp(Args,...)', '    RunOnDevice', '    GetGradientDefs', '    duration_cast', '    FailOp(Args,...)', '    RunOnDevice', '    AliasOp(Args,...)', '    DoRunWithType', '    DoRunWithType', '    EnsureDenseOp(Args,...)', '    InputIsTensorType', '    IsNanOp(const OperatorDef & operator_def,Workspace *ws)', '    occurrences_mod_n_', '    PrintOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    RunOnDevice', '    WallClockTimeOp(Args,...)', '    ~AliasOp', '    ~EnsureDenseOp', '    FlattenToVecOp(Args,...)', '    RunOnDevice', '    ~FlattenToVecOp', '    accumulate(Index *ranges,size_t start,size_t end)', '    DoRunWithType', '    GatherRangesOp(Args,...)', '    RunOnDevice', '    ~GatherRangesOp', '    HasElementsOp(Args,...)', '    RunOnDevice', '    ~HasElementsOp', '    now', '    DoRunWithType', '    LengthsGatherOp(Args,...)', '    RunOnDevice', '    ~LengthsGatherOp', '    LengthsToRangesOp(Args,...)', '    RunOnDevice', '    ~LengthsToRangesOp', '    LengthsToSegmentIdsOp(Args,...)', '    RunOnDevice', '    ~LengthsToSegmentIdsOp', '    LengthsToShapeOp(Args,...)', '    RunOnDevice', '    ~LengthsToShapeOp', '    DoRunWithType', '    LengthsToWeightsOp(Args,...)', '    RunOnDevice', '    LogFatalOp(Args,...)', '    RunOnDevice', '    Add', '    Axpby', '    Axpy', '    AxpyFixedSize', '    Dot', '    Scale', '    ScaleFixedSize', '    Set', '    dim', '    numel', '    size', '    size_from_dim', '    sizes', '    DoRunOnDevice(const T & start,const T & step,Tensor *output)', '    DoRunWithType', '    local_', '    RangeOp(Args,...)', '    readScalarInput(const int index)', '    RunOnDevice', '    ~RangeOp', '    ResizeLikeOp(Args,...)', '    RunOnDevice', '    ~ResizeLikeOp', '    DoRun', '    DoScatterAssign(T *data,const Index *idxs,const T *slicesData,int64_t N,int64_t K,int64_t block_size)', '    GetRunner(const TensorProto_DataType dataType,const TensorProto_DataType slicesType,const TensorProto_DataType indicesType)', '    RunOnDevice', '    ScatterAssignOp(Args,...)', '    ~ScatterAssignOp', '    DoRunWithType', '    RunOnDevice', '    ScatterOp(Args,...)', '    ~ScatterOp', '    DoRunWithType', '    DoRunWithValue', '    RunOnDevice', '    ScatterWeightedSumOp(Args,...)', '    ~ScatterWeightedSumOp', '    DoRunWithType', '    RunOnDevice', '    SegmentIdsToLengthsOp(Args,...)', '    ~SegmentIdsToLengthsOp', '    DoRunWithType', '    RunOnDevice', '    SegmentIdsToRangesOp(Args,...)', '    ~SegmentIdsToRangesOp', '    RunOnDevice', '    SizeOp(Args,...)', '    ~SizeOp', '    DoRunWithType', '    RunOnDevice', '    SumOp(Args,...)', '    ~SumOp', '    RunOnDevice', '    ThrowChildThreadExceptionOp(Args,...)', '    RunOnDevice', '    ThrowExceptionOp(Args,...)', '    DoRunWithType', '    RunOnDevice', '    WeightedSumGradientOp(Args,...)', '    DoRunWithType', '    InputSize', '    RunOnDevice', '    WeightedSumOp(Args,...)', '    ~WeightedSumOp'];
script_resp.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 26;  4; 6;4;  15; 0;0;12;0;9;0.27;0;[];['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(UtilityOpGPUTest,testReshapeWithScalar)'];
testing.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc/testing; 15;  4; 4;2;  9; 0;0;9;0;5;0.44;0;[];['    AddConstInput(const vector & shape,const float value,const string & name,Workspace *ws)', '    TEST(UtilityOpTest,testReshapeWithScalar)'];
types.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 63;  3; 17;3;  43; 0;8;33;5;35;0.07;2;[];['    CheckReduceDims(const int ndim,const int *X_dims,const int *Y_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const std::int32_t *A_dims,const int B_ndim,const std::int32_t *B_dims,std::int32_t *A_broadcast_dims,std::int32_t *B_broadcast_dims,std::int32_t *C_broadcast_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const std::int64_t *A_dims,const int B_ndim,const std::int64_t *B_dims,std::int64_t *A_broadcast_dims,std::int64_t *B_broadcast_dims,std::int64_t *C_broadcast_dims)', '    ComputeTransposeAxesForReduceOp(const int num_dims,const int num_reduce_axes,const int *reduce_axes,int *transpose_axes)', '    ComputeTransposeAxesForReduceOp(const int ndim,const int *dims,int *axes)', '    ComputeTransposedStrides(const int ndim,const std::int32_t *dims,const int *axes,std::int32_t *strides)', '    ComputeTransposedStrides(const int ndim,const std::int64_t *dims,const int *axes,std::int64_t *strides)', '    GetIndexFromDims(const int n,const std::int32_t *dims,const std::int32_t *index)', '    GetIndexFromDims(const int n,const std::int64_t *dims,const std::int64_t *index)', '    IncreaseIndexInDims(const int ndim,const std::int32_t *dims,std::int32_t *index)', '    IncreaseIndexInDims(const int ndim,const std::int64_t *dims,std::int64_t *index)', '    IsBatchTranspose2D(const int ndim,const int *axes)', '    IsBothEndsBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt,bool *broadcast_1st)', '    IsBothEndsReduce(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt)', '    IsColwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsColwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    IsIdentityPermutation(const int n,const int *perm)', '    IsRowwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsRowwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)'];
unpickled_python_remote_call.h;C++;pytorch-master/pytorch-master/torch/csrc/distributed/rpc; 36;  10; 6;5;  18; 0;0;15;0;9;0.56;0;[];[];
Dtype.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 133;  42; 13;9;  107; 0;80;64;39;21;0.39;8;[];[];
empty.c;C;pytorch-master/pytorch-master/torch/csrc; 1;  0; 1;0;  0; 0;0;0;0;0;0.00;0;[];['    check_input_variables(const char *name,const variable_list & inputs,int args,int required_args)', '    wrap_outputs(const variable_list & inputs,tensor_list,const function_constructor & ctr)'];
Generator.h;C++;pytorch-master/pytorch-master/torch/csrc; 29;  5; 9;6;  9; 0;0;0;0;0;0.56;0;[];['    pool_output_sizes(IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding_l,IntArrayRef padding_r,IntArrayRef dilation,bool ceil_mode)'];
Storage.h;C++;pytorch-master/pytorch-master/torch/csrc/generic; 17;  0; 6;6;  5; 1;0;5;0;6;0.00;0;[];['    classOrTypename(PyObject *obj)', '    getBackCompatBroadcastWarn', '    getBackCompatKeepdimWarn', '    maybeThrowBackCompatKeepdimWarn(char *func)', '    setBackCompatBroadcastWarn(bool warn)', '    setBackCompatKeepdimWarn(bool warn)', '    THPUtils_addPyMethodDefs(std::vector & vector,PyMethodDef *methods)', '    THPUtils_checkIntTuple(PyObject *arg)', '    THPUtils_dispatchStateless(PyObject *tensor,const char *name,PyObject *args,PyObject *kwargs)', '    THPUtils_getCallable(PyObject *arg,PyObject **result)', '    THPUtils_invalidArguments(PyObject *given_args,PyObject *given_kwargs,const char *function_name,size_t num_options,...)', '    THPUtils_setError(const char *format,...)', '    THPUtils_tryUnpackLongs(PyObject *arg,THLongStoragePtr & result)', '    THPUtils_tryUnpackLongVarArgs(PyObject *args,int ignore_first,THLongStoragePtr & result)', '    THPUtils_unpackIntTuple(PyObject *arg)', '    THPUtils_unpackLongs(PyObject *arg)', '    THPUtils_unpackSize(PyObject *arg)', '    free', '    free', '    free'];
utils.h;C++;pytorch-master/pytorch-master/torch/csrc/generic; 34;  0; 6;18;  9; 3;1;8;0;7;0.00;0;[];['    cloneSparseTensors(const std::vector & tensors)', '    metaDataReadFunc', '    sectionReadFunc', '    deserializeRequest(const Message & request)', '    deserializeResponse(const Message & response,MessageType & wrappedMsgType)', '    deserializeRespToIValue(const Message & message)', '    deserializeResptoIValueInternal(RpcCommandBase & rpc,MessageType messageType)', '    wireSerialize(const std::vector & payload,const std::vector & tensors)', '    worthRecopying'];
method.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 70;  17; 15;4;  37; 0;0;0;0;0;0.46;0;[];['    addRecvRpcBackward(const AutogradMetadata & autogradMetadata,std::vector & tensors,rpc::worker_id_t fromWorkerId)', '    addSendRpcBackward(const ContextPtr & autogradContext,const AutogradMetadata & autogradMetadata,std::vector & tensors)', '    getMessageWithAutograd(const rpc::worker_id_t dstId,torch::distributed::rpc::Message,MessageType msgType,bool forceGradRecording)', '    sendMessageWithAutograd(RpcAgent & agent,const WorkerInfo & dst,torch::distributed::rpc::Message,bool forceGradRecording,const std::shared_ptr & rf)'];
object.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/api; 39;  2; 7;5;  27; 0;9;15;8;8;0.07;4;[];['    helper(const Tensor & self)', '    global_helper_call_AA_op_1(const Tensor & self)', '    global_helper_call_AA_op_2(const Tensor & self)', '    global_helper_call_AA_op_3(const Tensor & self)', '    lambda', '    lambda'];
codegen.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 30;  5; 5;10;  13; 0;0;13;0;7;0.38;0;[];['    accept(int listenSocket,const std::chrono::milliseconds & timeout)', '    connect(const std::string & address,PortType port,bool wait,const std::chrono::milliseconds & timeout)', '    getSocketPort(int fd)', '    handleConnectException(struct ::addrinfo **nextAddr,int error_code,bool *anyRefused,bool *anyReset,bool wait,std::chrono::time_point start,std::shared_ptr addresses,std::chrono::milliseconds timeout)', '    handleConnectSystemError(struct ::addrinfo **nextAddr,std::system_error & e,bool *anyRefused,bool *anyReset,bool wait,std::chrono::time_point start,std::shared_ptr addresses,std::chrono::milliseconds timeout)', '    listen(PortType port)', '    setSocketNoDelay(int socket)', '    sockaddrToString(struct ::sockaddr *addr)'];
fused_kernel.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cpu; 45;  5; 8;8;  28; 0;3;22;2;10;0.18;2;[];['    _crash_if_asan(int arg)'];
fused_kernel.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser/cuda; 59;  8; 11;10;  34; 0;2;29;1;16;0.24;1;[];['    DivUp(const T a,const T b)', '    IntegerLog2(T n,int p)', '    IntegerNextHighestPowerOf2(T v)', '    RoundUp(const T a,const T b)', '    CheckReduceDims(const int ndim,const int *X_dims,const int *Y_dims)', '    ComputeBroadcastBinaryOpDims(const int A_ndim,const TIndex *A_dims,const int B_ndim,const TIndex *B_dims,TIndex *A_broadcast_dims,TIndex *B_broadcast_dims,TIndex *C_broadcast_dims)', '    ComputeTransposeAxesForReduceOp(const int num_dims,const int num_reduce_axes,const int *reduce_axes,int *transpose_axes)', '    ComputeTransposeAxesForReduceOp(const int ndim,const int *dims,int *axes)', '    ComputeTransposedStrides(int ndim,const TIndex *dims,const int *axes,TIndex *strides)', '    Cube(const T x)', '    GetIndexFromDims(const int n,const TIndex *dims,const TIndex *index)', '    IncreaseIndexInDims(int ndim,const TIndex *dims,TIndex *index)', '    Inv(const T x)', '    IsAGeZeroAndALtB(const int a,const int b)', '    IsBatchTranspose2D(const int ndim,const int *axes)', '    IsBothEndsBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt,bool *broadcast_1st)', '    IsBothEndsReduce(const int ndim,const int *A_dims,const int *B_dims,int *pre,int *mid,int *nxt)', '    IsColwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsColwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    IsIdentityPermutation(const int n,const int *perm)', '    IsRowwiseBroadcastBinaryOp(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols,bool *broadcast_1st)', '    IsRowwiseReduce(const int ndim,const int *A_dims,const int *B_dims,int *rows,int *cols)', '    Negate(const T x)', '    Not(const T x)', '    Sign(const T x)', '    Square(const T x)'];
fallback.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 52;  7; 8;8;  34; 0;20;28;6;9;0.21;2;[];['    contiguousIfZeroInStrides(const Tensor & t)', '    setMIOpenStreamToCurrent', '    getCurrentHIPStream'];
interface.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 53;  16; 13;8;  18; 0;1;18;0;12;0.89;0;[];[];
partition_desc.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/codegen/fuser; 62;  15; 8;7;  38; 0;9;19;5;48;0.39;9;[];['    contiguousIfZeroInStrides(const Tensor & t)', '    contiguous'];
builtin_functions.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 11;  2; 3;3;  5; 0;0;5;0;3;0.40;0;[];['    getBackCompatBroadcastWarn', '    getBackCompatKeepdimWarn', '    maybeThrowBackCompatKeepdimWarn(char *func)', '    setBackCompatBroadcastWarn(bool warn)', '    setBackCompatKeepdimWarn(bool warn)', '    THPUtils_addPyMethodDefs(std::vector & vector,PyMethodDef *methods)', '    THPUtils_checkIntTuple(PyObject *arg)', '    THPUtils_dispatchStateless(PyObject *tensor,const char *name,PyObject *args,PyObject *kwargs)', '    THPUtils_getCallable(PyObject *arg,PyObject **result)', '    THPUtils_invalidArguments(PyObject *given_args,PyObject *given_kwargs,const char *function_name,size_t num_options,...)', '    THPUtils_setError(const char *format,...)', '    THPUtils_tryUnpackLongs(PyObject *arg,THLongStoragePtr & result)', '    THPUtils_tryUnpackLongVarArgs(PyObject *args,int ignore_first,THLongStoragePtr & result)', '    THPUtils_unpackIntTuple(PyObject *arg)', '    THPUtils_unpackLongs(PyObject *arg)', '    THPUtils_unpackSize(PyObject *arg)', '    mod(_real a,_real b)', '    mod(_real a,_real b)'];
concrete_module_type.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 315;  20; 39;2;  258; 0;133;103;81;97;0.08;23;[];[];
edit_distance.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 54;  5; 9;4;  38; 0;25;20;18;15;0.13;1;[];['    check_path_valid(std::string path,bool remove)', '    replace(std::string line,const std::string & substring,const std::string & target)', '    split(const string & str,const string & delim)'];
exit_transforms.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 591;  198; 59;6;  330; 0;201;111;157;108;0.60;27;[];['    check_input_variables(const char *name,const variable_list & inputs,int args,int required_args)', '    compute_requires_grad(Args,...)', '    set_history(at::Tensor & variable,const std::shared_ptr & grad_fn)', '    set_history(std::vector,const std::shared_ptr & grad_fn)', '    set_history(std::vector & variables,const std::shared_ptr & grad_fn)', '    wrap_outputs(const variable_list & inputs,tensor_list,const function_constructor & ctr)', '    defined', '    set_gradient_edge', '    operator()(const at::Tensor & tensor)', '    short_circuit', '    undefined_input'];
inline_loop_condition.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 65;  18; 9;6;  35; 0;19;15;15;13;0.51;4;[];['    addRecvRpcBackward(const AutogradMetadata & autogradMetadata,std::vector & tensors,rpc::worker_id_t fromWorkerId)', '    addSendRpcBackward(const ContextPtr & autogradContext,const AutogradMetadata & autogradMetadata,std::vector & tensors)', '    getMessageWithAutograd(const rpc::worker_id_t dstId,rpc::Message,rpc::MessageType msgType,bool forceGradRecording)', '    sendMessageWithAutograd(rpc::RpcAgent & agent,const rpc::WorkerInfo & dst,rpc::Message,bool forceGradRecording,const std::shared_ptr & rf)'];
lexer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 106;  4; 10;13;  82; 0;55;49;334;27;0.05;5;[];['    cloneSparseTensors(const std::vector & tensors)', '    deserializeRequest(const Message & request)', '    deserializeResponse(const Message & response,MessageType & wrappedMsgType)', '    deserializeRespToIValue(const Message & message)', '    deserializeResptoIValueInternal(RpcCommandBase & rpc,MessageType messageType)', '    wireSerialize(const std::vector & payload,const std::vector & tensors)'];
parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 746;  62; 45;6;  644; 0;441;194;271;200;0.10;44;[];[];
schema_matching.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 615;  77; 49;5;  491; 0;308;226;171;97;0.16;18;[];[];
script_type_parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 363;  28; 31;4;  307; 0;195;118;97;187;0.09;11;[];[];
string_to_type.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 25;  4; 1;1;  21; 0;1;18;2;5;0.19;1;[];[];
sugared_value.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 656;  105; 84;8;  461; 0;119;288;86;173;0.23;62;[];['    global_helper_call_AA_op_1(const at::Tensor & self)', '    global_helper_call_AA_op_2(const at::Tensor & self)', '    global_helper_call_AA_op_3(const at::Tensor & self)'];
tree_views.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/frontend; 1060;  111; 63;8;  884; 0;321;386;286;332;0.13;173;[];['    pool_output_sizes(IntArrayRef input_size,IntArrayRef kernel_size,IntArrayRef stride,IntArrayRef padding_l,IntArrayRef padding_r,IntArrayRef dilation,bool ceil_mode)'];
attributes.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 161;  5; 20;6;  133; 0;0;0;0;0;0.04;0;['    ResourceGuard'];['    assertCPU(std::function fn,const at::ArrayRef tensors)', '    assertDense(std::function fn,const at::ArrayRef tensors)', '    assertLayoutMatch(std::function fn,const c10::Layout & expected,const at::ArrayRef tensors,size_t index)', '    assertLayoutMatch(std::function fn,const at::ArrayRef tensors)', '    assertNonEmpty(std::function fn,const at::ArrayRef tensors)', '    assertRootRank(std::function fn,int rank,int size)', '    assertRootTensor(std::function fn,int rank,int size)', '    assertSameDevice(std::function fn,const at::ArrayRef tensors)', '    assertSameSizeAndType(const std::vector & tensors)', '    assertSameSizes(const at::IntArrayRef & sizes,const std::vector & tensors)', '    assertSameType(const at::DeprecatedTypeProperties & type,const std::vector & tensors)', '    assertSingleElement(std::function fn,const at::ArrayRef tensors)', '    assertSingleElementInput(std::function fn,const at::ArrayRef tensors)', '    assertSingleElementOutput(std::function fn,const at::ArrayRef tensors)', '    assertSizesMatch(std::function fn,const at::IntArrayRef & sizes,const at::ArrayRef tensors,size_t index)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors,const at::DeprecatedTypeProperties & type,const at::IntArrayRef & sizes)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors,const at::TensorOptions & options,const at::IntArrayRef & sizes)', '    assertTypeAndSizesMatch(std::function fn,const at::ArrayRef tensors)', '    assertTypeMatch(std::function fn,const at::DeprecatedTypeProperties & type,const at::ArrayRef tensors,size_t index)', '    assertTypeMatch(std::function fn,const at::TensorOptions & options,const at::ArrayRef tensors,size_t index)', '    fmap(T & inputs,const F & fn)', '    toString(at::IntArrayRef l)', '    toString(const c10::Layout & layout)', '    flattenDenseTensors(at::TensorList tensors)', '    getDataPointer(const at::Tensor & tensor)', '    getDataPointers(const std::vector & tensors)', '    getDevices(const std::vector & tensors)', '    newLikeFlat(std::vector,size_t deviceIdx)', '    newLikeFlat(std::vector & tensors)', '    sizes', '    sizes', '    accept(int listenSocket,const std::chrono::milliseconds & timeout)', '    connect(const std::string & address,PortType port,bool wait,const std::chrono::milliseconds & timeout)', '    listen(PortType port)', '    recvBytes(int socket,T *buffer,size_t length)', '    recvString(int socket)', '    recvValue(int socket)', '    recvVector(int socket)', '    sendBytes(int socket,const T *buffer,size_t length,bool moreData)', '    sendString(int socket,const std::string & str,bool moreData)', '    sendValue(int socket,const T & value,bool moreData)', '    sendVector(int socket,const std::vector & vec,bool moreData)', '    sockaddrToString(struct sockaddr *addr)', '    data_ptr', '    release', '    ResourceGuard(std::function destructor)', '    ~ResourceGuard', '    system_category', '    system_error', '    data', '    device', '    end', '    equals', '    insert', '    options', '    size', '    sizes', '    storage', '    toString', '    type_equal'];
ir.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 1968;  171; 215;20;  1577; 0;989;528;968;408;0.11;143;['    VAddMicrokernelTester'];['    aScale(float aScale)', '    aScale', '    aScale_', '    aZeroPoint(uint8_t aZeroPoint)', '    aZeroPoint', '    aZeroPoint_', '    bScale(float bScale)', '    bScale', '    bScale_', '    bZeroPoint(uint8_t bZeroPoint)', '    bZeroPoint', '    bZeroPoint_', '    inplaceA(bool inplaceA)', '    inplaceA', '    inplaceA_', '    inplaceB(bool inplaceB)', '    inplaceB', '    inplaceB_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    qmax(uint8_t qmax)', '    qmax', '    qmax_', '    qmin(uint8_t qmin)', '    qmin', '    qmin_', '    test(pytorch_q8vadd_ukernel_function q8vadd)', '    yScale(float yScale)', '    yScale', '    yScale_', '    yZeroPoint(uint8_t yZeroPoint)', '    yZeroPoint', '    yZeroPoint_'];
irparser.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 29;  8; 7;5;  11; 0;0;11;0;6;0.73;0;[];['    elems', '    elems', '    createObject(Stack & stack,at::ClassTypePtr type)', '    dictConstruct(Stack & stack,at::DictTypePtr type,size_t num_inputs)', '    format(Stack & stack,size_t num_inputs)', '    isinstance(Stack & stack,at::ArrayRef types)', '    listConstruct(Stack & stack,at::ListTypePtr type,size_t num_inputs)', '    listUnpack(Stack & stack,size_t num_outputs)', '    namedTupleConstruct(Stack & stack,at::TupleTypePtr type,size_t num_inputs)', '    tupleConstruct(Stack & stack,size_t num_inputs)', '    tupleSlice(Stack & stack,size_t begin,size_t end)', '    tupleUnpack(Stack & stack)'];
scope.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 114;  12; 17;2;  87; 0;39;35;32;26;0.14;16;[];['    createObject(Stack & stack,at::ClassTypePtr type)', '    dictConstruct(Stack & stack,at::DictTypePtr type,size_t num_inputs)', '    format(Stack & stack,size_t num_inputs)', '    isinstance(Stack & stack,at::ArrayRef types)', '    listConstruct(Stack & stack,at::ListTypePtr type,size_t num_inputs)', '    listUnpack(Stack & stack,size_t num_outputs)', '    namedTupleConstruct(Stack & stack,at::TupleTypePtr type,size_t num_inputs)', '    tupleConstruct(Stack & stack,size_t num_inputs)', '    tupleSlice(Stack & stack,size_t begin,size_t end)', '    tupleUnpack(Stack & stack)'];
type_hashing.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/ir; 28;  2; 4;6;  18; 0;9;12;4;6;0.11;2;[];['    _register_hook(const Tensor & self,std::function hook)', '    base(const Tensor & self)', '    clear_hooks(const Variable & self)', '    DifferentiableViewMeta(at::TensorImpl *self_impl,Variable base,CreationMeta creation_meta)', '    get_autograd_meta(const Variable & self)', '    grad_fn(const Tensor & self)', '    handle_view_on_rebase(DifferentiableViewMeta *diff_view_meta,bool indirect)', '    is_view(const Tensor & self)', '    name(const Tensor & self)', '    pyobj(const Variable & self)', '    remove_hook(const Tensor & self,unsigned pos)', '    set_name(const Variable & self,const std::string & name)', '    set_pyobj(const Variable & self,PyObject *pyobj)', '    tensor_data(const Tensor & self)', '    add_hook(const Variable & self,std::shared_ptr hook)', '    materialize_autograd_meta(const Variable & self)', '    rebase_history(const Variable & self,Edge gradient_edge)', '    bump_version(const Variable & self)', '    create_cpp_hook(const Variable & self)', '    grad_accumulator(const Variable & self)', '    grad_fn_unsafe(const Variable & self)', '    gradient_edge(const Variable & self)', '    set_grad_accumulator(const Variable & self,std::weak_ptr grad_accumulator)', '    set_gradient_edge(const Variable & self,Edge edge)', '    set_version_counter(const Variable & self,const c10::VariableVersion & version_counter)', '    try_get_grad_accumulator(const Variable & self)', '    version_counter(const Variable & self)', '    variable_data(const Tensor & self)', '    ~DifferentiableViewMeta', '    make', '    undefined_tensor'];
function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 75;  8; 11;7;  53; 0;23;22;18;16;0.15;7;[];[];
interpreter.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 180;  20; 6;12;  139; 9;117;27;104;23;0.14;3;[];['    $', '    from_blob(void *data,at::IntArrayRef sizes,at::IntArrayRef strides,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,const Deleter & deleter,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,const at::TensorOptions & options)', '    from_blob(void *data,at::IntArrayRef sizes,at::IntArrayRef strides,const Deleter & deleter,const at::TensorOptions & options)', '    tensor(detail::TensorDataContainer tensor_data_container,const at::TensorOptions & options)'];
observer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 10;  1; 3;1;  6; 0;1;4;1;3;0.17;1;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUVariableLengthSequencePadding', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_VariableLengthSequencePadding'];
type_parser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/mobile; 141;  5; 12;4;  124; 0;60;35;56;31;0.04;9;['    VariableLengthSequencePaddingOp'];['    VariableLengthSequencePadding(int N,int B,int M,T *X,const int32_t *seqLengths,const T padValue,Context *)', '    RunOnDevice', '    VariableLengthSequencePaddingOp(Args,...)'];
batch_mm.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 485;  102; 36;12;  350; 0;240;184;167;138;0.29;21;[];[];
canonicalize_ops.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 92;  5; 6;2;  82; 0;39;34;19;83;0.06;4;[];['    variable_fallback_kernel(const OperatorHandle & op,Stack *stack)'];
common_subexpression_elimination.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 97;  12; 13;6;  69; 0;45;19;37;13;0.17;2;[];['    GetVariableHooks', '    SetVariableHooks(VariableHooksInterface *h)'];
constant_propagation.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 363;  36; 32;14;  290; 0;143;98;98;187;0.12;20;[];['    GetVariableHooks', '    SetVariableHooks(VariableHooksInterface *h)', '    _register_hook(const Tensor &,std::function hook)', '    base(const Tensor &)', '    grad_fn(const Tensor &)', '    is_view(const Tensor &)', '    name(const Tensor &)', '    remove_hook(const Tensor &,unsigned pos)', '    tensor_data(const Tensor &)', '    variable_data(const Tensor &)', '    ~VariableHooksInterface', '    VariableHooksRegisterer(VariableHooksInterface *hooks)'];
create_functional_graphs.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 394;  54; 53;8;  282; 0;171;101;124;115;0.19;21;[];['    _version(const Tensor & self)', '    backward(const Tensor & self,const Tensor & gradient,bool keep_graph,bool create_graph)', '    data(const Tensor & self)', '    is_leaf(const Tensor & self)', '    output_nr(const Tensor & self)', '    requires_grad_(Tensor & self,bool _requires_grad)', '    retain_grad(const Tensor & self)', '    set_data(const Tensor & self,const Tensor & new_data)'];
dead_code_elimination.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 440;  83; 43;6;  314; 0;161;102;139;70;0.26;19;[];['    registerer', '    $'];
erase_number_types.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 66;  4; 4;3;  57; 0;39;13;34;10;0.07;2;[];[];
freeze_module.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 405;  75; 29;6;  302; 0;186;91;149;83;0.25;10;[];['    detach(const Tensor & self)', '    detach_(Tensor & self)', '    resize_(Tensor & self,IntArrayRef size,c10::optional optional_memory_format)', '    resize_as_(Tensor & self,const Tensor & the_template,c10::optional optional_memory_format)', '    _version(const Tensor & self)', '    allCPUTypes', '    allCUDATypes', '    allTypesForBackends(at::ArrayRef backends)', '    backward(const Tensor & self,const Tensor & gradient,bool keep_graph,bool create_graph)', '    checked_cast_variable(const Tensor & t,const char *name,int pos)', '    checked_cast_variable(Tensor & t,const char *name,int pos)', '    copy_(Tensor & self,const Tensor & src,bool non_blocking)', '    data(const Tensor & self)', '    is_leaf(const Tensor & self)', '    output_nr(const Tensor & self)', '    requires_grad_(Tensor & self,bool _requires_grad)', '    retain_grad(const Tensor & self)', '    set_data(const Tensor & self,const Tensor & new_data)', '    unpack(const Tensor & t,const char *name,int pos)', '    unpack(Tensor & t,const char *name,int pos)', '    unpack(at::TensorList tl,const char *name,int pos)', '    unpack_opt(const Tensor & t,const char *name,int pos)'];
graph_fuser.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 1241;  256; 103;14;  875; 0;623;420;432;327;0.29;46;[];['    as_view(const Tensor & base,Tensor tensor,bool is_differentiable,CreationMeta creation_meta)', '    as_view(const Tensor & base,std::vector tensors,bool is_differentiable,CreationMeta creation_meta)', '    check_no_requires_grad(const Tensor & tensor,const char *name)', '    check_no_requires_grad(TensorList tensors,const char *name)', '    flatten_tensor_args(Args,...)', '    increment_version(Tensor & t)', '    make_saved_variable_list(TensorList tensors)', '    check_inplace(const Tensor & tensor)', '    rebase_history(Variable & var,std::shared_ptr grad_fn)', '    throw_error_out_requires_grad(const char *name)', '    rebase_history(std::vector,std::shared_ptr grad_fn)', '    bump_version', '    get_autograd_meta', '    rebase_history', '    apply', '    Flatten(variable_list & out)', '    operator()(const at::Tensor & x)', '    operator()(at::ArrayRef xs)', '    undefined_input'];
guard_elimination.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 407;  72; 18;8;  312; 0;230;50;195;44;0.23;11;[];[];
inline_fork_wait.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 36;  2; 7;1;  28; 0;14;14;17;10;0.07;2;[];[];
inliner.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 58;  2; 5;4;  49; 0;31;17;33;13;0.04;2;[];[];
insert_guards.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 63;  4; 8;3;  50; 0;25;20;21;20;0.08;5;[];[];
liveness.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 141;  18; 15;5;  105; 0;47;45;37;81;0.17;6;[];['    func(c10::variant v)', '    TEST(VariantTest,Basic)', '    operator()(enumtype::Enum1 & v)', '    operator()(enumtype::Enum2 & v)', '    operator()(enumtype::Enum3 & v)', '    Enum1', '    Enum2', '    Enum3'];
lower_grad_of.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 38;  6; 3;2;  29; 0;19;17;13;10;0.21;1;[];[];
lower_tuples.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 240;  35; 22;5;  183; 0;114;66;91;52;0.19;9;[];['    Vec256(T val)', '    size', '    Vec256'];
cast_all_constant_to_floating.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 70;  15; 6;1;  52; 0;35;15;29;13;0.29;2;[];[];
fixup_onnx_conditionals.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 41;  4; 5;1;  33; 0;17;15;13;13;0.12;2;[];[];
helper.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 34;  2; 4;1;  29; 0;11;14;9;10;0.07;2;[];[];
prepare_division_for_onnx.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 40;  3; 6;2;  31; 0;19;20;9;9;0.10;2;[];[];
scalar_type_analysis.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/onnx; 246;  31; 25;2;  191; 0;129;77;54;43;0.16;13;[];[];
pass_manager.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 25;  2; 6;1;  18; 0;4;10;4;8;0.11;4;[];[];
prepack_folding.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 66;  3; 4;5;  56; 0;31;25;21;19;0.05;1;[];['    main'];
quantization_patterns.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 226;  16; 112;6;  94; 0;81;72;1;31;0.17;1;[];['    get_mkl_version', '    get_mkldnn_version', '    get_openmp_version', '    show_config', '    used_cpu_capability'];
remove_inplace_ops.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 12;  3; 3;3;  5; 0;0;5;0;3;0.60;0;[];[];
shape_analysis.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 15;  2; 5;3;  7; 0;0;0;0;0;0.29;0;[];['    DecodeMultipleClipsFromVideo(const char *video_buffer,const std::string & video_filename,const int encoded_size,const Params & params,const int start_frm,const int clip_per_video,const std::vector & clip_start_positions,const bool use_local_file,int & height,int & width,std::vector & buffer_rgb)', '    FreeDecodedData(std::vector,std::vector)', '    decodeFile(const string & file,const Params & params,const int start_frm,Callback & callback)', '    decodeLoop(const string & videoName,VideoIOContext & ioctx,const Params & params,const int start_frm,Callback & callback)', '    decodeMemory(const string & videoName,const char *buffer,const int size,const Params & params,const int start_frm,Callback & callback)', '    ffmpegErrorStr(int result)', '    getAudioSample(AVPacket & packet,AVCodecContext *audioCodecContext_,AVFrame *audioStreamFrame_,SwrContext *convertCtx_,Callback & callback,const Params & params)', '    ResizeAndKeepAspectRatio(const int origWidth,const int origHeight,const int short_edge,const int long_edge,int & outWidth,int & outHeight)', '    VideoDecoder'];
subgraph_rewrite.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes; 108;  51; 13;6;  40; 0;8;36;0;17;1.27;0;['    Callback', '    CallbackImpl', '    DecodedFrame', '    Params', '    VideoDecoder', '    VideoIOContext'];['    DecodeMultipleClipsFromVideo(const char *video_buffer,const std::string & video_filename,const int encoded_size,const Params & params,const int start_frm,const int clip_per_video,const std::vector & clip_start_positions,const bool use_local_file,int & height,int & width,std::vector & buffer_rgb)', '    FreeDecodedData(std::vector,std::vector)', '    readFile(void *opaque,unsigned char *buf,int buf_size)', '    readMemory(void *opaque,unsigned char *buf,int buf_size)', '    seekFile(void *opaque,int64_t offset,int whence)', '    seekMemory(void *opaque,int64_t offset,int whence)', '    audioDecoded(std::unique_ptr)', '    frameDecoded(std::unique_ptr img)', '    videoDecodingEnded(double)', '    videoDecodingStarted(const VideoMeta &)', '    ~Callback', '    audioDecoded(std::unique_ptr audio_sample)', '    CallbackImpl', '    clear', '    frameDecoded(std::unique_ptr frame)', '    videoDecodingStarted(const VideoMeta &)', '    DecodedAudio(int dataSize,int outSampleSize,std::unique_ptr audio_data)', '    operator()(unsigned char *p)', '    fps(float v)', '    keyFrames(bool keyFrames)', '    maxOutputDimension(int size)', '    maxOutputFrames(int count)', '    outputHeight(int height)', '    outputWidth(int width)', '    Params', '    pixelFormat(AVPixelFormat pixelFormat)', '    setSampleTimestamps(const std::vector & timestamps)', '    streamIndex(int index)', '    operator<(const SampleInterval & itvl)', '    SampleInterval', '    SampleInterval(double ts,double f)', '    decodeFile(const string & file,const Params & params,const int start_frm,Callback & callback)', '    decodeLoop(const string & videoName,VideoIOContext & ioctx,const Params & params,const int start_frm,Callback & callback)', '    decodeMemory(const string & videoName,const char *buffer,const int size,const Params & params,const int start_frm,Callback & callback)', '    ffmpegErrorStr(int result)', '    getAudioSample(AVPacket & packet,AVCodecContext *audioCodecContext_,AVFrame *audioStreamFrame_,SwrContext *convertCtx_,Callback & callback,const Params & params)', '    ResizeAndKeepAspectRatio(const int origWidth,const int origHeight,const int short_edge,const int long_edge,int & outWidth,int & outHeight)', '    VideoDecoder', '    get_avio', '    read(unsigned char *buf,int buf_size)', '    seek(int64_t offset,int whence)', '    VideoIOContext(const std::string & fname)', '    VideoIOContext(const char *buffer,int size)', '    ~VideoIOContext', '    VideoMeta'];
check_alias_annotation.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 22;  7; 3;6;  8; 0;0;8;0;3;0.88;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUVideoInput', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_VideoInput'];
subgraph_utils.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/passes/utils; 37;  19; 8;3;  10; 0;0;10;0;7;1.90;0;['    final'];['    ThrowEnforceNotMet(,,,CAFFE_ENFORCE_THAT_IMPL_r_)', '    thread_pool_(std::make_shared num_decode_threads_)', '    memset(label_data,,)', '    CheckParamsAndPrint', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *clip_rgb_data,float *clip_of_data,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_clip)', '    GetClipsAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen)', '    GetImageAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data)', '    GetLabelsFromProto(const TensorProto & label_proto,int *label_data)', '    Prefetch', '    prefetched_clip_of_on_device_', '    prefetched_clip_rgb_on_device_', '    prefetched_label_on_device_', '    prefetched_start_frame_on_device_', '    prefetched_video_id_on_device_', '    VideoInputOp(const OperatorDef & operator_def,Workspace *ws)', '    ~VideoInputOp', '    cvtColor', '    clear', '    emplace_back', '    push_back', '    size', '    byte_data', '    data', '    data_type', '    dims', '    dims_size', '    int32_data', '    int64_data', '    size', '    string_data', '    string_data_size', '    CheckParamsAndPrint', '    CopyPrefetched', '    DecodeAndTransform(const std::string & value,float *clip_rgb_data,float *clip_of_data,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen,std::bernoulli_distribution *mirror_this_clip)', '    GetClipsAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data,int64_t *video_id_data,int *start_frame_data,std::mt19937 *randgen)', '    GetImageAndLabelsFromDBValue(const std::string & value,int & height,int & width,std::vector & buffer_rgb,int *label_data)', '    Prefetch'];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 11;  1; 4;2;  5; 0;0;5;0;3;0.20;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAVideoInput'];
python_arg_flatten.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 165;  9; 16;4;  142; 0;97;66;67;52;0.06;9;[];['    ClipTransformOpticalFlow(const unsigned char *buffer_rgb,const int crop_size,const int length_of,const int channels_of,const int sampling_rate_of,const int height,const int width,const cv::Rect & rect,const int channels_rgb,const bool mirror_me,const int flow_alg_type,const int flow_data_type,const int frame_gap_of,const bool do_flow_aggregation,const std::vector & mean_of,const std::vector & inv_std_of,float *transformed_clip)', '    ClipTransformRGB(const unsigned char *buffer_rgb,const int crop_size,const int length_rgb,const int channels_rgb,const int sampling_rate_rgb,const int height,const int width,const int h_off,const int w_off,const bool mirror_me,const std::vector & mean_rgb,const std::vector & inv_std_rgb,float *transformed_clip)'];
python_interpreter.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 88;  6; 13;18;  54; 0;42;18;10;11;0.11;2;[];['    ClipTransformOpticalFlow(const unsigned char *buffer_rgb,const int crop_size,const int length_of,const int channels_of,const int sampling_rate_of,const int height,const int width,const cv::Rect & rect,const int channels_rgb,const bool mirror_me,const int flow_alg_type,const int flow_data_type,const int frame_gap_of,const bool do_flow_aggregation,const std::vector & mean_of,const std::vector & inv_std_of,float *transformed_clip)', '    ClipTransformRGB(const unsigned char *buffer_rgb,const int crop_size,const int length_rgb,const int channels_rgb,const int sampling_rate_rgb,const int height,const int width,const int h_off,const int w_off,const bool mirror_me,const std::vector & mean_rgb,const std::vector & inv_std_rgb,float *transformed_clip)'];
python_sugared_value.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 784;  77; 80;14;  620; 7;406;241;256;148;0.12;24;[];[];
python_tree_views.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 349;  7; 22;5;  319; 0;127;143;29;304;0.02;7;[];[];
update_graph_executor_opt.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/python; 14;  2; 2;1;  11; 0;3;7;2;5;0.18;2;[];[];
argument_spec.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 480;  77; 39;10;  369; 0;0;0;0;0;0.21;0;[];[];
exception_message.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 31;  2; 5;3;  23; 0;6;14;4;8;0.09;2;[];[];
instruction.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 89;  5; 9;17;  60; 0;33;22;207;16;0.08;7;[];[];
jit_exception.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 9;  2; 3;1;  5; 0;0;5;0;3;0.40;1;[];['    vabs(scalar_t *out,const scalar_t *in,int64_t size)', '    vacos(scalar_t *out,const scalar_t *in,int64_t size)', '    vasin(scalar_t *out,const scalar_t *in,int64_t size)', '    vatan(scalar_t *out,const scalar_t *in,int64_t size)', '    vceil(scalar_t *out,const scalar_t *in,int64_t size)', '    vcos(scalar_t *out,const scalar_t *in,int64_t size)', '    verf(scalar_t *out,const scalar_t *in,int64_t size)', '    verfc(scalar_t *out,const scalar_t *in,int64_t size)', '    verfinv(scalar_t *out,const scalar_t *in,int64_t size)', '    vexp(scalar_t *out,const scalar_t *in,int64_t size)', '    vexpm1(scalar_t *out,const scalar_t *in,int64_t size)', '    vfloor(scalar_t *out,const scalar_t *in,int64_t size)', '    vlgamma(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog10(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog1p(scalar_t *out,const scalar_t *in,int64_t size)', '    vlog2(scalar_t *out,const scalar_t *in,int64_t size)', '    vneg(scalar_t *out,const scalar_t *in,int64_t size)', '    vreciprocal(scalar_t *out,const scalar_t *in,int64_t size)', '    vround(scalar_t *out,const scalar_t *in,int64_t size)', '    vrsqrt(scalar_t *out,scalar_t *in,int64_t size)', '    vrsqrt(scalar_t *out,const scalar_t *in,int64_t size)', '    vsin(scalar_t *out,const scalar_t *in,int64_t size)', '    vsqrt(scalar_t *out,const scalar_t *in,int64_t size)', '    vtan(scalar_t *out,const scalar_t *in,int64_t size)', '    vtanh(scalar_t *out,const scalar_t *in,int64_t size)', '    vtrunc(scalar_t *out,const scalar_t *in,int64_t size)'];
operator.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 388;  55; 40;9;  301; 5;179;214;84;133;0.18;13;[];['    col2vol(const T *data_col,const int64_t channels,const int64_t depth,const int64_t height,const int64_t width,const int64_t out_depth,const int64_t out_height,const int64_t out_width,const int64_t kT,const int64_t kernel_height,const int64_t kernel_width,const int64_t pT,const int64_t pH,const int64_t pW,const int64_t dT,const int64_t dH,const int64_t dW,const int64_t dilationT,const int64_t dilationH,const int64_t dilationW,T *data_vol)', '    vol2col(const T *data_vol,const int64_t channels,const int64_t depth,const int64_t height,const int64_t width,const int64_t depth_col,const int64_t height_col,const int64_t width_col,const int64_t kT,const int64_t kernel_height,const int64_t kernel_width,const int64_t pT,const int64_t pH,const int64_t pW,const int64_t dT,const int64_t dH,const int64_t dW,const int64_t dilationT,const int64_t dilationH,const int64_t dilationW,T *data_col)'];
print_handler.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 18;  2; 6;5;  7; 0;1;6;1;6;0.29;0;[];[];
profiling_record.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 47;  5; 8;9;  27; 0;3;20;3;16;0.19;2;[];[];
register_prim_ops_c10.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 36;  0; 2;3;  31; 0;8;7;9;51;0.00;0;[];['    TEST(TestWeakPointer,WeakPointerGetsInvalidated)', '    TEST(TestWeakPointer,WeakPointerLock)', '    TEST(TestWeakPointer,WeakUpdatesRefcountsTest)'];
symbolic_script.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 1499;  23; 1355;3;  121; 0;77;57;40;41;0.19;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightScale', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightScale'];
variable_tensor_list.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/runtime; 19;  4; 3;2;  12; 0;0;0;0;0;0.33;0;['    final'];['    weight_scale_update(int N,const T *w,const T scale,int64_t iter,int64_t stepsize,int64_t update_upper_bound,T *nw,Context *context)', '    GetSingleArgument', '    RunOnDevice', '    WeightScaleOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
import.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 296;  36; 29;24;  213; 2;93;122;54;70;0.17;13;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedMultiSampling', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedMultiSampling', '    RunOnDevice'];
import_export_helpers.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 54;  2; 9;6;  39; 0;22;17;12;10;0.05;2;['    WeightedMultiSamplingOp'];['    GetSingleArgument', '    RunOnDevice', '    WeightedMultiSamplingOp(Args,...)'];
import_source.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 511;  75; 44;7;  393; 0;212;162;143;104;0.19;27;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUWeightedSample', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_WeightedSample', '    RunOnDevice'];
pickler.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 684;  81; 79;14;  491; 24;340;92;284;84;0.16;32;['    final'];['    RunOnDevice', '    WeightedSampleOp(Args,...)'];
source_range_serialization.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 150;  10; 23;4;  115; 0;62;66;30;42;0.09;10;[];['    _weight_norm(const Tensor & v_in,const Tensor & g_in,int64_t dim)', '    _weight_norm_differentiable_backward(const Tensor & grad_w,const Tensor & saved_v,const Tensor & saved_g,const Tensor & saved_norms,int64_t dim)', '    norm_except_dim(const Tensor & v,int64_t pow,int64_t dim)'];
unpickler.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/serialization; 149;  42; 20;6;  82; 1;0;0;0;0;0.51;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUWhile', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_While'];
codegen.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 52;  3; 6;2;  44; 0;21;21;16;10;0.07;3;['    final'];['    GetSingleArgument', '    HasSingleArgumentOfType', '    InputIsTensorType', '    RunOnDevice', '    WhileOp(const OperatorDef & operator_def,Workspace *ws)'];
cuda_half_support.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 30;  4; 6;3;  20; 0;4;11;3;8;0.20;4;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAWhile'];
exceptions.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 65;  9; 10;4;  49; 0;0;41;0;26;0.18;11;[];[];
function.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 142;  4; 16;3;  123; 0;55;74;38;42;0.03;8;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUSparseWngrad', '    CAFFE_ANONYMOUS_VARIABLE_CPUWngrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_SparseWngrad', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_Wngrad'];
ir.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 153;  6; 18;2;  130; 0;63;50;66;23;0.05;12;['    final', '    final'];['    wngrad_update(int N,const float *w,const float *g,const float *h,float *nw,float *nh,float epsilon,const float *lr,Context *)', '    wngrad_update_output_effective_lr(int N,const float *paramIn,const float *gradIn,const float *seqBIn,float *paramOut,float *seqBOut,float *effectiveLROut,float epsilon,const float *lr,Context *)', '    wngrad_update_output_effective_lr_and_update(int N,const float *paramIn,const float *gradIn,const float *seqBIn,float *paramOut,float *seqBOut,float *effectiveLROut,float *updateOut,float epsilon,const float *lr,Context *)', '    DoRunWithType', '    GetSingleArgument', '    RunOnDevice', '    RunOnDevice', '    SparseWngradOp(const OperatorDef & operator_def,Workspace *ws)', '    WngradOp(const OperatorDef & operator_def,Workspace *ws)', '    ResizeLike'];
ir_printer.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 476;  10; 60;7;  403; 0;253;115;210;97;0.02;55;[];[];
ir_visitor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 196;  4; 35;7;  153; 0;72;54;65;58;0.03;42;['    BlockingCounter', '    WorkersPool'];['    ThreadFunc(void *arg)', '    ChangeState(State new_state)', '    Do256NOPs', '    kGEMMLOWPCacheLineSize', '    StartWork(Task *task)', '    ThreadFunc', '    WaitForVariableChange(std::atomic *var,T initial_value,std::condition_variable *cond,std::mutex *mutex)', '    Worker(BlockingCounter *counter_to_decrement_when_ready)', '    ~Worker', '    alloc(Args,...)', '    release(T *p)', '    count_', '    DecrementCount', '    fetch_sub', '    load', '    Reset(std::size_t initial_count)', '    Wait', '    operator()(T *p)', '    make', '    atomic_thread_fence', '    Run', '    Task', '    ~Task', '    CreateWorkers(std::size_t workers_count)', '    Execute(const std::vector)', '    operator=', '    WorkersPool', '    WorkersPool'];
llvm_codegen.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 1492;  1; 0;269;  0; 1490;0;0;0;0;0.00;0;['    C10FlagParser_caffe2_print_blob_sizes_at_exit'];['    C10FlagParser_caffe2_print_blob_sizes_at_exit(const std::string & content)', '    AddBlobMapping(const Workspace *parent,const std::unordered_map & forwarded_blobs,bool skip_defined_blobs)', '    Blobs', '    bookkeeper', '    CreateBlob(const string & name)', '    CreateLocalBlob(const string & name)', '    CreateNet(const NetDef & net_def,bool overwrite)', '    CreateNet(const std::shared_ptr & net_def,bool overwrite)', '    DeleteNet(const string & name)', '    GetBlob(const string & name)', '    GetBlob(const string & name)', '    GetNet(const string & name)', '    GetThreadPool', '    LocalBlobs', '    PrintBlobSizes', '    RemoveBlob(const string & name)', '    RenameBlob(const string & old_name,const string & new_name)', '    RunNet(const string & name)', '    RunNetOnce(const NetDef & net_def)', '    RunOperatorOnce(const OperatorDef & op_def)', '    RunPlan(const PlanDef & plan,ShouldContinue shouldContinue)'];
loopnest.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 884;  78; 130;13;  670; 0;405;270;218;285;0.12;53;[];[];
reduction.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 94;  3; 13;5;  76; 0;21;40;20;21;0.04;11;['    final'];['    CAFFE_ANONYMOUS_VARIABLE_CPUGetAllBlobNames', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_GetAllBlobNames', '    GetAllBlobNamesOp(const OperatorDef & operator_def,Workspace *ws)', '    RunOnDevice'];
types.cpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/tensorexpr; 163;  9; 25;24;  109; 0;68;24;144;26;0.08;10;['    WorkspaceTestFoo'];['    forEachCheck(std::initializer_list workspaces)', '    TEST(WorkspaceTest,BlobAccess)', '    TEST(WorkspaceTest,RunEmptyPlan)', '    TEST(WorkspaceTest,Sharing)', '    TEST(WorkspaceTest,BlobMapping)', '    TEST(WorkspaceTest,ForEach)', '    _typeMetaDataInstance'];
catch_utils.hpp;C++;pytorch-master/pytorch-master/torch/csrc/jit/testing; 10;  2; 2;6;  0; 0;0;0;0;0;0.00;0;[];['    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    r', '    wrap(bool value)', '    wrap(std::tuple tensors)', '    wrap(int64_t value)', '    wrap(double value)', '    wrap(std::complex value)', '    wrap(void *value)', '    wrap(THPDtype *dtype)', '    wrap(at::ScalarType scalarType)', '    wrap(THPLayout *layout)', '    wrap(at::Tensor tensor)', '    wrap(at::Scalar scalar)', '    wrap(at::QScheme qscheme)', '    wrap(PyTypeObject *type,std::tuple tensors)', '    wrap(PyTypeObject *type,std::tuple tensors)', '    wrap(at::TensorList tl)', '    wrap(at::IntArrayRef list)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)', '    wrap(std::tuple tensors)'];
hooks_for_testing.h;C++;pytorch-master/pytorch-master/torch/csrc/jit/testing; 21;  2; 5;5;  11; 0;2;9;2;11;0.18;0;[];['    TEST(TestWrapdim,TestWrapdim)', '    TestEmptyTensor(DeprecatedTypeProperties & T)', '    TestExpressionSpecification(DeprecatedTypeProperties & T)', '    TestScalarVs1Dim1Size(DeprecatedTypeProperties & T)', '    TestSimpleCase(DeprecatedTypeProperties & T)'];
MemoryFormat.h;C++;pytorch-master/pytorch-master/torch/csrc; 25;  0; 9;4;  12; 0;2;9;1;8;0.00;1;[];[];
init.h;C++;pytorch-master/pytorch-master/torch/csrc/multiprocessing; 11;  2; 4;2;  5; 0;0;5;0;3;0.40;0;[];[];
PtrWrapper.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 102;  37; 9;3;  90; 0;65;56;19;16;0.41;6;[];['    dim_list_to_bitset(IntArrayRef dims,int64_t ndims)'];
python_headers.h;C++;pytorch-master/pytorch-master/torch/csrc; 13;  1; 3;9;  0; 0;0;0;0;0;0.00;0;[];[];
serialization.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 193;  28; 27;20;  118; 5;64;40;82;31;0.24;11;[];['    pytorch_qnnp_x8zip_x2__neon(size_t n,const void *input,void *output)'];
Storage.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 43;  2; 9;26;  6; 0;2;2;2;2;0.33;1;[];[];
python_tensor.cpp;C++;pytorch-master/pytorch-master/torch/csrc/tensor; 392;  43; 63;21;  270; 0;171;107;156;94;0.16;27;[];['    pytorch_qnnp_x8zip_x2__sse2(size_t n,const void *input,void *output)'];
ThreadLocalState.cpp;C++;pytorch-master/pytorch-master/torch/csrc; 44;  1; 8;14;  14; 9;4;9;2;5;0.07;3;[];[];
Types.h;C++;pytorch-master/pytorch-master/torch/csrc; 21;  1; 8;8;  5; 0;0;5;0;4;0.20;0;[];['    pytorch_qnnp_x8zip_x3__neon(size_t n,const void *input,void *output)'];
byte_order.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 248;  6; 28;18;  178; 27;82;60;83;62;0.03;23;[];[];
cuda_lazy_init.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 33;  14; 6;2;  11; 0;2;7;2;5;1.27;1;[];['    pytorch_qnnp_x8zip_x3__sse2(size_t n,const void *input,void *output)'];
init.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 52;  7; 8;4;  35; 0;28;6;4;9;0.20;1;[];[];
memory.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 38;  3; 9;2;  25; 0;0;0;0;0;0.12;0;[];['    pytorch_qnnp_x8zip_x4__neon(size_t n,const void *input,void *output)'];
pybind.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 100;  8; 15;12;  69; 0;0;0;0;0;0.12;0;[];[];
python_dispatch.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 162;  16; 17;6;  125; 0;46;47;15;167;0.13;4;[];['    pytorch_qnnp_x8zip_x4__sse2(size_t n,const void *input,void *output)'];
python_strings.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 85;  9; 9;23;  33; 11;15;10;13;9;0.27;7;[];['    TEST(X8LUT__SCALAR,n_eq_1)', '    TEST(X8LUT__SCALAR,small_n)', '    TEST(X8LUT__SCALAR,large_n)', '    TEST(X8LUT__SCALAR,n_eq_1_inplace)', '    TEST(X8LUT__SCALAR,small_n_inplace)', '    TEST(X8LUT__SCALAR,large_n_inplace)'];
structseq.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 98;  13; 12;7;  40; 27;26;14;19;12;0.33;1;[];['    pytorch_x8lut_ukernel__scalar(size_t n,const uint8_t *x,const uint8_t [256] t,uint8_t *y)'];
tensor_dtypes.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 88;  6; 7;9;  68; 0;53;8;47;6;0.09;2;[];[];
tensor_layouts.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 44;  2; 6;8;  29; 0;22;7;19;7;0.07;1;[];['    pytorch_qnnp_x8zip_x2__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x2__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x3__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x3__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x4__neon(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_x4__sse2(size_t n,const void *input,void *output)', '    pytorch_qnnp_x8zip_xm__neon(size_t n,size_t m,const void *input,void *output)', '    pytorch_qnnp_x8zip_xm__sse2(size_t n,size_t m,const void *input,void *output)'];
tensor_memoryformats.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 39;  2; 9;16;  14; 0;7;10;14;12;0.14;1;[];['    TEST(XlaTensorTest,TestNoStorage)', '    XLAFree(void *ptr)', '    XLAMalloc(ptrdiff_t size)', '    allocate(size_t size)', '    raw_deleter'];
tensor_numpy.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 349;  1; 1;15;  17; 326;5;7;5;7;0.06;5;[];['    pytorch_qnnp_x8zip_xm__neon(size_t n,size_t m,const void *input,void *output)'];
tensor_types.cpp;C++;pytorch-master/pytorch-master/torch/csrc/utils; 99;  4; 16;9;  71; 0;27;29;24;60;0.06;4;[];[];
throughput_benchmark.h;C++;pytorch-master/pytorch-master/torch/csrc/utils; 185;  62; 31;8;  87; 0;12;78;1;53;0.71;12;[];['    pytorch_qnnp_x8zip_xm__sse2(size_t n,size_t m,const void *input,void *output)'];
custom_class.h;C++;pytorch-master/pytorch-master/torch; 273;  107; 24;15;  130; 0;0;0;0;0;0.82;0;[];[];
FileStore.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 337;  23; 44;19;  253; 0;138;90;112;70;0.09;29;[];['    FoldPrePackingOps(script::Module & m)', '    insertPrePackedOps(std::shared_ptr & graph)', '    insertPrePackedOps(script::Module & module)', '    optimizeForMobile(script::Module & m)'];
HashStore.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 90;  2; 11;7;  71; 0;46;22;32;19;0.03;7;[];['    FoldPrePackingOps(script::Module & m)', '    insertPrePackedOps(std::shared_ptr & graph)', '    insertPrePackedOps(script::Module & module)', '    optimizeForMobile(script::Module & m)'];
PrefixStore.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 55;  1; 11;1;  43; 0;15;23;12;14;0.02;9;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUYellowFin', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_YellowFin', '    GetLrMu'];
ProcessGroupGloo.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 2387;  147; 244;99;  1254; 664;676;538;825;377;0.12;85;['    final'];['    AfterApply', '    GetLrMu', '    GetSingleArgument', '    MomentumSgdUpdate', '    MovingAverage(const int N,const T *elt,const T *avg,T *new_avg,T *debias_avg)', '    RunOnDevice', '    scratch_tensor_', '    YellowFinOp(const OperatorDef & operator_def,Workspace *ws)', '    ZeroDebiasFactor'];
ProcessGroupNCCL.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 956;  151; 124;16;  683; 5;401;226;244;258;0.22;46;[];['    CAFFE_ANONYMOUS_VARIABLE_CPUZeroGradient', '    CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_ZeroGradient', '    vector', '    vector', '    GetGradientDefs'];
Store.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 16;  3; 5;1;  8; 0;1;6;1;5;0.38;2;['    final'];['    RunOnDevice', '    ZeroGradientOp(Args,...)', '    ~ZeroGradientOp'];
CUDATest.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 13;  2; 5;2;  6; 0;0;6;0;4;0.33;0;[];['    CAFFE_ANONYMOUS_VARIABLE_CUDAZeroGradient'];
ProcessGroupGlooTest.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 433;  38; 63;16;  297; 19;132;155;101;174;0.13;22;['    ZipMicrokernelTester'];['    g(size_t g)', '    g', '    g_', '    iterations(size_t iterations)', '    iterations', '    iterations_', '    n(size_t n)', '    n', '    n_', '    test(pytorch_xzipc_ukernel_function xzip)', '    test(pytorch_xzipv_ukernel_function xzip)'];
StoreTestCommon.hpp;C++;pytorch-master/pytorch-master/torch/lib/c10d/test; 29;  2; 5;3;  21; 0;6;14;4;6;0.10;2;[];['    angle_impl(SCALAR_TYPE z)', '    angle_impl(std::complex z)', '    angle_impl(std::complex z)', '    zabs(SCALAR_TYPE z)', '    ceil_impl(std::complex z)', '    ceil_impl(std::complex z)', '    ceil_impl(TYPE z)', '    conj_impl(TYPE z)', '    floor_impl(std::complex z)', '    floor_impl(std::complex z)', '    floor_impl(TYPE z)', '    imag_impl(std::complex z)', '    imag_impl(SCALAR_TYPE z)', '    imag_impl(std::complex z)', '    max_impl(TYPE a,TYPE b)', '    max_impl(TYPE a,TYPE b)', '    min_impl(TYPE a,TYPE b)', '    min_impl(TYPE a,TYPE b)', '    real_impl(std::complex z)', '    real_impl(SCALAR_TYPE z)', '    real_impl(std::complex z)', '    round_impl(std::complex z)', '    round_impl(std::complex z)', '    round_impl(TYPE z)', '    trunc_impl(std::complex z)', '    trunc_impl(std::complex z)', '    trunc_impl(TYPE z)', '    zabs(std::complex z)', '    zabs(std::complex z)', '    abs', '    arg', '    nearbyint', '    trunc'];
Utils.cpp;C++;pytorch-master/pytorch-master/torch/lib/c10d; 359;  38; 52;13;  265; 0;172;97;210;63;0.14;8;['    C10FlagParser_input_db', '    C10FlagParser_input_db_type', '    C10FlagParser_server'];['    main(int argc,char **argv)', '    C10FlagParser_input_db(const std::string & content)', '    C10FlagParser_input_db_type(const std::string & content)', '    C10FlagParser_server(const std::string & content)'];
err.h;C++;pytorch-master/pytorch-master/torch/lib/libshm; 25;  8; 2;15;  0; 0;0;0;0;0;0.00;0;['    ZmqContext', '    ZmqMessage', '    ZmqSocket'];['    operator=', '    ptr', '    ZmqContext(int io_threads)', '    ZmqContext', '    ~ZmqContext', '    data', '    msg', '    operator=', '    size', '    ZmqMessage', '    ZmqMessage', '    ~ZmqMessage', '    Bind(const string & addr)', '    Connect(const string & addr)', '    Disconnect(const string & addr)', '    Recv(ZmqMessage *msg)', '    RecvTillSuccess(ZmqMessage *msg)', '    Send(const string & msg,int flags)', '    SendTillSuccess(const string & msg,int flags)', '    Unbind(const string & addr)', '    ZmqSocket(int type)', '    ~ZmqSocket'];
core.cpp;C++;pytorch-master/pytorch-master/torch/lib/libshm_windows; 23;  0; 6;5;  12; 0;4;5;3;5;0.00;4;['    ZmqDB', '    ZmqDBCursor'];['    Close', '    NewCursor', '    NewTransaction', '    ZmqDB(const string & source,Mode mode)', '    ~ZmqDB', '    key', '    Next', '    Prefetch', '    Seek(const string &)', '    SeekToFirst', '    Valid', '    value', '    ZmqDBCursor(const string & source)', '    ~ZmqDBCursor', ''];
